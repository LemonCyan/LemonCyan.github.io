[{"path":"/2025/03/14/2-语言-结构算法-数组/","content":"这里有一个循环，把数组中所有的元素都初始化为零 #define N_VALUES 5float values[N_VALUES];float *vp;for( vp = values[0]; vp values[N_VALUES]; )\t*vp++ = 0; for 语句的初始部分把vp 指向数组的第1个元素。 这个例子中的指针运算是用++操作符完成的。增加值 1 与 float 的长度相乘，其结果加到指针vp上。 经过第1次循环之后，指针在内存中的位置? 现在考虑下面这个循环: for( vp = values[N VALUES]; vp values[0]; )\t*--vp =0; 它和前面那个循环所执行的任务相同，但数组元素将以相反的次序清除。 们让 vp 指向数组最后那个元素后面的内存位置，但在对它进行间接访问之前先执行自减操作。当vp指向数组第1个元素时，循环便告终止，不过这发生在第1 个数组元素被清除之后。 有些人可能会反对像*-vp 这样的表达式，觉得它的可读性较差。但是，如果对其进行”简化”看看这个循环会发生什么: for( vp = values[N VALUES - 1]; vp = values[0]; vp-- )\t*vp=0; 现在 vp 指向数组最后一个元素，它的自减操作放在 for 语的调整部分进行。这个循环存在一个问题，能发现它吗? 在数组第 1个元素被清除之后，vp 的值还将减去 1，而接下去的一次比较运算是用于结束循环的。但这就是问题所在: 比较表达式 vpvalues[0]的值是未定义的，因为 p 到了数组的边界之外。标准允许指向数组元素的指针与指向数组最后一个元素后面的那个内存位置的指针进行比较，但不允许与指向数组第 1个元素之前的那个内存位置的指针进行比较 实际上，在绝大多数 C 编译器中，这个循环将顺利完成任务。然而，还是应该避免使用它，因为标准并不保证它可行。 循环和使用下标访问的循环之间的效率比较 如果下标值是从那些已知是正确的值计算得来，那么就无需检查它的值。如果一个用作下标的值是根据某种方法从用户输入的数据产生而来的，那么在使用它之前必须进行检测，确保它们位于有效的范围之内。","categories":["2.语言","结构算法"]},{"title":"DRM+GBM+EGL显示","path":"/2025/03/14/1-平台-Linux-Graphics-DRM-GBM-EGL显示/","content":"DRM (Direct Rendering Manager)、GBM (Generic Buffer Manager) 和 EGL (Embedded-System Graphics Library) 组合在一起，是在 Linux 平台上进行图形渲染和硬件加速的常见方式。这些组件一起提供了一个完整的图形渲染栈，允许应用程序直接与图形硬件进行交互。 DRM（Direct Rendering Manager）：DRM 是 Linux 内核中的一个子系统，用于管理图形硬件的驱动程序。它提供了一种通用的接口，允许用户空间程序直接与硬件交互，通过设备文件 /dev/dri/cardX 访问。DRM 提供了诸如模式设置、显示控制、渲染加速等功能。 GBM（Generic Buffer Manager）：GBM 是一个用于管理图形缓冲区的库，通常与 DRM 配合使用。它提供了一种标准的接口，用于分配、管理和操作图形内存。GBM 还提供了与 EGL 和 OpenGL ES 兼容的接口，使应用程序能够使用硬件加速进行渲染。 EGL（Embedded-System Graphics Library）：EGL 是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。EGL 通常与 GBM 和 DRM 一起使用，通过 GBM 提供的接口来创建图形表面，并将其与 OpenGL 或 OpenGL ES 上下文关联起来，实现硬件加速的图形渲染。","categories":["1.平台","Linux","Graphics"]},{"title":"OpenGL显示","path":"/2025/03/14/1-平台-Linux-Graphics-OpenGL显示/","content":"GLUGLU（OpenGL Utility Library）是 OpenGL 的一个辅助库，提供了一些更高级的几何计算和对象构造函数，如曲面和体的生成、平移、旋转等，这些函数在处理复杂的几何操作时非常有用。 GLFWGLFW 是一个流行的开源库，主要用于创建和管理图形应用程序中的窗口、OpenGL 或 Vulkan 上下文，以及处理用户输入、定时器等功能。适用于各种图形应用程序的开发，提供了窗口管理、上下文管理、输入处理等功能，使开发者能够专注于图形渲染和应用逻辑的实现。 主要功能： 窗口管理： GLFW 允许开发者创建窗口并对其进行管理，包括调整大小、最小化、最大化、关闭等操作。 上下文管理： 它提供了创建 OpenGL 或 Vulkan 上下文的功能，使得图形渲染程序可以在窗口中绘制图形。 输入处理： GLFW 支持处理用户输入，包括键盘输入、鼠标移动和点击、游戏手柄等。 事件处理： 它允许开发者监听和响应各种事件，如窗口大小改变、键盘按键、鼠标移动等。 监视器管理： GLFW 支持多个显示器的管理，可以获取显示器的分辨率、刷新率等信息。 使用步骤： 初始化： 在程序启动时，调用 GLFW 的初始化函数来初始化库。 创建窗口： 使用 GLFW 的窗口创建函数来创建一个窗口并指定其属性，如大小、标题等。 创建上下文： 使用 GLFW 的上下文创建函数来创建一个 OpenGL 或 Vulkan 上下文。 主循环： 在主循环中轮询事件，并根据事件类型做出相应的处理。 渲染： 在渲染阶段，使用 OpenGL 或 Vulkan 等图形 API 绘制场景。 清理： 在程序结束时，调用 GLFW 的清理函数来释放资源并关闭库。 利用 glfw 监视器 Demo #include GLFW/glfw3.h int main() // 初始化 GLFW if (!glfwInit()) return -1; // 获取监视器（显示器）列表 int count; GLFWmonitor** monitors = glfwGetMonitors(count); // 指定要使用的显示设备索引 int monitor_index = 0; // 设置为想要的显示设备索引 // 获取指定索引的显示设备 GLFWmonitor* monitor = (monitor_index count) ? monitors[monitor_index] : NULL; // 获取显示设备的视频模式 const GLFWvidmode* mode = glfwGetVideoMode(monitor); // 创建窗口并指定显示设备 GLFWwindow* window = glfwCreateWindow(mode-width, mode-height, OpenGL Window, monitor, NULL); if (!window) glfwTerminate(); return -1; // 进入主循环 while (!glfwWindowShouldClose(window)) // 渲染代码 glClear(GL_COLOR_BUFFER_BIT); // ... glfwSwapBuffers(window); glfwPollEvents(); // 清理资源 glfwDestroyWindow(window); glfwTerminate(); return 0; GLUT（OpenGL Utility Toolkit） GLUT 是一个跨平台的工具包，用于创建和管理 OpenGL 窗口、处理用户输入等。它提供了一组简单的 API，使得编写基本的 OpenGL 程序变得更加容易。 - GLUT 支持多种操作系统，包括 Windows、Linux 和 macOS。 - 使用 GLUT，可以很快地编写出一个可以在不同平台上运行的简单 OpenGL 程序，而不必担心平台特定的细节。 - 但是，GLUT 对于创建复杂的图形用户界面（GUI）可能不够灵活，因为它的功能相对有限。 GLUT 是一个跨平台的工具包，用于简化 OpenGL 应用程序的开发。它提供了一组函数，用于创建窗口、处理输入事件、进行基本的图形绘制等，使开发者可以更轻松地编写 OpenGL 应用程序，而无需处理底层的窗口系统的细节。 GLUT 提供了一个相对简单的接口，适用于快速原型设计和简单的图形应用程序。它通常用于学习 OpenGL、编写小型游戏、演示程序等。 GLX（OpenGL Extension to the X Window System） GLX 是 OpenGL 在 X Window System 上的扩展，它允许 OpenGL 应用程序与 X 服务器通信，并在 X 窗口系统中创建 OpenGL 上下文。GLX 提供了一组函数，用于在 X 窗口系统中创建 OpenGL 渲染上下文、管理 OpenGL 窗口和图形渲染等。 GLX 允许 OpenGL 应用程序直接与 X 服务器通信，而不需要借助其他库或工具。它提供了对 OpenGL 的完整支持，可以实现高性能的图形渲染和交互。 GLX 则是 OpenGL 在 X 窗口系统上的扩展，提供了与 X 服务器通信和在 X 窗口系统中创建 OpenGL 渲染上下文的功能。 EGL（Embedded Graphics Library）EGL 是一个用于管理图形渲染上下文的接口，通常用于嵌入式系统和移动设备上。 - EGL 是 OpenGL ES 和 OpenVG 的标准的本地显示系统接口，它提供了与底层窗口系统交互的能力。 - 在 Linux 上，EGL 通常与 GBM（Generic Buffer Manager）或其他图形系统配合使用，如 Wayland。 - 使用 EGL，可以在嵌入式系统上更好地控制 OpenGL 上下文的创建和管理，以及与窗口系统的交互。","categories":["1.平台","Linux","Graphics"]},{"title":"Qt Android Linux环境配置","path":"/2025/03/08/2-语言-Qt-Qt-Android-Linux环境配置/","content":"下载 JDK #wget https://download.oracle.com/java/21/latest/jdk-21_linux-x64_bin.tar.gzsudo apt-get install openjdk-8-jdkjava -versionsudo update-alternatives --set java /usr/bin/java 下载 SDK 下载 NDK wget https://dl.google.com/android/repository/android-ndk-r21e-linux-x86_64.zipwget https://dl.google.com/android/repository/android-ndk-r20b-linux-x86_64.zip 下载 open-ssl git clone https://github.com/KDAB/android_openssl.git","categories":["2.语言","Qt"]},{"title":"进程上下文","path":"/2025/03/07/1-平台-Linux-进程线程-进程上下文/","content":"上下文、进程上下文、中断上下文与原子上下文详解上下文的基本概念上下文是从英文“context”翻译而来，意为“环境”。在计算机科学中，特别是操作系统领域，指的是程序或进程在执行时所处的环境。具体来说，进程的上下文包括： 寄存器变量：CPU 寄存器中的值，如程序计数器（PC）、栈指针（SP）等。 内存信息：进程的虚拟地址空间，包括代码段、数据段、堆栈段等。 系统资源：进程打开的文件描述符、信号量、管道等。 进程状态：就绪、运行、阻塞、终止等状态信息。 上下文的概念是操作系统实现进程切换和内核态用户态切换的基础。 原子操作的概念原子（atom）本意是“不可分割的最小粒子”，而原子操作（atomic operation）则指“不可被中断的一个或一系列操作”。在计算机科学中，原子操作确保在多线程或多进程环境中，关键代码段只能由一个线程或进程执行，防止数据不一致或竞态条件。 例如，一个递增操作（i++）在汇编层面通常分为读取、加一、写回三个步骤。如果在读取和写回之间被中断，可能导致多个进程读取到相同的值，导致最终结果不正确。通过原子操作，可以确保这三个步骤作为一个整体执行，避免竞态条件。 为什么会有上下文的概念？现代操作系统的两种主要运行模式是内核空间和用户空间： 内核空间：内核模块运行在内核空间，具有最高权限，可以直接访问硬件资源。 用户空间：用户态应用程序运行在用户空间，权限较低，无法直接访问硬件资源。 当用户空间的应用程序需要访问硬件资源（如读写文件、网络通信）时，必须通过系统调用进入内核空间。这个过程涉及上下文切换： 用户态到内核态：切换到内核空间，使用内核的地址空间和寄存器。 内核态到用户态：系统调用完成后，切换回用户空间，恢复原进程的上下文。 进程上下文进程上下文是进程执行时的环境，包括： 用户级上下文： 代码段（text） 数据段（data） 用户堆栈（user stack） 共享存储区（shared memory） 寄存器上下文： 通用寄存器（如 EAX、EBX） 程序计数器（EIP） 状态寄存器（EFLAGS） 栈指针（ESP） 系统级上下文： 进程控制块（task_struct） 内存管理信息（mm_struct、vm_area_struct、pgd、pte） 内核栈（kernel stack） 当操作系统需要切换进程时，必须保存当前进程的上下文，并恢复下一个进程的上下文。这一过程称为进程切换或上下文切换。 示例：假设进程 A 正在运行，调度器决定切换到进程 B。操作系统会保存进程 A 的寄存器值、内存映射等信息，并加载进程 B 的上下文，继续执行进程 B。 中断上下文中断上下文是硬件通过中断信号触发，导致内核调用中断处理程序进入内核空间的环境。中断上下文主要包括： 硬件传递的参数（如中断号、错误码） 被中断进程的环境（如寄存器值） 中断处理程序通常在中断上下文中运行，这种上下文与任何进程无关。中断处理程序的主要任务是处理硬件事件（如键盘按键、磁盘完成），并可能唤醒等待该事件的进程。 示例：进程 A 等待磁盘读取完成，进入睡眠状态。磁盘完成读取后，硬件触发中断，中断处理程序唤醒进程 A。 进程上下文 VS 中断上下文 特性 进程上下文 中断上下文 触发方式 进程调度或系统调用 硬件中断信号 上下文切换 需要保存和恢复进程的所有状态 只需要保存恢复寄存器 可抢占性 可以被其他进程抢占 不可被中断，直到处理完成 访问用户空间 允许 不允许 睡眠 允许 不允许 与进程关联 与特定进程相关 与硬件事件相关，不依赖进程 原子上下文原子上下文是指内核处于不可中断、不可抢占的状态，通常出现在以下情况： 硬中断处理：中断处理程序执行时，CPU 无法被其他中断打断。 软中断处理：处理内核的一些异步任务（如网络数据处理）。 持有自旋锁：自旋锁占用时，内核禁止抢占。 在原子上下文中，内核不能： 访问用户空间虚拟内存：因为没有关联的进程上下文。 进入睡眠状态：会导致系统无法唤醒。 占用互斥体：可能导致死锁。 执行耗时任务：会影响系统实时性。 示例：在中断处理程序中，不能调用 sleep() 函数，否则会导致系统崩溃。 原子上下文的判断内核提供了四个宏来判断是否处于原子上下文： in_irq()：判断是否在硬中断处理中。 in_softirq()：判断是否在软中断处理中。 in_interrupt()：判断是否在硬中断或软中断处理中。 in_atomic()：判断是否在原子上下文中（包括硬中断、软中断或持有自旋锁）。 这些宏通过检查 thread_info-preempt_count 的值来判断上下文状态。preempt_count 是一个位掩码，记录了系统的抢占状态。 总结 上下文是操作系统实现进程切换和内核态用户态切换的基础。 进程上下文与特定进程相关，用于进程切换。 中断上下文与硬件事件相关，用于处理中断。 原子上下文是不可中断、不可抢占的状态，通常出现在中断处理或持有自旋锁时。 理解这些概念有助于掌握操作系统的内核机制，尤其是在处理并发、同步和中断时。","categories":["1.平台","Linux","进程线程"]},{"title":"死锁","path":"/2025/03/07/1-平台-Linux-进程线程-死锁/","content":"死锁1. 死锁的概念在多道程序系统中，多个进程的并发执行提高了系统资源利用率和处理能力，但也带来了死锁问题。死锁是指多个进程因竞争资源而陷入僵局，无法推进，若无外力作用则永远无法解除。 1.1 系统资源的竞争系统中不可剥夺资源（如 CPU、内存）数量有限，多个进程竞争时可能导致死锁。例如，两个进程各占一台打印机，各自等待另一台，导致僵局。可剥夺资源（如 CPU 时间片）不会引起死锁。 1.2 进程推进顺序非法资源请求和释放顺序不当会导致死锁。例如，进程 A 先请求资源 1，再请求资源 2，而进程 B 先请求资源 2，再请求资源 1，若同时占用对方资源，双方都无法继续。 1.3 信号量使用不当进程间相互等待消息也会引发死锁。例如，进程 A 等待进程 B 的消息，进程 B 又等待进程 A 的消息，双方永远无法推进。 2. 死锁的必要条件死锁需同时满足以下四个条件： 互斥条件：资源独占。例如，打印机只能由一个进程使用。 不剥夺条件：资源只能由占有进程释放。例如，进程占用内存直到完成。 请求和保持条件：进程占有资源又请求其他资源。例如，进程 A 占用资源 1，请求资源 2。 循环等待条件：形成资源循环等待链。例如，A 等待 B 的资源，B 等待 A 的资源。 3. 死锁的处理策略3.1 破坏死锁条件破坏任一条件即可预防死锁： 破坏互斥条件：允许资源共享，但不可行。 破坏不剥夺条件：允许资源抢占，但可能导致进程失败。 破坏请求和保持条件：一次性分配所有资源，避免部分分配。 破坏循环等待条件：按编号顺序分配资源，避免循环。 3.2 预防死锁在资源分配前检查安全性，避免进入不安全状态： 预先静态分配：进程启动前一次性分配所需资源，避免动态请求。 资源利用率低：资源可能闲置，导致浪费和饥饿。 4. 死锁避免4.1 安全状态系统能按安全序列为每个进程分配资源，满足最大需求则为安全状态。安全状态可避免死锁。 4.2 银行家算法模拟银行家贷款，确保每次分配后系统安全： 数据结构：Available、Max、Allocation、Need 矩阵。 步骤： 检查请求是否超过需求。 检查资源是否足够。 试探分配，更新数据结构。 执行安全性算法，确认安全后正式分配。 4.3 安全性算法检查系统是否安全： 初始化 Work 为 Available，Finish 为 false。 找出可满足条件的进程，分配资源，更新 Work 和 Finish。 重复直到所有进程完成或无法继续。 5. 死锁检测和解除5.1 检测通过资源分配图简化检测死锁： 找出可运行进程，释放资源。 更新图，重复直到无法简化。 若图不可简化，系统死锁。 5.2 解除一旦检测到死锁，采取措施： 资源剥夺法：挂起进程，抢占资源。 进程撤销法：撤销进程，释放资源。 进程回退法：回退进程到避免死锁的状态。 通过以上策略，可以有效预防、避免和处理死锁，确保系统稳定运行。","categories":["1.平台","Linux","进程线程"]},{"title":"同步","path":"/2025/03/07/1-平台-Linux-进程线程-同步/","content":"进程同步1. 进程同步的基本概念在多道程序环境中，进程是并发执行的，不同进程间存在着复杂的相互制约关系。为了协调这些关系，实现资源共享和进程协作，避免冲突，引入了进程同步的概念。 （1） 临界资源多个进程可以共享系统资源，但某些资源一次只能被一个进程使用，这些资源称为临界资源。例如，打印机、磁盘等。访问临界资源的代码段称为临界区。 为了安全访问临界资源，进程的执行分为四个部分： 进入区：检查是否能进入临界区。 临界区：访问临界资源的代码。 退出区：清除占用标志。 剩余区：其他代码。 do // 进入区 entry section(); // 临界区 critical section(); // 退出区 exit section(); // 剩余区 remainder section(); while (true); （2） 同步同步是进程间直接制约关系，用于协调任务顺序。例如，生产者-消费者问题中，生产者必须在消费者取之前生产。 （3） 互斥互斥是进程间间接制约关系，确保临界资源独占访问。例如，打印机的使用。 2. 实现临界区互斥的基本方法通过在进入区设置标志位，检查和等待，实现互斥。 （1） 硬件实现方法利用硬件指令实现低级互斥。 1. 中断屏蔽方法在临界区执行时屏蔽中断，防止切换。例如，内核更新变量时。 优点：简单。 缺点：降低效率，用户进程不宜使用。 2. 硬件原子指令法使用 TestAndSet 和 Swap 指令。 TestAndSet 指令：原子操作，检查并设置标志。 Boolean TestAndSet(Boolean *lock) Boolean old = *lock; *lock = true; return old; Swap 指令：交换两个变量的值。 void Swap(Boolean *a, Boolean *b) Boolean temp = *a; *a = *b; *b = temp; 优点：简单，支持多处理器。 缺点：忙等，可能导致饥饿。 3. 信号量信号量是强大机制，解决互斥和同步。 （1） 整形信号量表示资源数量。 （2） 记录性信号量包含资源计数和等待队列。 typedef struct int value; struct process *L; semaphore; Wait 操作：请求资源，若不足则阻塞。 Signal 操作：释放资源，唤醒等待进程。 （3） 实现同步与互斥 同步：通过信号量协调进程顺序。 互斥：信号量控制同一资源的访问。 4. 管程管程是数据结构和操作组成的软件模块，管理共享数据。 局部数据：只能通过管程内过程访问。 互斥访问：编译器自动处理，避免冲突。 5. 经典同步问题（1） 生产者-消费者问题共享缓冲区，协调生产者和消费者。 解决步骤： 关系分析：生产者和消费者是同步关系。 整体思路：使用信号量 mutex、full、empty。 信号量设置： mutex：互斥访问，初值 1。 full：已满缓冲区数，初值 0。 empty：空缓冲区数，初值 n。 （2） 读者-写者问题允许多个读者同时读，写者独占。 解决步骤： 关系分析：读者和写者互斥。 整体思路：使用计数器和信号量。 信号量设置： count：记录读者数，初值 0。 mutex：互斥访问计数器。 rw：读者和写者互斥。 （3） 哲学家进餐问题五位哲学家交替拿筷子。 解决步骤： 关系分析：哲学家与邻居互斥。 整体思路：避免死锁和饥饿。 信号量设置： chopsticks：五个互斥信号量。 （4） 吸烟者问题供应者提供材料，吸烟者制作烟。 解决步骤： 关系分析：供应者与吸烟者同步。 整体思路：协调材料组合。 信号量设置： offer1、offer2、offer3：材料组合。 finish：互斥抽烟。","categories":["1.平台","Linux","进程线程"]},{"title":"线程调度","path":"/2025/03/07/1-平台-Linux-进程线程-线程调度/","content":"2.2 线程的调度1. 调度的概念在多道程序系统中，进程的数量往往多于处理器的个数，进程争用处理器的情况在所难免。处理器调度是对处理器进行分配，即从就绪队列中按照一定的算法选择一个进程，并将处理器分配给它运行，以实现进程的并发执行。 处理器调度是多道程序操作系统的基础，是操作系统设计的核心问题。 一个作业从提交开始到完成，往往要经历以下三级调度： 作业调度作业调度又称高级调度。其主要任务是按一定的原则从外存上处于后备状态的作业中挑选一个或多个作业，分配内存、输入输出设备等必要的资源，并建立相应的进程，使其获得竞争处理器的权利。在多道批处理系统中大多配有作业调度，而在其他系统中通常不需要配置作业调度。作业调度的执行频率较低，通常为几分钟一次。 中级调度中级调度又称内存调度。引入中级调度是为了提高内存利用率和系统吞吐率。为此，应将那些暂时不能运行的进程调至外存等待，把此时的进程状态称为挂起状态。当它们具备运行条件且内存有空闲时，由中级调度决定将外存上具备运行条件的就绪进程重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待。 进程调度进程调度又称为低级调度，其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理器分配给它。进程调度是操作系统中最基本的一种调度，在一般操作系统中都不需配置进程调度。进程调度的频率很高，通常为几十毫秒一次。 作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程。这些进程被送入就绪队列。进程调度从就绪队列中选出一个进程，并将其状态改为运行状态，把 CPU 分配给它。中级调度是位于高级调度和低级调度之间的一种调度。为了提高内存的利用率，系统将那些暂时不能运行的进程挂起。当内存空间宽松时，通过中级调度选择具备运行条件的进程，将其唤醒。 2. 调度的时机、切换与过程进程调度和切换程序是操作系统内核程序。当请求调度的事件发生后，才可能会运行进程调度程序，当调度了新的就绪进程后，才会去进行进程间的切换。 现在操作系统中，不能进行进程的调度与切换的情况有以下几种： 在处理中断的过程中中断处理过程复杂，在实现上很难做到，而且中断处理时系统工作的一部分，逻辑上不属于某一进程，不应被剥夺处理器资源。 进程在操作系统内核程序临界区中进入临界区后，需要独占式的访问共享数据，理论上必须加锁，以防止其他并行程序的进入，在解锁前不应该切换到其他进程，以加快该共享数据的释放。 其他需要完全屏蔽中断的原子操作过程中如加锁、解锁、中断现场保护、恢复等源自操作。在原子过程中，连中断都要屏蔽，更不应该进行进程的切换。 如果在上述过程中发生了引起调度的条件，并不能马上进行调度和切换，应置系统请求调度标志，直到上述过程结束后才能进行相应的调度和切换。 应该进行进程的调度与切换的情况有： 当发生引起调度条件且当前进程无法继续运行下去时可以马上进行调度与切换。如果操作系统只在这种情况下进行进程调度，就是非剥夺调度。 当中断处理结束后或自陷处理结束后返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。如果操作系统支持这种情况下的运行调度程序，就实现了剥夺方式的调度。 进程切换往往在调度完成后立刻发生，它要求保存源进程当前切换点的县城信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将远近程的现场信息推入到当前进程的内核对战来保存它们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的县城信息、更新当前运行进程空间指针、重设 PC 寄存器等相关工作之后，开始运行新的进程。 3. 进程调度方式所谓进程调度方式是指当某一个进程正在处理器上执行时，若有某个更为重要或紧迫的进程需要处理，既有优先权更高的进程进入就绪队列，此时应如何分配处理器。通常有以下两种进程调度方式： 非剥夺调度方式非剥夺调度方式又称为非抢占调度方式，是指当一个进程正在处理器上执行时，即使有某个更为重要或紧迫的进程进入就绪状态，仍然让正在执行的进程继续执行，直到该进程完成或发生某种事件而进入阻塞状态时，才把处理器分配给更为重要或紧迫的进程。 剥夺调度方式 剥夺调度方式又称为抢占方式，是指当一个进程正在处理器上执行时，若有某个更为重要或紧迫的进程需要使用处理器，则立即暂停正在执行的进程，将处理器分配给这个更为重要或紧迫的进程。 “剥夺”不是一种任意性行为，必须遵循一定的原则：优先权原则、短进程优先原则和时间片原则。 4. 调度的基本准则不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法所具有的特性。为了比较处理器调度算法的性能，人们提出很多评价准则，下面介绍主要的几种准则： CPU 利用率 CPU 是计算机系统中最重要的资源之一，所以应尽可能使 CPU 保持在忙状态，以提高这一资源利用率最高。 系统吞吐量 系统吞吐量表示单位时间内 CPU 完成作业的数量。长作业需要消耗较长的处理器时间，因此会降低系统的吞吐量。而对于短作业，他们所需要消耗的处理器时间短，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。 周转时间 周转时间是指从作业提交到作业完成所经历的时间，包括作业等待、在就绪队列中排队、在处理器上运行以及进行输入输出操作所花费的时间的总和。 作业的周转时间作业完成时间-作业提交时间。 等待时间 等待时间是指进程处于等处理器状态时间之和，等待时间越长，用户满意度越低。处理器调度算法实际上并不影响作业执行或输入输出操作时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法优劣常常只需简单地考察等待时间。 响应时间 响应时间是指从用户提交请求到系统首次产生响应的时间。在交互式系统中，周转时间不可能是最好的评测准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户的角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能够接受的范围之内。 5. 典型的调度算法通常系统的设计目标不同，所采用的调度算法也不同。在操作系统中存在多种调度算法，其中有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面介绍几种常用的调度算法： FCFS（先来先服务）调度算法 特点：算法简单，但是效率低；有利于长作业，不利于短作业；有利于 CPU 繁忙型作业而不利于 IO 繁忙型作业。 SJF（短作业优先）调度算法 短作业（进程）优先调度算法是指对短作业或进程优先调度的算法。短作业优先调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们放入内存运行。 SJF 调度算法的缺点： 对长作业不利。 完全未考虑作业的紧迫程度。 由于作业的长短只根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。 注意：SJF 调度算法的平均等待时间、平均周转时间最少。 优先级调度算法 根据进程的优先级来决定调度顺序。优先级可以是静态的（在作业提交时确定）或动态的（根据系统情况变化）。 高响应比优先调度算法 高响应比优先调度算法主要用于作业调度。同时考虑从每个作业的等待时间和估计需要运行的时间。 时间片轮转调度算法 时间片轮转调度算法主要适用于分时系统。每个进程分配一个时间片，时间片结束后轮转到下一个进程。 多级反馈队列调度算法 多级反馈队列调度算法主要是时间片轮转调度算法和优先级调度算法的综合和发展。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。","categories":["1.平台","Linux","进程线程"]},{"title":"信号量","path":"/2025/03/07/1-平台-Linux-进程线程-信号量/","content":"进程间 System V IPC 通信之 信号量 信号量  信号量是一种 system v 提供的进程间同步的机制。  信号量是线程间信号量机制在进程间的扩展实现  之前学的 posix 线程信号机制：sem_init、sem_wait、sem_post、sem_destory  进程间 system v 信号机制：  semget：初始化，对应 sem_init  semop： P、V 操作，对应 sem_wait、sem_post  semctl： 删除信息，对应 sem_destroy  不同点：  进程间信号一次可操作多个信号灯，更复杂一点。 信号量 所需头文件 #include systypes.h #include sysipc.h #include syssem.h 函数原型 int semget(key_t key, int nsems, int semflg); 函数参数 key：和信号灯集关联的 key 值 nsems: 信号灯集中包含的信号灯数目 semflg：信号灯集的访问权限，通常为 IPC_CREAT | 0666 函数返回值 成功：信号灯集 ID 出错：-1 信号量 所需头文件 #include systypes.h #include sysipc.h #include syssem.h 函数原型 int semop ( int semid, struct sembuf *opsptr, size_t nops); 函数参数 semid：信号灯集 ID opsptr：要操作的信号灯数组 struct sembuf { short sem_num; 要操作的信号灯的编号 short sem_op; 0 : 等待，直到信号灯的值变成 0 1 : 释放资源，V 操作 -1 : 分配资源，P 操作 short sem_flg; 0, IPC_NOWAIT, SEM_UNDO }; nops: 要操作的信号灯的个数 函数返回值 成功：0 出错：-1 信号量  struct sembuf sops[2];  int semid;  * Code to set semid omitted *  sops[0].sem_num 0; * Operate on semaphore 0 *  sops[0].sem_op 0; * Wait for value to equal 0 *  sops[0].sem_flg 0;  sops[1].sem_num 0; * Operate on semaphore 0 *  sops[1].sem_op 1; * Increment value by one *  sops[1].sem_flg 0;  if (semop(semid, sops, 2) -1) {第二个参数是标识要操作的信号灯，如果多于一个，使用数组存放，第三个参数标识数组中元素个数  perror(“semop”);  exit(EXIT_FAILURE);  } 信号量  信号量被占用之后，一般不会自动释放，如果程序意外崩溃，可能导致 信号量得不到释放而死锁。  设置 sops 的 SEM_UNDO 标识位，可在程序终止时自动释放申请的信号量。  sops[1].sem_num 0; * Operate on semaphore 0 *  sops[1].sem_op 1; * Increment value by one *  sops[1].sem_flg SEM_UNDO;  思考：如何设计一个程序，每次开机后只能运行一次。 信号量 所需头文件 #include systypes.h #include sysipc.h #include syssem.h 函数原型 int semctl ( int semid, int semnum, int cmd…union semun arg); 函数参数 semid：信号灯集 ID semnum: 要修改的信号灯编号 cmd： GETVAL：获取信号灯的值 SETVAL：设置信号灯的值 IPC_RMID：从系统中删除信号灯集合 函数返回值 成功：0 出错：-1 信号量 union semun { int val; * Value for SETVAL * struct semid_ds buf; Buffer for IPC_STAT, IPC_SET * unsigned short array; Array for GETALL, SETALL * struct seminfo __buf; Buffer for IPC_INFO * };  semctl(semid, 0, SETVAL, 3);设置第 0 个信号的初始值是 3","categories":["1.平台","Linux","进程线程"]},{"title":"消息队列","path":"/2025/03/07/1-平台-Linux-进程线程-消息队列/","content":"概念消息队列是一种进程间通信（IPC）的机制，允许进程通过发送和接收消息进行数据交换。它是内核中的一个链表，所有进程可见，通过操作该链表完成通信。 特点 消息链表：消息队列本质上是内核中的一个链表，进程可以在其中添加或移除消息节点。 消息类型：支持不同消息类型，进程可选择性接收特定类型的消息。 原子操作：消息的发送和接收是原子操作，确保数据完整性。 广泛应用：消息队列是最常用的进程通信方式之一。 消息结构消息结构通常包含两部分： struct msgbuf long mtype; // 消息类型，必须大于0 char mtext[N]; // 消息正文; 操作函数1. 创建或打开消息队列int msgget(key_t key, int msgflg); 参数： key：消息队列的键，通常由 ftok 生成。 msgflg：标志位，用于控制创建行为。 返回值： 成功：消息队列 ID 失败：-1 2. 发送消息int msgsnd(int msqid, const void *msgp, size_t size, int flag); 参数： msqid：消息队列 ID。 msgp：消息指针，指向 msgbuf 结构。 size：消息正文大小。 flag：控制阻塞行为。 返回值： 成功：0 失败：-1 3. 接收消息ssize_t msgrcv(int msqid, void *msgp, size_t size, long msgtype, int flag); 参数： msqid：消息队列 ID。 msgp：接收缓冲区指针。 size：接收缓冲区大小。 msgtype：接收消息类型。 flag：控制阻塞行为。 返回值： 成功：接收消息长度 失败：-1 4. 控制消息队列int msgctl(int msqid, int cmd, struct msqid_ds *buf); 参数： msqid：消息队列 ID。 cmd：操作命令（IPC_STAT、IPC_SET、IPC_RMID）。 buf：消息队列属性结构指针。 返回值： 成功：0 失败：-1 消息队列结构struct msqid_ds struct ipc_perm msg_perm; // 权限信息 struct msg *msg_first; // 队列第一个消息 struct msg *msg_last; // 队列最后一个消息 __kernel_time_t msg_stime; // 最后发送时间 __kernel_time_t msg_rtime; // 最后接收时间 __kernel_time_t msg_ctime; // 最后修改时间 unsigned long msg_lcbytes; // 循环字段 unsigned long msg_lqbytes; // 循环字段 unsigned short msg_cbytes; // 当前队列字节数 unsigned short msg_qnum; // 消息数量 unsigned short msg_qbytes; // 最大队列字节数 __kernel_ipc_pid_t msg_lspid; // 最后发送进程ID __kernel_ipc_pid_t msg_lrpid; // 最后接收进程ID; 优势 避免临界区保护：消息队列无需额外的同步机制。 选择性接收：通过消息类型实现精准接收。 消息完整性：保证消息原子性，避免数据损坏。 示例发送进程（send.c）#include stdio.h#include stdlib.h#include sys/types.h#include sys/ipc.h#include sys/msg.h#define MSGKEY 1024#define MSG_SIZE 2048struct msgstru long msgtype; char msgtext[MSG_SIZE];;int main() struct msgstru msgs; int msqid; int msg_type; char str[256]; // 获取消息队列 msqid = msgget(MSGKEY, IPC_EXCL); if (msqid 0) // 创建消息队列 msqid = msgget(MSGKEY, IPC_CREAT | 0666); if (msqid 0) perror(msgget failed); exit(EXIT_FAILURE); while (1) printf(输入消息类型（0结束）：); scanf(%d, msg_type); if (msg_type == 0) break; printf(输入消息内容：); scanf(%s, str); msgs.msgtype = msg_type; strcpy(msgs.msgtext, str); // 发送消息 if (msgsnd(msqid, msgs, sizeof(struct msgstru), IPC_NOWAIT) 0) perror(msgsnd failed); exit(EXIT_FAILURE); // 删除消息队列 msgctl(msqid, IPC_RMID, NULL); return 0; 接收进程（receive.c）#include stdio.h#include stdlib.h#include unistd.h#include sys/types.h#include sys/ipc.h#include sys/msg.h#define MSGKEY 1024#define MSG_SIZE 2048struct msgstru long msgtype; char msgtext[MSG_SIZE];;void childproc() struct msgstru msgs; int msgid; int ret_value; while (1) // 获取消息队列 msgid = msgget(MSGKEY, IPC_EXCL); if (msgid 0) printf(消息队列不存在，5秒后重试... ); sleep(5); continue; // 接收消息 ret_value = msgrcv(msgid, msgs, sizeof(struct msgstru), 0, 0); if (ret_value 0) perror(msgrcv failed); continue; printf(接收消息：%s，进程ID：%d , msgs.msgtext, getpid()); int main() int i; pid_t cpid; for (i = 0; i 5; ++i) cpid = fork(); if (cpid == -1) perror(fork failed); exit(EXIT_FAILURE); else if (cpid == 0) childproc(); return 0; 注意事项 权限设置：确保消息队列权限（如 0666）允许适当的访问。 错误处理：检查函数返回值，处理可能的错误。 类型匹配：发送和接收时确保 msgtype 匹配。 内存管理：避免内存泄漏，正确处理接收缓冲区。 通过以上详细说明和示例，消息队列的使用和优势更加清晰，适用于需要可靠进程间通信的场景。","categories":["1.平台","Linux","进程线程"]},{"title":"进程间通讯","path":"/2025/03/07/1-平台-Linux-进程线程-进程间通讯/","content":"进程间通信进程间通信方式 管道（pipe） 特点：用于具有亲缘关系的进程间通信，数据在内存中传输。 特性：单工通信，数据只能单向流动。 应用场景：常用于父子进程之间的通信。例如，父进程通过 pipe 将数据传递给子进程。 命名管道（FIFO） 特点：可用于任意进程间通信，数据在内存中传输。 特性：双工通信，需要有文件名。 应用场景：适用于客户端和服务器之间的通信。例如，客户端通过 FIFO 向服务器发送请求。 信号（signal） 特点：唯一的异步通信方式。 特性：信号是事件驱动的，用于通知进程某个事件的发生。 应用场景：常用于异常处理。例如，接收中断信号 SIGINT 时，进程可以选择终止或处理。 消息队列（msg） 特点：常用于客户端-服务器模式，按消息类型访问，可有优先级。 特性：消息队列允许进程以消息的形式发送和接收数据。 应用场景：适用于需要不同优先级处理的场景。例如，高优先级的消息可以被优先处理。 共享内存（shm） 特点：效率最高，直接访问内存。 特性：需要同步和互斥机制，防止数据竞态。 应用场景：适用于需要高效数据共享的场景。例如，多个进程同时读写同一块内存。 信号量（sem） 特点：用于实现同步和互斥。 特性：信号量可以控制对共享资源的访问。 应用场景：常用于控制共享内存的访问。例如，使用信号量实现互斥锁。 理解进程间通信 Unix 进程间通信的历史 起源：Linux 的进程间通信手段主要来源于 Unix 平台。 System V IPC：由 ATT 的贝尔实验室开发，包括消息队列、信号灯和共享内存，通信局限在单个计算机内。 BSD IPC：由加州大学伯克利分校开发，引入了基于套接口的进程间通信，突破了单机限制。 Linux：继承了 System V 和 BSD 的特点，提供了丰富的 IPC 机制。 Unix IPC 的发展 初始 Unix IPC：包括管道、FIFO 和信号。 System V IPC：扩展了消息队列、信号灯和共享内存。 Posix IPC：提供了 Posix 消息队列、Posix 信号灯和 Posix 共享内存，具有更好的可移植性。 System V IPC 对象 创建和访问 IPC 对象 **ftok()**：生成 IPC 键，用于唯一标识 IPC 对象。 **msg_get()、shm_get()、sem_get()**：打开或创建 IPC 通道。 参数： int id：IPC 对象的 ID。 key_t key：IPC 键。 pathname：用于生成 IPC 键的路径名。 IPC 对象操作 消息队列： msgsnd(): 发送消息。 msgrcv(): 接收消息。 msgctl(): 控制消息队列。 共享内存： shmat(): 映射共享内存。 shmdt(): 卸载共享内存。 shmctl(): 控制共享内存。 信号量： semop(): 信号量操作。 semctl(): 控制信号量。 进程间通信之共享内存 共享内存原理 物理内存映射：操作系统提供一块物理内存，映射到多个进程的虚拟地址空间。 虚拟内存映射：多个进程的虚拟内存指向同一块物理内存。 注意事项 同步机制：需要依靠进程间同步机制（如信号量）保护临界资源。 互斥机制：防止多进程同时操作共享内存导致数据不一致。 共享内存示例 问题：多个进程同时写入共享内存可能导致数据竞态。 解决方案：使用信号量实现互斥，确保只有一个进程可以访问共享内存。 通过以上详细说明，读者可以更好地理解进程间通信的各种机制及其应用场景。","categories":["1.平台","Linux","进程线程"]},{"title":"共享内存","path":"/2025/03/07/1-平台-Linux-进程线程-共享内存/","content":"原理共享内存是一种进程间通信（IPC）的机制，允许多个进程共享同一块物理内存区域。操作系统将这块内存映射到每个参与进程的虚拟地址空间中，从而实现高效的数据交换。具体来说： 物理内存分配：操作系统在内核预先申请了一部分内存，供多个进程共享。 虚拟内存映射：每个进程的虚拟内存映射表中都指向这块物理内存，允许进程通过自己的虚拟地址访问共享内存。 高效访问：共享内存的访问速度接近于进程内的内存访问，因为它直接操作物理内存，而无需经过内核的数据复制。 注意事项 同步机制：多个进程同时操作共享内存时，必须使用进程间同步机制（如信号量、互斥锁）来保护临界资源，防止竞态条件和数据不一致。 数据格式：共享内存中的数据需要自定义格式，确保所有进程理解和使用相同的数据结构。 共享内存创建之后，一直存在于内核中，直到被删除或或者系统关闭共享内存和管道不一样，读取后，内容仍在共享内存中 优点 速度快：共享内存是最快的 IPC 方法之一，适合需要频繁、大量数据交换的场景。 简单操作：无需复杂的数据复制，直接修改共享内存中的数据即可影响其他进程。 高效内存使用：避免了数据复制，减少内存占用和复制开销。 缺点 同步复杂性：需要额外的同步机制，增加了程序的复杂性。 数据格式管理：必须自定义数据格式，确保所有进程的一致性。 管理复杂：共享内存的创建、映射、删除需要手动管理，容易导致内存泄漏。 ipcs –m 显示共享内存的信息（root 权限才能显示所有的共享内存信息） ipcrm –m shmid 删除指定的共享内存（没人用时才被删掉） ipcs –a 显示所有的 ipc 对象信息，包括共享内存、消息队列、信号量。 共享内存 API以下是使用共享内存的主要 API： 1. ftok()生成一个共享内存的唯一标识符。 key_t ftok(const char *pathname, int proj_id); 参数： pathname：用于生成键的文件路径。 proj_id：项目标识符，通常是一个字符。 作用：将文件路径和项目 ID 组合生成一个唯一的键，类似于域名解析为 IP 的过程。 示例： key_t key = ftok(shared_memory.txt, m); 2. shmget()创建或获取一段共享内存。 int shmget(key_t key, int size, int shmflag); 参数： key：从 ftok() 获取的键，或 IPC_PRIVATE 创建私有段。 size：共享内存的大小（字节）。 shmflag：权限标志，类似文件权限（如 0666 表示所有用户读写）。 返回值：共享内存 ID（成功）或-1（失败）。 key 为 shm 产生前的索引值，一般可以设为： - ftok 的返回值。只要其他进程知道 ftok 的参数，即文件和工程号就可以生成相同的 key，使用它找到、使用这块共享内存。 - 自定义的值。自己随便定义一个，只要其他进程知道这个值就可以找到并使用这块共享内存。- IPC_PRIVATEsize：要申请的共享内存区大小，注意共享内存不能无限大，每个系统共享内存区大小时固定的，但在系统中可以配置，默认都大于 32MB。shmflg 为标识位，可由以下常用标记组成 - IPC_CREAT shmid 标识的共享内存区不存在则创建，存在则打开。 - IPC_EXCL 和 IPC_CREAT 同时使用，shmid 标识的共享内存区存在时返回错误。0600 如果共享内存时新创建的，标识该共享内存的用户权限。 示例： int shmid = shmget(IPC_PRIVATE, 1024, 0666);if (shmid == -1) perror(shmget failed); exit(EXIT_FAILURE); 3. shmat()将共享内存映射到进程的虚拟地址空间。 void *shmat(int shmid, const void *shmaddr, int shmflag); 参数： shmid：共享内存 ID。 shmaddr：映射地址，NULL 表示让系统自动分配。 shmflag：访问标志，如 SHM_RDONLY 只读。 返回值：映射后的地址（成功）或 (void *) -1（失败）。 示例： char *shmaddr = shmat(shmid, NULL, 0);if (shmaddr == (void *) -1) perror(shmat failed); exit(EXIT_FAILURE); 4. shmctl()控制和管理共享内存段。 int shmctl(int shmid, int cmd, struct shmid_ds *buf); 参数： shmid：共享内存 ID。 cmd：命令，如 IPC_STAT 获取属性，IPC_SET 设置属性，IPC_RMID 删除段。 buf：指向 shmid_ds 结构体的指针，用于获取或设置属性。 返回值：成功返回 0，失败返回-1。 示例： if (shmctl(shmid, IPC_RMID, NULL) == -1) perror(shmctl failed); exit(EXIT_FAILURE); 5. shmdt()分离共享内存段。 int shmdt(const void *shmaddr); 参数： shmaddr：共享内存映射后的地址。 返回值：成功返回 0，失败返回-1。 示例： if (shmdt(shmaddr) == -1) perror(shmdt failed); exit(EXIT_FAILURE); 使用步骤1. 创建共享内存使用 shmget() 创建共享内存段。 int shmid = shmget(IPC_PRIVATE, 1024, 0666);if (shmid == -1) perror(shmget failed); exit(EXIT_FAILURE); 2. 映射共享内存使用 shmat() 将共享内存映射到进程地址空间。 char *shmaddr = shmat(shmid, NULL, 0);if (shmaddr == (void *) -1) perror(shmat failed); exit(EXIT_FAILURE); 3. 访问共享内存像操作普通内存一样读写共享内存。 // 写入共享内存strcpy(shmaddr, Hello, shared memory!);// 读取共享内存printf(Shared memory contents: %s , shmaddr); 4. 分离共享内存使用 shmdt() 分离共享内存。 if (shmdt(shmaddr) == -1) perror(shmdt failed); exit(EXIT_FAILURE); 5. 删除共享内存使用 shmctl() 删除共享内存段。 if (shmctl(shmid, IPC_RMID, NULL) == -1) perror(shmctl failed); exit(EXIT_FAILURE); 完整示例以下是一个完整的共享内存示例，展示了创建、映射、写入、读取和清理共享内存的过程： #include stdio.h#include stdlib.h#include string.h#include sys/types.h#include sys/ipc.h#include sys/shm.hint main() int shmid; char *shmaddr; // 创建共享内存段（1024字节，读写权限） shmid = shmget(IPC_PRIVATE, 1024, 0666); if (shmid == -1) perror(shmget); exit(EXIT_FAILURE); printf(Shared memory ID: %d , shmid); // 映射共享内存段 shmaddr = shmat(shmid, NULL, 0); if (shmaddr == (void *) -1) perror(shmat); exit(EXIT_FAILURE); // 写入共享内存 char* message = Hello, shared memory!; strcpy(shmaddr, message); printf(Written to shared memory: %s , shmaddr); // 分离共享内存 if (shmdt(shmaddr) == -1) perror(shmdt); exit(EXIT_FAILURE); // 删除共享内存段 if (shmctl(shmid, IPC_RMID, NULL) == -1) perror(shmctl); exit(EXIT_FAILURE); printf(Shared memory segment removed ); return EXIT_SUCCESS; 关键考虑因素 错误处理：始终检查 API 返回值，处理可能的错误。 权限管理：合理设置共享内存权限，确保安全性。 同步机制：在多进程环境中使用信号量或互斥锁保护共享内存。 内存管理：在不再需要时及时删除共享内存，避免内存泄漏。 通过遵循这些步骤和注意事项，你可以在 C 语言程序中高效、安全地使用共享内存进行进程间通信。 父子进程之间的通信通过共享内存实现有亲缘关系间的通信首先在创建共享内存块地址，然后在创建子进程，父进程和子进程都要调用 shmat 进行地址映射，并且是同一块映射地址。 父进程先写入，然后调用 kill 函数，此时子进程处于休眠状态，因为 pause() 函数在等待父进程给子进程发送信号，然后父进程给子进程发送 SIGUSR1 信号，此时 pause() 函数被唤醒，然后读取共享内存中的信息。 然后子进程给父进程发送 SIGUSR2 信号，此时的父进程中的 pause() 函数被唤醒，然后又可以开始向共享内存中写入。 一直循环。 void myfun(int signum) return;int main(int argc, char **argv) int key; char *p; key = ftok(./triumph.c,a); if(key0) printf(creat key error ); exit(1); printf(creat key success key=%x ,key); int shmid = shmget(IPC_PRIVATE,128,IPC_CREAT|0777); if(shmid0) printf(Creat share memory fail ); exit(1); printf(creat share memory success shmid =%d , shmid); pid_t pid = fork(); if(pid0) //system(ipcrm -m shmid); p = (char *)shmat(shmid,NULL,0); signal(SIGUSR2,myfun); if(p==NULL) printf(parent process: shmat function error ); exit(1); while(1) //write share memory printf(parent process start write share memory : ); fgets(p,128,stdin); kill(pid,SIGUSR1); //child process read data pause(); //wait child process read if(pid==0) signal(SIGUSR1, myfun); p = (char *)shmat(shmid, NULL,0);//child address map if(p==NULL) printf(child process: shmat function error ); exit(1); while(1) pause();// wait parent process write //start read share memory printf(share memory data : %s,p); kill(getppid(),SIGUSR2); shmctl(shmid, IPC_RMID, NULL); system(ipcs -m); return 0; 共享内存段信息示例Shared Memory Segments----key owner perms nattch status0x00000000 229379 700 0 dest0x00000000 262148 300 0 dest...0x00000000 819214 777 128 dest 在实际运行中，共享内存段的信息会根据具体情况有所不同，上述内容仅为示例展示 。 实现无亲缘关系之间的通信服务器端程序struct mybuf int pid; //4 char buf[124];//124;void myfun(int signum) return;int main(int argc,char **argv) pid_t pid; int shmid; int key; struct mybuf *p; key = ftok(./triumph.c,a); if(key0) printf(creat key error ); exit(1); printf(creat key success key =%x ,key); shmid = shmget(key, 128, IPC_CREAT|0777); if(shmid0) printf(Creat share memory fail ); exit(1); printf(creat share memory success shmid =%d , shmid); system(ipcs -m); signal(SIGUSR2,myfun); p = (struct mybuf *)shmat(shmid,NULL,0); if(p==NULL) printf(parent process:shmat function fail ); return -1; //get client pid p-pid = getpid();//write server pid to share memory pause();//wait client read server pid pid = p-pid; //write while(1) //write share memory printf(parent process start write share memory : ); fgets(p-buf,128,stdin); //pid ==client pid pause(); kill(pid,SIGUSR1);//wait client read 客户端程序struct mybuf int pid; char buf[124];//124 ;void myfun(int signum) return;int main(int argc,char **argv) int shmid; pid_t pid; int key; struct mybuf *p; key = ftok(./triumph.c,a); if(key0) printf(creat key error ); exit(1); printf(creat key success key=%x ,key); shmid = shmget(key, 128, IPC_CREAT|0777); if(shmid0) printf(Creat share memory fail ); exit(1); printf(creat share memory success shmid =%d , shmid); system(ipcs -m); signal(SIGUSR1,myfun); p = (struct mybuf *)shmat(shmid, NULL,0); if(p==NULL) printf(parent process:shmat function fail ); return -3; //get server pid //read share memroy pid = p-pid; //write client pid to share memory p-pid = getpid(); //kill signal kill(pid, SIGUSR2); //client start read data from share memory while(1) pause(); //wait server write data to share memory printf(client process receive data from share memory: %s, p-buf); //pid ==server pid kill(pid, SIGUSR2);//server can write share memory 通信流程说明 首先创建一个结构体，在服务器端先把服务器（server pid）发送到共享内存，然后等待客户端（client pid）读取服务器端的 pid 号。 客户端读取服务器端的 pid 号后，将客户端的 pid 号发送给共享内存，然后发送给服务器端一个 kill 信号 SIGUSR2。此时服务器端就可以接受客户端的 pid 号，此时的 pid 号是客户端的 pid 号，然后服务器端开始获得客户端的 pid 号，此时两者可以通信。 然后服务器端开始发送内容，此时的客户端正在等待服务器端发送（pause()）。服务器端开始从 stdin 中读取数据到 p-buf 共享内存的缓冲区中，然后给客户端发送 kill 信号 SIGUSR1，写完后的服务器端处于 pause()等待状态。 此时客户端开始读取数据，从共享内存 p-buf 中读取，然后发送给服务器端 kill 信号 SIGUSR2。此时服务器端可以写入数据，客户端又开始处于等待状态，直到服务器端发送 kill 信号，才可以读取。","categories":["1.平台","Linux","进程线程"]},{"title":"串口数据接收状态机","path":"/2025/03/05/3-协议-串口-串口数据接收状态机/","content":"// 接收到的数据缓冲区首字节rcvdat = RxBuffer1[0];// UART1协议解析状态机if (uart1_state_machine == 0) // 等待接收数据包的第一个字节 if (rcvdat == 0xFF) // 接收到包头第一字节，移位到高位 res_data.FrameHead |= rcvdat 8; uart1_state_machine = 1; // 状态转移到接收包头第二字节 else uart1_state_machine = 0; // 未接收到包头，保持当前状态 else if (uart1_state_machine == 1) // 接收数据包的第二个字节 if (rcvdat == 0xEF) // 接收到完整包头，填充包头低位 res_data.FrameHead |= rcvdat; uart1_state_machine = 2; // 状态转移到接收数据长度 else if (rcvdat == 0xFF) // 重新接收到包头第一字节，保持在当前状态 uart1_state_machine = 1; else uart1_state_machine = 0; // 未接收到有效包头，复位状态机 else if (uart1_state_machine == 2) // 接收数据长度 res_data.FrameLen = rcvdat; uart1_state_machine = 3; // 状态转移到接收CRC else if (uart1_state_machine == 3) // 接收CRC校验和 res_data.FrameCRC = rcvdat; uart1_state_machine = 4; // 状态转移到接收应答码 else if (uart1_state_machine == 4) // 接收应答码/读写码 res_data.FrameACK = rcvdat; uart1_state_machine = 5; // 状态转移到接收模块码 else if (uart1_state_machine == 5) // 接收模块码 if (rcvdat == 0x01 || rcvdat == 0x02 || rcvdat == 0x03) res_data.FrameModule = rcvdat; uart1_state_machine = 6; // 状态转移到接收ID码 else uart1_state_machine = 0; // 无效模块码，复位状态机 else if (uart1_state_machine == 6) // 接收ID码 if (rcvdat = 0x0A) res_data.FrameID = rcvdat; uart1_state_machine = 7; // 状态转移到接收命令码 else uart1_state_machine = 0; // 无效ID码，复位状态机 else if (uart1_state_machine == 7) // 接收命令码 if (rcvdat = 0x08) res_data.FrameCMD = rcvdat; uart1_state_machine = 8; // 状态转移到接收子命令码 else if (uart1_state_machine == 8) // 初始化数据长度计数器 uart1_lencnt = 0; if (1) // 接收子命令码 res_data.FrameSubCMD = rcvdat; if (res_data.FrameLen != 0) // 清除上次数据区内容 memset(res_data.DataContent, 0x00, sizeof(res_data.DataContent)); uart1_state_machine = 9; // 状态转移到接收数据内容 else res_data.DataContent[0] = NULL; // 数据区为空 uart1_state_machine = 11; // 转移到包尾处理 else uart1_state_machine = 0; // 无效子命令码，复位状态机 else if (uart1_state_machine == 9 || uart1_state_machine == 10) // 保存接收到的数据 res_data.DataContent[uart1_lencnt++] = rcvdat; if (uart1_lencnt == res_data.FrameLen) // 计算CRC校验和 __IO u8 crc1 = 0; crc1 = u8_CRC_Check(res_data.DataContent, res_data.FrameLen); if (crc1 == res_data.FrameCRC) // CRC校验通过，转移到包尾处理 uart1_state_machine = 11; else // CRC校验失败，复位状态机 uart1_state_machine = 0; else // 继续接收数据 uart1_state_machine = 10; else if (uart1_state_machine == 11) // 接收包尾结束符 if (rcvdat == 0xFE) if (UART1_Rx_Done == 0) uart1_len = 0; res_data.FrameEnd = 0xFE; // 设置包尾标志 UART1_Rx_Done = 0xAA; // 标记数据包接收完成 UART1_RX_BUF[uart1_len] = res_data; // 保存接收到的数据包 uart1_len += 1; // 更新数据包计数 memset(res_data, 0x00, sizeof(res_data)); // 清除数据包结构体 uart1_state_machine = 0; // 复位状态机","categories":["3.协议","串口"]},{"title":"策略学习","path":"/2025/03/05/5-生活-金融-策略学习-策略学习/","content":"复利计算公式复利计算是金融领域的核心公式，用于计算投资随时间的增长。该公式考虑了本金、利率和时间的综合作用，使投资者能够清晰地了解资金的增值过程。 公式为： [ A P \\times (1 + r)^n ] 其中： A 最终金额（本金与利息之和） P 本金（初始投资金额） r 年利率（以小数表示） n 投资年数 详细解释： 本金（P）：这是您最初投资的金额，是计算利息的基础。 年利率（r）：表示每年的利率，以小数形式表示。例如，5%的年利率表示为 0.05。 投资年数（n）：投资持有的年数，时间越长，复利增长越明显。 实际应用场景： 银行存款：了解存款的年利率和存款时间，可以计算出最终获得的本息和。 投资理财：评估不同投资项目的收益，帮助投资者做出更明智的决策。 示例计算：假设您投资 10,000 元，年利率为 **5%**，投资期限为 10 年：[ A 10000 \\times (1 + 0.05)^{10} 10000 \\times 1.62889 16288.94 \\text{元} ]通过复利计算，可以清楚地看到，10 年后您的投资将增长到 16,288.94 元，比本金增加了 6,288.94 元。 扩展应用： 定期存款：通过定期存入本金，结合复利计算，可以实现更快的资金增长。 投资比较：在选择不同投资产品时，利用复利公式可以直观比较不同利率和时间下的收益。 matplotlib 绘图模块库matplotlib 是 Python 编程语言中功能强大的绘图库，广泛应用于数据可视化领域。它能够生成高质量的 2D 和 3D 图表，帮助开发者和数据分析师更直观地展示数据。 主要功能： 多样化的图表类型： 线性图：展示数据随时间或其他变量的变化趋势。 柱状图：比较不同类别之间的数量或程度。 散点图：显示数据点之间的分布情况，适合发现潜在的关联性。 饼图：直观展示各部分占整体的比例。 3D 图表：用于展示三维数据的分布和变化。 高度的可定制性： 样式主题：提供多种预设主题，满足不同美学需求。 颜色和字体：支持自定义颜色、字体样式和大小，提升图表的可读性。 图例和标签：便于解释图表内容，帮助读者理解数据含义。 交互功能：通过与其他库如 plotly 结合，生成交互式图表，增强用户体验。 与其他库的集成： Pandas：直接绘制 DataFrame 和 Series 对象，简化数据可视化流程。 NumPy：支持数组数据的高效绘制，适用于科学计算场景。 Scikit-learn：辅助机器学习结果的可视化，如分类结果、聚类分析等。 安装方法：使用 pip 进行安装： pip install matplotlib 基本使用示例： import matplotlib.pyplot as plt# 创建数据x = [1, 2, 3, 4]y = [1, 4, 9, 16]# 绘制图表plt.figure(figsize=(8, 6)) # 设置图表大小plt.plot(x, y, marker=o, linestyle=-, color=blue, linewidth=2, markersize=8)plt.title(平方函数图像, fontsize=16, fontweight=bold) # 设置标题plt.xlabel(x, fontsize=12) # 设置 x 轴标签plt.ylabel(y = x², fontsize=12) # 设置 y 轴标签plt.grid(True, linestyle=--, alpha=0.7) # 显示网格线plt.show() 实际应用场景： 数据分析：展示数据的变化趋势和分布情况，帮助发现潜在规律。 科学研究：绘制实验数据图表，直观呈现研究结果。 商业报告：通过图表清晰展示销售数据、市场趋势等信息，辅助决策。 SMA（简单均线）量化策略SMA（Simple Moving Average），即简单均线，是技术分析中最基础且广泛使用的工具。它通过计算一定时期内的平均价格，帮助交易者识别价格趋势和潜在的买卖信号。 计算方法：SMA 的计算公式为：[ SMA_n \\frac{\\sum_{i1}^{n} P_i}{n} ]其中： SMA_n n 日均线值 P_i 第 i 天的收盘价 n 计算周期（如 50 天、200 天） 策略逻辑：4. 买入信号： 当股票价格上涨并突破 SMA 均线，且均线呈上升趋势时，发出买入信号。 例如，若 SMA50 日均线在 50 元，当前价格上涨至 52 元，且均线向上，系统会触发买入信号。 卖出信号： 当股票价格下跌并跌破 SMA 均线，且均线呈下降趋势时，发出卖出信号。 例如，若 SMA50 日均线在 50 元，当前价格下跌至 48 元，且均线向下，系统会触发卖出信号。 策略优点： 简洁易用：计算简单，适合新手投资者。 平滑价格波动：通过平均价格减少短期波动的影响，提供更稳定的信号。 广泛应用：适用于不同的金融市场，如股票、外汇、期货等。 策略缺点： 滞后性：作为后验指标，SMA 反应市场变化较慢。 忽视近期波动：可能导致在强趋势中过晚介入或退出。 实际操作建议： 结合其他指标：如 RSI、MACD 等，形成多指标策略，提高信号准确性。 选择合适周期：根据投资目标选择不同的均线周期，短期用于短线交易，长期用于长线投资。 观察均线形态：均线的斜率、交叉情况等，提供额外的趋势信息。 示例分析：假设某股票的价格走势如下： SMA50 日均线：50 元 当前价格：52 元，且呈上升趋势 根据策略逻辑，系统会触发买入信号，建议投资者介入该股票。 策略的回溯测试—MMM 模式MMM 模式（多周期、多市场、多频率）是一种全面评估量化策略稳健性的方法。通过在不同时间窗口、不同市场和不同交易频率下测试策略，可以发现其潜在的优势和不足，从而优化策略参数，提高其适用性和稳定性。 测试维度：6. 多周期测试： 不同时间窗口：测试策略在 1 年、5 年、10 年的表现，评估其短期和长期的有效性。 历史数据覆盖：选择包含不同市场环境的历史数据，如牛市、熊市、震荡市，全面评估策略的适应性。 多市场测试： 不同地区市场：测试策略在沪深股市、港股市场、美股市场等地的表现，评估其在不同市场环境下的稳定性。 不同资产类别：测试策略在股票、期货、外汇等不同资产类别的表现，验证其通用性。 多频率测试： 不同交易频率：测试策略在日线、周线、月线等不同时间粒度下的表现，评估其在不同交易周期的有效性。 高频交易：测试策略在分钟级、秒级等高频数据下的表现，适用于高频交易策略的评估。 测试目的： 评估稳健性：通过在不同环境下的测试，评估策略的稳定性和一致性。 发现缺陷：识别策略在特定市场条件下的不足，避免在实际交易中出现重大损失。 优化参数：根据测试结果调整策略参数，提升其在不同环境下的表现。 实际操作步骤： 数据收集：收集不同市场、不同时间窗口的历史数据，确保数据的完整性和准确性。 策略实现：将策略逻辑转化为可执行的代码，确保策略在不同环境下的正确运行。 回溯测试：在不同测试维度下运行策略，记录其表现指标，如收益率、最大回撤、胜率等。 结果分析：分析测试结果，评估策略的稳健性和有效性，识别潜在的问题和改进空间。 优化调整：根据测试结果调整策略参数，优化策略逻辑，提升策略的稳定性和收益能力。 示例分析：假设某策略在以下环境下进行测试： 多周期：1 年、5 年、10 年 多市场：沪深股市、港股市场、美股市场 多频率：日线、周线、月线 通过测试发现，该策略在沪深股市的日线和周线表现良好，但在美股市场的月线表现不佳。分析原因可能是市场环境差异，美股市场的波动性和趋势特征与沪深股市不同。根据测试结果，可以调整策略参数，如增加均线周期，优化交易信号生成逻辑，提升策略在美股市场的表现。 总结：MMM 模式通过多维度的回溯测试，全面评估量化策略的稳健性，帮助交易者发现策略的潜在问题，优化策略参数，提升策略的适用性和稳定性。在实际应用中，建议结合多种测试维度，进行全面的回溯测试，确保策略在不同市场环境下的稳定表现。","categories":["5.生活","金融","策略学习"]},{"title":"串口数据接收指定帧判断","path":"/2025/03/05/3-协议-串口-串口数据接收指定帧判断/","content":"1. 概述实现了一个串口数据接收的驱动函数，主要功能是接收和处理通过串口发送来的数据帧。数据帧具有固定的帧头和帧尾结构，接收函数会检测帧头，读取完整的数据帧，并对数据进行处理。 2. 代码结构代码分为两个主要部分： SlotDataReady()：负责从串口接收数据，检测帧头，读取完整的数据帧。 slotDealFrame()：处理接收到的数据帧，提取信息并进行后续处理。 3. SlotDataReady() 函数功能：接收串口数据，检测帧头，读取完整的数据帧。 逻辑流程： 检测帧头： 检查是否有新的消息接收。 读取固定长度的帧头数据。 验证帧头和帧尾是否正确，如果不正确则丢弃该数据。 读取完整帧： 根据帧头中的长度信息，计算需要读取的数据长度。 逐次读取剩余数据，直到读取完整一个帧。 处理数据帧： 将完整的数据帧发送到消息处理模块。 重置接收状态，准备接收下一个数据帧。 关键代码解释： void SerialPortDriver::SlotDataReady() quint8 *getData_p; quint64 unSize; // 未读字节数 bool bCountinue = false; QByteArray baPacket; do // 1. 检测帧头 if (m_bNewCmd) // 有新的消息 while (1) // 检查是否有足够的数据来读取帧头 if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE) break; // 读取帧头数据 m_readData = ComNodeIns-read(FRAME_HEAD_SIZE); getData_p = (quint8 *)(m_readData.data()); // 验证帧头和帧尾 if (getData_p[0] == MSG_HEAD getData_p[6] == MSG_HEAD_END) // 计算需要读取的数据长度 m_unNeedReadNu = getData_p[4] - FRAME_HEAD_SIZE; m_bNewCmd = false; break; else printf(ERROR: MSG RECEIVE HEADEND FAILED!!! ); // 丢弃错误数据 // 2. 读取完整帧 unSize = ComNodeIns-bytesAvailable(); if (m_unNeedReadNu 0 m_unNeedReadNu = unSize) // 读取剩余数据 m_readData.append(ComNodeIns-read(m_unNeedReadNu)); else // 读取所有可用数据 m_readData.append(ComNodeIns-read(unSize)); m_unNeedReadNu = m_unNeedReadNu - unSize; break; // 3. 发送到消息处理模块 baPacket = m_readData; slotDealFrame(baPacket); // 重置状态 m_bNewCmd = true; m_unNeedReadNu = 0; // 4. 继续读取 if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE) bCountinue = true; while (bCountinue); 4. slotDealFrame() 函数功能：处理接收到的数据帧，提取信息并进行后续处理。 逻辑流程： 提取消息节点： 将接收到的数据转换为消息节点结构体。 CRC 校验： 计算接收数据的 CRC 值。 对比数据中的 CRC 值，验证数据完整性。 消息处理： 根据消息 ID 确定消息类型。 构造输出字符串，打印接收信息。 通过信号发送消息节点到其他模块。 关键代码解释： void SerialPortDriver::slotDealFrame(QByteArray baPacket) do MessageNode dFrame; // 提取消息节点 MessageNode *fpNew = (MessageNode *)baPacket.data(); dFrame = *fpNew; // CRC校验 quint8 scrc = CRC_CAL(baPacket); quint8 dcrc = dFrame.frameHeader.datacksum; // CRC校验失败处理 // if (dcrc != scrc) // // printf(ERROR: CRC CAL FAILED!!! ); // break; // // 确定消息类型 QString type = none; switch(dFrame.frameHeader.payloadID) case MSG_IRU: type = iru; break; case MSG_ADU: type = adu; break; case MSG_GPS: type = gps; break; // 构造输出字符串并打印 static int index = 0; QString outputStr = [RecvMsg + QString::number(index++) + ] + QDateTime::currentDateTime().toString(HH:mm:ss zzz) + + type; printf(%s , qPrintable(outputStr)); // 发送消息节点 emit sendBlockMsg(dFrame); while (0); 5. 示例说明示例 1：帧头检测 假设接收到的数据帧头为：[0x55, 0x00, 0x00, 0x01, 0x10, 0x00, 0xAA]，其中： 0x55 是帧头标识。 0x10 是数据长度（16 bytes）。 0xAA 是帧尾标识。 系统会检测到帧头和帧尾正确，计算需要读取的数据长度为 0x10 - FRAME_HEAD_SIZE。 示例 2：数据读取 假设串口缓冲区有 20 bytes 数据，其中帧头 6 bytes，剩余 14 bytes 数据： 首先读取帧头，验证正确。 计算需要读取 14 bytes 数据。 读取剩余 14 bytes，完成一个完整的数据帧。 示例 3：消息处理 接收到的数据帧类型为 MSG_GPS，系统会打印： [RecvMsg 0 ] 2023-10-01 12:34:56 +0800 gps 并通过信号发送 dFrame 到其他模块进行处理。 6. 总结这段代码实现了一个可靠的串口数据接收和处理机制，能够正确检测和处理固定结构的数据帧，确保数据的完整性和正确性。通过分离接收和处理逻辑，使得代码结构清晰，易于维护和扩展。","categories":["3.协议","串口"]},{"title":"识别照片时间戳并分类","path":"/2025/03/05/2-语言-Python-识别照片时间戳并分类/","content":"# 导入必要的库import osimport timeimport refrom PIL import Imageimport ExifTagsimport subprocessimport exiftoolimport shutil# 配置 ExifTool 的路径，确保脚本能够找到该工具EXIFTOOL_PATH = rC:\\Program Portable\\exiftool-13.04_64\\exiftool.exe # 替换为你的实际路径def get_image_time_from_exif(image_path): 通过 EXIF 元数据获取图片的原始拍摄时间 EXIF（Exchangeable Image File Format）是图片文件中常用的元数据格式，通常包含拍摄时间、相机型号等信息。 该函数尝试从图片的 EXIF 数据中提取 DateTimeOriginal 标签，该标签记录了图片的原始拍摄时间。 try: # 打开图片文件并加载 EXIF 数据 image = Image.open(image_path) exif_data = image._getexif() if exif_data: # 遍历 EXIF 标签，查找 DateTimeOriginal for tag, value in exif_data.items(): decoded_tag = ExifTags.TAGS.get(tag, tag) if decoded_tag == DateTimeOriginal: # 返回格式化的日期字符串，例如：2023-10-01 return value[:10].replace(:, -) except Exception as e: # 记录错误信息，继续执行 print(f通过 EXIF 获取时间失败: e, 文件路径: image_path) return Nonedef get_image_time_with_exiftool(image_path): 使用 ExifTool 工具获取图片时间 ExifTool 是一个强大的元数据读取工具，可以从各种文件格式中提取详细的元数据信息。 该函数尝试通过 ExifTool 获取多个时间相关的标签，包括 DateTimeOriginal、CreateDate 等。 try: with exiftool.ExifTool() as et: # 获取图片的元数据 metadata = et.get_metadata(image_path) # 按优先级查找时间信息 for tag in [EXIF:DateTimeOriginal, EXIF:CreateDate, QuickTime:CreateDate]: if tag in metadata: # 返回格式化的日期字符串 return metadata[tag][:10].replace(:, -) except Exception as e: print(f通过 ExifTool 获取时间失败: e, 文件路径: image_path) return Nonedef get_media_creation_time_with_ffprobe(media_path): 使用 ffprobe 获取媒体文件的创建时间 ffprobe 是 FFmpeg 套件的一部分，能够从媒体文件中提取详细的元数据信息。 该函数通过 ffprobe 提取视频或图片的创建时间。 try: # 构建 ffprobe 命令，提取创建时间 command = [ ffprobe, -v, error, -select_streams, v:0, -show_entries, stream_tags=creation_time, -of, default=noprint_wrappers=1:nokey=1, media_path ] # 执行命令并获取输出 output = subprocess.check_output(command).decode().strip() if output: # 提取日期部分，格式为 YYYY-MM-DD return output[:10] except Exception as e: print(f通过 ffprobe 获取时间失败: e, 文件路径: media_path) return Nonedef extract_date_from_filename(file_name): 从文件名中提取日期 该函数尝试从文件名中匹配常见的日期格式，例如 20231001 或 2023-10-01。 date_patterns = [ r\\d4-\\d2-\\d2, # 匹配 YYYY-MM-DD 格式 r\\d8 # 匹配 YYYYMMDD 格式 ] for pattern in date_patterns: match = re.search(pattern, file_name) if match: date_str = match.group() # 将 YYYYMMDD 格式转换为 YYYY-MM-DD if len(date_str) == 8: return fdate_str[:4]-date_str[4:6]-date_str[6:] return date_str return Nonedef get_file_creation_time(file_path): 通过文件系统获取文件的创建时间 当上述方法都无法获取时间时，作为最后的备用方法，使用文件系统的创建时间。 try: # 获取文件的创建时间 creation_time = time.ctime(os.path.getctime(file_path)) # 将时间字符串转换为 YYYY-MM-DD 格式 return time.strftime(%Y-%m-%d, time.strptime(creation_time, %a %b %d %H:%M:%S %Y)) except Exception as e: print(f通过文件系统获取时间失败: e, 文件路径: file_path) return Nonedef get_image_creation_time(image_path): 综合多种方法获取图片的创建时间 按照优先级依次尝试多种方法，确保获取到最准确的创建时间。 time_getters = [ get_image_time_from_exif, # 1. 通过 EXIF 数据 get_image_time_with_exiftool, # 2. 通过 ExifTool get_media_creation_time_with_ffprobe, # 3. 通过 ffprobe extract_date_from_filename, # 4. 从文件名提取 get_file_creation_time # 5. 文件系统创建时间 ] for method in time_getters: creation_time = method(image_path) if creation_time: return creation_time return Nonedef move_image_to_date_directory(image_path): 根据图片的创建时间移动图片到对应的年份和月份目录下 目标目录结构为：年/月 creation_time = get_image_creation_time(image_path) if creation_time: year, month = creation_time.split(-)[:2] # 目标目录路径 target_directory = os.path.join(rC:\\Users\\Administrator\\2024\\08, year, month) # 创建目标目录（如果不存在） if not os.path.exists(target_directory): os.makedirs(target_directory) # 移动文件 shutil.move(image_path, os.path.join(target_directory, os.path.basename(image_path))) print(f移动文件 image_path 到 target_directory) else: print(f跳过文件：无法获取创建时间，路径：image_path)if __name__ == __main__: # 设置目标目录 image_dir = rC:\\Users\\Administrator\\2024\\08 # 获取所有符合条件的媒体文件 image_files = [ os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith((.jpg, .png, .jpeg, .heic, .mp4)) ] # 处理每个文件 for image_file in image_files: move_image_to_date_directory(image_file)","categories":["2.语言","Python"]},{"title":"环境配置","path":"/2025/03/05/2-语言-Qt-环境配置/","content":"缺少-lGL当在 Qt 编译时出现 -1: error: cannot find -lGL: No such file or directory 错误，这表明编译器在链接过程中找不到 OpenGL 库（libGL）。以下是几种可能的解决办法： 1. 安装 OpenGL 开发库不同的 Linux 发行版安装 OpenGL 开发库的命令不同，以下是常见发行版的安装方法： UbuntuDebian在终端中执行以下命令来安装 OpenGL 开发库： sudo apt updatesudo apt install libgl1-mesa-dev 2. 检查库文件是否存在安装完成后，你可以使用以下命令来检查 libGL 库文件是否存在于系统中： find / -name libGL.so* 如果找到了该文件，说明库已经正确安装。 3. 检查库文件路径是否正确有时候，库文件存在，但编译器找不到它，可能是因为库文件所在的路径没有被包含在系统的库搜索路径中。你可以通过以下方法解决： 临时添加库搜索路径在终端中设置 LD_LIBRARY_PATH 环境变量，将包含 libGL 库文件的路径添加到该变量中。假设 libGL.so 文件位于 /path/to/library，可以使用以下命令： export LD_LIBRARY_PATH=/path/to/library:$LD_LIBRARY_PATH 然后再尝试编译 Qt 项目。 永久添加库搜索路径如果你希望每次启动系统时都自动添加该路径，可以将上述命令添加到 ~/.bashrc 或 /etc/profile 文件中。例如，在 ~/.bashrc 文件末尾添加： export LD_LIBRARY_PATH=/path/to/library:$LD_LIBRARY_PATH 保存文件后，执行以下命令使修改生效： source ~/.bashrc 4. 检查 Qt 项目配置文件确保你的 Qt 项目配置文件（通常是 .pro 文件）中正确包含了 OpenGL 库的链接选项。在 .pro 文件中添加以下内容： LIBS += -lGL 这将告诉编译器在链接时使用 libGL 库。 完成上述操作后，再次尝试编译 Qt 项目，看问题是否解决。 中文乱码WSL 下中文都无法显示。因为，WSL 是没有中文字体的，所以中文显示成了一个个小框框，没有相应字体库，所以渲染不出相应纹理。直接使用 Windows 自带的字体（你也可以自己安装字体库）。 sudo ln -s /mnt/c/Windows/Fonts /usr/share/fonts/font 扫描字体目录，并生成字体信息的缓存 fc-cache -fv 缺少 curl从你给出的错误信息来看，编译时找不到 curl/curl.h 头文件，这通常是由于系统中未安装 libcurl 开发库，或者编译器无法找到该库的头文件路径所导致的。下面为你提供几种解决办法： 1. 安装 libcurl 开发库不同的操作系统安装 libcurl 开发库的方式有所不同： UbuntuDebian在终端里执行以下命令： sudo apt-get updatesudo apt-get install libcurl4-openssl-dev CentOSRHEL在终端中运行以下命令： sudo yum install libcurl-devel macOS如果你使用的是 Homebrew 包管理器，那么可以执行以下命令： brew install curl 2. 检查头文件路径要是已经安装了 libcurl 开发库，但编译器还是找不到头文件，你可以手动指定头文件的搜索路径。在编译命令里添加 -I 选项，例如： g++ -I/path/to/curl/include your_source_file.cpp -o your_program 这里的 /path/to/curl/include 要替换成 curl 头文件实际所在的目录。 3. 检查环境变量你也可以通过设置 CPATH 环境变量来让编译器搜索指定的目录。在终端中执行以下命令： export CPATH=/path/to/curl/include:$CPATH 同样，/path/to/curl/include 要替换成 curl 头文件实际所在的目录。如果你希望这个设置在每次启动终端时都生效，可以把上述命令添加到你的 shell 配置文件（像 .bashrc 或者 .zshrc）中。 4. 示例假设你使用 g++ 来编译 CommonClient.cpp 文件，在安装好 libcurl 开发库之后，编译命令可以这样写： g++ -I /usr/include -L /usr/lib -lcurl ../asr/core/src/CommonClient.cpp -o common_client 这里的 -I /usr/include 指定了头文件的搜索路径，-L /usr/lib 指定了库文件的搜索路径，-lcurl 表示链接 libcurl 库。 通过上述步骤，你应该能够解决 curl/curl.h: No such file or directory 的错误。","categories":["2.语言","Qt"]},{"title":"WSL配置","path":"/2025/03/05/1-平台-WSL-WSL配置/","content":"安装 Qt 报错./qt-opensource-linux-x64-5.12.12.run: error while loading shared libraries: libxkbcommon-x11.so.0: cannot open shared object file: No such file or directory 当你在运行 ./qt-opensource-linux-x64-5.12.12.run 时出现 error while loading shared libraries: libxkbcommon-x11.so.0: cannot open shared object file: No such file or directory 错误，这表明系统在运行该程序时找不到所需的共享库文件 libxkbcommon-x11.so.0。以下是几种可以解决此问题的方法： 安装缺失的库在终端中运行以下命令来安装 libxkbcommon-x11 库： sudo apt updatesudo apt install libxkbcommon-x11-0 创建软链接如果系统中存在类似版本的库文件，但文件名不完全匹配，你可以尝试创建软链接。首先，使用 find 命令查找类似的库文件，例如： sudo find / -name libxkbcommon-x11.so.* 假设找到的文件是 libxkbcommon-x11.so.1，可以使用以下命令创建软链接： sudo ln -s /path/to/libxkbcommon-x11.so.1 /usr/lib/libxkbcommon-x11.so.0 检查库文件是否存在于系统中有时候，库文件可能已经存在于系统中，但不在系统默认的搜索路径里。你可以使用以下命令来查找该库文件： sudo find / -name libxkbcommon-x11.so.0 如果找到了该文件，你可以将其所在的目录添加到 LD_LIBRARY_PATH 环境变量中。假设找到的文件路径为 /path/to/library，可以使用以下命令临时添加该路径： export LD_LIBRARY_PATH=/path/to/library:$LD_LIBRARY_PATH 如果你希望每次启动系统时都自动添加该路径，可以将上述命令添加到 ~/.bashrc 或 /etc/profile 文件中。 启动 Qt 失败qt.qpa.plugin: Could not load the Qt platform plugin xcb in even though it was found.This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, xcb.Aborted (core dumped) 当你遇到 qt.qpa.plugin: Could not load the Qt platform plugin xcb in even though it was found. 错误时，这表明 Qt 应用程序无法初始化所需的 xcb 平台插件，以下是一些可能的解决办法： 1. 安装必要的依赖库xcb 插件依赖于一些系统库，确保这些库已经安装： UbuntuDebiansudo apt-get updatesudo apt-get install libxcb-xinerama0 libxcb-xkb1 libxcb-render-util0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-shape0 libxcb-xfixes0 2. 设置 QT_QPA_PLATFORM_PLUGIN_PATH 环境变量有时候，Qt 可能无法自动找到平台插件的路径，你可以手动设置 QT_QPA_PLATFORM_PLUGIN_PATH 环境变量。 先找到 xcb 插件所在的目录，通常在 Qt 安装目录的 plugins/platforms 下。假设 Qt 安装在 /opt/Qt5.12.12，可以使用以下命令设置环境变量： export QT_QPA_PLATFORM_PLUGIN_PATH=/opt/Qt5.12.12/plugins/platforms 你可以将上述命令添加到 ~/.bashrc 或 ~/.zshrc 文件中，使其每次启动时自动生效： echo export QT_QPA_PLATFORM_PLUGIN_PATH=/opt/Qt5.12.12/plugins/platforms ~/.bashrcsource ~/.bashrc 3. 检查权限问题确保 xcb 插件文件以及其所在目录具有正确的权限。你可以使用以下命令来检查和修改权限： chmod -R 755 /opt/Qt5.12.12/plugins/platforms 4. 检查 Qt 版本兼容性确保你使用的 Qt 版本与系统环境兼容。如果 Qt 版本过旧或过新，可能会导致插件加载问题。尝试更新或降级 Qt 到合适的版本。 5. 清除缓存有时候，Qt 的缓存文件可能会导致问题。你可以尝试清除这些缓存文件： rm -rf ~/.cache/Qt* 6. 尝试其他平台插件如果 xcb 插件仍然无法加载，你可以尝试使用其他可用的平台插件，例如 offscreen。在运行 Qt 应用程序时，使用 QT_QPA_PLATFORM 环境变量指定平台插件： export QT_QPA_PLATFORM=offscreen./your_qt_application 通过以上步骤，你应该能够解决 xcb 平台插件加载失败的问题。如果问题仍然存在，建议检查 Qt 安装是否正确，或者查看系统日志以获取更多详细信息。","categories":["1.平台","WSL"]},{"title":"QSplitter","path":"/2025/03/05/2-语言-Qt-QSplitter/","content":"QSplitter：灵活控制子窗口大小的界面元素QSplitter 是一种强大的界面元素，允许用户通过拖动子窗口之间的边界来控制它们的大小。这种功能使得用户可以根据自己的需求，灵活调整不同窗口的显示比例，从而提升操作的舒适度和效率。 1. 可拖动边界QSplitter 的核心功能在于它提供了可拖动的边界线。用户只需用鼠标抓住分隔线，然后向左或向右拖动，就可以轻松调整左右（或上下）两个子窗口的大小。这种交互方式直观且易用，非常适合需要用户自定义布局的场景。 2. 支持多个子窗口除了基本的两个子窗口，QSplitter 还支持嵌套多个窗口。例如，你可以在一个主分割器中添加多个子分割器，从而实现更复杂的布局需求。这种灵活性使得 QSplitter 成为构建多窗口界面的理想选择。 3. 保存和恢复布局QSplitter 提供了保存和恢复当前窗口大小的功能。通过程序化接口，开发者可以方便地保存用户调整后的布局，并在下次启动时自动恢复。这一特性极大地提升了用户体验，避免了每次都需要重新调整窗口大小的麻烦。 5. 与其他控件的结合QSplitter 可以与其他 Qt 控件无缝结合。例如，你可以将 QTreeWidget、QTableWidget、QTextEdit 等控件嵌入到 QSplitter 中，构建出功能丰富的多窗口界面。这种模块化的设计使得界面构建变得更加灵活和高效。","categories":["2.语言","Qt"]},{"title":"python目录索引","path":"/2025/03/04/2-语言-Python-python目录索引/","content":"在搭建一个网站时，可以选择使用不同的技术和框架来构建前端和后端部分。以下是一个常见的组合： 前端技术和框架： HTML: 用于定义网页的结构。 CSS: 用于网页的样式和布局。 JavaScript: 用于网页的交互和动态效果。 对于前端，可以使用一些流行的前端框架来简化开发和管理状态，例如： React: 由 Facebook 开发，用于构建用户界面的 JavaScript 库。 Vue.js: 一个轻量级的 JavaScript 框架，用于构建用户界面。 Angular: 由 Google 开发，用于构建动态 Web 应用程序的框架。 后端技术和框架： Python: 作为后端开发语言，可以使用 Python 来处理业务逻辑、数据存储等。 Web 框架: 用于简化处理 HTTP 请求和响应、路由管理等。一些流行的 Python Web 框架包括： Django: 一个强大的全栈 Web 框架，提供许多内置功能。 Flask: 一个轻量级的 Web 框架，适合构建小型到中型的 Web 应用程序。 FastAPI: 一个快速（高性能）的 Web 框架，专注于 API 开发。 其他可能需要的技术和工具： 数据库: 如果需要存储和管理数据，可以选择合适的数据库，如 MySQL、PostgreSQL、SQLite 等。 RESTful API: 如果的前端和后端需要进行通信，设计和实现 RESTful API 可以是一个很好的方式。 版本控制: 使用版本控制工具（如 Git）来管理代码版本和协作。 Web 服务器: 在生产环境中，需要一个 Web 服务器（如 Nginx、Apache）来处理 HTTP 请求，并将它们转发给后端应用程序。 部署和托管: 将的网站部署到生产环境可能需要使用云服务（如 AWS、Azure、Heroku）或虚拟专用服务器（VPS）。 安全性: 保护的网站免受安全威胁，包括输入验证、身份验证、授权等。 总之，选择适合项目需求和技能水平的技术和框架是很重要的。这里提到的只是一些常见的选择，实际上还有许多其他技术和工具可供选择。 import os def generate_index(path): index = ul class=menu for root, dirs, files in os.walk(path): Create a list item for each folder for dir_name in dirs: index += fliadir_name/aul class=menu for file_name in files: index += flia href=os.path.join(root, dir_name, file_name)file_name/a/li index += /ul/li index += /ul return index Specify the root directory for indexingroot_directory “.StudyDoc” index_html generate_index(root_directory) print(index_html)","categories":["2.语言","Python"]},{"title":"微信后台机器人","path":"/2025/03/04/2-语言-Python-微信后台机器人/","content":"基于微信公众号后台的夸克网盘资源查找和 OpenAI 的回复 # 导入必要的库import werobotimport openaifrom openai import OpenAIimport reimport jsonimport requestsimport pandas as pdfrom bs4 import BeautifulSoupfrom functools import partialfrom datetime import datetime, timedelta# 定义请求头，模拟浏览器访问headers = User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36, Authorization: Bearer token123, Cookie: session=abcdef123456# 初始化 OpenAI 客户端client = OpenAI( api_key=*****************************, base_url=*****************************)# 初始化 WeRoBot 实例robot = werobot.WeRoBot()# 配置类，设置微信公众号的相关参数class RobotConfig(object): HOST = *.*.*.* # 监听所有网络接口 PORT = xxxx # 使用80端口 TOKEN = xxxxxxxx # 微信公众号的接入凭证robot.config.from_object(RobotConfig)# 定义生成回复的函数def generate_response(prompt): 生成对话的回复 Args: prompt (str): 用户输入的内容 Returns: str: 生成的回复内容 messages = [role: user, content: prompt] try: completion = client.chat.completions.create(model=gpt-3.5-turbo, messages=messages) return completion.choices[0].message.content except Exception as e: return f错误：str(e)# 定义获取 URL 的函数def getUrl(url): 爬取指定 URL 并提取相关链接 Args: url (str): 需要爬取的 URL Returns: str: 提取到的链接，换行分隔 result = try: response = requests.get(url, headers=headers, timeout=10) if response.status_code == 200: soup = BeautifulSoup(response.content, html.parser) elements = soup.find_all(class_=container) for links in elements: a_tags = links.find_all(a, href=True) for a in a_tags: if a[href].startswith(https://quarkzy.com/): try: response2 = requests.get(a[href], headers=headers, timeout=10) if response2.status_code == 200: soup2 = BeautifulSoup(response2.content, html.parser) b_tags = soup2.find_all(a, href=True) for b in b_tags: if b[href].startswith(https://pan.quark): result += b[href] + \\r except Exception as e: continue else: result = f请求失败，状态码: response.status_code except Exception as e: result = f请求错误：str(e) return result# 定义微信消息处理器@robot.handlerdef weChatReturn(messages): 处理微信公众号的消息 Args: messages: 微信公众号的消息对象 Returns: str: 回复内容 msg = messages.content retMsg = if msg.startswith(夸克): url = https://quarkzy.com/?q= url += msg[3:] retMsg += getUrl(url) else: retMsg += generate_response(msg) return retMsg# 主程序if __name__ == __main__: # 测试生成回复 # messages = 夸克 猎罪图鉴 # print(weChatReturn(messages)) robot.run() 改进说明： 添加注释和文档字符串：为每个函数添加了详细的注释，说明其功能、参数和返回值，方便他人理解代码。 错误处理：在关键的地方添加了 try-except 块，处理可能的异常，避免程序因网络问题或解析错误而崩溃。 代码结构优化：调整了代码结构，使其更符合 Python 的编码规范，增加了空行和注释，提高可读性。 安全提示：注释提醒用户注意保护 API 密钥和其他敏感信息。 详细步骤说明：在代码中添加了详细的步骤说明，帮助读者理解每个部分的功能。 添加 timeout 参数：在 requests.get() 中添加了 timeout 参数，避免因网络延迟导致程序长时间无响应。 结果处理：在 getUrl() 函数中，结果以换行分隔，方便后续处理和展示。 函数分离：将功能分离到不同的函数中，提高代码的模块化和可维护性。 日志和调试信息：在关键步骤添加了打印语句，方便调试和排查问题。 代码风格统一：统一了代码风格，遵循 PEP8 编码规范，提高代码的可读性和一致性。","categories":["2.语言","Python"]},{"title":"基于Linux系统的ARM平台QT移植","path":"/2025/03/02/2-语言-Qt-基于Linux系统的ARM平台QT移植/","content":"移植前述在当前的技术环境中，ARM 行业正蓬勃发展，越来越多的设备选择使用 Linux 作为操作系统。本文将专注于在 ARM 和 Linux 平台下进行 Qt 的移植和程序测试，其他系统如 Windows CE 等将不在讨论范围内。 ARM 开发所需的硬件和平台条件进行 ARM 开发时，必须具备以下硬件和平台条件： ARM 硬件开发板目前，市场上广泛使用的处理器主要是 ARM9 和 ARM11。这些开发板通常配备了必要的接口和功能，方便开发者进行各种实验和测试。例如，常见的开发板如 BeagleBone 和 Raspberry Pi，它们都基于 ARM 架构，适合进行嵌入式开发。 Linux 系统内核针对嵌入式行业的 Linux 系统内核是必不可少的。此外，开发者还需要在 PC 上搭建 Linux 开发环境，常用的发行版包括 Ubuntu、Red Hat 和 CentOS 等。这些系统提供了丰富的开发工具和库，支持开发者进行高效的应用程序开发。 ARM 软件开发环境ARM 开发环境相对复杂，涵盖了底层驱动的移植与开发，以及顶层应用程序的开发。开发者需要使用相应的工具和软件进行调试和开发。虽然本文不涉及驱动开发的细节，但顶层应用程序开发的一个重要环节是图形用户界面的设计。在嵌入式领域，Qt 是最常用的图形界面开发框架。 Qt 是由诺基亚开发的跨平台 C++图形用户界面应用程序框架。它为开发者提供了构建艺术级图形用户界面所需的所有功能。Qt 完全面向对象，易于扩展，并支持组件化编程，使得开发者能够高效地创建复杂的用户界面。 应用程序开发与调试开发者通常在 PC 上完成应用程序的开发，随后希望在 ARM 开发板上进行调试，以验证程序的正确性和完整性。这一过程涉及多个知识领域，包括： 开发板引导启动文件 U-Boot：U-Boot 是一个常用的引导加载程序，负责在设备启动时加载 Linux 内核。 Linux 内核镜像的烧写：将编译好的 Linux 内核镜像写入开发板的存储介质，以便设备启动时能够加载。 交叉编译：由于 ARM 架构与 PC 架构不同，开发者需要使用交叉编译工具链，将代码编译为 ARM 可执行文件。 搭建 Qt 开发环境：在 PC 上配置 Qt 开发环境，包括安装 Qt 库和开发工具。 开发板与 PC 的 NFS 挂载连接：通过网络文件系统（NFS）将开发板与 PC 连接，方便文件的共享和访问。 Qt 程序在线测试：在开发板上运行 Qt 应用程序，进行实时测试和调试。 上述内容涉及的交叉编译之前的所有操作，本文将不作详细讨论。若读者对此有疑问，建议查阅相关资料。本文的主要目的是构建一个 Qt 开发环境，并介绍如何通过 NFS 挂载进行 Qt 应用程序的测试。 QT 移植具备条件 交叉编译器交叉编译器是将代码编译为不同平台可执行文件的工具。在 QT 移植过程中，常用的版本包括 arm-linux-gcc-4.3.2 和 arm-linux-gcc-4.1.2。这些编译器能够将为 Linux 环境编写的代码转换为适用于 ARM 架构的可执行文件。例如，如果你在一台 x86 架构的 PC 上开发应用程序，交叉编译器将帮助你生成可以在 ARM 开发板上运行的代码。 QT 版本需要下载特定版本的 QT 库，推荐使用 qt-embedded-linux-opensource-src-4.5.3.tar.gz 和 qt-x11-opensource-src-4.5.3.tar.gz。这些文件可以从 QT 的官方网站获取。值得注意的是，QT 的开发公司已经被诺基亚收购，因此官方网站地址为 http://qt.nokia.com/。 qt-embedded-linux-opensource-src 包含了支持在 ARM 开发板上运行的应用程序所需的库文件。 qt-x11-opensource-src 则用于在 PC 上模拟 ARM 环境，以便进行程序调试。这在没有实际开发板的情况下尤为重要，开发者可以在 PC 上验证代码的可行性。 触摸屏支持 tslibtslib 是一个用于触摸屏的支持库，负责处理触摸输入。它的工作流程如下：首先，触摸数据通过开发板上的驱动程序获取（这些驱动程序已经加载到内核中）。接着，这些原始数据会传递给 tslib，该库会对数据进行去抖动和校准等处理，确保触摸输入的准确性。最后，处理后的数据将被传递给顶层应用程序。这样，开发者可以确保用户的触摸操作能够被准确识别和响应。 Linux 系统上的一些编译工具或库在进行 QT 移植时，还需要一些额外的编译工具和库。这些工具可能包括 make、cmake 等构建工具，以及一些必要的开发库，如 libX11、libXext 等。这些工具和库将帮助你在 Linux 系统上顺利编译和调试 QT 应用程序。 说明 交叉编译工具在 QT 库安装时至关重要，它不仅用于编译 QT 库本身，还在调试 QT 应用程序时将代码编译成 ARM 板上可运行的格式。 qt-embedded-linux-opensource-src 提供了支持在 ARM 开发板上运行的应用程序的必要库文件，而 qt-x11-opensource-src 则用于在 PC 上进行 ARM 环境的模拟调试，确保在没有开发板的情况下也能验证程序的可行性。 tslib 的作用是校准触摸屏，确保触摸输入的准确性。它通过去抖动和校准等处理，提升用户体验，使得应用程序能够更好地响应用户的触摸操作。 第三部分：QT 移植详情注：此移植过程在 Ubuntu 9.04 系统下完成 带 # 开头的表示终端运行的命令带 // 开头的表示注释红色字体表示应该特别注意的地方 我的移植环境 开发板：友坚恒天公司的 S3C6410 PC 机系统：Windows XP PC 机上装 VMware 虚拟机系统：Ubuntu 9.04 交叉编译工具：arm920t-eabi-4.1.2.tar.gz Qt 版本：qt-embedded-linux-opensource-src-4.5.3.tar.gz 触摸屏校准：tslib1.4.tar.gz 第一步：安装交叉编译工具解压并设置环境变量 将 arm920t-eabi-4.1.2.tar.gz 拷贝到 /home/resource 下，然后解压到根目录： # cd /home# mkdir resource# cd /home/resource# tar zxvf arm920t-eabi-4.1.2.tar.gz -C / 注：zxvf 是解压参数，-C 是改变解压路径，/ 表示到根目录。 解压完成后，安装路径为 /opt/toolchains/arm920teabi/，可以通过以下命令查看： # ls /opt/toolchains/arm920teabi/ 为了后续 QT 安装能够调用 arm-linux-gcc 等命令，需要设置环境变量： # gedit /etc/bash.bashrc 在该文件的末尾添加： export PATH=$PATH:/opt/toolchains/arm920teabi/bin 保存并关闭文件后，执行： # source /etc/bash.bashrc# arm-linux-gcc -v 注： 安装路径可以自定义，但环境变量设置必须与安装路径一致。 不同的交叉编译工具默认的安装路径不同，确保环境变量设置正确。 第二步：安装 tslib解压并安装，然后设置配置文件 在 Ubuntu 下安装必要的工具： # apt-get install automake autoconf libtool tslib 是支持触摸屏的库，确保以下条件满足： 硬件支持触摸屏。 内核已加载触摸屏驱动，可以通过命令测试： # cat /dev/input/event0 如果驱动已加载，点击触摸屏会有反应（如乱码）。 有支持触摸屏校准的库，tslib 是常用的选择。 应用程序支持触摸屏。 将 tslib1.4.tar.gz 拷贝到 /home/resource 下，然后解压到 /home 目录： # cd /home/# tar zxvf ./resource/tslib1.4.tar.gz 进入 tslib 目录并配置安装： # cd tslib# ./autogen.sh# ./configure --prefix=/usr/local/tslib/ --host=arm-linux ac_cv_func_malloc_0_nonnull=yes 生成 Makefile 并安装： # make# make install 清理安装文件： # cd /home# rm -r tslib 注：安装过程中若没有出现错误，则表示安装成功，检查 /usr/local/tslib/ 下是否有安装好的文件。 第三步：安装 Qt安装 qt-embedded-linux-opensource-src-4.5.3.tar.gz 确保已安装 Linux 下的 G++ 工具： # apt-get install g++ 将 qt-embedded-linux-opensource-src-4.5.3.tar.gz 拷贝到 /home/resource 下并解压： # cd /home# tar zxvf ./resource/qt-embedded-linux-opensource-src-4.5.3.tar.gz 进入解压后的目录并配置 Qt： # cd qt-embedded-linux-opensource-src-4.5.3# ./configure -prefix /usr/local/Trolltech/QtEmbedded-4.5.3 \\-release -shared \\-fast \\-pch \\-no-qt3support \\-qt-sql-sqlite \\-no-libtiff -no-libmng \\-qt-libjpeg \\-qt-zlib \\-qt-libpng \\-qt-freetype \\-no-openssl \\-nomake examples -nomake demos -nomake tools \\-optimized-qmake \\-no-phonon \\-no-nis \\-no-opengl \\-no-cups \\-no-xcursor -no-xfixes -no-xrandr -no-xrender -no-xkb -no-sm \\-no-xinerama -no-xshape \\-no-separate-debug-info \\-xplatform qws/linux-arm-g++ \\-embedded arm \\-depths 16 \\-no-qvfb \\-qt-gfx-linuxfb \\-no-gfx-qvfb -no-kbd-qvfb -no-mouse-qvfb \\-qt-kbd-usb \\-confirm-license \\-no-armfpa \\-qt-mouse-tslib \\-L /usr/local/tslib/lib \\-I /usr/local/tslib/include 注：上述配置命令用于裁剪 Qt 库，避免过大的库导致 ARM 板负载不了。可以通过 ./configure -help 查看各选项的含义。 编译和安装： # make# make install 修改 qmake 名称以避免冲突： # cd /usr/local/Trolltech/QtEmbedded-4.5.3/bin# mv qmake qmake-arm 添加环境变量： # gedit /etc/bash.bashrc 在文件末尾添加： export PATH=$PATH:/usr/local/Trolltech/QtEmbedded-4.5.3/bin 保存并关闭文件后，执行： # source /etc/bash.bashrc# qmake-arm (按 Tab 键，若出现 qmake-arm 则表示环境变量设置成功) 第四步：启动 NFS 服务在进行程序调试时，使用 NFS（网络文件系统）挂载的方法非常方便且节省资源。首先，确保你的 Ubuntu 系统已经安装了 NFS 服务。如果尚未安装，可以通过以下命令进行安装： # apt-get install nfs-kernel-server // 安装 NFS 服务 接下来，修改 NFS 配置文件以设置共享目录： # gedit /etc/exports // 打开 NFS 配置文件 在该文件的末尾添加以下内容： /home/nfs 192.168.1.128(rw,sync,no_root_squash) // 192.168.1.128 为开发板的 IP 地址 保存并关闭文件。然后，重启 NFS 服务以使配置生效： # /etc/init.d/portmap restart // 重启 portmap 服务# /etc/init.d/nfs-kernel-server restart // 重启 NFS 服务 注意：确保 IP 地址配置正确，否则 NFS 将无法挂载。开发板和 Ubuntu 必须在同一网段。若 Ubuntu 是在虚拟机中运行，还需确保虚拟机与主机（PC）之间的网络连接正常。通常，使用桥接（bridged）或 NAT（网络地址转换）均可，具体可根据实际情况进行测试。开发板的 IP 地址设置通常会在购买时提供的文档中说明。 例如，我的配置如下： 开发板 IP 地址：192.168.1.128 主机（虚拟机）IP 地址：192.168.1.110（在第七步中设置） 设置开发板的 IP 地址：在串口终端中输入以下命令： setenv bootargs root=/dev/nfs nfsroot=192.168.1.110:/home/nfs ip=192.168.1.128:192.168.1.110:192.168.1.1:255.255.255.0:www.urbetter.com:eth0:off console=ttySAC0,115200 然后保存配置： # saveenv // 保存配置 此命令在开发板启动时进入 U-Boot（类似于 PC 的 BIOS）时输入。使用串口调试工具（如 Windows 的超级终端），在开发板开机时按空格键进入 U-Boot，然后在串口终端输入上述命令并保存参数配置。具体操作可参考第七步。 第五步：修改文件系统为了确保开发板能够成功挂载 NFS 并运行程序，必须使用针对 ARM 硬件平台的文件系统。通常，开发板供应商会提供这样的文件系统。我使用的是 urbetter-rootfs-qt-2.2.0.tgz。 将 urbetter-rootfs-qt-2.2.0.tgz 拷贝到 /home/resource 目录下，并创建一个 NFS 挂载用的共享文件夹： # cd /home# mkdir nfs // 创建 NFS 共享目录# cd /home/resource# tar zxvf urbetter-rootfs-qt-2.2.0.tgz -C /home/nfs // 解压文件系统到 /home/nfs 进入 /home/nfs 目录，删除不需要的文件： # cd /home/nfs# ls // 查看文件 手动删除 /home/nfs/opt/Qtopia 下的所有内容，以移除文件系统自带的系统软件等。接着，删除 /home/nfs/usr/local 下的所有内容，以移除文件系统自带的用户程序等。 打开 /home/nfs/etc/init.d/rcS 文件，屏蔽系统默认启动代码，删除以下内容： /bin/qtopia // 启动代码echo /dev/tty1echo Starting Qtopia, please waiting... /dev/tty1 // 提示信息echo echo Starting Qtopia, please waiting... 保存并关闭文件。 将 Qt 的库文件从安装目录拷贝到 /home/nfs/opt/Qtopia： # cp -r /usr/local/Trolltech/QtEmbedded-4.5.3/lib /home/nfs/opt/Qtopia // -r 是递归拷贝 将 tslib 的整个文件夹拷贝到 /home/nfs/usr/local/： # cp -r /usr/local/tslib/ /home/nfs/usr/local/ // -r 是递归拷贝 进入 /usr/local/tslib/ 目录，查看以下目录： # cd /usr/local/tslib/# ls // 应该看到 /bin, /etc, /include, /lib 在 /bin 目录下，你应该看到一些可执行文件，如 ts_calibrate（校准程序）和 ts_test（测试程序）。在 /etc 目录下，找到触摸屏的配置文件 ts.conf，并在文件末尾添加以下内容： module_raw input // 启动触摸屏的数据输入方式module pthres module variance delta=30module dejitter delta=100module linear 保存并关闭该文件。 设置 NFS 文件系统的环境变量： # gedit /home/nfs/etc/profile // 手动以记事本打开 在该文件末尾添加以下内容： export QTDIR=/opt/Qtopia // Qt 根目录export PATH=$QTDIR/bin:$PATH // Qt 可执行文件目录export QT_QWS_FONTDIR=/opt/Qtopia/lib/fonts // Qt 字体库export TSLIB_ROOT=/usr/local/tslib // tslib 路径export TSLIB_TSDEVICE=/dev/input/event1 // 指定触摸屏对应驱动设备export TSLIB_FBDEVICE=/dev/fb0export TSLIB_CONSOLEDEVICE=noneexport TSLIB_CALIBFILE=/etc/pointercal // 指定校准文件生成目录export TSLIB_CONFFILE=$TSLIB_ROOT/etc/ts.conf // 指定 tslib 配置文件export TSLIB_PLUGINDIR=$TSLIB_ROOT/lib/ts // 指定 tslib 数据读取库export LD_LIBRARY_PATH=$TSLIB_ROOT/lib:$QTDIR/lib:$LD_LIBRARY_PATH // 指定 QT 库和 tslib 校准库 保存并关闭文件。 第六步：找到 QT 测试程序为了验证 QT 是否成功移植，需要进行 QT 程序测试。测试程序有很多，例如在解压的 /home/qt-embedded-linux-opensource-src-4.5.3/ 目录下的 ./demos 和 ./examples 文件夹中就有许多示例。你也可以使用自己开发的 QT 应用程序进行测试。我选择了 ./demos/embedded 作为测试程序。 在测试程序之前，确保先进行编译，使用 qmake-arm（重命名后的 qmake 命令）进行编译。编译步骤如下： 确保程序完整且正确，将与程序相关的所有文件（如头文件等）放在同一文件夹下。 使用 cd 命令进入该文件夹，然后执行以下命令： # qmake -project# qmake# make 执行 make 后，将生成能够在 ARM 板上运行的可执行文件（在 PC 上无法运行）。将该可执行文件拷贝到 NFS 目录（homenfs）下的任意位置，最好连同整个文件夹一起拷贝过来。 例如，我的测试程序为 ./demos/embedded，该程序下有三个小的测试程序，可以一起编译，也可以单独编译。我的操作如下： # cp -r /home/qt-embedded-linux-opensource-src-4.5.3/demos/embedded /home/nfs // 拷贝测试程序# cd /home/nfs/embedded# ls // 查看三个小测试程序# qmake-arm# make // 编译三个测试程序 此时，测试程序已经准备好，等待测试。 第七步：NFS 挂载测试 确保开发板与 PC 连接正常，包括网线和串口连接。打开终端调试工具（如 Xshell），我使用的是 Windows 下的超级终端，确保波特率设置为 115200。 设置虚拟机 Ubuntu 的 IP 地址： #ifconfig // 查看当前 IP#ifconfig eth5 192.168.1.110 up // 配置 IP 地址#ifconfig // 确认 IP 地址为 192.168.1.110 注意：eth 后面的数字可能不同，查看 IP 时可以看到自己的 eth 号，替换为相应的数字即可。 打开 ARM 开发板电源，此时你应该在终端工具上看到反应（出现一系列数据），当出现提示信息 Please press Enter to active this console. 时，按回车键。 在串口终端上运行以下命令： 串口终端# ls // 显示 NFS 文件系统下的所有文件串口终端# cd /embedded串口终端# ls串口终端# cd ./styledemo串口终端# ls串口终端# ./styledemo -qws // 运行测试文件，-qws 是参数 等待片刻，ARM 板显示屏上应该会出现一些 QT 程序的画面。此时可以插入鼠标进行测试，但触摸屏可能无法使用。这个问题我曾经困扰很久，最终找到了解决方法，具体方法不在此文档中提及。如有需要，可以在我的百度文库上下载《GPS 触摸屏校准》。 注意：如果运行时串口终端提示找不到某个库文件（问题不大），可能是环境变量未设置好，或确实缺少该库文件。此时可以在 Linux 终端下输入以下命令查找库文件： # locate 这个库的名字 // 找出存在该库的路径 例如，如果缺少库 libts-1.0.so.0，则输入： # locate libts-1.0.so.0 你会发现该库可能存在于多个路径中，甚至在 /home/nfs/opt/Qtopia/lib 下也有。可以尝试将交叉编译器安装目录下的对应库拷贝到 /home/nfs/opt/Qtopia/lib。如果缺少的是库链接文件，最好连同库和库链接一起拷贝。拷贝完成后，重启开发板，再次在串口终端上重复上述测试。如果交叉编译器安装目录下的对应库没有，或者尝试后仍然不行，可以转到 QT 的安装目录寻找对应库并拷贝（替换原有库），重启开发板后再试。","categories":["2.语言","Qt"]},{"title":"Qt基本数据类型转换","path":"/2025/03/02/2-语言-Qt-Qt基本数据类型转换/","content":"char * 与 const char * 的转换在 C 和 C++ 中，char * 和 const char * 是两种常见的字符指针类型。它们之间的转换需要谨慎处理，以避免潜在的错误和警告。 char *ch1 = hello11; // ch1 是一个可修改的字符指针const char *ch2 = hello22; // ch2 是一个常量字符指针ch2 = ch1; // 这行代码不会报错，但会产生警告，因为我们试图将一个可修改的指针赋值给一个常量指针 在上面的例子中，虽然 ch2 可以接受 ch1 的值，但由于 ch2 是常量指针，编译器会警告我们可能会修改常量数据。为了将 const char * 转换为 char *，可以使用强制类型转换： ch1 = (char *)ch2; // 这里将 const char * 强制转换为 char * 这种转换可能会导致未定义行为，特别是如果 ch2 指向的是一个字符串字面量，因为字符串字面量是不可修改的。 char 转换为 QString在 Qt 框架中，QString 是一个用于处理字符串的类。将单个字符转换为 QString 可以使用构造函数： char a = b; // 定义一个字符变量QString str; // 创建一个 QString 对象str = QString(a); // 将字符转换为 QString 这里，QString 的构造函数接受一个字符并创建一个包含该字符的字符串。 QString 转换为 char要将 QString 转换为 char *，可以使用 toLatin1() 方法，该方法返回一个 QByteArray，然后可以通过 data() 方法获取 char *： QString str = abc; // 创建一个 QString 对象char *ch; // 定义一个 char 指针ch = str.toLatin1().data(); // 将 QString 转换为 char * 请注意，data() 返回的指针指向的内存是临时的，因此在使用后应谨慎处理。 QByteArray 转换为 char *在 Qt 中，QByteArray 是一个用于处理字节数组的类。将 QByteArray 转换为 char * 可以直接使用 data() 方法： char *ch; // 定义一个 char 指针QByteArray byte; // 创建一个 QByteArray 对象ch = byte.data(); // 将 QByteArray 转换为 char * 同样，data() 返回的指针指向的内存是临时的，使用时要小心。 char * 转换为 QByteArray将 char * 转换为 QByteArray 可以通过构造函数实现： char *ch; // 定义一个 char 指针QByteArray byte; // 创建一个 QByteArray 对象byte = QByteArray(ch); // 将 char * 转换为 QByteArray 这种转换会创建一个新的 QByteArray，其内容与 char * 指向的内容相同。 QString 转换为 QByteArray将 QString 转换为 QByteArray 可以使用 toUtf8() 或 toAscii() 方法： QByteArray byte; // 创建一个 QByteArray 对象QString string; // 创建一个 QString 对象byte = string.toUtf8(); // 将 QString 转换为 QByteArray 这里，toUtf8() 方法将 QString 转换为 UTF-8 编码的字节数组。 QByteArray 转换为 QString将 QByteArray 转换为 QString 可以直接使用构造函数： QByteArray byte; // 创建一个 QByteArray 对象QString string; // 创建一个 QString 对象string = QString(byte); // 将 QByteArray 转换为 QString 这种转换会将字节数组的内容解码为字符串。 int 转 QString将整数转换为 QString 可以使用 QString::number() 方法： int a = 10; // 定义一个整数QString b; // 创建一个 QString 对象b = QString::number(a); // 将整数转换为 QString 这种方法将整数转换为对应的字符串表示。 QString 转 int要将 QString 转换为整数，可以使用 toInt() 方法： QString a = 120; // 创建一个 QString 对象int b; // 定义一个整数b = a.toInt(); // 将 QString 转换为 int toInt() 方法会将字符串中的数字解析为整数。","categories":["2.语言","Qt"]},{"title":"半透明","path":"/2025/03/02/2-语言-Qt-样式表-半透明/","content":"头文件（mainwindow.h）#ifndef MAINWINDOW_H#define MAINWINDOW_H#include QMainWindow#include QIconnamespace Ui class MainWindow;class MainWindow : public QMainWindow Q_OBJECTpublic: explicit MainWindow(QWidget *parent = nullptr); ~MainWindow();private: Ui::MainWindow *ui;private slots: void on_pushButton_Set_clicked();;#endif // MAINWINDOW_H 实现文件（mainwindow.cpp）#include mainwindow.h#include ui_mainwindow.hMainWindow::MainWindow(QWidget *parent) : QMainWindow(parent), ui(new Ui::MainWindow) ui-setupUi(this); this-setWindowTitle(QQ); this-setWindowIcon(QIcon(:/images/po.jpg)); this-setWindowFlags(Qt::FramelessWindowHint); // 去掉标题栏 this-setGeometry(QRect(950, 55, 350, 250)); // 设置窗口的位置和大小 this-setAttribute(Qt::WA_TranslucentBackground, true); // 设置背景透明 this-resize(300, 300); // 设置显示大小MainWindow::~MainWindow() delete ui; 主程序（main.cpp）#include QApplication#include QTextCodec#include mainwindow.hint main(int argc, char *argv[]) QApplication a(argc, argv); QTextCodec::setCodecForCStrings(QTextCodec::codecForName(GB2312)); QTextCodec::setCodecForLocale(QTextCodec::codecForName(GB2312)); QTextCodec::setCodecForTr(QTextCodec::codecForName(GB2312)); MainWindow w; w.show(); return a.exec(); 透明效果的实现在这个例子中，我们使用了几种不同的透明效果，具体如下： 全体透明：使用 this-setWindowOpacity(0.7); 可以将整个窗口（包括标题栏和所有控件）设置为透明，参数值控制透明度，0.0 表示完全透明，1.0 表示完全不透明。 窗口整体透明，控件不透明：通过设置窗体的背景色为全透明来实现。代码示例如下： QPalette pal = palette();pal.setColor(QPalette::background, QColor(0x00, 0xff, 0x00, 0x00));setPalette(pal); 窗体标题栏不透明，背景透明：这是本例中使用的效果，通过 this-setAttribute(Qt::WA_TranslucentBackground, true); 来实现。 窗口整体不透明，局部透明：在 paintEvent 中使用 QPainter::CompositionMode_Clear 模式绘制区域全透明，示例代码如下： void MainWindow::paintEvent(QPaintEvent*) QPainter p(this); p.setCompositionMode(QPainter::CompositionMode_Clear); p.fillRect(30, 30, 300, 300, Qt::SolidPattern); 去掉标题栏要去掉窗口的标题栏，可以使用以下代码： this-setWindowFlags(Qt::FramelessWindowHint); // 去掉标题栏","categories":["2.语言","Qt","样式表"]},{"title":"QSlider样式表","path":"/2025/03/02/2-语言-Qt-样式表-QSlider样式表/","content":"// 滑动条槽（整体）的美化QSlider::groove:horizontal height: 12px; // 设置滑动条槽的高度为12像素，确保用户在使用时有良好的触感 left: 0px; // 左侧边距为0，确保滑动条从最左边开始 right: 0px; // 右侧边距为0，确保滑动条延伸到最右边 border: 0px; // 指定无边框，保持简洁的外观 border-radius: 6px; // 设置圆角为6像素，使滑动条看起来更加柔和 background: rgba(0, 0, 0, 0.5); // 设置背景颜色为半透明黑色，增加视觉层次感// 滑块的美化QSlider::handle:horizontal width: 50px; // 设置滑块的宽度为50像素，确保用户易于抓取 height: 50px; // 设置滑块的高度为50像素，提供足够的点击区域 margin-top: -20px; // 上边距为-20像素，使滑块与槽的中心对齐 margin-left: 0px; // 左边距为0，保持滑块在槽内 margin-bottom: -20px; // 下边距为-20像素，确保滑块与槽的底部对齐 margin-right: 0px; // 右边距为0，保持滑块在槽内 border-image: url(:/res/images/setting_slider_handle.png); // 使用自定义图片作为滑块的外观// 已滑过的进度美化QSlider::sub-page:horizontal background: rgba(80, 166, 234, 1); // 设置已滑过部分的背景颜色为不透明的蓝色// 未滑过的进度美化QSlider::add-page:horizontal background: rgb(0, 0, 255); // 设置未滑过部分的背景颜色为纯蓝色// 注意事项// groove、sub-page 和 add-page 三个属性共存时，add-page 的颜色会覆盖 groove 的颜色。// 如果滑块需要外扩比槽部分大，可以使用 margin 参数进行调整。// 当然，QSlider 的整体高度必须大于或等于滑块的高度，否则滑块会被压缩。// 例子中滑块使用的是图片，groove、handle、sub-page 和 add-page 这些既可以用颜色填充，也可以用图片填充，具体取决于设计需求。// 如果想要更炫酷的效果，可以使用线性渐变颜色来定义背景，例如：background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #fff, stop:1 #ddd); // 定义从白色到灰色的渐变效果// 状态变化的美化QSlider::handle:horizontal:hover width: 50px; // 鼠标悬停时，滑块宽度保持不变 height: 50px; // 鼠标悬停时，滑块高度保持不变 margin-top: -20px; // 鼠标悬停时，上边距保持不变 margin-left: 0px; // 鼠标悬停时，左边距保持不变 margin-bottom: -20px; // 鼠标悬停时，下边距保持不变 margin-right: 0px; // 鼠标悬停时，右边距保持不变 border-image: url(:/res/images/setting_slider_handle_hover.png); // 鼠标悬停时使用不同的滑块图片QSlider::sub-page:horizontal:disabled background: #BB345F; // 设置禁用状态下已滑过部分的背景颜色为暗红色QSlider::add-page:horizontal:disabled background: #1ADEFF; // 设置禁用状态下未滑过部分的背景颜色为明亮的蓝色QSlider::handle:horizontal:disabled background: #EEDDFF; // 设置禁用状态下滑块的背景颜色为淡紫色// 这样在鼠标悬停或设置为无效状态时，滑块和进度条的颜色会发生变化，增强用户体验。","categories":["2.语言","Qt","样式表"]},{"title":"样式表","path":"/2025/03/02/2-语言-Qt-样式表-样式表/","content":"Qt 的 QSS 样式表功能Qt 自带一个强大的皮肤功能，称为 QSS（Qt 样式表），类似于网页设计中的 CSS。即使没有专业的美工设计师，你也能轻松创建出炫酷的用户界面。完整的官方文档可以通过文首的蓝色链接访问，这里我们将介绍一些常用的语法。 1 样式表语法🔵 选择器类型在开发过程中，你可能会遇到在界面上设置背景图片的情况，但发现界面上的某些组件（例如按钮）的背景也被设置为该背景图。这通常是由于选择器的使用不当造成的。 例如，假设你有一个名为 frame 的组件，使用选择器时可以指定样式仅对该组件有效。若选择器为具体的类实例对象名，需在前面加上 # 符号。例如，#frame 表示只对名为 frame 的具体对象生效，而 QFrame 则会影响所有 QFrame 类及其子类的实例。 以下是一些常见的选择器示例： **QPushButton[flat=false]**：匹配所有非扁平化的 QPushButton 实例。 **.QPushButton**：匹配所有 QPushButton 实例，但不包括其子类，注意前面的点。 **QPushButton#okButton**：匹配对象名称为 okButton 的所有 QPushButton 实例。 **QDialog QPushButton**：匹配所有 QPushButton 实例，这些实例是 QDialog 的后代。 **QDialog QPushButton**：匹配所有 QPushButton 实例，这些实例是 QDialog 的直接子代。 🔵 声明样式表中的声明部分定义了具体的样式属性。例如： QPushButton color: rgb(255, 0, 0); /* 这条语句将所有QPushButton类的按钮字体颜色设置为红色。 */QPushButton background-color: rgb(0, 170, 255); /* 这条语句将所有QPushButton类的按钮背景色设置为蓝色。 */ 如果你按照上述方式设置，按钮的字体颜色在编译前是可见的，但按钮的背景可能不会立即显示。为了确保背景色显示，可以添加 border-radius: 0px;，这样按钮的背景色就会正常显示。border-radius 属性定义了边框的圆角半径，数值越大，按钮的角就越圆润。 🔵 子控件对于复杂的窗口组件（如 QTabWidget），你需要访问其子控件并单独设置样式。直接右键点击 QTabWidget 使用样式表是不可行的。 例如，在一个 QTabWidget 中，红色部分代表选项卡（如 QTabBar 或 QToolBox），而蓝色部分则是窗格（pane）。为了实现特定的样式效果，你需要分别为这些子控件设置样式表。 🔵 伪状态伪状态用于实现界面的动态效果，能够检测用户的交互行为，例如鼠标悬停或按下按钮等。以下是一些常用的伪状态： 悬停：:hover 不悬停：:!hover 悬停并选中：:hover:checked 悬停并按下：:hover:!pressed 例如，如果你想修改输入框的边框颜色，可以使用以下样式： border-style: solid;border-color: rgb(170, 170, 255); 在使用边框颜色之前，必须先定义边框的风格。默认情况下，边框类型是 none，这意味着即使设置了边框颜色，边框也不会显示。以下是可用的边框样式类型： none：无边框。 hidden：与 none 相同，但在表格中用于解决边框冲突。 dotted：点状边框，通常在大多数浏览器中呈现为实线。 dashed：虚线，通常在大多数浏览器中呈现为实线。 solid：实线边框。 double：双线边框，宽度等于 border-width 的值。 groove：3D 凹槽边框，效果取决于 border-color 的值。 ridge：3D 垄状边框，效果取决于 border-color 的值。 inset：3D 内嵌边框，效果取决于 border-color 的值。 outset：3D 外凸边框，效果取决于 border-color 的值。 通过合理使用这些选择器和样式声明，你可以为 Qt 应用程序创建出丰富多彩的用户界面。 2 setStyleSheet 简介Qt 的样式表（Style Sheets）是一个非常有用的工具，它允许开发者自定义窗口的外观。除了使用样式表，开发者还可以通过子类 QStyle 来实现样式定制。Qt 样式表的语法与 HTML 的 CSS 有很大的相似性，但它专门用于窗口组件。简单来说，setStyleSheet 函数用于设置组件窗口的外观。 3 setStyleSheet 使用方法基本句法样式表的语法基本上与 HTML CSS 语法一致。样式表由一系列样式规则组成，每个样式规则由一个 selector 和一个 declaration 组成。selector 指定哪些窗口将受到这些规则的影响，而 declaration 则指定要设置的属性。例如： QPushButton color: red; 在这个例子中，QPushButton 是 selector，而 color: red; 是 declaration。这个规则指定所有 QPushButton 及其子类的前景颜色为红色。值得注意的是，Qt 对大小写不敏感，因此 color、ColoR 和 COLOR 都是等效的。 多个 selector 可以用逗号 , 分隔，例如： QPushButton, QLineEdit, QComboBox color: red; declaration 部分可以包含多个属性值对，用分号 ; 分隔。例如： QPushButton color: red; font-family: Arial; line-height: 26px; 示例代码如下： QWidget-setStyleSheet(QPushButton, QLineEdit, QPlainTextEdit color: blue; background-color: yellow; selection-color: yellow; selection-background-color: blue; ); 常见的 selector 部分 declaration 样式-英文 参数 样式-中文 color: white rgb(110,110,110) #eb7350 前景颜色，字体颜色 background: transparent 背景为透明（可以为图片等） background-color: white rgb(110,110,110) #eb7350 背景颜色（只能为颜色） background-position: left right center top bottom 设定图片的位置 background-image: url() .imgback.jpg 背景图片，不缩放图片大小 border-image: url() .imgback.jpg 背景图片，会对图片进行拉伸 border-style: outset inset 边框样式，按下是 inset border-width: px 边框大小 border-radius: px 边框弧度 border: 3px solid red 边框宽度及颜色 border-color: rgba(255, 225, 255, 30) 边框颜色 font-family 微软雅黑 设定字体所属家族 font: bold 14px 字体大小并加粗 font-size: px 字体大小 font-style: inset 字体样式 font-weight: px 字体深浅 selection-color: color 设定选中时的颜色 selection-background-color: color 设定选中时的背景颜色 子控件在 Qt 中，一些界面组件是组合而成的，例如 QComboBox 的下拉按钮或 QSpinBox 的上下调节按钮。这些按钮被称为子控件，子控件同样可以设置样式。子控件使用伪状态进行样式定义。例如： table-setStyleSheet(QTableView::item background-color: #383838; color: white; ); 这段代码设置了 QTableView 中每个单元格的背景色和字体颜色。 常见的子控件 伪状态伪状态允许开发者为组件的特定状态定义样式规则。伪状态出现在 selector 后面，用冒号 : 隔开。 基本使用示例：当鼠标悬停在 QLineEdit 上时，改变其背景色和前景色： QWidget-setStyleSheet(QLineEdit::hover background-color: black; color: yellow; ); 伪状态取反：在伪状态前加一个感叹号。例如，下面的代码定义了 readonly 属性为 false 的 QLineEdit 的背景色： QWidget-setStyleSheet(QLineEdit::!readonly background-color: gray; ); 伪状态串联使用：相当于“逻辑与”的计算。例如，当鼠标悬停在一个被勾选的 QCheckBox 组件上方时，其样式可以这样定义： QWidget-setStyleSheet(QCheckBox:checked:hover background-color: green; ); 伪状态并联使用：相当于“逻辑或”。例如，当鼠标悬停在 QCheckBox 上方或 QCheckBox 被勾选时，样式都被应用： QWidget-setStyleSheet(QCheckBox:hover, QCheckBox:checked background-color: blue; ); 子控件使用伪状态的示例：下面定义了 QCheckBox 的 indicator 在 checked 和 unchecked 两种状态下显示的图片： QCheckBox::indicator:checked image: url(checked.png); QCheckBox::indicator:unchecked image: url(unchecked.png); 常见的伪状态 4 setStyleSheet 使用实例全局使用使用 qApp 的 setStyleSheet 函数可以为整个应用程序设置样式。例如，下面的代码为应用程序的 QLineEdit 组件设置样式： qApp-setStyleSheet(QLineEdit background-color: lightgray; ); 局部使用使用 QWidget::setStyleSheet 函数可以为一个窗口、对话框或界面组件设置样式。例如，下面的代码为主窗口 MainWindow 内的 QLineEdit 组件设置样式： mainWindow-setStyleSheet(QLineEdit color: blue; ); 单独设置一个对象的样式表时，无需指定 selector 的名称。例如，下面的代码设置一个名为 editName 的 QLineEdit 组件的样式： editName-setStyleSheet(color: green;); 注意事项对于同一个组件，样式需要一次性设置好，否则会覆盖掉前一次的设置。例如： btn1-setStyleSheet(QPushButton color: red; ); // 设定前景颜色btn1-setStyleSheet(QPushButton background: yellow; ); // 设定背景颜色 在执行完第一句后，字体会变红；执行完第二句后，字体颜色恢复默认，背景变为黄色。这意味着对于同一个组件的连续设置，只有最后一次执行的样式会生效。 如果想同时设置字体为红色和背景为黄色，应该将所有设置放在一个 setStyleSheet 调用中： btn1-setStyleSheet(QPushButton color: red; background: yellow; ); 对于一个组件及其子组件和伪状态，也需要一次性设置好，否则会覆盖掉前一次设置。例如： table-setStyleSheet(\\ QTableView::item background-color: #383838; color: white; \\ QTableView::item:selected background-color: #383838; color: white; \\ QTableView::item:hover background-color: #4d80e6; color: white; ); 如果再执行下面的代码： table-setStyleSheet(QTableView selection-color: white; selection-background-color: #4d80e6; ); 上面的设置将会被覆盖，导致最终只实现了文字选中后变色的功能。虽然我设置了 QTableView 的不同子部件和伪状态，但 setStyleSheet 始终作用在对象 table 上。 为了实现预期效果，所有设置应放在一个 setStyleSheet 调用中： table-setStyleSheet(\\ QTableView::item background-color: #383838; color: white; \\ QTableView::item:selected background-color: #383838; color: white; \\ QTableView::item:hover background-color: #4d80e6; color: white; \\ selection-color: white; selection-background-color: #4d80e6;); 提示：设置同一组件的子控件和伪状态时，使用空格连接两个对象，进行级联。","categories":["2.语言","Qt","样式表"]},{"title":"QLabel实现滚动字幕","path":"/2025/03/02/2-语言-Qt-QLabel实现滚动字幕/","content":"滚动字幕实现滚动字幕，也称为跑马灯，是一种动态显示文本的方式，通常用于展示信息或广告。使用 QTimer 来控制显示的节奏，但我将文本的截取和显示逻辑放在了 paintEvent 方法中。这样，文本从左端被截掉的部分可以从右端重新显示出来，形成一个循环的效果。 关键难点实现这一效果的关键在于，必须根据控件的宽度来控制字符串的显示位置。因此，我们需要准确计算每个字符的宽度。QWidget 提供了一些方法来帮助我们完成这一任务，其中 QFontMetrics 类可以用来计算字符或字符串的宽度。需要注意的是，这里计算的是字符的宽度，而不是字符的数量。 实现效果下面是如何计算一个字符所占的宽度的示例代码： fontMetrics().width(a); // 计算字符 a 的宽度 完整示例代码以下是实现滚动字幕的完整示例代码： #ifndef TEXTTICKER_H#define TEXTTICKER_H#include QLabel#include QTimer#include QPainterclass TextTicker : public QLabel Q_OBJECTpublic: TextTicker(QWidget *parent = 0); ~TextTicker();protected: void paintEvent(QPaintEvent *event); void updateIndex();private: int m_charWidth; // 每个字符的宽度 int m_curIndex; // 当前字符索引 QString m_showText; // 要显示的文本;#endif // TEXTTICKER_H #include textticker.hTextTicker::TextTicker(QWidget *parent) : QLabel(parent) setMinimumWidth(200); // 设置控件的最小宽度 setMinimumHeight(40); // 设置控件的最小高度 m_curIndex = 0; // 初始化当前字符索引 m_showText = This is a textTicker Text!; // 要显示的文本 m_charWidth = fontMetrics().width(a); // 计算每个字符的宽度 QTimer *timer = new QTimer(this); connect(timer, QTimer::timeout, this, TextTicker::updateIndex); timer-start(100); // 每100毫秒更新一次TextTicker::~TextTicker()void TextTicker::paintEvent(QPaintEvent *event) QLabel::paintEvent(event); // 调用父类的绘制事件 QPainter painter(this); painter.drawText(0, 30, m_showText.mid(m_curIndex)); // 从当前索引开始绘制文本 painter.drawText(width() - m_charWidth * m_curIndex, 30, m_showText.left(m_curIndex)); // 从右侧绘制被截掉的部分void TextTicker::updateIndex() update(); // 更新控件 m_curIndex++; // 增加当前索引 if (m_curIndex * m_charWidth width()) // 如果超出控件宽度 m_curIndex = 0; // 重置索引","categories":["2.语言","Qt"]},{"title":"事件处理","path":"/2025/03/02/2-语言-Qt-事件处理/","content":"一 事件过滤器 eventFilter 的使用方法事件过滤器是一个强大的工具，可以让你在事件到达目标对象之前对其进行处理。使用事件过滤器的过程可以分为两个主要步骤： 1. 安装事件过滤器首先，你需要为目标对象安装事件过滤器。这可以通过调用 installEventFilter 方法来实现。以下是一个简单的示例，展示如何为一个 QComboBox 对象安装事件过滤器： #include QComboBox#include QKeyEvent#include XXX.hbool eventFilter(QObject *obj, QEvent *e); 在 XXX.cpp 文件中的构造函数中，你可以这样做： Xxx::Xxx() combox = new QComboBox(this); // 创建一个 QComboBox 对象 combox-installEventFilter(this); // 为 combox 安装事件过滤器 combox-view()-installEventFilter(this); // 为下拉视图安装事件过滤器 2. 重写 eventFilter 函数接下来，你需要重写 eventFilter 函数，以便处理特定的事件。以下是一个示例，展示如何重写 eventFilter 函数来处理键盘事件： bool timewindows::eventFilter(QObject *obj, QEvent *e) if (e-type() == QEvent::KeyRelease) // 判断是否有键盘事件发生 QKeyEvent *keyEvent = static_castQKeyEvent *(e); // 将事件转换为键盘事件 if (obj == combox-view()) // 判断焦点是否在 combox-view() 上 if (keyEvent-key() == Qt::Key_Up) // 判断按键是否为 Up 键 function(); // 处理函数 return true; // 事件被处理，返回 true else if (obj == combox) if (keyEvent-key() == Qt::Key_Y) // 判断按键是否为 Y 键 function(); // 处理函数 return true; // 事件被处理，返回 true return QObject::eventFilter(obj, e); // 其他情况，调用基类的 eventFilter 在这个示例中，当用户在 QComboBox 的下拉视图中按下 Up 键时，function() 函数将被调用。同样，如果在 QComboBox 本身按下 Y 键，function() 也会被调用。 二 事件QEvent 类概述QEvent 类是所有事件类的基类，负责封装事件参数。它在 Qt 框架中扮演着重要角色，确保事件能够被正确地处理和分发。Qt 的主事件循环通过调用 QCoreApplication::exec() 来启动，并从事件队列中获取本地窗口系统事件。这些事件随后被转换为 QEvent 对象，并通过 QObject 将它们分发到相应的事件处理器。 事件的获取与分发通常情况下，来自窗口系统的事件会被自动处理（spontaneous() 返回真）。然而，开发者也可以通过 QApplication::sendEvent() 和 QApplication::postEvent() 手动发送事件，这时 spontaneous() 返回假。QObject 通过其 event() 函数接收事件。这个函数可以在子类中被重新实现，以处理自定义事件并添加额外的事件类型。例如，QWidget 类就重载了 event() 函数来处理特定的事件。 默认情况下，像 QEvent::MouseButtonPress 和 QEvent::KeyPress 这样的事件会被发送到相应的事件处理函数。值得注意的是，QApplication::sendEvent() 允许一个对象在事件到达目标对象之前进行拦截和处理。 QEvent 的结构基本的 QEvent 只包含一个事件类型参数，而其子类则包含了额外的参数，用于描述特定事件。例如，QMouseEvent 包含鼠标位置和按钮状态的信息，QKeyEvent 则包含按下的键码和修饰键状态。 事件处理器的设计在 Qt 中，事件处理器的设计旨在简化事件的管理。假设每个事件都对应同一个事件处理器，开发者需要在该处理器中对不同事件进行分类处理，这样会导致以下两个问题： 事件处理器变得臃肿复杂，难以维护。 当系统新增事件类型或需要使用自定义事件时，开发者不得不修改 Qt 的源码。 为了解决这些问题，Qt 设计者为不同类型的事件提供了相应的事件处理器。事件和事件处理器之间的桥梁是 QObject::event() 函数。这个虚函数在 QObject 的子类中被实现，例如 QWidget。它的主要功能是分发事件，将不同类型的事件与相应的事件处理器关联起来。真正的事件处理是在事件处理器中进行的。 事件分发示例例如，当 QWidget 产生 QPaintEvent 事件时，QWidget 的 event() 函数会将该事件分发给 QWidget::paintEvent() 事件处理器，从而完成事件的处理。 重载事件处理器根据需要，开发者可以重载 event() 函数，在其中添加事件处理逻辑，或者重载特定的事件处理器函数，如 QResizeEvent、QPaintEvent、QMouseEvent、QKeyEvent 和 QCloseEvent。 示例 1：重载 event()函数以下是一个重载 event() 函数的示例，实现了“Tab”键的缩进功能： bool MyWidget::event(QEvent *event) if (event-type() == QEvent::KeyPress) QKeyEvent *keyEvent = static_castQKeyEvent*(event); if (keyEvent-key() == Qt::Key_Tab) insertCurrentPosition(\\t); return true; // 事件已处理 return QWidget::event(event); // 将其他事件传递给父窗口部件处理 示例 2：重载事件处理函数假设我们有一个 CustomerInfoDialog 小部件，里面包含多个 QLineEdit。我们希望用空格键来代替 Tab 键，以便在这些 QLineEdit 之间切换焦点。可以通过子类化 QLineEdit 并重载 keyPressEvent() 来实现： void MyLineEdit::keyPressEvent(QKeyEvent *event) if (event-key() == Qt::Key_Space) focusNextChild(); // 切换到下一个子控件 else QLineEdit::keyPressEvent(event); // 处理其他未处理的事件 通过这种方式，开发者可以灵活地处理事件，确保应用程序的响应性和可维护性。 三 按键事件的使用方法在处理按键事件时，你需要重写 keyReleaseEvent 函数。这个函数会在用户释放按键时被调用。以下是一个示例： void timewindows::keyReleaseEvent(QKeyEvent *e) switch (e-key()) case Qt::Key_Up: function(); // 处理函数 break; // 退出 switch 语句 case Qt::Key_Down: function(); // 处理函数 break; // 退出 switch 语句 // 其他按键事件可以在这里处理 default: break; // 默认情况下不处理 在这个示例中，当用户释放 Up 键或 Down 键时，function() 函数将被调用。你可以根据需要添加更多的按键事件处理。 四 鼠标事件的使用方法QMouseEvent 的详细描述在 Qt 框架中，QMouseEvent 主要用于处理鼠标左键和右键的单击、释放等操作，而鼠标滚的事件则通过 QWheelEvent 来处理。QMouseEvent 类包含了描述鼠标事件的多个参数，帮助开发者获取鼠标操作的详细信息。 当用户在窗口中按住鼠标按键、移动鼠标或释放按键时，都会产生一个 QMouseEvent 事件。需要注意的是，鼠标移动事件只有在按下鼠标按键的情况下才会被触发，除非开发者显式调用 QWidget::setMouseTracking() 函数来开启鼠标追踪功能。在这种情况下，只要鼠标指针在移动，就会产生一系列的鼠标事件。 在一个窗口中，当鼠标按键被按下时，Qt 会自动捕捉鼠标轨迹，直到最后一个鼠标按键被释放为止。在此期间，鼠标指针所在的父窗口会继续接收鼠标事件。 QMouseEvent 的传递每个鼠标事件都包含一些特定的接受标志（flag），用于指示该事件是否会被接收和处理。如果鼠标指针所在的父窗口不接收该事件，可以调用 ignore() 函数来忽略它。 在多个重叠的窗口中，鼠标事件的传递类似于一个递归的倒立树结构。鼠标事件会沿着鼠标指针所在的父窗口链表向上传递，直到某个窗口调用 accept() 函数进行事件处理。如果没有窗口接受该事件，它将被过滤并销毁。 如果一个鼠标事件传递给鼠标指针所在的窗口，而该窗口的 QT::WA_NoMousePropagation 属性为 TRUE，则该事件不会继续向上传递。 开发者可以通过 pos()、x() 和 y() 函数获取鼠标事件发生时鼠标指针相对于窗口的位置。如果将移动窗口视为一次鼠标事件，可以使用 globalPos() 函数返回全局坐标值，以避免窗口抖动。 使用 QWidget::setEnabled() 函数可以开启或关闭窗口对键盘和鼠标事件的接收。需要处理鼠标事件时，通常需要重写以下几个鼠标事件处理函数： QWidget::mousePressEvent() QWidget::mouseReleaseEvent() QWidget::mouseDoubleClickEvent() QWidget::mouseMoveEvent() 鼠标事件在使用鼠标事件时，需要包含头文件： #include QMouseEvent 1. 鼠标按下事件void Widget::mousePressEvent(QMouseEvent *event) // 如果是鼠标左键按下 if (event-button() == Qt::LeftButton) // 处理左键按下的逻辑 // 如果是鼠标右键按下 else if (event-button() == Qt::RightButton) // 处理右键按下的逻辑 2. 鼠标移动事件默认情况下，鼠标移动事件需要在点击后才能触发。可以通过设置为自动触发来改变这一行为： setMouseTracking(true); void Widget::mouseMoveEvent(QMouseEvent *event) // 这里必须使用buttons()进行按位与 if (event-buttons() Qt::LeftButton) // 处理鼠标移动的逻辑 3. 鼠标释放事件void Widget::mouseReleaseEvent(QMouseEvent *event) // 处理鼠标释放的逻辑 4. 鼠标双击事件void Widget::mouseDoubleClickEvent(QMouseEvent *event) // 如果是鼠标左键双击 if (event-button() == Qt::LeftButton) // 处理左键双击的逻辑 5. 滚轮事件void Widget::wheelEvent(QWheelEvent *event) if (event-delta() 0) // 当滚轮远离使用者时 // 处理滚轮向上滚动的逻辑 else // 当滚轮向使用者方向旋转时 // 处理滚轮向下滚动的逻辑 键盘事件在使用键盘事件时，需要包含头文件： #include QKeyEvent 1. 键盘按下事件void Widget::keyPressEvent(QKeyEvent *event) // 检查是否按下Ctrl键 if (event-modifiers() == Qt::ControlModifier) // 检查是否按下M键 if (event-key() == Qt::Key_M) // 处理Ctrl + M的逻辑 else QWidget::keyPressEvent(event); // 保存默认事件 // 处理两个普通按键，避免自动重复 if (event-key() == Qt::Key_Up) if (event-isAutoRepeat()) return; // 避免重复处理 keyUp = true; // 标记向上方向键已按下 else if (event-key() == Qt::Key_Left) if (event-isAutoRepeat()) return; keyLeft = true; 2. 按键释放事件void Widget::keyReleaseEvent(QKeyEvent *event) // 处理两个普通按键，避免自动重复 if (event-key() == Qt::Key_Up) if (event-isAutoRepeat()) return; // 处理向上方向键释放的逻辑 else if (event-key() == Qt::Key_Left) if (event-isAutoRepeat()) return; // 处理向左方向键释放的逻辑 常用公有成员函数1. globalPos()、globalX()、globalY()这三个函数返回鼠标指针的全局坐标，尤其在异步窗口系统（如 X11）中非常重要。 const QPoint QMouseEvent::globalPos() const 返回鼠标指针的全局坐标值。无论何时移动窗口作为对鼠标事件的响应时，globalPos() 返回的当前鼠标指针坐标值与 QCursor::pos() 的返回值是不同的。可以通过调用 QWidget::mapToGlobal(pos()) 在窗口坐标和全局坐标系之间进行转换。 int QMouseEvent::globalX() const 返回鼠标事件发生时鼠标指针全局坐标的 X 值，相当于 globalPos.x()。 int QMouseEvent::globalY() const 返回鼠标事件发生时鼠标指针全局坐标的 Y 值，相当于 globalPos.y()。 2. pos()、posF()、x()、y()这四个函数返回鼠标指针在当前接收鼠标事件的窗口中的位置。 const QPoint QMouseEvent::pos() const 返回鼠标指针相对于接收该鼠标事件窗口的位置，坐标值为整型。 QPointF QMouseEvent::posF() const 返回鼠标指针在接收该鼠标事件窗口的相对位置，坐标值为浮点型，提供更高的精度。 int QMouseEvent::x() const 返回鼠标事件发生时，鼠标指针在当前接收鼠标事件的窗口中位置的 X 坐标值，相当于 pos().x()。 int QMouseEvent::y() const 返回鼠标事件发生时，鼠标指针在当前接收鼠标事件的窗口中位置的 Y 坐标值，相当于 pos().y()。","categories":["2.语言","Qt"]},{"title":"布局管理","path":"/2025/03/02/2-语言-Qt-布局管理/","content":"// m.h 文件的内容#ifndef M_H#define M_H#include QtWidgets // 引入Qt Widgets模块，提供图形用户界面组件// 定义一个名为B的类，继承自QWidget，表示一个窗口部件class B : public QWidget Q_OBJECT // 宏，启用Qt的信号和槽机制public: QVBoxLayout *pv; // 垂直布局指针，用于管理按钮的布局 QHBoxLayout *ph; // 水平布局指针，用于管理操作按钮的布局 QLayoutItem* pi; // 布局项指针，用于存储当前操作的布局项 QWidget *pw; // 用于保存被操作的部件 QPushButton *pb, *pb1, *pb2, *pb3, *pb4, *pb5, *pb6, *pb7; // 多个按钮指针 // 构造函数，初始化窗口部件 B(QWidget* p = 0) : QWidget(p) pw = 0; // 初始化pw为0 pi = 0; // 初始化pi为0 pv = new QVBoxLayout; // 创建一个新的垂直布局 // 创建多个按钮并设置其文本 pb = new QPushButton(AAA); pb1 = new QPushButton(BBB); pb2 = new QPushButton(CCC); pb3 = new QPushButton(DDD); pb4 = new QPushButton(replace); // 替换按钮 pb5 = new QPushButton(remove); // 移除按钮 pb6 = new QPushButton(take); // 取出按钮 pb7 = new QPushButton(del); // 删除按钮 // 将按钮添加到垂直布局中 pv-addWidget(pb); pv-addWidget(pb1); pv-addWidget(pb2); ph = new QHBoxLayout; // 创建一个新的水平布局 // 将操作按钮添加到水平布局中 ph-addWidget(pb4); ph-addWidget(pb5); ph-addWidget(pb6); ph-addWidget(pb7); // 创建主布局，将水平布局和垂直布局添加到主布局中 QVBoxLayout *pv1 = new QVBoxLayout; pv1-addLayout(ph); pv1-addLayout(pv); setLayout(pv1); // 设置窗口的布局为主布局 // 连接按钮的点击信号到相应的槽函数 connect(pb4, QPushButton::clicked, this, B::f); // 点击替换按钮时调用f函数 connect(pb5, QPushButton::clicked, this, B::f1); // 点击移除按钮时调用f1函数 connect(pb6, QPushButton::clicked, this, B::f2); // 点击取出按钮时调用f2函数 connect(pb7, QPushButton::clicked, this, B::f3); // 点击删除按钮时调用f3函数 // 构造函数结束public slots: void f() // 替换pv布局中的pb按钮为pb3按钮，pb未被删除 pi = pv-replaceWidget(pb, pb3); // 检查pi管理的部件是否为按钮 if (pi-controlTypes() == QSizePolicy::PushButton) pw = pi-widget(); // 将被替换的按钮赋值给pw void f1() // 从pv布局中移除pb1按钮，但不删除它 pv-QLayout::removeWidget(pb1); pw = pb1; // 将pb1赋值给pw void f2() // 使用QBoxLayout类的takeAt函数移除索引为0的部件，但不删除它 pi = pv-QBoxLayout::takeAt(0); // 检查pi管理的部件是否为按钮 if (pi-controlTypes() == QSizePolicy::PushButton) pw = pi-widget(); // 将被取出的按钮赋值给pw void f3() // 删除项目和部件的函数 // 仅删除布局项目pi不会删除布局管理的部件pw，因此需要明确删除 if (pi != 0) delete pi; // 删除布局项 pi = 0; // 将pi重置为0 if (pw != 0) delete pw; // 删除部件 pw = 0; // 将pw重置为0 ;#endif // M_H// m.cpp 文件的内容#include m.h // 包含头文件m.hint main(int argc, char *argv[]) QApplication a(argc, argv); // 创建QApplication对象，初始化应用程序 B w; // 创建B类的实例，表示主窗口 w.resize(300, 200); // 设置窗口大小为300x200像素 w.show(); // 显示窗口 return a.exec(); // 进入应用程序的事件循环 总结这段代码定义了一个 Qt 应用程序，创建了一个窗口部件类 B。该类包含多个按钮和布局，允许用户通过点击按钮来替换、移除、取出和删除按钮。每个按钮的功能通过槽函数实现，确保用户的交互能够动态更新界面。主函数初始化应用程序并显示窗口。","categories":["2.语言","Qt"]},{"title":"QTabWidget","path":"/2025/03/02/2-语言-Qt-QTabWidget的隐藏/","content":"对于一个 QTabWidget，在不同的状态下显示不同的标签页（tab）是一个常见需求。有时，我们需要隐藏某些标签页，以便用户界面更加简洁。虽然可以使用 removeTab() 方法来删除标签页，但这样做会导致在需要再次显示这些标签页时，必须重新添加它们，这不仅繁琐，还可能需要复杂的索引计算。 因此，寻找一种在不删除标签页的情况下隐藏它们的方法显得尤为重要。遗憾的是，Qt 并没有提供类似 hide() 或 setVisible() 的接口来直接隐藏标签页（查看源码可以发现，标签页并不是 QWidget 的子类）。那么，我们该如何解决这个问题呢？ 我的解决方案是结合使用 QTabWidget::setTabEnabled() 接口和 Qt 样式表（QSS）来实现隐藏标签页的效果。 使用 setTabEnabled()setTabEnabled() 方法的功能非常简单明了：当某些标签页不需要被使用时，可以将它们禁用。禁用标签页后，它们仍然会显示在界面上，但用户无法与之交互。然而，禁用标签页并不会使其完全隐藏，这时就需要借助 QSS 的力量。 使用 QSS 隐藏标签页虽然 QSS 本身并不能直接隐藏标签页，但我们可以通过设置标签页的样式来达到类似的效果。具体来说，我们可以将禁用状态的标签页的宽度设置为 0，并将其文字颜色设置为透明。这样，用户在界面上就看不到这些标签页，从而实现了间接隐藏的目的。 示例代码以下是实现这一功能的示例代码： // 假设 tabWidget 是一个 QTabWidget 的实例tabWidget-setTabEnabled(index, false); // 禁用指定的标签页// 使用 QSS 设置样式QString style = QTabBar::tab:disabled width: 0px; color: transparent; ;tabWidget-setStyleSheet(style); 在这个示例中，index 是我们想要隐藏的标签页的索引。通过调用 setTabEnabled() 方法，我们可以禁用该标签页。接着，我们使用 QSS 设置标签页的样式，使其在禁用状态下宽度为 0，并将文字颜色设为透明。这样，用户在界面上就看不到这个标签页了。 如果之前被选择的 tab 如果被禁用掉的话，它不会自动重新选择一个可用的 tab，这个需要手动处理；另一个是如果仔细观察的话，tab 之间有一个隐藏的 tab 的话对显示样式会有细微的影响，最左侧和最右侧最为明显（可能会少一个边框）。","categories":["2.语言","Qt"]},{"title":"QTabWidget样式","path":"/2025/03/02/2-语言-Qt-样式表-QTabWidget样式/","content":"一、QTabWidget 样式设置 在设置 QTabWidget 的样式时，使用了 setStyleSheet 方法来定义其外观。以下是具体的样式设置： setStyleSheet(QTabWidget::pane \\ border-width: 1px; \\ border-color: rgb(48, 104, 151); \\ border-style: outset; \\ background-color: rgb(132, 171, 208); \\ background: transparent; \\ \\QTabWidget::tab-bar \\ border-width: 0px; \\ \\QTabBar::tab \\ border-bottom-color: #C2C7CB; \\ border-top-left-radius: 0px; \\ border-top-right-radius: 0px; \\ max-width: 75px; \\ min-width: 75px; \\ min-height: 25px; \\ font: 14px Times New Roman; \\ padding: 0px; \\ \\QTabBar::scroller \\ width: 25; \\ border: 0; \\ padding: 0px; \\ \\QTabBar QToolButton::right-arrow \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/rightbtn.png); \\ \\QTabBar QToolButton::right-arrow:hover \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/hoverrightbtn.png); \\ \\QTabBar QToolButton::right-arrow:disabled \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/grayrightbtn.png); \\ \\QTabBar QToolButton::left-arrow \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/leftbtn.png); \\ \\QTabBar QToolButton::left-arrow:hover \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/hoverleftbtn.png); \\ \\QTabBar QToolButton::left-arrow:disabled \\ background-color: rgb(132, 171, 208); \\ border-width: 0; \\ background-image: url(:/images/tab/grayleftbtn.png); \\ \\QTabBar::tab:first:selected \\ margin-left: 30; \\ margin-right: 0; \\ color: white; \\ border-image: url(:/images/tab/sel3.png); \\ \\QTabBar::tab:first:!selected \\ color: black; \\ margin-left: 30; \\ margin-right: 0; \\ border-image: url(:/images/tab/normal3.png); \\ \\QTabBar::tab:first:hover:!selected \\ color: black; \\ margin-left: 30; \\ margin-right: 0; \\ border-image: url(:/images/tab/hover3.png); \\ \\QTabBar::tab:middle:selected \\ margin-top: 0; \\ margin-left: -15; \\ margin-right: 8; \\ color: white; \\ border-image: url(:/images/tab/sel3.png); \\ \\QTabBar::tab:middle:!selected \\ color: black; \\ margin-top: 0; \\ margin-left: -15; \\ margin-right: 8; \\ border-image: url(:/images/tab/normal3.png); \\ \\QTabBar::tab:middle:hover:!selected \\ color: black; \\ margin-top: 0; \\ margin-left: -15; \\ margin-right: 8; \\ border-image: url(:/images/tab/hover3.png); \\ \\QTabBar::tab:last:selected \\ margin-top: 0px; \\ margin-left: 0; \\ margin-right: 0; \\ color: white; \\ border-image: url(); \\ \\QTabBar::tab:last:!selected \\ color: black; \\ margin-top: 0; \\ margin-left: 0; \\ margin-right: 0; \\ border-image: url(); \\ \\QTabBar::tab:last:hover:!selected \\ color: black; \\ margin-top: 0; \\ margin-left: 0; \\ margin-right: 0; \\ border-image: url(); \\ \\QTabBar::tab:only-one \\ margin: 0; \\); 在上述代码中，QTabWidget 的外观通过设置边框、背景颜色和字体样式等属性进行了详细的定义。例如，border-color 设置了边框的颜色，而 background-color 则定义了背景的颜色。通过使用 border-image，可以为选中的标签提供更具视觉吸引力的效果。 二、设置 QTabWidget 的 TabBar 样式 1为了进一步自定义 QTabWidget 的 TabBar 样式，可以使用以下代码： QString tabBarStyle = QTabBar::tab \\ min-width: 100px; \\ color: white; \\ border: 2px solid; \\ border-top-left-radius: 10px; \\ border-top-right-radius: 10px; \\ padding: 5px; \\ \\QTabBar::tab:!selected \\ margin-top: 5px; \\ \\QTabBar::tab:selected \\ color: blue; \\;m_TabWidget-setStyleSheet(tabBarStyle); 在这个样式中，min-width 确保每个标签的最小宽度为 100 像素，提供了足够的空间来显示标签文本。border 属性定义了标签的边框样式，而 border-top-left-radius 和 border-top-right-radius 则为标签的顶部角添加了圆角效果，使其看起来更加柔和。选中的标签颜色设置为蓝色，增强了用户的视觉体验。 三、设置 QTabWidget 的 TabBar 样式 2 另一种样式设置的方式如下： QTabWidget::pane \\ border: none; \\ \\QTabWidget::tab-bar \\ alignment: left; \\ \\QTabBar::tab \\ background: transparent; \\ color: white; \\ min-width: 30ex; \\ min-height: 10ex; \\ \\QTabBar::tab:hover \\ background: rgb(255, 255, 255, 100); \\ \\QTabBar::tab:selected \\ border-color: white; \\ background: white; \\ color: green; \\ 在这个样式中，QTabWidget::pane 的边框被设置为无，以便使标签的背景更加干净。QTabBar::tab 的背景设置为透明，确保标签与背景融为一体。min-width 和 min-height 确保标签的尺寸适中，便于用户点击。鼠标悬停时，标签的背景颜色变为半透明的白色，提供了视觉反馈。选中的标签则显示为白色背景和绿色文本，进一步增强了可读性和美观性。 参考链接 CSDN 讨论区 CSDN 博客","categories":["2.语言","Qt","样式表"]},{"title":"表格Qtxlsx","path":"/2025/03/02/2-语言-Qt-表格Qtxlsx/","content":"该文档介绍了在 ARM 上使用 Qtxlsx 的方法，主要包括两种方式： 1. 编译成动态库使用 下载 Qtxlsx 源码（GitHub地址）。 运行： qmakemakemake install 在 .pro 文件中添加： QT += xlsx 示例代码： #include xlsxdocument.hint main() QXlsx::Document xlsx; xlsx.write(A1, Hello Qt!); xlsx.saveAs(Test.xlsx); return 0; 2. 直接使用源代码 在工程目录中新建 qtxlsx 目录，拷贝 QtXlsxWriter-master/src/xlsx 下的所有文件，并删除 doc 文件夹和 xlsx.pro 文件。 在 .pro 文件中添加： include(qtxlsx/qtxlsx.pri) 直接使用源码时，如果不使用 qmake，需手动定义： XLSX_NO_LIB 如果编译报错，需要修改 qzipwriter_p.h 和 qzipreader.h 头文件（根据交叉编译环境调整）。 这两种方法均可在 ARM 设备上使用 Qtxlsx 进行 Excel 文件的处理。如果你有具体的问题或编译遇到问题，可以提供详细的错误信息，我可以帮助你分析解决。","categories":["2.语言","Qt"]},{"title":"PyQt","path":"/2025/03/02/2-语言-Qt-PyQt/","content":"PyQt5 工具安装1. 使用 pip 工具安装 PyQt5首先，打开命令提示符（cmd），输入以下命令来安装 PyQt5： pip install PyQt5 这个命令会从 Python 的包管理系统中下载并安装 PyQt5 库，确保你有稳定的网络连接。 2. 安装 Qt Designer 图形界面开发工具接下来，安装 Qt Designer，这是一个用于创建图形用户界面的工具。继续在命令提示符中执行： pip install PyQt5-tools 安装完成后，Qt Designer 的文件将被放置在以下路径： C:\\Users\\用户\\AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages 3. 环境变量配置为了能够在命令行中直接启动 Qt Designer，需要将其安装目录下的 qt/bin 路径添加到系统环境变量 PATH 中。具体步骤如下： 找到 C:\\Users\\用户\\AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages\\PyQt5_tools\\qt\\bin 目录。 右键点击“此电脑”或“计算机”，选择“属性”。 点击“高级系统设置”，然后选择“环境变量”。 在“系统变量”中找到 Path，选择后点击“编辑”。 在编辑窗口中，点击“新建”，然后粘贴上面提到的路径。 完成后，你可以在命令提示符中输入 designer 来启动 Qt Designer。 如果启动失败，可以尝试将 pyqt5_tools 目录下的 qt/plugins/platforms 文件夹复制到与 qt/bin/designer.exe 文件同级的目录中，这通常可以解决启动问题。 4. IDE 配置我目前使用的是 Visual Studio Code（VSCode），为了更好地集成 PyQt5，建议安装插件 PYQT Integration。安装完成后，按照以下步骤配置： 打开 VSCode，点击左下角的设置图标，选择“首选项”。 在搜索框中输入 pyqt，找到最后一项，填写 Qt Designer 的路径。 这样，系统会自动配置 pyuic 工具，pyuic 用于将 Qt Designer 创建的 .ui 文件转换为 .py 文件。 简单的登录例子1. 创建新的 UI在 Qt Designer 中创建一个新的 UI 文件，命名为 login.ui。 2. 设计界面在设计界面中，添加以下控件： TextLabel（文本标签）用于显示“用户名”和“密码”。 PushButton（按钮）用于“登录”和“退出”操作。 TextBrowser（文本浏览器）用于显示登录结果。 3. 修改控件属性双击每个控件以修改其名称和属性。例如： 将用户名标签的文本修改为“用户名”。 将密码标签的文本修改为“密码”。 将登录按钮的文本修改为“登录”。 将退出按钮的文本修改为“退出”。 4. 保存并编译 UI 文件保存设计好的文件为 login.ui。右键点击该文件，选择“Compile”生成对应的 login.py 文件。生成的代码大致如下： # -*- coding: utf-8 -*-# Form implementation generated from reading ui file login.ui# Created by: PyQt5 UI code generator 5.14.2# WARNING! All changes made in this file will be lost!from PyQt5 import QtCore, QtGui, QtWidgetsclass Ui_Form(object): def setupUi(self, Form): Form.setObjectName(Form) Form.resize(542, 311) Form.setMaximumSize(QtCore.QSize(699, 499)) self.user_lable = QtWidgets.QLabel(Form) self.user_lable.setGeometry(QtCore.QRect(40, 60, 55, 16)) self.user_lable.setObjectName(user_lable) self.pwd_lable = QtWidgets.QLabel(Form) self.pwd_lable.setGeometry(QtCore.QRect(40, 100, 55, 16)) self.pwd_lable.setObjectName(pwd_lable) self.user_lineEdit = QtWidgets.QLineEdit(Form) self.user_lineEdit.setGeometry(QtCore.QRect(130, 60, 113, 22)) self.user_lineEdit.setObjectName(user_lineEdit) self.pwd_lineEdit = QtWidgets.QLineEdit(Form) self.pwd_lineEdit.setGeometry(QtCore.QRect(130, 100, 113, 22)) self.pwd_lineEdit.setObjectName(pwd_lineEdit) self.login_Button = QtWidgets.QPushButton(Form) self.login_Button.setGeometry(QtCore.QRect(40, 180, 93, 28)) self.login_Button.setObjectName(login_Button) self.cancel_Button = QtWidgets.QPushButton(Form) self.cancel_Button.setGeometry(QtCore.QRect(170, 180, 93, 28)) self.cancel_Button.setObjectName(cancel_Button) self.user_textBrowser = QtWidgets.QTextBrowser(Form) self.user_textBrowser.setGeometry(QtCore.QRect(290, 61, 231, 131)) self.user_textBrowser.setObjectName(user_textBrowser) self.retranslateUi(Form) QtCore.QMetaObject.connectSlotsByName(Form) def retranslateUi(self, Form): _translate = QtCore.QCoreApplication.translate Form.setWindowTitle(_translate(Form, Form)) self.user_lable.setText(_translate(Form, 用户名)) self.pwd_lable.setText(_translate(Form, 密码)) self.login_Button.setText(_translate(Form, 登录)) self.cancel_Button.setText(_translate(Form, 退出)) 5. 实现逻辑代码在与 login.py 同一目录下创建一个名为 call_login.py 的文件，编写以下代码以实现登录逻辑： import sysfrom PyQt5.QtWidgets import QApplication, QMainWindowfrom login import Ui_Formclass MyMainForm(QMainWindow, Ui_Form): def __init__(self, parent=None): super(MyMainForm, self).__init__(parent) self.setupUi(self) # 连接登录按钮的点击信号到display函数 self.login_Button.clicked.connect(self.display) # 连接退出按钮的点击信号到close函数 self.cancel_Button.clicked.connect(self.close) def display(self): # 获取用户名和密码 username = self.user_lineEdit.text() password = self.pwd_lineEdit.text() # 在文本浏览器中显示登录信息 self.user_textBrowser.setText(登录成功! + 用户名是: + username + , 密码是: + password)if __name__ == __main__: app = QApplication(sys.argv) # 创建QApplication对象 myWin = MyMainForm() # 创建主窗口 myWin.show() # 显示窗口 sys.exit(app.exec_()) # 确保程序完整退出 在这个代码中，我们创建了一个主窗口类 MyMainForm，并在构造函数中设置了 UI。我们还连接了按钮的点击事件到相应的处理函数，确保用户输入的用户名和密码能够被正确处理并显示在文本浏览器中。","categories":["2.语言","Qt"]},{"title":"打包分发应用","path":"/2025/03/02/2-语言-Qt-打包分发应用/","content":"设置应用程序图标 创建 .ico 文件使用如 Photoshop 或在线工具（如 ConvertICO）将 PNGJPG 图像转换为 ICO 格式。ICO 文件通常包含多个尺寸（如 16x16, 32x32, 48x48, 256x256 像素），以适应不同环境的显示需求。 将 .ico 文件放置在源码目录将生成的 car.ico 文件放在与 .pro 文件同级的目录中，确保路径正确。 在 .pro 文件中添加图标配置打开项目的 .pro 文件，在 RC_ICONS 部分添加以下代码： RC_ICONS = car.ico # 替换为你的图标文件名 重新构建项目 重新运行 qmake 以应用更改。 重新编译程序，生成的可执行文件将显示新图标。 发布程序方法一：手动复制依赖文件 识别所需的 DLL 文件从 Qt 安装目录的 bin 文件夹（如 F:\\technology\\Qt5.9.7\\5.9.7\\mingw53_32\\bin）中复制必要的 DLL 文件，如 QtCore.dll, QtGui.dll, QtWidgets.dll 等。 将 DLL 文件放置在可执行文件目录确保所有 DLL 文件与 .exe 文件位于同一目录或正确的子目录中。 方法二：使用 windeployqt.exe 以 Release 模式编译确保项目已正确编译为 Release 版本。 复制可执行文件到新文件夹将生成的 cleanRobot.exe 复制到新文件夹（如 F:\\cleanRobot）。 运行 Qt 命令行工具打开 Qt 提供的命令行工具（如 Qt 5.9.7 for Desktop）。 执行部署命令在命令行中执行： cd F:\\cleanRobotwindeployqt cleanRobot.exe 优化依赖文件删除不必要的 DLL 文件，如 D3Dcompiler_47.dll，以减少发布包体积。 添加资源文件将所需的图片、配置文件等资源文件复制到同一文件夹。 打包程序使用 Inno Setup 制作安装包 下载并安装 Inno Setup从 Inno Setup 官方网站 下载并安装。 创建新脚本 打开 Inno Setup Compiler，选择 File → New 创建新脚本。 填写应用程序信息： 应用程序名称：红牌检测系统应用程序版本：2.5发布者：SHIOTC, Inc.网站：http://www.shiotc.com/ 指定输出目录和文件 设置输出目录（如 E:\\release）和主执行文件路径。 配置安装选项 选择开始菜单选项、许可协议、安装语言等。 生成脚本示例 ; Script generated by the Inno Setup Script Wizard.#define MyAppName 红牌检测系统#define MyAppVersion 2.5#define MyAppPublisher SHIOTC, Inc.#define MyAppURL http://www.shiotc.com/#define MyAppExeName redplate_qt.exe[Setup]AppId=ID21B4F6B-401E-4575-B6E1-612A9CA50D58AppName=#MyAppNameAppVersion=#MyAppVersionDefaultDirName=D:/redplate_detection_v2.5OutputDir=E:\\releaseSetupIconFile=ICON.icoCompression=lzma[Files]Source: E:\\release\\*; DestDir: app; Flags: ignoreversion recursesubdirs[Icons]Name: group\\#MyAppName; Filename: app\\#MyAppExeName 编译脚本 点击 Build → Compile 生成安装包。","categories":["2.语言","Qt"]},{"title":"5.常见问题总结","path":"/2025/02/24/4-软件-3D打印-5-常见问题总结/","content":"3D 打印机问题总结平台上的蓝色纸有什么用处，用到什么程度需要更换？美纹纸，它的作用一是防止刮坏喷嘴，二让模型与平台粘接更稳。 由于打印材料的热胀冷缩效应，当打印大体积模型时，可能会发生翘边现象，建议打印前先贴上蓝色美纹纸，才开始打印。该纸可反复使用，直到破损或者明显粘不住模型为止。 大部分人都在用 PEI 喷涂的钢板作为底面。PEI 的特性是冷的时候不粘，热的时候具有一定的粘性。 新的 PEI 床和旧的自带的床。更换 PEI 后打印 PETG 就非常好用了。等床凉了以后轻轻一拿就可以从床上拿起来了，不像是原来那张床用铲子翘半天。 不过新床目前也是遇到了一些问题，就是打 PLA 没有原来粘了。所以用 PLA 打印第一层得时候需要压得更低一点，才能获得最佳得粘性。 哪些模型要加支撑？如何判断？ 红色位置是需要加支撑的位置，Cura 右侧可以设置支撑的相关参数 调平台这个步骤怎么确保距离调的 ok 呢？喷嘴距离平台距离太远或太近有什么区别？为什么模型打印过程中直接被拖走？ 首先在调节平台之前需要先保证 X 轴在丝杆上移动是水平的 喷嘴和平台的距离标准为一张 A4 纸的距离，如果不好判断，塞张纸在平台和喷嘴之间，以正常抽拉并附带阻力为标准； 在不会刮伤平台的前提下，调的越近模型粘的越牢固！ 还可以通过模型打印第一层的状态来判断距离是否调好，有以下三种情况： 1、正确的距离：扁平，无间隙，铺在平台上面很平整无毛刺,喷头与热床是最佳距离能保证打印出的耗材被紧压在热床上成平整的带状（扁皮状）。如图所示： 2、不正确的距离：细圆的，粘上去时铺的不均匀，有空隙和翘起，说明距离太远,耗材是靠重力作用垂到热床，形成圆润的条状，其黏附效果不佳，模型容易移动，打印效果非常不理想。如图所示： 3、不正确的距离：出丝时，压在平台上会出现中间薄两边有不规则突起（有毛刺）的，说明贴的太紧，或者可能造成无法出丝以及喷头移动时会刮带到之前打印的地方，相关形状如图所示： 以上情况均可以通过调节热床下方的弹簧来调整。 调节平台需要注意什么？而且每次打印前都需要检查平台吗？ 调节弹簧螺丝时，请注意按住下方的羊角螺母，不然在拧的过程中也会一起转动； 每次调完或检查平台操作后，都必须移动喷嘴在平台上走一圈，确保不会刮伤平台才能进行下一步操作； 虽然不需要每次在打印前调节平台，但需要以 1 天 1 次作为周期性检查，平台距离合适； 为什么预热后上料？为何感觉插到底了，下方喷嘴却不出丝？换料的时候需要注意哪些情况？ 上料时，如果喷头没有加热，耗材插到底也不会吐丝，客户就无法判断是否已正常上料，所以必须先预热，再上料！ 在上料时，插入进料口后一段距离感觉已经无法插入，但是喷头下方并没有出丝，因为在耗材在进入进料口后需要穿过挤出轮和压料轮中间后再进入下方喷嘴导料管，在上耗材的时候没有把耗材前段剪尖和捋直，导致耗材插入时没能直接进入下方导料口而被旁边阻挡，如图： 正确上料步骤：预热—剪尖并捋直耗材—下压螺丝—笔直插入耗材—出丝 每次打模型前都需要预热吗？提前预热的情况只有在进行换料前才需要提前预热，正常打印时，只需要选择打印的模型文件即可自动加热； 模型打印过程中停电了能否继续打印？如果停电了模型直接终止打印，下次开机无法延续打印（但可以通过测量已打印高度，仅将未打印的部分切片进行打印，再粘上，仅适合非精密零件模型） 那中途可以暂停再继续打吗？看机器是否有设计暂停打印功能 在打印时暂停喷嘴依旧处于加热状态，耗材因重力作用会下垂流出，影响模型外观； 中途耗材用完怎么办？ 首先模型在软件进行切片转换格式的时候就会显示所需打印的时间，耗材长度以及重量，那需要判断机器上余下的耗材能否支持本次打印完成，避免中途打印耗材用完； 若碰到耗材中途快用完，请在耗材还没进入进料口的时候及时的进行暂停，并迅速拔出剩余耗材，将新的耗材插入至喉管的深度即可 每次打完需要将耗材取出来做排空处理吗？不是，距离下次打印超过 72 小时，则需要排空处理； 喷头需要定期清理吗？需要！ 挤出头加热到指定温度后用最小号的内六角螺丝刀，压下进料弹簧，插入进料口，往下挤压，挤压的时候扳手插慢慢插到底时，来回挤压三次，扳手回抽不要过急或过长，插进去后小幅度的在里面挤压三次即可，再迅速拔出，空烧 1 分钟左右注意观察下方是否有东西流出，流完或没东西流出一分钟后请用配送的小捅针，从下方喷嘴插入，抽拉三次没东西流出即可；最后一步，请弄根新耗材，插入到底向下挤压出丝后猛的迅速拔出，尽量带出内壁附着物即可； 模型刚开始打印第一层就不出丝，怎么回事？如果这种情况发生在刚才有换过耗材的情况下，那需要确定耗材已上到底，并出丝；确保喷嘴是否顶到平台，导致无间隙空间吐丝； 打出来的模型很脆，外壁像网丝状，很脆，一捏就瘪了？此情况属于出丝量很小，需要检查以下几点： 拉料正常，料盘上的耗材没有打结等缠住现象； 耗材在进入导料管与喷嘴（加热管喉管）之前，要穿过一个 u 型轮和挤出电机齿轮中间，u 型轮压住耗材让齿轮把耗材往下挤送，u 型轮压住耗材的力量是由旁边的六角螺钉顶着弹簧的力度来决定的，螺丝扭紧弹簧弹性越大，u 型轮压料就越紧，反之越松， 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 齿轮本身带动耗材挤压也有许多因素，耗材从上往下经过齿轮的时候是否有在齿轮的中间，如果齿轮脱位，耗材在齿轮的牙边下去的，可能出现带不动耗材往下的情况而出丝不顺 模型打印时，突然在某一层高处整体向 X（左右）Y（前后）方向偏移？首先需要确定机器传动系统问题，再来排除软件参数和主板固件问题，排除方法如下： 首先需要判断的模型摆放在平台上时，偏移的方向是 x（横向）还是 y（纵向），然后需要检查对应的 xy 轴的传动系统是否正常，第一先检查皮带是否松动脱落；第二检查同步轮固定螺丝是否松动 ① 带松动加紧： 首先，如果是 X 轴皮带松动，必须拉紧至绷紧状态，切平行； ②同步轮松动：Y 轴传动系统同步轮和 X 轴同步轮都需要检查到； 排除完机器问题，建议看下软件参数是否存在问题 例如检查是否是电机运动速度过快或出现阻碍导致的丢步 以上两点排除完毕，需要对主板固件程序进行重新烧录来解决问题 打印模型过程中中间断了几层，但是上面打印还可以？为什么模型突然中途就不出丝，喷嘴一直在空走打印不出丝？这几种问题都属于前期能正常打，但是中途不出丝的情况，这种情况需要从以下几点判断： 挤出电机接线口处四针排线松动，导致电机挤出齿轮来回正反转，耗材送不下去； 打印不出丝时，可以从电机右侧方弹簧方向往里面看到齿轮转到情况，如果齿轮来回摆动不定，说明接线出有问题，将接线拔掉重新插入尝试即可； 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 耗材在料盘上缠住，导致进料不顺,检查料盘的耗材缠绕是否有拉扯住 喷嘴可能有残料堵塞,可以把喷头首先预热 230，一手按住进料口旁螺丝，一手快速挤压耗材（多送点丝），再迅速拔出，然后让喷嘴空烧一会儿，直到有黑色物质从喷嘴里流出，然后用钢丝从喷嘴端插入，抽拉，拔出，让里面剩余的耗材掉出，重复抽拉动作，直到喷嘴没料自然流出为止，最后上料，重新打印； 为什么打印模型在中途过程中，喷嘴周边缠着很多耗材，模型变成一团乱丝，不成形？这种情况分两种： 刚开始打印阶段，此情况一般是喷嘴和平台之间的距离过远，喷嘴出丝无法粘住平台，就会被喷嘴带走并一直出丝形成一坨； 打印过程中出丝不均匀，有断层现象，打印模型比实际高度低，超过一定间隙距离后出料正常是没附着下面的模型上面就会缠成一坨； 打印过程中喷嘴突然停止在打印模型上方不打印，并未回原点，怎么回事？ 切片问题,重新切片打印测试 内存卡松及读取问题 主板固件问题 为什么把模型保存在卡里是显示 ok，但插入机器后选择模型打印后不加热也没反应？为什么 SD 卡在电脑读取正常放入机器缺显示无卡？一般由于保存文件时的文件名上，切片完成后进行保存时文件名请使用英文字母或数字. 为什么 SD 卡在电脑读取正常放入机器缺显示无卡？这种问题首先要排除卡和卡槽是否正常配合，保证卡和卡槽读取正常，如果重新插入还是无法读取，可用身边的内存卡保存文件插入机器是否能正常读取 为什么选择模型打印，机器没任何反应？或者加热了很久但是不打印？这种情况可能喷嘴冷却风扇提前开启，导致实际温度和设置温度总有 1-2 度差距，导致无法打印，请选择停止打印并关掉风扇开关后，重新选择打印模型即可； 宽度 5mm 高度 6mm 的字体打得出来不,类似这种小模型需要修改哪些参数呢？小模型打印需要将速度和挤出量降低，模型可以打得更好看。比如打 5mm 左右的字体，可以采用 22 左右的速度配合 85 的挤出量来进行切片打印，温度采用 190 左右的即溶温度即可，这适合小模型打印哦； 为什么在打印模型时，某个位置会剧烈振动，机器声音很大？这种位置一般是模型实体部分的填充，特别是交窄的壁厚，填充为波浪形，打印速度很快的时候 xy 配合产生共振引起的 为什么在打印很大模型例如 190*190*180 和平台尺寸相近的模型时，喷头移动到某个方向极限值时，会有振动然后再改方向进行移动呢？打印前，喷嘴会在模型周围打一圈进行排空出料的操作，这样的话就实际增加了大模型的成型空间，导致直接碰到机箱，可以把此设置关掉即可 查看切片时是否有裙边设置 打印模型经常翘边问题怎么解决？PLA 与 ABS 通用原因： 喷嘴距离与平台太远，没能充分贴紧平台 模型与热床接触面积太小，导致附着力不够 解决办法：可增加 brim 或者 raft 垫子 ；打印 ABS 的话 Brim 效果更理想； 打印 ABS 时开了散热风扇。 解决办法：在打印是进入主界面的控制 – 温度 – 风扇速度 Bed 中由最高转速 255 改成 100 减少冷却效果，直接关闭风扇开关效果更理想； - 挤出头或热床温度不合适，挤出头温度不够可能导致挤出的材料流动性不够，无法完美的平铺在热床上，影响其粘滞力。热床温度过高也可能导致翘边，原因是材料受热流动性变大，不能稳固黏在热床上。 - 热床表面不干净。手的汗与油粘在胶带上，表面上看不见，但也导致表面打滑，影响黏附效果。这种情况在湿度大的南方比较常见。 ABS 材料很特殊因为它有一定的收缩率，打印较大的物体时，效果更佳明显，整体收缩导致底面翘起。最好能配合洞洞板。 显示屏下方显示 Err 报错，挤出头热床温度温度显示不正常？喷头上热敏电阻的接触不良或者损坏了 拆下热敏电阻，若是接触不良，则重新拔插接好；若是线的焊点脱落，用电烙铁焊好否则易损坏电阻；若是损坏，则更换新的热敏电阻。注：固定线时螺丝不宜拧过紧 这个黑色螺丝拧松，热敏电阻取出来，同时热敏电阻线也从主板上拔下来，用万用表测一下阻值，80-100K 正常 打完第一层，打印头在左边，要打上面一层的时候，打印头不是要回到右边的吗，回去的时候就会刮在之前打印的第一层上并留下一条线呢？那是距离平台过近，会刮到上一层打印的耗材 平台距离喷嘴近有利于粘住平台，不会翘边; 会轻微刮到上一层打印模型，但不影响模型成型过程，最多挂点料在喷嘴上挂着，然后在掉下来 模型平面上字体打出来效果不好怎么办？如果字写在模型上，此情况可以将模型竖起来打，层厚 0.1 能更为细腻的打出字体； 为什么从绘图软件里导出来的模型放在 cura 里显示不规整，弧面都是棱面组成的？在绘图软件里导出 stl 的时候会有二进制和 ASCⅡ，通常选择二进制并将角度和弦值设置默认最小值，但在 maya 等一些软件里，文件导出的时候 stl 格式是默认设置的，这是软件的特性，但是这个默认数值会随着文件的建模时的网格细腻程度增加，也就是说文件平滑原本是一倍的，现在加到三倍导出来的 STL 就会比一倍的细腻很多 调试机器时选择自动丝出来都不是直的，是弯曲的?如果出丝是弯曲的 挤出量有关；挤出量一般由温度以及进料口旁边的螺丝松紧度有关，需要检查进料口旁边的螺丝 温度原因，1.风扇吹的 2.温度可以适当加高到 200 度左右 温度总是上不去或者不稳定？ 挤出头的热敏感应件没固定好在铝块里，打印的时候易松，导致探温不准； 导风嘴冷却风扇的风是吹到喷嘴下方的模型，如果没有调好就会吹到 喷嘴，导致温度下降； 如果出现以下情况是怎么导致？ 挤出齿轮底部缠料，一般是由此部位温度过高引起耗材变软，送丝过程中导致齿轮下部耗材折断而缠住； 遇到此情况首先需检查电机前方的方形冷却风扇是否工作以及叶片是否完整，避免冷却不够而导致堵料； 请检查耗材是否长时间未密封保存而变脆，取一段从中间这段，若折后显白痕且有韧性即正常，若折后直接啪的应声而断即已变脆； X 轴架构在 Z 轴电机丝杆控制上下过程中，会导致一边高一边低，每次都需要重新调节平台高度呢？ x 轴本身没有平衡，在移动过程中反应更明显； 请解决 X 轴调平问题； 黄色 T 型螺母太紧，导致 T 型螺母与丝杆紧配受力不均匀，移动不顺畅； 将固定 T 型螺母上的螺丝不要拧紧，留半个螺纹的缝隙，给予缓冲，再将 x 轴调至平衡，移动 z 轴电机调试！ x 轴光杆太长，没有完全捅到底去，顶住丝杆，导致移动不顺 检查光杆插入深度； 将 Z 轴两边的两个光杆去掉，控制电机上升是否正常，排除光杆弯曲配合滑动轴承配合不顺问题（可以单独将光杆插入滑动轴承，上下移动是否顺滑） 更换光杆或者滑动轴承 以上问题都检查后就可能: 移动不顺畅的丝杆部分弯曲或者螺纹损伤，更换丝杆 在更新固件后，挤出电机齿轮检测出反转，无法正常下料 固件中电机引脚配置反了 拔出挤出电机后端电机线接口，按照现在正常 1234 线序，把其中‘一组’12 对调或者 34 对掉即可 如果模型摆放在软件里为中心点，但在实际打印过程中并不在平台中间；因为机器喷嘴回原点的时候并不在热床平台上方而是在外面，而 cura 软件的机器设置里原点就在平台某个角的正上方，为了补偿原点所在误差，需要将软件的平台设置扩大，才能让模型打印在正中间，如图操作更改即可： 加热后拔料感觉扯不出来，也无法下压了铝块融化处剩余耗材口径较大，加热后直接上拉耗材，易堵在口径较小的喉管处，并迅速冷却，以至堵塞喉管 预热达到温度后，一只手按住进料口旁边的螺丝，另一只手将耗材往下挤压，让前端耗材挤出一段距离后，再迅速拔出耗材即可避免堵塞喉管 选择自动回原点时，当喷头移动至限位开关的时候，电机一直不停的往前走，撞击限位开关并抖动，这是怎么回事？ 需要检查在部件回原点触碰到限位开关之前是否有东西挡住它前进才无法触碰到限位开关而不停止运动； - 可能是限位开关坏了导致的，检查方法是将每个轴的移动部件移至轴中部，选择自动回原点，在部件向原点限位开关移动的过程中，请按住限位开关，观察部件是否停止移动，如果没有停止，请马上切断电源，基本上可以确定限位开关问题 为什么 X 轴上的喷头在移动过程中，一顿一顿的，特别是在回原点的时候，移动时几乎在抖动很不顺畅？ 排除下电机线与电机的问题：拆卸底板：需要用万用表检查 x 轴四根电机线是否都是通路，如果正常就是电机本身问题； 可以断电后手动运动下挤出头，是否丝杆或滑块中的钢珠生锈导致运动不流畅 超出打印范围安装软件的时候初始设置选择错误机型导致的，重新设置机型即可 不粘床，找平 自动找平后，但有的时候打印出来的第一层还是和床粘的不紧密 Z Offset 设置也会影响粘不粘床。 其中白色部分为压力传感器（BLTouch），右边蓝色硅胶罩下面的为喷头 可以看到左边白色的压力传感器的高度和右边蓝色硅胶套下面的喷嘴是不在一个高度的。设置喷嘴和床之前的距离是以压力传感器的反馈为准的。但是压力传感器测到的距离是传感器本身到床的距离，并不是喷嘴到床的距离。所以压力传感器到喷嘴之间的高度差就是 Z Offset，需要通过调整它来设置合适的喷嘴高度。 手动调平 需要用到一张纸，一般打印用的 A4 即可。 然后在床的中点进行 Z Offset 调整，在四个角落（螺丝位置）手动调整床的高低。具体步骤如下： 中点 Z-Offset 调整 首先通过控制面板将喷嘴移动到床的中间的正上方，接下来将纸放喷嘴下方的床上，紧接着慢慢将 Z 轴的高度降低到 0（如果降不下去不要硬来），喷嘴可能会压住纸或者没碰到纸；尝试前后不停的移动纸张。 如果纸张能移动并且刚好有一点阻力就是合适的喷嘴高度不需要调节，通常而言不会那么顺利；如果如果喷嘴完全没碰到纸张，或者纸张移动完全没有任何阻力，可以尝试通过调整 Z-Offset ，一点点降低喷嘴高度。直到达到上述的移动纸张有一点点阻力的状态；如果纸张被压的很死无法动弹，则先将 Z 轴升高到 5mm 然后尝试调整 Z-Offset 升高喷嘴，然后再继续尝试慢慢降低 Z 轴到 0mm，反复调整直到移动纸张有一点点阻力的状态。 使用一张纸来手动找到喷头合适高度的方法。但是这个能移动但是有一点点阻力状态有点模糊，它并不是一个固定的点，是一段区间内都可以感觉到能移动但是有摩擦力。建议是选摩擦力稍微轻一点的力度的点，这样喷嘴高度较高，后面调整的时候不容易刮伤床上的底板。 四周螺丝调整 在中间确定了最基本的 Z 轴的高度之后则需要物理调整四周的螺丝了，调整四周的螺丝需要按照顺序一个一个的调整，并且需要多次调整和确认，具体步骤如下： 首先抬起 Z 轴让喷嘴距离床大概 5mm 的距离，再移动到任意一个距离调整螺母的正上方，将纸放在喷嘴正下方的床上，紧接着一点点尝试往下移动 Z 轴到 0mm，和上面一样如果降不下去不要硬来；接下来就和上面一样，尝试移动不停的前后移动纸张，如果处于能移动但是有摩擦力的状态则是合适的，如果完全没碰到纸张，在移动纸张的同时旋转下方的螺丝来物理调节这个角落的高度，直到纸张处于能移动但是有摩擦力的状态。最后将 Z 抬起到 5mm 左右，顺逆时针移动到下一个调节螺母的上方，重复以上步骤。 上面步骤是单个角落手动物理调整床高度的方法，完成四个点（上图的床只有四个螺丝，有几个螺丝就校准几个点）为一个循环。因为打印机的床是一个固体，所以当上下移动某一个角落的高度的时候另外三个角落的高低也是会受到影响的，尤其是相邻的两个角落。所以这里需要多个循环来拧螺丝调整各个角落的高度，直到四个角落的高度都合适的情况，即为纸张能移动但是有阻力的状态。 在拧玩螺丝校准完四个角落的高度后，需要再次通过 Z-Offset 校准中间喷嘴的高度。因为在调整四角的螺丝的时候可能会整体抬高或者降低了床的高度，所以中间的喷嘴高度需要再一次校准。重复上面中点 Z-Offset 校准即可。 如果固件自带自动找平还是比较简单的，选择自动找平等就好了。虽然手动找平完之后床基本上是处于可以用的状态了，但是便宜的桌面打印机的床它本身可能就是凹凸不平的，所以需要自动找平来弥补床本身的凹凸起伏的部分。如果没有自动找平的打印机就没有太好的办法避免这个了。只能通过稍微压低一点点喷嘴来做到尽量都粘到床。 测试调平是否成功 在做完上述的调整后就可以进行最终的调整了。这一步是通过打印一些模型来确认喷嘴的高度是否合适。 虽然用纸调整好了喷嘴的高度，但是纸有薄有厚，调整出来的喷嘴高度并不一定是最好的打印高度，所以最终还是需要通过打印来调整。 打印测试时尽量选择有颜色的材料，透明透明材料会看不清楚第一层有没有打好，在打印模型的时候，手需要在电源附近随时待命。在喷嘴高度设置错误或者床不平的时能及时停止打印机降低损失。 打印出来的模型主要是用来检查喷嘴的高度和床是否倾斜的，四周的圆柱和绕场一周的线条用来检查床的倾斜度。 外围线条如果高低不平均，薄的那边就是较高的地方，厚的那边则是较低的地方。四角的圆柱则可以和上述的 Raise 3D 的示意图来比较确认喷头的高度是否合适。如果不合适可能需要重新手动找平。中间的圆形是确认喷嘴高度用的。同样通过对比来观察高度是否合适，如果床并没有很严重的倾斜，则只需要调整 Z-Offset 来移动喷嘴。然后重新打印确认。如果确认床有倾斜，就要重新走一遍手动找平的流程的了，然后重新打印确认。 当然找平也不是一定完美的。但是有自动找平后，整个过程还是比较简单的。但是也有无论怎么调整，都觉得床有倾斜或者高度不对的时候。这里就要分两种情况讨论了。如果能正常打印不想折腾了就选一个能调整到的最好的状态直接用吧。如果严重到了无法打印的程度，则需要检查打印的装配是不是有问题了。 过度挤出 打印出来的东西都有奇怪的纹理。而且质量也参差不齐。 检查之后是 klipper 配置里面的挤出机的「roration_distance」配错了。导致挤出机往外挤的时候给了远比正常情况多的料，进而溢出到边缘产生了神奇的纹理。 Klipper 配置里面的挤出机转一圈挤多少料这些东西都需要自己配置。所以配置挤出参数时是需要校准的，当给指令让他挤 100mm 的材料的时候，他应该就挤出来 100mm 左右的材料。没有校准所以导致了非常严重的过度挤出，配置正确后打印的东西表面的问题就漂亮多了。 正常挤出打印的零件的表面质感 材料与环境湿度由于 FDM 3D 打印件一般都需要将材料加热到 200 摄氏度或以上的温度才能打印，所以当材料通过热端的时候，其中的水蒸气会蒸发出来，造成喷嘴里面的材料有间隙，这些现象还会造成打印件在物理特性上的改变： 水汽膨胀造成挤出原料不均匀导致的表面粗糙 水汽膨胀造成材料之间有很多空隙导致的强度下降 水汽膨胀喷嘴中黏在一块的材料有缝隙，导致拉丝。 材料均需要密封干燥保存！买干燥盒 主要成分简称 推荐打印喷嘴温度 推荐打印床温度 特点 PLA 190˚C – 230˚C 25˚C-60˚C 易受潮 TPU 200˚C – 210˚C 50˚C 易拉丝 PETG 230˚C – 240˚C 70˚C – 80˚C ABS 245˚C – 265˚C 90˚C – 100˚C 有毒 ASA 240˚C – 260˚C 75˚C – 95˚C PC 250˚C – 270˚C 90˚C – 105˚C PA6 250˚C – 270˚C 25˚C – 50˚C PA6-CF 280˚C – 300˚C 25˚C – 50˚C","categories":["4.软件","3D打印"]},{"title":"PCR设备设计的基本参数","path":"/2025/02/24/4-软件-PCR-PCR设备设计的基本参数/","content":"项目： 反应类型：定性定量 溶解曲线 反应体系：20ul 单位：copiesml IUml（可选输入） 温度信息（温度范围，时间范围） 升降温速率可控 降落 PCR（可选） 程序组，程序步骤 通道实验基本参数 通道分析类型：定性定量 通道基线起点终点：6、12 基线优化：自动优化不优化 阈值：自动阈值、手动阈值 数字滤波：不滤波、轻度滤波、重度滤波 每个通道的基线取值方式不同 定量检测范围：单位 UIml，检测上限和检测下限 检测规则 阴阳性判断 溶解曲线 连续升温方式和步骤升温方式 高点过冲温度范围监控，低点过冲温度范围监控 最小界定温度和最大界定温度 噪声阈值（峰高阈值，用于排除噪声和非特异性杂峰） 光强边缘效应、温控边缘效应 溶解曲线的 Tm 值和 Rm 溶解曲线 连续升温方式和步骤升温方式 最小界定温度和最大界定温度 噪声阈值（峰高阈值，用于 常用通道波长和染料","categories":["4.软件","PCR"]},{"title":"QChart绘图","path":"/2025/02/24/2-语言-Qt-绘图-QChart绘图/","content":"QChartViewQChartQLineSeries在 Qt Charts 框架中，QChart、QLineSeries 和 QChartView 是构建和展示图表的三个核心组件。它们各自承担着不同的角色，并通过紧密的协作来实现图表的创建和显示。以下是对这三个组件的详细说明，以及它们之间的关系。 1. QChart 含义: QChart 是一个图表容器，负责管理图表中的数据系列、坐标轴、图例等布局元素。它是图表的核心，处理整体的绘制和呈现逻辑。 用法: 创建一个 QChart 实例后，可以通过 addSeries() 方法将数据系列（如 QLineSeries）添加到图表中。 通过 setTitle() 方法设置图表的标题，使用 createDefaultAxes() 方法自动生成坐标轴。 QChart 支持多种类型的数据系列，包括线形图、柱状图等，允许用户创建复杂的多轴图表。例如，您可以同时显示多个 QLineSeries，并为每个系列设置不同的颜色和样式，以便于区分。 2. QLineSeries 含义: QLineSeries 是一种特定类型的数据系列，用于在图表中表示线形图。它由一系列的点构成，这些点通过线段连接，形成一条连续的曲线。 用法: 创建一个 QLineSeries 实例后，可以使用 append(x, y) 方法向其中添加数据点。例如，series-append(0, 6) 表示在坐标 (0, 6) 处添加一个点。 通过设置线条的样式、颜色和宽度等属性，用户可以自定义线形图的外观。比如，您可以使用 setPen() 方法来改变线条的颜色和粗细，使得图表更加美观和易于理解。 3. QChartView 含义: QChartView 是 QWidget 的子类，专门用于显示 QChart 实例。它为将图表集成到标准 Qt 用户界面提供了便利的方式。 用法: 创建一个 QChartView 实例，并通过 setChart() 方法将一个 QChart 对象设置给它。这样，QChartView 就可以显示该图表。 QChartView 可以像其他 QWidget 一样被放置在任何 Qt 布局中，例如使用 QVBoxLayout 或 QHBoxLayout。这使得图表能够与其他界面元素（如按钮、文本框等）无缝结合。 组件关系概述这三个组件的关系可以总结为：QChartView 用于展示 QChart，而 QChart 则负责容纳和管理一个或多个数据系列（如 QLineSeries）。具体来说，您首先创建数据系列以存储数据，然后使用 QChart 来组织和处理这些系列，最后通过 QChartView 在用户界面中展示图表。 示例代码以下是一个简单的示例，展示了如何将这三个组件组合使用： QLineSeries *series = new QLineSeries();series-append(0, 6); // 在 (0, 6) 添加点series-append(1, 3); // 在 (1, 3) 添加点series-append(2, 5); // 在 (2, 5) 添加点// ... 可以继续添加更多数据点QChart *chart = new QChart();chart-addSeries(series); // 将数据系列添加到图表中chart-setTitle(示例线形图); // 设置图表标题chart-createDefaultAxes(); // 创建默认坐标轴QChartView *chartView = new QChartView(chart);chartView-setRenderHint(QPainter::Antialiasing); // 设置抗锯齿以提高渲染质量// 将 chartView 添加到布局中QVBoxLayout *layout = new QVBoxLayout(ui-chart_widget);layout-addWidget(chartView); // 将图表视图添加到指定的 QWidget 中 在这个示例中，您可以看到如何创建一个简单的线形图，并将其嵌入到 Qt 界面中。通过调整数据点和样式，您可以轻松地创建出符合需求的图表。 QChartView每个 QChartView 对象都绑定一个 QChart 对象。可以在构造函数中传入 QChart 对象的指针，也可以通过 setChart() 函数设置。 QChartView *chartView = new QChartView(chart); // 创建一个 QChartView 对象并将图表添加到其中QMainWindow window; // 创建主窗口window.setCentralWidget(chartView); // 将图表视图设置为主窗口的中心控件window.show(); // 显示主窗口 通过将 QChartView 设置为主窗口的中心控件，用户可以方便地查看图表。 主要功能： 图表显示：将 QChart 的内容呈现为图形，用户可以直观地理解数据。 用户交互：允许用户进行缩放、平移、点击等操作，增强用户体验。 抗锯齿渲染：提供平滑的图表显示，避免了图形的锯齿状边缘，使得图表更加美观。 集成到 Qt UI 系统：QChartView 可以作为 Qt UI 界面的一部分嵌入到应用程序中，方便与其他控件协同工作。 1. QChartView 的构造函数QChartView 的构造函数如下： QChartView::QChartView(QChart *chart, QWidget *parent = nullptr); **QChart *chart**：要显示的 QChart 对象，用户可以通过此参数指定要展示的数据图表。 **QWidget *parent**：父窗口部件，默认为空。如果设置为非空，QChartView 会嵌入到指定的父组件中，便于管理和布局。 2. QChartView 的主要方法和属性2.1 设置与获取图表对象 **void setChart(QChart *chart)**：设置要显示的 QChart 对象，允许动态更新图表内容。 **QChart* chart() const**：获取当前显示的 QChart 对象，便于后续操作。 例如： QChartView *chartView = new QChartView(); QChart *chart = new QChart(); chartView-setChart(chart); // 动态设置图表 2.2 渲染设置 **void setRenderHint(QPainter::RenderHint hint, bool on = true)**：设置 QPainter 的渲染提示，常用来启用抗锯齿以提升图表的平滑度。 chartView-setRenderHint(QPainter::Antialiasing); // 启用抗锯齿 2.3 动画效果 **void setAnimationOptions(QChart::AnimationOption options)**：为图表设置动画效果，使数据展示更为流畅，吸引用户的注意。 chartView-chart()-setAnimationOptions(QChart::AllAnimations); // 启用所有动画效果 2.4 用户交互设置 **void setRubberBand(QChartView::RubberBand rubberBand)**：设置用户交互模式，支持矩形区域缩放、水平或垂直缩放等，方便用户选择特定区域进行查看。 chartView-setRubberBand(QChartView::RectangleRubberBand); // 启用区域缩放 **void setDragMode(QGraphicsView::DragMode mode)**：设置拖动模式，允许用户通过鼠标拖动图表，便于查看不同部分的数据。 chartView-setDragMode(QGraphicsView::ScrollHandDrag); // 启用拖动 **void resetZoom()**：重置图表缩放到默认状态，方便用户快速恢复视图。 chartView-chart()-zoomReset(); // 重置缩放 3. 缩放与拖动功能QChartView 支持强大的缩放和平移功能，通过设置缩放方式和拖动模式，用户可以轻松地调整图表视图。 启用缩放：通过 RubberBand 允许用户选择图表区域进行缩放，提升数据分析的灵活性。 chartView-setRubberBand(QChartView::RectangleRubberBand); // 矩形缩放 拖动图表：通过 ScrollHandDrag 模式允许用户拖动图表视图，便于查看不同数据点。 chartView-setDragMode(QGraphicsView::ScrollHandDrag); // 启用手动拖动 与 RubberBand 相关的函数QChartView 的另一个功能是设置 RubberBand 类型。 RubberBands rubberBand() constvoid setRubberBand(const RubberBands rubberBand) RubberBand 类型有 4 种，含义如下： 默认效果 无橡皮圈效果setRubberBand(QChartView::NoRubberBand); 设置为无橡皮圈效果，则无法在绘图区拖出选定区域，也就不会进行缩放了。 矩形橡皮圈效果setRubberBand(QChartView::RectangleRubberBand); 可以在图表的绘图区拉出矩形橡皮圈： 放手后，橡皮圈部分将放大显示，填满两个绘图区： 水平橡皮圈效果setRubberBand(QChartView::HorizontalRubberBand); 可以在图表的绘图区拉出水平橡皮圈： 松手后，将所选矩形水平放大： 竖直橡皮圈效果setRubberBand(QChartView::VerticalRubberBand); 可以在图表的绘图区拉出竖直橡皮圈： 松手后，效果为： 4. 事件处理与交互由于 QChartView 继承自 QGraphicsView，它也支持鼠标和键盘事件的处理，允许开发者定制用户的交互行为。 4.1 鼠标事件你可以通过重载 mousePressEvent 方法处理用户的鼠标点击事件，例如处理用户点击某个数据点的操作。 void MyChartView::mousePressEvent(QMouseEvent *event) QPoint point = event-pos(); // 获取鼠标点击位置 // 自定义鼠标点击操作 QChartView::mousePressEvent(event); // 保持默认行为 4.2 键盘事件你可以通过重载 keyPressEvent 来处理键盘事件，例如为图表设置快捷键操作。 void MyChartView::keyPressEvent(QKeyEvent *event) if (event-key() == Qt::Key_R) chart()-zoomReset(); // 按 R 键重置缩放 else QChartView::keyPressEvent(event); 5. 实例代码以下是一个简单的折线图示例，演示如何使用 QChartView 在 Qt 应用程序中显示图表。 #include QtCharts/QChartView#include QtCharts/QLineSeries#include QtCharts/QChart#include QtWidgets/QApplication#include QtWidgets/QMainWindowQT_CHARTS_USE_NAMESPACEint main(int argc, char *argv[]) QApplication a(argc, argv); QLineSeries *series = new QLineSeries(); // 创建折线系列 series-append(0, 6); // 添加数据点 series-append(2, 4); series-append(3, 8); series-append(7, 4); series-append(10, 5); QChart *chart = new QChart(); // 创建图表 chart-addSeries(series); // 将数据系列添加到图表 chart-setTitle(Simple Line Chart Example); // 设置图表标题 chart-createDefaultAxes(); // 创建默认坐标轴 QChartView *chartView = new QChartView(chart); // 创建图表视图 chartView-setRenderHint(QPainter::Antialiasing); // 启用抗锯齿 QMainWindow window; // 创建主窗口 window.setCentralWidget(chartView); // 设置中心控件 window.resize(800, 600); // 设置窗口大小 window.show(); // 显示窗口 return a.exec(); // 运行应用程序 Qt Chart 模块对于 QChart，一个稍微能缓解卡顿的方案就是：series-setUseOpenGL(true); 在开启 openGl 之后，X 轴只能使用原生数据轴 QValueAxis，X 轴无法使用时间轴 QDateTimeAxis，采用时间轴的点，在开启 OpenGL 之后，曲线无法显示。 画直线使用 QLineSeries 来绘制直线是一种简单而有效的方法。以下是实现的代码示例： QLineSeries m_series; // 创建一个 QLineSeries 对象QPen green(Qt::red); // 创建一个红色的画笔green.setWidth(2); // 设置画笔的宽度为 2 像素m_series.setPen(green); // 将画笔应用到系列上m_series.append(m_x, m_y); // 向曲线添加数据点 (m_x, m_y) 在这个示例中，QLineSeries 用于存储一系列的点，并通过 QPen 设置线条的颜色和宽度。你可以通过调用 append 方法不断添加新的数据点，从而动态更新图表。 画弧线使用 QSplineSeries 可以绘制平滑的弧线。QSplineSeries 适合于需要平滑过渡的曲线，能够使得数据点之间的连接更加自然。 数字量坐标为了在图表中显示数字坐标，可以使用 QValueAxis。以下是设置数字坐标的代码示例： QValueAxis *axisX = new QValueAxis // 创建一个新的 QValueAxis 对象axisX-setRange(0, 2000); // 设置坐标范围为 0 到 2000axisX-setLabelFormat(%g); // 设置坐标标签的格式axisX-setTitleText(Samples); // 设置标轴的标题为 SamplesaxisX-setTickCount(5); // 设置坐标轴上显示的刻度数量为 5 在这个示例中，setRange 方法定义了坐标轴的显示范围，而 setTickCount 方法则了刻度的数量，使得图表更加清晰易读。 时间日期坐标使用 QDateTimeAxis 可以在图表中显示时间和日期。以下是相关代码示例： QDateTimeAxis *axisX = new QDateTimeAxis; // 创建一个新的 QDateTimeAxis 对象axisX-setTickCount(10); // 设置刻度数量为 10axisX-setFormat(yyyy-MM-dd); // 设置日期格式为 月 年axisX-setTitleText(Date); // 设置坐标轴的标题为 Date//设置坐标轴的开始事件和结束事件QDateTime startTime = QDateTime::fromString(minValue,yyyy-MM-dd);QDateTime endTime = QDateTime::fromString(maxValue,yyyy-MM-dd);axisXDate-setRange(startTime, endTime);//绑定坐标轴到图标chart-addAxis(axisXDate, Qt::AlignBottom); // 将 X 轴添加到图表底部//绑定坐标轴到曲线series-attachAxis(axisXDate);//追加点位到曲线中去series-append(QPointF(QDateTime::fromString(curValueX,yyyy-MM-dd).toMSecsSinceEpoch(), curValueY)); 通过设置日期格式，用户可以直观地看到时间的变化，这对于时间序列数据的可视化尤为重要。 管理 QChart在 Qt 中，QChart 用于管理和显示图表。以下是如何创建和管理一个图表的示例： QChart *chart = new QChart(); // 创建一个新的 QChart 对象chart-addSeries(series); // 将数据系列添加到图表中chart-setTitle(Sunspots count (by Space Weather Prediction Center)); // 设置图表的标题chart-setAxisX(axisX, series); // 将 X 轴坐标添加到图表中 这里，addSeries 方法用于将数据系列添加到图表中，而 setTitle 方法则为图表设置了一个描述性的标题，帮助用户理解图表的内容。 更新更新图表数据有两种方式： 追加的方式更新：使用 m_series.append(m_x, m_y); 可以在现有数据系列中添加新的数据点。 整体刷新：使用 m_series-replace(m_buffer); 可以用新的数据集替换现有的数据。 这种灵活的更新方式使得图表能够实时反映数据的变化。 动态显示为了实现动态显示，可以使用以下代码： qreal dwidth = chart-plotArea().width() / (m_axis.tickCount() * 2); // 计算每次滚动的宽度qreal dx = 10 / (m_axis.tickCount() * 2); // 计算横坐标的偏移量m_x += dx; // 更新 x 坐标m_y = sin(m_x); // 计算新的 y 坐标m_series.append(m_x, m_y); // 添加新的数据点// 满屏之后滚动窗口if (m_x 10) chart-scroll(dwidth, 0); // 滚动图表 在这个示例中，图表会根据数据的变化动态更新，提供实时的可视化效果。 通过事件处理框选放大选中区域/// 鼠标右键菜单void WidgetPloter::mousePressEvent(QMouseEvent *event) // 检查鼠标按下的按钮是否为右键 if (event-button() == Qt::RightButton) // 在鼠标点击位置显示右键菜单 m_menu-exec(event-globalPos()); // 检查鼠标按下的按钮是否为左键 if (event-button() == Qt::LeftButton) // 记录鼠标按下的位置，作为框选的起点 origin = event-pos(); // 如果还没有创建橡皮筋框，则创建一个新的 if (!rubberBand) rubberBand = new QRubberBand(QRubberBand::Line, this); // 设置橡皮筋框的几何形状，初始大小为0 rubberBand-setGeometry(QRect(origin, QSize())); // 显示橡皮筋框 rubberBand-show(); // 这里可以设置橡皮筋框的类型为矩形，允许在XY方向上放大 // this-setRubberBand(QChartView::RectangleRubberBand);void WidgetPloter::mouseMoveEvent(QMouseEvent *event) // 如果橡皮筋框存在，则更新其几何形状 if (rubberBand) // 根据起始点和当前鼠标位置计算并设置橡皮筋框的大小 rubberBand-set(QRect(origin, event-pos()).normalized()); void WidgetPloter::mouseReleaseEvent(QMouseEvent *event) // 当鼠标释放时，检查橡皮筋框是否存在 if (rubberBand) // 隐藏橡皮筋框 rubberBand-hide(); // 使用选定的矩形区域进行缩放 m_plot-zoomIn(QRect(origin, event-pos()).normalized()); // 下面的代码是一些可选的缩放操作示例 // m_plot-scroll10, 5); // 整体平移，参数分别为Δx和Δy // m_plot-zoom(0.9); // 整体缩放，参数为放缩系数，1代表缩小，1代表放大 // m_plot-zoomReset(); // 撤销所有缩放操作 // 下面的代码可以设置X轴和Y轴的范围 // m_axisX-setRange(origin.x() - this-pos().x(), event-pos().x() - this-pos().x()); // m_axisY-setRange(event-pos().y() - this-pos().y(), origin.y() - this-pos().y()); // 调试信息，输出当前矩形和鼠标位置 // qDebug() this-rect().x() this-rect().y() this-rect().width() this-rect().height() origin.x() origin.y() event-pos().x() event-pos().y(); 代码说明 鼠标事件处理： mousePressEvent：处理鼠标按下事件，右键显示菜单，左键开始框选。 mouseMoveEvent：实时更新橡皮筋框的大小，以便用户可以看到当前选中的区域。 mouseReleaseEvent：当用户释放鼠标时，隐藏橡皮筋框，并根据选定的区域进行缩放。 橡皮筋框： 使用 QRubberBand 类创建一个可视化的框选效果，用户可以通过拖动鼠标选择区域。 缩放功能： zoomIn 方法根据用户选定的矩形区域进行缩放，提供更直观的数据查看方式。 调试信息： 使用 qDebug() 输出当前状态，便于开发者调试和理解程序运行情况。 通过这些细节，读者可以更好地理解每个部分的功能和作用，即使对代码不够熟悉，也能感受到整体的逻辑和设计思路。","categories":["2.语言","Qt","绘图"]},{"title":"联网获取数据并通过Json和正则进行解析","path":"/2025/02/24/2-语言-Qt-联网获取数据并通过Json和正则进行解析/","content":"#ifndef NETDRIVER_H#define NETDRIVER_H#include QObject#include QApplication#include QNetworkAccessManager#include QNetworkReply#include QRegularExpression#include QRegularExpressionMatch#include QJsonDocument#include QJsonObject#include QThread#include blackboard.h// 定义消息类型的常量#define EMPTY_MSG 1 // 空消息#define NETVALUE_MSG 2 // 网络值消息#define HISTORY_MSG 3 // 历史消息#define STBY_MSG 4 // 待机消息class NetDriver : public QObject Q_OBJECTpublic: NetDriver(); // 构造函数 // 单例模式获取实例 static NetDriver* getIns() static NetDriver *ins = nullptr; // 静态指针，确保只有一个实例 if(ins == nullptr) ins = new NetDriver(); // 如果实例不存在，则创建一个新的实例 return ins; // 返回实例 // 更新网络值和历史数据的函数 void updateNetValue(MSG_CONTENT *); void updateHistory(MSG_CONTENT *); QNetworkAccessManager m_AccessManager; // 网络访问管理器 QNetworkRequest m_Request; // 网络请求对象 QString todaySub; // 今日数据的URL模板 QString historySub; // 历史数据的URL模板 int retMsgType = 0; // 返回消息类型 MSG_CONTENT *msg_content_p; // 指向消息内容的指针private slots: void analysisGet(QNetworkReply *reply); // 处理网络返回数据的槽函数;#endif // NETDRIVER_H #include netdriver.h// 构造函数实现NetDriver::NetDriver() // 设置用户代理字符串，模拟浏览器请求 QString agent = xxxxxxxxxxxxxxxx; // 设置授权头部，使用Bearer Token进行身份验证 QByteArray authHeaderData = xxxxxxxxx; // 设置Cookie头部，模拟用户会话 QByteArray cookieHeaderData = xxxxxxxxxx; // 设置请求头部 m_Request.setRawHeader(QByteArray(User-Agent), agent.toUtf8()); m_Request.setRawHeader(QByteArray(Authorization), authHeaderData); m_Request.setRawHeader(QByteArray(Cookie), cookieHeaderData); // 初始化今日数据和历史数据的URL模板 todaySub = https://xxxxxxxxxx/%1.js; // %1将被替换为基金代码 historySub = http://xxxxxxxxx/%1.js; // %1将被替换为基金代码 // 连接网络请求完成信号到数据分析槽函数 connect(m_AccessManager, QNetworkAccessManager::finished, this, NetDriver::analysisGet);// 更新网络值的函数实现void NetDriver::updateNetValue(MSG_CONTENT* msg_code) msg_content_p = msg_code; // 保存消息内容指针 retMsgType = NETVALUE_MSG; // 设置返回消息类型为网络值消息 QString urlStr = todaySub.arg(msg_code-code); // 根据基金代码生成请求URL m_Request.setUrl(urlStr); // 设置请求的URL m_AccessManager.get(m_Request); // 发送GET请求 int timeoutIndex = 0; // 超时计数器 while(retMsgType != STBY_MSG timeoutIndex 100) // 如果未收到应答且未超时 QApplication::processEvents(); // 处理事件，保持应用响应 QThread::msleep(50); // 暂停50毫秒 timeoutIndex++; // 增加计数器 // 如果超时，设置错误信息 if(timeoutIndex = 100) msg_code-name = 网络超时，请稍后重试！; // 提示用户网络超时 /** * @brief NetDriver::updateHistory * @param code * 阻塞函数，调用后会等待网络返回数据 */void NetDriver::updateHistory(MSG_CONTENT* msg_code) msg_content_p = msg_code; // 保存消息内容指针 retMsgType = HISTORY_MSG; // 设置返回消息类型为历史消息 QString urlStr = historySub.arg(msg_code-code); // 根据基金代码生成请求URL m_Request.setUrl(urlStr); // 设置请求的URL m_AccessManager.get(m_Request); // 发送GET请求 int timeoutIndex = 0; // 超时计数器 while(retMsgType != STBY_MSG timeoutIndex 100) // 如果未收到应答且未超时 QApplication::processEvents(); // 处理事件，保持应用响应 QThread::msleep(50); // 暂停50毫秒 timeoutIndex++; // 增加计数器 // 如果超时，设置错误信息 if(timeoutIndex = 100) msg_code-name = 网络超时，请稍后重试！; // 提示用户网络超时 /** * @brief NetDriver::analysisGet * @param reply * 分析网络返回的数据，并解析成需要保存的格式 */void NetDriver::analysisGet(QNetworkReply *reply) // 检查网络请求是否出错 if (reply-error() != QNetworkReply::NoError) reply-deleteLater(); // 删除reply对象，释放资源 return; // 退出函数 // 根据返回的消息类型进行不同的处理 switch (retMsgType) case NETVALUE_MSG: // 处理网络值消息 QString data = QString::fromUtf8(reply-readAll()); // 读取返回的数据 QRegularExpression re(jsonpgz\\\\((.*)\\\\)); // 正则表达式匹配JSON数据 QRegularExpressionMatch match = re.match(data); // 执行匹配 if (match.hasMatch()) // 如果匹配成功 QString jsonStr = match.captured(1); // 获取JSON字符串 QJsonDocument jsonDoc = QJsonDocument::fromJson(jsonStr.toUtf8()); // 解析JSON文档 QJsonObject jsonObj = jsonDoc.object(); // 获取JSON对象 // 提取所需数据并保存到msg_content_p中 msg_content_p-code = jsonObj[fundcode].toString(); // 基金代码 msg_content_p-name = jsonObj[name].toString(); // 基金名称 msg_content_p-lastNetValue = jsonObj[gsz].toString(); // 最新净值 msg_content_p-lastPercent = jsonObj[gszzl].toString() + %; // 最新涨幅 msg_content_p-lastTime = jsonObj[gztime].toString(); // 更新时间 break; case HISTORY_MSG: // 处理历史消息 QByteArray data = reply-readAll(); // 读取返回的数据 // 正则表达式匹配历史数据 QRegularExpression re(\\\\\\x\\:(\\\\d+),\\y\\:([\\\\d.]+),\\equityReturn\\:([\\\\-\\\\d.]+),\\unitMoney\\:\\([^\\]*)\\\\\\); QRegularExpressionMatchIterator match_it = re.globalMatch(data); // 获取所有匹配项 // 清空历史数据 msg_content_p-hisDate.clear(); msg_content_p-hisNetValue.clear(); msg_content_p-hisPercent.clear(); // 遍历所有匹配项并提取数据 while (match_it.hasNext()) QRegularExpressionMatch match = match_it.next(); // 获取下一个匹配项 // 将匹配的数据转换并保存 msg_content_p-hisDate.append(QDateTime::fromMSecsSinceEpoch(match.captured(1).toULongLong()).date().toString(yyyy-MM-dd)); // 日期 msg_content_p-hisNetValue.append(match.captured(2)); // 净值 msg_content_p-hisPercent.append(match.captured(3)); // 涨幅 break; retMsgType = STBY_MSG; // 重置消息类型为待机状态 reply-deleteLater(); // 删除reply对象，释放资源","categories":["2.语言","Qt"]},{"title":"链表和数组的数据存取方式","path":"/2025/02/24/2-语言-结构算法-链表和数组的数据存取方式/","content":"BlackBoardArray 类实现了一个简单的数组结构来存储数据，而 BlackBoardLinkList 类则使用链表结构来存储数据。每个类都实现了 write、read 和 size 方法，以便在多线程环境中安全地读写数据。通过使用 QMutex 和 QMutexLocker，确保了对共享数据的访问是线程安全的。 #ifndef BLACKBOARD_H#define BLACKBOARD_H#include QObject#include QByteArray#include QMutex#include QMutexLocker#include DriverDefines.h// 定义一个结构体，表示黑板节点struct BlackBoardNode QByteArray bytedata; // 存储数据的字节数组 BlackBoardNode *next; // 指向下一个节点的指针 // 构造函数，初始化节点数据和指针 BlackBoardNode(QByteArray insertNode) : bytedata(insertNode), next(nullptr) ;// 黑板基类，提供基本的读写接口class BlackBoard public: BlackBoard() return; // 默认构造函数 // 纯虚函数，子类必须实现 virtual void write(QByteArray) = 0; // 写入数据 virtual QByteArray read() = 0; // 读取数据 int size() // 获取当前数据大小 QMutexLocker locker(mutex); // 确保线程安全 return sizeCount; // 返回当前数据大小 protected: QMutex mutex; // 互斥锁，确保线程安全 int sizeCount = 0; // 记录当前数据数量;// 黑板数组类，继承自黑板基类class BlackBoardArray : public BlackBoard private:\tQVectorQByteArray dataArray;public: void write(QByteArray); // 写入数据 QByteArray read(); // 读取数据;// 黑板链表类，继承自黑板基类class BlackBoardLinkList : public BlackBoard private: BlackBoardNode *head = nullptr; // 链表头指针 BlackBoardNode *tail = nullptr; // 链表尾指针public: void write(QByteArray); // 写入数据 QByteArray read(); // 读取数据;#endif // BLACKBOARD_H #include blackboard.h// 在黑板数组中写入数据void BlackBoardArray::write(QByteArray insertNode) QMutexLocker locker(mutex); // 确保线程安全 // 这里可以实现一个动态数组，存储数据 dataArray.append(insertNode); // 将数据添加到数组中 sizeCount++; // 更新数据大小计数// 从黑板数组中读取数据QByteArray BlackBoardArray::read() QMutexLocker locker(mutex); // 确保线程安全 if (dataArray.isEmpty()) return QByteArray(); // 如果数组为空，返回空字节数组 QByteArray data = dataArray.takeFirst(); // 取出第一个元素 sizeCount--; // 更新数据大小计数 return data; // 返回读取的数据// 在黑板链表中写入数据void BlackBoardLinkList::write(QByteArray insertNode) QMutexLocker locker(mutex); // 确保线程安全 BlackBoardNode *newNode = new BlackBoardNode(insertNode); // 创建新节点 if (!head) // 如果链表为空 head = tail = newNode; // 新节点既是头也是尾 else tail-next = newNode; // 将新节点链接到链表尾部 tail = newNode; // 更新尾指针 sizeCount++; // 更新数据大小计数// 从黑板链表中读取数据QByteArray BlackBoardLinkList::read() QMutexLocker locker(mutex); // 确保线程安全 QByteArray getData; if (!head) // 如果链表为空 return getData; // 返回空字节数组 getData = head-bytedata; // 获取头节点的数据 BlackBoardNode *tmp = head; // 临时保存头节点 head = head-next; // 更新头指针 if (!head) // 如果链表变为空 tail = nullptr; // 更新尾指针 delete tmp; // 删除旧的头节点 sizeCount--; // 更新数据大小计数 return getData; // 返回读取的数据","categories":["2.语言","结构算法"]},{"title":"如何打造属于自己的3D打印机上位机？这篇文章带你了解一下！-腾讯云开发者社区-腾讯云","path":"/2025/02/24/4-软件-3D打印-如何打造属于自己的3D打印机上位机？这篇文章带你了解一下！-腾讯云开发者社区-腾讯云/","content":"建议不是本行又感兴趣的小伙伴们先看下面两篇了解一下Marlin: 开源Marlin2.x源代码架构学习笔记 3D打印机marlin固件框架与GCode命令总结 YouTube上的老外通俗易懂的方式讲解Marlin2.0然后再看下面的文章。 1、摘要说到 RepRaptor，我们就有必要来了解下RepRap 3D打印机。RepRap是人类历史上第一部可以自我复制型的机器。RepRap是一部可以生成塑料实物的免费桌面型 3D 打印机。由于 RepRap 很多部件都是由塑料制成了，并且 RepRap 都可以进行打印，所以 RepRap 可以自我复制。也就是说，任何人都可以花一些时间收集够材料进行制作。这也意味着，如果您已经有一台 RepRap 了，您可以在打印很多有用的物件的同时，为朋友再打印出另一部 RepRap。RepRap 致力于自我复制型机器的制作，并无偿的提供给大家使用。我们用 3D 打印来实现这些，但如果您使用其它的技术也实现了自我复制并愿意无偿提供给大家使用。那么，这里也将非常欢迎您的加入。RepRap是第一款低成本 3D 打印机，并且 RepRap 还开创了开源 3D 打印机的革命。在手工制作类社区的所有成员中被广泛使用的一款 3D 打印机。 关键词：3D打印机；自我复制；RepRap；RepRaptor 2、RepRaptor简介RepRaptor是一个可用于支持GCode指令3D打印上位机，它是用QT5来编写的。之所以使用QT5来编写，这是因为开发者希望它能够任何硬件上运行。因此，RepRaptor也可以用于控制RepRap 来实现3D模型的打印。它的界面是这样的： 我们能够看到的是，它已经具备了3D打印机上位机的基本雏形。目前3D打印机的主流的架构主要是这样的： 因此，RepRaptor相当于充当了上位机这个部分的工作： 只可惜，这个版本仅仅发布到了RepRaptor v0.3.8以后就没有再进行继续更新了。 但是没关系，我们可以基于这个雏形，做出属于我们自己的3D打印机上位机，然后我们就可以买一台支持联机打印的3D打印机，愉快的进行模型打印了！ 3、RepRaptor源码架构导读在开发属于自己的3D打印机上位机之前，我们必须获得它的源码： git clone https://github.com/josefprusa/RepRapCalculator.git 然后使用QT Creator将其打开，接下来我们就可以看到下面的代码结构: 3.1、界面介绍在这里，我们可以看到这是一个基于QT Designer做UI界面,类似于MFC一样拖控件，然后再使用C++写逻辑。因此，我们能够看到它是由6个UI界面来完成的，分别是： (1) aboutwindow.ui 关于项目的介绍 (2)eepromwindow.ui 获取打印机EEPROM中的数据并展现到界面上来，此部分功能不全。 (3) errorwindow.ui 一些运行错误的提示窗口 (4)mainwindow.ui 主页面，用于控制打印机的常规操作、获取打印机反馈的信息，例如温度、速度： (5)sdwindow.ui 使用SD卡进行打印锁需要的设置和文件读取等功能，此部分功能不全。 (6)settingswindow.ui 一些参数的设置，此部分功能不全 3.2、核心代码架构导读 4、打造属于我们自己的3D打印机上位机4.1、成功打造属于我们自己的3D打印机上位机的前提当然，想要学会打造自己的打印机的前提，你得具备以下基础知识： 掌握QT软件开发(如果你会C#或者其它当然也没问题) 掌握3D打印机GCode指令协议 其它必要的知识，如设计模式、数据结构等。 4.2、核心交互逻辑的实现关于GCode的格式以及响应的通讯协议可以参考： https://marlinfw.org/meta/gcode/ 这上面列出了几乎所有Marlin支持的GCode协议指令。 从源码导读部分，我们最需要关心的是mainwindow.cpp、sender.cpp和parser.cpp这三个文件，因为它们是实现3D打印机上位机成功的基础，这里我们能够看到这三个线程之间的交集部分，也就是mainwindow.cpp里的这段代码： //Parser thread signal-slots and initparserWorker-moveToThread(parserThread);connect(parserThread, QThread::finished, parserWorker, QObject::deleteLater);connect(this, MainWindow::startedReadingEEPROM, parserWorker, Parser::setEEPROMReadingMode);connect(parserWorker, Parser::receivedTemperature, this, MainWindow::updateTemperature);connect(parserWorker, Parser::receivedSDFilesList, this, MainWindow::initSDprinting);connect(parserWorker, Parser::receivedEEPROMLine, this, MainWindow::EEPROMSettingReceived);connect(parserWorker, Parser::recievingEEPROMDone, this, MainWindow::openEEPROMeditor);connect(parserWorker, Parser::receivedError, this, MainWindow::receivedError);connect(parserWorker, Parser::receivedSDDone, this, MainWindow::receivedSDDone);connect(parserWorker, Parser::receivedSDUpdate, this, MainWindow::updateSDStatus);connect(parserWorker, Parser::receivedNotSDPrinting, this, MainWindow::receivedNotSDPrinting);parserThread-start();parserThread-setPriority(QThread::HighestPriority);//Sender thread signal-slots and initsenderWorker-moveToThread(senderThread);connect(senderThread, QThread::finished, senderWorker, QObject::deleteLater);connect(parserWorker, Parser::receivedOkNum, senderWorker, Sender::receivedOkNum);connect(parserWorker, Parser::receivedOkWait, senderWorker, Sender::receivedOkWait);connect(parserWorker, Parser::receivedResend, senderWorker, Sender::receivedResend);connect(parserWorker, Parser::receivedStart, senderWorker, Sender::receivedStart);connect(senderWorker, Sender::errorReceived, this, MainWindow::serialError);connect(senderWorker, Sender::dataReceived, parserWorker, Parser::parse);connect(senderWorker, Sender::dataReceived, this, MainWindow::readSerial);connect(senderWorker, Sender::reportProgress, this, MainWindow::updateFileProgress);connect(senderWorker, Sender::baudrateSetFailed, this, MainWindow::baudrateSetFailed);connect(this, MainWindow::setFile, senderWorker, Sender::setFile);connect(this, MainWindow::startPrinting, senderWorker, Sender::startPrinting);connect(this, MainWindow::stopPrinting, senderWorker, Sender::stopPrinting);connect(this, MainWindow::pause, senderWorker, Sender::pause);connect(this, MainWindow::setBaudrate, senderWorker, Sender::setBaudrate);connect(this, MainWindow::openPort, senderWorker, Sender::openPort);connect(this, MainWindow::closePort, senderWorker, Sender::closePort);connect(this, MainWindow::injectCommand, senderWorker, Sender::injectCommand);connect(this, MainWindow::flushInjectionBuffer, senderWorker, Sender::flushInjectionBuffer);senderThread-start();senderThread-setPriority(QThread::TimeCriticalPriority); (1)线程交互的设计 当我们看懂了这段代码以后就可以将它们抽象成我们自己的代码，即分解为： 以下是我基于上面的这个架构进行了简单的修改： /*注册串口线程*/void MainWindow::Register_Uart_thread() uartThread = new QThread(this); uartWorker = new SerialThread(Sensor_Uart,Sensor_Baud); uartWorker-moveToThread(uartThread); connect(uartThread, QThread::finished, uartWorker, QObject::deleteLater); connect(uartWorker, SerialThread::reportProgress, this, MainWindow::updateFileProgress); connect(uartWorker, SerialThread::update_layer, this, MainWindow::updateModelLayer); connect(uartWorker, SerialThread::send_debug_gcode_line, this, MainWindow::GCode_Debug); connect(this, MainWindow::startPrinting, uartWorker, SerialThread::startPrinting); connect(this, MainWindow::stopPrinting, uartWorker, SerialThread::stopPrinting); connect(this, MainWindow::pausePrinting, uartWorker, SerialThread::pausePrinting); connect(this, MainWindow::recovery_print, uartWorker, SerialThread::recovery_print); uartThread-start(); uartThread-setPriority(QThread::TimeCriticalPriority);/*注册文件管理线程*/void MainWindow::Register_FileManage_thread() fileThread = new QThread(this); fileWorker = new file_manage(); fileWorker-moveToThread(fileThread); connect(fileThread, QThread::finished, fileWorker, QObject::deleteLater); connect(this, MainWindow::setGodeFile, fileWorker, file_manage::parseFile); connect(fileWorker, file_manage::update_gcode_info_display, this, MainWindow::GCode_File_Info); connect(fileWorker, file_manage::send_gcode_file, uartWorker, SerialThread::setFile); fileThread-start(); fileThread-setPriority(QThread::HighestPriority);/*注册协议解析线程*/void MainWindow::Register_Protocol_Parse_thread() parserThread = new QThread(this); parseWorker = new protocol_parse(); parseWorker-moveToThread(parserThread); connect(parserThread, QThread::finished, parseWorker, QObject::deleteLater); connect(parseWorker, protocol_parse::hotbed_temp, this, MainWindow::Display_HotBed_Temp); connect(parseWorker, protocol_parse::hotend_temp, this, MainWindow::Display_Hotend_Temp); connect(parseWorker, protocol_parse::move_position, this, MainWindow::Display_Move_Position); connect(uartWorker, SerialThread::Data_Process, parseWorker, protocol_parse::Data_Process); parserThread-start(); parserThread-setPriority(QThread::HighestPriority); (2)打印GCode文件与用户发送GCode命令的核心实现 (3)协议解析的核心实现 关于协议解析部分，我依然采用的是正则表达式的方案来实现，例如对温度部分的处理： typedef struct QString raw; double e_c, b_c; double e_t, b_t; TemperatureReadings;//正则表达式获取温度void MainWindow::Get_Temp_Test() int p = 0; QStringList data_list ; TemperatureReadings r; /*对于单喷头打印机，它回复的数据格式是这样的*/ QByteArray data = T:41.88 /0.00 B:56.02 /60.00 @:0 B@:0 W:?; QRegExp temperatureRegxp(-?(([0-9]\\\\d*\\\\.\\\\d*)|(0\\\\.\\\\d*[0-9]\\\\d*)|([0-9]\\\\d*))); while ((p = temperatureRegxp.indexIn(data, p)) != -1) data_list.append(temperatureRegxp.cap(1)); //上一个匹配的字符串的长度 p += temperatureRegxp.matchedLength(); r.raw = QString(data); r.e_c = data_list[0].toDouble(); //喷头当前温度 r.e_t = data_list[1].toDouble(); //喷头目标温度 r.b_c = data_list[2].toDouble(); //热床当前温度 r.b_t = data_list[3].toDouble(); //热床目标温度 qDebug() 解析源字符串: r.raw 解析长度： data_list.length(); qDebug() r.e_c ; qDebug() r.e_t ; qDebug() r.b_c ; qDebug() r.b_t ; 例如对当前移动坐标的获取： typedef struct QString raw; double x,y,z ; CoreXYZ ;//正则表达式获取坐标void MainWindow::Get_GCodeXYZ_Test() int p = 0; QStringList data_list ; CoreXYZ r; /*移动指令，例如解析下面这个指令*/ QByteArray data = G1 F1200 X-9.914 Y-9.843 E3.36222; QRegExp CoreXYZRegxp(-?(([XYZ]|[0-9]\\\\d*\\\\.\\\\d*)|(0\\\\.\\\\d*[0-9]\\\\d*)|([0-9]\\\\d*))); while ((p = CoreXYZRegxp.indexIn(data, p)) != -1) data_list.append(CoreXYZRegxp.cap(1)); //上一个匹配的字符串的长度 p += CoreXYZRegxp.matchedLength(); r.raw = QString(data); r.x = data_list[0].toDouble(); r.y = data_list[1].toDouble(); qDebug() 解析源字符串: r.raw 解析长度： data_list.length(); qDebug() data_list[0]; qDebug() data_list[1]; (4)其它功能的设计 这部分就发挥大家自己的想象了，我先做了个测试版本，随便捣鼓一下，已经能够正常打印模型了： 目前这个项目还没有开源，我还在持续的完善中，希望最后能够助力一把 RepRapCalculator，希望加什么功能，大家可以在下方给我留言。 5、总结要做属于自己的打印机，需要掌握以下技能： 掌握QT软件开发(如果你会C#或者其它当然也没问题) 掌握3D打印机GCode指令协议 其它必要的知识，如设计模式、数据结构等。 另外，让我们对3D打印开源的小伙伴们为3D打印开源发发力量！ 6、参考文献 引用[1] G-Code Index. (n.d.). Marlin Firmware. https://marlinfw.org/meta/gcode/ [2] Neo, T. (2017, May 27). G-Code Index. Github. https://github.com/NeoTheFox/RepRaptor [3] Neo, T. (2017, May 27). A Qt RepRap Gcode SenderHost Controller. https://opensourcelibs.com/lib/repraptor [4]卢华东. (2015, December 26). RepRap 3D Printer 入门介绍. https://blog.csdn.net/lu\\_embedded/article/details/50409510 本文参与 腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2021-11-08，如有侵权请联系 cloudcommunity@tencent.com 删除","tags":["clippings"],"categories":["4.软件","3D打印"]},{"title":"最常用的入门切片工具Cura安装教程","path":"/2025/02/24/4-软件-3D打印-最常用的入门切片工具Cura安装教程/","content":"Cura是一款最常用的入门切片工具，它的界面美观，操作简便，而且每个参数都有注释，对入门玩家非常的友好。 安装使用【安装】 Cura安装完后打开，看不懂英文的，可先快速点击同意“Agree”、下一步”Next“和跳过“Skip”。 【配置打印机】 当来到这一步不能跳过时，点击“Add a networked printer”选择打印机（具体操作请仔细阅读说明书） 【中文设置】 完成打印机设置后，进入操作界面。选择菜单栏的“Preferences”和“Configure Cure”，点击进入。 在“General”栏中点击语言选项“Language”，下拉选择“简体中文”后，点击关闭。重启软件后即可换成简体中文。 使用教程常用操作 单击STL模型，将模型拖入Cura 长按鼠标滚轮中键，可平移视角 长按鼠标右键，可旋转视角 滚动鼠标滚轮，可放大缩小视角 模型调整 点击选中模型后，激活左边工具栏。工具栏可以调节模型的大小、比例、位置、旋转角度、镜像等模型设置。 【特殊位移】 默认状态下模型是自动贴合平台的。特殊情况下（如：只想打印一半模型），可解除Z轴限制 第1步：打开“偏好设置”—“基本”—“自动下降模型到打印平台”，取消勾选。 第2步：选择模型，点击位移工具，通用推拉Z轴或直接输入Z轴坐标可使模型下降至负数。切片后只会打印平台上方部分。 右击模型，可进行“复制”、“清空平台”、“居中模型等设置 操作界面左下角位置，可查看模型基本信息。点击“钢笔”图标，可更改切片后的文件名。 模型切片 点击操作界面右边的设置栏，选择“Expert”专家模式 可在配置文件中选择默认设切片设置，建议选择0.12mm或0.2mm层高的设置体验打印效果。 【切片预览】 切片完毕后，可在预览界面预览打印效果、耗材用量及预计用时。拉动最右边进度条，可查看每层打印情况。点击右下角保存gcode文件到U盘准备打印。 切片参数设置【质量】 主要设置打印的每层高度，这个参数对打印时长、及打印精度有关键作用，层高越小，打印越慢。一般建议层高0.1、0.12、0.2mm。（0.1适合高精度，0.2适合普通精度） 【填充】 为模型内部自动生成的填充物。一般没力学要求的模型填充密度为10-20%。如果填充率过低，也会有一定程度导致翘边，不同的内部填充图案也可以有效减少翘边。 【材料】 主要设置打印时喷嘴和热床的温度。一般耗材上会写有打印温度。也可通过打印温度塔测试出每种最耗材品牌最佳的打印温度。建议首层温度用230°C，容易粘床。 而打印PLA，热床的温度建议在50-60°C。 【速度】 PLA建议打印速度为60mms，±20也在常用速度。 【移动】 当打印出现拉丝情况，可调整回抽设置。建议回抽距离用2.0mm，回抽速度用50mms，加大数值可减少拉丝情况。如果打印过程中喷嘴有碰到打印物的情况，可勾选Z轴抬升。 【打印平台附着方式】 平台附着方式有三种。Skirt主要用于擦净喷头。而常用防止翘边的设置的有Brim和Raft，这两种模式能 让模型能够更好地与打印平台粘连 ， 发 现翘边时，可提高接触面宽度。 Brim是在模型底层加几圈裙边，底面复杂的模型不建议用这种，因为裙边不易拆除，容易影响底层边界。 raft是在模型下方打印一个几层的底座，不让模型与打印平台直接接触，可以有效弥补调平不佳的情况。若模型底层接触面小，容易发生倾倒，亦可使用raft。缺点是影响底层打印效果。 【支撑】 作为入门最难的一个设置。通常角度过大，打印过程中悬空部位则需要添加支撑，否则容易下垂。支撑与模型接触面往往很粗糙，影响模型质量。 支撑悬垂角度越大，需要支撑部位（红色部分）则越小。建议45-50间。 【普通支撑】 建议参数 支撑图案：锯齿形 支撑密度：15-20， 支撑墙行数：0 支撑Z距离：推荐比层高略小（如：0.2层高，设置为0.15） 一般此参数为0.6~1.5倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。 支撑XY距离：1-1.5mm 【树形支撑】 Cura提供普通支撑和树型支撑两种选择。树型支撑对模型影响更小，也节省材料。注意，它只适合于非平面的悬空，如鼻尖，指尖或拱形。对于平面的悬空，树形支撑无法提供足够的稳定性。 建议参数 支撑图案：锯齿形 支撑密度：15-20， 支撑墙行数：1 连接支撑锯齿形:勾选 支撑Z距离：推荐比层高略小（如：0.2层高，设置为0.15） 一般此参数为0.6~1.5倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。 支撑XY距离：1-1.5 什么情况可以不加支撑？ 【轻微挑出】有些模型位置挑空距离不远，可以不用加支撑，如浮雕纹理、表面轻微突起等。（比较适合层高较大，低速低温的设置。具体情况需根据不同模型合理运用）可在左边工具栏点击支撑拦截器，在相应位置添加方块减少支撑应用。 【悬空拉线模型】如下图的拉线模型，悬空的拉线从一端墙壁走到另一端墙壁，两端粘连在支撑位置上，则不需要支撑。（注意：预览打印过程，看是否符合此条件，同时也比较考验机器） 在天地万物间徜徉,在淡淡书香中寻觅人生至味。 Cura的入门教程就分享到这，有疑问或有更好建议的伙伴们，可以留言分享。","tags":["clippings"],"categories":["4.软件","3D打印"]},{"title":"跟着思兼学习Klipper(16) Klipper 网页使用摄像头比较全指南","path":"/2025/02/24/4-软件-3D打印-跟着思兼学习Klipper-16-Klipper-网页使用摄像头比较全指南/","content":"【思兼】Klipper 网页使用摄像头比较全指南前言原创文章，转载引用请务必注明链接。水平有限，如有疏漏，欢迎指正交流。 本文分为两部分：一是针对我出售的 Klipper 免驱摄像头的专有内容，二是关于使用摄像头的通用内容。 文章如有更新请访问 DFRobot社区 或者 cnblogs博客园(排版更好)。 欢迎对 Klipper 固件感兴趣，以及对改版 CNC 加工的 Voron 三叉戟、v0、v2.4 感兴趣的朋友加群交流（QQ Group：490111638） 一、专有内容 | Exclusive Content 请结合视频了解如何快速入门：思兼的 Klipper 免驱摄像头快速使用指南，做这个主要是解决以下问题： 上位机支持什么样的摄像头哪些摄像头免驱? 哪种摄像头价格便宜，成像质量好？ 如何在 FluiddMainsailOctoprint 中设置使用摄像头？ 众多摄像头选项，如何配置和选择？ 为什么我步骤都对，就是没有图像，如何排除故障？ 除了监控，摄像头还有没有其他玩法？ 其实预算足够，可以考虑购买这篇文章 Best Cameras for OctoPrint of 2021 推荐的，比如 罗技C270 等。 1、关于 Klipper 使用摄像头的一些问题# 除了树莓派，大部分上位机都不支持视频的硬件解码 大多数上位机使用 CPU 软件解码，如果性能不足会出现卡滞现象，可以适当降低分辨率和帧率 Fluidd 默认的 640x480@10fps 多能满足需求 高性能 CPU 酌情使用 800x600 分辨率，并根据使用目的设置帧率 请为上位机提供稳定供电，5V@2A 以上比较稳妥 和 Windows 下一样，最大分辨率用于静态拍照，视频录制模式无法达到最大分辨率 MJPG-Streamer 比较吃 CPU 资源，KlipperScreen 比较吃内存资源 使用过程中建议为上位机 CPU 增加主动散热，摄像头芯片可以贴一个小散热片 安装此 USB 摄像头时，请确保没有正在执行打印任务，避免意外中断通讯 在低性能 CPU 上如果摄像头移动过快超出 CPU 处理能力，可能会导致图像卡死，可以尝试使用 µStreamer 或者重启 webcamd 服务，并尽量固定摄像头位置 2、安装使用 Klipper 摄像头#2.1 安装摄像头软件依赖#Copy# 使用一键脚本，第一种方式会导致 kiauh 报无效参数错误，原因暂未知。# 脚本默认策略是不相信本地软件环境，会备份并删除旧文件：.gitconfig、klipper_config/webcamd.txt、kiauh# curl -fsSL http://klipper.7130404.xyz:8001/enable_webcam.sh | bashbash (curl -fsSL http://klipper.7130404.xyz:8001/add_webcam.sh) 2.2 安装 MJPG-Streamer#如视频中所示，在出现的 KIAUH 助手中删除并重新安装 MJPG-Streamer： 2.3 添加摄像头#添加摄像头，设置如下，刷新主面板即可看到摄像头内容： MJPEG Stream | 传统方式，Fluidd 被动接收 上位机上的 MJPEG 服务以 webcamd.txt 中 配置好的分辨率和帧率 推送来的视频流（连续的图片序列），此种方式多数情况下占用大量带宽，并且网络不稳定时会出现问题。 MJPEG Adaptive | 推荐方式，Fluidd 主动拉取 单帧图片组成视频流，因此你可以设置合适的帧率，此种方式更稳定，占用网络带宽也更小。 IP Camera| 实验性选项，仅支持 HTML5 视频，具体未测试。 HTTP Page |（内嵌网页，支持更多视频来源） U4VL (Mainsail) 3、修改基本参数：分辨率和帧率#Copy# 修改 ~/klipper_config/webcam.txt 最下面一行camera_usb_options=-r 640x480 -f 10 -y -d /dev/v4l/by-id/usb-Etron_Technology__Inc._USB2.0_Camera-video-index0# -r (resolution, 分辨率)：640x480 修改为你想要的分辨率如 800x600# -f (fps，帧率)：10 修改为 25 重启生效：sudo systemctl restart webcamd 二、通用内容 | Generic Content2.1 启用简单安全认证 | Enable Authentication#Copy# 修改 ~/klipper_config/webcam.txt 下面几行-#camera_http_options=-n+camera_http_options=-n -c [username]:[password] 默认使用http访问时，密码传输采用明文，存在一定安全隐患，如需更严格的安全保护，请参考 Secure Webcam streaming with MJPG-Streamer on a Raspberry Pi。 2.2 启用多摄像头 | Enable Multiple Cameras#参考链接如下，注意是有先后传承顺序的，即使是使用 Fluidd，KIAUH 下载使用的摄像头依赖软件和配置文件也是来源于 Mainsail，所以我常说 Fluidd 有问题可以去看 Mainsial 文档： Setting up multiple webcams in OctoPi the right way Mainsail docs: Webcams Fluidd docs: Cameras | 不建议 主要操作就是 复制一份 webcam1.txt 配置文件 更改监听端口：8080~8083，受限于 nginx 默认设置，目前最多支持四个摄像头。 更改捕获的视频设备地址，注意相同设备的话，所以配置文件都要更改，可以使用 by-path 重启服务 新的视频地址为 webcam2/?action=stream 对应 8081 对应 webcam1.txt aka 配置文件从 0 开始，摄像头地址从 1 开始，fluidd 的文档错了 Copy# 复制一份配置文件cp ~/klipper_config/webcam.txt ~/klipper_config/webcam1.txt# 更改监听端口sed -i /#camera_http_options=/a camera_http_options=-n -p 8081 ~/klipper_config/webcam1.txt# 由于同一摄像头其 id 相同，所以我们用 path 来进行区分，此处类似 klipper 的 serial 地址查找方法：ls /dev/v4l/by-path/*# 地址分别对应不同的USB接口，选择 index0 地址修改所有 webcam*.txt，使每个配置文件中的设备号不同。例如camera_usb_options=-r 640x480 -f 10 -y -d /dev/v4l/by-path/platform-xhci-hcd.3.auto-usb-0:2:1.0-video-index0# 重启服务生效sudo systemctl restart webcamd.service 2.3 启用延时摄影 | Enable Timelapse#上次研究这个还是在去年 8 月份，现在该组件已经合并到 Mainsail 里面了，话说 Mainsail 功能是真的丰富，不排除有一天切换到它。 项目地址，项目镜像地址 安装指南 Copy# 安装 ffmpeg 用于合成视频sudo apt install ffmpeg# 下载并安装 moonraker timelapse 组件cd ~/ git clone https://hub.0z.gs/mainsail-crew/moonraker-timelapse.gitbash ~/moonraker-timelapse/install.sh 配置参考 修改 printer.cfg 如下 Copy# printer.cfg[include timelapse.cfg] 修改 moonraker.cfg 如下 Copy# moonraker.conf[timelapse]## 以下为默认设置，如果需要更改请取消注释#output_path: ~/timelapse/## 存储生成的延时摄影视频目录#frame_path: /tmp/timelapse/## 存储临时图像的目录#ffmpeg_binary_path: /usr/bin/ffmpeg## ffmpeg 所在路径snapshoturl: http://localhost:8080/?action=snapshot## 摄像头快照访问地址，如果有多个摄像头可以设置具体的端口号 新版组件采用 moonraker API 来进行修改参数，具体查看上面的文档，也可以手动设置参数，调整分辨率在 webcam.txt 中修改。可以手动在控制台输入 TIMELAPSE_TAKE_FRAME 拍摄图片。 注意： 即使网页没有添加摄像头，图像和视频也是可以通过上述被访问的，但是即使没有显示，系统资源也会被占用 延时摄影相关宏 不支持密码访问 的摄像头 用作延时摄影的摄像头可以采用高分辨率低帧率，如 1600x1200@7fps 优化：创建软链接，方便直接在网页查看图片和下载视频 Copymkdir /home/pi/gcode_files/timelapse/ln -s /tmp/timelapse/ /home/pi/gcode_files/timelapse/tmpln -s /home/pi/timelapse/ /home/pi/gcode_files/timelapse/video 2.4 使用人工智能自动检测打印失败#可以借助 The Spaghetti Detective (TSD) 服务来自动检测炒面，免费服务受限颇多，可以 自己搭建服务器 使用，我手里有一台 Jetson Nano 可以用于测试。 combines improved webcam streaming with AI-driven print failure detection. You can access your printer’s webcam feed from any device, and time-lapses of all your past prints are available on your TSD dashboard. An additional beta feature is a secure tunnel through which you can access your entire OctoPrint interface from any device. 既往在 Octoprint 系统上安装插件使用 目前有一个 moonraker 组件 可供测试使用。 此外 TSD 还有一个 摄像头放置建议，值得一看。 TSD 免费版限制： Limited to 1 printer. Basic Streaming is at 0.1fps (1 frame per 10 seconds). The stream is on only when the printer is printing. 10 free Detective Hoursmonth included Unused Detective Hours roll over month to month. You can also earn free Detective Hours by helping her improve. 50MB month Tunneling Detective Hour is sometimes abbreviated as DH. 2.5 使用 µStreamer 替代 MJPG-Streamer#虽然此实验版 MJPG-Streamer 使用 libjpeg-turbo 而非普通的 libjpeg 库进行编译，编解码速度有所提升，但是还是有优化空间。这里介绍另一个类似的改进项目：µStreamer，它是这么自我介绍的：µStreamer - Lightweight and fast MJPEG-HTTP streamer 也就是更轻量更快速的 MJPG-Streamer 替代服务。我测试下来优点明显，比如： 代码配置更简洁 支持多线程 JPEG 编码 支持树莓派的硬件编码，基于 V4L2 M2M 支持断线重连后信号恢复，而无需重启服务 支持控制 GPIO 输出 支持 WebRTC 串流，降低网络带宽占用，借助 Janus 和 H.264 兼容 mjpg-streamer API 但是性能不如 mjpg-streamer，不知道是不是我参数设置不正确。好处是几乎可以完全替代后者，后面会持续关注它。 创建 systemd 服务请参考：init.d and systemctl scripts，µStreamer 不需要 webcamd 和 webcam.txt。 2.6 降低系统和带宽占用 (TBD)#目的是研究如何优化性能、提高流畅度，以下项目需要整理、测试、验证。硬件加速基本就限定树莓派了。 Fluidd HTTP Page ：Add camera iframe option with height option Uses less bandwidth and runs with hw accel in your browser but needs to be setup as a simple web page 基于 pi-h264-to-browser |RPi Cam Pi H264 To Browser is a simple Python application designed to stream hardware encoded h.264 from a Raspberry Pi equiped with a V1, V2, or HQ camera module, directly to a browser. 以及 h264 webrtc-streamer I set up webrtc-streamer to get a very low latency (and low bandwidth) camera feed from my printer into a browser, sadly fluidd’s options do not allow me to embed that at all. .webrtc-streamer -vvv v4l2:devvideo1 https://www.cnblogs.com/savorboard/p/webrtc-rtsp.html https://community.octoprint.org/t/js-help-needed-better-webcam-streaming-webrtc/4969/10 h264rcam | This project was inspired by pi-h264-to-browser ，h264rcam provides an easy way to get a Raspberry Pi Camera stream inside web browser. https://askubuntu.com/questions/881305/is-there-any-way-ffmpeg-send-video-to-dev-video0-on-ubuntu4. U4VL | https://www.jianshu.com/p/c08d68a1a505 2.7 远程监控#关于这部分我没有需求，简单说说。 建议使用萤石等家用监控摄像头进行监控，自带远程访问功能 有访问条件的可以使用 telegram-bot 基本方法就是暴露 8080 端口，做强加密；或者使用 VPN 还可以推流到 B 站 另外家用宽带如果上行下行不对等，上行带宽较小时效果可能不好 如果想要进行远程控制打印机，安全起见建议只暴露 moonraker 7125 端口，不要暴露 80 端口（运营商可能也不愿意），可以访问 app.fluidd.xyz 或者 my.mainsail.xyz 访问。如果是自有域名，一是可以创建用户，二是可以修改 cors_domains 策略。 三、其他摄像头方案3.1 树莓派摄像头 | RPi Cam# 注意：树莓派官方以及一些优质厂商提供的摄像头质量很不错，但是也有一些兼容树莓派引脚的劣质摄像头存在，注意甄别。 树莓派官方摄像头出了 3 代，1代支持自动对焦；2代不支持自动对焦，但是性能更好；3代这里就不介绍了。 我们这里都以 Raspberry Pi OS Bullseye 为例，使用方法很简单，说是新版会自动侦测并启用，但是对于 RPi3 等老型号，还需要设置以启动硬件加速： sudo raspi-config —— Advanced Options —— Glamor —— Yes ，重启生效。 然后配置文件修改分辨率帧率即可。更多内容可以查看 官方文档。不过最好购买官方的摄像头，很多很便宜的摄像头显示质量很差。 3.2 手机作为摄像头使用#前面讲过旧手机可以充当 KlipperScreen 的显示触摸屏，其实旧手机的摄像头也可以为我所用。最初尝试我常用的由 沈垚 开发的 IP摄像头，下图黄黑色图标，只能以 http page 方式使用；于是搜索下载安装了第二款国外开发的黑灰色图标的 IP摄像头 （下文称为 IP Webcam） 测试成功。xapk 安装器 下载地址。注意如果是 32bit 老安卓手机，要找到老版本 APK 的下载。 灰色摄像头软件的界面如下图所示功能强大，免费版功能就够用了。https://www.dev47apps.com/https://wolicheng.com/womic/ 【图 】IP Webcam APP 界面，支持读取传感器数据，所以有无可能根据陀螺仪做视频后处理，或者 GoPro 那种自稳视频效果？ 【图 】IP Webcam 网页管理界面，支持多种操作，以及开启 LED 闪光灯等功能，还可以设置熄屏和网页管理，美滋滋。 其他值得关注的软件还包括： DroidCam | 高级功能需要收费 WO Mic | 无线麦功能 手机物理工坊 | 手机物理工坊 – 利用 8 种手机传感器，做最强物理实验，可以保存陀螺仪等数据 Gyroflow | 结合陀螺仪数据，使视频实现 GoPro 类似效果（大概这样） 四、进阶知识4.1 获取 USB-Camera 参数#Copy# 安装所需工具包sudo apt install v4l-utils usbtop# 查看已连接的摄像头设备v4l2-ctl --list-devices# 如果没有识别到相应设备，请检查设备是否连接良好，以及 lsusb、dmesg 等命令查看是否被系统识别# 查看对应摄像头的支持格式v4l2-ctl -d [/dev/video1] --list-formats-extv4l2-ctl --device=/dev/video* --all# 查看并设置摄像头支持的控制参数v4l2-ctl -d /dev/video0 --list-ctrls# v4l2-ctl -d /dev/video1 --set-ctrl=zoom_absolute=170 由上图我们就可以获得所需的配置： 摄像头设备地址为：/dev/video0，非 video1 或者 media0 此摄像头支持的最大分辨率和对应的帧率为 1600×1200，亦即 1080P， 纵横比为 4:3。 用于 FluiddMainsail 网页前端使用时，可以选择 800×600@25fps 以获取较好的显示兼容性和较低的系统占用，减少 CPU 发热，降低打印管理进程被干扰的可能。 编码方法为 YUYV，在配置参数中添加 -y 选项。此外有的摄像头还支持 MJPG 等编码方式。 番外：# 通过 lsusb 命令获取设备 Vendor ID 和 Device ID 可以查询到相关设备信息。 ​ 继而可以从以下网址查询相关信息： DEVICE HUNT linux-usb.org 图形化设置摄像头参数工具：v4l2ucp 获取更多 mjpg_streamer 选项，可以通过查看 octoprint文档 也可以查看帮助文件 Copyudevadm info --attribute-walk /dev/bus/usb/[Bus]/[Device]cd ~/mjpg_streamer./mjpg_streamer -i input_uvc.so --help./mjpg_streamer -o output_http.so --help 4.2 固定摄像头设备地址#在有多个 video 设备时，插拔摄像头后，其 /dev/video[num] 编号可能会发生改变，从而导致摄像头配置文件失效，这也是为什么很多人原来用的好好的，插拔之后不能用的原因。 此外有些设备自带 devvideo0 设备，而 webcamd 会默认读取第一个 video 设备，应该访问 video1 却访问了 video0。 4.2.1 Method 1：创建 udev 规则（不推荐）#参考 Archwiki ，创建 udev 规则： Copy# /etc/udev/rules.d/83-webcam.rulesKERNEL==video[0-9]*, SUBSYSTEM==video4linux, SUBSYSTEMS==usb, ATTRSidVendor==1e4e, ATTRSidProduct==0109, ATTRindex==0, SYMLINK+=video-cam1 使用 sudo udevadm control --reload 命令可以强制重载生效 udev 规则，重新插拔 USB 摄像头即可看到新的 video-cam1 设备 同时修改 webcamd.txt 指定设备地址 -d /dev/video-cam1，重启 webcamd 服务生效 注意设备名称必须以 video 开头，以被 v4l 使用 比较奇怪的是 ls -al /dev/video-cam1 可以看到链接到 video2（不显示参数那个），但是手动修改 webcamd.txt 又只能用 video1 才行 发现 mjpg_streamer 仅支持 video[0-9]，不支持上述命名格式，webcamd.log 看到会自动忽略 如果制定的设备地址无效，会自动调用第一个 video 设备，从而有可能出错 更多信息可以参考 Webcam ordering is not persistent in Linux 4.2.2 Method 2：使用 v4l 设备地址#这个很像 Klipper 获取 serial 设备地址的方法，不会出现重新插拔后出错的问题，导致 ttyAMA0 等设备无法对应，klipper 读取的是 /dev/serial/by-id/*，摄像头读取的是 /dev/v4l/by-id/* ，同样也面临一个问题，比如 CH340 设备的 id 相同，此时多个 MKS Gen L 等主板无法区分，此问题同样也出现在这里，解决方法是使用 /dev/v4l/by-path/*，此路径与USB接口绑定。 4.3 为什么一个物理摄像头，有多个 video 设备？#参考这个回答：Multiple devvideo for one physical device ，可知第一个用于传递图像，第二个用于传递 V4L MetaData，包含时间戳以及图像捕捉参数等信息。 The second device provides metadata about the video data from the first device. 4.4 将摄像头图像输出到屏幕#参考 Viewing an mjpeg stream with mplayer Copysudo apt install -y mplayermplayer -nolirc -vo fbdev2 -zoom -x 320 -y 240 test.mpgmplayer -fps 4 -demuxer lavf http://localhost:8080/?action=stream 4.5 查看带宽、数据吞吐量# nethogs | 用于查看网络带宽吞吐量，优化调试使用。可以看到 jpeg 质量对带宽占用影响很大 Copysudo nethogs# 使用 r 和 s 键来排序传入和传出的实时及累计数据量 **usbtop ** | 用于查看 USB 接口数据吞吐量，也可以观察上位机一带多情况 Copy# 列出所有可用的USB总线usbtop --list# 监控特定USB总线上的带宽流量sudo usbtop --bus [usbmon1]","tags":["clippings"],"categories":["4.软件","3D打印"]},{"title":"QCustomPlot实时动态曲线","path":"/2025/02/22/2-语言-Qt-绘图-QCustomPlot实时动态曲线/","content":"先来个动图看看效果： 支持鼠标平移、滚轮缩放、框选放大、取消框选、一键全显、单击显示 xy 坐标值。。等 平移功能是 QCustomPlot 自带的功能，参见我的该系列前面的博文。框选放大、全显等功能在另一篇博文中也讲到了。 这里只讲 2 个知识点：1、显示鼠标指向的点坐标，2、实时滚动 1、箭头指向要显示的坐标点，代码步骤： （1）添加新类，继承 QCustomPlot添加 private 成员变量： QCPItemText *textLabel;//单击时提示信息框QCPItemLine *arrow;//提示信息的箭头 在构造中初始化他俩： //下面这一段是从QCustomPlot官网抄来的/*显示数值的提示框*/ textLabel = new QCPItemText(this); textLabel-setPositionAlignment(Qt::AlignTop|Qt::AlignHCenter);//方框置于上部中间 textLabel-position-setType(QCPItemPosition::ptAxisRectRatio); textLabel-position-setCoords(0.5, 0); // place position at center/top of axis rect textLabel-setFont(QFont(font().family(), 16)); // 字体 textLabel-setPen(QPen(Qt::black)); // 颜色//指向数值的箭头: arrow = new QCPItemLine(this); arrow-start-setParentAnchor(textLabel-bottom);//箭头起点位于提示框的下边框中点//arrow-end-setCoords(4, 1.6); // 设置箭头的终点 arrow-setHead(QCPLineEnding::esSpikeArrow);//箭头类型 textLabel-setVisible(false);//提示框不可见 arrow-setVisible(false);//箭头不可见 （2）重写鼠标按下弹起事件 void MultiCurvesPlot::mousePressEvent(QMouseEvent *event)//重写后，仍然要使父类的函数，否则自带的拖动功能等就失效了 QCustomPlot::mousePressEvent(event);//父类的函数if(event-buttons() Qt::LeftButton)//按下鼠标左键 textLabel-setVisible(true);//提示框可见 arrow-setVisible(true);//箭头可见 double x = xAxis-pixelToCoord(event-pos().x());//鼠标坐标转化为XY轴的坐标 double y = yAxis-pixelToCoord(event-pos().y()); arrow-end-setCoords(x, y); // 设置箭头的终点 QString xTime = QDateTime::fromMSecsSinceEpoch(x * 1000.0).toString(hh:mm:ss.zzz);//把单击处的X值转换为时间String textLabel-setText(QString(x = %1 y=%2).arg(xTime).arg(y));//显示XY值 void MultiCurvesPlot::mouseReleaseEvent(QMouseEvent *event) QCustomPlot::mouseReleaseEvent(event);if(event-button() == Qt::LeftButton)//左键弹起 textLabel-setVisible(false);//隐藏数值方框和箭头 arrow-setVisible(false); 2、实时滚动的曲线我们要做的就两点：1、向 graph 中添加新的点 this-graph(graphIdx)-addData(currentTime, y); 2、实时修改 X 轴的显示范围 在我这个例子中，X 轴是实时时间，所以，要想使曲线实时滚动，只要把 X 轴的显示范围实时修改为：从当前时间-当前 X 轴的显示宽度到当前时间即可， 这样曲线就会滚动起来。其中，当前 X 轴的显示宽度可以从 xAxis-range().size()读取。 注意：如果我们接收到的数据点过于频繁，我们不应该每收到一个点都要刷新图像，那样程序效率太低，也没必要。一般设置每 30ms 刷新一次就足够流畅了，毕竟我们下载的普通电影也就 30 帧每秒。 因此，我们在一个 30ms 定时器的槽函数中来做：修改 X 轴的显示范围+刷新图像。 代码步骤如下： （1）在构造函数中启动 QWidget 自带的定时器 startTimer(30, Qt::CoarseTimer);//每30ms触发一次timeEvent事件 （2）重写 void timerEvent(QTimerEvent *event) Q_DECL_OVERRIDE;函数来响应这个定时器的超时事件: void MultiCurvesPlot::timerEvent(QTimerEvent *event) Q_UNUSED(event);if(autoScroll)//如果启动了自动滚动功能 double curSeclf = (double)(QDateTime::currentMSecsSinceEpoch()) / 1000.0;//读取当前时间（因为QCustomPlot支持的时间值的ms值在小数位，所以/1000.0了） this-xAxis-setRange(curSeclf - xAxis-range().size(), curSeclf);//实时调整X轴的显示范围 this-replot();//刷新图像 代码就这些，非常简单。 群号在左边。","tags":["clippings"],"categories":["2.语言","Qt","绘图"]},{"title":"QTableWidget大量数据处理","path":"/2025/02/22/2-语言-Qt-QTableWidget大量数据处理/","content":"Qt 大数据列表展示优化方案在 Qt 中使用 QListWidget、QTableWidget 或 QTreeWidget（最多支持三层结构）进行大数据列表展示时，通常会遇到加载缓慢和内存占用高的问题。其主要原因是创建了过多的子 Widget，导致系统资源紧张，影响界面响应速度。 问题分析当列表中的数据量达到上千甚至上万条时，如果为每一条数据都创建一个 Widget 实例，窗口管理和内存占用都会成为瓶颈。实际上，列表的可视区域高度是有限的，通常只需要少量的 Widget 便可填满屏幕。 核心优化思路不为每条数据创建 Widget，而是： **仅创建可视范围内的 Widget**，其余数据通过逻辑控制进行显示与隐藏。 **复用已创建的 Widget**，当滚动条滚动时，将超出屏幕的 Widget 隐藏，并用其展示新的数据，而不再新建实例。 仅在 Widget 数量不足时创建新的 Widget，确保始终只占用一个屏幕所需的 Widget 数量。 实现步骤1. 组件组成 **m_widgets**：缓存所有已创建的 Widget，避免重复创建。 **父 Widget**：容纳子 Widget 和滚动条，确保子 Widget 在其中适当布局。 滚动条：控制可视范围，动态调整可见 Widget。 2. 复用 WidgetQListItemWidget* m_widgets; // 存储所有创建的子 WidgetItemWidget *TreeWidget::getWidget(const ItemInfo info) ItemWidget *widget = nullptr; // 查找已存在但隐藏的 Widget，直接复用 for (int i = 0; i m_widgets.size(); i++) if (m_widgets[i]-data().type == info.type !m_widgets[i]-isVisible()) widget = m_widgets[i]; break; // 若找不到可复用 Widget，则创建新的 if (widget == nullptr) if (info.type == Top) widget = new TopWidget(this); else if (info.type == Parent) widget = new ParentWidget(this); else if (info.type == Child) widget = new ChildWidget(this); else Q_ASSERT(0); // 绑定信号槽 connect(widget, ItemWidget::sigMousePress, [this, widget]() if (widget-data().type != Child) ItemInfo newInfo = widget-data(); newInfo.isExpand = !newInfo.isExpand; updateItemInfo(newInfo); refreshWidgets(); else gotoSelected(widget-data().id); emit sigItemMousePress(widget-data()); ); connect(widget, ItemWidget::sigMouseDoubleClick, [this, widget]() emit sigItemMouseDoubleClick(widget-data()); ); m_widgets.append(widget); // 设置数据 widget-setData(info); if (widget-data().type == Child) widget-setSelected(widget-data().id == m_curChildId); widget-resize(this-width(), widget-height()); widget-show(); return widget; 3. 刷新数据 先隐藏所有 Widget。 遍历数据，根据 y 轴坐标计算哪些数据需要显示。 显示符合范围的 Widget，并更新滚动条。 void TreeWidget::refreshWidgets() // 隐藏所有 Widget for (int i = 0; i m_widgets.size(); i++) m_widgets[i]-resize(this-width(), m_widgets[i]-height()); m_widgets[i]-hide(); auto moveItem = [this](const ItemInfo item, int y, int startPos, bool isContinue) if (y = m_scrollbar-value() isContinue) getWidget(item)-move(0, startPos); startPos += item.height; isContinue = startPos this-height(); y += item.height; ; int y = 0, startPos = 0; bool isContinue = true; for (int i = 0; i m_list.count(); i++) const ItemInfo topItem = m_list[i]; moveItem(topItem, y, startPos, isContinue); if (topItem.childList.count() 0 topItem.isExpand) for (int j = 0; j topItem.childList.count(); j++) const ItemInfo parentItem = topItem.childList[j]; moveItem(parentItem, y, startPos, isContinue); if (parentItem.childList.count() 0 parentItem.isExpand) for (int k = 0; k parentItem.childList.count(); k++) const ItemInfo childItem = parentItem.childList[k]; moveItem(childItem, y, startPos, isContinue); // 计算滚动条范围 m_scrollbar-move(this-width() - m_scrollbar-width(), 0); m_scrollbar-resize(m_scrollbar-width(), this-height()); m_scrollbar-setPageStep(this-height()); if (y startPos) m_scrollbar-setMaximum(y - m_scrollbar-pageStep()); m_scrollbar-show(); m_scrollbar-raise(); else m_scrollbar-setMaximum(0); m_scrollbar-setValue(0); m_scrollbar-hide(); 性能优化1. 响应事件扩展 支持鼠标滚动： wheelEvent() 处理滚动事件，动态更新 Widget 可见状态。 支持窗口大小调整： resizeEvent() 重新计算可见区域，确保窗口变化时 Widget 布局合理。 2. 代码优化 减少 Widget 创建，保证流畅滚动。 事件触发减少 UI 线程阻塞，提升用户体验。 实际效果 测试数据量：17000+ 条记录，滚动流畅。 层级结构： 红色：最顶层（Top） 绿色：中间层（Parent） 白色：最底层（Child） 具体实现在使用 QTableWidget 时，当数据量超过 1000 条时，用户可能会感到界面响应变慢。如果数据量达到 1 万、10 万甚至 100 万条，显示速度的下降将更加明显。这种情况下，用户体验会受到显著影响，因此需要采取措施来优化数据的显示。 为了提高性能，我重新封装了一个类 BigTableWidget，它继承自 QTableWidget。这个类的核心思想是采用延迟加载的方法来显示数据。具体来说，BigTableWidget 通过滚动条控制显示内容。由于在屏幕上一次只能显示有限的数据行，只有当前可见的数据会被加载到界面中，而不在视野中的数据则保留在内存中。只有当用户拖动滚动条时，才会加载新的数据行。这种方法有效地将大数据集分批显示，避免一次性加载所有数据导致的性能问题。 例如，如果我们有 100 万条数据，直接在 QTableWidget 中显示会消耗大量内存和处理时间。而通过 BigTableWidget，我们只需加载当前视图所需的行，其他数据则在用户需要时动态加载。这种“空间换时间”的策略在处理大数据时非常有效。 BigTableWidget 类的头文件/// 这个类来保存每一个 Item 的信息class BigTableWidgetInfo public: BigTableWidgetInfo() ; ~BigTableWidgetInfo() ; int nRow; //! 插入数据所在行数 int nColumn; //! 插入数据所在列数 char strText[100]; //! 在单元格中显示的数据 QVariant userData; //! 单元格中用户关联的数据;class BigTableWidget : public QTableWidget Q_OBJECTpublic: BigTableWidget(QWidget* parent = 0); ~BigTableWidget(); //! 向表格中指定的行列添加显示信息和用户数据 void addItem(int row, int column, QString strText, QVariant userData = QVariant()); //! 初始化表格的行数和列数 void initTableRowAndColumn(int row, int nColumn); //! 清除表格中的数据，启动一个线程在后台去处理数据的清除操作，不影响界面的操作 void clearTableData(); //! 获取当前表格窗口显示最大的行数 int getMaxCount() return m_nMaxCount; //! 将数据保存到 list 的列表中 void pushData(int row, int column, QString strText, QVariant userData); protected: static void dealClearData(void* users); private slots: void dealChangeValue(int nValue); private: Ui::BigTableWidget ui; int m_nMaxCount; //! 每页显示的最大行数 QListBigTableWidgetInfo* m_listTableInfo; //! 显示数据的存储列表 QListBigTableWidgetInfo* m_listCopyTableInfo; //! 存储清除数据的垃圾列表 QMutex m_tableInfoMutex;; BigTableWidget 类的实现BigTableWidget::BigTableWidget(QWidget *parent) : QTableWidget(parent) ui.setupUi(this); // 设置单元格为禁止编辑 setEditTriggers(QAbstractItemView::NoEditTriggers);/// 初始化表格的行数和列数void BigTableWidget::initTableRowAndColumn(int row, int nColumn) this-setColumnCount(nColumn); this-setRowCount(row); // 初始化窗口滚动条拖动变化的信号槽，以及窗口最多显示数据的行数 QScrollBar* pBar = this-verticalScrollBar(); connect((QObject*)pBar, SIGNAL(valueChanged(int)), this, SLOT(dealChangeValue(int))); int nRowHeight = this-rowHeight(0); int nScrollBarHeight = this-maximumViewportSize().height(); // 获取滚动条的滚动范围 m_nMaxCount = nScrollBarHeight / nRowHeight + 1;/// 这个是最重要的槽函数，拖动滚动条来动态的加载数据显示void BigTableWidget::dealChangeValue(int nValue) int nRealRow = nValue; int nRowChanged = 0; int nTempColumn = this-columnCount(); int nListSize = m_listTableInfo.size() / nTempColumn; // 滚动条拖动的数值但数据没有加载完成 if (nValue nListSize) QScrollBar* pBar = this-verticalScrollBar(); pBar-setValue(nListSize); return; if (nListSize - nRealRow m_nMaxCount) nRowChanged = nListSize - nRealRow; for (int i = 0; i nRowChanged; ++i) if (i == nRowChanged i + nRealRow == this-rowCount()) break; for (int j = 0; j nTempColumn; ++j) int temp = (i + nRealRow) * (nTempColumn) + j; if (temp = m_listTableInfo.size()) return; BigTableWidgetInfo* info = m_listTableInfo.at(temp); QTableWidgetItem* tempItem = new QTableWidgetItem(QString::fromStdString(info-strText)); tempItem-setTextAlignment(Qt::AlignHCenter); this-setItem(info-nRow, info-nColumn, tempItem); /// 向看到的表格中加载显示数据void BigTableWidget::addItem(int row, int column, QString strText, QVariant pUserData) BigTableWidgetInfo* info = new BigTableWidgetInfo; info-nRow = row; info-nColumn = column; strcpy(info-strText, strText.toStdString().c_str()); info-userData = pUserData; m_listTableInfo.push_back(info); // m_nMaxCount 在看到的区域内最多显示的记录条数 if (row m_nMaxCount) QTableWidgetItem* tempItem = new QTableWidgetItem(strText); tempItem-setTextAlignment(Qt::AlignHCenter); this-setItem(row, column, tempItem); /// 如果没有在表格中显示的则存储到内存中void BigTableWidget::pushData(int row, int column, QString strText, QVariant pUserData) BigTableWidgetInfo* info = new BigTableWidgetInfo; info-nRow = row; info-nColumn = column; strcpy(info-strText, strText.toStdString().c_str()); info-userData = pUserData; m_listTableInfo.push_back(info);/// 如果很多条数据，在不用的时候将表格清空，并且要将内存中的数据清除，否则会占用内存；void BigTableWidget::clearTableData() if (m_listTableInfo.isEmpty()) return; m_listCopyTableInfo.append(m_listTableInfo); QMutexLocker locker(m_tableInfoMutex); m_listTableInfo.clear(); this-clearContents(); this-setRowCount(1); QtConcurrent::run(dealClearData, (void*)this);/// 线程函数 清除历史数据void BigTableWidget::dealClearData(void* users) BigTableWidget* pThis = static_castBigTableWidget*(users); for (int i = 0; i pThis-m_listCopyTableInfo.size(); ++i) if (pThis-m_listCopyTableInfo.at(i)) delete pThis-m_listCopyTableInfo.at(i); pThis-m_listCopyTableInfo.clear(); 上述代码展示了 BigTableWidget 的基本实现。需要注意的是，如果需要对数据进行排序，当前的数据结构可能会导致效率低下。因为每个 Item 的数据都被单独保存，排序时需要调整所有相关 Item 的顺序，并更新它们的行列信息。因此，针对排序的需求，可能需要考虑更高效的数据结构来存储和管理数据。","categories":["2.语言","Qt"]},{"title":"QTableWidget样式表","path":"/2025/02/22/2-语言-Qt-样式表-QTableWidget样式表/","content":"// 1. 均匀拉直表头ui-tableWidget-horizontalHeader()-setSectionResizeMode(QHeaderView::Stretch); // 设置水平表头的每一列均匀拉伸，确保表格的宽度被充分利用。ui-tableWidget-verticalHeader()-setSectionResizeMode(QHeaderView::Stretch); // 设置垂直表头的每一行均匀拉伸，使得表格的高度也被合理分配。// 2. 将表格宽度覆盖满ui-tableWidget-horizontalHeader()-setStretchLastSection(true); // 使最后一列的宽度自动扩展，以填满表格的剩余空间。ui-tableWidget-verticalHeader()-setStretchLastSection(true); // 使最后一行的高度自动扩展，以填满表格的剩余空间。 外观 #ifndef MAINWIDGET_H#define MAINWIDGET_H#include QWidgetQT_BEGIN_NAMESPACEnamespace Ui class MainWidget; QT_END_NAMESPACEclass MainWidget : public QWidget Q_OBJECTpublic: MainWidget(QWidget *parent = nullptr); // 构造函数，接受一个父窗口指针，默认为nullptr。 ~MainWidget(); // 析构函数，负责释放资源。private: Ui::MainWidget *ui; // 指向UI界面的指针，负责管理界面元素。;#endif // MAINWIDGET_H // mainwidget.cpp#include mainwidget.h#include ui_mainwidget.h#include QString#include QFile#include QTextStreamMainWidget::MainWidget(QWidget *parent) : QWidget(parent) // 调用父类构造函数，初始化父窗口。 , ui(new Ui::MainWidget) // 创建UI界面的实例。 ui-setupUi(this); // 设置UI界面，初始化所有界面元素。 ui-tableWidget-verticalHeader()-setVisible(true); // 显示垂直表头，便于用户查看行信息。 QString qss; // 用于存储样式表的字符串。 QFile file(:/style.css); // 创建文件对象，指向资源中的样式表文件。 if (file.open(QFile::ReadOnly)) // 以只读方式打开文件。 QStringList list; // 存储样式表每一行的列表。 QTextStream in(file); // 创建文本流对象，用于读取文件内容。 while (!in.atEnd()) // 循环读取文件，直到结束。 QString line; // 存储当前行的字符串。 in line; // 读取一行。 list line; // 将读取的行添加到列表中。 file.close(); // 关闭文件，释放资源。 qss = list.join( ); // 将列表中的行合并为一个字符串，以换行符分隔。 QString paletteColor = qss.mid(20, 7); // 从样式表中提取颜色信息，用于设置应用程序的调色板。 qApp-setPalette(QPalette(paletteColor)); // 设置应用程序的调色板，影响整个应用的颜色。 qApp-setStyleSheet(qss); // 应用样式表，改变界面的外观。 MainWidget::~MainWidget() // 析构函数实现 delete ui; // 释放UI界面资源，防止内存泄漏。 // main.cpp#include mainwidget.h#include QApplicationint main(int argc, char *argv[]) // 主函数，程序入口。 QApplication a(argc, argv); // 创建QApplication对象，管理应用程序的控制流和主要设置。 MainWidget w; // 创建MainWidget对象，表示主窗口。 w.show(); // 显示主窗口。 return a.exec(); // 进入事件循环，等待用户操作。 // style.css* outline: 0px; // 去掉所有元素的轮廓线。 color: #DCDCDC; // 设置文本颜色为浅灰色。 background: #444444; // 设置背景颜色为深灰色。QTableView border: 1px solid #242424; // 设置表格边框为深灰色。 selection-background-color: #646464; // 设置选中项的背景颜色。 selection-color: #DCDCDC; // 设置选中项的文本颜色。 alternate-background-color: #525252; // 设置交替行的背景颜色。 gridline-color: #242424; // 设置网格线颜色。QTableView::indicator padding: 0px; // 设置指示器的内边距为0。 width: 15px; // 设置指示器的宽度。 height: 15px; // 设置指示器的高度。QTableView::indicator:unchecked image:url(:/image/checkbox_unchecked.png); // 未选中状态下的指示器图标。QTableView::indicator:unchecked:disabled image:url(:/image/checkbox_unchecked_disable.png); // 禁用状态下的未选中指示器图标。QTableView::indicator:checked image:url(:/image/checkbox_checked.png); // 选中状态下的指示器图标。QTableView::indicator:checked:disabled image:url(:/image/checkbox_checked_disable.png); // 禁用状态下的选中指示器图标。QTableView::indicator:indeterminate image:url(:/image/checkbox_parcial.png); // 不确定状态下的指示器图标。QTableView::indicator:indeterminate:disabled image:url(:/image/checkbox_parcial_disable.png); // 禁用状态下的不确定指示器图标。QTableView::item:selected color: #DCDCDC; // 选中项的文本颜色。 background: #383838; // 选中项的背景颜色。QTableView::item:hover color: #DCDCDC; // 鼠标悬停时的文本颜色。 background: #525252; // 鼠标悬停时的背景颜色。QTableView::item padding: 1px; // 表格项的内边距。 margin: 0px; // 表格项的外边距。 border: 0px; // 表格项的边框。/* 表格样式 */QTableView QLineEdit,QTableView QComboBox,QTableView QSpinBox,QTableView QDoubleSpinBox,QTableView QDateEdit,QTableView QTimeEdit,QTableView QDateTimeEdit border-width: 1px; // 设置边框宽度。 border-radius: 0px; // 设置边框圆角为0。/* 选中表格后样式 (此处QLineEdit:focus生效) */QTableView QLineEdit:focus,QTableView QComboBox:focus,QTableView QSpinBox:focus,QTableView QDoubleSpinBox:focus,QTableView QDateEdit:focus,QTableView QTimeEdit:focus,QTableView QDateTimeEdit:focus background-color: #3fd4f2; // 焦点状态下的背景颜色。 border-width: 3px; // 焦点状态下的边框宽度。 border-radius: 5px; // 焦点状态下的边框圆角。/* 滚动条样式 */QScrollBar:horizontal background:#484848; // 水平滚动条的背景颜色。 padding:0px; // 水平滚动条的内边距。 border-radius:6px; // 水平滚动条的圆角。 max-height:12px; // 水平滚动条的最大高度。QScrollBar::handle:horizontal background:#242424; // 水平滚动条滑块的背景颜色。 min-width:50px; // 水平滚动条滑块的最小宽度。 border-radius:6px; // 水平滚动条滑块的圆角。QScrollBar::handle:horizontal:hover background:#AAAAAA; // 鼠标悬停时的水平滚动条滑块颜色。QScrollBar::handle:horizontal:pressed background:#AAAAAA; // 按下时的水平滚动条滑块颜色。QScrollBar::add-page:horizontal background:none; // 水平滚动条添加区域的背景颜色。QScrollBar::sub-page:horizontal background:none; // 水平滚动条减去区域的背景颜色。QScrollBar::add-line:horizontal background:none; // 水平滚动条添加线的背景颜色。QScrollBar::sub-line:horizontal background:none; // 水平滚动条减去线的背景颜色。QScrollBar:vertical background:#484848; // 垂直滚动条的背景颜色。 padding:0px; // 垂直滚动条的内边距。 border-radius:6px; // 垂直滚动条的圆角。 max-width:12px; // 垂直滚动条的最大宽度。QScrollBar::handle:vertical background:#242424; // 垂直滚动条滑块的背景颜色。 min-height:50px; // 垂直滚动条滑块的最小高度。 border-radius:6px; // 垂直滚动条滑块的圆角。QScrollBar::handle:vertical:hover background:#AAAAAA; // 鼠标悬停时的垂直滚动条滑块颜色。QScrollBar::handle:vertical:pressed background:#AAAAAA; // 按下时的垂直滚动条滑块颜色。QScrollBar::add-page:vertical background:none; // 垂直滚动条添加区域的背景颜色。QScrollBar::sub-page:vertical background:none; // 垂直滚动条减去区域的背景颜色。QScrollBar::add-line:vertical background:none; // 垂直滚动条添加线的背景颜色。QScrollBar::sub-line:vertical background:none; // 垂直滚动条减去线的背景颜色。/* 表头样式 QTableCornerButton::section是tablewidget左上角那一小块 详见https://blog.csdn.net/qq_43627907/article/details/125677496 */QHeaderView, QHeaderView::section, QTableView QTableCornerButton::section color: #DCDCDC; // 表头文本颜色。 background: #525252; // 表头背景颜色。QHeaderView::section, QTableCornerButton:section padding: 3px; // 表头的内边距。 margin: 0px; // 表头的外边距。 border: 1px solid #242424; // 表头的边框样式。 border-left-width: 0px; // 表头左边框宽度为0。 border-right-width: 1px; // 表头右边框宽度。 border-top-width: 0px; // 表头上边框宽度为0。 border-bottom-width: 1px; // 表头下边框宽度。QHeaderView::section:disabled background: #444444; // 禁用状态下的表头背景颜色。 border-color: #484848; // 禁用状态下的表头边框颜色。 color: #242424; // 禁用状态下的表头文本颜色。","tags":["clippings"],"categories":["2.语言","Qt","样式表"]},{"title":"表格QTableWidget","path":"/2025/02/22/2-语言-Qt-表格QTableWidget/","content":"QTableWidget 概述QTableWidget 是 QT 程序中常用的显示数据表格的组件，类似于 VC 和 C# 中的 DataGrid。它提供了一个直观的方式来展示和操作表格数据。为了更好地理解 QTableWidget，我们需要先了解它与 QTableView 的区别。 QTableWidget 与 QTableView 的区别QTableWidget 是 QTableView 的子类，二者的主要区别在于数据模型的使用。QTableView 允许开发者使用自定义的数据模型来显示内容，这意味着开发者需要通过 setModel 方法来绑定数据源。而 QTableWidget 则只能使用标准的数据模型，其单元格的数据是通过 QTableWidgetItem 对象来实现的。这意味着在使用 QTableWidget 时，开发者可以逐个填充单元格的信息，而不需要事先定义数据源。具体来说，QTableView 类中有 setModel 成员函数，而在 QTableWidget 类中，该成员函数被设为私有。 QTableWidgetItem 的重要性在使用 QTableWidget 时，QTableWidgetItem 是不可或缺的。它用于表示表格中的一个单元格，整个表格的构建都是基于这些单元格的。例如，开发者可以通过以下代码创建和设置单元格的内容： tableWidget-setItem(0, 0, new QTableWidgetItem(Jan)); 这行代码创建了一个新的 QTableWidgetItem 对象，并将其设置为第一行第一列的内容。 示例代码以下是一个简单的示例代码，展示了如何创建一个 QTableWidget 对象并设置其内容： #include QApplication#include QTableWidget#include QStringList#include QIconint main(int argc, char *argv[]) QApplication a(argc, argv); QTableWidget *tableWidget = newTableWidget(10, 5); // 创建一个10行5列的QTableWidget对象 tableWidget-setWindowTitle(QTableWidget Item); tableWidget-resize(350, 200); // 设置表格的大小 QStringList header; header Month Description // 设置表头 tableWidget-setHorizontalHeaderLabels(header); // 填充表格数据 tableWidget-setItem(0, 0, new QTableWidgetItem(Jan)); tableWidget-setItem(1, 0, new QTableWidgetItemFeb)); tableWidget-setItem(2, 0, new QTableWidgetItem(Mar)); tableWidget-setItem(0, 1, new QTableWidgetItem(QIcon(images/IED.png), Jans month)); tableWidget-setItem(1,1, new QTableWidgetItem(QIcon(images/IED.png), Febs month)); tableWidget-setItem(2, 1, new QTableWidgetItem(QIcon(images/IED.png), Mars month)); tableWidget-show(); // 显示格 return a.exec(); // 进入事件循环 获取单击单元格的内容要获取用户单击的单元格内容，可以通过实现 itemClicked(QTableWidgetItem *) 信号的槽函数。这样，开发可以获取鼠标单击到的单元格指针，并进一步获取其中的文字信息。例如： connect(tableWidget, SIGNAL(itemDoubleClicked(QTableWidgetItem*)), this, SLOT(getItem(QTableWidgetItem*))); 调整表格行宽和列宽在使用 QTableWidget 时，调整表格的行宽和列宽是常见的需求。可以使用以下函数： resizeColumnsToContents()：根据内容自动调整所有列的宽度。 resizeColumnToContents(int col)：根据内容自动调整指定列的宽度。 setColumnWidth(int column, int width)：设置指定列的宽度。 setRowHeight(int row, int height)：设置指定行的高度。 例如： tableWidget-setColumnWidth(3, 200); // 设置第四列宽度为200tableWidget-setRowHeight(3, 60); // 设置第四行高度为60 表格的其他设置开发者还可以进行其他设置，例如： setShowGrid(true)：显示表格线。 verticalHeader()-setVisible(false)：隐藏左侧的垂直表头。 setEditTriggers(QTableWidget::NoEditTriggers)：禁止编辑单元格。 setSelectionBehavior(QTableWidget::SelectRows)：一次选中一整行。 setSelectionMode(QAbstractItemView::SingleSelection)：只能单选。 如果希望去掉左边的行号，可以使用以下代码： QHeaderView* headerView = tableWidget-verticalHeader();headerView-setHidden(true); // 隐藏垂直表头 通过这些设置，开发者可以根据需求灵活地调整 QTableWidget 的外观和行为，以提供更好的用户体验。 QTableWidget 不能在 mainwindow 中随主窗口的大小变化？为了确保 QTableWidget 随着主窗口的大小变化而调整，可以在表格外部添加布局。这样，表格会自动适应父窗口的尺寸变化。 tableWidget = new QTableWidget;tableWidget-setObjectName(QString::fromUtf8(tableWidget));QVBoxLayout *verticalLayout = new QVBoxLayout; // 创建一个垂直布局verticalLayout-addWidget(tableWidget); // 将表格添加到布局中 将表格变为禁止编辑：通过设置编辑触发器，可以控制用户对表格内容的编辑权限。以下代码将表格设置为禁止编辑。 tableWidget-setEditTriggers(QAbstractItemView::NoEditTriggers); 参数含义： QAbstractItemView::NoEditTriggers：用户无法修改表格内容。 QAbstractItemView::CurrentChanged：用户可以在任何时候修改单元格。 QAbstractItemView::DoubleClicked：用户双击单元格时可以修改。 QAbstractItemView::SelectedClicked：用户单击已选中的内容时可以修改。 QAbstractItemView::EditKeyPressed：按下编辑键时可以修改。 QAbstractItemView::AnyKeyPressed：按下任意键时可以修改。 QAbstractItemView::AllEditTriggers：以上所有条件均可编辑。 设置表格为整行选择：通过设置选择行为，可以控制用户选择的方式。以下代码将表格设置为整行选择。 tableWidget-setSelectionBehavior(QAbstractItemView::SelectRows); // 整行选中的方式 参数含义： QAbstractItemView::SelectItems：选中单个单元格。 QAbstractItemView::SelectRows：选中整行。 QAbstractItemView::SelectColumns：选中整列。 单个选中和多个选中的设置：通过设置选择模式，可以控制用户的选择方式。以下代码允许用户选择多个目标。 tableWidget-setSelectionMode(QAbstractItemView::ExtendedSelection); // 设置为可以选中多个目标 参数含义： QAbstractItemView::NoSelection：不能选择。 QAbstractItemView::SingleSelection：只能选中单个目标。 QAbstractItemView::MultiSelection：可以选中多个目标。 QAbstractItemView::ExtendedSelection 和 QAbstractItemView::ContiguousSelection 的区别不明显，主要功能是正常情况下是单选，但按下 Ctrl 或 Shift 键后可以多选。 表格表头的显示与隐藏：可以通过以下代码来隐藏或显示表头。 tableWidget-verticalHeader()-setVisible(false); // 隐藏垂直表头 tableWidget-horizontalHeader()-setVisible(false); // 隐藏水平表头 对表头文字的字体、颜色进行设置：可以通过以下代码设置表头的字体和颜色。 QTableWidgetItem *columnHeaderItem0 = tableWidget-horizontalHeaderItem(0); // 获取水平表头的 Item 对象 columnHeaderItem0-setFont(QFont(Helvetica)); // 设置字体 columnHeaderItem0-setBackgroundColor(QColor(0, 60, 10)); // 设置单元格背景颜色 columnHeaderItem0-setTextColor(QColor(200, 111, 30)); // 设置文字颜色 在单元格里加入控件：可以在表格的单元格中添加控件，例如下拉框。 QComboBox *comBox = new QComboBox();comBox-addItem(Y);comBox-addItem(N);tableWidget-setCellWidget(0, 2, comBox); // 将下拉框添加到第一行第三列 单元格中添加图片：可以在单元格中添加图片，以下代码示例展示了如何在单元格中插入图标。 tableWidget-setItem(row, 0, new QTableWidgetItem(QIcon(:/new/images/kingdemo.ico), tr())); 设置单元格字体颜色、背景颜色和字体字符：可以通过以下代码设置单元格的字体、背景颜色和字体样式。 QTableWidgetItem *item = new QTableWidgetItem(Apple);item-setBackgroundColor(QColor(0, 60, 10));item-setTextColor(QColor(200, 111, 100));item-setFont(QFont(Helvetica));tableWidget-setItem(0, 3, item); // 将设置好的单元格项添加到第一行第四列 如果需要对所有单元格使用相同的字体，可以使用以下代码： tableWidget-setFont(QFont(Helvetica)); 设置单元格内文字的对齐方式：可以通过以下常量设置单元格内文字的水平和垂直对齐方式。 水平对齐方式： Constant Value DescriptionQt.AlignLeft 0x0001 Aligns with the left edge.Qt.AlignRight 0x0002 Aligns with the right edge.Qt.AlignHCenter 0x0004 Centers horizontally in the available space.Qt.AlignJustify 0x0008 Justifies the text in the available space. 垂直对齐方式： Constant Value DescriptionQt.AlignTop 0x0020 Aligns with the top.Qt.AlignBottom 0x0040 Aligns with the bottom.Qt.AlignVCenter 0x0080 Centers vertically in the available space. 如果需要同时设置水平和垂直对齐方式，可以使用按位或运算符： Qt.AlignHCenter | Qt.AlignVCenter 合并单元格：可以通过以下代码合并多个单元格。 tableWidget-setSpan(0, 0, 3, 1); // 合并第一行第一列的3行1列 设置单元格的大小：可以通过以下代码设置特定行或列的大小。 tableWidget-setColumnWidth(3, 200); // 设置第四列宽度为200tableWidget-setRowHeight(3, 60); // 设置第四行高度为60 还可以将行和列的大小设为与内容相匹配： tableWidget-resizeColumnsToContents(); // 根据内容调整所有列宽tableWidget-resizeRowsToContents(); // 根据内容调整所有行高 获得单击单元格的内容：通过实现 itemClicked(QTableWidgetItem *) 信号的槽函数，可以获得鼠标单击到的单元格指针，从而获取其中的文字信息。 connect(tableWidget, SIGNAL(itemDoubleClicked(QTableWidgetItem*, int)), this, SLOT(getItem(QTableWidgetItem*, int)));// 将 itemClicked 信号与函数 getItem 绑定 QTableWidget 要调整表格行宽主要涉及以下函数：通过以下代码可以调整表格的行宽和列宽。 tableWidget-horizontalHeader()-setResizeMode(QHeaderView::Stretch); // 列完全填充并平分tableWidget-verticalHeader()-setResizeMode(QHeaderView::Stretch); // 行自适应宽度 tableWidget-resizeColumnsToContents(); // 根据内容调整列宽tableWidget-resizeColumnToContents(int col); // 根据内容自动调整给定列宽 添加表头内容：可以通过以下两种方法添加表头内容。 方法一： QStringList header;header Column 1 Column 2 Column 3; // 添加列名tableWidget-setHorizontalHeaderLabels(header); // 设置表头 方法二： tableWidget-setHorizontalHeaderLabels(QStringList() tr(1) tr(2) tr(3)); // 直接设置表头 清除：可以通过以下代码清除表格中的内容。 tableWidget-clear(); // 清除所有可见数据（包括表头），行还在tableWidget-clearContents(); // 只清除表中数据，不清除表头内容tableWidget-setRowCount(0); // 清除所有行 一些零碎的知识点代码：下面是一些常用的操作代码示例。 int row = tableWidget-rowCount(); // 获取表格中当前总行数tableWidget-setRowCount(row + 1); // 添加一行tableWidget-removeRow(row); // 清除已有的行int row1 = tableWidget-currentItem()-row(); // 获取当前选中行bool focus = tableWidget-isItemSelected(tableWidget-currentItem()); // 判断是否选中一行QString proName = tableWidget-item(row, col)-text(); // 获取某一格内容tableWidget-setShowGrid(true); // 显示表格线tableWidget-verticalHeader()-setVisible(false); // 隐藏左边垂直表头QHeaderView *headerView = tableWidget-horizontalHeader();headerView-setMovable(false); // 去除表头的移动headerView-resizeSection(0, 284); // 设置第一列宽headerView-resizeSection(1, 127); // 设置第二列宽headerView-setResizeMode(QHeaderView::Fixed); // 列表不能移动headerView-setClickable(false); // 不响应鼠标单击tableWidget-setEditTriggers(QTableWidget::NoEditTriggers); // 不能编辑tableWidget-setSelectionBehavior(QTableWidget::SelectRows); // 一次选中一行tableWidget-setSelectionMode(QAbstractItemView::SingleSelection); // 只能单选// QScrollBar *scrollBar = tableWidget-horizontalScrollBar();// scrollBar-hide(); // 隐藏水平滚动条tableWidget-setHorizontalScrollBarPolicy(Qt::ScrollBarAlwaysOff); // 去掉水平滚动条tableWidget-setVerticalScrollMode(QAbstractItemView::ScrollPerItem); // 垂直滚动条按项移动tableWidget-setAutoScroll(false); // 去掉自动滚动 排序：可以通过以下代码对表格的某一列进行排序。 tableWidget-sortByColumn(0, Qt::AscendingOrder); // 将第一列按升序排列 点击表头设置单元格排序在 QT C++中，QTableWidget 提供了方便的排序功能，可以通过点击表头进行排序。本文将详细介绍两种实现方法，并提供完整的代码示例和使用场景说明。 方法一：启用默认排序功能QTableWidget 提供了一个简单的方法来启用排序功能，即通过调用 setSortingEnabled(true) 方法。这种方法的优点是实现简单，适用于大多数默认的排序需求。 代码示例QTableWidget *tableWidget = new QTableWidget(this);tableWidget-setRowCount(5);tableWidget-setColumnCount(3);tableWidget-setSortingEnabled(true); // 启用排序功能 详细说明 实现原理：setSortingEnabled(true) 会自动根据表格中每一列的数据类型（如数字、文本、日期等）进行排序。例如： 数字列会按照从小到大或从大到小的顺序排列。 文本列会按照字母顺序排列。 日期列会按照时间顺序排列。 适用场景： 适用于需要快速实现简单排序的场景。 适用于数据类型为 QT 内置类型（如 int、QString、QDateTime）的表格。 优缺点： 优点：实现简单，代码量少。 缺点：排序逻辑完全由 QT 控制，无法自定义排序规则。 方法二：自定义排序实现如果需要更灵活的排序功能，可以通过 QHeaderView 的 sectionClicked 信号来实现自定义排序。这种方法适用于需要自定义排序逻辑的场景。 代码示例// 在表头单击时触发排序horizontalHeader()-setSectionsClickable(true);connect(horizontalHeader(), QHeaderView::sectionClicked, this, CustomTableWidget::onHeaderClicked);// 自定义排序槽函数void CustomTableWidget::onHeaderClicked(int logicalIndex) // 获取当前排序列 int column = logicalIndex; // 设置排序方式（升序或降序） Qt::SortOrder order = (horizontalHeader()-sortIndicatorOrder() == Qt::AscendingOrder) ? Qt::DescendingOrder : Qt::AscendingOrder; horizontalHeader()-setSortIndicator(column, order); // 根据排序列和排序方式对表格项进行排序 sortItems(column, order);// 自定义排序函数void CustomTableWidget::sortItems(int column, Qt::SortOrder order) // 获取行数 int row_count = tableWidget-rowCount(); // 获取所有行数据 QListQTableWidgetItem* items; for (int i = 0; i row_count; i++) items tableWidget-item(i, column); // 自定义排序逻辑 std::sort(items.begin(), items.end(), [](QTableWidgetItem* a, QTableWidgetItem* b) // 根据不同数据类型实现不同的排序规则 if (a-text().isdigit() b-text().isdigit()) // 数字排序 return order == Qt::AscendingOrder ? a-text().toInt() b-text().toInt() : a-text().toInt() b-text().toInt(); else // 文本排序 return order == Qt::AscendingOrder ? a-text() b-text() : a-text() b-text(); ); // 将排序后的数据重新填充到表格 for (int i = 0; i row_count; i++) tableWidget-setItem(i, column, items[i]); 详细说明 实现原理： 通过 QHeaderView::sectionClicked 信号捕获表头单击事件。 在自定义槽函数中，获取点击的列索引和排序方式（升序或降序）。 调用自定义的 sortItems 函数对表格项进行排序。 适用场景： 需要自定义排序逻辑的场景。 表格中的数据类型为自定义类型或需要特殊处理的类型。 优缺点： 优点：可以完全自定义排序逻辑，灵活性强。 缺点：实现复杂，代码量较大。 注意事项 数据类型影响排序： 确保表格中的数据类型与排序逻辑匹配。例如，文本形式的数字需要先转换为数值类型再排序。 表格刷新： 在自定义排序后，可能需要调用 tableWidget-viewport()-update() 刷新表格。 性能问题： 对于大数据量的表格，自定义排序可能会导致性能问题。可以通过优化排序算法或使用数据库排序来解决。","categories":["2.语言","Qt"]},{"title":"循环语句","path":"/2025/02/22/2-语言-C语言-循环语句/","content":"基本结构 顺序结构、选择结构、循环结构 在生活中我们常常遇到需要重复处理的问题，我们在编程时解决需要重复处理的问题需要使用循环语句 循环语句主要有 3 种：while()循环；do-while()循环和 for()循环 while()循环用法： while(循环条件)\t循环体;\t…… 当程序遇到 while()循环的时候，首先会判断 while()的括号内的表达式，若为真（即满足循环条件）则执行循环，执行完循环体后再次返回到 while()；若为假则结束循环 示例：输入 10 个学生的成绩，输出这 10 个学生的成绩总和以及平均分 int main()\tint i = 1,count = 0,input = 0;//i用来控制循环次数，count用于总和，input用于每次输入\tfloat avg = 0;//avg用于平均分\twhile(i=10)//循环条件 printf(请输入第%d个学生的成绩： ,i); scanf(%d,input); count += input; i++;//不要忘了让i++ avg = (float)count/10;\tprintf(总成绩是%d 平均成绩是%f ,count,avg);\treturn 0; 思考：若在循环体中没有 i++这一句将会发生什么结果？ i++这一句的作用是改变循环的状态。若没有 i++这句，则 i 的值会永远是 1，则循环永远都不会结束，即程序会进入死循环 初学者在使用循环时一定要注意不要陷入死循环。当你的程序使用了循环结构，在编译阶段无语法错误，在执行时发现程序会无限期进行下去，则很可能你的程序进入了死循环。此时要检查循环条件设置是否正确，以及检查是否设置了改变循环状态的量。 若 while()后没有{}限制，则循环只执行到 while()后第一个分号处（即只执行一条语句），这点与 if()-else 相同 do-while()循环用法： do\t循环体;\t……while(循环条件); 当程序遇到 do，会首先执行 do 下面的语句（即循环体），之后执行到 while()，判断 while()的括号内的表达式是真假，若为真（即满足循环条件）则返回 do 语句处再次执行循环体；若为假则结束循环。 示例：将上文示例改写成 do-while()循环 int main()\tint i = 1,count = 0,input = 0;//i用来控制循环次数，count用于总和，input用于每次输入\tfloat avg = 0;//avg用于平均分\tdo//循环开始 printf(请输入第%d个学生的成绩： ,i); scanf(%d,input); count += input; i++;//不要忘了让i++\twhile(i=10);//循环条件\tavg = (float)count/10;\tprintf(总成绩是%d 平均成绩是%f ,count,avg);\treturn 0; while()与 do-while()的区别： while()循环是先判断循环条件，再进入循环体。而 do-while()循环是先进入循环体，再判断循环条件。 while()循环有可能不执行循环体，而 do-while()循环一定会执行一次循环体 for()循环用法： for(表达式 1;表达式 2;表达式 3)\t循环体;\t…… 注意：for()括号内的 3 个表达式的分隔符是分号;不是逗号, 表达式 1：循环的初始条件，只执行一次。可以为 0 个、1 个或多个变量设置初值 表达式 2：判断循环结束的条件。在每次执行循环体前判断此表达式，若表达式为真则进入循环，否则不执行循环 表达式 3：作为循环的调整（即改变循环状态），在执行完循环体之后执行 等价于： 表达式 1;while(表达式 2)\t循环体;\t表达式3; 表达式 1 可以省略。若如此做，相当于没有给 for()循环设定起始初值。因此，若要循环正常进行，需要在 for()之前设置好循环起始初值 表达式 2 可以省略。若如此做，相当于 for()循环没有结束条件，即死循环。等价于： while(1)\t循环体;\t表达式3; 表达式 3 可以省略。若如此做，需要在循环体内设置循环调整语句，否则循环无法正常执行。 若将 3 个表达式都省略（即 for(;;)），则相当于设置了一个无限循环 若 for()后没有{}限制，则循环只执行到 for()后第一个分号处（即只执行一条语句），这点与 if()-else 相同 三种循环的比较：1）如果使用 while()或 do-while()，需要注意在循环体内设置改变循环状态的变量。而 for()循环则是在表达式 3 中设置 2）一般来说，for()循环的表达式 3 的位置甚至可以将循环体都放入，所以 for()循环更常用 3）在知道循环次数的情况下，推荐使用 for()循环；在不知循环次数的情况下推荐使用 while()或 do-while()循环 4）从 C99 版本开始，C 语言支持以下用法： for(int i=0;i10;i++)\t循环体;\t…… 这样就可以不用事先特地定义一个用于循环的变量，随时使用随时定义即可。 注意 1：这种使用方式循环变量 i 的生命周期仅仅是在 for()循环中，当 for()循环结束 i 即结束其生命周期。如果这样使用： for(int i=0;i10;i++)\t循环体;\t……printf(%d,i);//此时 i 的生命周期已经结束，企图访问不存在的变量 i，非法 则编译会显示语法错误。 注意 2：这种用法仅支持 C99 及以后 C 语言版本的编译器，如果这样使用出现语法错误则证明其编译器版本不支持这种语法，请不要使用这种语法而是在 for()循环开始前就定义循环变量。 循环的嵌套使用一个循环体内又包含一个循环体的结构称之为循环的嵌套。内嵌循环还可以再嵌套循环。3 种循环都是可以互相嵌套使用的。例如下面的例子都是合法的： 1） while()\tdo while(); 2） for(;;)\twhile() 3） do\tfor() while(); 提前结束循环语句：continue、break、return、exit() continuecontinue 语句的用法是： continue; 其作用是结束本次循环，即跳过所有 continue 下的语句，进入下次循环。 breakbreak 语句的用法是： break; 其作用是结束循环，执行循环体外的下一个语句 回顾：break 在 switch()语句中的作用 break 在 switch()语句中的作用是跳出 switch()语句，执行 switch()语句下一条语句。 returnreturn 语句的用法是： return 需要的返回值; 其中需要的返回值由函数类型决定。如 main()函数是 int 类型，则需要返回一个整数。如果函数是 void 类型则无需写返回值。 return 语句的作用是结束当前函数，并将返回值返回给函数调用的位置。 有关 return 语句的用法我们将在函数的课程中详细讲解。 需要注意的是 return 不仅仅是结束了循环，更是结束了当前的函数。因此要慎用。 exitexit 语句的用法是： exit(x);//x 为 0 或正整数 当 x 为 0 时表示正常结束，不为 0 时表示异常结束（异常号） exit()在头文件 stdlib.h 中 exit()不仅仅是结束循环，它的真正意义是退出当前程序。因此非常不推荐使用 exit()结束循环 从效果来看，4 个语句的效果如下： exit() return break continue强----------------------------弱 goto 语句用法： goto 语句标号; 说明： goto 语句是无条件跳转语句，当执行到 goto 语句时，程序会跳转到 goto 语句所指向的标号处。语句标号的命名规则与 C 语言标识符的命名规则相同。 示例： int main()\tlabel_1:\t……\t……\tgoto label_1; 滥用 goto 语句会使程序无规律、可读性差。goto 语句违背了 C 语言的模块化编程的基本思想，因此 goto 语句不推荐使用。","categories":["2.语言","C语言"]},{"title":"Android 12 操作指南  两仪","path":"/2025/02/22/5-生活-手机相机游戏机-Android-12-操作指南-两仪/","content":"由于 Android 12 上，Google 引入的 phantom processes 机制会影响两仪的运行，需要使用 ADB 来解除此限制；请按照如下指南操作： 去 B 站观看 视频中的 ADB 指令： systembindevice_config set_sync_disabled_for_tests persistent; systembindevice_config put activity_manager max_phantom_processes 2147483647 如果你不再使用两仪，并且想恢复上述指令的影响，可以执行如下指令恢复： systembindevice_config set_sync_disabled_for_tests none; systembindevice_config put activity_manager max_phantom_processes 32 如果你使用的是 Android 13 或更高系统，可以使用如下命令来解除限制： settings put global settings_enable_monitor_phantom_procs false Android 13 的恢复指令： settings put global settings_enable_monitor_phantom_procs true 说明： 如果有 root 权限，可以直接用 root 权限执行上述命令；无需 ADB。 执行完这个命令以后，相应的辅助 App（如视频中的黑阈）可以卸载。 Android 13 以上两种指令都可以，推荐第二种。 PS C:\\Program Files\\Netease\\MuMu Player 12\\shell .\\adb.exe devices* daemon not running; starting now at tcp:5037* daemon started successfullyList of devices attached9CN0223B02021084 unauthorizedPS C:\\Program Files\\Netease\\MuMu Player 12\\shell .\\adb.exe shell /system/bin/device_config set_sync_disabled_for_tests persistent;PS C:\\Program Files\\Netease\\MuMu Player 12\\shell .\\adb.exe shell /system/bin/device_config put activity_manager max_phantom_processes 2147483647PS C:\\Program Files\\Netease\\MuMu Player 12\\shell .\\adb.exe shell settings put global settings_enable_monitor_phantom_procs falsePS C:\\Program Files\\Netease\\MuMu Player 12\\shell .\\adb.exe shell /system/bin/dumpsys activity settings | findstr max_phantom_processes max_phantom_processes=2147483647","tags":["clippings"],"categories":["5.生活","手机相机游戏机"]},{"title":"HTML内嵌Markdown编辑器_html嵌入markdown-CSDN博客","path":"/2025/02/22/2-语言-工具语言-HTML内嵌Markdown编辑器-html嵌入markdown-CSDN博客/","content":"实现步骤1、获取markdown的开源库，这里用的是开源项目showdown。将showdown.min.js拷贝到项目中，需要的其他扩展可通过setOption(“扩展名”,true)去启动。 showdown: https://github.com/showdownjs/showdown 2、选择喜欢的Markdown样式，下载引用该css到自己的项目，还可以适当修改样式。 李笑来老师的https://gist.github.com/xiaolai/aa190255b7dde302d10208ae247fc9f2 少数派主题: https://cdn.sspai.com/sspai.css Mweb主题: https://cdn.sspai.com/MWeb.css Github主题: https://github.com/sindresorhus/github-markdown-css typora主题合集下载: https://theme.typora.io/ 3、按照showdown和选择的样式要求的格式来书写html文件。我这里用的是Github主题。Github主题的使用方式：showdown.min.js的使用方式：其他扩展选项：实现代码： !DOCTYPE htmlhtmlhead meta charset=UTF-8 meta name=viewport content=width=device-width, initial-scale=1 titlehtml内嵌markdown/title script src=showdown.min.js/script link rel=stylesheet type=text/css href=github-markdown.css/headbody style #editor display: flex; min-height: 600px; width: 100%; #md-area width: 100%; background: #f5f5f5; border: 1px solid #111; #view-area width: 100%; border: 1px solid #111; /*Github主题要求的样式引入*/ .markdown-body box-sizing: border-box; min-width: 200px; max-width: 980px; margin: 0 auto; padding: 45px; @media (max-width: 767px) .markdown-body padding: 15px; /stylediv id=editor textarea id=md-area onkeyup=mdConverter()/textarea !-- 键盘每次点击实时调用 -- article id=view-area class=markdown-body !-- github主题样式应用 -- /article/divscript function mdConverter() var md = document.getElementById(md-area).value; var converter = new showdown.Converter(); //增加拓展table converter.setOption(tables, true); //启用表格选项。从showdown 1.2.0版开始，表支持已作为可选功能移入核心拓展，showdown.table.min.js扩展已被弃用 var view = converter.makeHtml(md); document.getElementById(view-area).innerHTML = view; /script/body/html 效果： 参考文章：https://www.jianshu.com/p/a57114bd9380https://www.jianshu.com/p/7bb05fc9b7f0","tags":["clippings"],"categories":["2.语言","工具语言"]},{"title":"模态窗口","path":"/2025/02/19/2-语言-Qt-模态窗口/","content":"假设程序正常运行时，只有一个简单的窗体 A，此时只有一个 GUI 主线程。在这个主线程中，有一个事件循环负责处理窗体上的各种事件，比如用户的点击、键盘输入等。当程序运行到某个阶段时，弹出一个模态窗体 B。根据书中的定义，模态窗体是有其自己的事件循环的。在这种情况下，模态窗体 B 并不会创建一个新的子线程来处理其事件循环，而是会在主线程中运行其事件循环。 问题分析这里实际上有两个问题需要澄清： 模态窗体的事件循环：模态窗体 B 在弹出时，会阻塞主窗体 A 的交互。这意味着用户必须先处理模态窗体 B 的内容，才能返回到主窗体 A。模态窗体 B 的事件循环会在主线程中运行，而不是在一个新的子线程中。 QDialog 的用法：在 Qt 中，QDialog 是一个常用的对话框类，提供了两种常规用法： 非模态对话框： QDialog * dlg = new QDialog();dlg-show(); 在这种情况下，QDialog 对象被分配在堆上（heap），这并不是必须的，但使用指针可以方便地管理对话框的生命周期。如果你发现窗口一闪而过，可能是因为变量的作用域和生存周期不当。 模态对话框： QDialog dlg;dlg.exec(); 这里，QDialog 对象通常分配在栈上（stack），这意味着它的生命周期与当前作用域相同。如果你更喜欢使用堆，也可以这样做： QDialog * dlg = new QDialog();dlg-exec();delete dlg; 模态与非模态的区别模态对话框与非模态对话框的主要区别在于用户交互的限制。要使一个 Widget 成为模态，只需设置其属性： setAttribute(Qt::WA_ShowModal, true); 这意味着 QWidget 可以被设置为模态或非模态。 设置窗体模态除了直接调用 setAttribute，QWidget 还提供了一个更易用的函数来设置窗体的模态： void QWidget::setWindowModality(Qt::WindowModality windowModality) data-window_modality = windowModality; setAttribute(Qt::WA_ShowModal, (data-window_modality != Qt::NonModal)); setAttribute(Qt::WA_SetWindowModality, true); 这里的参数取值包括 NonModal、WindowModal 和 ApplicationModal，分别对应不同的模态行为。 模态对话框模态对话框是一种用户界面元素，当它弹出时，整个应用程序窗口会被锁定，用户无法与其他部分进行交互，直到该对话框被关闭。这种设计确保用户在做出选择之前，无法进行其他操作。例如，当用户在保存文件时，弹出的模态对话框会要求用户确认是否保存更改。用户必须点击“确定”或“取消”按钮来关闭对话框，程序会根据用户的选择执行相应的操作，比如保存文件或放弃更改。只有在模态对话框关闭后，用户才能再次与应用程序的其他窗口进行交互。 简单来说，模态对话框的作用是强制用户完成某项任务或做出选择，确保他们的输入被处理。例如，在填写在线表单时，系统可能会弹出一个模态对话框，询问用户是否确认提交信息。用户必须在对话框中做出选择，才能继续进行。 非模态对话框非模态对话框，也称为无模式对话框，与模态对话框不同。当非模态对话框弹出时，用户仍然可以自由地与其他窗口进行交互。这种设计允许用户在处理对话框的同时，继续使用应用程序的其他功能。例如，用户可以在一个非模态对话框中查看帮助信息，同时在主窗口中编辑文档。这种灵活性使得用户体验更加顺畅，尤其是在需要同时处理多个任务时。 半模态对话框半模态对话框是一种介于模态和非模态之间的对话框。它会阻塞用户对某些窗口的响应，但不会影响后续代码的执行。这意味着，虽然用户无法与某些部分进行交互，但程序仍然可以继续执行其他操作。例如，用户在进行数据输入时，可能会弹出一个半模态对话框，提示用户输入有效的数据。此时，用户无法关闭该对话框，但程序可以继续执行其他不依赖于该输入的代码。这种设计在某些情况下可以提高效率，确保用户在完成特定任务时不会被完全锁定。 Qt 中的模态、非模态和半模态QWidget 提供了 setWindowModality() 方法，用于设置窗口的模态状态，可以选择半模态或非模态。 Qt::NonModal该窗口为非模态窗口，不会阻塞其他窗口的输入。示例：在一个文本编辑器中打开一个非模态的设置窗口，用户可以同时编辑文本而不受设置窗口的影响。 Qt::WindowModal该窗口为窗口级模态窗口，只会阻塞其父窗口、父窗口的父窗口及兄弟窗口。示例：在一个图形设计软件中，打开一个颜色选择器窗口，用户必须先选择颜色才能返回到主窗口进行设计。 Qt::ApplicationModal该窗口为应用程序级模态窗口，会阻塞整个应用程序的所有窗口。示例：在一个文件管理器中，打开一个确认删除的对话框，用户必须先确认或取消操作才能继续使用文件管理器。 setWindowModality() 方法用于设置窗口的模态状态。根据上图，Qt::WindowModality 的默认值为 Qt::NonModal，这意味着如果没有设置模态属性，使用 show() 方法显示的窗口将始终是非模态窗口。 QDialog 还提供了 setModal 方法： void QDialog::setModal(bool modal) setAttribute(Qt::WA_ShowModal, modal); 要显示模态对话框，只需简单的代码： QDialog * dlg = new QDialog();dlg-setAttribute(Qt::WA_ShowModal, true);dlg-show(); show() ——非模态对话框 show() 方法用于显示窗口及其子窗口。使用此方法时，窗口会以非模态的形式出现，用户可以自由切换到其他窗口。 open() ——半模态对话框 使用 open() 方法显示的对话框为窗口级模态对话框，并且该方法会立即返回，允许后续代码继续执行。open() 方法的行为类似于以下代码： QDialog *dialog = new QDialog(this);dialog-setWindowModality(Qt::WindowModal);dialog-show(); 在这个例子中，用户可以在打开对话框的同时继续与其他窗口交互。 exec() ——模态对话框 exec() 方法是模态对话框的关键，它直接显示模态对话框： int QDialog::exec() Q_D(QDialog); setAttribute(Qt::WA_ShowModal, true); show(); QEventLoop eventLoop; return eventLoop.exec(QEventLoop::DialogExec); 在这里，exec() 方法首先设置模态属性，然后调用 show() 显示对话框，最后启用事件循环。 使用 exec() 方法显示的对话框为模态对话框，调用此方法会阻塞之前窗口的响应，直到用户关闭对话框。exec() 方法返回一个 DialogCode，通常包括 Accepted 和 Rejected 两个值，程序可以根据返回值执行不同的操作。 如果没有设置 Qt::WindowModality 属性，使用 exec() 方法显示的对话框默认为应用程序级模态对话框。这意味着在对话框关闭之前，整个应用程序的所有窗口都将被阻塞，后续代码也会在对话框关闭后才继续执行。 事件循环事件循环的工作原理Qt 程序是事件驱动的。每个程序需要调用 QApplication::exec() 来启动事件循环： int QCoreApplication::exec() QEventLoop eventLoop; return eventLoop.exec(); 事件循环的核心是处理各种事件，比如用户输入、窗口重绘等。QEventLoop::exec() 方法会在内部循环中处理这些事件，直到退出条件满足。 事件循环的启动与基本概念 事件循环通常通过 exec() 函数启动。在 Qt 中，QApplication::exec() 和 QMessageBox::exec() 都是事件循环的实例，其中 QApplication::exec() 被称为主事件循环。事件循环的核心是一个无限循环，程序在 exec() 内部持续运行，直到某个条件触发使其退出。这意味着在 exec() 后面的代码不会被执行，直到事件循环被终止。要终止事件循环，可以调用 QEventLoop::quit() 方法。 事件循环之所以被称为“事件”循环，是因为它能够接收和处理各种事件。当事件数量过多，无法立即处理时，这些待处理的事件会被放入一个称为“事件循环队列”的结构中。事件循环会逐个处理这些事件，每处理完一个事件，就从队列中取出下一个事件进行处理。当事件循环队列为空时，事件循环的行为与一个什么都不做的永真循环相似，但不同的是，事件循环不会大量占用 CPU 资源。实际上，事件循环的本质是通过队列的方式来合理分配线程的时间片，从而实现高效的事件处理。 事件循环的嵌套特性 事件循环支持嵌套，这意味着可以在一个事件循环中启动另一个事件循环。当子事件循环执行 exec() 时，父事件循环会被中断，暂停其执行。只有当子事件循环完成并跳出 exec() 后，父事件循环才能继续运行。这种机制允许开发者在处理复杂的用户交互时，能够灵活地管理事件处理流程。 另外，子事件循环几乎继承了父事件循环的所有功能。Qt 会将事件发送到当前活跃的事件循环队列中，包括各种 GUI 事件。因此，即使在主线程中执行了多个 exec()（例如 QMessageBox::exec() 或 QEventLoop::exec()），这些调用虽然打断了 main() 中的 QApplication::exec()，但 GUI 界面仍然能够正常响应用户的操作。这种设计确保了用户界面的流畅性和响应性。 父子事件循环的退出机制 如果某个子事件循环仍然有效，但其父事件循环被强制跳出，父循环不会立即执行退出操作。相反，父循环会等待子事件循环完成并跳出后，才会继续执行退出。这种设计保证了事件处理的顺序性和一致性，避免了在事件处理过程中可能出现的状态不一致问题。例如，如果在一个对话框中打开了一个子事件循环，用户在对话框中进行操作，只有在对话框关闭后，父事件循环才会继续执行。这种机制使得事件处理更加可靠，确保了用户体验的连贯性。 事件循环与线程的关系事件循环和线程之间没有必然的联系。事件循环可以在 QThread 中使用，从 Qt 4.4 开始，QThread 的 run 函数默认会调用自己的事件循环。当模态对话框的 QEventLoop 启用时，主程序的事件循环会处于暂停状态。实际上，这形成了两个嵌套的事件循环：一个在内，一个在外。只有内部的循环结束后，外部的循环才会继续执行。 总结来说，模态对话框的事件循环在主线程中运行，而不是在子线程中。理解这一点对于开发 Qt 应用程序至关重要，因为它影响了用户交互和程序的响应性。","tags":["clippings"],"categories":["2.语言","Qt"]},{"title":"Qt对话框之二：模态、非模态、半模态对话框","path":"/2025/02/19/2-语言-Qt-Qt对话框之二：模态、非模态、半模态对话框/","content":"目录 一、模态对话框 二、非模态对话框 三、半模态对话框 四、扩展1：QWidget作为半模态窗口显示 五、扩展2：QWidget模态对话框不模态的问题 一、模态对话框模态对话框：阻塞同一应用程序中其它可视窗口输入的对话框。启动模态对话框时，例如弹出对话框强制用户从其他正在进行的业务中聚焦到当前对话框，除了该对话框整个应用程序窗口都无法接受用户响应。只有关闭和退出该模态界面，才可以访问本应用程序的其他界面和功能。 显示模态对话框最常见的方法是调用其 exec() 函数，当用户关闭对话框，exec() 将提供一个有用的返回值，并且这时流程控制继续从调用 exec() 的地方进行。通常情况下，要获得对话框关闭并返回相应的值，我们连接默认按钮，例如：”确定”按钮连接到 accept() 槽，”取消”按钮连接到 reject() 槽。另外我们也可以连接 done() 槽，传递给它 Accepted 或 Rejected。 示例代码1： Widget *pWidget = new Widget();pWidget-setWindowTitle(QStringLiteral(主界面));pWidget-show(); CustomDialog *pDialog = new CustomDialog(pWidget);pDialog-setWindowTitle(QStringLiteral(模态对话框)); // 关键代码pDialog-exec();// 或者//pDialog-setModal(true);//pDialog-show(); // 关闭模态对话框以后才会执行下面的代码pWidget-setWindowTitle(QStringLiteral(主界面-模式对话框));qDebug() QStringLiteral(关闭模态对话框以后，可以继续向下执行); 示例代码2： 我们可以通过调用 accept() 或者是 reject() 函数来是使得 exec() 函数结束代码如下： //可以在之前的代码的快要结束的额时候调用accept();然后在主函数中login *user_login=new login;//login是继承dialog的类int res = user_login-exec();if (res == QDialog::Accepted)\tdelete user_login; 二、非模态对话框非模态对话框：和同一个程序中其它窗口操作无关的对话框。与模态对话框相反，允许用户同时与应用程序的主窗口和对话框进行交互，调用 show() 来显示非模式对话框，并立即将控制返回给调用者。 示例代码： Widget *pWidget = new Widget();pWidget-setWindowTitle(QStringLiteral(主界面));pWidget-show(); CustomDialog *pDialog = new CustomDialog(pWidget);pDialog-setWindowTitle(QStringLiteral(非模式对话框)); // 关键代码pDialog-show(); // 下面的代码会立即运行pWidget-setWindowTitle(QStringLiteral(主界面-非模式对话框));qDebug() QStringLiteral(立即运行); 主界面不会被阻塞，可以进行点击、拖动等任何操作。 show() 之后的代码会立即执行。 三、半模态对话框半模态对话框：介于二者之间，冻结窗口界面，但其他应用继续执行响应。调用 setModal(true) 或者 setWindowModality(Qt::WindowModal)，然后 show()。有别于 show() 立即返回给控制调用者。 Widget *pWidget = new Widget();pWidget-setWindowTitle(QStringLiteral(主界面));pWidget-show(); CustomDialog *pDialog = new CustomDialog(pWidget);pDialog-setWindowTitle(QStringLiteral(半模式对话框)); // 关键代码pDialog-setModal(true);pDialog-show(); // 下面的代码会立即运行pWidget-setWindowTitle(QStringLiteral(主界面-半模式对话框));qDebug() QStringLiteral(立即运行); 主界面被阻塞，不能进行点击、拖动等任何操作。 show()之后的代码却会立即执行。 QDialog 实现模态和非模态很简单，但是对于 QWidget 有点迷茫，QWidget 中没有 exec()，也没有 setModal() 方式，要实现半模态窗口只有以下两种方法： 方法1：setWindowModality方法 Qt 中的 QWidget 对象自带 setWindowModality(type) 方法，用以设置窗口模态类型。参数 type 可选为一下三种： Qt::NonModal 非模态：正常模式 Qt::WindowModal 半模态：窗口级模态对话框，阻塞父窗口、父窗口的父窗口及兄弟窗口。 Qt::ApplicationModal 模态：应用程序级模态对话框，阻塞整个应用程序的所有窗口。（实际上也只是半模态） QWidget *pWidget = new QWidget();pWidget-setWindowModality(Qt::ApplicationModal);pWidget-show(); 但是运行发现并未实现模态效果，只是实现了半模态。 方法2：setAttribute方法 设置部件（或窗口）属性也可以： pWidget-setAttribute(Qt::WA_ShowModal, true); // 属性设置 true:模态 false:非模态 备注：QWidget 实际上实现不了真正的模态窗口，只能实现半模态窗口。 自定义 QWidget 对话框，通过函数this-setWindowFlags(Qt::FramelessWindowHint | Qt::WindowStaysOnTopHint);设置了对话框的显示设置后，会导致该对话框在模态显示的时候如果设置了父窗口指针，会导致模态的设置无效，这时需要在该函数中加一个参数Qt::Dialog就可以了。 PS：如果不传父窗口的指针，模态也是有效的，只是这样在任务栏上弹出的窗口也会有一个独立的图标，并且在任务管理其中会多一个任务出现，这样感觉不是太好。设置父窗口后，任务栏和任务管理器中就都合并为一个了。 参考： Qt 之模式、非模式、半模式对话框 Qt 模态对话框不模态的问题","tags":["clippings"],"categories":["2.语言","Qt"]},{"title":"量化平台及API","path":"/2025/02/13/5-生活-金融-策略学习-量化平台及API/","content":"国内量化平台 掘金量化 支持多种编程语言，包括 CC++、C#、MATLAB、Python 和 R，适合不同背景的开发者。 提供全面的量化交易工具，适合高频交易和算法交易。 DigQuant 专注于 MATLAB 用户，提供量化工具，适合金融工程师和学术研究者。 SmartQuant 提供策略交易平台，支持多种金融产品的算法交易。 OpenQuant 基于 C#的开源量化回测平台，适合.NET 开发者进行策略开发和测试。 BigQuant 人工智能量化平台，支持无门槛使用机器学习和人工智能，提供策略自动生成器，基于 Python。 镭矿 提供量化回测平台，支持策略开发和测试。 果仁网 提供回测量化平台，适合策略验证和优化。 京东量化 算法交易和量化回测平台，支持多种金融产品。 聚宽 提供量化回测平台，适合个人投资者和机构。 优矿 通联量化实验室，提供量化研究和策略开发工具。 Ricequant 量化交易平台，支持多种金融产品的算法交易。 况客 基于 R 语言的量化回测平台，适合数据分析师和统计学家。 Factors 数库多因子量化平台，专注于多因子策略研究。 诸葛量化 提供量化交易平台，支持策略开发和执行。 宽狗量化 提供回测量化平台，适合策略测试和优化。 文华赢智、TB、金字塔、MultiCharts 中国版 程序化交易软件，支持多种语言和平台。 Auto-Trader 基于 MATLAB 的量化交易平台，适合快速策略开发。 BotVS 云端在线量化平台，支持策略开发和部署。 Progress Apama 事件驱动的算法交易平台，适合复杂策略开发。 龙软 DTS 提供专业的程序化交易解决方案。 国泰安量化投资平台 机构级量化投资平台，支持多策略管理。 飞创 STP 直接市场访问（STP）交易平台，适合高频交易。 易盛程序化交易 提供程序化交易工具，支持多种金融产品。 盛立 SPT 平台 专业的策略交易平台，适合机构用户。 天软量化回测平台 提供量化策略回测和优化工具。 量邦天语 量化交易平台，支持多种策略开发。 EQB-Quant 专业的量化交易平台，适合机构和个人用户。 国外量化平台 Quantopian 提供研究、回测和算法众包平台，支持 Python 策略开发。 QuantConnect 开源平台，支持研究、回测和投资交易，提供多语言支持。 QuantStart 提供研究、回测和投资交易工具，适合数据科学家。 ASC 专业的交易平台，支持多种金融产品。 ZuluTrade 自动交易平台，支持社交交易和策略复制。 Quantpedia 提供研究和策略平台，专注于量化策略。 Algotrading101 策略研究平台，适合初学者和专业人士。 Investopedia 提供股票、外汇模拟交易的财经网站，适合学习和测试。 AmiBroker 提供系统交易工具，支持自定义指标和策略。 AlgoTrades 支持股票、ETF、期货的自动交易系统。 Numerai 数据工程师众包平台，专注于量化对冲基金。 WealthFront 自动化财富管理平台，提供个性化投资方案。 Betterment 个人投资平台，提供智能投资建议。 TradeLink 量化交易平台，支持多种金融产品。 ActiveQuant 基于 JavaScript 的开源交易开发框架。 开源框架 Pandas 数据分析包，提供高效的数据处理和分析工具。 Zipline Python 的回测框架，支持策略开发和测试。 vnpy 基于 Python 的开源交易平台开发框架。 tushare 提供中文财经数据接口包，方便获取市场数据。 easytrader 支持自动程序化股票交易，适合快速执行策略。 pyalgotrade Python 的事件驱动回测框架。 pyalgotrade-cn 支持 A 股历史行情回测，整合 tushare 提供实时行情。 zwPython 基于 WinPython 的集成式开发平台。 quantmod 量化金融建模框架。 rqalpha 基于 Python 的回测引擎。 quantdigger 基于 Python 的量化回测框架。 pyktrader 使用 tkinter 作为 GUI 的 Python 交易平台。 QuantConnectLean 支持多语言的算法交易引擎。 QUANTAXIS 量化金融策略框架。 数据源 TuShare 提供免费的中文财经数据接口。 Quandl 提供国际金融和经济数据。 Wind 资讯 收费的经济数据库。 东方财富 Choice 收费的金融数据研究终端。 iFinD 同花顺金融数据终端。 朝阳永续 Go-Goal 收费的数据终端。 天软数据 收费的金融数据服务。 国泰安数据服务中心 提供收费的金融数据。 锐思数据 收费的金融数据服务。 恒生 API 收费的金融数据接口。 Bloomberg API 收费的金融数据接口。 数库金融数据 提供深度分析 API 服务。 Historical Data Sources 数据源索引。 预测者网 收费的金融数据服务。 巨潮资讯 收费的金融数据服务。 通联数据商城 收费的金融数据服务。 通达信 提供免费的金融数据。 历史数据 | BigQuant 提供免费的历史数据。 新浪、雅虎、东方财富网 提供免费的金融数据。 聚合数据、数粮、数据宝 收费的金融数据服务。 数据库 manahlarctic 基于 MongoDB 和 Python 的高性能时间序列和 tick 数据存储。 kdb 收费的高性能金融序列数据库解决方案。 MongoDB 支持时间序列数据存储。 InfluxDB Go 写的分布式时间序列数据库。 OpenTSDB 基于 HBase 的时间序列数据库。 kairosdb 基于 Cassandra 的时间序列数据库。 SQLite 轻量级关系型数据库。 交易 API 详解1. 上海期货信息技术有限公司 CTP API 简介：CTP API 是中国期货交易所提供的标准交易接口，广泛应用于期货公司和机构投资者。它支持期货和期权的交易。 功能： 支持实时行情数据接收 提供订单提交、撤单、查询等交易功能 支持持仓查询、成交回报等 适用场景： 适用于期货交易所的交易员进行自动化交易 适合开发期货交易系统 优势： 官方支持，稳定可靠 功能全面，覆盖期货交易的所有环节 支持多种编程语言（如 C++、Java、Python 等） 限制： 需要较高的技术门槛 需要通过期货公司开户并获得权限 2. 飞马快速交易平台 API 简介：飞马快速交易平台由上海金融期货信息技术有限公司开发，专注于期货交易的快速执行。 功能： 支持超低延迟的订单提交 提供实时行情数据 支持多种策略的自动化交易 适用场景： 适用于高频交易 适合对延迟要求高的交易者 优势： 交易延迟低 支持多种编程语言 提供详细的 API 文档 限制： 需要较高的开发成本 需要通过期货公司开户 3. 大连飞创信息技术有限公司飞创 API 简介：飞创 API 由大连飞创信息技术有限公司开发，主要服务于期货交易市场。 功能： 支持期货和期权交易 提供实时行情数据 支持订单管理和策略执行 适用场景： 适用于期货交易 适合中小型期货公司 优势： 功能全面 支持多种编程语言 提供良好的客户支持 限制： 需要较高的技术门槛 需要通过期货公司开户 4. vnpy 简介：vnpy 是一个基于 Python 的开源交易平台开发框架，支持多种交易接口。 功能： 支持多种交易接口（如 CTP、飞马、IB 等） 提供策略开发框架 支持回测和实时交易 适用场景： 适用于开发者进行交易系统开发 适合量化交易研究 优势： 开源免费 支持多种交易接口 社区活跃 限制： 需要一定的编程能力 需要自行维护和扩展 5. QuantBoxXAPI2 简介：QuantBoxXAPI2 是统一行情交易接口的第二版，支持多种交易所和期货公司。 功能： 支持多种交易所的行情和交易 提供统一的 API 接口 支持多种编程语言 适用场景： 适用于多市场的交易 适合机构投资者 优势： 支持多种市场 提供统一的接口 功能强大 限制： 需要许可证 需要较高的技术门槛 6. easytrader 简介：easytrader 是一个提供券商接口的开源交易组件，支持多家券商。 功能： 支持多家券商（如华泰、佣金宝、银河、广发、雪球等） 提供基金、股票的自动化交易 支持量化交易 适用场景： 适用于股票和基金的自动化交易 适合个人投资者 优势： 开源免费 支持多家券商 易于使用 限制： 主要适用于 A 股市场 需要一定的编程能力 7. IB API | Interactive Brokers 简介：IB API 是盈透证券提供的交易接口，支持多种金融产品。 功能： 支持多种金融产品（股票、期货、期权、外汇等） 提供实时行情数据 支持自动化交易 适用场景： 适用于多种金融产品的交易 适合国际市场的投资者 优势： 支持多种金融产品 功能强大 提供详细的文档 限制： 需要开户并获得权限 需要较高的技术门槛","tags":["clippings"],"categories":["5.生活","金融","策略学习"]},{"title":"未命名","path":"/2025/02/13/5-生活-金融-未命名/","content":"复利计算公式 matplotlib 绘图模块库 SMA（简单均线）量化策略 策略的回溯测试—MMM 模式，是多周期、多地区、多 频率的回溯测试，即 Mul-Mul-Mul Backtest。 SMA 均线策略很简单： 当股票价格高于 SMA 平均线价格并且是向上趋势时，买入； 当股票价格低于 SMA 平均线价格并且是向下趋势时，卖出。","categories":["5.生活","金融"]},{"title":"爬取基金相关数据","path":"/2025/02/13/5-生活-金融-代码实现-爬取基金相关数据/","content":"# 代码实现import reimport jsonimport requestsimport pandas as pdfrom bs4 import BeautifulSoupfrom functools import partialfrom datetime import datetime, timedeltaShowHistory = Trueheaders = User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36, Authorization: Bearer token123, Cookie: session=abcdef123456# 获取基金当前净值估算数据def GetFundInfoNow(FundCode): 获取指定基金的实时信息。 参数： FundCode (str): 基金代码 返回： dict: 包含基金名称、上一交易日净值、实时估算净值等信息 url = http://fundgz.1234567.com.cn/js/%s.js % FundCode res = requests.get(url, headers=headers) res.encoding = utf-8 match = re.findall(rjsonpgz\\((.*)\\), res.text) if match: js_data = json.loads(match[0]) return js_data else: return 0# 获取基金网页数据def Get_html(fund_code, start_date, end_date, type_=lsjz, page=1, per=20): 获取基金历史数据的HTML内容。 参数： fund_code (str): 基金代码 start_date (str): 开始日期 end_date (str): 结束日期 type_ (str): 数据类型，默认为lsjz（历史净值） page (int): 页码 per (int): 每页记录数 返回： requests.Response: HTTP响应对象 url = http://fund.eastmoney.com/f10/F10DataApi.aspx?type=code=page=sdate=edate=per=.format( type_, fund_code, page, start_date, end_date, per) return requests.get(url, headers=headers)# 获取最大页数def Get_pages(HTML): 从HTML中提取最大页数。 参数： HTML (requests.Response): HTTP响应对象 返回： int: 最大页数 pages = re.findall(rpages:(.*),, HTML.text)[0] return int(pages)# 通过html获取基金历史数据def Get_FundData_history(HTML): 解析HTML内容，提取基金历史数据。 参数： HTML (requests.Response): HTTP响应对象 返回： pd.DataFrame: 包含基金历史数据的DataFrame soup = BeautifulSoup(HTML.text, html.parser) trs = soup.find_all(tr) res = [] for tr in trs[1:]: date = tr.find_all(td)[0].text unit_net = tr.find_all(td)[1].text acc_net = tr.find_all(td)[2].text fund_r = tr.find_all(td)[3].text buy_status = tr.find_all(td)[4].text sell_status = tr.find_all(td)[5].text res.append([date, unit_net, acc_net, fund_r, buy_status, sell_status]) return pd.DataFrame(res, columns=[净值日期, 单位净值, 累计净值, 日增长率, 申购状态, 赎回状态])# 获取基金数据主函数（仅支持单基金）def Get_FundData_main(fund_code, start_date, end_date): 获取指定基金在指定日期范围内的历史数据。 参数： fund_code (str): 基金代码 start_date (str): 开始日期 end_date (str): 结束日期 返回： pd.DataFrame: 包含基金历史数据的DataFrame html = Get_html(fund_code, start_date, end_date) pages = Get_pages(html) res_df = pd.DataFrame() for page in range(1, pages + 1): html = Get_html(fund_code, start_date, end_date, lsjz, page) df_ = Get_FundData_history(html) res_df = pd.concat([res_df, df_]) res_df.insert(0, 基金代码, fund_code) return res_dfdef Print_FundData(codes): 打印指定基金的实时信息及历史数据。 参数： codes (list): 基金代码列表 print(====START======) res_df = pd.DataFrame(list(map(GetFundInfoNow, codes))) print(res_df) if ShowHistory: print(================) fund_df = pd.concat(list(map(partial(Get_FundData_main, start_date=start_date, end_date=end_date), codes))) print(fund_df) print(====END======)def getUrl(url): 获取基金费率信息。 参数： url (str): 目标URL response = requests.get(url, headers=headers) if response.status_code == 200: soup = BeautifulSoup(response.content, html.parser) elements = soup.find_all(class_=info w790) for element in elements: print(element) table = soup.find(table, class_=info w790) if table: rows = table.find_all(tr) fee_rates = 管理费率: None, 托管费率: None, 销售服务费率: None, 基金简称: None for row in rows: mheaders = row.find_all(th) data = row.find_all(td) for header, datum in zip(mheaders, data): if 管理费率 in header.text: fee_rates[管理费率] = datum.text elif 托管费率 in header.text: fee_rates[托管费率] = datum.text elif 销售服务费率 in header.text: fee_rates[销售服务费率] = datum.text elif 基金简称 in header.text: fee_rates[基金简称] = datum.text print(f管理费率: fee_rates[管理费率]) print(f托管费率: fee_rates[托管费率]) print(f销售服务费率: fee_rates[销售服务费率]) print(f基金简称: fee_rates[基金简称]) else: print(未找到目标表格) else: print(f请求失败，状态码: response.status_code)def getdata(url): 获取基金实时净值估算。 参数： url (str): 目标URL response = requests.get(url, headers=headers) if response.status_code == 200: soup = BeautifulSoup(response.content, html.parser) net_value_element = soup.select_one(#gz_gsz) if net_value_element: net_value = net_value_element.text.strip() print(净值估算:, net_value) else: print(未找到净值估算元素) else: print(f请求失败，状态码: response.status_code)if __name__ == __main__: char_array = [015879, 005693, 014111, 001593, 011041, 010364, 012832, 014903, 006229, 008702] for seq in char_array: url = https://fundf10.eastmoney.com/jbgk_ + seq + .html print(url) getUrl(url) for seq in char_array: url = https://fund.eastmoney.com/ + seq + .html?spm=search print(url) getdata(url) end_date = (datetime.now() - timedelta(days=1)).strftime(%Y-%m-%d) start_date = (datetime.now() - timedelta(days=2)).strftime(%Y-%m-%d) print(Start-Date:, start_date) print(End-Date, end_date) codes = [015879] Print_FundData(codes) codes = [005693] Print_FundData(codes) codes = [014111] Print_FundData(codes) codes = [001593] Print_FundData(codes) codes = [011041] Print_FundData(codes) codes = [010364] Print_FundData(codes) codes = [012832] Print_FundData(codes) codes = [014903] Print_FundData(codes) codes = [006229] Print_FundData(codes) codes = [008702] Print_FundData(codes)","categories":["5.生活","金融","代码实现"]},{"title":"高铁","path":"/2025/02/13/5-生活-高铁/","content":"","categories":["5.生活"]},{"title":"史上最全的量化交易资源合集","path":"/2025/02/13/5-生活-金融-史上最全的量化交易资源合集/","content":"有些国外的平台、社区、博客如果连接无法打开，那说明可能需要“科学”上网。 国内量化平台： 掘金量化 - 支持CC++、C#、MATLAB、Python和R的量化交易平台DigQuant - 提供基于matlab量化工具SmartQuant - 策略交易平台OpenQuant - 基于C#的开源量化回测平台 BigQuant - 你的人工智能量化平台 - 可以无门槛地使用机器学习、人工智能开发量化策略，基于python，提供策略自动生成器镭矿 - 基于量化回测平台果仁网 - 回测量化平台京东量化 - 算法交易和量化回测平台聚宽 - 量化回测平台优矿 - 通联量化实验室Ricequant - 量化交易平台况客 - 基于R语言量化回测平台Factors - 数库多因子量化平台诸葛量化 - 量化交易平台宽狗量化 - 回测量化平台 文华赢智 、TB、金字塔、MultiCharts 中国版 - 程序化交易软件、MT4、TradeStationAuto-Trader - 基于MATLAB的量化交易平台BotVS - 云端在线量化平台 Progress Apama、龙软DTS、国泰安量化投资平台、飞创STP、易盛程序化交易、盛立SPT平台、天软量化回测平台 、量邦天语、EQB-Quant 国外量化平台： Quantopian 研究、回测、算法众包平台QuantConnect 研究、回测和投资交易Quantstart 研究、回测和投资交易、数据科学网站ASC 研究、交易平台zulutrade 自动交易平台quantpedia 研究、策略平台algotrading101 策略研究平台investopedia 可以股票、外汇模拟交易的财经网站Amibroker 提供系统交易工具的一家公司AlgoTrades 股票、ETF、期货自动交易系统Numerai 数据工程师众包的一家对冲基金WealthFront 财富管理平台Betterment 个人投资平台TradeLink 量化交易平台ActiveQuant 基于JavaScript开源交易开发框架 开源框架： Pandas - 数据分析包Zipline - 一个Python的回测框架vnpy - 基于python的开源交易平台开发框架tushare - 财经数据接口包easytrader - 进行自动的程序化股票交易pyalgotrade - 一个Python的事件驱动回测框架pyalgotrade-cn - Pyalgotrade-cn在原版pyalgotrade的基础上加入了A股历史行情回测，并整合了tushare提供实时行情。zwPython - 基于winpython的集成式python开发平台quantmod - 量化金融建模rqalpha - 基于Python的回测引擎quantdigger - 基于python的量化回测框架pyktrader - 基于pyctp接口，并采用vnpy的eventEngine，使用tkinter作为GUI的python交易平台QuantConnectLean - Lean Algorithmic Trading Engine by QuantConnect (C#, Python, F#, VB, Java)QUANTAXIS - 量化金融策略框架 数据源： TuShare - 中文财经数据接口包Quandl - 国际金融和经济数据Wind资讯-经济数据库 - 收费东方财富 Choice金融数据研究终端 - 收费iFinD 同花顺金融数据终端 - 收费朝阳永续 Go-Goal数据终端 - 收费天软数据 - 收费国泰安数据服务中心 - 收费锐思数据 - 收费恒生API - 收费Bloomberg API - 收费数库金融数据和深度分析API服务 - 收费Historical Data Sources - 一个数据源索引预测者网 - 收费巨潮资讯 - 收费通联数据商城 - 收费通达信 - 免费历史数据 - 文档 | BigQuant - 免费新浪、雅虎、东方财富网 - 免费聚合数据、数粮 、数据宝 - 收费 数据库 manahlarctic: High performance datastore for time series and tick data - 基于mongodb和python的高性能时间序列和tick数据存储kdb | The Leader in High-Performance Tick Database Technology | Kx Systems - 收费的高性能金融序列数据库解决方案MongoDB Blog - 用mongodb存储时间序列数据InfluxDB – Time-Series Data Storage | InfluxData - Go写的分布式时间序列数据库OpenTSDBopentsdb: A scalable, distributed Time Series Database. - 基于HBase的时间序列数据库kairosdbkairosdb: Fast scalable time series database - 基于Cassandra的时间序列数据库SQLite Home Page 网站、论坛、社区、博客 国外： AQR - Alternative Investments http://epchan.blogspot.jp/FOSS Tradingwilmott.com - ForumTraders Magazine: The stock dealers and institutional traders complete interactive news and information service http://practicalquant.blogspot.jp/?view=classic http://www.thewholestreet.com/Implementing QuantLib http://tradingwithpython.blogspot.jp/Coding the marketsQuantivityQuant Mashup | QuantocracyOn a long enough timeline the survival rate for everyone drops to zeroKeplerian Finance - exploring the boundaries of quantitative financeThe Journal of Trading: HomeAll things finance and technology…Quant NewsQuantitative Trading Strategies | Numerical Method Inc.Nuclear PhynanceElite TraderMeb Faber Research - Stock Market and Investing BlogPortfolio Workstation by Alpha Level http://falkenblog.blogspot.jp/Quantitative Finance Stack ExchangeThe mathematics of investing and markets • rquantfinanceQuantNet CommunityQUANTITATIVE RESEARCH AND TRADING - The latest theories, models and investment strategies in quantitative research and tradingQUSMA - Quantitative Systematic Market Analysis https://abnormalreturns.com/CSSA http://www.tradingtheodds.com/Quantitative Trading, Statistical Arbitrage, Machine Learning and Binary OptionsCollective2 - The platform that connects investors with top-tradersAlvarez Quant TradingThe Marketplace For Algorithmic Trading Systems | QuantiacsQuantitative FinanceQuantopian LecturesKitces.com - Advancing Knowledge in Financial PlanningForex FactoryThe R TraderHow to be a Quant关于交易策略的机器学习scikit-learn: machine learning in PythonPaul WilmottThe Trend is your FriendPractical QuantJohn Mauldin’s Outside the BoxQuantum FinancierQuantified StrategiesBlackRock BlogQuant at Risk 国内： BigQuant量化社区算法组_新浪微博海洋部落水木社区（经管之家）人大经济论坛清华大学学生经济金融论坛matlab技术论坛微量网Code4Quant量化交易 - 热门问答 - 知乎集思录 - 低风险投资 - 集思录雪球 - 聪明的投资者都在这里myquantstrategy: 掘金策略集锦botvsstrategies - 用Javascript or Python进行量化交易芝诺量化交易,程序化交易统计之都 (Capital of Statistics)中国量化投资学会宽客 (Quant) - 索引 - 知乎faruto的博客博文_bicloud_新浪博客博文_郑来轶_新浪博客flitter_新浪博客david自由之路作者安道全_新浪博客债券的大拿没钱又丑期货用来复盘的blog花荣_新浪博客股海泛舟 - 股海范舟带头大哥777的博客 交易API 上海期货信息技术有限公司CTP API - 期货交易所提供的API飞马快速交易平台 - 上海金融期货信息技术有限公司 - 飞马大连飞创信息技术有限公司 - 飞创vnpy - 基于python的开源交易平台开发框架QuantBoxXAPI2 - 统一行情交易接口第2版easytrader - 提供券商华泰佣金宝银河广发雪球的基金、股票自动程序化交易，量化交易组件IB API | Interactive Brokers - 盈透证券的交易API编程Python安装Anaconda - 推荐通过清华大学镜像 下载安装Pycharm downloadPython Extension Packages for Windows - Christoph Gohlke - Windows用户从这里可以下载许多python库的预编译包教程Python | Codecademy用 Python 玩转数据 - 南京大学 | CourseraGoogle 开源项目风格指南 (中文版)廖雪峰python教程Introduction to Data Science in Python - University of Michigan | CourseraThe Python TutorialPython for FinanceAlgorithmic Thinking - Python 算法思维训练Python Cookbook 3rd Edition Documentation库Python Extension Packages for Windowsawesome-python: A curated list of awesome Python frameworks, libraries, software and resourcespandas - Python做数据分析的基础pyql: Cython QuantLib wrappers ffn - 绩效评估ta-lib: Python wrapper for TA-Lib (http://ta-lib.org/). - 技术指标StatsModels: Statistics in Python — statsmodels documentation - 常用统计模型arch: ARCH models in Python - 时间序列pyfolio: Portfolio and risk analytics in Python - 组合风险评估twosigmaflint: A Time Series Library for Apache Spark - Apache Spark上的时间序列库R安装The Comprehensive R Archive Network - 从国内清华镜像下载安装RStudio - R的常用开发平台下载教程Free Introduction to R Programming Online Course - datacamp的在线学习R Programming - 约翰霍普金斯大学 | CourseraIntro to Computational Finance with R - 用R进行计算金融分析库CRAN Task View: Empirical Finance - CRAN官方的R金融相关包整理qinwfawesome-R: A curated list of awesome R packages, frameworks and software. - R包的awesomeC++教程C++程序设计 - 北京大学 郭炜基于Linux的C++ - 清华大学 乔林面向对象程序设计（C++） - 清华大学 徐明星C++ Design Patterns and Derivatives Pricing - C++设计模式C++ reference - cppreference.com - 在线文档库fffarazawesome-cpp: A curated list of awesome CC++ frameworks, libraries, resources, and shiny things. - C++库整理rigtorpawesome-modern-cpp: A collection of resources on modern C++ - 现代C++库整理QuantLib: a freeopen-source library for quantitative financelibtradinglibtrading: Libtrading, an ultra low-latency trading connectivity library for C and C++.Julia教程Learning Julia - 官方整理QUANTITATIVE ECONOMICS with Julia - 经济学诺奖获得者Thomas Sargent教你Julia在量化经济的应用。库Quantitative Finance in Julia - 多数为正在实现中，感兴趣的可以参与编程论坛Stack OverflowSegmentFaultQuoraGithub知乎 - 与世界分享你的知识、经验和见解编程能力在线训练Solve Programming Questions | HackerRank - 包含常用语言(C++, Java, Python, Ruby, SQL)和相关计算机应用技术(算法、数据结构、数学、AI、Linux Shell、分布式系统、正则表达式、安全)的教程和挑战。LeetCode Online Judge - C, C++, Java, Python, C#, JavaScript, Ruby, Bash, MySQL在线编程训练Quant Books 《投资学》第6版[美]兹维·博迪.文字版 (link)《打开量化投资的黑箱》 里什·纳兰《宽客》[美] 斯科特·帕特森（Scott Patterson） 著；译科，卢开济 译《解读量化投资：西蒙斯用公式打败市场的故事》 忻海《Trends in Quantitative Finance》 Frank J. Fabozzi, Sergio M. Focardi, Petter N. Kolm《漫步华尔街》麦基尔《海龟交易法则》柯蒂斯·费思《交易策略评估与最佳化》罗伯特·帕多《统计套利》 安德鲁·波尔《信号与噪声》纳特•西尔弗《期货截拳道》朱淋靖《量化投资—策略与技术》 丁鹏《量化投资—以matlab为工具》 李洋faruto《量化投资策略:如何实现超额收益Alpha》 吴冲锋《中低频量化交易策略研发（上）》 杨博理《走出幻觉走向成熟》 金融帝国《失控》凯文·凯利《通往财务自由之路》范K撒普《以交易为生》 埃尔德《超越技术分析》图莎尔·钱德《高级技术分析》布鲁斯·巴布科克《积极型投资组合管理》格里纳德，卡恩《金融计量学:从初级到高级建模技术》 斯维特洛扎《投资革命》Bernstein《富可敌国》Sebastian Mallaby《量化交易——如何建立自己的算法交易事业》欧内斯特·陈《聪明的投资者》 本杰明·格雷厄姆《黑天鹅·如何应对不可知的未来》 纳西姆·塔勒布 《期权、期货和其他衍生品》 约翰·赫尔《Building Reliable Trading Systems: Tradable Strategies That Perform As They Backtest and Meet Your Risk-Reward Goals》 Keith Fitschen《Quantitative Equity Investing》by Frank J. Fabozzi, Sergio M. Focardi, Petter N. KolmBarra USE3 handbook《Quantitative Equity Portfolio Management》 Ludwig Chincarini《Quantitative Equity Portfolio Management》 Qian Hua SorensenQuant Papers Machine Learning RelatedCavalcante, Rodolfo C., et al. “Computational Intelligence and Financial Markets: A Survey and Future Directions.” Expert Systems with Applications 55 (2016): 194-211.(link)Low Frequency PredictionAtsalakis G S, Valavanis K P. Surveying stock market forecasting techniques Part II: Soft computing methods. Expert Systems with Applications, 2009, 36(3):5932–5941. (link) Cai X, Lin X. Feature Extraction Using Restricted Boltzmann Machine for Stock Price Predic- tion. 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE), 2012. 80–83.(link) Nair B B, Dharini N M, Mohandas V P. A stock market trend prediction system using a hybrid decision tree-neuro-fuzzy system. Proceedings - 2nd International Conference on Advances in Recent Technologies in Communication and Computing, ARTCom 2010, 2010. 381–385. (link) Lu C J, Lee T S, Chiu C C. Financial time series forecasting using independent component analysis and support vector regression. Decision Support Systems, 2009, 47(2):115–125. (link) Creamer G, Freund Y. Automated trading with boosting and expert weighting. Quantitative Finance, 2010, 10(4):401–420. (link) Batres-Estrada, Bilberto. “Deep learning for multivariate financial time series.” (2015). (link) Xiong, Ruoxuan, Eric P. Nicholas, and Yuan Shen. “Deep Learning Stock Volatilities with Google Domestic Trends.” arXiv preprint arXiv:1512.04916 (2015).(link) Sharang, Abhijit, and Chetan Rao. “Using machine learning for medium frequency derivative portfolio trading.” arXiv preprint arXiv:1512.06228 (2015).(link) Reinforcement LearningDempster, Michael AH, and Vasco Leemans. “An automated FX trading system using adaptive reinforcement learning.” Expert Systems with Applications 30.3 (2006): 543-552. (link) Tan, Zhiyong, Chai Quek, and Philip YK Cheng. “Stock trading with cycles: A financial application of ANFIS and reinforcement learning.” Expert Systems with Applications 38.5 (2011): 4741-4755. (link) Rutkauskas, Aleksandras Vytautas, and Tomas Ramanauskas. “Building an artificial stock market populated by reinforcement‐learning agents.” Journal of Business Economics and Management 10.4 (2009): 329-341.(link) Deng, Yue, et al. “Deep Direct Reinforcement Learning for Financial Signal Representation and Trading.” (2016).(link) Natual Language Processing RelatedBollen J, Mao H, Zeng X. Twitter mood predicts the stock market. Journal of Computational Science, 2011, 2(1):1–8. (link) Preis T, Moat H S, Stanley H E, et al. Quantifying trading behavior in financial markets using Google Trends. Scientific reports, 2013, 3:1684. (link) Moat H S, Curme C, Avakian A, et al. Quantifying Wikipedia Usage Patterns Before Stock Market Moves. Scientific Reports, 2013, 3:1–5. (link) Ding, Xiao, et al. “Deep learning for event-driven stock prediction.” Proceedings of the 24th International Joint Conference on Artificial Intelligence (ICJAI’15). 2015. (link) Fehrer, R., Feuerriegel, S. (2015). Improving Decision Analytics with Deep Learning: The Case of Financial Disclosures. arXiv preprint arXiv:1508.01993. (link) High Frequency TradingNevmyvaka Y, Feng Y, Kearns M. Reinforcement learning for optimized trade execution. Proceedings of the 23rd international conference on Machine learning ICML 06, 2006, 17(1):673–680. (link) Ganchev K, Nevmyvaka Y, Kearns M, et al. Censored exploration and the dark pool problem. Communications of the ACM, 2010, 53(5):99. (link) Kearns M, Nevmyvaka Y. Machine learning for market microstructure and high frequency trading. High frequency trading - New realities for traders, markets and regulators, 2013. 1–21. (link) Sirignano, Justin A. “Deep Learning for Limit Order Books.” arXiv preprint arXiv:1601.01987 (2016). (link) Deng, Yue, et al. “Sparse coding-inspired optimal trading system for HFT industry.” IEEE Transactions on Industrial Informatics 11.2 (2015): 467-475.(link) Ahuja, Saran, et al. “Limit order trading with a mean reverting reference price.” arXiv preprint arXiv:1607.00454 (2016). (link) Aït-Sahalia, Yacine, and Jean Jacod. “Analyzing the spectrum of asset returns: Jump and volatility components in high frequency data.” Journal of Economic Literature 50.4 (2012): 1007-1050. (link) Portfolio ManagementB. Li and S. C. H. Hoi, “Online portfolio selection,” ACM Comput. Surv., vol. 46, no. 3, pp. 1–36, 2014. (link) Heaton, J. B., Polson, N. G., Witte, J. H. (2016). Deep Portfolio Theory. (link) Eugene F. Fama, Kenneth R. French. The cross-section of expected stock returns. Journal of Finance, 47 (1992), pp. 427–465. 学术期刊一堆学术期刊可以常常去浏览一下，也会有许多思路，作者常常看的有： Journal of FinanceJournal of Financial EconomicsReview of Financial StudiesJournal of Accounting and EconomicsReview of Accounting StudiesJournal of Accounting ResearchAccounting ReviewJournal of Financial and Quantitative AnalysisFinancial Analysts JournalFinancial ManagementJournal of Empirical FinanceQuantitative FinanceJournal of Alternative InvestmentsJournal of Fixed IncomeJournal of InvestingJournal of Portfolio ManagementJournal of TradingReview of Asset Pricing Studies经济研究经济学（季刊）金融研究管理世界会计研究投资研究 来源：网络转载","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"大模型接入","path":"/2025/02/05/4-软件-AI-大模型接入/","content":"1. 术语1.1 输入输出价格含义：输入价格是指用户向大模型输入文本内容时，根据输入内容的 token 数量而计算的费用。输出价格则是大模型基于用户输入生成回答内容而按照输出内容的 token 数量计算的费用。 作用：用户可根据自身业务需求与预算来合理控制输入输出内容的长度，以降低使用成本。例如，在进行简单问答时，精简输入问题可有效减少输入费用；而在获取输出结果时，依据实际需要设置合适的输出长度，避免无必要的输出费用。 1.2 models 选择含义：大模型通常提供多种模型版本，这些版本在性能、功能和适用场景上各有差异。例如，OpenAI 的 GPT-4 适合复杂推理和创意写作，而 GPT-3.5-turbo 则更偏向于日常对话和简单文本生成。 作用：根据具体业务场景选择合适的模型，能够显著提高处理效果与效率。假如从事专业论文撰写，选择擅长深度推理和知识整合的模型无疑更有利；而在开发聊天机器人时，选择对话交互体验好的模型则能提升用户满意度。 1.3 temperature 参数含义：temperature 参数用于控制生成文本的随机性，其取值范围通常在 0 到 1 之间。值越靠近 0，生成的文本越确定且保守，更符合逻辑和常见表达；值越靠近 1，生成的文本则具有更多的随机性和创造性，可能产生新颖但有时不太符合常规的内容。 作用：在不同应用场景下灵活调整 temperature 值，以满足多元化需求。比如撰写新闻报道时可使用较低的 temperature 值，以确保内容客观准确；而在创作小说和诗歌时，适度提高 temperature 值则能增加文本的趣味性和独特性。 1.4 tokens含义：tokens 是大模型在处理文本时的基本单位，它可以是一个完整的单词、一个标点符号，或是一个子词。例如，“apple” 可能是一个 token，而 “international” 可能被拆分为 “inter” 和 “national” 两个 token。 作用：大模型按 tokens 的数量进行计费，并且对输入与输出的 tokens 数量均有限制。了解 tokens 的概念有助于用户提前预估使用成本，合理规划输入输出内容的长度，以防止因超出 token 限制而导致请求失败。例如，使用大模型进行长篇文章总结时，可以提前估算文章的 tokens 数量，若超出限制，则可对内容进行删减或拆分处理。 2. 大模型定价策略及范围以下是当前国内主要大模型的定价策略： 大模型厂商 模型名称 输入价格（每 100 万 TOKEN） 输出价格（每 100 万 TOKEN） 免费模型 DeepSeek DeepSeek 大模型 1 元人民币 1 元人民币 无 字节跳动 豆包大模型 0.8 元人民币 0.8 元人民币 无 阿里巴巴 通义千问 0.5 元人民币 0.8 元人民币 无 百度 文心一言 免费 免费 快速模型、轻量级模型 科大讯飞 星火大模型 0.5 元人民币 0.5 元人民币 轻量级模型 腾讯 浑元大模型 0.6 元人民币 0.6 元人民币 轻量级模型 灵异万物 灵异万物大模型 10 元人民币 10 元人民币 无 百川智能 百川大模型 12 元人民币 12 元人民币 无 该表格展示了各大厂商在输入和输出 TOKEN 上的定价策略，反映出市场的竞争态势。 2.1 OpenAI定价策略：以 GPT-4o 系列为例，OpenAI 采用按输入和输出的 tokens 数量进行收费。例如，GPT-4o mini 的收费标准为：每百万输入 tokens 收费 15 美分，每百万输出 tokens 收费 60 美分。这种收费方式使得用户能够根据具体应用的需求来控制成本。 价格范围：不同模型版本的输入输出价格会有所差异。模型的性能和功能复杂程度是主要定价依据。通常，功能更强大的模型如 GPT-4o 的价格高于其简单版 GPT-4o mini。 2.2 DeepSeek定价策略：DeepSeek-R1 API 服务同样按照输入输出 tokens 收费。当输入 tokens 发生缓存命中时，每百万 tokens 的定价为 1 元人民币；如果缓存未命中，则每百万 tokens 的费用会上升至 4 元人民币。而每百万输出 tokens 的定价为 16 元人民币。这种依据缓存情况的定价策略有助于提高系统性能并降低使用成本。 价格范围：计费基于输入输出的具体情况以及 tokens 的数量，因此在不同使用场景中，成本可能存在波动。 2.3 百度文心一言定价策略：文心一言采用阶梯式定价，根据调用量的不同区间设置不同单价。例如，基础调用量的用户可享受较低的单价，而当调用量增加时单价可能会有所调整。此外，不同类型的任务，如文本生成或知识问答，其定价策略也会有所不同。 价格范围：具体的价格因业务类型和调用量的不同而异，因此企业级用户可以与百度协商定制符合自身需求的价格套餐。 2.4 阿里通义千问定价策略：阿里通义千问的定价综合考虑了使用时长、调用次数和生成内容量等因素。为了吸引长时间使用或高频调用的用户，阿里提供了一定的优惠套餐；而对于生成复杂内容（例如长篇文章或专业文案）时的收费标准则相对较高。 价格范围：在不同的套餐和使用场景下，价格会有所不同，企业用户可根据实际需要选择合适的计费方式，以满足不同的业务需求。 2.5 字节跳动豆包定价策略：豆包通用模型 Pro-32k 的输入价格为每百万 tokens 0.8 元，输出价格为每百万 tokens 2 元。根据不同规格的模型，其价格会根据性能和资源消耗进行适当调整。 价格范围：不同模型版本和应用场景的价格有所区别，用户有自由选择依据自身需求的模型进行使用。 3. API 接入方案3.1 OpenAI注册与获取密钥：访问 OpenAI 官网（https://openai.com/），注册开发者账号，并按照指引获取 API 密钥。 配置请求：使用获取的 API 密钥构建 HTTP 请求。请求中需包含模型选择（如 gpt-4、gpt-3.5-turbo 等）、输入文本，以及其他参数（如 temperature、max_tokens 等）。 处理响应：接收模型返回的 JSON 格式响应，解析结果，包括生成的文本内容和使用的 token 数量等。 3.2 DeepSeek访问官网注册：打开 DeepSeek 官方入口（https://www.deepseek.com/），注册账号，登录后进入左侧的 API Keys 页面，创建 API Key。 调用配置：DeepSeek API 使用懂与 OpenAI 兼容的参数格式，配置主要包括： base_url：设置为 https://api.deepseek.com 或 https://api.deepseek.com/v1 api_key：输入用户 API Key model：选择默认模型 deepseek-chat 示例代码（Python）： # 安装 DeepSeek SDK：pip3 install openaifrom openai import OpenAI# 创建 API 客户端client = OpenAI(api_key=你的 API Key, base_url=https://api.deepseek.com)# 调用 deepseek-chat 模型response = client.chat.completions.create( model=deepseek-chat, messages=[ role: user, content: 请用DeepSeek模型回复这句话！ ], stream=False # 设置为True可启用流式输出)# 输出响应内容print(response.choices[0].message.content) 3.3 百度文心一言申请与认证：在百度智能云官网（https://cloud.baidu.com/）申请文心一言 API 接入，完成企业或个人认证。 获取 AKSK：认证通过后，在控制台获取 Access Key（AK）和 Secret Key（SK）。 开发接入：根据百度提供的 API 文档，使用 AK 和 SK 进行签名认证，构建 HTTP 请求，选择合适的模型和参数发起调用。 3.4 阿里通义千问入驻阿里云：在阿里云官网（https://www.aliyun.com/）完成入驻流程，获得阿里云用户身份。 开通服务：在阿里云市场搜索通义千问，开通 API 服务，获取 API 密钥。 接入开发：参考阿里云提供的接入文档，使用 API 密钥和相关参数进行接口调用，支持多种编程语言进行开发。 3.5 字节跳动豆包进入官网：访问火山引擎豆包大模型官网（https://www.volcengine.com/）。 获取接入信息：点击 “立即体验”，选择模型（如 doubao-lite-128k），点击 “创建推理接入点”。 调用方法：使用 OpenAI SDK 标准接口调用方式，设置 API 域名为 https://ark.cn-beijing.volces.com，api 路径则设为 /api/v3/chat/completions。","categories":["4.软件","AI"]},{"title":"Switch 大气层 Atmosphere 最新版 历史版 下载 | 时鹏亮的Blog","path":"/2025/01/16/5-生活-手机相机游戏机-Switch-大气层-Atmosphere-最新版-历史版-下载-时鹏亮的Blog/","content":"大气层 Atmosphere是Switch中的免费开源的破解系统，配合Hekate引导，可以实现备份恢复NAND、制作虚拟系统游玩破解游戏等多种功能。 注意事项 请勿使用Mac传输数据，也不要用移动设备（如手机）读取内存卡，会损坏文件损坏后参考 修复方案，强烈建议使用Windows传输文件。 如遇文件损坏或密码错误，可参考修复教程：WinRAR如何修复受损的压缩文件 大气层 Atmosphere 最新版 下载点击下载：Atmosphere1.8.0-prereleaseV4+Hekate6.2.2(支持19.0.0)(解压密码shipengliang).rar 看广告高速下载：Atmosphere1.8.0-prereleaseV4+Hekate6.2.2(支持19.0.0)(解压密码shipengliang).rar 启动 黑屏 报错的可能原因根据热心访客们的留言反馈，直接大气层包覆盖到卡中后使用Daybreak升级系统或出现 启动黑屏的情况 。可能是由三方插件引起的黑屏，也可能升级系统时漏选exFAT驱动并使用exFAT格式内存卡造成的。 插件造成的黑屏可以尝试移除/switch/文件夹以及/atmosphere/contents/中的三方插件后，重启设备。 漏驱动的话，找张FAT32的卡重刷系统把exFAT驱动刷回去。 关于软破设备注入器的顿悟所有三方注入器，使用SX Loader-payload.rar，配合博客的大气层整合包，可实现 永不更新注入器payload。 看广告高速下载：SX Loader-payload.rar payload.bin的更新方法下方有说明，不同的是，更新的payload.bin来自：SX Loader-payload.rar。 看广告高速下载：SX Loader-payload.rar 使用SX Loader作为payload，会默认以SX的注入方式拉起TF卡根目录的payload.bin，这个bin会随新版整合包更新为最新的Hekate。如此，注入器再也不需要更新什么payload了，完全智能兼容，使用三方注入器的同学们可参考。 上述方法由热心访客 凌魔火影 确认可行。三方注入器的同学从此告别更新payload。 附：三方注入器（RCMloader、ns-ATMOSPHERE等）更新payload方法。 整合包说明一个整合包软破硬破设备通用。 整合包不附带任何额外插件，默认有虚拟系统和真实系统屏蔽任天堂服务hosts、引导配置，虚拟系统隐藏序列号、禁用金手指自启动功能： 如需移除虚拟系统屏蔽DNS（屏蔽hosts），删除atmosphere\\hosts\\emummc.txt后重启设备即可。 如需移除真实系统屏蔽DNS（屏蔽hosts），删除atmosphere\\hosts\\sysmmc.txt后重启设备即可。 如需默认启用金手指，删除atmosphere\\config\\system_settings.ini后重启设备即可(由热心访客 fennnnn测试核对)。 exosphere.ini的blank_prodinfo_emummc=11改为0后重启设备即可关闭虚拟系统隐藏序列号功能。 默认Launch下引导配置自定义了常用的3个引导： 启用开机直接进入破解系统流程Hekate引导页右上Options-Auto Boot OFF-选择要默认进入的系统-Auto Boot ON-点底部Save Options保存即可。 禁用开机直接进入破解系统流程如按住**音量+（不灵就试试音量-）后，点按电源键后直接进入系统；如无法进入Hekate引导页，则启动后按住音量-**。 Hekate引导页右上Options-Auto Boot ON-点击右上Disable-Auto Boot OFF-点底部Save Options保存即可。 常见注入（引导）器更新指南 RCMloader注入器 payload更新Hekate引导的，将根目录的payload.bin覆盖注入器ATMOSPHERE_HEKATE目录下同名文件。 大气层引导的，复制bootloader\\payloads\\fusee.bin并重命名为payload.bin，覆盖注入器ATMOSPHERE_HEKATE目录下同名文件。 长按注入器 +号钮 切换到蓝灯（Atmosphere）或者 红灯（SX OS），即可正常使用RCMloader注入器。 固件更新如果注入不正常，可能是固件版本过低造成的问题，根据热心访客 【split_rain】 和 【凌魔火影】 提示：可以尝试更新固件，以便支持后续版本Hekate（注意，固件对应注入器为白色纸盒包装的RCMloader one plus，相关留言讨论已置顶。）。 固件更新除非有新版本，否则只需一次。当前版本日期：20210916。 下载固件升级包：RCMloader_One_Plus_Update_Tool_V2.02.rar 看广告高速下载：RCMloader_One_Plus_Update_Tool_V2.02.rar 解压固件升级包文件 打开升级软件：Rcmloader one plus Update Tool V2.02 升级软件中，点击勾选“Auto Download”。 注入器关机状态下，插入USB 数据线的同时按注入器的按键+，注入器的指示灯蓝绿交替闪烁，注入器进入升级模式。 注入器进入升级模式后，会自动升级。等待升级成功，蓝色升级进度满格100%，同时软件的上方显示“PASS”,则注入器升级成功。 ns-ATMOSPHERE注入器 使用： NS-Atmosphere programmer v0.3（Windows）.rar 看广告高速下载：NS-Atmosphere programmer v0.3（Windows）.rar ns-atmosphere-programmer-osx-11（Mac）.rar 看广告高速下载：ns-atmosphere-programmer-osx-11（Mac）.rar Hekate引导的，将根目录的payload.bin烧录到NS-Atmosphere注入器。 大气层引导的，将bootloader\\payloads\\fusee.bin烧录到NS-Atmosphere注入器。 软破设备 PC端可用： TegraRcmGUI.msi 看广告高速下载：TegraRcmGUI.msi 检测到Switch的RCM模式后，人工选择payload.bin，引导Switch进入Hekate。 硬破设备 音量+和电源键（不灵就试试音量-）即可进入Hekate引导页。 安卓设备 下载注入工具：Rekado多功能注入软件4.1汉化版.apk 看广告高速下载：Rekado多功能注入软件4.1汉化版.apk 如需下载最新Switch 固件，访问：Switch Firmware 固件 最新版历史版 下载 如需离线更新系统，访问：Switch 大气层 Atmosphere 如何离线升级系统 大气层 Atmosphere 历史版下载列表显示历史版本列表，强烈建议下载顶部 最新版（智能兼容低版本系统）。~~Atmosphere1.7.1+Hekate6.2.1(支持18.1.0).rar~~ 看广告高速下载：Atmosphere1.7.1+Hekate6.2.1(支持18.1.0).rar Atmosphere1.7.0-prerelease+Hekate6.1.1(支持18.0.0).rar 看广告高速下载：Atmosphere1.7.0-prerelease+Hekate6.1.1(支持18.0.0).rar Atmosphere1.6.2+Hekate6.1.0(支持17.0.1).rar 看广告高速下载：Atmosphere1.6.2+Hekate6.1.0(支持17.0.1).rar Atmosphere1.6.2+Hekate6.0.7(支持17.0.0).rar 看广告高速下载：Atmosphere1.6.2+Hekate6.0.7(支持17.0.0).rar Atmosphere1.5.5+Hekate6.0.6(支持16.1.0).rar 看广告高速下载：Atmosphere1.5.5+Hekate6.0.6(支持16.1.0).rar Atmosphere1.5.3+Hekate6.0.4(支持16.0.3).rar 看广告高速下载：Atmosphere1.5.3+Hekate6.0.4(支持16.0.3).rar Atmosphere1.5.2+Hekate6.0.3(支持16.0.2).rar 看广告高速下载：Atmosphere1.5.2+Hekate6.0.3(支持16.0.2).rar Atmosphere1.5.1+Hekate6.0.3(支持16.0.1).rar 看广告高速下载：Atmosphere1.5.1+Hekate6.0.3(支持16.0.1).rar Atmosphere1.5.1+Hekate6.0.2(支持到16.0.1).rar 看广告高速下载：Atmosphere1.5.1+Hekate6.0.2(支持到16.0.1).rar Atmosphere1.4.1+Hekate6.0.1(支持15.0.1).rar 看广告高速下载：Atmosphere1.4.1+Hekate6.0.1(支持15.0.1).rar Atmosphere1.4.0+Hekate6.0.1(支持15.0.1).rar 看广告高速下载：Atmosphere1.4.0+Hekate6.0.1(支持15.0.1).rar Atmosphere1.4.0+Hekate5.9.0(支持15.0.1).rar 看广告高速下载：Atmosphere1.4.0+Hekate5.9.0(支持15.0.1).rar Atmosphere1.4.0-prerelease+Hekate5.9.0(支持15.0.0).rar 看广告高速下载：Atmosphere1.4.0-prerelease+Hekate5.9.0(支持15.0.0).rar Atmosphere1.3.2+Hekate5.7.2(支持14.1.2).rar 看广告高速下载：Atmosphere1.3.2+Hekate5.7.2(支持14.1.2).rar Atmosphere1.3.2+Hekate5.7.2(支持14.1.1).rar 看广告高速下载：Atmosphere1.3.2+Hekate5.7.2(支持14.1.1).rar Atmosphere1.3.1(20220409-2)+Hekate5.7.2(支持14.1.0).rar 看广告高速下载：Atmosphere1.3.1(20220409-2)+Hekate5.7.2(支持14.1.0).rar Atmosphere1.3.1+Hekate5.7.2(支持14.1.10).rar 看广告高速下载：Atmosphere1.3.1+Hekate5.7.2(支持14.1.10).rar Atmosphere1.3.0-prerelease2+Hekate5.7.2(支持14.0.0).rar 看广告高速下载：Atmosphere1.3.0-prerelease2+Hekate5.7.2(支持14.0.0).rar Atmosphere1.2.6+Hekate5.7.0(支持13.2.1).rar 看广告高速下载：Atmosphere1.2.6+Hekate5.7.0(支持13.2.1).rar Atmosphere1.2.5+Hekate5.6.5(支持13.2.0).rar 看广告高速下载：Atmosphere1.2.5+Hekate5.6.5(支持13.2.0).rar Atmosphere1.2.4+Hekate5.6.5(支持13.1.0).rar 看广告高速下载：Atmosphere1.2.4+Hekate5.6.5(支持13.1.0).rar Atmosphere1.2.3+Hekate5.6.5(支持13.1.0).rar 看广告高速下载：Atmosphere1.2.3+Hekate5.6.5(支持13.1.0).rar Atmosphere1.2.2+Hekate5.6.5(支持13.1.0).rar 看广告高速下载：Atmosphere1.2.2+Hekate5.6.5(支持13.1.0).rar Atmosphere1.2.1+Hekate5.6.5(支持13.1.0).rar 看广告高速下载：Atmosphere1.2.1+Hekate5.6.5(支持13.1.0).rar Atmosphere1.1.1+Hekate5.6.3(支持13.0.0).rar 看广告高速下载：Atmosphere1.1.1+Hekate5.6.3(支持13.0.0).rar Atmosphere1.1.1+Hekate5.6.2(支持13.0.0).rar 看广告高速下载：Atmosphere1.1.1+Hekate5.6.2(支持13.0.0).rar Atmosphere1.1.0-prerelease+Hekate5.6.2(支持13.0.0).rar 看广告高速下载：Atmosphere1.1.0-prerelease+Hekate5.6.2(支持13.0.0).rar Atmosphere1.1.0-prerelease+Hekate5.6.1(支持13.0.0).rar 看广告高速下载：Atmosphere1.1.0-prerelease+Hekate5.6.1(支持13.0.0).rar Atmosphere1.0.0+Hekate5.6.0(支持12.1.0).rar 看广告高速下载：Atmosphere1.0.0+Hekate5.6.0(支持12.1.0).rar Atmosphere0.20.1+Hekate5.6.0(支持12.1.0-软破设备).rar 看广告高速下载：Atmosphere0.20.1+Hekate5.6.0(支持12.1.0-软破设备).rar Atmosphere0.20.1+Hekate5.6.0(支持12.1.0-硬破设备).rar 看广告高速下载：Atmosphere0.20.1+Hekate5.6.0(支持12.1.0-硬破设备).rar Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-软破设备).rar 看广告高速下载：Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-软破设备).rar Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-硬破设备).rar 看广告高速下载：Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-硬破设备).rar Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-原版大气层引导-硬破设备).rar 看广告高速下载：Atmosphere0.19.5+Hekate5.5.8(支持12.1.0-原版大气层引导-硬破设备).rar Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-软破设备).rar 看广告高速下载：Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-软破设备).rar Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-硬破设备).rar 看广告高速下载：Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-硬破设备).rar Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-原版大气层引导-硬破设备).rar 看广告高速下载：Atmosphere0.19.4+Hekate5.5.7(支持12.0.3-原版大气层引导-硬破设备).rar Atmosphere0.19.3+Hekate5.5.6(支持12.0.2-硬破设备).rar 看广告高速下载：Atmosphere0.19.3+Hekate5.5.6(支持12.0.2-硬破设备).rar Atmosphere0.19.3+Hekate5.5.6(支持12.0.2-原版大气层引导-硬破设备).rar 看广告高速下载：Atmosphere0.19.3+Hekate5.5.6(支持12.0.2-原版大气层引导-硬破设备).rar Atmosphere0.19.2+Hekate5.5.5(支持12.0.1-软破设备).rar 看广告高速下载：Atmosphere0.19.2+Hekate5.5.5(支持12.0.1-软破设备).rar Atmosphere0.19.2+Hekate5.5.5(支持12.0.1-硬破设备).rar 看广告高速下载：Atmosphere0.19.2+Hekate5.5.5(支持12.0.1-硬破设备).rar Atmosphere0.19.1+Hekate5.5.5(支持12.0.0-软破设备).rar 看广告高速下载：Atmosphere0.19.1+Hekate5.5.5(支持12.0.0-软破设备).rar Atmosphere0.19.1+Hekate5.5.5(支持12.0.0-硬破设备).rar 看广告高速下载：Atmosphere0.19.1+Hekate5.5.5(支持12.0.0-硬破设备).rar Atmosphere0.19.0+Hekate5.5.5(支持12.0.0).rar 看广告高速下载：Atmosphere0.19.0+Hekate5.5.5(支持12.0.0).rar Atmosphere0.18.1+Hekate5.5.4-v2(支持11.0.1).rar 看广告高速下载：Atmosphere0.18.1+Hekate5.5.4-v2(支持11.0.1).rar Atmosphere0.18.0+Hekate5.5.4-v2(支持11.0.1).rar 看广告高速下载：Atmosphere0.18.0+Hekate5.5.4-v2(支持11.0.1).rar Atmosphere0.18.0+Hekate5.5.3(支持11.0.1).rar 看广告高速下载：Atmosphere0.18.0+Hekate5.5.3(支持11.0.1).rar Atmosphere0.17.1+Hekate5.5.3(支持11.0.1).rar 看广告高速下载：Atmosphere0.17.1+Hekate5.5.3(支持11.0.1).rar Atmosphere0.17.0+Hekate5.5.2(支持11.0.1).rar 看广告高速下载：Atmosphere0.17.0+Hekate5.5.2(支持11.0.1).rar Atmosphere0.16.2+Hekate5.5.1(支持11.0.1).rar 看广告高速下载：Atmosphere0.16.2+Hekate5.5.1(支持11.0.1).rar Atmosphere0.16.1-p1+Hekate5.5.1(支持11.0.1).rar 看广告高速下载：Atmosphere0.16.1-p1+Hekate5.5.1(支持11.0.1).rar Atmosphere0.16.0-p2+Hekate5.5.0(支持11.0.0).rar 看广告高速下载：Atmosphere0.16.0-p2+Hekate5.5.0(支持11.0.0).rar Atmosphere0.15.0+Hekate5.3.4(支持10.2.0).rar 看广告高速下载：Atmosphere0.15.0+Hekate5.3.4(支持10.2.0).rar Atmosphere0.14.4+Hekate5.3.3(支持10.2.0).rar 看广告高速下载：Atmosphere0.14.4+Hekate5.3.3(支持10.2.0).rar Atmosphere0.14.3+Hekate5.3.3(支持10.2.0).rar 看广告高速下载：Atmosphere0.14.3+Hekate5.3.3(支持10.2.0).rar Atmosphere0.14.2+Hekate5.3.2(支持10.1.1).rar 看广告高速下载：Atmosphere0.14.2+Hekate5.3.2(支持10.1.1).rar Atmosphere0.14.1+Hekate5.3.2(支持10.1.0).rar 看广告高速下载：Atmosphere0.14.1+Hekate5.3.2(支持10.1.0).rar 如您从本文得到了有价值的信息或帮助，请考虑扫描文末的二维码对我进行捐赠和鼓励。 特别鸣谢p6天下第一 发布的：大气层屏蔽任天堂服务hosts 感谢热心的 震震 同学使用硬破设备协助测试核对大气层包功能。 感谢热心访客 split_rain 留言提供RCMloader 固件更新资讯：RCMloader one plus v2.02 固件升级软件 感谢热心访客 凌魔火影 留言从细节上辅证访客 split_rain 的固件更新反馈及相关细节补充。 相关资料与GitHubhttps://github.com/Atmosphere-NX/Atmosphere/releaseshttps://github.com/CTCaer/hekate/releasesSigpatches for Atmosphere(Hekatefss0fusee-secondary only!) 本站资源，请 注册城通账户 后，使用客户端下载，参考教程：城通网盘如何使用客户端下载文件。 如本文对您有用，捐赠和留言 将是对我最好的支持~（捐赠可转为站内积分）如愿意，请向朋友推荐本站，谢谢。 尊重他人劳动成果。转载请务必附上原文链接，我将感激不尽。 与《Switch 大气层 Atmosphere 最新版 历史版 下载》相关的博文： Switch Firmware 固件 最新版 历史版 NS 历史版本 下载 Switch 大气层 Atmosphere 如何制作虚拟系统 双系统制作 教程 Switch 大气层 Atmosphere 如何启用FTP功能 Switch 大气层 Atmosphere 如何启用禁用免短接功能 Switch 大气层 Atmosphere 如何离线升降级系统","tags":["clippings"],"categories":["5.生活","手机相机游戏机"]},{"title":"Switch双系统：2024.6，自己动手丰衣足食版_switch大气层-CSDN博客","path":"/2025/01/16/5-生活-手机相机游戏机-Switch双系统：2024-6，自己动手丰衣足食版-switch大气层-CSDN博客/","content":"文章目录 资源（追本溯源） Atmosphere Hekate Rekado DBI NXThemesInstaller Tesla-Menu SysClk RetroArch 其他常用插件 基础教程（自己动手丰衣足食版） 大气层双系统教程 安装插件 大气层系统升级 救砖和恢复官方系统版本 其他 不推荐使用使用Mac系统连接Switch 返回Hekate界面 虚拟系统的Switch版本更新 安装游戏方法 主题 快捷浮层菜单 超频 全能模拟器 操作存档文件 使用金手指 修改游戏的TID、标题、图标、封面和引导图等 刷Amiibo XCI NSP NSZ格式转换方法 Dump卡带和数字版游戏 其他 资源（第三方） 整合包 NS历史固件 游戏 主题 模拟游戏ROM 金手指、MOD、游戏存档、汉化等 更多 资源（追本溯源）Atmosphere官网：https://github.com/Atmosphere-NX/Atmosphere 官方文档：https://github.com/Atmosphere-NX/Atmosphere/blob/master/docs/main.md 官方下载地址：https://github.com/Atmosphere-NX/Atmosphere/releases 2024.6最新版本（1.7.0官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401320 大气层（Atmosphere）系统是针对任天堂Switch游戏主机的一种定制固件，它允许用户解锁Switch的官方限制，从而能够安装自制软件、备份游戏、修改系统设置等，极大地扩展了Switch的功能性和可玩性。以下是大气层系统的一些特点和使用时的注意事项： 自定义功能：提供用户界面（如Aurora菜单）的定制，允许用户更改主题、布局等，增强个性化体验。 备份与恢复：支持游戏存档和整个系统的备份，方便管理和保护数据。 扩展游戏兼容性：可以运行各种自制程序和游戏，包括那些未经Nintendo正式认证的。 性能调整：允许用户调整系统性能参数，如CPU频率，以优化游戏表现。 安全性：在线使用自定义固件、非官方修改版系统的设备可能会导致Nintendo封禁账户，建议使用单独的账户进行离线游戏。 保修：使用此类自定义固件可能违反设备制造商的服务条款，导致失去官方保修，送修前可以逆向删除自定义固件系统即可完美复原官方系统。 系统更新：官方系统更新可能与大气层不兼容，更新前应确认是否有相应的自定义固件、非官方修改版系统可用。 Hekate官网：https://github.com/CTCaer/hekate 官方配置文档：https://github.com/CTCaer/hekate 官方下载地址：https://github.com/CTCaer/hekate/releases 2024.6最新版本（6.1.1官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401360 Hekate是一款为Nintendo Switch定制的多功能引导加载程序，广泛应用于Switch的自定义固件场景，特别是与大气层（Atmosphere）系统配合使用。它提供了丰富的功能，帮助用户管理及维护他们的Switch设备，以下是几个核心功能的介绍： 修复SD卡格式异常：Hekate具有磁盘工具，能够检测并修复SD卡的文件系统错误，包括FAT32格式的修复，这对于维护SD卡的健康状态和确保系统启动至关重要。 备份与恢复NAND：Hekate允许用户完整备份Switch的内部存储（NAND），这是保护系统数据安全的重要步骤。在遇到系统崩溃或需要恢复出厂设置时，可以通过之前备份的NAND镜像快速恢复到之前的系统状态，保留所有游戏进度和设置。 获取本机密钥信息：在首次安装大气层或其他自定义固件时，Hekate能帮助提取Switch的唯一密钥信息，这是安装自定义固件所必需的步骤，确保系统能够正确地验证和运行自制软件。 USB传输：Hekate提供了一个便利功能，即能让Switch通过USB接口以大容量存储设备（U盘模式）连接到电脑，便于用户在Switch和电脑之间传输文件，如安装大型游戏、备份文件或更新自制内容，大大提升了数据管理的效率。 高级调试与定制：对于高级用户，Hekate提供了丰富的调试选项和自定义启动设置，包括但不限于修改启动参数、选择不同的payloads（如大气层启动）、调整系统时钟速率（超频降频）等，满足用户对系统性能调校的需求。 安全与恢复：包含恢复菜单，当系统因错误配置或软件冲突导致无法启动时，Hekate能够作为安全网，帮助用户恢复系统至可启动状态。 Rekado官网：https://github.com/MenosGrante/Rekado 官方文档：https://github.com/MenosGrante/Rekado 官方下载地址：https://github.com/MenosGrante/Rekado/releases 2024.6最新版本（5.2官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89400253 Rekado是一个安卓应用，是一款专为Nintendo Switch设计的payload注入器工具。通过简单的用户界面，Rekado能够将特定格式的payload文件（如Hekate.bin）注入Switch系统，实现Hekate的启动。 DBI官网：https://github.com/rashevskyv/dbi 官方文档地址：https://github.com/rashevskyv/dbi/blob/main/README_ENG.md 官方下载地址：https://github.com/rashevskyv/dbi/releases 2024.6最新版本（658官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401747 用于安装 NSP、NSZ、XCI 和 XCZ 并能与 Nintendo Switch 协同使用的终极解决办法。支持经由 MTP、USB、http（自个人服务器）、外部 USB 等途径进行安装。支持查看 jpg、png 和 psd 格式的图像。支持运用 zip 和 rar 归档，以及使用 cbrcbz 容器。支持文本文件、纯文本视图以及十六进制视图。可当作文件管理器（对文件和文件夹进行复制、移动、删除以及创建文件夹）。用于保存（包含备份与恢复）等等。 NXThemesInstaller官网：https://github.com/exelix11/SwitchThemeInjector 官方文档：https://github.com/exelix11/SwitchThemeInjector 官方下载地址：https://github.com/exelix11/SwitchThemeInjector/releases 2024.6最新版本（2.7.1官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89402016 主题资源参见下文第三方资源部分。 NXThemesInstaller允许用户轻松安装和管理主机的主题界面，个性化定制Switch的视觉效果。通过下载自定义主题，用户可以简单操作即换上心仪的主题包，为Switch带来耳目一新的操作界面，增强了系统的可玩性和趣味性。 Tesla-Menu官网：https://github.com/WerWolv/Tesla-Menu 官方文档：https://github.com/WerWolv/Tesla-Menu 官方下载地址：https://github.com/Team-Neptune/Tesla-Menu/releases 2024.6最新版本（1.2.3版本）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401877 Tesla-Menu是一款专为Switch大气层系统设计的悬浮菜单插件，它通过快捷键呼出，提供游戏途中快速访问系统功能、调整设置（如显示FPS、切换模式）及管理插件的能力，极大提升了操作便利性和系统自定义程度，是提升Switch游玩体验的实用工具。 SysClk官网：https://github.com/retronx-team/sys-clk 官方文档地址：https://github.com/retronx-team/sys-clk 官方下载地址：https://github.com/retronx-team/sys-clk/releases 2024.6最新版本（2.0.0 r4版本）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401952 Switch大气层系统的SysClk插件是一款专为Nintendo Switch自制系统设计的超频工具，它允许用户调整主机的CPU、GPU及内存的工作频率，实现动态超频或降频。通过这一插件，玩家能够根据实际需求优化系统性能，特别是在运行一些对硬件要求较高的大型游戏时，能够提升游戏运行的流畅度和画质表现。 RetroArch官网：https://www.retroarch.com/ 官方文档地址：https://docs.libretro.com/guides/install-libnx/ 官方下载地址：https://www.retroarch.com/?page=platforms 2024.6最新版本（1.19.1官方正式版）也可使用CSDN本地下载地址：https://download.csdn.net/download/zhiyuan411/89401722 游戏ROM资源参见下文第三方资源部分。 RetroArch 是一款高度可定制化的跨平台全能模拟器，由 Libretro 团队开发。它不仅模拟单一游戏平台，而是通过不同的“核心”(cores) 支持多种游戏机和计算机系统，允许用户在单一应用中玩遍NES、SNES、Game Boy Advance、Sega Genesis乃至PlayStation等众多平台的经典游戏。RetroArch 还提供了高级功能，比如实时重播、网络对战、各种视频滤镜和增强功能，以及高度可配置的控制设置。 其他常用插件 JKSV Emuiibo EdiZon-SE Tinfoil Breeze-Beta CheckPoint NSC_BUILDER NSGameManager Haku33 NxNandManager BCAT nxdumptool 90DNS MissionControl sys-con nx-btred NX-Activity-Log PKHeX SysDVR Browser Reboot-to-Hekate Reset-Parental-Controls Moonlight-Switch 基础教程（自己动手丰衣足食版）大气层双系统教程为Nintendo Switch安装大气层（Atmosphere）双系统，即在保留原版官方系统的同时安装大气层自定义固件。 准备工作： 备份数据：首先备份Switch的所有重要数据，包括游戏存档、截图等，以防意外丢失。 下载大气层整合包或纯净版：从可靠的来源下载适用于你Switch型号和当前系统版本的大气层整合包。安装无插件的纯净版则只需要提前下载好大气层系统固件和Hekate。 SD卡：准备一个质量良好的SD卡，格式化为FAT32（或exFAT，如果游戏文件超过4GB），并确保有足够的容量安装大气层：32G机型至少需要32G，推荐64G以上，64G机型则翻倍。 读卡器：使用高速的读卡器，以便快速传输大文件。 步骤1：解锁Switch 无论什么设备，要刷机首先要解锁bootloader。查找并遵循适用于你Switch型号的初始解锁教程。 早期的NS型号，首发和之后的几个生产批次的机器因为存在Tegra X1芯片漏洞，是可以软件解锁的。但任天堂在后续生产的新Switch型号中对硬件做了改动，修补了该漏洞，故只能通过修改硬件手段来绕过系统安全措施。 早期的NS型号，利用针脚短接方式来加载payload： 可以软件解锁的版本序列号： 在手机上下载软件版注入器App：Rekado（电脑版使用TegraRcmGUI，原理亦同）。或者使用三方注入器（RCMloader、ns-ATMOSPHERE等，大约几十元价格）。 将Switch关机。然后使用Type-C数据线（可以传输数据的，而非仅限于充电）将Switch和手机连接，或者将三方注入器插入Switch； 可以参见B站教程使用锡纸自制短接器，或购买短接器（大约5-10元）。短接针脚后按住音量+键再点击开机，就会进入RCM模式，通过注入器加载Rekado即可启动。 注意：有时候Switch可能插入TYPE-C接口后会自动开机。此时，可以将顺序改为：首先短接针脚，然后按住音量+键，最后在连接手机或插入注入器。 新Switch型号，修改硬件比较专业，可某宝某鱼寻求帮助，或自行查找教程操作。 步骤2：拷贝大气层数据包 整合包只需要复制文件：将下载的大气层整合包解压缩，将其中的文件复制到SD卡的根目录下。 纯净版（无插件）：将下载的大气层固件文件复制到SD卡上。将下载的Hekate文件（通常是.bin格式）改名为payload.bin，并放置在SD卡的根目录下，根据需求自行修改相关配置文件内容，例如hekate_ipl.ini、atmosphereconfig.txt等。 步骤3：创建和设置双系统 备份原始固件（可选但推荐）：在Hekate的Tools工具栏中，选择“Backup emuMMC”，将BOOT（仅引导数据）和RAW GPP（全部数据）均备份完毕，并将生成的备份文件（SD卡根目录backup文件夹内）拷贝出来到可靠的存储空间。 创建虚拟系统：在Hekate主界面中创建一个emuMMC虚拟系统。这是大气层系统独立运行的空间，与原装系统隔离的系统环境，你在emuMMC上的任何修改、操作都不会影响Switch的原装系统，保持了原装系统的纯净性和可恢复性。 进入 Hekate 启动页后，点击右侧的“emuMMC”（虚拟系统）； 点击“Create emuMMC”，在弹出的虚拟系统类型提示框中点击“SD File”； 耐心等待虚拟系统创建结束，然后点击右上角“Close”返回到虚拟系统管理页； 此时左上角已经会显示“Enabled!”，点击右上角“Close”，返回首页； 配置启动菜单：设置Hekate引导菜单以允许在启动时选择进入原版系统还是大气层系统。在Hekate的各级菜单中根据自己的偏好进行设置。 设置AutoCRM：在Hekate的工具栏打开AutoCRM选项。这可以让Switch在没有物理短接的情况下也能自动进入RCM模式，进而简化大气层系统的启动流程。 断网后测试大气层系统：首先断开家里网络，以防止大气层系统自动联网导致ban机。启动大气层，检查是否一切正常，然后删除系统记忆的WiFi连接后可以打开家里网络。纯净版可以开始安装必要的插件和补丁。 切换系统：测试从大气层系统切换回官方系统是否顺畅，确保双系统均可正常工作。 安装插件参考所使用的插件的官方说明或提供的教程来进行安装，有可能会需要复制多份文件到多个目录下。 一般的安装方法都是将插件文件放到 /Switch 目录下。 .nro 插件 ：放在根目录的Switch目录下。 压缩包：将压缩包解压后的内容保持原封不动地复制到根目录的Switch目录下。 大气层系统升级 备份重要数据：在进行任何系统级别的操作之前，备份SD卡上的重要数据，特别是emuMMC（虚拟系统）和Nintendo文件夹（包含游戏和存档），以及其他个人数据。 hekate个性化设置：/bootloader文件夹下，res文件夹包含自定义图标，hekate_ipl.ini文件包含个性化设置。 主题：/theme文件夹下，各个子目录均为一个主题包。 Mod文件：/mods文件夹下，各个子目录均为一款游戏Mod。 模拟游戏ROM：/ROM文件夹下，各个子目录均为一款模拟机型。 获取最新大气层整合包：访问GitHub下载最新的大气层安装包或者寻找最新整合包。确保安装包或整合包与当前Switch系统版本兼容。 准备SD卡：将SD卡连接到电脑上。如果后面步骤更新后不正常，在本步骤中保留emuMMC和Nintendo文件夹，先删除其他所有大气层相关的文件和文件夹（如atmosphere、firmware、titles等），但请先备份这些文件以防万一。（有金手指、主题、汉化补丁等文件，也应保留） 复制整合包到SD卡：将下载的最新大气层整合包解压后，将其中的所有文件和文件夹复制到SD卡的根目录，覆盖原有的大气层文件。 恢复备份数据：将之前备份的个性化数据、主题等数据恢复到SD卡中，并可以根据实际情况再做一些设置调整。 安全移除SD卡并插入Switch：安全地将SD卡从电脑移除并插入Switch中。 启动Switch：开机后，如果之前设置了Hekate自动启动大气层，那么它会自动进入大气层系统。如果没有自动启动，需要手动通过Hekate选择启动大气层。 验证升级：进入大气层系统后，可以通过检查系统设置中的大气层版本号来确认升级是否成功。 重新安装必要的插件和补丁：升级后，可能需要重新安装之前使用的金手指、主题、汉化补丁等插件。这些通常位于SD:/atmosphere/contents/目录下。 救砖和恢复官方系统版本 如果开启了AutoRCM选项，首先需要进行关闭： 使用短接器使Switch进入RCM模式。 通过USB线连接Switch到手机使用注入器软件，将Hekate的payload发送至Switch。 在Hekate的工具栏菜单中关闭AutoRCM选项。 在关机状态下启动Switch会自动进入官方系统，在官方系统的设置中选择将SD卡进行格式化，即可完全删除大气层系统。 如果开机无法进入官方系统则需要重新恢复官方固件： 使用短接器、注入器使得Switch进入Hekate界面。 在Hekate的eMMCemuMMC BackupRestore Tools中恢复之前备份的官方系统固件版本，或者恢复网上下载的官方系统固件版本。 其他不推荐使用使用Mac系统连接Switch尽量使用Windows系统连接Switch。因为有些工具如果使用Mac系统连接Switch，可能会导致存储区域格式发生错误异常。 如果已经因为Mac系统连接导致存储区域格式异常，则可以使用Hekate的工具栏的存档位修复器进行修复。 返回Hekate界面有插件 Reboot-to-Hekate 等支持，新版本的大气层系统中，长按电源键，选择重启后，会自动返回Hekate界面。 在老版本系统中，当大气层系统刚开始启动内的几秒内（Hekate内可配置延时），按下音量减键，即可返回Hekate系统。 虚拟系统的Switch版本更新Switch大气层系统中是不能从官方渠道联网在线更新Switch系统版本的。要在Switch大气层系统中离线更新Switch系统版本，可以使用Daybreak插件。 首先下载与设备兼容的系统更新文件至SD卡指定位置，然后从相册中启动Daybreak，按照提示选择更新文件进行安装，完成后重启Switch即可。 不推荐总是将虚拟系统中的Switch系统更新到最新，除非虚拟系统中有新游戏要求更高的系统版本，当前系统版本已经无法满足，否则，不要更新虚拟系统的Switch版本。 安装游戏方法开启Switch进入大气层系统，通过USB连接电脑，从相册启动DBI插件，在DBI中选择MTP传输模式使Switch被识别为外置磁盘，随后直接在电脑上将游戏文件拖拽至Switch相应的安装目录，等待安装完毕，在Switch主界面就可以看到新游戏。 在Switch大气层系统中，之前也会使用GoldLeaf、Tinfoil及LayeredFS等工具或插件来安装和管理游戏，但是现在更推荐使用DBI。 主题使用NXThemesInstaller（或Atmosphere Theme Manager）等工具来安装和管理主题，它们使用的主题文件是兼容的。下载好主题文件（.tik或.zip格式），将文件拷贝到SD卡的适当目录（如atmospherethemes），之后启动主题管理工具，浏览并选择你喜欢的主题进行应用，从而可以个性化你的Switch界面。 快捷浮层菜单特斯拉插件是一个高度集成的自制软件，可以在任何界面展开使用特斯拉插件的快捷浮层菜单，提供了金手指功能、系统性能调整、蓝牙手柄支持、界面美化以及便捷的插件管理，极大地扩展和个性化了Switch的功能体验。 超频超频Switch需要安装超频插件Sys-Clk，配置CPU、GPU频率及电压等参数。 内存可以放心超频。 Tegra是带核显的SoC，内存带宽就是核显带宽，不存在瓶颈。 无论初代版LPDDR4内存还是续航版、Lite版的LPDDR4X内存，Switch原始的1600 MHz的内存频率都是偏低的。 CPU和GPU的安全超频上限通常依据具体的NS机型有所不同。 对于普通版Switch，CPU安全超频上限大致不超过1.75GHz至1.9GHz，而GPU则不宜超过900MHz至1GHz。 对于续航增强版，CPU超频范围相似，GPU安全超频上限建议不超过1.2GHz至1.26GHz。 具体还需视乎散热和系统整体稳定性而调整。 全能模拟器RetroArch 是一个非常流行的全能模拟器工具。允许用户在Switch上模拟运行来自多个平台的经典游戏，包括但不限于FC、SFC、GBA、GBC、MD、PSP、PS1、N64以及各种街机游戏。 除了RetroArch这一全能模拟器之外，还有一些专注于特定平台的模拟器： melonDS 或其他NDS模拟器：用于模拟任天堂DS游戏，提供较好的图形渲染和兼容性，支持触控操作模拟。 YUZU：这是一个专为Nintendo Switch设计的实验性Nintendo 3DS模拟器，随着不断的开发更新，已经能够运行不少3DS游戏，虽然性能和兼容性还在逐步提升中。 Snes9x 或 higan：这些模拟器用于模拟超级任天堂（SNES）游戏，提供高质量的图形输出和广泛的兼容性。 DuckStation：这是一个PlayStation 1模拟器，提供了增强图形选项，如高清纹理和更宽的渲染比例，让PS1游戏在现代屏幕上看起来更加出色。 PPSSPP：用于模拟PSP游戏的一个流行选择，当配置得当时，能够提供良好的游戏体验。 Genesis Plus GX 或其他Sega MD模拟器：这些模拟器专注于世嘉Mega Drive（Genesis）游戏的模拟，允许用户在Switch上玩经典的Sega游戏。 VBANext：这是一个Virtual Boy模拟器，尽管Virtual Boy本身并不成功，但对于想要探索任天堂这一独特掌机历史的玩家来说，这个模拟器提供了一个途径。 操作存档文件使用JKSV或Checkpoint进行游戏存档的导入与导出： KSV：通过USB连接Switch到电脑，启动JKSV插件后，使用电脑访问Switch的SD卡，直接在JKSV文件夹内拷贝游戏存档文件来回进行存档的导入与导出。 Checkpoint：在Switch上安装Checkpoint应用，运行后选择游戏，利用Checkpoint的图形界面直接在Switch上备份存档至SD卡或从SD卡恢复备份的存档，实现存档管理。 使用金手指使用游戏金手指通常推荐使用Edizon工具。首先，确保金手指文件与你的游戏版本匹配，并将其放置于SD卡的相应目录；然后，启动Switch并运行游戏；接下来，打开Edizon，选择游戏数据搜索界面；输入游戏中你想修改的数值进行搜索，锁定或修改后返回游戏，即可看到金手指效果。 修改游戏的TID、标题、图标、封面和引导图等在Switch大气层系统中，要解包、修改游戏的TID、标题、图标、封面和引导图等元数据，通常会使用工具NSCB（Nintendo Switch Content BuilderExtractor）。首先，使用NSCB提取游戏文件，对其进行所需的修改，如更换图标和封面图片，以及编辑标题和TID等信息；接着，利用该工具将修改后的文件重新打包为NSP格式，最后通过大气层系统的安装器安装到Switch上。这样，就能自定义游戏的外观和部分元数据信息。 刷Amiibo打开emuiibo，通过简单的用户界面选择或导入Amiibo数据，随后在游戏中Amiibo识别区域激活相应功能，无需额外硬件，就能方便地享受Amiibo带来的游戏内福利与互动体验。 XCI NSP NSZ格式转换方法转换XCI、NSP、NSZ格式游戏时，可借助NSC_BUILDER工具，实现格式之间的相互转换，如NSZ转NSPXCI，XCI与NSP之间的互换。 Tinfoil、SAK等工具也可以完成相似功能。 Dump卡带和数字版游戏在Switch大气层系统中，使用nxdumptool工具进行游戏Dump。对于卡带游戏，启动nxdumptool选择“Dump gamecard content”并执行XCI Dump；而对于数字版游戏，则选择“Dump installed SD cardeMMC content”，之后选定游戏执行NSP Dump，整个操作直接在Switch的大气层系统中完成。 其他 可以将虚拟系统的系统空间（一般为 30G 大小）借助NxNandManager工具进行精简。需完成虚拟系统制作和备份密钥，过程比较复杂。 使用ftpd工具可以启用 FTP 功能。 使用 Switch_90DNS_tester 工具可以查本机有没有屏蔽任天堂服务，和一键进行屏蔽。 资源（第三方）整合包 Switch-17.0.0大气层整合包-支持系统18.0.1|纯净版+特斯拉版 ：有更新后可以从 Switch520网站 的Switch菜单中自行寻找最新版本整合包。 MSSJ 个人大气层整合包 1.7.0 v8.0 适用于18.0.0系统 等：可以从 “switch交流吧”的吧主推荐 的最新帖子中寻找更新。 NS历史固件 Switch Firmware 历代固件+18.0.1 固件与整合包大全 游戏Switch520游戏下载：switch游戏及相关资源网站，无会员，完全免费，防丢链接为 Switch520防迷路网址 主题 Switch520 Switch主题 品技论坛 Switch主题分享 模拟游戏ROMNS全能模拟器Retroarch 1.1x.0 更新：更多资源可以在品技论坛搜索。 金手指、MOD、游戏存档、汉化等在 品技论坛 Nintendo Switch 综合讨论区 有对应的子版块，也可以论坛内搜索。品技论坛，也就是 91TVG， 是一个人气很高的switch论坛，前身是 91wii，在wii时代就很有名。 更多参见：https://blog.csdn.net/zhiyuan411/article/details/130254190","tags":["clippings"],"categories":["5.生活","手机相机游戏机"]},{"title":"字节序(byte order)和位序(bit order)_字节序起始位计算-CSDN博客","path":"/2025/01/16/2-语言-C语言-位运算-字节序-byte-order-和位序-bit-order-字节序起始位计算-CSDN博客/","content":"字节序(byte order)和位序(bit order) 在网络编程中经常会提到网络字节序和主机序，也就是说当一个对象由多个字节组成的时候需要注意对象的多个字节在内存中的顺序。 以前我也基本只了解过字节序，但是有一天当我看到ip.h中对IP头部结构体struct iphdr的定义时，我发现其中竟然对一个字节中的8个比特位也区分了大小端，这时我就迷糊了，不是说大小端只有在多个字节之间才会有区分的吗，为什么这里的定义却对一个字节中的比特位也区分大小端呢? 下面我们先看一下struct iphdr的定义，后文会解惑为什么要在一个字节中区分大小端。 struct iphdr #if defined(__LITTLE_ENDIAN_BITFIELD) __u8 ihl:4, version:4;#elif defined (__BIG_ENDIAN_BITFIELD) __u8 version:4, ihl:4;#else#error Please fix asm/byteorder.h#endif __u8 tos; __be16 tot_len; __be16 id; __be16 frag_off; __u8 ttl; __u8 protocol; __sum16 check; __be32 saddr; __be32 daddr; /*The options start here. */;12345678910111213141516171819202122 字节序(Byte order) 关于字节序的文章已经有很多了，在我这篇文章中不打算过多的说字节序，但是也不能完全脱离字节序因为后面的重点部分比特序跟字节序也有一定的相似度和联系。 字节序就是说一个对象的多个字节在内存中如何排序存放，比如我们要想往一个地址a中写入一个整形数据0x12345678，那么最后在内存中是如何存放这四个字节的呢？ 0x12这个字节值为最高有效字节，也就是整数值的最高位(在本文中0x120x12000000)，0x78为最低有效字节。 图1：大端字节序上图是大端字节序的示意图，所谓”大端字节序”，便是指最高有效字节落在低地址上的字节存放方式。 图2：小端字节序 而小端字节序就是最低有效字节落在低地址上的字节存放方式。 0x123456780x12000000 + 0x340000 + 0x5600 + 0x78，所以要想保持一个对象的值在大小端系统之间不变，那么就必须确保不同的系统能够正确的识别最高有效字节和最低有效字节(不能错误的识别最高、最低有效字节)。 同样的字节序12 34 56 78在大端序机器中会识别为0x12345678(0x12000000 + 0x340000 + 0x5600 + 0x780x12345678)，在小端序机器中识别为0x78563412(0x12 + 0x3400 + 0x5600 00+ 0x780000000x78563412)。 所以要想两者保持一致就必须确保系统能够正确的识别最高有效字节0x12和最低有效字节0x78，那么在小端系统中字节存放的顺序应该为78 56 34 12。 比特序(bit order) 字节序是一个对象中的多个字节之间的顺序问题，比特序就是一个字节中的8个比特位(bit)之间的顺序问题。一般情况下系统的比特序和字节序是保持一致的。 一个字节由8个bit组成，这8个bit也存在如何排序的情况，跟字节序类似的有最高有效比特位、最低有效比特位。 比特序1 0 0 1 0 0 1 0在大端系统中最高有效比特位为1、最低有效比特位为0，字节的值为0x92。在小端系统中最高、最低有效比特位则相反为0、1，字节的值为0x49。 跟字节序类似，要想保持一个字节值不变那么就要使系统能正确的识别最高、最低有效比特位。 字节序转换函数ntohl(s)、htonl(s) 在socket编程中经常要用到网络字节序转换函数ntohl、htonl来进行主机序和网络序(大端序)的转换，在主机序为小端的系统中字节序列78 56 34 12(val0x12345678)经过htonl转换后字节序列变成12 34 56 78： 图3：htonl函数 字节序转换后我在想是不是比特序也一同进行了转换? 为什么会有这个疑问呢，因为前文可知系统的比特序和字节序是一致的，现在字节序已经从小端变成了大端那么比特序应该也要一起转换。而且如果比特序不变化那么当这些字节到了目标大端序系统中后每一个字节的值都会发生变化，因为同样的比特序列在小端和大端系统中识别的字节值会不一样。 首先从htonl、ntohl的源码来看确实只进行了字节序的转换并没有进行比特序的转换，再有就是以前socket编程的时候只调用了ntohl、htonl等函数并没有调用(而且系统也没有提供)比特序转换函数，但是最后的结果都是正确的，并没有发现上面提到的字节值发生变化的问题。 那么这个”神奇”的事情是怎么解决的呢，好像系统本身就给我们”悄悄”的解决了我担心的问题。答案我们下文揭晓。 比特(bit)的发送和接收顺序 比特的发送、接收顺序是指一个字节中的bit在网络电缆中是如何发送、接收的。在以太网(Ethernet)中，是从最低有效比特位到最高有效比特位的发送顺序，也就是最低有效比特位首先发送，参考资料：frame。 在以太网中这个规定有点奇怪，因为字节序我们是按照大端序来发送，但是比特序却是按照小端序的方式来发送，下图是直接从网上找来的一张图，主机序本身是大端序： 图4：比特发送、接受示意图 比特的发送、接收顺序对CPU、软件都是不可见的，因为我们的网卡会给我们处理这种转换，在发送的时候按照小端序发送比特位，在接收的时候会把接收到的比特序转换成主机的比特序，下面是一个小端机器发送一个int整型给一个大端机器的示意图： 图5：小端-大端比特发送示例 因为对网卡对比特序的发送、接收所做的转换没有深入的了解所以上图很有可能会有错误之处。 现在来回答一下第3节中的那个疑问： htonl、ntohl函数肯定是不会同步转换一个字节中的比特序的，因为如果比特序也发生了转换的话那么这个字节的值也就发生了变化，记住htonl、ntohl只是字节序转换函数。 比特序按照小端的方式发送，首先发送的是最低有效比特位，最后发送的是最高有效比特位，接收端的网卡在接收到比特序列后按照主机的比特序把接收到的”小端序”比特流转换成主机对应的比特序列。 可以假设存在ntohb、htonb(b代表bit)这样的两个函数，网卡进行了比特序的转换，不过是这两个函数是网卡自动调用的，我们平时不用关注。 按照规则，发送、接收的时候进行比特序的转换，那么就能保证在不同的机器之间进行通信不会发生我担心的字节值发生变化的问题。 结构体的位域 关于C语言中结构体的位域可以参考这篇文章：http://tonybai.com/2013/05/21/talk-about-bitfield-in-c-again/，对于位域的具体用法、语法参考这篇文章即可有。 对于位域有一个约定：在C语言的结构体中如果包含了位域，如果位域A定义在位域B之前，那么位域A总是出现在低序的比特位。在计算机中可寻址的最小单位为字节，bit是无法寻址的，但是为了抽象我们可以把计算机的最小寻址单位变成bit，也就是我们可以单独获得一个bit位。 我们有如下的一段代码： #includestdio.hstruct bit_order unsigned char a: 2, b: 3, c: 3;;int main(int argc, char *argv[]) unsigned char ch = 0x79; struct bit_order *ptr = (struct bit_order *)ch; printf(bit_order-a : %u , ptr-a); printf(bit_order-b : %u , ptr-b); printf(bit_order-c : %u , ptr-c); return 0;1234567891011121314151617181920 我们把代码在gentoo(intel小端机器)、hu-unix(大端机器)两个机器上面编译、运行，结果如下： liuxingen@ V6-Dev ~station $ .bitfiledbit_order-a : 1bit_order-b : 6bit_order-c : 3下面是hp-unix的运行结果# .bitfiledbit_order-a : 1bit_order-b : 7bit_order-c : 1 我们先分析一下gentoo上面的结果： 图6：小端机器的位域示例 从上图中我们很容易就能理解gentoo上面的输出结果，下面是hp-unix上面示意图： 图7：大端机器的位域示例 从上面的输出可以看到同样的代码在不同的机器中输出了不同的结果，也就是说我们的代码在不同的平台不能直接移植，导致这个问题的原因就是我们前面提到的关于位域的一个约定，定义在前面的位域总是出现在低地址的bit位中，因为不同的平台的比特序是不同的，但是我们定义的位域没有根据平台的大小端进行转换，最后就导致了问题。那么如何解决这个问题，那就是在定义结构体中的位域时判断平台的大小端： #includestdio.h#includeasm/byteorder.hstruct bit_order#if defined(__LITTLE_ENDIAN_BITFIELD) unsigned char a: 2, b: 3, c: 3;#elif defined (__BIG_ENDIAN_BITFIELD) unsigned char c: 3, b: 3, a: 2;#else#error Please fix asm/byteorder.h#endif;int main(int argc, char *argv[]) unsigned char ch = 0x79; struct bit_order *ptr = (struct bit_order *)ch; printf(bit_order-a : %u , ptr-a); printf(bit_order-b : %u , ptr-b); printf(bit_order-c : %u , ptr-c); return 0;1234567891011121314151617181920212223242526272829 到此我们也就解释了文章开头关于struct iphdr定义中的那个疑问。 最后给大家隆重介绍一篇文章，对我启发很大，文中的很多知识来自于它：byte order and bit order","tags":["clippings"],"categories":["2.语言","C语言","位运算"]},{"title":"字节序与位序详解-CSDN博客","path":"/2025/01/16/2-语言-C语言-位运算-字节序与位序详解-CSDN博客/","content":"Endianness字节序大家见得比较多，网络上论述也比较多。这里简要介绍：书写十六进制数据时，我们习惯上 MSB 在左，而 LSB 在右。 LSB: least significant byte MSB: most significant byte 大端：Big-endian数据在内存中(地址由低到高)的存放顺序和书写顺序是一致的。记忆方法：低地址放的是数据的 MSB，所以称作大端。低地址存 MSB，高地址存 LSB。 小端：Litthle-endian数据在内存中(地址由低到高)的存放顺序和书写顺序是相反的。记忆方法：低地址放的是数据的 LSB，所以称作小端。即“高高低低”。低地址存 LSB，高地址存 MSB。 如何写出兼容大小端的代码编码时如果不注意大小端的问题，容易在可移植性上打折扣，并且出问题时不容易定位。特别是指针操作，常见的问题如下： 将长类型数据强转成短类型的指针进行操作 long long val = 0;void func((int *)val);...check(val);1234 上面的代码在大端情况下就容易出问题。例如 func 里将 val 处赋值 int 类型的数据 0x1122,3344。check(val) 时，由于 val 为 8 字节的数据，此时实际读取到的值为 0x1122,3344,0000,0000。小端场景则无此问题，读者可以自己思考一下为什么。 Bit numbering我们知道一个字节有 8 个比特位。从第 0 位到第 7 位共 8 位。位序描述比特位在字节中的存放顺序。可参阅 维基百科中关于位序的描述。 这里的 LSB 及 MSB 的用词代表的是： LSB是指 least significant bit MSB是指 most significant bit 位序分为两种： LSB 0字节的第 0 位存放数据的 least significant bit，即我们的数据的最低位存放在字节的第 0 位。以十进制150为例，0b10010110。在LSB 0方式下存放形式为： | 7 0 |---------------------------------| 1 | 0 | 0 | 1 | 0 | 1 | 1 | 0 |---------------------------------1234 Least Significant Bit First means that the least significant bit will arrive first. 数据流从 bit0 开始传送，故数据流出现的顺序是 01101001。 MSB 0字节的第 0 位存放数据的 most significant bit，即我们的数据的最高位存放在字节的第 0 位。以十进制150为例，0b10010110。在MSB 0方式下存放形式为： | 7 0 |---------------------------------| 0 | 1 | 1 | 0 | 1 | 0 | 0 | 1 |---------------------------------1234 Most Significant Bit First means that the most significant bit will arrive first. 也就是说数据流出现的顺序是 10010110。 实际机器类型字节序是小端的 CPU 通常其位序为 LSB 0。数据不仅在内存中是“高高低低”存放，其位序也是“高高低低”放置的，即 msb 放在 bit7 位置上，lsb 放置在 bit0 位置上。值得注意的是，字节序是大端的 CPU 采用的位序却不是那么统一，既有 MSB 0，也要 LSB 0 的机器。 Bit order usually follows the same endianness as the byte order for a given computer system. That is, in a big endian system the most significant bit is stored at the lowest bit address; in a little endian system, the least significant bit is stored at the lowest bit address. 如果我们要表示一个整数 0xabcd。 Write Integer for Big Endian System byte addr 0 1 2 3bit offset 01234567 01234567 01234567 01234567 binary 00001010 00001011 00001100 00001101 hex 0a 0b 0c 0d1234 Write Integer for Little Endian System byte addr 3 2 1 0bit offset 76543210 76543210 76543210 76543210 binary 00001010 00001011 00001100 00001101 hex 0a 0b 0c 0d1234 位域 Bit Fields For big-endian mode, bit fields are packed into registers from most significant bit (MSB) to least significant bit (LSB) in the order in which they are defined. Bit fields are packed in memory from most significant byte (MSbyte) to least significant byte (LSbyte).For little-endian mode, bit fields are packed into registers from the LSB to the MSB in the order in which they are defined, and packed in memory from LSbyte to MSbyte. 大小端对位域打包方式的影响 大端场景下根据定义的顺序，从 MSB 开始排布到 LSB。小端场景下根据定义的顺序，从 LSB 开始排布到 MSB。 位域的类型可以是 unsigned signed 包含位域的结构体的大小和对齐值取决于定义位域所使用的数据类型如 struct st { int a:4 }; 该结构体的大小为4，对齐值为4。 无名位域会影响结构体或联合体的大小和对齐值如 struct st { char a:4; int :22; }; 该结构体的大小为4，对齐值为4。 struct int A:7;\tint B:10;\tint C:3;\tint D:2;\tint E:9; x;1234567 LEGEND: X = not used, MS = most significant, LS = least significantBig-endian register MS LSA A\tA A\tA A\tA B\tB B\tB B\tB B\tB B\tB C\tC C\tD D\tE E\tE E\tE E\tE E\tE X6 5\t4 3\t2 1\t0 9 8 7 6 5\t4 3\t2 1\t0 2\t1 0\t1 0\t8 7 6 5\t4 3\t2 1\t0 X31 0Big-endian memory Byte 0 Byte 1 Byte 2 Byte 3A A\tA A A A A B B B B B B B B B B C C C D D E E E E\tE E\tE E\tE X6 5\t4 3\t2 1\t0 9\t8 7\t6 5\t4 3\t2 1\t0 2\t1 0\t1 0\t8 7\t6 5\t4 3\t2 1\t0 XLittle-endian register MS LSX E\tE E\tE E\tE E\tE E\tD D\tC C\tC B\tB B\tB B\tB B\tB B\tB A\tA A\tA A\tA AX 8\t7 6\t5 4\t3 2\t1 0\t1 0\t2 1\t0 9\t8 7\t6 5\t4 3\t2 1\t0 6\t5 4\t3 2\t1 031 0Little-endian memory Byte 0 Byte 1 Byte 2 Byte 3B A\tA A\tA A\tA A\tB B\tB B\tB B\tB B\tE E\tD D\tC C\tC B\tX E\tE E\tE E\tE E0 6\t5 4\t3 2\t1 0\t8 7\t6 5\t4 3\t2 1\t1 0\t1 0\t2 1\t0 9\tX 8\t7 6\t5 4\t3 21234567891011121314151617181920212223 以下面的数据类型为例。 union unsigned short value;\tunsigned char byte[2];\tstruct unsigned short one : 1; unsigned short two : 2; unsigned short three : 3; unsigned short four : 4; unsigned short five : 5; field; u;1234567891011 其排布为：大端场景 小端场景 可以通过下面的程序来验证一下。 #include stdio.hint main() union unsigned short value; unsigned char byte[2]; struct unsigned short one : 1; unsigned short two : 2; unsigned short three : 3; unsigned short four : 4; unsigned short five : 5; field; u;\tu.value = 0;\tu.field.one = 1;\tu.field.two = 2;\tu.field.three = 3;\tu.field.four = 4;\tu.field.five = 5;\tprintf(The fields are 1, 2, 3, 4, 5. );\tprintf(The entire hex value is 0x%04x , u.value);\tprintf(The first byte is 0x%02x , u.byte[0]);\tprintf(The second byte is 0x%02x , u.byte[1]);\treturn 0;1234567891011121314151617181920212223242526272829 在 x86 小端，arm，aarch64 大小端场景下的测试结果如下： // x86 小端The fields are 1, 2, 3, 4, 5.The entire hex value is 0x151dThe first byte is 0x1dThe second byte is 0x15// aarch64_beThe fields are 1, 2, 3, 4, 5.The entire hex value is 0xcd0aThe first byte is 0xcdThe second byte is 0x0a// armebThe fields are 1, 2, 3, 4, 5.The entire hex value is 0xcd0aThe first byte is 0xcdThe second byte is 0x0a// armThe fields are 1, 2, 3, 4, 5.The entire hex value is 0x151dThe first byte is 0x1dThe second byte is 0x15// aarch64The fields are 1, 2, 3, 4, 5.The entire hex value is 0x151dThe first byte is 0x1dThe second byte is 0x15 字节序测试#include stdio.hint main() union char c; int i; u; u.i = 0x11223344; if(u.c == 0x44) printf(little-endian ); else if (u.c == 0x11) printf(big-endian ); else printf(unknown ); return 0;123456789101112131415161718 位序测试union struct unsigned char a1:2; unsigned char a2:3; unsigned char a3:3; x;\tunsigned char b; d;int main (void)\td.b = 150;\tprintf(0x%x 0x%x 0x%x , d.x.a1, d.x.a2, d.x.a3); return 0;123456789101112131415 结果如下： // 150 == 0b1001 0110arm, aarch64/* bit numbering: lsb 0 * 0x2 （== 10） * 0x5 （== 101） * 0x4 （== 110） * /armeb, aarch64_be/* bit numbering: lsb 0 * 0x2 （== 10） * 0x2 （== 010） * 0x6 （== 100） * /123456789101112131415","tags":["clippings"],"categories":["2.语言","C语言","位运算"]},{"title":"面向对象基础","path":"/2025/01/10/2-语言-结构算法-面向对象基础/","content":"类与实例对象是一个自包含的实体，用一组可识别的特性和行为来标识。例如，一个具有“名称”、“年龄”和“颜色”属性的猫可被视为对象。 类是指具有相同属性和功能的对象的抽象集合。它定义了对象的特性（属性）和可能执行的操作（方法）。类的定义通常使用 class 关键字。 类的名称通常以大写字母开头，多个单词时采用驼峰式命名法（例如，Animal 或 DogHouse）。 对外公开的方法需要使用 public 修饰符，以便允许其他类访问。 实例是一种真实的对象，实例化是创建对象的过程。使用 new 关键字可以创建类的实例。例如，Cat myCat = new Cat(); 便是创建一个 Cat 类的实例。 public 修饰符意味着该类成员可以被任何其他类访问。 private 修饰符则表示成员只能在本类中访问，其他类包括子类都无法访问。若类的成员没有指定修饰符，则默认为 private。通常采用大写字母开头的命名约定来定义属性（Age），而字段则通常以小写字母开头或前加下划线（_age）。 构造方法构造方法，也称为构造函数，是用于初始化类的特殊方法。构造方法的名称与类名相同，且没有返回值，调用时不需要指定 void。 所有类都有构造方法。若没有显式定义构造方法，则会使用默认构造方法。如果定义了自定义构造方法，则默认构造方法将失效。 例如，考虑一个 Car 类，如果没有定义构造方法，则系统将会自动提供一个默认构造方法。若需要特定的初始化行为，则可自定义构造方法，如： class Car public: Car(string color) this-color = color; private: string color;; 方法重载方法重载允许在同一个类中创建多个同名方法，但它们必须具有不同的参数类型或数量。这种特性增加了函数的灵活性和可读性。 方法重载使得不需要改变方法名称便能引入新功能，便于对外接口的维护与拓展。例如，可能有一个 CalculateArea 方法，可以根据输入参数的不同，重载为： double CalculateArea(int radius); // 计算圆的面积double CalculateArea(double length, double width); // 计算矩形的面积 在这种情况下，保持方法名一致使得理解变得简单。 属性属性的定义是为了简化字段的访问，提供了一组方法以便控制对类内字段的访问。变量私有的称为字段，公开的则称为属性。 属性通常由两个访问器方法组成：get 和 set。get 访问器返回与声明的属性相同的数据类型，允许通过它获取字段的值。 set 访问器则包含一个隐式参数 value，可以将值赋给字段。例如： private int age;public int Age get return age; set age = value; 在上面的代码中，可以通过 myCat.Age 访问和修改 age 属性，而无需直接操作私有字段。 封装封装是指每个对象将它操作所需的所有信息封装在一起，从而无需依赖外部因素来执行操作。良好的封装能够减少耦合，让类的内部实现可以自由更改，同时外部调用接口保持不变。 一个实际例子是，一个智能手机应用里用户信息的管理。应用可以提供方法来获取和更新用户信息，但其内部如何存储和处理这些信息则对用户保持隐藏，从而确保数据的安全性和完整性。 继承继承是指对象之间一种 is-a 的关系。若对象 A 和对象 B 的关系可以描述为 B 是 A，那么 B 就能继承 A。继承也可以看作是在被继承者的基础上对其进行某种程度的特殊化。 继承允许类之间共享特性和功能。例如，如果定义了一个 Animal 基类，Dog 和 Cat 就可以作为其子类，继承 Animal 类的特性，如 Age 和 Sound，且还可以定义各自独有的特性。 子类继承父类的非 private 属性和功能，具有自己的属性和功能，并且可以实现方法的重写。例如： class Dog : Animal public: void Bark() Console.WriteLine(Woof!); 需要注意，虽然继承带来代码的重用性，但父类的变更可能会影响子类，导致类之间的耦合性增加。 多态多态是指不同类型的对象可以执行相同的操作，但它们的具体实现是由各自的代码来决定的。这种特性使得编程更加灵活和可扩展。例如，一个动物类的 speak 方法可以在猫类和狗类中有不同的实现，猫类可能输出“喵”，而狗类则输出“汪”。尽管两者都调用了 speak 方法，得到的结果却是完全不同的。 在多态的实现中，子类可以被视为其父类的实例。然而，子类独有的属性和方法在父类的上下文中是不可用的。例如，当出现一个 Animal 类型的变量时，可以赋值为 Cat 或 Dog 的实例，但无法直接访问 Cat 或 Dog 中独有的方法，如 Cat 的 chaseMouse。 虚方法为了让子类能够完全接管父类的成员，父类中的成员需要被声明为虚拟。这是通过在方法前添加 virtual 关键字来实现的。虚拟方法可以有方法体，这意味着它们可以包含执行的具体代码。可以考虑一个 Shape 类，其中有一个 Draw 方法被定义为虚拟的，具体的图形类如 Circle 和 Square 可以各自实现不同的绘制方式。 尽管字段不能是虚拟的，但属性、事件和索引器都是可以声明为虚拟的。这样，子类就可以提供自己的实现，从而增强了灵活性和可扩展性。 方法重写子类能够选择使用 override 关键字来替换父类的实现。这意味着，即便父类定义了某个方法，子类可以根据需求提供一个新的实现。例如，父类 Animal 有一个 MakeSound 方法，子类 Cat 可以重写这个方法，使其输出“喵”。这样，在调用 MakeSound 方法时，具体的实现会依据对象的实际类型。 在多态的上下文中，当方法被调用时，即使对象被转换为父类类型，也只有继承链中最末端（子类）的方法实现会被调用。这体现了虚方法在运行时类型（而非编译时类型）上的动态绑定特性。 重构什么是重构重构是改善已有代码设计的一种方法。目标是增强代码的可读性和可维护性，同时不改变其外部行为。通过重构，代码的结构可以变得更加清晰，使后续的开发和维护工作更加高效。 什么是敏捷开发敏捷开发是一种灵活的软件开发方法论，强调通过快速迭代和持续反馈来满足客户需求。它重视团队之间的协作以及适应变化的能力。重构常常在敏捷开发过程中被作为一种实践，用于改善和适应不断变化的需求。 抽象类和接口抽象类与接口的区别抽象类可以实现某些成员的方法，而接口则不包含任何实现。抽象类中的抽象成员可以被子类部分实现，而接口的成员必须被实现类完全实现。此外，一个类只能继承一个抽象类，但可以实现多个接口。在设计中，类是对对象的抽象，抽象类是对类的抽象，接口则是对行为的抽象描述。 在选择使用接口或抽象类时，如果需要跨越不同类的对象，可以考虑使用接口；对于一些相似的类对象，继承抽象类则更加合适。抽象类从子类中发现了公共特性并泛化出父类，接口则是在方法实现上保持不确定性，仅通过预定义的方法声明来促进实现。 抽象类在类的实例化没有意义的情况下，可以将类和方法声明为抽象，即它们被定义为 abstract。抽象类不能直接实例化，抽象方法必须被子类实现。如果一个类中包含抽象方法，那么该类必须被标识为抽象类。 设计抽象类时，应尽可能地集中共同的代码，并减少不必要的数据。抽象类通常代表一个抽象概念，为类的继承提供基础。在一个继承结构中，末端的叶子节点应为具体类，而树枝节点则应为抽象类。 接口接口是一种组合隐式公共方法和属性的集合，用于封装特定功能。实现接口的类必须涵盖接口中所有的方法和属性。接口的定义在语法上与抽象类相似，但不能提供具体的实现，意味着接口无法被实例化，也不得包含构造方法和字段。 实现接口的类必须实现所有接口方法，多个类可以实现同一个接口，接口的命名通常以大写字母 I 开头。声明接口时使用 interface 关键词，接口中的方法和属性不应包含任何修饰符，方法体也不被允许。这种清晰的结构使得接口在设计可扩展性和灵活性时显得尤为重要。 泛型泛型是一种编程语言特性，它允许在定义类、结构、接口和方法时使用占位符，这些占位符通常被称为类型参数。通过类型参数，开发者能够定义通用的算法和数据结构，这些算法和数据结构可以处理不同的数据类型，而无需在每种情况下都重新编写代码。 在泛型的实现中，开发者可以指定一个或多个类型参数。例如，类或方法声明中通常会使用如下语法： class GenericClassT T field; public void SetField(T value) field = value; public T GetField() return field; 在上述示例中，GenericClassT 定义了一个泛型类，其中的 T 是类型参数。这个类型参数可以在使用时被替换为任何具体类型，例如 int、string 或者用户自定义类型。当创建 GenericClassint 实例时，T 会被替换为 int，这意味着此类会专门存储整数类型的值。 泛型集合类是泛型的一个重要应用，允许存储特定类型的对象而无需转换或强制类型转换。例如，在 C#中，ListT 就是一个泛型集合类，它可以存储任何类型的元素。下面的代码展示了如何使用泛型集合类： Liststring stringList = new Liststring();stringList.Add(Hello);stringList.Add(World); 在这里，Liststring 表示一个专门存储字符串的列表。使用泛型集合类的好处在于类型安全性，开发者不需担心因类型不匹配而导致的运行时错误。 类型参数在泛型中同时用于定义字段和方法的参数类型，这使得代码更加灵活。例如，泛型方法的定义可以如下所示： public void PrintValueT(T value) Console.WriteLine(value.ToString()); 在这个例子中，PrintValueT 是一个泛型方法，其接受参数 value 的具体类型在调用时确定。这种方式使得方法能够接受各种类型的输入，而无须为不同的类型编写多个重载版本。 通过使用泛型，开发者可以在提高代码复用性的同时，确保程序运行时的类型安全，减少潜在的错误。这种特性在数据结构与算法设计中尤其重要，因为它能够有效应对多种数据类型的需求，而无需重复代码编写。","categories":["2.语言","结构算法"]},{"title":"五种存储类","path":"/2025/01/08/2-语言-C语言-五种存储类/","content":"1. 存储类型与作用域的区别修改变量的存储类型，例如将其从栈上转换到静态数据区，并不改变变量的作用域。尽管 static 关键字使得变量的生命周期在程序运行期间持续存在，但它仍只能在定义它的函数内部通过名字访问。 auto：存储在栈上，生命周期限制于其作用域内，当函数执行结束后，这些变量会自动释放。 register：声明为寄存器变量，意图将其存储在更快的寄存器中。虽然可以请求将变量存储在寄存器，但这是一个建议，并不保证成功。如果没有申请到寄存器空间，register 变量的行为与 auto 变量相同。此外，register 变量不能使用 运算符获取其地址，因为寄存器并不是内存地址的概念。 2. static 关键字的作用当使用 static 修饰一个局部变量时，该变量将存储在程序的静态存储区域。其中的值将在整个程序运行期间保持不变，并可以在该函数多次调用时进行持续性存取。然而，它的作用域被限制在该函数内部，外部无法访问。 限制作用域：通过使用 static，可以确认该变量仅在定义它的函数内可见。例如，在一个函数中： void fun() static int x = 0; x++; printf(%d , x); 每次调用 fun() 时，x 的值都会递增，但外部代码无法直接访问或修改 x。 3. extern 关键字和作用域extern 关键字用于声明一个外部变量，该变量在其他文件中定义，允许跨文件访问。 使用 extern 声明： extern int i; // 声明 i 是在其他文件定义的全局变量 如果在 fun 函数中声明 extern int i; 则表示将引用全局变量 i，而不在 fun 中创建一个新的局部变量 i。若不声明 extern，变量 i 将被视作局部变量。 4. const 关键字的作用使用 const 声明变量可确保当前线程无法改变该变量的值。例如： const int maxLimit = 100; 在这种情况下，maxLimit 的值在当前线程中不可修改，但其他线程或系统代码可能仍然会对其进行改变。 5. 变量作用域与遮蔽在函数内部，如果声明了一个局部变量与形参同名，由于作用域相同，这个局部变量将自动遮蔽外部或全局的同名变量。 局部变量遮蔽全局变量：若在 fun 函数内部声明一个与全局变量相同名字的局部变量，所有对该名字的引用将指向局部变量而非全局变量。 static 定义的变量是否可以用 extern 进行引用在 C 和 C++编程中，static 关键字用于定义具有静态存储期的变量。这样的变量在其定义的文件内具有内部链接性，意味着这些变量仅在定义它们的源文件中可见。使用 static 关键字定义的变量的生命周期从程序开始一直持续到程序结束，即便它们的作用域可能是在特定的函数内部。 相对而言，extern 关键字用于声明一个变量在其他文件中定义，从而允许跨文件引用。在一定程度上，extern 指示编译器该变量的定义在其他某处，通常是在另一个源文件中。 因此，如果在某个源文件中定义了一个静态变量，并尝试在另一个源文件中使用 extern 进行引用，将会导致编译错误。这是因为静态变量的链接性仅限于定义它的文件。使用 extern 引用时，编译器会寻找该变量的外部定义，但由于静态变量不会被导出到其他文件，所以会无法找到。 示例分析： 静态变量定义示例： // file1.cstatic int count = 0; // count是一个静态变量，仅在file1.c可见 extern 引用示例： // file2.cextern int count; // 尝试通过extern引用一个在file1.c中定义的静态变量 在上述示例中，file2.c 中的 extern int count; 无法成功引用 file1.c 中的 count 变量，因为 count 是静态的，只在 file1.c 中可见，编译器在 file2.c 中将无法找到对应的定义。 总结来说，static 定义的变量不能用 extern 进行引用，因为 static 限制了变量的可见性，使其无法被其他文件访问。","categories":["2.语言","C语言"]},{"title":"Docker Compose","path":"/2024/12/26/1-平台-Docker-Docker-Compose/","content":"Docker ComposeDocker Compose 是一个工具，用于定义和运行多个 Docker 容器的应用程序。 docker-compose 需要编写 yml 脚本，定义配置以及多个容器之间的依赖关系和网络连接 * 注意：yml 文件对缩进有严格要求 通过命令控制 docker-compose以下是一个简单的 docker-compose.yml 文件示例： version: 3.9services: db: image: mysql:5.7 volumes: - ./db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - ./wordpress_data:/var/www/html ports: - 80:80 - 443:443 restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: wordpress_data: 这里用到了 mysql:5.7 和 wordpress:latest 两个 Docker 镜像，WordPress 镜像依赖 depends_on 于 MySQL 镜像。 restart: always 参数表明容器服务宕机后会自动重启。 MYSQL_ROOT_PASSWORD 为数据库的 root 密码，MYSQL_PASSWORD 为数据库的普通用户密码，请自行修改，对应的 WORDPRESS_DB_PASSWORD 也要同时修改。MYSQL_USER 为数据库普通用户的用户名，如果有需要也可以修改，对应的 WORDPRESS_DB_USER 也要同时修改。 80:80 的意思是把宿主机的 80 端口映射到容器内部的 80 端口。如需通过其他端口访问，只需修改前面的 80。比如，要通过 8080 端口访问 WordPress，填写 8080:80 即可。 volumes 会将主机中指定的目录 ./wordpress_data 和容器中的指定目录 /var/www/html 共享，类似于虚拟机中的共享文件夹。并且在容器销毁后目录中的文件依旧存在。 在 Docker Compose 版本 3 及以上的配置中，不再使用 links 字段来定义容器之间的连接。取而代之的是使用 Docker 网络来实现容器之间的通信。现在，Docker Compose 默认创建一个项目级别的默认网络，其中每个服务（service）都可以使用它。 只需保证 db 和 wordpress 属于同一个项目（即在同一个 docker-compose.yml 文件中定义），它们将自动连接到默认网络，并可以通过服务名称（db 和 wordpress）相互访问。 脚本Docker Compose官方文档 Docker Compose 命令解析 **docker-compose up -d**：此命令根据当前目录中的 yml 文件配置启动所有服务容器。使用 -d 参数使容器在后台运行，用户可以继续执行其他命令而不必等待容器启动完成。 **docker-compose ps**：此命令用于查看运行中的容器状态。它将列出项目中所有容器的当前状态，包括已停止状态。这对于监控容器运行情况非常有用，尤其是在需要检查已停止容器时，而不仅限于只查看正在运行的状态。 **docker-compose stop**：通过此命令可以停止所有正在运行的容器，相当于一种便捷的关闭方式。 **docker-compose restart**：该命令用于重启所有容器，非常适合简单的服务更新或配置变更后需要刷新服务的场合。 **docker-compose restart service-name**：重启指定的单个服务。这在需要仅更新某个服务而不影响其他服务时特别有用。 **docker-compose exec service-name sh**：允许用户进入特定服务的命令行环境，便于进行应用级别的直接操作，如调试或手动执行某些命令。 **docker-compose logs [service-name]**：查看特定服务的日志信息，可以使用 -f 参数指定特定的日志文件。此命令对于排查运行时错误和诊断问题非常重要。 **docker-compose build**：用于构建或重建服务所需的镜像。该命令会根据 Dockerfile 配置文件创建新的镜像，以确保所需的服务版本。 **docker-compose build service_a**：专门创建名为 service_a 的镜像，适合针对某个特定服务进行构建。 **docker-compose kill**：强行停止服务，通过向容器发送 SIGKILL 信号，适用于需要立即终止容器而不予以清理的情况。 **docker-compose pause/unpause**： docker-compose pause：将服务暂停，所有服务容器的进程会被挂起，资源使用会显著降低。 docker-compose unpause：恢复被暂停的服务，让服务重新开始处理请求。 **docker-compose port**：用于查看服务内的特定端口与物理机上端口的映射关系。例如，执行 docker-compose port nginx_web 80 会展示 Nginx 服务的 80 端口映射到主机的哪个端口。 **docker-compose ps**：该命令专注于显示当前项目下的容器状态，包括已停止状态的容器，和 docker ps 相比，这里提供更多项目上下文信息。 **docker-compose pull**：用于拉取服务依赖的镜像，确保本地环境与远程仓库保持一致。这对于更新或部署时获取最新镜像非常重要。 **docker-compose restart service_name**：重启单个服务中的所有容器。当服务尚在运行时，此命令有效，停止的服务无法被重启。 **docker-compose rm**：删除已停止的服务容器，保持环境的整洁。可以使用参数 -f 强制删除，或使用 -v 删除与容器相关的卷，以释放更多存储空间。 **docker-compose run**：该命令用于创建并运行一个新的容器，执行一次性命令。其配置与定义在 yml 文件中的服务一致，但会覆盖服务中定义的命令。此外，新容器不会使用服务配置中指定的端口，若需要使用这些端口，可添加 --service-ports 参数。 **docker-compose start/stop**： **docker-compose start**：用于启动指定服务的所有容器。 **docker-compose stop**：则可停止特定服务的所有容器。 **docker-compose scale**：允许用户指定某个服务启动的容器数量。尽管该命令正在被弃用，但可通过 --help 查看用法示例，如 docker-compose scale web=2 worker=3，这将创建两个 web 容器和三个 worker 容器。 部署 nginx 代理 Tomcat 集群，实现负载均衡大体步骤整个过程分为以下四个主要步骤： 下载所需的软件包 需要下载的文件包括 Tomcat 和 JDK（Java Development Kit），这两个都是构建 Java 应用程序的基础工具。Tomcat 作为 Java 的 Servlet 容器，通常用于运行 Java EE Web 应用程序。 编写 Dockerfile 以部署 Tomcat 和 Java 环境 Dockerfile 定义了 Docker 镜像的构建过程。本示例使用一个基于 CentOS 的镜像添加 Java 和 Tomcat。通过这一过程生成的镜像将包含所需的运行环境。 编写 docker-compose.yml 配置文件 此配置文件用于定义和运行多个 Docker 容器。它指定了需要启动的服务，包括 nginx 和两个 Tomcat 实例，并配置了它们之间的网络链接。 测试负载均衡 部署完成后，通过访问 nginx 代理，验证负载均衡的效果，确保请求在 Tomcat 集群之间得到合理分配。 具体配置文件目录结构[root@master java]# tree ././├── docker-compose.yml├── etc│ └── localtime├── nginx│ └── nginx.conf├── tomcat│ ├── apache-tomcat-8.5.31.tar.gz│ ├── Dockerfile│ └── jdk-8u144-linux-x64.tar.gz└── webserver ├── tomcatA │ └── index.jsp └── tomcatB └── index.jsp 测试首页文件对于两个 Tomcat 实例，分别提供了简单的测试页面： Tomcat A 主页: welcome to tomcat-A server Tomcat B 主页: welcome to tomcat-B server docker-compose.yml 配置文件该配置文件详细描述了服务的设定，下面是配置文件的内容： version: 3services: nginx: image: nginx:1.14 restart: always ports: - 80:80 links: - tomcat1:tomcat1 - tomcat2:tomcat2 volumes: - ./webserver:/webserver - ./nginx/nginx.conf:/etc/nginx/nginx.conf - ./etc/localtime:/etc/localtime depends_on: - tomcat1 - tomcat2 tomcat1: hostname: tomcat1 build: ./tomcat volumes: - ./webserver/tomcatA:/usr/local/apache-tomcat-8.5.31/webapps/ROOT - ./etc/localtime:/etc/localtime tomcat2: hostname: tomcat2 build: ./tomcat volumes: - ./webserver/tomcatB:/usr/local/apache-tomcat-8.5.31/webapps/ROOT - ./etc/localtime:/etc/localtime 安装 Java 环境的 Dockerfile以下 Dockerfile 用于创建 Tomcat 容器时的 Java 运行环境： FROM centosADD jdk-8u144-linux-x64.tar.gz /usr/localENV JAVA_HOME /usr/local/jdk1.8.0_144ADD apache-tomcat-8.5.31.tar.gz /usr/localEXPOSE 8080ENTRYPOINT [/usr/local/apache-tomcat-8.5.31/bin/catalina.sh, run] 容器服务的启动通过运行以下命令来启动所有定义的服务： [root@master java]# docker-compose up 在这个过程中，Docker 将首先构建 Tomcat 的镜像，随后逐步启动 nginx 和两个 Tomcat 实例。 启动情况检查启动后，可以使用以下命令查看各个服务的运行状态： [root@master java]# docker-compose ps Name Command State Ports ----------------------------------------------------------------------------java_nginx_1 nginx -g daemon off; Up 0.0.0.0:80-80/tcpjava_tomcat1_1 /usr/local/apache-tomcat-8 ... Up 8080/tcp java_tomcat2_1 /usr/local/apache-tomcat-8 ... Up 8080/tcp 检测负载均衡访问 localhost 可测试负载均衡效果： [root@master java]# curl http://localhostwelcome to tomcat-A server[root@master java]# curl http://localhostwelcome to tomcat-B server 一系列请求将交替返回 Tomcat A 和 Tomcat B 的首页内容，验证负载均衡功能正常。 查看日志输出信息可以通过 Docker logs 来查看 nginx 的访问记录，其中包含每次请求的 IP 地址和请求的详细信息，例如： nginx_1 | 192.168.22.170 - - [08/Jun/2018:02:14:36 +0000] GET / HTTP/1.1 200 27 - Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36 - 这些信息记录了每一请求的时间、状态码和用户代理，方便后续的监控与分析。","categories":["1.平台","Docker"]},{"title":"消息队列详解与实例-CSDN博客","path":"/2024/12/25/2-语言-C语言-消息队列详解与实例-CSDN博客/","content":"前言：消息队列是一种用于进程间通信的机制，可以将其视为一个有序的消息链表。每条消息都像一个记录，包含特定的格式和优先级。具有写权限的进程可以按照一定的规则将新消息添加到队列中，而具有读权限的进程则可以从队列中读取消息。这种机制在多进程环境中非常有用，能够有效地实现数据的异步传输和处理。 函数：1. 创建新消息队列或取得已存在消息队列原型： int msgget(key_t key, int msgflg); 参数： key：可以看作是一个唯一的标识符，类似于网络中的端口号。这个值可以通过函数 ftok 生成，确保在不同进程中唯一。 msgflg：用于控制消息队列的创建和访问行为。 IPC_CREAT：如果消息队列不存在，则创建一个新的消息队列并返回其标识符；如果已存在，则返回现有的标识符。 IPC_EXCL：如果消息队列不存在，则返回 -1；如果已存在，则返回 0。 2. 向队列读写消息原型： ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg); int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg); 参数： msqid：消息队列的标识符，通常是通过 msgget 函数获取的。 msgp：指向消息缓冲区的指针，用于暂时存储发送和接收的消息。这个缓冲区的结构通常定义如下： struct msgstru long mtype; // 消息类型 char mtext[1]; // 消息内容; msgsz：消息的大小，通常是 struct msgstru 的大小。 msgtyp：指定要读取的消息类型。如果值为零，则表示读取队列中的所有消息。 msgflg：指示在队列没有数据时的行为。 如果与 IPC_NOWAIT 一起使用，msgsnd() 在队列已满时不会阻塞，而是立即返回 -1；msgrcv() 在队列为空时也会立即返回 -1，并设置错误码为 ENOMSG。 如果 msgflg 为 0，msgsnd() 和 msgrcv() 会在队列满或空时阻塞等待。 3. 设置消息队列属性原型： int msgctl(int msgqid, int cmd, struct msqid_ds *buf); 参数： msgqid：消息队列的标识符。 cmd：指定要执行的操作，系统定义了三种操作： IPC_STAT：获取消息队列的状态信息，并将其存储在 buf 指向的地址空间。 IPC_SET：设置消息队列的属性，属性信息存储在 buf 中。 IPC_RMID：从内核中删除指定的消息队列。 实例：以下是一个使用消息队列的简单示例，展示了如何创建消息队列、发送和接收消息。 #include stdio.h#include sys/types.h#include sys/ipc.h#include sys/msg.h#include errno.h#define MSGKEY 1024struct msgstru long msgtype; // 消息类型 char msgtext[2048]; // 消息内容;void childproc() struct msgstru msgs; int msgid, ret_value; char str[512]; while (1) msgid = msgget(MSGKEY, IPC_EXCL); if (msgid 0) printf(消息队列不存在! errno=%d [%s] , errno, strerror(errno)); sleep(5); continue; ret_value = msgrcv(msgid, msgs, sizeof(struct msgstru), 0, 0); printf(接收到的消息: [%s] 进程ID: [%d] , msgs.msgtext, getpid()); return;int main() int i, cpid; for (i = 0; i 5; i++) cpid = fork(); if (cpid 0) printf(创建子进程失败 ); else if (cpid == 0) childproc(); 另一个示例展示了如何创建消息队列并发送消息： #include stdio.h#include sys/types.h#include sys/ipc.h#include sys/msg.h#include errno.h#define MSGKEY 1024struct msgstru long msgtype; // 消息类型 char msgtext[2048]; // 消息内容;int main() struct msgstru msgs; int msg_type; char str[256]; int ret_value; int msqid; msqid = msgget(MSGKEY, IPC_EXCL); if (msqid 0) msqid = msgget(MSGKEY, IPC_CREAT | 0666); if (msqid 0) printf(创建消息队列失败 | errno=%d [%s] , errno, strerror(errno)); exit(-1); while (1) printf(输入消息类型[0=结束进程]: ); scanf(%d, msg_type); if (msg_type == 0) break; printf(输入要发送的消息: ); scanf(%s, str); msgs.msgtype = msg_type; strcpy(msgs.msgtext, str); ret_value = msgsnd(msqid, msgs, sizeof(struct msgstru), IPC_NOWAIT); if (ret_value 0) printf(msgsnd() 发送消息失败, errno=%d [%s] , errno, strerror(errno)); exit(-1); msgctl(msqid, IPC_RMID, 0); // 删除消息队列 在这些示例中，首先创建了一个消息队列，然后通过 msgsnd() 函数发送消息，接着通过 msgrcv() 函数接收消息。每个进程都可以独立地发送和接收消息，展示了消息队列在多进程通信中的有效性。","tags":["clippings"],"categories":["2.语言","C语言"]},{"title":"消息队列通信示例-CSDN博客","path":"/2024/12/25/2-语言-C语言-消息队列通信示例-CSDN博客/","content":"/* msglucy.c */#include sys/ipc.h // 引入IPC相关的头文件#include sys/msg.h // 引入消息队列相关的头文件#include sys/stat.h // 引入文件状态相关的头文件#include sys/types.h // 引入数据类型相关的头文件#include stdio.h // 引入标准输入输出库#include fcntl.h // 引入文件控制相关的头文件#include signal.h // 引入信号处理相关的头文件#include stdlib.h // 引入标准库#include string.h // 引入字符串处理相关的头文件#define PROJID 0XFF // 定义项目ID，用于生成唯一的消息队列键#define LUCY 1 // 定义LUCY的消息类型#define PETER 2 // 定义PETER的消息类型int mqid; // 消息队列标识符// 终止处理函数void terminate_handler(int signo) msgctl(mqid, IPC_RMID, NULL); // 删除消息队列 exit(0); // 退出程序int main() char filenm[] = msg; // 定义用于生成消息队列键的文件名 key_t mqkey; // 消息队列键 struct msgbuf long mtype; // 消息类型 char mtext[256]; // 消息内容 msg; int ret; // 生成消息队列键 mqkey = ftok(filenm, PROJID); if (mqkey == -1) perror(ftok error:); // 输出错误信息 exit(-1); // 退出程序 // 创建消息队列，如果不存在则创建 mqid = msgget(mqkey, IPC_CREAT | IPC_EXCL | 0666); if (mqid == -1) perror(msgget error:); // 输出错误信息 exit(-1); // 退出程序 // 注册信号处理函数 signal(SIGINT, terminate_handler); // 处理终端中断信号 signal(SIGTERM, terminate_handler); // 处理终止信号 while (1) printf(Lucy:); fgets(msg.mtext, 256, stdin); // 从标准输入获取消息内容 if (strncmp(quit, msg.mtext, 4) == 0) msgctl(mqid, IPC_RMID, NULL); // 删除消息队列和数据 exit(0); // 退出程序 msg.mtext[strlen(msg.mtext) - 1] = \\0; // 去掉换行符 msg.mtype = LUCY; // 设置消息类型为LUCY msgsnd(mqid, msg, strlen(msg.mtext) + 1, 0); // 发送消息 msgrcv(mqid, msg, 256, PETER, 0); // 接收来自PETER的消息 printf(Peter: %s , msg.mtext); // 输出PETER的消息 /* msgpeter.c */#include sys/ipc.h // 引入IPC相关的头文件#include sys/msg.h // 引入消息队列相关的头文件#include sys/stat.h // 引入文件状态相关的头文件#include sys/types.h // 引入数据类型相关的头文件#include stdio.h // 引入标准输入输出库#include fcntl.h // 引入文件控制相关的头文件#include signal.h // 引入信号处理相关的头文件#include stdlib.h // 引入标准库#include string.h // 引入字符串处理相关的头文件#define PROJID 0XFF // 定义项目ID，用于生成唯一的消息队列键#define LUCY 1 // 定义LUCY的消息类型#define PETER 2 // 定义PETER的消息类型int main() char filenm[] = msg; // 定义用于生成消息队列键的文件名 int mqid; // 消息队列标识符 key_t mqkey; // 消息队列键 struct msgbuf long mtype; // 消息类型 char mtext[256]; // 消息内容 msg; int ret; // 生成消息队列键 mqkey = ftok(filenm, PROJID); if (mqkey == -1) perror(ftok error:); // 输出错误信息 exit(-1); // 退出程序 // 获取消息队列标识符 mqid = msgget(mqkey, 0); if (mqid == -1) perror(msgget error:); // 输出错误信息 exit(-1); // 退出程序 while (1) msgrcv(mqid, msg, 256, LUCY, 0); // 接收来自LUCY的消息 printf(LUCY: %s , msg.mtext); // 输出LUCY的消息 printf(Peter:); fgets(msg.mtext, 256, stdin); // 从标准输入获取消息内容 if (strncmp(quit, msg.mtext, 4) == 0) msgctl(mqid, IPC_RMID, NULL); // 删除消息队列 exit(0); // 退出程序 msg.mtext[strlen(msg.mtext) - 1] = \\0; // 去掉换行符 msg.mtype = PETER; // 设置消息类型为PETER msgsnd(mqid, msg, strlen(msg.mtext) + 1, 0); // 发送消息 代码解析 头文件引入： 代码中引入了多个系统头文件，主要用于处理消息队列、信号、输入输出等功能。 宏定义： PROJID、LUCY 和 PETER 分别定义了项目 ID 和消息类型，用于标识不同的消息发送者。 消息队列的创建与管理： 使用 ftok 函数生成一个唯一的消息队列键，若失败则输出错误信息并退出。 使用 msgget 创建消息队列，若队列已存在则返回错误。 信号处理： 注册信号处理函数 terminate_handler，用于处理程序终止时的清理工作，确保消息队列被删除。 消息发送与接收： 在 while 循环中，程序不断读取用户输入并发送消息。 使用 fgets 获取输入，并通过 msgsnd 发送消息。 使用 msgrcv 接收来自另一进程的消息，并输出。 退出机制： 用户输入 “quit” 时，程序会删除消息队列并退出。 使用说明 在运行程序之前，需要手动创建一个名为 msg 的空文件。 首先运行 lucy 程序，然后再运行 peter 程序，二者可以相互发送信息。","tags":["clippings"],"categories":["2.语言","C语言"]},{"title":"Linux进程间通信(八)---消息队列之msgget()、msgsnd()、msgrcv()及其基础实验_linux msgrcv-CSDN博客","path":"/2024/12/25/2-语言-C语言-Linux进程间通信-八-消息队列之msgget-、msgsnd-、msgrcv-及其基础实验-linux-msgrcv-CSDN博客/","content":"概述 消息队列，就是一些消息的列表，用户可以在消息队列中添加消息和读取消息等。从这点上看，消息队列具有一定的FIFO特性，但是它可以实现消息的随机查询，比FIFO具有更大的优势。同时，这些消息又是存在于内核中的，由“队列ID”来标识。 消息队列的实现操作 ① 创建或打开消息队列。使用的函数是msgget()，这里创建的消息队列的数量会受到系统消息队列数量的限制。 ② 添加消息。使用的函数是msgsnd()，它把消息添加到已打开的消息队列末尾。 ③ 读取消息。使用的函数是msgrcv()，它把消息从消息队列中取走，与FIFO不同的是，这里可以取走指定的某一条消息。 ④ 控制消息队列。使用的函数是msgctl()，它可以完成多项功能。 函数格式 基础实验 功能 本实验意在展示如何使用消息队列进行两个进程(发送端和接收端)之间的通信，包括消息队列的创建、消息发送与读取、消息队列的撤销和删除等多种操作。 消息发送端进程和消息接收端进程不需要额外实现进程间的同步。在本实验中，发送端发送的消息类型设置为该进程的进程号（可以取其他值），因此接收端根据消息类型来确定消息发送者的进程号。注意这里使用了ftok()函数，它可以根据不同的路径和关键字来产生标准的key。 源程序 本实验包括两个文件，msgsnd.c文件和msgrcv.c文件。下面贴出这两部分的代码。 msgrcv.c文件，点此下载 msgsnd.c文件，点此下载 执行程序 需要开两个终端，将上述文件下载后编译，首先在终端1上执行msgrcv创建一个消息队列，然后在终端2上执行msgsnd，向消息队列中发送消息。 终端1 终端2 在终端2输入消息后 此时终端1 到这里，实验已经完了。 但是我在做实验的时候，有一次，先打开了msgsnd，输入了消息，并且输入了“quit”退出了msgsnd程序，然后打开了msgrcv，发现msgrcv也接收到了刚才的消息，有点意思，建议做一下，然后思考一下为什么会这样。 同时，使用命令 ipcs -q可以查看当前系统的消息队列的信息。 原文地址：http://blog.csdn.net/mybelief321/article/details/9185625","tags":["clippings"],"categories":["2.语言","C语言"]},{"title":"Python量化","path":"/2024/12/24/5-生活-金融-Python量化/","content":"Python 入门篇 、金融数据篇、量化分析篇和策略回测篇，形成了较为完整的框架体系供大家学习参考。 01 Python 入门篇这一部分主要是关于Python 金融量化入门学习路径、量化资源，以及 numpy、pandas、matplotlib 等量化常用库的入门和应用。Python 的编译软件有很多，个人建议安装 Anaconda，自带 Jupyter notebook 和 Spyder，其中 Jupyter 在交互式编程与数据分析上功能十分强大，公众号上所有文章都是基于 Jupyter 写的。 首先，结合个人经验分享 Python 金融量化的学习路径，以及分享 Python 从入门、进阶、到高阶的学习资料，以及金融投资相关书籍（PDF）。 1.1【Python金融量化】零基础如何开始学？ 1.2【推荐收藏】倾心整理的Python量化资源大合集 其次，关于 Numpy（数组矩阵）、Pandas（数据处理分析）、Matplotlib（可视化）、Seaborn（可视化）、Sklearn（机器学习）等金融量化常用库的入门和应用。 1.3【手把手教】玩转Python量化金融工具之NumPy 1.4【手把手教】玩转Python金融量化利器之Pandas 1.5【建议收藏】Matplotlib可视化最有价值的50张图 1.6【手把手教】Seaborn在金融数据可视化中的应 1.7【手把手教】玩转机器学习 Sklearn 1.8【手把手教】股票可视化分析之Pyecharts（一） 1.9【手把手教】股票可视化分析之Pyecharts（二） 02 金融数据篇本部分主要是使用 Python 获取股票行情、上市公司基本面、宏观经济以及财经新闻等数据，对其进行可视化分析，使用 Postgresql （sqlite3）搭建本地量化分析数据库，以及如何使用 qstcok 免费开源库在线获取行情数据、板块资金流数据、宏观基本面和财经新闻数据等。 2.1【手把手教】Python获取交易数据 2.2【Python金融量化】上市公司知多少？ 2.3 Python量化选股初探 2.4 2018不可不知的十大关键词 2.5【手把手教】Python获取财经数据和可视化分析 2.6【文本挖掘】Python带笑看江湖 2.7【Python金融量化】财经新闻文本分析 2.8【手把手教】搭建自己的量化分析数据库 2.9【手把手教】Python面向对象编程入门及股票数据管理应用实例 3.0【qstock开源了】数据篇之行情交易数据 3.1【qstock量化】数据篇之宏观指标和财经新闻文本 3.2【qstock数据篇】行业概念板块与资金流 03 量化分析篇本部分涉及内容比较多，包括使用 Python 做对 A 股市场进行探索性分析，金融统计分析、蒙特卡洛模拟，时间序列建模，Talib 技术分析、投资组合、多因子模型分析 和基本面量化分析等。 A 股数据探索性分析： 3.1【Python量化】股票分析入门 3.2 A股指数图谱：是否有月份效应？ 3.3【Python金融量化】A股沉浮启示录 3.4【宏观量化】股市趋势与拐点如何看？ 3.5 2005-2020年A股数据挖掘：谁是最大的牛股？【附Python分析源码】 3.6 机器学习刻画股票市场结构和可视化——以上证50成分股为例 3.7【Python量化】股票涨停板探索性分析与数据挖掘 时间序列专题： 3.8【手把手教】时间序列之日期处理 3.9【Python量化基础】时间序列的自相关性与平稳性 3.10【手把手教】使用Python玩转金融时间序列模型 3.11 Python玩转金融时间序列之ARCH与GARCH模型 3.12 资产收益率的非平稳性——为何机器学习预测效果不佳？ 3.13 基于Markov区制转换模型的股票波动分析 3.14【手把手教】使用Python实现统计套利 3.15 股市牛熊兴替——时间序列相似性量化分析 TA-Lib 与 股票技术分析： 3.16 【手把手教】股市技术分析利器之TA-Lib（一） 3.17 【手把手教】股市技术分析利器之TA-Lib（二） 3.18 【手把手教】量价关系分析与Python实现 3.19 【手把手教】Python量化股票市场情绪指标ARBR 3.20 【手把手教】动量指标的Python量化回测 3.21 【Python量化】如何利用欧奈尔的RPS寻找强势股？ 3.22 【手把手教】Python实现量价形态选股 3.23 牛股价量探索性分析与趋势指标可视化 3.24【手把手教】使用Python对股价的Heikin Ashi蜡烛图进行可视化 3.25 趋势预测：基于期货未平仓合约、展期和FIIDII指标【附Python源码】 3.26【交易系统与方法】价格噪音的量化与应用 3.27【交易系统与方法】统计学基本概念与市场分析应用 投资组合分析与多因子模型： 3.28 什么是多因子量化选股模型？ 3.29 单因子测试框架分享 3.30 如何对选股因子进行量化回测？ 债券与期权衍生品之 QuantLib 入门与应用： 3.31【手把手教】固定收益和衍生品分析利器QuantLib入门 3.32【手把手教】使用QuantLib进行债券估值和期权定价分析 比特币量化分析： 3.33 比特币交易者的行为模式分析【附 Python 源码】 基本面量化分析： 3.34【手把手教】使用Python构建股票财务指标打分系统 3.35 高管增持股价一定会上涨吗？【附Python代码】 3.36【Python量化】如何监测领涨板块，挖掘题材龙头股？ 04 策略回测篇本部分主要是使用 Python 分析量化策略的评价指标，指数定投策略、机器学习、海龟交易法则和均值回归策略等，以及专题介绍 backtrader 回测系统的运用和使用 qstock 进行量化回测。 量化交易策略概述及评价指标： 4.1 【干货分享】一文讲透量化投资方法论体系 4.2 【量化回测】如何规避陷阱及评价策略？ 4.3 【手把手教】Python量化策略风险指标 4.4 【手把手教】使用pyfinance进行证券收益分析 4.5 【手把手教】Python实现基于事件驱动的量化回测 4.6 Pyfolio一行代码实现专业量化回测图表 构建交易策略并进行简单的量化回测： 4.7 Python数说指数定投策略 4.8【Python量化】怎么在基金定投上实现收益最大化 4.9【手把手教】使用Logistic回归、LDA和QDA模型预测指数涨跌 4.10 【手把手教】使用RNN深度学习预测股票价格 4.11 手把手教用Python搭建自己的量化回测框架【均值回归策略】 4.12【手把手教】用Python量化海龟交易法则 4.13 A股存在月份效应吗？构建月度择时策略【附Python源码】 4.14 北向资金能预示大盘涨跌？【附Python源码】 4.15【手把手教】获取股票数据并进行量化回测——基于ADX和MACD趋势策略 4.16【量化实战】跟随龙虎榜个股交易能获利吗？ 4.17【手把手教】使用qstock进行量化回测 4.18【手把手教】基于均线排列的价格动量策略回测 机器学习与量化交易：4.19【Python量化】使用机器学习预测股票交易信号 4.20【手把手教】利用神经网络构建量化交易策略 开源回测框架 backtrader 专题系列： 4.21 【手把手教】入门量化回测最强神器backtrader（一） 4.22【手把手教】入门量化回测最强神器backtrader（二） 4.23【手把手教】入门量化回测最强神器backtrader（三） 4.24 backtrader如何加载股票因子数据？以换手率、市盈率为例进行回测【附Python代码】 4.25 如何用backtrader对股票组合进行量化回测？ 4.26【手把手教】用backtrader量化回测海龟交易策略 4.27 backtrader股票技术指标自定义与量化回测 4.28【手把手教】Ichimoku云图指标可视化与交易策略回测 4.29【backtrader回测】隔夜持仓 VS 日内交易","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python量化交易入门进阶指南(全) - 量化经典 -  迅投QMT社区 -  Powered by Discuz!","path":"/2024/12/24/5-生活-金融-Python量化交易入门进阶指南-全-量化经典-迅投QMT社区-Powered-by-Discuz/","content":"本文约 5800 字，建议阅读 10分钟 本文介绍了语言模型是如何感知时间的。 量化，简单说就是程序 + 交易 → 盈利。 程序员，或许内心深处都怀揣着一个量化投资的梦想，渴望凭借自己的编程和人工智能技能，再补点基础的金融知识，便可以构建一个量化交易系统，轻松实现财富自由。这样的理想确实诱人，似乎让看到了轻松实现个人价值的可能性，也让看到了用代码改变世界的力量。 不过丑话说在前面，”钱难挣屎难吃”，量化交易也是一样。这领域的风险、机遇肯定都不会少，当然水的深浅可能要试了才知道，只是小韭菜，对量化的认识肯定有不到位的地方，而本篇入门文章就当作抛砖引玉。 回到正文，对于量化交易，神秘感还是满满的，相关的介绍比较零散，很多就是一上来就是屠龙之术，告诉一个看上去很牛逼的策略，很难系统地了解整个概念及流程。在此，本文系统梳理量化交易的基本概念，实践过程，并附上相关资料代码，为 quant 小白填填坑。 1、量化交易的概念 投机如山岳一样古老，华尔街没有新鲜事 在研究量化投资策略之前，建议补充下相关的金融知识（可以百度下各种名词术语），有空可以再读几本金融理财方面经典的书，可以形成一些金融市场基本的概念，养成一些投资理念。 价值 : 对投资的思考 富爸爸穷爸爸 投资中最简单的事 投资最重要的事 指数基金投资指南 – ETF 随机漫步的傻瓜 : 发现市场和人生中的隐藏机遇 聪明的投资者 证券分析 – 格雷厄姆 巴菲特致股东的信 穷查理宝典 : 查理•芒格智慧箴言录 量化交易，相较于传统人为主观投资，本质并没有区别。简单来说，通过程序选出合适的股票（或其他），在合适的时机，发起买入或卖出的交易，从中追求盈利。 量化没有创造出新的投资逻辑，也不改变市场的运行和结构，但它用新的科学技术、对实现方法和工具进行了创新——利用了数学统计人工智能等方法取代人工决策。一般情况，市场研究、基本面分析、选股、择时、下单等都可以由计算机自动完成，在市场进行投资。 而量化投资的核心优势在于：通过计算机分析挖掘因子的能力更强，可以从低信噪比的大数据中获取有价值的信息，可以更好量化风险及收益，决策也更为及时及客观可靠，可以克服情绪及人为操作的局限性。 2、量化交易的市场量化投资广泛地出现在各种交易市场，如股市、期货、基金、期权、外汇、债券、比特币、NFT 等等，有资源交换需求的地方就可以量化交易。这里主要展开介绍下股票和期货市场。 2.1 股市股票市场：是股票发行和交易的场所，是已经发行的股票转让、买卖和流通的场所。股份公司通过面向社会发行股票，迅速集中大量资金，实现生产的规模经营。而社会资金也可以购买股份公司的股票，谋求财富的增值 国内股票市场（简称 A 股）更多的是融资市场的角色，而不是投资市场。主要是为融资服务，卖力 IPO，稳定地助力实体经济。（也难怪大 A 投资层面比较拉胯，毕竟市场的态度就在这。） 再者，国内市场上各种面的分析，诸如基本面分析、技术面、市场面、政策面，各种面都很好，但在 A 股都不够（流泪吃面是大 A 韭菜的必备休养！）。各种理论也是层出不穷，比如缠论、庄家理论、以及美股推崇的长期价值理论，尽管都很有道理，但经不住现实 A 股的打击。 归根结底在于，「市场的核心还是基于信息差，真正重要的信息获取不到的，可能很多还是制造乌烟瘴气的烟雾弹。只能寄望更好的经济预期，以及信息披露及制度完善，打造一个更公平的市场吧！」 那股票量化能不能赚钱？个人感觉量化会比散户有优势（并不是绝对优势）。毕竟股票量化的盈利来源和其他市场上的参与者，并无本质区别，主要可以归因成几个部分： 一是，源于企业自身的价值和成长。能够实现这个收益可能只是 A 股的理想，因为现实中还是很受各种打击的。毕竟辛苦成长了那么多年，还在 3000 点徘徊。再遥望下美丽国、阿三的股市，真的格外尴尬。 二是，源于股票价格的非理性波动，并提供更准确的定价。量化的盈利基于市场的失效的前提下，用较低的价格买入被市场低估的”商品”，推动市场价格达到更好的平衡。在热衷跟风炒作的 A 股上面，这点还是有不错的空间的，量化可以通过大数据中挖掘更多有价值的信息，形成更为理性合理的决策。只要跑赢散户的非理性就有一定的收益。 2.2 期货市场期货合约（Futures contract），简称期货（Futures），是一种跨越时间的交易方式。买卖双方透过签订合约，同意按指定的时间、价格与其他交易条件，交收指定数量的现货。通常期货集中在期货交易所，以标准化合约进行买卖，但亦有部分期货合约可透过柜台交易进行买卖，称为场外交易合约。交易的资产通常是商品或金融工具。期货的品种有： 农产品期货：如棉花、大豆、小麦、玉米、白糖等。 金属期货：如铜、铝、锡、锌、镍、黄金、白银。 能源期货：如原油、汽油、燃料油。 金融期货: 如国债期货、股指期货。（注: 金融期货的波动性及风险相对较大） 一样的，期货市场在于买卖期货赚取差价。但与股市不同，期货市场的投资操作空间更多（可以做多、做空；支持 T+0 交易等等），同时杠杆也更大，回撤大，风险高，风险收益可能也高。 个人的感觉，期货是一个负和博弈市场，赢得收益主要来自市场中对手的失误，赢的只有少数信息优势的人。可能期货更适合行业人员，需要敏锐地捕捉行业的机遇。再者通过期现套利对冲实业经营的风险也是很不错的手段。 3、量化交易常见策略量化策略的方法有五花八门的，搞简单点可以通过基本面、技术面分析获得一些因子进行交易（比如股票猛涨并且近期有所收缓，利用相关指标简单设定一个 RSI 大于 80 就抛出股票），复杂点还可以利用各种各样数据，结合人工智能分析预测、高频交易什么的。 这里按照个人不深刻的理解，如下归类大概量化策略： A. 多因子选股模型：用”因子”来识别股票和市场的特征，在因子的帮助下评估价格，买入价格偏低的，卖出价格偏高的股票。比如根据 RSI 设计一个反转因子，RSI 非常高，过度高涨，后面可能就容易跌。再根据过去时间 T 内的加权平均涨幅设计动量因子，通过结合多个因子做打分回归建模预测未来收益。 常见的因子有： 价值因子：市盈率、市净率、现金流等财务指标（估值低的票容易涨）； 成长因子：过去三年期间的净利润和营收的复合增长率（高增长的票容易涨）； 动量因子：过去时间 T 内的加权平均涨幅（趋势是否确立)； 波动率因子：如果股票的波动率偏低，它后续往往会涨（市场风险偏好）； 流动性因子：如果股票的换手率偏低，它后续往往会涨（缩量筑底）； 情绪因子：如果统计分析显示，市场参与者普遍偏乐观，一般会涨； 资金流因子：如果大盘、板块、个股持续有资金流入，往往会涨； 板块因子：如果一个板的热点股票涨了，往往整个板块的股票都会涨；‍ 盘口因子：在十档盘口上，如果买挂单比卖挂单强势，短期往往会涨； 反转因子，通俗地说，就是涨多了的股票可能要跌，跌多了的股票可能要涨。 ‍来源：幻方量化 18 问‍ ‍ 市场常见的多因子模型有： ‍ **B. 价值投资策略：** 通过基本面分析，如市盈率、市净率、现金流、净利润和营收的复合增长率等财务指标，分析公司的盈利模式是否可靠，预估未来价值，在价格较低的时候考虑买入。 **C. 事件驱动策略：** 及时根据政策变化（货币政策、外汇、行业政策）、自然因素变化制定对应策略，这个应该是炒股、期货必知策略。比如：当有加息计划，大家就会考虑把股票的钱存银行，获得更多无风险利益，可能要适当减持些股票；当有自然灾害，可能农作物期货价值就会上升，可以做多。 **D. 对冲策略：** 通过投资组合的多样化来降低市场风险的策略。对冲策略的核心思想是利用不同资产之间的价格波动来抵消彼此的风险，从而降低整体投资组合的风险。对冲策略的具体操作方式有很多种，包括配对交易、套利交易、期权交易、alpha 对冲等。比如经典的配对交易对冲策略，当两个合约有很强的相关性时，可能存在相似的变动关系，两种合约之间的价差会维持在一定的水平上。当市场出现变化时，两种合约之间的价差会偏离均衡水平。此时，可以买入其中一份合约同时卖出其中一份合约，当价差恢复到正常水平时平仓，获取收益。 **E. 高频交易策略：** 其核心思想是利用市场价格的短期波动来获取利润。通过高频数据分析和预测，投资者可以快速地买入和卖出股票、期货和其他金融产品，以捕捉微小的价格差异和波动。这种策略通常依赖于高速交易系统和算法，以在毫秒或更短的时间内执行交易决策，具有较高的交易频率和风险，但同时也具有较高的潜在收益。 **F. 量化择时策略：** 通过分析历史数据、市场趋势、投资者情绪等因素，预测未来的市场走势，做为投资决策。常用的有趋势择时、市场情绪择时、牛熊线、神经网络预测、统计套利等方法。比如经典的双均线趋势跟踪策略，当近短期上升趋势比之前有所突破就可以考虑入手，反之可以考虑抛出。如下附上经典的双均线策略示例： #encoding:gbkimport pandas as pdimport numpy as npimport datetime示例说明：当短期均线由上向下穿越长期均线时做空当短期均线由下向上穿越长期均线时做多策略讲解：https://www.myquant.cn/docs/python_strategyies/153class a():passA = a() #创建空的类的实例 用来保存委托状态 #ContextInfo对象在盘中每次handlebar调用前都会被深拷贝, 如果调用handlebar的分笔不是k线最后分笔 ContextInfo会被回退到深拷贝的内容 所以ContextInfo不能用来记录快速交易的信号def init(C): # 回测代码 A.acct = 88 A.acct_type= STOCK A.stock= C.stockcode + . + C.market #品种为模型交易界面选择品种 #A.acct= account #账号为模型交易界面选择账号 #A.acct_type= accountType #账号类型为模型交易界面选择账号 A.amount = 10000 #单笔买入金额 触发买入信号后买入指定金额 A.line1=5 #快线周期 A.line2=20 #慢线周期 A.waiting_list = [] #未查到委托列表 存在未查到委托情况暂停后续报单 防止超单 A.buy_code = 23 if A.acct_type == STOCK else 33 #买卖代码 区分股票 与 两融账号 A.sell_code = 24 if A.acct_type == STOCK else 34 #设置股票池 订阅品种行情 C.set_universe([A.stock]) print(f设置双均线A.line1，A.line2实盘示例A.stock A.acct A.acct_type 单笔买入金额A.amount)def handlebar(C): #跳过历史k线 if not C.is_last_bar() : #回测 print(is last null) return now = datetime.datetime.now() now_time = now.strftime(%H%M%S) #跳过非交易时间 if now_time 093000 or now_time 150000: print(非交易时间) return # 获取账户信息 #print(get_trade_detail_data(A.acct, A.acct_type, account)) #print(get_trade_detail_data(A.acct, A.acct_type, ACCOUNT)) account = get_trade_detail_data(A.acct, A.acct_type, account) if len(account)==0: print(f账号A.acct 未登录 请检查) return account = account[0] available_cash = int(account.m_dAvailable) #如果有未查到委托 查询委托 if A.waiting_list: found_list = [] orders = get_trade_detail_data(A.acct, A.acct_type, order) print(wait-orders,A.waiting_list,orders) for order in orders: if order.m_strRemark in A.waiting_list: found_list.append(order.m_strRemark) A.waiting_list = [i for i in A.waiting_list if i not in found_list] A.waiting_list = [] #回测修改为0 if A.waiting_list: print(f当前有未查到委托 A.waiting_list 暂停后续报单) return holdings = get_trade_detail_data(A.acct, A.acct_type, position) #print(holdings,holdings) holdings = i.m_strInstrumentID + . + i.m_strExchangeID : i.m_nCanUseVolume for i in holdings #print(holdings,holdings)####核心逻辑代码 # 获取行情数据 1d data = C.get_history_data(max(A.line1, A.line2)+1, 1d, close,dividend_type=front_ratio) close_list = data[A.stock] if len(close_list) max(A.line1, A.line2)+1: print(行情长度不足(新上市或最近有停牌) 跳过运行) return pre_line1 = np.mean(close_list[-A.line1-1: -1]) pre_line2 = np.mean(close_list[-A.line2-1: -1]) current_line1 = np.mean(close_list[-A.line1:]) current_line2 = np.mean(close_list[-A.line2:]) ## # 旧短大于旧长 新短小于新长 死叉抛；旧短小于旧长 新短大于新长 自下而上穿均线金叉入 #如果快线穿过慢线,则买入委托 当前无持仓 买入 vol = int(A.amount / close_list[-1] / 100) * 100 #买入数量 向下取整到100的整数倍 if A.amount available_cash and vol = 100 and A.stock not in holdings and pre_line1 pre_line2 and current_line1 current_line2: #下单开仓 ，参数说明可搜索PY交易函数 passorder msg = f双均线实盘 A.stock 上穿均线 买入 vol股 passorder(A.buy_code, 1101, A.acct, A.stock, 14, -1, vol, 双均线实盘, 1 , msg, C) print(msg) A.waiting_list.append(msg) #如果快线下穿慢线,则卖出委托 if A.stock in holdings and holdings[A.stock] 0 and pre_line1 pre_line2 and current_line1 current_line2: msg = f双均线实盘 A.stock 下穿均线 卖出 holdings[A.stock]股 passorder(A.sell_code, 1101, A.acct, A.stock, 14, -1, holdings[A.stock], 双均线实盘, 1 , msg, C) print(msg) A.waiting_list.append(msg) 量化策略设计开发中，Python 编程的入门并不难（可以参考-Python 人工智能学习路线 的 Python 学习建议），前期编程只要入门够用就行了，只有交易的思路才是始终的核心！除了积累交易经验、学习经典策略，还可以研究各大公司的 研报，学习前沿的策略设计，才比较有可能跟得上市场。（有时找 ChatGPT 聊聊策略，激发些思路也是不错~） 特别地，对于新手而言，个人觉得先学习写一个止盈止损策略是门必修课，先学会如何控制好风险是首要的，其次才是折腾怎么盈利。 4、完整量化交易的流程 可能很多文章讲到量化策略就戛然而止，对于新手很不友好。梳理下量化主要的流程：开通证券账号 → 搭建量化交易系统及开通实盘交易 → 设计量化策略 → 数据获取及处理 → 开发策略 → 策略回测 → 调试优化 → 实盘交易。 入门量化其实较大的门槛是搭建并开通好量化交易环境，然后才是开发策略代码。 搭建量化交易系统及开通实盘交易 量化交易系统环境的准备，个人不建议在没有较多量化经验的基础就从头折腾交易系统，诸如 编写交易的框架（还有个折中方案，可以折腾下开源的框架）、回测框架、穿透测试、对接实盘接口及调试 bugs 等等的会很耗费精力。（当然技术过硬的有兴趣折腾的人还是可以试试。） 前期，可以直接使用现成量化交易框架，现成的软件可以方便 数据获取，回测验证效果，交易，可以专攻量化策略的实现及优化。先达成效果，再过度优化，也会有比较有效率。 比较常用的量化交易系统有：云核、iquant、迅投 QMT、GTrade、极智量化、文 华、TB 开拓者、聚宽等，这些平台也大都支持股票、ETF、期货、期权交易。（笔者用的是 iquant，目前感觉够用。具体文末微信群咨询。） 策略实盘交易 实盘过程主要还是注意控制风险，设定好止损及合理的仓位，开发好的策略需要梳理好逻辑以及充足的回测，调试好再上实盘交易会比较稳妥，根据实盘表现，定期复盘，改进交易策略，尝试新的交易思路和方法，不断精进交易策略。另外的，最好将前期的资金投入控制少一点，即使已经过充足的回测可以盈利，但回测结果也可能是过拟合，所以实盘前期投入点先试试水也是很有必要的！ 个人是直接先入个几百块做股票量化：实盘买些便宜且稳定的 ETF 股票（买一手也就 100 来块），既可以手动交易下熟悉下股票交易流程，也可以挂机跑些简单策略，晚上下班在分析下策略运行结果，做一些调整优化。小资金实盘交易试水，过段时间看下策略效果及市场行情稳定后，再投入较大资金。个人实践表明这样的量化入门效率是比较高的。 文末免责声明：本文观点仅供参考，不作为投资建议哈","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python量化交易策略 【附代码示例 - 实战必备】 - AllTick 博客","path":"/2024/12/24/5-生活-金融-Python量化交易策略-【附代码示例-实战必备】-AllTick-博客/","content":"五个经典量化交易策略及 Python 实现随着算法交易的兴起，Python 已成为量化开发从业者的必备工具。这得益于 Python 在科学计算和数据分析领域的强大生态系统，以及其优秀的第三方库的支持。以下是五个经典的量化交易策略及其对应的 Python 代码示例： #1 均值回归策略均值回归策略是一种统计套利策略，基于资产价格围绕其长期均值波动的假设。以下是使用简单移动平均线和标准差来定义买卖信号的示例： import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# 生成模拟数据data = pd.DataFrame( Date: pd.date_range(start=2023-01-01, periods=100), Close: np.random.normal(100, 10, 100))data.set_index(Date, inplace=True)# 计算20日移动均线和标准差window = 20data[Moving Average] = data[Close].rolling(window=window).mean()data[Standard Deviation] = data[Close].rolling(window=window).std()# 定义买卖信号data[Upper Bound] = data[Moving Average] + data[Standard Deviation]data[Lower Bound] = data[Moving Average] - data[Standard Deviation]data[Position] = 0data.loc[data[Close] data[Lower Bound], Position] = 1 # 买入信号data.loc[data[Close] data[Upper Bound], Position] = -1 # 卖出信号# 绘制图表plt.figure(figsize=(14, 7))plt.plot(data[Close], label=Close Price)plt.plot(data[Moving Average], label=Moving Average)plt.fill_between(data.index, data[Upper Bound], data[Lower Bound], color=gray, alpha=0.3, label=Mean Reversion Band)plt.plot(data.index, data[Position] * 50, label=Trading Signal, color=magenta)plt.legend()plt.show() #2 趋势跟踪策略趋势跟踪策略通过比较短期和长期移动平均线来判断市场趋势。以下是使用 MACD 指标生成买卖信号的示例： import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# 生成模拟数据data = pd.DataFrame( Date: pd.date_range(start=2023-01-01, periods=200), Close: np.random.normal(100, 15, 200))data.set_index(Date, inplace=True)# 计算短期和长期移动平均线short_window = 40long_window = 100data[Short MA] = data[Close].rolling(short_window).mean()data[Long MA] = data[Close].rolling(long_window).mean()# 生成交易信号data[Signal] = 0data[Signal][short_window:] = np.where(data[Short MA][short_window:] data[Long MA][short_window:], 1, 0)data[Position] = data[Signal].diff()# 绘制图表plt.figure(figsize=(14, 7))plt.plot(data[Close], label=Close Price)plt.plot(data[Short MA], label=40-Day Moving Average)plt.plot(data[Long MA], label=100-Day Moving Average)plt.plot(data.index, data[Position] * 50, label=Trading Signal, color=magenta, marker=o, linestyle=None)plt.legend()plt.show() #3 配对交易（Pair Trading）配对交易基于两种资产价格差异的统计套利。以下是使用价差和标准差生成买卖信号的示例： import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# 生成模拟数据np.random.seed(42)data = pd.DataFrame( Date: pd.date_range(start=2023-01-01, periods=180), Asset_A: np.random.normal(100, 10, 180).cumsum() + 100, Asset_B: np.random.normal(100, 10, 180).cumsum() + 120)data.set_index(Date, inplace=True)# 计算价差data[Price_Diff] = data[Asset_A] - data[Asset_B]# 计算移动平均和标准差window = 30data[Mean_Diff] = data[Price_Diff].rolling(window=window).mean()data[Std_Diff] = data[Price_Diff].rolling(window=window).std()# 定义买卖信号data[Upper_Bound] = data[Mean_Diff] + data[Std_Diff]data[Lower_Bound] = data[Mean_Diff] - data[Std_Diff]data[Position] = 0data.loc[data[Price_Diff] data[Upper_Bound], Position] = -1 # 做空 Asset A，做多 Asset Bdata.loc[data[Price_Diff] data[Lower_Bound], Position] = 1 # 做多 Asset A，做空 Asset B# 绘制图表plt.figure(figsize=(14, 7))plt.subplot(211)plt.plot(data[Asset_A], label=Asset A)plt.plot(data[Asset_B], label=Asset B)plt.legend()plt.subplot(212)plt.plot(data[Price_Diff], label=Price Difference)plt.plot(data[Mean_Diff], label=Mean Difference)plt.fill_between(data.index, data[Upper_Bound], data[Lower_Bound], color=gray, alpha=0.3, label=Trading Zone)plt.plot(data.index, data[Position] * 20, label=Trading Signal, color=magenta, marker=o, linestyle=None)plt.legend()plt.show() #4 统计套利统计套利利用多种资产之间的价格差异进行套利。以下是基于两个股票价差的示例： import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# 生成模拟数据np.random.seed(42)data = pd.DataFrame( Date: pd.date_range(start=2023-01-01, periods=250), Stock_A: np.random.normal(0, 1, 250).cumsum() + 50, Stock_B: np.random.normal(0, 1, 250).cumsum() + 50)data.set_index(Date, inplace=True)# 计算价差data[Spread] = data[Stock_A] - data[Stock_B]# 计算移动平均和标准差window = 20data[Spread Mean] = data[Spread].rolling(window=window).mean()data[Spread Std] = data[Spread].rolling(window=window).std()# 定义买卖阈值entry_z = 2exit_z = 0data[Upper Threshold] = data[Spread Mean] + entry_z * data[Spread Std]data[Lower Threshold] = data[Spread Mean] - entry_z * data[Spread Std]data[Exit Threshold] = data[Spread Mean] + exit_z * data[Spread Std]# 生成交易信号data[Position] = 0data.loc[data[Spread] data[Upper Threshold], Position] = -1 # 做空 Stock A，做多 Stock Bdata.loc[data[Spread] data[Lower Threshold], Position] = 1 # 做多 Stock A，做空 Stock Bdata.loc[data[Spread] * data[Position] data[Exit Threshold], Position] = 0 # 退出信号# 绘制图表plt.figure(figsize=(14, 7))plt.subplot(211)plt.plot(data[Stock_A], label=Stock A)plt.plot(data[Stock_B], label=Stock B)plt.title(Stock Prices)plt.legend()plt.subplot(212)plt.plot(data[Spread], label=Spread)plt.plot(data[Spread Mean], label=Mean Spread)plt.fill_between(data.index, data[Upper Threshold], data[Lower Threshold], color=gray, alpha=0.3, label=Entry Zone)plt.plot(data.index, data[Position] * 10, label=Trading Signal, color=magenta, marker=o, linestyle=None)plt.title(Spread and Trading Signals)plt.legend()plt.show() #5 波动性交易波动性交易策略利用市场波动性变化进行交易。以下是基于历史波动性生成买卖信号的示例： import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# 生成模拟数据np.random.seed(42)dates = pd.date_range(start=2023-01-01, periods=250)prices = np.random.normal(0, 1, 250).cumsum() + 100data = pd.DataFrame(Date: dates, Price: prices)data.set_index(Date, inplace=True)# 计算日收益率data[Returns] = data[Price].pct_change()data.dropna(inplace=True)# 计算历史波动性window = 20data[Volatility] = data[Returns].rolling(window=window).std() * np.sqrt(252) # 年化波动性# 定义买卖阈值threshold_high = data[Volatility].mean() * 1.2threshold_low = data[Volatility].mean() * 0.8# 生成交易信号data[Position] = 0data.loc[data[Volatility] threshold_high, Position] = -1 # 高波动性时卖出data.loc[data[Volatility] threshold_low, Position] = 1 # 低波动性时买入# 绘制图表plt.figure(figsize=(14, 10))plt.subplot(211)plt.plot(data[Price], label=Price)plt.title(Stock Price)plt.legend()plt.subplot(212)plt.plot(data[Volatility], label=Volatility)plt.axhline(y=threshold_high, color=r, linestyle=--, label=High Threshold)plt.axhline(y=threshold_low, color=g, linestyle=--, label=Low Threshold)plt.plot(data.index, data[Position] * 0.01, label=Trading Signal, color=magenta, marker=o, linestyle=None)plt.title(Volatility and Trading Signals)plt.legend()plt.show() 以上五种策略各有其适用场景，投资者可以根据市场环境和资产特性选择合适的策略进行交易。","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python 量化股票 K 线图  菜鸟教程","path":"/2024/12/24/5-生活-金融-Python-量化股票-K-线图/","content":"可以通过 Python pyecharts 模块 来绘制股票 K 线图。 pyecharts 是一个基于 ECharts 的 Python 数据可视化库，它允许用户使用 Python 语言生成各种类型的交互式图表和数据可视化。 Python pyecharts 模块内容查看：Python pyecharts 模块。 在 pyecharts 中，可以使用 K 线图（Kline）来展示股票走势，K 线图主要用于展示金融数据，如股票的开盘价、收盘价、最高价、最低价等信息。 首先，确保已经安装了 pyecharts： pip install pyecharts 使用雅虎财经（Yahoo Finance）的数据获取近一年的股票数据，可以使用 yfinance 库： pip install yfinance K 线图使用导入相关模块： from pyecharts import options as optsfrom pyecharts.charts import Kline 准备数据： Kline 图的数据通常是一个包含开盘价、收盘价、最高价、最低价的二维数组，例如： data = [ [2320.26, 2320.26, 2287.3, 2362.94], [2300, 2291.3, 2288.26, 2308.38], # ...] 配置 Kline 图： kline = ( Kline() .add_xaxis(xaxis_data=[2017-10-24, 2017-10-25, 2017-10-26, 2017-10-27]) .add_yaxis(series_name=Kline, y_axis=data) .set_global_opts( xaxis_opts=opts.AxisOpts(is_scale=True), yaxis_opts=opts.AxisOpts(is_scale=True), title_opts=opts.TitleOpts(title=Kline 示例), )) 在这里，使用了 add_xaxis 设置 x 轴的数据，使用 add_yaxis 添加 Kline 数据系列，set_global_opts 则用于设置全局配置，包括标题等。 渲染图表： kline.render(kline_chart.html) 将 Kline 图渲染到 HTML 文件中。 实例from pyecharts import options as opts from pyecharts.charts import Kline# 准备数据 data = [ [2320.26, 2320.26, 2287.3, 2362.94], [2300, 2291.3, 2288.26, 2308.38], [2295.35, 2346.5, 2295.35, 2345.92], [2347.22, 2358.98, 2337.35, 2363.8], # ... more data ]# 配置 Kline 图 kline = ( Kline() .add_xaxis(xaxis_data=[2017-10-24, 2017-10-25, 2017-10-26, 2017-10-27]) .add_yaxis(series_name=Kline, y_axis=data) .set_global_opts( xaxis_opts=opts.AxisOpts(is_scale=True), yaxis_opts=opts.AxisOpts(is_scale=True), title_opts=opts.TitleOpts(title=Kline 示例), ) )# 渲染图表 kline.render(kline_chart.html) 说明： 有一个名为 data 的数据集，其中包含每天的金融数据，包括开盘价、收盘价、最高价和最低价。 创建了一个 Kline 实例，使用 add_xaxis 设置 x 轴数据（在这种情况下是日期），使用 add_yaxis 添加 Kline 数据系列。 使用 set_global_opts 设置全局选项，例如 x 轴和 y 轴的缩放，以及图表标题。 最后，使用 render 将图表渲染到一个 HTML 文件中。 当前目录会生成一个 kline_chart.html 文件，打开该文件图表显示如下： 下面是一个实例代码，演示如何获取贵州茅台的股票数据并生成 K 线图： 实例import yfinance as yf from pyecharts import options as opts from pyecharts.charts import Kline# 获取贵州茅台近三年的股票数据 symbol = 600519.SS # 600519.SS 为贵州茅台的股票代码 start_date = 2020-01-01 end_date = 2022-12-31stock_data = yf.download(symbol, start=start_date, end=end_date)# 提取 K 线图所需的数据格式 kline_data = [] for index, row in stock_data.iterrows(): kline_data.append([row[Open], row[Close], row[Low], row[High]])# 配置 Kline 图 kline = ( Kline() .add_xaxis(xaxis_data=stock_data.index.strftime(%Y-%m-%d).tolist()) .add_yaxis(series_name=Kline, y_axis=kline_data) .set_global_opts( xaxis_opts=opts.AxisOpts(is_scale=True), yaxis_opts=opts.AxisOpts(is_scale=True), title_opts=opts.TitleOpts(title=贵州茅台 Kline 图示例), datazoom_opts=[opts.DataZoomOpts()], toolbox_opts=opts.ToolboxOpts( feature= dataZoom: yAxisIndex: none, restore: , saveAsImage: , ), ) )# 渲染图表 kline.render(maotai_kline_chart.html) 当前目录会生成一个 maotai_kline_chart.html 文件，打开该文件图表显示如下： 绘制曲线图也可以使用 pyecharts 绘制股票的简单曲线图，以茅台（600519.SH）为例： 实例import yfinance as yf from pyecharts import options as opts from pyecharts.charts import Line from datetime import datetime, timedelta# 设置茅台股票代码 stock_code = 600519.SS# 获取当前日期 end_date = datetime.now().strftime(%Y-%m-%d)# 计算三年前的日期 start_date = (datetime.now() - timedelta(days=3 * 365)).strftime(%Y-%m-%d)# 使用 yfinance 获取股票数据 df = yf.download(stock_code, start=start_date, end=end_date)# 提取数据中的日期和收盘价 dates = df.index.strftime(%Y-%m-%d).tolist() closing_prices = df[Close].tolist()# 创建 Line 图表 line_chart = Line() line_chart.add_xaxis(xaxis_data=dates) line_chart.add_yaxis(series_name=茅台股价走势, y_axis=closing_prices, markline_opts=opts.MarkLineOpts( data=[opts.MarkLineItem(type_=average, name=平均值)] ) ) line_chart.set_global_opts( title_opts=opts.TitleOpts(title=茅台股价走势图（近三年）), xaxis_opts=opts.AxisOpts(type_=category), yaxis_opts=opts.AxisOpts(is_scale=True), datazoom_opts=[opts.DataZoomOpts(pos_bottom=-2%)], )# 渲染图表 line_chart.render(maotai_stock_trend_chart.html) 当前目录会生成一个 maotai_stock_trend_chart.html 文件，打开该文件图表显示如下： 可以考虑添加一些图表的工具，例如数据缩放、数据视图等，以提升用户的交互体验。 以下是优化后的代码，添加了数据缩放和数据视图的功能： 实例import yfinance as yf from pyecharts import options as opts from pyecharts.charts import Line from pyecharts.commons.utils import JsCode from datetime import datetime, timedelta# 设置茅台股票代码 stock_code = 600519.SS# 获取当前日期 end_date = datetime.now().strftime(%Y-%m-%d)# 计算三年前的日期 start_date = (datetime.now() - timedelta(days=3 * 365)).strftime(%Y-%m-%d)# 使用 yfinance 获取股票数据 df = yf.download(stock_code, start=start_date, end=end_date)# 提取数据中的日期和收盘价 dates = df.index.strftime(%Y-%m-%d).tolist() closing_prices = df[Close].tolist()# 创建 Line 图表 line_chart = Line() line_chart.add_xaxis(xaxis_data=dates) line_chart.add_yaxis(series_name=茅台股价走势, y_axis=closing_prices, markline_opts=opts.MarkLineOpts( data=[opts.MarkLineItem(type_=average, name=平均值)] ) ) line_chart.set_global_opts( title_opts=opts.TitleOpts(title=茅台股价走势图（近三年）), xaxis_opts=opts.AxisOpts(type_=category), yaxis_opts=opts.AxisOpts(is_scale=True), datazoom_opts=[ opts.DataZoomOpts( pos_bottom=-2%, range_start=0, range_end=100, type_=inside ), opts.DataZoomOpts( pos_bottom=-2%, range_start=0, range_end=100, type_=slider, ), ], toolbox_opts=opts.ToolboxOpts( feature= dataZoom: yAxisIndex: none, restore: , saveAsImage: , ), )# 渲染图表 line_chart.render(maotai_stock_trend_chart2.html) 当前目录会生成一个 maotai_stock_trend_chart2.html 文件，打开该文件图表显示如下：","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python 量化回测","path":"/2024/12/24/5-生活-金融-Python-量化回测/","content":"回测是在历史市场数据上模拟和评估一个交易策略的过程。 在量化金融和算法交易中，回测是一个关键的步骤，用于评估交易策略在过去市场行为上的表现。 通过回测，交易者可以了解其策略在不同市场条件下的表现，并进行优化和改进。 回测通常包括以下步骤： 定义交易策略： 确定何时买入、卖出或持仓的规则。这可能涉及到技术指标、移动平均线策略、趋势跟踪、套利等各种策略。 获取历史数据： 获取过去的市场数据，包括股票、期货、外汇等金融工具的价格、成交量等信息。 模拟交易： 根据定义的策略，模拟在历史数据上执行交易。这包括确定何时买入或卖出，并计算每次交易的收益和损失。 计算绩效指标： 根据回测结果，计算各种绩效指标，如年化收益率、最大回撤、夏普比率等，以评估策略的表现。 优化策略： 如果回测结果不理想，交易者可以进行策略的优化，调整参数或修改规则，然后重新进行回测。 未来性检验： 回测的一个关键问题是防止未来数据的泄漏。未来性检验是确保在设计和评估策略时只使用历史数据的一部分，以模拟实际交易中只能使用已知信息的情况。 接下来，这是一个简单的移动平均交叉策略的回测实例代码： 实例import yfinance as yf import pandas as pd import matplotlib.pyplot as plt# 获取股票数据 symbol = 600519.SS # 茅台股票代码 start_date = 2019-01-01 end_date = 2021-01-01data = yf.download(symbol, start=start_date, end=end_date)# 计算移动平均 data[SMA_50] = data[Close].rolling(window=50).mean() data[SMA_200] = data[Close].rolling(window=200).mean()# 初始化交叉信号列 data[Signal] = 0# 计算交叉信号 data.loc[data[SMA_50] data[SMA_200], Signal] = 1 data.loc[data[SMA_50] data[SMA_200], Signal] = -1# 计算每日收益率 data[Daily_Return] = data[Close].pct_change()# 计算策略信号的收益率（shift(1) 是为了避免未来数据的偏差） data[Strategy_Return] = data[Signal].shift(1) * data[Daily_Return]# 计算累计收益 data[Cumulative_Return] = (1 + data[Strategy_Return]).cumprod()# 绘制累计收益曲线 plt.figure(figsize=(10, 6)) plt.plot(data[Cumulative_Return], label=Strategy Cumulative Return, color=b) plt.plot(data[Close] / data[Close].iloc[0], label=Stock Cumulative Return, color=g) plt.title(Cumulative Return of Strategy vs. Stock) plt.xlabel(Date) plt.ylabel(Cumulative Return) plt.legend() plt.show() 执行以上代码，输出结果如下：","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python 量化金融库  菜鸟教程","path":"/2024/12/24/5-生活-金融-Python-量化金融库-菜鸟教程/","content":"学习一些量化金融领域常用的 Python 库，比如： zipline: 用于回测和实施交易算法的库，安装命令：pip install zipline。 Quantlib: 用于定价金融工具和执行金融计算的库，安装命令：pip install Quantlib。 TA-Lib: 用于技术分析的库，安装命令：pip install TA-Lib。 pyfolio: 是一个用于评估投资组合性能的库，它可以与 zipline 等回测工具集成，提供分析投资组合收益、风险等方面的工具，安装命令：pip install pyfolio。 statsmodels: 是一个用于估计统计模型的库，包括线性回归、时间序列分析等。在量化金融中，它可用于建立和测试交易策略，安装命令：pip install statsmodels。 ziplinezipline 是一个用于量化金融研究和算法交易的开源框架。 它是由 Quantopian 公司开发的，旨在为研究员和开发者提供一个方便的工具，用于构建、测试和执行量化交易策略。 在 zipline 的使用之前，请确保已经安装了该库，可以使用以下命令进行安装： conda install -c conda-forge zipline 这里使用 Anaconda 来安装 zipline，免得后面出现奇奇怪怪的问题。 接下来登录 quandl 官网，进行注册，获得 api key：https://data.nasdaq.com/account/profile。 然后设置 api key，并下载数据包，具体命令如下： set QUANDL_API_KEY=your_key macOS 系统使用以下命令： export QUANDL_API_KEY=your_key-zZQN 下载数据包： zipline ingest -b quandl 查询数据包： # zipline bundlescsvdir no ingestionsquandl 2023-12-09 06:02:03.178299quandl 2023-12-09 05:59:04.273082quandl 2023-12-09 05:54:57.277732quandl 2023-12-09 05:52:15.532504quandl 2023-12-09 03:32:03.853032quantopian-quandl no ingestions 现在，让使用 zipline 进行一个简单的测试。 以下是是一个简单的 Zipline 策略脚本，用于进行股票交易的回测： 实例from zipline.api import order, record, symboldef initialize(context): passdef handle\\_data(context, data): order(symbol(AAPL), 10) record(AAPL\\=data.current(symbol(AAPL), price)) 以上是一个简单的策略在每个交易日都以当前价格买入 10 股苹果公司的股票，并记录每个交易日的 AAPL 当前价格。 order(symbol(AAPL), 10)：这一行表示在每个交易日，以当前价格购买 10 股苹果公司（AAPL）的股票。symbol(AAPL) 用于获取 AAPL 的股票符号。 record(AAPL=data.current(symbol(AAPL), price))：这一行表示记录每个交易日 AAPL 的当前价格。data.current(symbol(AAPL), price) 用于获取当前 AAPL 的股价。 然后执行以下命令： # zipline run -f my_strategy.py --start 2016-1-1 --end 2018-1-1 -o buyapple_out.pickle --no-benchmarkSimulated 503 trading days first open: 2016-01-04 14:30:00+00:00 last close: 2017-12-29 21:00:00+00:00 执行成功后，会生成 buyapple_out.pickle 文件，可以使用 pickle 模块读取它。 命令说明： zipline run： 启动 Zipline 运行回测。 -f my_strategy.py： 指定策略文件。在这个例子中，my_strategy.py 是包含编写的策略的 Python 文件。 --start 2016-1-1 和 --end 2018-1-1： 指定回测的起始和结束日期。这个例子中回测的时间范围是从 2016 年 1 月 1 日到 2018 年 1 月 1 日。 -o buyapple_out.pickle： 指定输出文件的名称。在这个例子中，回测的结果将被保存为 buyapple_out.pickle 文件。这个文件包含了回测的各种输出信息，例如交易记录、性能指标等。 --no-benchmark： 禁用基准（benchmark）。在回测中，有时会使用某个基准来比较策略的表现。使用 --no-benchmark 选项表示不使用任何基准。 pickle 模块用于序列化和反序列化对象，可以方便地将对象保存到文件或从文件中加载对象。 以下演示如何读取 buyapple_out.pickle 文件中的内容： 实例import pickle # 指定 pickle 文件路径pickle_file_path = ‘buyapple_out.pickle’ # 读取 pickle 文件with open(pickle_file_path, ‘rb’) as file: buyapple_out_data = pickle.load(file) # 打印读取的数据print(buyapple_out_data) 输出内容如下所示： period_open period_close short_value pnl long_exposure ... max_leverage excess_return treasury_period_return trading_days period_label2016-01-04 21:00:00+00:00 2016-01-04 14:31:00+00:00 2016-01-04 21:00:00+00:00 0.0 0.00000 0.0 ... 0.000000 0.0 0.0 1 2016-012016-01-05 21:00:00+00:00 2016-01-05 14:31:00+00:00 2016-01-05 21:00:00+00:00","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python 量化数据可视化  菜鸟教程","path":"/2024/12/24/5-生活-金融-Python-量化数据可视化-菜鸟教程/","content":"Python 量化数据可视化可以使用 Matplotlib 和 Seaborn 库。 安装 Matplotlib 和 Seaborn 可以在终端或命令提示符中运行： pip install matplotlib seaborn Matplotlib 详细内容可以参考： Matplotlib 教程 本章节主要为大家介绍 Seaborn 库的使用。 Seaborn 库Seaborn 是一个基于 Matplotlib 的数据可视化库，专注于统计图形的绘制。 Seaborn 提供了一些高层次的界面和颜色主题，使得在 Python 中创建漂亮的统计图表变得更加容易。 Seaborn 的目标是使数据可视化变得更简单，同时也让图表更具有吸引力。 1. 统计图形的简单创建Seaborn 提供了一系列内置的绘图函数，可以轻松地创建各种统计图形，如散点图、直方图、箱线图等。 实例import seaborn as snsimport matplotlib.pyplot as plt # 创建散点图sns.scatterplot(x=‘sepal_length’, y=‘sepal_width’, data=iris)plt.show() 2. 内置颜色主题Seaborn 提供了内置的颜色主题，可以让轻松地改变图表的外观，使其更具有吸引力。 # 使用 Seaborn 颜色主题sns.set(style=whitegrid) 3. 数据集可视化Seaborn 包含一些内置的数据集，可以直接用于绘图，例如，tips 和 flights 数据集。 # 使用内置数据集tips = sns.load_dataset(tips) 4. 分类数据的可视化Seaborn 对于分类数据的处理非常方便，可以轻松地创建分组柱状图、箱线图等。 # 创建分组柱状图sns.barplot(x=day, y=total_bill, hue=sex, data=tips) 5. 矩阵数据的可视化Seaborn 提供了一些专门用于可视化矩阵数据的函数，例如热力图（heatmap）。 # 创建热力图corr_matrix = df.corr()sns.heatmap(corr_matrix, annot=True, cmap=coolwarm) 6. 分面绘图Seaborn 支持分面绘图，可以根据数据的子集创建多个小图，以更全面地展示数据。 # 分面绘图sns.relplot(x=total_bill, y=tip, hue=day, col=time, data=tips) Seaborn 提供了大量的图形选项和参数，以满足不同类型的数据可视化需求。 总体而言，Seaborn 是一个功能强大而易用的库，适用于初学者和专业数据科学家，能够帮助用户更轻松地创建具有吸引力的统计图表。如果已经熟悉 Matplotlib，Seaborn 是一个很好的补充，可以让更高效地进行数据可视化。 实例接下来吗使用 Python 进行一个简单的量化实例，可以结合 yfinance 获取贵州茅台（600519.SS）的股票数据，然后使用 seaborn 进行数据可视化。 以下是一个简单的例子，演示如何下载茅台股票数据，并使用 seaborn 绘制股票的收盘价走势图： 实例import yfinance as yfimport seaborn as snsimport matplotlib.pyplot as plt # 获取贵州茅台的股票数据maotai_data = yf.download(“600519.SS”, start=“2020-01-01”, end=“2023-01-01”) # 选取收盘价数据closing_prices = maotai_data[‘Close’] # 使用 seaborn 绘制走势图plt.figure(figsize=(12, 6))sns.lineplot(x=closing_prices.index, y=closing_prices.values, label=‘Maotai Closing Prices’)plt.title(‘Maotai Stock Closing Prices Over Time’)plt.xlabel(‘Date’)plt.ylabel(‘Closing Price (CNY)’)plt.legend()plt.show() 执行以上代码，输出结果为：","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Python 获取金融数据  菜鸟教程","path":"/2024/12/24/5-生活-金融-Python-获取金融数据-菜鸟教程/","content":"在 Python 中，要进行量化分析，需要先获取金融数据，Python 中有多个库可以用于获取金融市场数据。 本站实例演示用到的库为 yfinance。 安装如下： pip install yfinance yfinance 库使用 yf.download() 函数下载金融数据的函数。 以下是它的基本语法格式： yf.download(tickers, start=None, end=None, actions=False, threads=True) 参数说明： tickers: 说明： 要下载数据的股票、指数、基金等金融工具的代码。 类型： 字符串（单个代码）或列表（多个代码）。 示例： “AAPL”、[“AAPL”, “GOOGL”]。 start: 说明： 下载数据的开始日期。 类型： 字符串（日期格式：”YYYY-MM-DD”）。 默认值： None，表示从可获取的最早日期开始。 示例： “2020-01-01”。 end: 说明： 下载数据的结束日期。 类型： 字符串（日期格式：”YYYY-MM-DD”）。 默认值： None，表示到可获取的最新日期结束。 示例： “2022-01-01”。 actions: 说明： 是否包括股票分红、拆股等信息。 类型： 布尔值。 默认值： False。 示例： actions=True。 threads: 说明： 是否使用多线程下载数据。 类型： 布尔值。 默认值： True。 示例： threads=False。 在 yfinance 中，中国 A 股的股票代码需要加上交易所的后缀，上海证券交易所（SSE）的后缀是 .SS，深圳证券交易所（SZSE）的后缀是 .SZ。 以下是一个使用 yfinance 获取贵州茅台（600519.SS）股票数据的简单实例： 实例import yfinance as yf# 上海证券交易所，茅台公司股票代码 symbol = 600519.SS# 或者，深圳证券交易所，泸州老窖公司股票代码 # luzhou_laojiao_szse = yf.Ticker(000568.SZ)# 获取茅台公司股票数据 maotai_data = yf.download(symbol, start=2022-01-01, end=2023-11-01)# 打印数据的前几行 print(maotai_data.head()) 以上代码们使用 yfinance 的 download 函数获取了贵州茅台（600519.SS）的股票数据，时间范围是从 2022 年 1 月 1 日到 2023 年 11 月 1 日。返回的数据是一个包含日期(Date)、开盘价(Open)、最高价(High)、最低价(Low)、收盘价(Close)、成交量(Volume)和调整后的收盘价(Adj Close)等信息的 Pandas DataFrame。 Pandas DataFrame 内容可以参考：Pandas 数据结构 - DataFrame 执行以上代码，输出结果如下： # python3 mt.py[*********************100%%**********************] 1 of 1 completed Open High Low Close Adj Close VolumeDate 2022-01-04 2055.00000 2068.949951 2014.000000 2051.229980 1973.508057 33842622022-01-05 2045.00000 2065.000000 2018.000000 2024.000000 1947.309937 28395512022-01-06 2022.01001 2036.000000 1938.510010 1982.219971 1907.112793 51794752022-01-07 1975.00000 1988.880005 1939.319946 1942.000000 1868.416870 29816692022-01-10 1928.01001 1977.000000 1917.550049 1966.000000 1891.507568 2962670 Ticker 类yfinance Ticker 类 用于获取特定金融工具的信息和实时数据。 Ticker 类构造函数： 用法：yf.Ticker(AAPL) 描述：创建一个 Ticker 对象，代表特定股票或金融资产。在括号内传入股票代码（例如：’AAPL’）。 history 方法： 用法：ticker.history(period=1d, interval=1m) 描述：获取历史价格数据。period 参数指定时间跨度，可以是 1d（一天）、1mo（一个月）、1y（一年）等；interval 参数指定时间间隔，可以是 1m（一分钟）、1d（一天）、1wk（一周）等。 info 属性： 用法：ticker.info 描述：获取有关股票的基本信息，如公司名称、行业、市值等。 dividends 属性： 用法：ticker.dividends 描述：获取分红数据，返回一个包含日期和分红金额的 DataFrame。 splits 属性： 用法：ticker.splits 描述：获取拆股数据，返回一个包含日期和拆股比例的 DataFrame。 recommendations 属性： 用法：ticker.recommendations 描述：获取股票的推荐信息，返回一个包含日期和推荐信息的 DataFrame。 major_holders 属性： 用法：ticker.major_holders 描述：获取股票的主要持有者信息，返回一个包含主要股东和其持股比例的 DataFrame。 sustainability 属性： 用法：ticker.sustainability 描述：获取股票的可持续性信息，返回一个包含环境、社会和治理（ESG）指标的 DataFrame。 actions 属性： 用法：ticker.actions 描述：获取股票的行动数据，包括拆股、分红等。 calendar 属性： 用法：ticker.calendar 描述：获取公司的财务日历信息，如报告季度财报的日期等。 以下代码使用了 yfinance 库中的 Ticker 类来获取 Microsoft 公司（股票代码：MSFT）的股票信息，包括基本信息、历史市场数据、股利、拆股、财务报表等： 实例import yfinance as yf# 创建 Ticker 对象，表示对 Microsoft 公司的股票数据进行操作 msft = yf.Ticker(MSFT)# 获取所有的股票信息 msft.info# 获取历史市场数据，这里是过去一个月的数据 hist = msft.history(period=1mo)# 显示历史数据的元信息（需要先调用 history() 函数） msft.history_metadata# 显示公司行为信息（股利、拆股、资本收益） msft.actions msft.dividends msft.splits msft.capital_gains # 仅适用于共同基金和交易所交易基金（etfs）# 显示股票股数 msft.get_shares_full(start=2022-01-01, end=None)# 显示财务报表： # - 收入表 msft.income_stmt msft.quarterly_income_stmt # - 资产负债表 msft.balance_sheet msft.quarterly_balance_sheet # - 现金流量表 msft.cashflow msft.quarterly_cashflow # 若要查看更多选项，请参考 `Ticker.get_income_stmt()`# 显示股东信息 msft.major_holders msft.institutional_holders msft.mutualfund_holders# 显示未来和历史的盈利日期，返回最多未来 4 个季度和过去 8 个季度的数据，默认情况下。 # 注意：如果需要更多信息，可以使用 msft.get_earnings_dates(limit=XX)，其中 XX 为增加的限制参数。 msft.earnings_dates# 显示国际证券识别码（ISIN） - * 实验性功能* # ISIN = International Securities Identification Number msft.isin# 显示期权到期日期 msft.options# 显示新闻 msft.news# 获取特定到期日的期权链 opt = msft.option_chain(YYYY-MM-DD) # 数据可通过 opt.calls, opt.puts 获取 获取多个股票数据以下代码使用 yfinance 库初始化了一个包含多个股票代码的 Tickers 对象，并通过该对象访问了不同股票的信息、历史数据和行为： 实例import yfinance as yf# 初始化包含多个股票代码的 Tickers 对象 tickers = yf.Tickers(msft aapl goog)# 使用示例，访问每个股票的信息 tickers.tickers[MSFT].info # 获取 Microsoft 公司（MSFT）的基本信息 tickers.tickers[AAPL].history(period=1mo) # 获取 Apple 公司（AAPL）过去一个月的历史数据 tickers.tickers[GOOG].actions # 获取 Google 公司（GOOG）的行为信息（股利、拆股等） 下载历史数据以下代码使用 yfinance 库下载了标普 500 ETF（SPY）和苹果公司（AAPL）过去一个月的历史市场数据： 实例import yfinance as yf# 使用 yfinance 下载标普 500 ETF（SPY）和苹果公司（AAPL）的历史市场数据 data = yf.download(SPY AAPL, period=1mo) period=1mo 参数表示下载的时间范围是过去一个月。 更多金融库以下是一些主要用于获取金融数据的库： yfinance 官方网站： yfinance 简介： yfinance 是一个用于获取 Yahoo Finance 数据的库。它提供简单的 API，允许用户获取股票、指数等金融数据。 安装： pip install yfinance Tushare 官方网站： Tushare 简介： Tushare 是一个开放的金融数据平台，提供了丰富的股票、期货、基金等金融市场数据的接口。它支持 Python，提供了易于使用的 API。 安装： pip install tushare pandas-datareader 官方网站： pandas-datareader 简介： pandas-datareader 是一个从多个在线数据源（如 Yahoo Finance、Google Finance 等）获取金融数据的库。 安装： pip install pandas-datareader 官方网站： baostock baostock 官方网站： baostock 简介： baostock 是一个免费提供 A 股、港股、期权等金融数据的库。它提供了 Python 接口，方便用户获取数据。 安装： pip install baostock alpha_vantage 官方网站： alpha_vantage 简介： alpha_vantage 提供了一个简单的 API，可以用来获取股票、外汇等金融数据。它还支持一些技术指标的计算。 安装： pip install alpha_vantage quandl 官方网站： Quandl 简介： Quandl 提供了来自各种来源的金融和经济数据。它提供了 Python 库，方便用户获取数据。 安装： pip install quandl ccxt 官方网站： ccxt 简介： ccxt 是一个用于交易和获取金融数据的开源库，支持多个交易所的数据获取。 安装： pip install ccxt AKShare 官方网站： AKShare 简介： AKShare 是基于 Python 的财经数据接口库，目的是实现对股票、期货、期权、基金、外汇、债券、指数、加密货币等金融产品的基本面数据、实时和历史行情数据、衍生数据从数据采集、数据清洗到数据落地的一套工具，主要用于学术研究目的。 安装： pip install akshare","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Anaconda 教程 | 菜鸟教程","path":"/2024/12/24/5-生活-金融-Anaconda-教程-菜鸟教程/","content":"Python 量化可以直接使用 Anaconda 工具来提高效率，免去一些安装的烦恼。 Anaconda 是一个数据科学和机器学习的软件套装，它包含了许多工具和库，让能够更轻松地进行编程、分析数据和构建机器学习模型。 Anaconda 包及其依赖项和环境的管理工具为 conda 命令，文章后面部分会详细介绍。 与传统的 Python pip 工具相比 Anaconda 的conda 可以更方便地在不同环境之间进行切换，环境管理较为简单。 为什么选择 Anaconda？ 方便安装： 安装 Anacond a就像安装一个应用程序一样简单，它为预先安装好了许多常用的工具，无需单独配置。 包管理器： Anaconda 包含一个名为 Conda 的包管理器，用于安装、更新和管理软件包。Conda 不仅限于 Python，还支持多种其他语言的包管理。 环境管理： 使用 Anaconda，可以轻松地创建和管理多个独立的 Python 环境，比如可以安装 python2 和 python3 环境，然后实现自由切换。这对于在不同项目中使用不同的库和工具版本非常有用，以避免版本冲突。 集成工具和库： Anaconda 捆绑了许多用于数据科学、机器学习和科学计算的重要工具和库，如 NumPy、Pandas、Matplotlib、SciPy、Scikit-learn 等。 Jupyter 笔记本： Jupyter 是一个交互式的计算环境，支持多种编程语言，但在 Anaconda 中主要用于 Python。它允许用户创建和共享包含实时代码、方程式、可视化和叙述文本的文档。 Spyder 集成开发环境： Anaconda 中集成了 Spyder，这是一个专为科学计算和数据分析而设计的开发环境，具有代码编辑、调试和数据可视化等功能。 跨平台性： Anaconda 可在 Windows、macOS 和 Linux 等操作系统上运行，使其成为一个跨平台的解决方案。 社区支持： Anaconda 拥有庞大的社区，用户可以在社区论坛上获取帮助、分享经验和解决问题。 Anaconda 安装Anaconda 安装包下载地址：https://www.anaconda.com/download。 Anaconda 可在 Windows、macOS 和 Linux 等操作系统上运行，可以根据不同平台下载安装包： macOS 平台安装过程也很简单，双击打开下载的安装包，选择 Install for me only: 点击 install 按钮： 安装完成后，点击 Continue 按钮，接下来就可以看到安装完成的界面： macOS 平台安装可以参考官网：https://docs.anaconda.com/free/anaconda/install/mac-os/ Win 平台Win 平台与 macOS 类似，在下载安装包后，双击安装包，同意一些协议，简单的就可以按默认设置一步步按 Next 按钮就可以。 选择安装目录： 在 “Advanced Installation Options” 中不要勾选 “Add Anaconda to my PATH environment variable.”（”添加Anaconda至的环境变量。”），因为如果勾选，则将会影响其他程序的使用。 点击 Install 按钮进行安装，安装成功出现如下界面： 点击 Next 按钮： Win 平台安装可以参考官网：https://docs.anaconda.com/free/anaconda/install/windows/ Linux 平台Linux 平台可以通过以下命令安装，可以替换安装的版本号： curl -O https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh Linux 不同平台安装可以参考官网：https://docs.anaconda.com/free/anaconda/install/linux/ Anaconda 界面使用安装完后们就可以进入 Anaconda 管理界面查看并安装不同的环境： 点击 Evironments 就可以查看已经安装的环境： 底部还有创建与删除环境的按钮，们可以自由操作： conda 命令除了界面操作，们还可以在命令行使用 conda 来管理不同环境。 conda 是 Anaconda 发行版中的包管理器，用于安装、更新、卸载软件包，以及创建和管理不同的 Python 环境。 以下是一些常用的Conda命令及其简要介绍： 环境管理创建一个名为 “myenv” 的新环境: conda create --name myenv 创建指定版本的环境： conda create --name myenv python=3.8 以上代码创建一个名为 “myenv” 的新环境，并指定 Python 版本为 3.8。 激活环境： conda activate myenv 以上代码激活名为 “myenv” 的环境。 要退出当前环境使用以下命令： deactivate 查看所有环境： conda env list 以上代码查看所有已创建的环境。 复制环境： conda create --name myclone --clone myenv 以上代码通过克隆已有环境创建新环境。 删除环境： conda env remove --name myenv 以上代码删除名为 “myenv” 的环境。 包管理安装包： conda install package_name 以上代码安装名为 “package_name” 的软件包。 安装指定版本的包： conda install package_name=1.2.3 以上代码安装 “package_name” 的指定版本。 更新包： conda update package_name 以上代码更新已安装的软件包。 卸载包： conda remove package_name 以上代码卸载已安装的软件包。 查看已安装的包： conda list 查看当前环境下已安装的所有软件包及其版本。 其他常用命令查看帮助： conda --help 以上代码获取 conda 命令的帮助信息。 查看 conda 版本： conda --version 以上代码查看安装的 conda 版本。 搜索包： conda search package_name 以上代码在 conda 仓库中搜索指定的软件包。 清理不再需要的包： conda clean --all 以上代码清理 conda 缓存，删除不再需要的软件包。 Jupyter Notebook（可选）安装 Jupyter Notebook： conda install jupyter 以上代码安装 Jupyter Notebook。 启动 Jupyter Notebook： jupyter notebook 以上代码在已激活的环境中启动 Jupyter Notebook。","tags":["clippings"],"categories":["5.生活","金融"]},{"title":"Docker的GUI显示","path":"/2024/12/23/1-平台-Docker-Docker的GUI显示/","content":"Docker 容器图形界面显示的配置方法Docker 主要基于命令行操作，常用于服务器后端管理，因此它在传统应用场景中对图形用户界面（GUI）软件的需求较少。然而，特定情况，例如在 Docker 容器内运行 GUI 软件或操作摄像头输出图像时，处理 Docker 的“可视化”问题就显得尤为重要。此处所述的“可视化”并非通常所见的网络可视化管理工具。 方式一：启动容器时添加配置选项可以比喻 Docker 镜像为一台未连接显示器的计算机，尽管程序可以正常运行，缺乏显示终端使得输出结果无处展示。目前，主流的 Linux 图形界面服务 X11 采用客户端服务器（ClientServer）模式。在容器启动时共享 Unix 端口或设置主机名和端口，使得 Docker 可获取显示输出位置，从而实现与 Linux 系统共享显示资源。 在主系统中先安装必需的工具，通过以下命令完成： sudo apt-get install x11-xserver-utils 开放权限，使所有用户（包括 Docker）能够访问 X11 显示接口。如果权限设定失败，可以考虑如下设置，将环境变量 DISPLAY 设置为默认显示： xhost +或xhost +SI:localuser:$(id -un) #允许本地用户访问显示 $(id -un) 将返回当前用户的用户名 启动 Docker 容器时，需添加以下选项： -v /tmp/.X11-unix:/tmp/.X11-unix \\ # 共享本地的 Unix 端口-e DISPLAY=unix$DISPLAY \\ # 设置环境变量 DISPLAY-e GDK_SCALE \\ # 设置 GDK 的缩放因子-e GDK_DPI_SCALE \\ # 设置 DPI 的缩放因子 通过此步骤启动的容器可以如本地应用程序般自由显示图形界面。需注意，每次系统重启后，需在主机上再次执行 xhost + 来重新打开权限。 $ docker run -d \\ -v /etc/localtime:/etc/localtime:ro \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e DISPLAY=unix$DISPLAY \\ -e GDK_SCALE \\ -e GDK_DPI_SCALE \\ --name libreoffice \\ jess/libreoffice docker run -it -e XDG_RUNTIME_DIR=/home/wangjl \\ -e WAYLAND_DISPLAY=$WAYLAND_DISPLAY \\ -v $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/home/wangjl/$WAYLAND_DISPLAY \\ --user=`id -u`:`id -g` \\ -e QT_QPA_PLATFORM=wayland \\ -v /home/wangjl/:/home/wangjl \\ -e DISPLAY=:0 \\ --name gui -v /tmp/.X11-unix/:/tmp/.X11-unix/ \\ -e LANG=zh_CN.UTF-8 \\ --network host \\ ubuntu:20.04.gui /bin/bash -e XDG_RUNTIME_DIR=/home/wangjl: 设置 XDG 运行时目录，用于存放临时文件和 Unix Socket。 -e WAYLAND_DISPLAY=$WAYLAND_DISPLAY: 将 Wayland 显示环境变量传递给容器，以便应用程序可使用 Wayland。 -v $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/home/wangjl/$WAYLAND_DISPLAY: 将运行时的 Wayland Socket 挂载到容器指定路径，支持图形界面。 --user：使用当前用户的 UID 和 GID，确保文件权限一致。 -e QT_QPA_PLATFORM=wayland: 为 Qt 应用程序配置 Wayland 平台，确保在 Wayland 环境中渲染。 -v /home/wangjl/:/home/wangjl: 将主机用户目录挂载到容器，以便访问主机文件。 -e DISPLAY=:0: 设置 X 显示环境变量为 0，指向 X11 图形会话。 -v /tmp/.X11-unix/:/tmp/.X11-unix/: 将主机的 X11 Unix Socket 目录挂载到容器，支持 X11 应用程序。 -e LANG=zh_CN.UTF-8: 将容器的语言设置为中文，确保中文字符的正常显示。 --network host: 使用主机网络，令容器能直接访问主机网络资源。 环境变量 XDG_RUNTIME_DIR 和 WAYLAND_DISPLAY 是 Wayland 运行所必需的，它们共同指向 Wayland 的 Unix Socket 路径。同时，将 QT_QPA_PLATFORM 设置为 wayland 借以确保 Qt 应用程序的兼容性。DISPLAY=:0 和 /tmp/.X11-unix/ 则指向 X11 Socket 路径，以便运行依赖 X11 的图形应用。 方式二：已启动容器修改系统参数若在已运行容器中需显示图像，则可应用上述方法，而无需重启容器。这一操作思路依旧以主机与 Docker 为客户端服务器关系，通过 IP 地址进行映射。 使用 ifconfig 命令检查主机和容器的 IP 地址示例： 主机 IP：xxx Docker IP：YYY 在 Docker 容器内部，执行以下命令将环境变量映射至主机 IP： export DISPLAY=XXX 在主机中修改 LightDM 配置，以允许 TCP 连接： sudo gedit /etc/lightdm/lightdm.conf # 增加一行 xserver-allow-tcp=truesudo systemctl restart lightdmxhost + # 注意加号前的空格 通过以上配置，每次重启后仍需在主机执行 xhost +，并在 Docker 内执行 export DISPLAY=XXX。该方法依赖 IP 地址，若系统未联网，可能会导致无法获取有效 IP。 方式三：VNC 在主系统中执行以下命令安装必要工具，包括 X11 服务器的相关实用程序，通常用于管理 GUI： sudo apt-get install x11-xserver-utils 开放权限，以使所有用户（包括 Docker）能够使用 X11 显示接口，并确保 VNC 的正常运行。如果权限设定失败，可将显示环境变量设置为默认值： export DISPLAY=:0.0 然后给予访问权限： xhost + 安装 VNC 服务器，以支持远程桌面管理： sudo apt install tigervnc-standalone-server 创建配置文件存储 VNC 启动参数： touch $HOME/.vnc/xstartup 编辑该配置文件以添加必要的启动代码。打开配置文件并使用 VIM 编辑： vim $HOME/.vnc/xstartup 添加以下内容： #!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESS/etc/X11/xinit/xinitrc# 假设系统中预装了 Gnome 或 KDE，启动默认桌面环境# 用户注销时自动终止会话if [ -e /usr/bin/gnome-session -o -e /usr/bin/startkde ]; then vncserver -kill $DISPLAYfi 为新创建的启动文件添加执行权限，以确保正确执行： chmod u+x $HOME/.vnc/xstartup 启动 VNC 服务器，设定显示屏号和分辨率，参数中可定义所需显示的分辨率与颜色深度。例如，通常可设置为 1920x1000 分辨率、24 位颜色深度，并允许外部访问： vncserver :1 -geometry 1920x1000 -depth 24 -localhost no 启动 Docker 容器并将其连接至 VNC 服务器，实现远程操作。以下命令启动指定 Docker 容器，确保配置了准确的环境变量和文件挂载： docker run -dit -P \\ -e DISPLAY=$DISPLAY \\ --privileged \\ --network=host \\ -v /tmp/.X11-unix:/tmp/.X11-unix:rw \\ -v /dev/bus/usb:/dev/bus/usb \\ -v /home/lfxs/StudioData:/StudioData \\ --name qoriq/arm64-ubuntu mydb:0.1 /bin/bash 解析 Docker 启动参数： -d: 将容器设置为后台运行，并返回容器 ID。 -i: 表示容器以交互模式运行，通常结合 -t 使用，以启用伪终端。 -P: 随机端口映射，将容器内部端口随机映射到宿主机端口。 -p: 自定义端口映射，格式为：主机端口:容器端口。 -e: 设置环境变量，以决定容器的操作环境。 --privileged: 使容器获得 root 权限，允许更广泛的操作。 --network: 指定容器网络连接类型，支持 bridge、host、none 和 container 等类型。 -v: 绑定卷，以实现宿主机与容器之间的文件共享。 --name: 定义容器名称，便于后续管理。 测试图像界面显示在 Docker 中执行以下命令以安装并测试： sudo apt-get install xarclock # 安装 xarclock 小程序xarclock # 运行测试 启动指定 GUI 应用程序容器启动完成后，可以通过以下命令在容器内运行图形界面程序： docker exec -it gui calibredocker exec -it gui /opt/deepinwine/apps/Deepin-WeChat/run.sh docker exec 命令允许在已经运行的容器内执行命令，其中 gui 为容器名称。通过此命令可启动图形程序，该程序表现如同本地应用。","categories":["1.平台","Docker"]},{"title":"Docker部署","path":"/2024/12/20/1-平台-Docker-Docker部署/","content":"环境在安装 docker 时，发现 docker 有多个版本： docker.io：debianubuntu 官方基于 docker 社区源码封装的版本，将 docker 的依赖直接转接到主系统上。docker.io 采用 apt 的方式管理依赖 。 docker-ce：docker.com 放出来的社区版，使用 golang 将依赖封装在一个包中。用 go 的方式管理依赖，会自己管理所有的依赖。 docker-ee：docker.com 维护的商业版 安装 Docker 及 Docker-composeDocker Compose 是一个工具，可以使用它轻松定义和启动 Docker 中的多容器应用程序。 使用 Compose，可以在单个 YAML 文件中定义所有服务，并且使用单个命令，可以启动或拆除所有服务。 在本教程中，们将使用 Docker Compose 在隔离的容器化环境中并排运行两个容器（WordPress 和 MySQL）。 安装 docker，如果之前已经安装过旧版本的 docker，在安装的时候需要卸载旧版本 apt install docker.ioapt install docker-compose 确认版本 docker versiondocker-compose version 启动 docker sudo service docker start Docker – 守护式容器什么是守护式容器守护式容器是一种特殊类型的容器，具备以下特征： 能够长期运行：与交互式容器不同，守护式容器设计为在后台持续运行，而不需要用户进行交互。此特性使得守护式容器适合承载长期执行的应用程序和服务。 没有交互式会话：守护式容器一旦启动，便无需任何直接的命令输入或输出。适用于需要定时任务、服务器、微服务等场景。 以守护形式运行容器使用以下命令以交互模式启动容器，然后可以通过快捷键退出： docker run -i -t IMAGE /bin/bash Ctrl + P + Ctrl + Q：使用 Ctrl + P 紧接着按 Ctrl + Q 的组合键可以安全退出交互式容器的 bash 而不停止容器。此操作将容器放置于后台运行。 要以守护形式运行容器，可以使用以下命令： docker run -d 镜像名 [COMMAND] [ARG...] -d：指示该容器在后台运行。一旦执行的命令完成，容器依然可能会停止，如果需要持续运行，就要选用可以长时间执行的命令。 附加到运行中的容器在需要对正在运行的容器进行进一步操作时，可以使用以下命令： docker attach 容器名 通过此命令，可将当前终端附加至指定容器，从而直接与之交互。 启动守护式容器可通过如下命令启动守护式容器： docker run -d 镜像名 [COMMAND] [ARG...] 将命令以后台形式运行，同样遵循容器运行结束后将停止的情况。 查看容器日志要查看某个容器的运行日志，可以使用以下命令： docker logs [-f] [-t] [--tail] 容器名 以下是各参数的具体含义： -f：表示实时跟踪(container logs)，持续输出日志的更新。默认设置为 false，如需实时更新，可设为 true。 -t：在日志信息前加上时间戳，方便追踪事件的发生时间，默认为关闭状态。 –tail：指定返回日志的最后部分，比如 --tail=100 将只返回最后 100 条日志。如果不指定，则返回所有日志。 查看容器内运行中的进程查看正在运行的容器内的进程，可以使用命令： docker top 容器名 此命令会显示容器中活跃的进程列表，便于用户理解当前容器状态。 在运行中的容器内启动新进程要在已运行的容器中执行新命令，可以使用： docker exec [-d] [-i] [-t] 容器名 [COMMAND] [ARG...] 使用 exec 功能，可以在现有容器内启动新进程，增强容器的灵活性。 如何停止守护式容器停止守护式容器可通过以下两种命令实现： docker stop 容器名 停止命令会向该容器发送信号，要求其优雅地停止运行，通常会有几秒钟的等待. docker kill 容器名 kill 命令则直接强制停止容器，适用于快节奏的开发场景，但不太适合生产环境。 Docker 设置国内镜像源（docker pull 超时）修改 Docker 的配置文件要修改 Docker 的软件源，需要调整 Docker 的配置文件。如果该文件不存在，可以创建一个新的配置文件。修改镜像仓库地址： sudo vim /etc/docker/daemon.json 以下是配置文件的基本内容示例： registry-mirrors: [ https://YOUR_ID.mirror.aliyuncs.com,//需注册 https://mirror.ccs.tencentyun.com,//需注册 https://docker.mirrors.ustc.edu.cn\thttps://do.nark.eu.org,\thttps://dc.j8.work,\thttps://docker.m.daocloud.io,\thttps://dockerproxy.com,\thttps://docker.nju.edu.cn,\thttps://registry.docker-cn.com ] 在将 YOUR_ID.mirror.aliyuncs.com 替换为实际的阿里云加速器地址之后，保存并关闭文件。 重启 Docker 服务完成配置修改后，需要重启 Docker 服务，以应用新的设置。可以通过以下命令重启 Docker： sudo systemctl daemon-reloadsudo systemctl restart docker 执行完这些命令后，Docker 将使用新的镜像源。 验证配置是否生效可以通过运行以下命令查看 Docker 的信息，以确认软件源是否设置成功： docker info 在输出信息中，可以找到 “Registry” 部分，检查是否包含了刚才设置的镜像源。如果显示了新的镜像地址，说明设置已经成功。 Docker 网络模式Docker 通过使用 Linux 桥接实现容器之间的相互通信。Docker 提供了四种网络模式： host 模式，使用 --net=host 指定。 container 模式，使用 --net=container:NAMEorID 指定。 none 模式，使用 --net=none 指定。 bridge 模式，使用 --net=bridge 指定，这也是 Docker 的默认配置。 host 模式在 host 模式下，容器不会获取独立的网络命名空间，而是与宿主机共享网络命名空间。这意味着容器将直接使用宿主机的 IP 地址和端口，而不需要为容器创建虚拟网卡或配置 IP 地址。实际上，容器的网络功能表现得如同直接在宿主机上运行的程序一样。然而，容器的文件系统和进程列表仍然与宿主机是隔离的。 例如，如果宿主机的 IP 地址是 192.168.0.10，则在 host 模式下运行的容器也会使用该 IP，而不需要额外的配置。这种模式适合需要高性能网络通讯的场景，比如运行数据库或者高吞吐量的服务。 container 模式container 模式允许新创建的容器与已存在的一个容器共享同一个网络命名空间。这并不意味着新容器会和宿主机共享网络，而是与指定的容器共享 IP 地址和端口范围。新容器在创建时不会分配独立的网卡或 IP，而是直接使用共享容器的网络配置。 举个例子，假设有一个已有的名为 my-container 的容器，如果想要创建一个新的容器并让它与 my-container 共享网络，可以使用以下命令： docker run -d --net=container:my-container nginx 这样，新容器将能够使用 my-container 的 IP 地址和端口，适用于需要相互通信的容器场景。 none 模式在 none 模式下，Docker 容器会拥有自己的网络命名空间，然而它不会被分配任何网络配置。换句话说，这种模式下容器没有任何网络连接，需要手动为容器添加网卡并配置 IP 地址。它适合于需要完全自定义网络配置的场景。 例如，可以通过此模式运行一个容器而不希望它与任何其他网络服务进行连接，进行隔离测试时会用到这种模式。命令形式如下： docker run -d --net=none nginx bridge 模式bridge 模式是 Docker 的默认网络设置，它会为每个容器分配独立的网络命名空间，并将容器连接到一个虚拟网桥上。每当新的容器被创建，Docker 会在宿主机上创建一个桥接网络，容器通过桥接网络与宿主机及其他容器进行通信。 这种模式的常见用法是利用默认的桥接网络创建互联的多容器应用。在这种情况下，每个容器都是设备自己的网络堆栈，具有独立的 IP 地址。例如，当您在 bridge 模式下启动一个 Nginx 容器时，那么它将有自己的 IP 地址，从而与宿主机的 IP 地址相互区别。 运行容器示例运行容器的基本命令如下： [root@centos7 ~]# docker run -d -P nginx 此命令将启动一个 Nginx 容器，将其启动为后台进程。命令执行后，会得到一个容器 ID： 6135db66a7d7c1237901a79974f88f1079b3d467c14ce83fc46bc6b4eb8b3240 可以通过查看正在运行的容器来确认容器的状态： [root@centos7 ~]# docker ps 输出可能如下： CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES6135db66a7d7 nginx nginx -g daemon off 33 seconds ago Up 31 seconds 0.0.0.0:32769-80/tcp, 0.0.0.0:32768-443/tcp gigantic_meitner 如上所示，Nginx 容器的端口 80 和 443 被随机映射到宿主机的 32769 和 32768。 参数说明 -P：随机端口映射为容器端口，适合想快速测试服务的情景。 -p：指定端口映射，允许用户自定义主机端口。 例如，以下命令将 Nginx 启动于宿主机 81 端口： [root@centos7 ~]# docker run -d -p 81:80 nginx 运行后，输出的容器 ID 将类似于： 3ca9f847bebec3684952b0f2c081d31f84b9489de50b635246d9a592cc06d46c 再次运行 docker ps 命令可以查看： CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3ca9f847bebe nginx nginx -g daemon off 8 seconds ago Up 6 seconds 443/tcp, 0.0.0.0:81-80/tcp goofy_mcnulty 可以通过宿主机的 http://localhost:81 地址来访问 Nginx 服务。 Docker 数据存储管理数据的方式Docker 提供两种管理数据的方式：数据卷 和 数据卷容器。 数据卷数据卷是一个或多个容器专门指定的目录，这些目录绕过了 Union File System，为持续性或共享数据提供了诸多功能： 数据共享与重用：数据卷可以在多个容器之间共享。例如，可以使用同一个数据卷在生产环境和测试环境中反复使用相同的数据库内容。 直接数据修改：对数据卷中的数据进行更改时，会直接在数据卷中反映，而无需将数据从容器中导出再导入。这种操作的高效性非常适合数据库等高频次访问的应用场景。如果一个容器正在运行并修改了卷中数据，其他容器可以立即看到这些修改。 数据独立性：数据卷中的数据并不被包含在容器的生命周期中。因此，即使容器被删除，数据卷中的数据依然存在，直到所有引用该数据卷的容器都被删除为止。 参数说明 -v /data：直接将宿主机的 /data 目录挂载到容器的 /data 目录。 -v src:dst：将宿主机上的一个物理目录挂载到容器的目录，其中 src 是宿主机上的目录，dst 是容器内的目录。 实例操作启动一个新的 CentOS 容器，并挂载宿主机上的 /data 目录： [root@centos7 ~]# docker run -it --name test-001 -v /data centos 进入容器后，查看 /data 目录： [root@4578675314b9 /]# ls -l /data/total 0 查看运行中的容器： [root@centos7 ~]# docker ps 运行结果如下： CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4578675314b9 centos /bin/bash 2 minutes ago Up 2 minutes test-001 使用 docker inspect 命令查看容器的详细信息： [root@centos7 ~]# docker inspect 4578675314b9 输出中的 Mounts 字段显示了已挂载的数据卷信息： Mounts: [ Name: ab2f85f900a68813c4fdbf3b0fe88242247e7e8320bb75035b1367ab82804115, Source: /var/lib/docker/volumes/ab2f85f900a68813c4fdbf3b0fe88242247e7e8320bb75035b1367ab82804115/_data, Destination: /data, Driver: local, Mode: , RW: true, Propagation: ] 这表示容器的存储目录已挂载到宿主机的 /data。 在宿主机上进入数据卷的物理路径： [root@centos7 ~]# cd /var/lib/docker/volumes/ab2f85f900a68813c4fdbf3b0fe88242247e7e8320bb75035b1367ab82804115/_data[root@centos7 _data]# lltotal 0 创建一个目录： [root@centos7 _data]# mkdir test 在容器内检查刚刚创建的目录： [root@4578675314b9 /]# cd /data/[root@4578675314b9 data]# lltotal 0drwxr-xr-x 2 root root 6 Apr 10 08:54 test 可以看到容器的数据目录中也存在刚刚在宿主机上创建的 test 目录。 此外，还可以用以下命令挂载数据： docker run -it -v /data1:/mnt centos 此命令中，前者是宿主机的目录，后者是容器内的目录。挂载成功后，宿主机上的 /data1 目录会自动创建。 [root@centos7 ~]# docker run -it -v /data1:/mnt centos[root@425569ce9eef /]# cd /mnt/[root@425569ce9eef mnt]# lltotal 0 在宿主机上向 /data1 写入文件： [root@centos7 ~]# cd /data1/[root@centos7 data1]# echo hellotest.txt 检查宿主机上的文件内容： [root@centos7 data1]# cat test.txthello 在容器内检查 /mnt 目录： [root@425569ce9eef mnt]# lltotal 4-rw-r--r-- 1 root root 6 Apr 10 09:09 test.txt[root@425569ce9eef mnt]# cat test.txt hello 获取当前工作目录和容器主机名： [root@425569ce9eef mnt]# pwd/mnt[root@425569ce9eef mnt]# hostname425569ce9eef 这种方法非常适合代码开发管理，开发者可以将代码目录直接挂载到容器中，方便实时修改 WEB 站点目录。 指定挂载权限 docker run -it -v /data2:/opt:ro centos 此命令将 /data2 以只读权限挂载到 /opt 中。 docker run -it -v /data2:/opt:rw centos 此命令将 /data2 以读写权限挂载到 /opt 中。 挂载单个文件 docker run -it -v /root/file1:file1 centos 这种方法用于将单个文件挂载到容器目录中。 容器卷的方式使用 --volumes-from 选项可以共享其他容器的目录： [root@centos7 ~]# docker run -d --name mydocker -v /data centos 接下来，启动一个新的容器并共享 mydocker 的数据卷： [root@centos7 ~]# docker run -it --name mynfs --volumes-from mydocker centos 进入到 mynfs 容器内，查看 /data 目录： [root@82a489adb07a /]# ll /data/total 0 然后进入 mydocker 容器，写入测试数据： [root@centos7~]# cd /var/lib/docker/volumes/8421a48b58337a30ac4750c06748e01a3f328bdc2fa3b945d7f9737d9bc1b002/_data[root@centos7 _data]# echo welcome to herefile 确认写入的数据： [root@centos7 _data]# lltotal 4-rw-r--r-- 1 root root 16 Apr 10 17:34 file 最后检查 mynfs 容器的数据目录： [root@82a489adb07a /]# cd /data/[root@82a489adb07a data]# lltotal 4-rw-r--r-- 1 root root 16 Apr 10 09:34 file[root@82a489adb07a data]# cat file welcome to here","categories":["1.平台","Docker"]},{"title":"etc目录","path":"/2024/12/18/1-平台-Linux-文件系统-etc目录/","content":"etc 目录在 Linux 中的角色/etc 目录被广泛认为是 Linux 系统中的配置文件之家。这个目录包含了大量用于系统管理的配置文件，系统管理员和用户需要在这里进行修改，以便优化系统性能和安全性。以下是一些关键的网络配置文件及其作用。 网络配置文件1 etchosts/etc/hosts 文件格式: IPaddress hostname aliases。它的主要功能是提供主机名与 IP 地址之间的映射关系，确保在没有 DNS 的情况下，仍然可以通过主机名访问特定的主机。将常用的主机添加到此文件中可以有效地提高网络应用的便捷性。例如： 127.0.0.1 localhost localhost.localdomain202.118.66.81 helius.dlut.edu.cn helius 在这个示例中，127.0.0.1 指向本地计算机，而 202.118.66.81 则指向特定的远程主机 helius.dlut.edu.cn。 2 etcresolv.conf这个文件的功能是配置 DNS 客户端，里面可以设置 DNS 服务器的 IP 地址和 DNS 域名。/etc/resolv.conf 文件的格式如下： domainname 域名search 域名nameserver Primary_DNS_Server_IP_addressnameserver Second_DNS_Server_IP_address 例如： search dlut.edu.cnnameserver 202.118.66.6 在这个例子中，search 指令允许系统在未提供完整域名的情况下自动补全，而 nameserver 指定了使用的 DNS 服务器 IP。 3 etchost.conf/etc/host.conf 文件的功能是指定主机名查找的顺序，通常先检查 /etc/hosts 文件，如果没有找到，系统再向 DNS 服务器发送请求。对于大多数用户来说，这个文件的默认内容往往是足够的，例如： order hosts, bindmulti on 在这个配置中，order hosts, bind 指定了文件优先级，multi on 允许添加多个相同主机名的条目。 4 etcHOSTNAME (Linux Redhat 5.x Distribution)这个文件用于设置主机名。不同 Linux 发行版可能会稍有差异，因此需要使用以下命令检查相应的设置文件： egrep hostname /etc/rc.d/init.d/* 或者 egrep hostname /etc/init.d/* 对于 Linux Redhat 5.x，这个配置通常在 /etc/sysconfig/network 文件中的 HOSTNAME 条目中找到。 5 etcinetd.conf/etc/inetd.conf 文件用于配置 Internet 超级服务器，这是一个监听和管理多种网络服务的程序，路径为 /usr/sbin/inetd。在此配置文件中，列出了许多网络服务的设置，例如： ftp stream tcp nowait root /usr/sbin/tcpd in.ftpd -l -atelnet stream tcp nowait root /usr/sbin/tcpd in.telnetd 这些行定义了如何启动 ftp 和 telnet 服务。某些服务如 r 系列的远程服务（如 rsh, rlogin）建议关闭，以增强系统的安全性。 6 etcservices/etc/services 文件描述了各种网络服务以及相应的端口号和协议。在 Linux 环境下，该文件的格式如下： 服务名称 端口号/协议 服务别名 例如： ftp 21/tcptelnet 23/tcpsmtp 25/tcp mail 此文件基本上包含了系统支持的所有网络服务，通常用户无需修改。虽然 Linux 自带的内容已覆盖绝大多数需求，但在特定情况下（如在 Solaris 系统上）可能需要手动添加服务。 7 etchosts.allow 和 etchosts.deny在 Linux 系统中，尤其是在启用 tcpd 服务管理器的情况下，访问控制通过 /etc/hosts.allow 和 /etc/hosts.deny 文件进行管理。 /etc/hosts.allow 文件列出了允许使用 inetd 服务的主机。例如，设置 All: 202.118 表示允许所有来自 IP 地址以 202.118 开头的请求。 相对地，/etc/hosts.deny 则定义了不允许访问这些服务的主机。在安全性要求较高的环境中，合理配置这两个文件是至关重要的。具体配置顺序和语法请参见相关手册： man tcpd man hosts.allow man hosts.deny 需要注意的是，对于安全性要求更为严格的服务器，建议使用 xinetd 代替传统的 inetd。xinetd 通常在 Debian 系统中预装；若在其他系统上，则可以从源代码进行编译和安装。 8 etcnetworks 和 etcnetmasks/etc/networks 和 /etc/netmasks 文件用于列出路由所需的网络地址。虽然这些文件可以帮助管理路由表，但也可以直接使用命令行工具 /usr/sbin/route 来完成相应的操作。 示例配置文件/etc/networksdlrin 202.199.128.0/etc/netmasks202.199.128.0 255.255.240.0 加入静态路由表项的基本结构如图所示： +---------------+ DDN| Cisco 2511 +--------------DLMU 202.118.64.0/255.255.255.0| +--------------DLNA 210.47.192.0/255.255.240.0+-------+-------+| 202.118.66.254| 202.118.66.16+-------+-------+| Switch/HUB +-------+网络中心 +-----+ LAN Router++-------+-------+ +-------------+ +-----------+| ||| 202.118.68.0/255.255.252.0| +--------------++--------------+ 202.118.66.81+ (测试机器)| +--------------+||| 202.118.66.1(Default Router)+-------+-------+| 路由器 ++-------+-------+| 202.112.30.65/255.255.255.252| DDN | PPP|| 202.112.30.66/255.255.255.252 在这个图示中，每个 IP 地址均分配给不同的设备或网络段。比如，202.118.66.1 是默认路由，而 202.118.66.81 可以是一台进行测试的机器。 相关命令示例$ netstat -rnKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface202.118.66.0 0.0.0.0 255.255.255.0 U 1500 0 0 eth0127.0.0.0 0.0.0.0 255.0.0.0 U 3584 0 0 lo0.0.0.0 202.118.66.1 0.0.0.0 UG 1500 0 0 eth0 在上述表格中，Destination 列显示目标网络地址，Gateway 列则包含它所指向的网关。0.0.0.0 代表所有默认路由。 加入静态路由要加入静态路由，可以使用如下命令： /sbin/route add -net 202.118.66.0 netmask 255.255.255.0 eth0/sbin/route add -net 202.199.128.0 netmask 255.255.240.0 gw 202.118.66.254 也可以通过别名方式添加： /sbin/route add -net dlrin gw 202.118.66.254 9. etcpasswd此文件用于存储系统中每个用户的账户信息，包括用户名、用户 ID（UID）、组 ID（GID）、用户描述、主目录及用户的 shell。 10. etcshadow如果系统支持阴影密码机制，该文件用于存储加密的用户密码及密码更改信息。权限设置为 -rwx------ 确保只有 root 用户可以访问此文件。 11. etcfstab这是文件系统表，包含各种文件系统的设备名、挂载点、文件系统类型和可选的加载选项。例如： # 设备名 MountPoint FileSystem Type 加载选项 fsck标志/dev/hda1 / ext2 defaults 1 1/dev/hda6 /home ext2 defaults 1 2/dev/hda3 /usr ext2 defaults 1 2/dev/hda5 /var ext2 defaults 1 2/dev/hda2 swap swap defaults 0 0 12. etcexports此文件用于配置 NFS（网络文件系统）服务器的输出文件系统表。通常建议避免使用 NFS，原因在于它的安全性相比其他文件共享机制较低。 13. etcdefaultrouter (Solaris 2.x)此文件存储默认路由的 IP 地址。在 Linux 系统中，这通常会在 /etc/sysconfig/network 或 /etc/init.d/network 中配置。示例如下： GATEWAY=202.118.66.1GATEWAYDEV=eth0 14. etcbashrc, etccsh.cshrc, etcprofile这些文件用于设置用户的默认环境，定义了如 PATH、umask 和 TERM 等环境变量。 15. etcftpaccess此文件用于控制 FTP 访问，具体访问配置会根据 FTP 服务器的配置进行设定。 16. etcftpusers此文件包括被禁止通过 FTP 登录的用户列表，通常包括 root, uucp, bin 等。 17. etcftpconvions 和 etcftpgroups这些是 FTP 服务器用于管理用户权限和组的配置文件。 18. etcgroup此文件包含用户组的相关信息，定义了系统中所有用户所属的组。 19. etcsendmail.cf这是 Sendmail（邮件服务器）的配置文件，其中 /etc/sendmail.cw 包含本地主机名的相关信息。 20. etcissue该文件定义了用户在系统登录时看到的提示信息，而 /etc/motd 则是用户登录后显示的欢迎信息。 21. etcnamed.boot此文件是 DNS (BIND 4.9.x) 的启动文件，定义了 DNS 服务器的工作目录和缓存设置。 22. etchost.equiv 和 $HOME.rhosts这两个文件用于 R 系列服务（如 rlogin 和 rsh 等）的主机信任配置。 23. etcld.so.conf这个文件定义动态链接库的路径，修改后需要使用 ldconfig 命令更新库文件。 24. etcpam.dlogin此文件涉及到 Linux 中的身份验证管理设置，可能会根据不同的发行版存在不同配置方式。 25. Linux Loader etclilo.conf该文件用于多重启动配置，修改后需执行 lilo 命令以使改动生效。 26. etcsyslog.conf这是 syslogd 的配置文件，用于系统日志的管理。 27. etcsmb.conf此配置文件用于 Samba 服务器，使 Linux 系统的文件与 Windows 系统共享。 28. etcnologin系统关机时创建此文件，内容为拒绝用户登录的信息。 29. etcsecurity此文件定义了哪些终端设备可以让 root 登录。 30. etcX11*用于 XFree86 的配置文件，涉及图形界面设置。 31. etcshells列出了系统中可用的 shell 程序，未在此列表中的 shell 将无法通过 FTP 使用。 32. etcmtab这是一个动态更新的信息文件，记录系统当前已挂载的所有文件系统。","categories":["1.平台","Linux","文件系统"]},{"title":"sys目录","path":"/2024/12/17/1-平台-Linux-文件系统-sys目录/","content":"sys 目录下的子目录sys 目录与 proc 目录的比较sys 目录专门用来将内核中的信息映射到用户空间，供应用程序进行访问。这与 proc 文件系统形成对比，后者是一个完全存在于内存中的伪文件系统，没有占用任何外部存储。在 proc 中，以文件和目录的形式提供了一个接口，允许用户和应用程序获取实时的系统内核数据，并在某些情况下修改内核参数。这是由于系统信息经常是动态的，比如进程的状态。当用户读取 proc 中的文件时，系统会实时地从内核中提取所需的信息并返回。 sysdevicessysdevices 目录包含了一个全局的设备结构体系，注册了所有在不同总线上的物理设备。设备按照其在总线上的拓扑结构进行展示，但有两个特例：platform devices 和 system devices。 platform devices 通常是挂载在芯片内部高速或低速总线上的控制器和外设，这些设备可以被 CPU 直接访问。例如，某个嵌入式系统中的 GPIO 控制器可能就属于这一类。 system devices 则是指芯片内部的核心组件，例如 CPU、定时器等。这些组件通常没有独立的驱动程序，但会有与体系结构相关的代码负责配置它们。 这一目录是内核对所有设备的分层表达模型，也是 sys 文件系统中最重要的设备管理结构。 sysdev该目录维护一个符号链接的文件列表，这些链接按字符设备和块设备的主次号码（major:minor）连接到真实设备（sysdevices）。这意味着用户可以通过这些链接轻松访问现实中的设备，方便管理和操作。例如，一个虚拟设备的符号链接可以连接到实际的块设备，使得用户无需直接操作底层的设备文件。 sysclasssysclass 目录包含系统中注册的所有设备类型，并根据设备功能进行分类。每个设备类型都有自己的子目录，其中包含指向具体设备的符号链接。例如，所有输入设备无论是通过 USB、PS2 还是其他方式连接的，都将在 sysclassinput 下出现。这个目录是 Linux 统一设备模型的重要组成部分，使得不同类型的设备可以通过统一的方式进行管理。 sysblock该目录下的子目录代表当前系统中检测到的所有块设备。尽管更合理的分类应在 sysclass 下，这部分设备历史上一直保留在 sysblock 下。从 Linux 2.6.22 内核版本开始，该目录被标记为过时，仅在开启 CONFIG_SYSFS_DEPRECATED 配置时才会存在。实际上，从 Linux 2.6.26 开始，相关信息已被迁移至 sysclassblock，因此 sysblock 目录中的内容仅保留指向真实设备的符号链接，以保持向后兼容性。 sysbus该目录下的每个子目录对应内核支持且已注册的总线类型。所有设备在 sysdevices 中都与某种总线连接。每个总线类型的子目录下，通常包含两个子目录：devices 和 drivers。 devices 子目录下列出了该总线类型下所有设备的符号链接，指向真实设备所在的 sysdevices 目录。 drivers 子目录包含所有注册到该总线的驱动程序。每个驱动子目录下都提供一些可以观察和修改的参数。 此目录同样是 Linux 统一设备模型的关键组成部分。 sysfs该目录旨在描述系统中所有的文件系统，包括文件系统本身及其按类别分类存放的已挂载点。这为系统管理员提供了一个清晰的视图，可以快速了解当前文件系统的状态及其挂载情况。 syskernelsyskernel 目录存放的是内核中所有可调节的参数，这些参数可用于系统调优和资源管理。通过调整这些参数，可以改善系统的性能和稳定性。 sysfirmware该目录提供对固件对象和属性的操作接口，是系统加载固件机制的用户空间接口，旨在管理和更新固件。 syshypervisor此目录专门与虚拟化系统 Xen 相关。Xen 是一个开源虚拟机监视器，能够在单个物理机器上同时运行多个操作系统，以便更高效地利用资源。 sysmodulesysmodule 目录包含系统中所有模块的信息，模块可以是直接编译入内核映像中的内联模块，也可以是作为外部模块（.ko 文件）加载。此目录提供了模块的当前状态和配置，有助于系统管理员进行模块管理和故障排除。 syspower该目录描述系统中的电源选项，覆盖当前正在使用的电源子系统。这里提供了多个属性文件，让用户控制机器的电源状态，例如，通过向属性文件写入特定指令来实现关机或重启等操作。","categories":["1.平台","Linux","文件系统"]},{"title":"task_struct和文件系统","path":"/2024/12/16/1-平台-Linux-文件系统-task-struct和文件系统/","content":"Linux 中 task_struct 和文件系统的关系在 Linux 内核中，task_struct 是表示每个进程的核心数据结构。在进程运行时，可以通过 current 宏获取当前执行的进程的 task_struct 结构。这一数据结构与文件系统之间有着密切的关联，影响着进程如何访问和管理其打开的文件。 进程与文件系统的连接1. fs_struct每个进程都有一个 fs_struct 结构，用于描述其文件系统信息。此结构体主要包含以下几个字段： count：表示共享同一 fs_struct 的进程数量。 umask：由 umask() 系统调用使用，其作用是设定新创建文件的默认权限。 root、pwd、altroot：分别表示进程的根目录、当前工作目录和替代根目录。 在 Linux 2.4 中，fs_struct 的定义如下： struct fs_struct atomic_t count; rwlock_t lock; int umask; struct dentry *root, *pwd, *altroot; struct vfsmount *rootmnt, *pwdmnt, *altrootmnt;; 这三个指针分别指向 dentry 结构，后者用于描述目录项。例如，进程的根目录可能指向位于 / 下的 Ext2 文件系统，而当前工作目录可以在不同的文件系统中，比如挂载点 /msdos 上的 DOS 文件系统。这种设计允许进程在同一运行期间跨越多个文件系统，而 rootmnt、pwdmnt 和 altrootmnt 则描述了这些目录的挂载点。 2. files_struct每个进程还拥有一个 files_struct 结构，记录其打开的文件描述符信息，实际上是一张用户打开文件的表格。该结构在 include/linux/sched.h 中定义为： struct files_struct atomic_t count; rwlock_t file_lock; int max_fds; int max_fdset; int next_fd; fd_set *close_on_exec; fd_set *open_fds; struct file **fd; struct file *fd_array[32];; fd_set：指向打开文件描述符的指针数组，通常长度为 32。当打开的文件数超出这个限制时，内核会为其分配更大的数组。 next_fd：跟踪下一个可用的文件描述符索引，确保每次打开新文件时可以正确分配描述符。 open_fds：维护当前已打开文件的位图，位数取决于 max_fdset 的值。该位图通常包含 1024 位，足以覆盖大多数情况。 在该结构中，前 3 个文件描述符通常用作标准输入（0）、标准输出（1）和标准错误（2）。通过系统调用如 dup() 和 dup2()，多个文件描述符可以指向同一打开的文件，从而实现文件重定向等功能。例如，命令 21 可以将标准错误输出重定向到标准输出。 3. struct filestruct file 在 include/linux/fs.h 中定义，描述每个打开文件的详细信息，结构如下： struct file struct list_head f_list; struct dentry *f_dentry; struct vfsmount *f_vfsmnt; struct file_operations *f_op; mode_t f_mode; loff_t f_pos; unsigned short f_flags; unsigned short f_count; int f_owner; uid_t f_uid; gid_t f_gid; unsigned long f_version; void *private_data;; f_list：指向所有已打开文件的链表。 f_dentry：指向文件对应的目录项，用于查找文件在文件系统中的位置。 f_op：指向文件操作表，包括文件的各种操作方法，如读取、写入、关闭等。 f_pos：记录文件当前的读取位置。 f_mode：指定文件的打开模式（如只读、读写等）。 该结构体使得 Linux 内核在文件操作时能够管理文件的状态和相关信息，确保进程间文件访问的协调和效率。 通过以上结构和描述，可以看到 Linux 的进程与文件系统之间的精密联系，使得操作系统能够高效地管理多进程环境下的文件操作。","categories":["1.平台","Linux","文件系统"]},{"title":"内存管理","path":"/2024/12/13/1-平台-Linux-程序-内存管理/","content":"物理内存管理（页管理）Linux 内核通过分页机制管理物理内存，将整个内存划分为多个 4KB 大小的页面（这是在 i386 体系结构中的标准大小）。在这种机制下，内存的基本分配和回收单位便是这些内存页。这种分页管理方式带来了灵活的内存地址分配，进程在需要内存时，可以不必依赖于大块连续的内存。在实际操作中，系统能够将好几块零散的页面组合起来，满足进程的内存需求。 虽然分页管理支持分散的内存分配，但在实际应用中，系统倾向于分配连续的内存块。这是因为在分配连续内存时，页表的结构不会发生变化，从而降低了翻译后备缓冲区（TLB）的刷新频率。TLB 刷新得越频繁，访问速度就越慢，因此系统通过此方式优化了总体性能。 为了减少不连续内存分配的情况，Linux 内核采用了一种称为“伙伴”关系的算法来管理空闲页框。伙伴关系分配算法是操作系统领域的经典理论，几乎所有相关教材都会介绍这一内容。在 Linux 中，空闲页面的组织和管理依赖于这种伙伴关系。因此，在分配空闲页面时，必须遵循伙伴关系的原则，最小的分配单位是 2 的幂倍，即页面大小必须为 2、4、8…512 等。 内核中负责分配空闲页框的基本函数是 get_free_page 和 get_free_pages。前者用于分配单个页面，而后者可用于分配指定数量的页框，比如 2、4、8，直至 512 页。这两个函数的使用与用户空间的内存分配机制显著不同。get_free_page 在内核中分配内存，而 malloc 则是在用户空间进行分配。malloc 依托于堆动态分配内存，实际上是通过调用 brk() 系统调用来实现的。 brk() 系统调用可以扩大或缩小进程的堆空间，修改进程的 brk 域。如果当前内存区域不足以容纳新请求的堆空间，则会以页面大小的倍数改变内存区域的大小。然而，brk 的修改并不一定严格按页面大小，而是依据实际请求来调整。这意味着，虽然用户空间的内存分配可以以字节为单位进行，但内核内部分配仍然是以页面为单位进行。 此外，物理页在系统中由一个名为 struct page 的结构描述。系统中的所有页框被存储在一个数组 mem_map[] 中，通过该数组可访问系统中的每一页，无论是空闲页还是正在使用的页。空闲页框则通过以伙伴关系组织的空闲页链表 （free_area[MAX_ORDER]） 索引，使得内存管理更加高效与系统化。 内核内存使用Slab内核在管理物理内存时，以页为最小单位来分配内存确实方便，但内核通常需求的小内存块往往远小于一个页面。比如，文件描述符、进程描述符和虚拟内存区域描述符等，这些都只需极小的内存。例如，一个文件描述符仅占用 64 字节，而一个完整的页面通常是 4KB。因此，将这些小块内存视为面包屑，数量众多且频繁变化，远远赋予它们更大的灵活性。 为了更高效地满足这种小内存块的需要，Linux 操作系统引入了被称为Slab 分配器的技术。虽然 Slab 的实现较为复杂，但其基本原理相对简单。核心思想是建立一个“存储池”，在这个池中，内存片段（或小块内存）被视为对象。使用完这些对象后，它们并不直接释放，而是存放在“存储池”中以待下次使用。这种做法显著减少了频繁创建和销毁对象时所产生的额外开销。 Slab 分配器的引入主要是为了减少对伙伴系统分配算法的调用频率，频繁的分配和回收容易导致内存碎片化问题。此外，Slab 还能够有效利用硬件缓存，提升内存访问速度。Slab 并非独立于伙伴系统的存在，它仍然依赖于页面的基本结构，实际上，Slab 在伙伴关系管理的空闲页框链基础上，将一个完整页面划分为多个可用的小内存块，以满足内核内存分配的需求。Slab 中对象的分配和释放则通过 kmem_cache_alloc 与 kmem_cache_free 来进行。 KmaloKmalloc是 Slab 分配器对小块内存（特别是小于一个页面的内存）的请求处理接口。虽然 Kmalloc 的分配范围从 32 字节到 131072 字节不等，但它通常用于申请小于一页的内存。它为内核程序提供了比 get_free_page 更灵活的内存分配方式，填补了不同内存需求之间的空白。实际上，从内核内存分配的角度来看，Kmalloc 与 get_free_page 互为补充，提供了不同粒度的内存分配。 在 /proc/slabinfo 路径中，可以找到有关当前内核运行时所使用的各类 Slab 的信息统计。这些数据显示了除专用结构体使用的 Slab 外，还有大量为 Kmalloc 所准备的 Slab 对象，包括某些专为 DMA（直接内存存取）操作设计的 Slab。 内核非连续内存分配（Vmalloc）从内存管理的理论出发，无论是伙伴关系还是 Slab 技术，都旨在避免“分片”问题。内部分片通常是由于系统为满足小范围的内存需求，不得不分配较大的内存段，从而造成空间的浪费。而外部分片则是指尽管有足够的内存，但由于分散的碎片无法满足对大块连续内存的请求。两种分片形式都是内存高效利用的障碍。 Slab 分配器使得一个页面可以容纳许多小内存块，避免低效的内部分片，节约了内存。而伙伴关系通过将内存块按大小分组进行管理，尽量缓解外部分片的影响。但即便如此，伙伴关系并未完全消除外部分片的问题。反映在多次分配后，剩余的空闲内存可能依旧分布不均，难以满足大内存块的请求。 要解决外部分片的问题，最终的方案在于如何将不连续的内存块组合成逻辑上看似“连续”的大内存块。这一理念和用户空间的虚拟内存分配相似，内存逻辑上连续，实际上却可能映射到不连贯的物理内存上。Linux 内核借用此技术，允许在内核地址空间中申请虚拟地址，并通过内核页表将这些虚拟地址映射到散布的物理页上，巧妙地解决了外部分片的问题。 内核提供了 vmalloc 函数来分配内核虚拟内存。与 Kmalloc 不同，vmalloc 能够分配更大，通常超过 128K 的内存空间，但必须是页面大小的倍数。由于要更新内核页表以实现虚拟地址的映射，vmalloc 的分配效率较 Kmalloc 低。这种“用空间换时间”的策略使得内核在面对较大的内存需求时，可通过映射无序的物理内存页来实现灵活分配。 类似于用户进程，内核也维护一个名为 init_mm 的 mm_struct 结构来描述其地址空间，页表项 pdg（swapper_pg_dir）列出了系统内核空间（3G-4G）的映射关系。因此，vmalloc 需要更新内核页表以完成虚拟地址的分配，而 kmalloc 或 get_free_page 因为分配的是连续内存，自然不需进行页表更新。 内核虚拟内存分配在内核空间中，内存分配采用了不同的机制，其中 vmalloc 所分配的内核虚拟内存和其他方法如 kmalloc 及 get_free_page 分配的内存是位于不同的地址区间，彼此之间不会发生重叠。这是因为内核虚拟空间必须经过有效的分区管理，以确保每种分配方法能高效且安全地运行各自的功能。 虚拟地址分布进程空间进程的虚拟地址空间通常分布在 0 到 3GB 的区间。对于 x86 架构，具体来说，实际的分界会在 PAGE_OFFSET，其值为 0xC0000000。这个范围主要用于进程自身的使用，包括用户空间和内核空间的交互。 物理内存映射区3GB 到 vmalloc_start 的地址段则是物理内存映射区域，在此区域内包括了许多重要的系统资源，比如内核镜像和物理页框表 mem_map 等。例如，在一个可用系统内存为 64MB 的情况下（可以通过命令 free 进行查看），则这段地址的映射物理内存是从 3GB 到 3GB + 64MB。这意味着在此物理内存映射区，内存的实际使用情况是可以被读写的。 vmalloc 区域通常，vmalloc_start 应该会位于 3GB + 64MB 附近。这个”附近”的定义是因为在物理内存映射区和 vmalloc_start 之间存在一个约 8MB 的间隙，这是为了防止地址的交叉和潜在的错误。 vmalloc_end相应地，vmalloc_end 的位置通常接近 4GB。这个接近的表述是由于系统需保留一个 128KB 的专用页面映射区域。此外，也可能会涉及高端内存映射区域，具体细节在此不再深入探讨。这样设计的主要目的是确保系统能够高效地进行内存管理。 以上图像清楚地展示了内存分布的模糊轮廓，使得整体结构一目了然。从图中可以看到，不同的内存分配区域在地址空间中的关系和布局，从而有助于更好地理解内核内存的分配机制。 由 get_free_page 或 kmalloc 函数所分配的连续内存属于物理映射区域，这意味着它们在内存中的内核虚拟地址和实际的物理地址之间仅相差一个固定的偏移量，称为 PAGE_OFFSET。这一特性使得在进行内存管理时能够很方便地进行内核虚拟地址与物理内存地址之间的转换。内核还提供了 virt_to_phys() 函数，专门用于将内核虚拟空间中的物理映射区地址转化为实际的物理地址。 在物理内存映射区域中的每个地址与内核页表有序对应，这样系统中的每个物理页框都能够被映射到它对应的内核虚拟地址。这种映射关系确保了内存管理的高效性。例如，在一个系统中，假设物理地址 0x1F000 通过内核页表可以查找到其对应的虚拟地址 0xC000F000，开发者可以利用这一映射关系更轻松地对内存进行操作。 与 get_free_page 和 kmalloc 的内存分配不同，vmalloc 分配的地址只是在 vmalloc_start 与 vmalloc_end 之间。每一块通过 vmalloc 分配的内核虚拟内存都对应一个 vm_struct 结构体。需要特别注意的是，不要将 vm_struct 与 vm_area_struct 混淆，后者是用于描述进程虚拟内存区域的结构体。为了防止内存越界，vmalloc 分配的内核虚拟地址间隔着 4k 字节大小的空闲区（请参见下图）。 这些内核虚拟地址的行为类似于进程的虚拟地址，二者之间并没有简单的位移关系。必须通过内核页表进行转换，以获取相应的物理地址或物理页。这意味着这些虚拟地址在某些情况下可能尚未被映射，当发生缺页异常时才会真正分配物理页框。 以下是一个小程序，帮助理解上述几种内存分配函数所对应的区域： #include linux/module.h#include linux/slab.h#include linux/vmalloc.hunsigned char *pagemem;unsigned char *kmallocmem;unsigned char *vmallocmem;int init_module(void) pagemem = get_free_page(0); printk(1 pagemem = %s , pagemem); kmallocmem = kmalloc(100, GFP_KERNEL); printk(1 kmallocmem = %s , kmallocmem); vmallocmem = vmalloc(1000000); printk(1 vmallocmem = %s , vmallocmem); return 0;void cleanup_module(void) free_page(pagemem); kfree(kmallocmem); vfree(vmallocmem); 在这个示例中： get_free_page(0) 分配一个物理页，并返回其内核虚拟地址。 kmalloc(100, GFP_KERNEL) 为内核分配 100 字节的连续内存。 vmalloc(1000000) 分配一个虚拟地址范围，能够容纳 1,000,000 字节，但其对应的物理内存不一定是连续的。 在模块卸载时，相应的资源被释放，以防止内存泄漏。这种优雅的内存管理确保了系统的稳定性和高效性。 内存管理实例代码功能介绍目标是通过访问用户空间的内存来读取内核数据，实现内核空间与用户空间之间的大规模信息传输。具体而言，利用内存映射功能，将系统内核中的一部分虚拟内存映射到用户空间，从而使得用户空间地址与被映射的内核内存地址相等。 代码结构体系介绍内核空间内存分配计划编写一个虚拟字符设备驱动程序，通过该程序将系统内核空间映射到用户空间。这意味着将内核虚拟内存映射到用户虚拟地址。在进行映射时，需要准确定位内核空间对应的物理地址，并建立新的用户页表项。这样，用户进程在寻址时能找到对应的物理内存。 为了实现这一目标，所需的关键数据为： 被映射内核空间的物理地址 对应的用户进程页表 在内核空间中，主要存在两种内存分配方式：kmalloc 和 vmalloc。 kmalloc：分配的是物理连续的内存，通常被称为内核逻辑地址。这种分配方式直接处理物理页框，因此其分配首地址是固定的。通过内核提供的 virt_to_phys 函数，可以方便地获得对应的物理地址。它的虚拟地址与物理地址之间的关系简单清晰：物理地址 内核虚拟地址 - PAGE_OFFSET（0xC0000000），其中 swapper_pg_dir 表示对应的页表已经在系统初始化时建立，省去了页表建立的步骤。 vmalloc：分配的是非连续的物理内存空间，被称为内核虚拟地址。其管理机制相对复杂，因为 vmalloc 分配的内核虚拟内存逻辑上是连续的，但是对应的物理内存并不连续。这使得其物理地址在分配前无法确定。尽管 vmalloc 和 kmalloc 都使用内核页表进行映射，但 vmalloc 在内存分配时还必须更新内核页表。需要注意的是，vmalloc 分配的内核虚拟内存与 kmalloc 分配的内核逻辑内存位于不同地址区间，避免重叠。 注释：内存空间的分区管理使得不同的内存分配方式各司其职。通常情况下，进程空间地址范围从 0 到 3G（实质上是到 PAGE_OFFSET，约等于 0xC0000000），而物理内存映射区域则位于 3G 到 vmalloc_start 之间。这一区域包含了内核镜像和物理页框表（mem_map）。以系统内存 64M 为例，内存映射区从 (3G - 3G + 64M) 将映射到物理内存，而 vmalloc_start 位置应位于 3G + 64M 附近。 另一个需要澄清的问题是：vmalloc 分配的内核空间的结构是 vm_area，不要与用户空间的 malloc 分配结构体 vm_area_struct 混淆。前者通过内核页表映射，后者则由用户页表映射。 内存分布示意进程地址空间物理内存映射区 kmalloc 分配|--------------------------|| 0 ||--------------------------|| 3G ||------- page_offset -----|| 内核虚拟空间 || vmalloc_start || vmalloc_end ||--------------------------| 上图展示了内存分布的基本轮廓，强调了不同分配方式之间的差异。 实例蓝图为了丰富我们的例子程序的场景，选择将 vmalloc 分配的内核虚拟空间（以下简称为 vk 地址）映射到用户空间是一项重要任务。 用户进程操作的是其虚拟内存区域 vm_area_struct。在此阶段，需要将用户的 vma 区间利用用户页表映射到 vk 对应的物理内存。此过程涉及若干步骤，如下所示。主要工作是建立用户页表项以完成映射，这一过程依赖于 vma-nopage 操作。该方法的作用是帮助系统在发生“缺页”时，动态构造所需的物理内存页表项。 用户虚拟空间: vm_area_struct 结构。 vk 空间: vm_struct。 物理内存: 系统实际可用的内存。 nopage 方法的实现为了成功实现这个过程，需要编写 nopage 方法，动态建立对应的页表。核心任务是找到 vk 地址对应的内核逻辑地址。这需要完成以下几个步骤： 定位 vmalloc 虚拟内存的内核页表: 首先需要访问内核中与 vmalloc 内存区相关的页表。这有助于确定具体的地址映射关系和页表项。 获取内核页表项对应的物理页框指针: 一旦找到页表，需提取对应的物理页框指针，供后续的地址映射使用。 从页框得到内核逻辑地址: 最后，通过页框信息，获取相关的内核逻辑地址，为后续的访问提供基础。 基本函数的设计在这一实例中，将利用一个虚拟字符驱动程序，驱动负责将一定长的内核虚拟地址（vmalloc 分配的空间）映射到设备文件。这种设计允许通过文件系统接口访问内存，从而显著提高内存访问速度，降低开发的复杂度。 驱动程序的构建map_driver.c 是我们的虚拟字符驱动程序。该程序需要实现文件操作表（file_operations），该结构中的主要任务是完成相关推荐操作。为了实现内存映射，除了常规的 open 和 release 操作外，还必须自定义实现 mmap 操作。此函数的主要职责是将指定的文件映射到目标地址空间，尤其是将 vmalloc 分配的内核地址映射到对应的设备文件上。 mmap 操作的具体实现文件操作的 mmap 操作在用户发起系统调用 mmap 时触发。在此之前，内核已经为用户分配了合适的虚拟内存区域 vm_area_struct，该区域代表着文件内容。接下来的关键在于如何将虚拟区域与物理内存连接起来，也就是构建页表。 由于前述原因，系统中的页表需要动态分配，因此无法一次性使用 remap_page_range 函数分配页表项，而必须依赖于虚拟内存区域本身提供的 nopage 方法以在需要时动态构造页表。这样一来，文件操作的 mmap 方法只需完成为其获取的虚拟内存区域绑定对应的操作表 vm_operations 的工作。 nopage 方法的核心功能如前所述，nopage 方法的核心内容是“寻找到 vk 地址对应的内核逻辑地址”。此项工作涉及解析内核页表，通常需要编写辅助函数 vaddr_to_kaddr 来完成。该函数的主要任务是依照之前提到的三个步骤：定位页表项、获取物理页面框指针以及获得内核逻辑地址。 执行路径的示意图 STEP BY STEP: 编译 map_driver.c 为 map_driver.o 模块，具体参数可参考 Makefile。 加载模块：insmod map_driver.o。 生成对应的设备文件： 在 /proc/devices 下查找 map_driver 对应的设备名和设备号：grep mapdrv /proc/devices。 使用命令 mknod mapfile c 254 0（在此系统中，设备号为 254）创建设备文件。 通过 maptest 读取设备文件 mapfile，将内核信息（如“ok”——我们在 vmalloc 分配的空间中填放的信息）打印到用户屏幕，以验证映射是否成功。 这种设计不仅完成了内存到文件的映射，还大幅度提高了内存访问的效率，同时利用了 Linux 中设备作为特殊文件的处理方式，降低了开发的复杂度。","categories":["1.平台","Linux","程序"]},{"title":"librkcrypto","path":"/2024/12/10/1-平台-Linux-加密-librkcrypto/","content":"librkcryptolibrkcrypto 提供了一套基于硬件的加密算法接口，能够有效地使用直接内存访问（DMA）方式进行数据处理。这一特性使得 librkcrypto 可广泛应用于加密、解密、数据认证等多种场景，提升了数据处理的效率和安全性。 librkcrypto 的设计依赖于内核加密驱动的实现。对于驱动开发以及应用 API 的开发，建议参考名为 Rockchip_Developer_Guide_Crypto_HWRNG_CN.pdf 的文档，该文档为开发者提供了详尽的指导。 版本号查询若需查询当前 API 的版本号，可以通过以下两种方式进行验证。 使用 strings 命令 # 在 64 位 Linux 平台上运行以下命令$ strings /lib64/librkcrypto.so | grep api | grep versionrkcrypto api version 1.2.0 执行以上命令后，将获得当前的 API 版本，其格式为 “rkcrypto api version x.x.x”。 查看日志输出 当任一进程首次调用 librkcrypto 的接口时，该接口会在日志中输出当前版本号。例如： RKCRYPTO I[rk_crypto_init, 262]: rkcrypto api version 1.2.0 此信息确保开发者能够迅速确认正在使用的版本。 适用芯片平台librkcrypto 支持以下多个芯片平台，这些平台包括但不限于： RK3588 RK356x RV1109 RV1126 RK3326PX30 RK3308 RV110603 请注意，部分 API 可能不适用于某些特定的芯片平台，用户应参考应用开发说明文档以获取详细信息。 版本依赖V1.2.0 对于 kernel 4.19 版本：需要更新到以下提交： c255a0aa097a crypto: rockchip: rk3326/px30 add aes gcm support 对于 kernel 5.10 版本：需更新至以下提交： 47e85085826d crypto: rockchip: rk3326/px30 add aes gcm support V1.1.0 对于 kernel 4.19 版本：需进行如下更新： 1e549d833bc3 crypto: rockchip: v2: ahash init/update/final use hardware crypto 对于 kernel 5.10 版本：需更新至： 4d2020372e7e crypto: rockchip: v2: ahash fix hash_algo2name setting error. 此外，若需要使用 OTP key 的加解密功能，请确保 rkbin 更新至相应的提交版本，具体步骤如下： 对于 RK3588： 23ca562 rk3588: bl32: update version to v1.07 对于 RK356x： 86e9bb7 rk3568: bl32: update version to v2.07 对于 RV1109RV1126： 42eea81 rv1126: tee: update version to v2.05 目录说明项目目录结构简洁明了，包含以下重要部分： demo: 提供 API 使用示例，帮助开发者快速上手。 docs: 包含应用开发说明文档，详细介绍各类接口的使用。 include: 包含头文件，供外部程序调用。 src: 用户空间的驱动及 API 实现代码。 test: 包含 API 测试代码，确保功能的正确性。 third_party: 包含第三方开源代码以供引用。 编译说明Android要在 Android 平台上编译 librkcrypto，包括库、测试和示例，可以按照以下步骤操作： # 首先，在 Android 工程目录下执行$ source build/envsetup.sh$ lunch rk3588_s-userdebug # 选择 RK3588 平台# 然后 cd 到 librkcrypto 目录并执行编译$ mm 编译成功后，将根据选择的芯片平台生成相应的 32 位或 64 位目标文件，包括 librkcrypto.so、librkcrypto_test 和 librkcrypto_demo。编译日志中会标明这些目标文件所在的目录。 Linux要在 Linux 平台上进行编译，步骤如下： # 在 librkcrypto 的目录下执行$ ./build.sh # 编译 32 位和 64 位$ ./build.sh 32 # 仅编译 32 位$ ./build.sh 64 # 仅编译 64 位 成功编译后，目标文件将位于 librkcrypto/out/target 目录下，文件包括 librkcrypto.so、librkcrypto.a 以及 librkcrypto_test。 编译 demo # 进入 demo 目录进行编译$ cd demo$ make 32 # 或直接 $ make，编译 32 位$ make 64 # 仅编译 64 位$ make clean # 清除目标文件 编译后，librkcrypto/demo 目录将生成目标文件 librkcrypto_demo。 使用说明 头文件 在使用 librkcrypto API 时，需包含以下头文件： #include rkcrypto_common.h // 包含通用函数#include rkcrypto_core.h // 使用 cipher、hash、hmac 等接口#include rkcrypto_mem.h // 使用支持 dma_fd 的接口#include rkcrypto_otp_key.h // 使用 otp_key 相关接口#include rkcrypto_random.h // 使用随机数接口 库文件 包括： librkcrypto.so librkcrypto.a (仅限于 Linux 平台) 日志打印 librkcrypto 设置了多种日志等级，方便开发者调试和获取运行信息： 等级 1 - TRACE_ERROR：表示错误信息，关键信息用以调试。 等级 2 - TRACE_INFO：包含常用信息，比如版本号等，默认级别。 等级 3 - TRACE_DEBUG：提供更深入的一般调试信息。 等级 4 - TRACE_VERBOSE：包括详细的调试信息，利于追踪问题。 可以通过以下方式自定义日志等级，设置后将打印该等级及其以下等级的日志。请注意，设备重启后日志等级将恢复为默认的等级 2。 使用 API 设置： RK_RES rkcrypto_set_trace_level(enum RKCRYPTO_TRACE_LEVEL level); 使用指令设置： # Androidsetprop vendor.rkcrypto.trace.level 1/2/3/4# Linuxexport rkcrypto_trace_level=1/2/3/4 应用开发说明文档 开发者可以参考 Rockchip_Developer_Guide_Crypto_HWRNG_CN.pdf 文档，以获取具体的应用开发信息和指导。 FAQ 编译链依赖 本项目的 CMake 默认使用的编译链为 gcc 10.3 版本，通过如下路径进行访问： gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu 如果的系统中没有相应的编译链版本，编译过程中可能会出现以下报错信息： make[2]: librkcrypto/../../prebuilts/gcc/linux-x86/arm/gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin/arm-none-linux-gnueabihf-gcc: Command not found 可以通过修改 CMakeLists.txt 文件中的编译链路径和版本来解决此问题： set (TOOLCHAIN_PREBUILTS $CMAKE_CURRENT_SOURCE_DIR/../../prebuilts)set (TOOLCHAIN_PATH_ARM32 gcc/linux-x86/arm/gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin)set (TOOLCHAIN_PATH_AARCH64 gcc/linux-x86/aarch64/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin) 若在运行时遇到如下报错，说明编译链的 GLIBC 版本与设备上的 GLIBC 版本不一致。需要修改编译链的版本或调整设备上的 GLIBC 版本。 version GLIBC_2.29 not found (required by /lib/librkcrypto.so)","categories":["1.平台","Linux","加密"]},{"title":"逻辑地址、线性地址及物理地址的区别","path":"/2024/12/09/1-平台-Linux-程序-逻辑地址、线性地址及物理地址的区别/","content":"逻辑地址、线性地址及物理地址的区别一、逻辑地址转线性地址在计算机系统中，所有的机器语言指令中的内存地址都是逻辑地址。这些地址必须经过转化才能被实际访问，具体过程是先将逻辑地址转换成线性地址，再通过内存管理单元（MMU，将 CPU 与主存连接的组件）将其转换为物理地址。举个例子，编写一个简单的 “Hello World” 程序并使用 GCC 编译后，反汇编得到的指令可能如下所示： mov 0x80495b0, %eax 这里的 0x80495b0 是一个逻辑地址。为了将这个逻辑地址转换为线性地址，需要加上隐含的数据段（DS）的基地址。这意味着 0x80495b0 实际上是当前任务在数据段中的偏移量。 在 x86 保护模式下，段描述符包含段的信息，例如段基础线性地址、长度和权限等，每个段描述符占用 8 个字节，而段寄存器则仅有 2 字节。Intel 的架构设计使得段描述符集中存放于全局描述符表 GDT 或局部描述符表 LDT 中，而段寄存器则保存的是在 GDT 或 LDT 中的索引值。 在 Linux 系统中，逻辑地址与线性地址是相等的，这背后的原因在于，Linux 所有的段——无论是用户代码段、用户数据段，还是内核代码段、内核数据段——的线性地址均从 0x00000000 开始，长度达到 4GB。因此，线性地址可以表示为 逻辑地址 + 0x00000000，在这种情况下，逻辑地址与线性地址完全相同。 由于这种设计，Linux 仅使用 GDT，在用户任务和内核任务中均不需要使用 LDT。GDT 中的第 12 和第 13 项段描述符分别是 __KERNEL_CS 和 __KERNEL_DS，而第 14 和第 15 项则是 __USER_CS 和 __USER_DS。内核任务使用的段描述符拥有最高特权（DPL 值为 0），而用户任务则共享同一个用户段描述符，DPL 值为 3。 使用 GDB 调试程序时，可以通过 info reg 命令查看当前寄存器的值： cs 0x73 115ss 0x7b 123ds 0x7b 123es 0x7b 123 在此输出中，可以注意到 ds 的值是 0x7b，将其转换为二进制得到 00000000 01111011。TI 字段值为 0，表明使用的是 GDT，并且 GDT 的索引值为 01111，即十进制的 15。这对应于 GDT 中的 __USER_DS 用户数据段描述符。 通过上述分析可以看出，尽管 Linux 在 x86 体系结构中运行，仍然通过精巧的方式规避了复杂的分段机制，而主要依赖于分页机制来实现内存管理。 二、线性地址转物理地址既然在 Linux 中逻辑地址等于线性地址，那么线性地址如何转换为物理地址呢？这个过程通过分页机制实现，而分页机制则是由 CPU 提供的一种内存管理方案。具体来说，线性地址到物理地址的转换是通过页表查找来完成的。 在保护模式下，控制寄存器 CR0 的最高位 PG 指定分页管理机制的状态。如果 PG 1，说明分页机制生效，需要通过页表查找到物理地址；如果 PG 0，则分页机制无效，此时线性地址直接作为物理地址。 分页的基本概念是将内存划分成大小固定的多个单元，每个单元称为一页（page），每页通常包含 4KB 的地址空间。为了将线性地址转换为物理地址，CPU 需要访问页目录表和页表，这两个表格充当当前任务的线性地址到物理地址的查找表。 在 x86 体系结构中，线性地址的转换采用双级查找方式。32 位的线性地址分为三个部分： 最高 10 位：用于页目录表偏移量。 中间 10 位：用于页表偏移量。 最低 12 位：表示物理页内的字节偏移量。 页目录表的大小为 4KB，包含 1024 项，每一项占用 4 字节，这些项目中存放的是页表的物理地址。若页目录表中的某项尚未分配，则对应的物理地址为 0。页表的结构类似，也为 4KB，同样包含 1024 项，且每项也占用 4 字节，内容为最终物理页的物理内存起始地址。 每个活动任务必须拥有自己的页目录表，并将其物理地址存入 CR3 寄存器。页表可以在需要时动态分配，或者在任务创建时提前分配。 以 mov 0x80495b0, %eax 中的地址为例，分析线性地址转物理地址的过程。前面提到，Linux 中的逻辑地址等于线性地址，因此需要转换的线性地址是 0x80495b0。这个转换过程由 CPU 自动完成，而 Linux 仅需准备相关的页目录表和页表（假设这些表已经准备好）。 内核首先将当前任务的页目录表物理地址填入 CR3 寄存器。将线性地址 0x80495b0 转换为二进制，得 0000 1000 0000 0100 1001 0101 1011 0000。最高 10 位 0000 1000 00 的十进制为 32，CPU 将查看页目录表的第 32 项，获取的内容为页表的物理地址。中间的 10 位 00 0100 1001 的十进制为 73，页表第 73 项则存储最终物理页的物理起始地址。通过物理页的基地址加上线性地址最低 12 位的偏移量，CPU 找到了对应的物理内存单元。 在 Linux 中，用户进程的线性地址范围为 0 到 3GB，是否需要提前创建这 3GB 虚拟内存的所有页表呢？实际上，物理内存通常远小于 3GB，并且多个进程同时运行，无法为每个进程都建立完整的页表。Linux 通过 CPU 的“缺页异常”机制巧妙解决了这个难题。当进程创建时，可以将页目录表的条目都设为 0。当进程试图访问未分配的页时，若页表项中的内容为 0，就会引发缺页异常，进程会在此时暂停。Linux 内核会根据一系列复杂的算法分配一个物理页，并将该物理页地址填写到页表项中，随后进程继续执行。在此过程中，虽然发生了异常，进程并未感知到，仍然像正常访问物理内存一样进行操作。","categories":["1.平台","Linux","程序"]},{"title":"用户管理","path":"/2024/12/05/1-平台-Linux-系统参数-用户管理/","content":"用户与用户组Linux 如何分辨用户在 Linux 系统中，用户并不是通过他们的用户名被识别的，而是通过一个称为 UID（用户 ID）的数字。计算机更容易处理数字，而人类则更易记住文字。这就是为何们通常使用用户名的原因。每个文件其实是通过 UID 来标识用户，显示的用户名如”vagrant”或”root”，是因为相关信息被存储在 /etc/passwd 这一文件中。具体来说，ls 命令在显示文件信息时，会查询 /etc/passwd 文件，将 UID 转换为们熟悉的用户名。如果修改了 /etc/passwd 中的 UID，ls 就会显示 UID 而非用户名。 以下是用户登录到 Linux 系统的流程： 用户输入用户名。 系统查找 /etc/passwd，验证用户信息。 从文件中读取 UID 和 GID（组 ID），以及用户的主目录和默认 shell。 系统查找 /etc/shadow，核对与用户关联的密码。 登录成功后，用户进入 shell。 vagrant@saltmaster:~$ ls -ltotal 256-rw-r--r-- 1 root root 256191 Nov 13 06:26 bootstrap-salt.sh-rw-rw-r-- 1 vagrant vagrant 0 Nov 26 08:44 file_a-rw-r--r-- 1 root root 100 Nov 20 06:30 nettools.sls 在上述例子中，可以看到各个文件的拥有者是通过 UID 识别并显示用户名的。 当查看 /etc/passwd 文件内容时： vagrant@saltmaster:~$ cat /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologin... 每一行代表一个账户，字段通过冒号进行分割。总共有 7 个字段，分别为： 用户名 密码占位符（通常为 x） UID GID 用户信息说明 主目录（用户登录后默认所在的位置） shell（用户登录后启动的 shell，如 /bin/bash） passwd 文件和 shadow 文件所有的用户信息存储在 /etc/passwd 文件中，而密码信息则被更安全地存储在 /etc/shadow 中，以增强安全性。密码移动到 /etc/shadow 后，/etc/passwd 中只保留一个占位符”x”。 /etc/shadow 文件的格式如下： vagrant@saltmaster:~$ sudo head -n 4 /etc/shadowroot:!:17466:0:99999:7:::daemon:*:17379:0:99999:7:::bin:*:17379:0:99999:7:::sys:*:17379:0:99999:7::: 每行对应一个账户，字段含义如下： 账户名称 密码（用符号如 ! 或 * 表示用户禁用） 最近改动密码的日期（以 1970 年 1 月 1 日为基准） 密码不可改动的日期（0 则可以随时修改） 密码过期前的提醒时间 过期宽限期 账户失效日期 保留字段 有效用户组与初始用户组在 Linux 中，每个用户都有一个用户组。与 UID 相似，用户组是通过 GID（组 ID）来识别的。同样，对于用户组，Linux 也有相应的文件 /etc/group 和 /etc/gshadow。 查看 /etc/group 文件： vagrant@saltmaster:~$ cat /etc/groupwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologinbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin 每一行记录一个用户组的信息，字段分别为： 用户组名称 密码（通常用 x 占位） GID 用户组成员列表（用逗号分隔） /etc/gshadow 文件内容示例： vagrant@saltmaster:~$ sudo head -n 4 /etc/gshadowroot:*::daemon:*::bin:*::sys:*:: 在这个文件中，第二个字段也是密码，如果这个字段为 !，则表示该用户组没有组管理员的权限。 一个常见问题是，为什么 /etc/passwd 中用户的用户组 ID 并不在 /etc/group 中列出？这是因为，/etc/passwd 中的用户组称为”初始用户组”，意味着当用户登录到 shell 时，所依据的用户组。该用户组不需要在 /etc/group 列表中显示。 当用户属于多个用户组时，他会获得所有这些组的权限。文件的默认组是”有效用户组”。可以通过命令 groups 查看到当前用户的所有用户组。其中第一个用户组是有效用户组，用于创建新文件。 示例命令： vagrant@saltmaster:~$ groupsadm cdrom sudo dip plugdev lxd lpadmin sambashare vagrant 使用 newgrp 命令可以在新的 shell 中切换用户组，最后通过使用 exit 可以返回到之前的用户组。 vagrant@saltmaster:~$ newgrp sudovagrant@saltmaster:~$ touch test_b 以上命令使得用户能够在 sudo 用户组下创建文件 test_b，该文件的属性如下： vagrant@saltmaster:~$ ll test_*-rw-rw-r-- 1 vagrant adm 0 Nov 26 15:46 test_a-rw-rw-r-- 1 vagrant sudo 0 Nov 26 15:47 test_b 通过这些过程，可以清晰地看到在 Linux 中，用户和用户组的处理是如何进行的，及其如何保持系统的安全性与组织性。 创建与管理用户useradd在熟悉了用户和用户组的基本概念后，们现在进入用户管理的实际操作部分。创建一个新的用户账户的命令是 useradd。请注意，该命令需要对系统文件（如 /etc/passwd 等）具有读写权限，因此一般需要以 root 用户身份执行。 以下是使用 useradd 创建一个名为 tom 的账户的示例： vagrant@saltmaster:/home$ useradd tomuseradd: Permission denied.useradd: cannot lock /etc/passwd; try again later. 在尝试执行命令时，系统提醒权限不足，这说明当前用户没有足够权限。接着，们可以使用 sudo -s 切换到 root 用户： vagrant@saltmaster:/home$ sudo -sroot@saltmaster:/home# useradd tom 在成功执行后，们可以通过以下命令查看新创建的用户在系统中的记录： root@saltmaster:/home# grep tom /etc/passwd/etc/passwd: tom:x:1001:1001::/home/tom: 这行输出显示，系统为用户 tom 在 /etc/passwd 文件中添加了一条记录，其中包含了用户的基本信息。此外，在 /etc/shadow 中也有相应的条目，密码字段为空，表示该用户尚未设置密码： root@saltmaster:/home# grep tom /etc/shadow/etc/shadow: tom:!:17496:0:99999:7::: 用户组信息也被添加到了 /etc/group 中： /etc/group: tom:x:1001: 尽管执行命令成功，但没有为 tom 用户创建家目录，这在 CentOS 系统中是常见的情况。可以通过修改系统配置来改变这一默认行为。 另外，使用 useradd 命令时，Linux 系统会自动应用一些默认参数。通过运行以下命令，可以查看这些默认配置： vagrant@saltmaster:~$ useradd -D 比如，系统会设置组 ID（GROUP）、家目录（HOME）、默认 shell（SHELL）等，具体默认值一般存储在 /etc/default/useradd 文件中。 passwd创建用户后，需要为新账户设置密码，这需要使用 passwd 命令。例如： root@saltmaster:/home# passwd tom 在执行该命令时，系统会提示输入 tom 用户的新密码。普通用户在修改自己密码时需要输入旧密码，而 root 用户则不需要。 其他修改账户的命令（sudo）除了创建用户和设置密码外，Linux 还提供了一些命令来修改账户属性： chage：用于修改与密码有关的账户参数，例如密码的失效日期等。 usermod：可以用来修改用户的有效组、初始组和主目录等信息。 userdel：此命令用于删除用户，需谨慎使用，因为会将用户相关的记录从 /etc/passwd 和 /etc/shadow 中删除，并且会删除用户的主目录。通常情况下，可以先将账户状态设置为不可用，而不是直接删除。 如果确实需要删除用户，使用 userdel -r username 命令可以同时删除用户以及其主目录及相关文件。 用户可以使用的一些命令除了管理账户的命令外，普通用户也可以执行一些基本命令： passwd：用户可以用该命令修改自己的密码。 chage -l username：查看用户的密码和帐户信息。 finger：查询用户相关的信息。 chfn：修改用户的详细信息。 chsh：改变默认登录的 shell。 id：查询用户的 ID 信息。 用户组的管理关于用户组的管理，命令与用户管理相似，主要涉及 /etc/group 和 /etc/gshadow 文件。使用 newgrp 命令可以开启一个新的 shell，以新环境登录用户和用户组。这个命令的使用可以让用户在不同的组中切换，但实际的组权限检验是基于进程的有效组 ID。 精确的权限控制 - ACL在 Linux 文件系统中，默认的权限管理是基于”所有者、组和其他人”三组权限的。对于同一个用户组内的成员或属于”其他人”的成员，权限的细致控制是有限的，因此引入了 ACL（Access Control List）。ACL 能够针对特定用户和特定文件或目录设置读、写、执行权限。使用 ACL 需要系统文件系统的支持，可以通过命令 mount | grep acl 检查当前文件系统是否支持此功能。 用户切换 - su, su - 和 sudo用户在 Linux 中切换身份的常用命令是 su。命令的格式为 su - username，其中 - 表示将用户的所有环境变量切换为目标用户的环境，如 su - vagrant 将切换到 vagrant 用户，改变所有的环境变量。 使用 su - root 可直接以 root 身份登录。如果只需要临时运行一个命令，可以使用 su - root -c command 格式，其中的 root 可以省略。 然而，每个人都使用 root 权限的需求可能导致不安全，所以引入了 sudo 命令。sudo 允许用户以其他用户的身份（通常是 root）执行命令。在使用 sudo 之前，用户必须在 /etc/sudoers 文件中进行授权。 sudores 文件支持对用户组的授权，使用 % 符号来表示用户组。例如，可以设置某个用户组的权限： root ALL=(ALL) ALL 此外，可以在条目中添加 NOPASSWD: ALL 来免除每次使用 sudo 时输入密码的要求。","categories":["1.平台","Linux","系统参数"]},{"title":"HTTP数据包头","path":"/2024/12/04/1-平台-Linux-网络-HTTP数据包头/","content":"一、连接至 Web 服务器在 Web 技术的世界中，客户端应用（如 Web 浏览器）首先需要连接到 Web 服务器的 HTTP 端口，默认端口为 80。在实际使用中，连接的地址可能包括特定的端口号，例如： http://www.myweb.com:8080/index.html 在 Java 代码中建立连接的相应方式如下： Socket socket = new Socket(www.myweb.com, 8080); 这里，通过 socket 类的构造函数创建一个到指定主机和端口的连接。 二、发送 HTTP 请求一旦建立连接，客户端会向服务器发送一个请求。HTTP 请求是 ASCII 文本格式，通常包括以下四个部分：请求行、请求头标、空行和请求数据。 请求行：请求行由三个部分组成： 请求方法（如 GET、POST 等） 请求 URI（请求资源的路径） HTTP 版本（如 HTTP1.1） 示例请求行： GET /index.html HTTP/1.1 HTTP 规范定义了常用的请求方法，包括： GET：用于检索资源。 HEAD：与 GET 相似，但服务器只返回响应头。 POST：用于提交数据给服务器。 PUT：用于上传文件到指定路径。 DELETE：删除指定 URI 资源。 OPTIONS：查询服务器支持的请求方法。 TRACE：环回请求，用于诊断。 CONNECT：用于建立一个网络连接的隧道（如 HTTPS）。 请求头标：请求头标由关键字和对应的值组成，通常采用“关键字: 值”的格式。常见的请求头标包括： User-Agent：指示客户端软件的信息（如浏览器类型和版本）。 Accept：客户端可以处理的内容类型列表，如 Accept: text/html, application/json。 Content-Length：请求体中数据的长度，以字节为单位。 空行：请求头标结束后，客户端发送一个空行，表示头部信息完结。这个空行通常是一个回车符和换行符的组合。 请求数据：当使用 POST 方法时，请求数据将随之而来。常常伴随着 Content-Type 和 Content-Length 头标，指明数据的媒体类型及其字节长度。 Socket socket = new Socket(www.myweb.com, 8080);InputStream in = socket.getInputStream();OutputStream out = socket.getOutputStream(); 三、服务端接受请求并返回 HTTP 响应Web 服务器接收到请求后，会解析这些信息并定位所请求的资源。随后，服务器会将资源的副本写入到套接字中，允许客户端读取。 一个响应通常包含四个部分：状态行、响应头标、空行和响应数据。 状态行：状态行由三个部分组成： HTTP 版本 响应代码（三位数字） 响应描述 例如： HTTP/1.1 200 OK 响应代码的分类： 1xx：信息性，表示请求已被接收且正在处理。 2xx：成功，表示请求成功被接受和处理。 3xx：重定向，表示后续操作需要继续进行。 4xx：客户端错误，表示请求有误或无法满足。 5xx：服务器错误，表示服务器无法满足请求。 响应头标：响应头标类似于请求头标，提供关于响应数据的细节和服务器的属性。例如： Date：表示响应生成的时间。 Content-Length：内容的字节长度。 Content-Type：资源的类型，如 Content-Type: text/html。 空行：响应头标后面的空行，表明后续数据为响应体。 响应数据：实际返回的数据体，例如 HTML 文档或图像文件。 四、服务器关闭连接，浏览器解析响应 浏览器解析状态行，以检查请求是否成功（通过状态代码判定）。 接续浏览器解析每个响应头标，这些头标表明接下来的数据字节数。 读取响应数据后，浏览器会依照 HTML 语法对其进行格式化，并在窗口中展示。 若 HTML 文档中包含其他资源（如 CSS 样式表、图像），浏览器会发起额外的请求加载这些资源，而该过程可能重复多次。 五、无状态连接HTTP 协议的无状态特性意味着每个请求都是独立的，服务器不会保存任何关于先前请求的状态。每次请求都是离散的，没有上下文关联。 六、实例示例 1 - 首次请求 浏览器发送请求： GET /index.html HTTP/1.1 服务器返回响应： HTTP/1.1 200 OKDate: Apr 11 2006 15:32:08 GMTServer: Apache/2.0.46(win32)Content-Length: 119Content-Type: text/htmlHTMLHEADLINK REL=stylesheet HREF=index.css/HEADBODYIMG SRC=image/logo.png/BODY/HTML 示例 2 - 请求 CSS 文件 浏览器发送请求： GET /index.css HTTP/1.1 服务器返回响应： HTTP/1.1 200 OKDate: Apr 11 2006 15:32:08 GMTServer: Apache/2.0.46(win32)Connection: Keep-alive, closeContent-Length: 70Content-Type: text/plainh3 font-size: 20px; font-weight: bold; color: #005A9C; 示例 3 - 请求图像文件 浏览器发送请求： GET image/logo.png HTTP/1.1 服务器返回响应： HTTP/1.1 200 OKDate: Apr 11 2006 15:32:08 GMTServer: Apache/2.0.46(win32)Connection: Keep-alive, closeContent-Length: 1280Content-Type: image/pngBinary image data follows 附录1. HTTP 规范HTTP 协议的标准文档由 Internet 工程制定组织（IETF）发布的 RFC（请求评论）文件来规范。由于这些 RFC 在网络行业被广泛接受，因此被誉为标准文档。 2. RFCRFC 文档编写后就会被分配一个号码并保持不变，当新版本发布时，旧版会获得新的 RFC 编号。这也就意味着，标准可能会随着技术的发展而更新演变。 3. HTTP 的几个重要 RFC RFC1945：描述了 HTTP 1.0 的基本特性。 RFC2068：初步描述 HTTP 1.1。 RFC2616：正式规范 HTTP 1.1。 4. 资源标识符 URI统一资源标识符（URI）用于标识互联网上的资源。 HTTP 响应码响应码是由三位数字组成，表示请求的处理结果，按第一位数字分类为以下五种类型： 1xx：信息性（请求已接收，继续处理） 2xx：成功（请求已成功处理） 3xx：重定向（需要进一步操作以完成请求） 4xx：客户端错误（请求不合法或无法完成） 5xx：服务器错误（服务器未能完成合法的请求） 响应代码 含义 100 继续 200 OK 301 永久性移动 404 未找到资源 500 内部服务器错误 HTTP 头标HTTP 头标由主键与值对构成，描述客户端或服务器的属性、传输的资源、以及连接信息。头标可分为以下四种类型： 通用头标：可用于请求和响应。 请求头标：允许客户端传递自身的相关信息。 响应头标：服务器用于传递自身信息。 实体头标：定义被传送资源的信息。 头标的格式通常是： name:valueCRLF 头标名 描述 Accept 客户端可以处理的媒体类型列表 Content-Length 请求或响应中数据的字节长度 User-Agent 发起请求的软件类型（如浏览器） Content-Type 发送或接收的实体的 MIME 类型 此外，HTTP 的头标有助于更好地识别和处理请求和响应，从而提高 Web 应用的效率和用户体验。","categories":["1.平台","Linux","网络"]},{"title":"Samba服务","path":"/2024/12/03/1-平台-Linux-网络-Samba服务/","content":"SMB 协议和 Samba SMB 协议（Server Message Block，服务信息块）是一种网络协议，它允许不同操作系统之间共享文件、打印机和其他网络资源。SMB 在各种环境中广泛使用，包括企业内网和云计算服务。它可以实现诸如文件传输、访问共享目录和打印机等功能。 Samba是一套让 Linux 系统能够支持 SMB 协议的软件集合。它实现了 TCPIP 协议栈，成为 Windows 网络中进行文件和打印共享的核心组件。Samba 不仅允许 Linux 系统访问 Windows 共享，还可以让 Windows 计算机访问 Linux 共享资源。 Samba 的核心由两个守护进程组成： smbd：这个进程监听 TCP 端口 139，主要处理进入的 SMB 数据包，负责提供文件服务。 nmbd：这个进程监听 UDP 端口 137 和 138，帮助其他计算机发现和访问 Linux Samba 服务器，包括提供工作组和名称解析服务。 安装 Samba 必装包：安装 Samba 的基本包是必不可少的，可以通过以下命令安装： # rpm -ivh samba-common-2.2.7a-7.9.0.i386.rpm# rpm -ivh samba-2.2.7a-7.9.0.i386.rpm# rpm -ivh samba-client-2.2.7a-7.9.0.i386.rpm 选装包：一些功能性扩展的包可以选择性安装，以增强 Samba 的功能： # rpm -ivh redhat-config-samba-1.0.4-1.noarch.rpm# rpm -ivh samba-swat-2.2.7a-7.9.0.i386.rpm Red Hat 9.0 中 Samba 的默认配置 配置文件：Samba 的主要配置文件位于 /etc/samba/smb.conf。 默认设置： 工作组：MYGROUP 安全等级：user（意味着需要用户认证） 密码加密设置：Yes（启用用户密码加密） 口令文件路径：etcsambasmbpasswd（存储用户凭证的文件） PAM 认证遵循：Yes（认证过程遵循 PAM 管理） 客户 DNS 查询：No（不允许 DNS 查询） 主目录共享：每个用户的主目录均被共享 打印机共享：所有打印机均可共享 建立 Samba 密码文件设置 Samba 账户 建立 Samba 密码文件的必要性：当设置用户密码加密为 Yes 和安全等级为 user 时，需建立密码文件。 添加 Samba 账户：使用以下命令为用户添加 Samba 账户： # smbpasswd -a username 修改 Samba 账户密码： # smbpasswd username 创建系统账户：如果指定的 Samba 用户的系统账号不存在，需先用以下命令添加： # useradd username 检测配置文件并启动 Samba 服务器 检测配置文件：运行以下命令检查 Samba 配置文件的正确性： # testparm 启动和管理 Samba 服务：Red Hat 的 Samba 通常以独立服务的方式运行，使用以下命令启动、停止或重启 Samba 服务： # service smb start# service smb stop# service smb restart 从客户机访问 Samba 共享 检查 Samba 服务器资源：使用以下命令查看共享资源： # smbclient -L IP -U username 访问共享：可以通过以下命令使用 smbclient 访问共享资源： smbclient //NetBIOS名或IP地址/共享名 -U 用户名 挂载共享：也可以通过以下命令将共享挂载到本地目录： smbmount //IP/share /挂载点 -o username=用户名 注意事项： 当访问 Windows 共享时，smbclient 命令的 -U 选项后指定的 username 需要是 Windows 计算机中的用户账户，验证口令为该 Windows 账户的口令。 当访问 Linux 的 Samba 共享时，smbclient 的 -U 选项后指定的 username 应为 Linux 计算机中 Samba 用户账户，验证口令为该 Samba 账户的口令。 Samba 配置基础－smb.conf 文件的结构 smb.conf 文件结构：该文件采用分节的结构，类似于 Windows 中的.INI 文件，方便用户进行配置和管理。 主要节内容： [Userdefined_ShareName]：用户自定义的共享名称，可以有多个共享定义。 [Printers]：用于配置打印机共享。 [Homes]：用于定义每个用户的 Home 目录共享。 [Global]：用于配置全局参数和缺省值。 配置 Samba 文件共享举例 为所有用户配置只读共享：可以设置共享目录的权限为只读，确保数据不会被修改。 为所有用户配置读写共享：允许用户对共享文件享有读和写的权限，适合需要协作编辑的场景。 为指定用户配置 Samba 共享：可以为特定用户设置访问权限，只有该用户可以访问指定的共享目录。 为指定组配置 Samba 共享：通过组权限管理，实现对多个用户的统一管理。 为指定用户和组配置 Samba 共享：结合用户与组权限，实现更加灵活的共享策略。 配置访问 Samba 共享组用户的不同权限：通过细粒度的权限设置，确保每个用户在共享中的权限制衡。","categories":["1.平台","Linux","网络"]},{"title":"tcpdump抓包","path":"/2024/12/02/1-平台-Linux-网络-tcpdump抓包/","content":"Linux 环境下抓包工具的使用1. Tcpdump 工具的介绍Tcpdump 是一种用于分析网络流量的强大命令行工具。在 Linux 环境中，它为网络管理员和开发人员提供了监控和调试功能。Tcpdump 的基本命令格式如下： tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ] [ -i 网络接口 ] [ -r 文件名] [ -s snaplen ] [ -T 类型 ] [ -w 文件名 ] [表达式] 2. Tcpdump 的选项介绍Tcpdump 提供多种选项，可以灵活控制抓包行为，下面是一些主要选项： -a: 将网络地址和广播地址转换为可读的名称，便于理解。例如，可以将 IP 地址转换为主机名。 -d: 以人类可读的汇编代码格式显示匹配的数据包的信息，便于开发者理解数据包的作用。 -dd: 输出 C 语言程序段的形式，这对于需要进一步编程分析的用户非常有效。 -ddd: 显示匹配信息包的十进制格式，对于原始数据处理非常实用。 -e: 在输出中包含数据链路层的头部信息，提供更低层次的数据细节。 -n: 不将网络地址转换为名称，从而提高捕获速度，适合对性能要求较高的场景。 -v: 提供比默认更详细的输出信息，例如 TTL（生存时间）和服务类型。 -w: 将捕获的数据包直接写入文件，便于后续分析。 表达式Tcpdump 的筛选表达式可分为三类： 类型的关键字: host 210.27.48.2: 指定某一主机的流量。 net 202.0.0.0: 指定某一网络的所有流量。 port 23: 指定某一特定端口的流量。 默认情况下，不指定类型时将使用 host。 传输方向的关键字: src 210.27.48.2: 指定源地址为该 IP 的数据包。 dst net 202.0.0.0: 指定目的地址为该网络的数据包。 传输方向关键字的组合可用于灵活过滤数据包。 协议的关键字: tcp, udp, arp, ip 等：用于指定协议类型，抓取特定协议的数据包。 默认情况下，如果不指定协议，Tcpdump 将监听所有协议的数据包。 逻辑运算Tcpdump 支持三种逻辑运算符，用于构建复杂的抓包条件： NOT: 使用 not 或 ! 进行取反。 AND: 使用 and 或 连接多个条件。 OR: 使用 or 或 || 达成逻辑或的效果。 示例命令以下示例展示了 Tcpdump 的具体用法： 启动 Tcpdump 监听所有数据包: tcpdump 指定网卡监听: tcpdump -i eth0 根据主机截获数据: tcpdump host 210.27.48.1 截获和两台主机之间的通信: tcpdump host 210.27.48.1 and (host 210.27.48.2 or host 210.27.48.3) 获取 IP 包，排除特定主机: tcpdump ip host 210.27.48.1 and not 210.27.48.2 监控 Telnet 流量: tcpdump tcp port 23 host 210.27.48.1 监控 NTP 服务流量: tcpdump udp port 123 通过网关监控数据包: tcpdump -i eth0 gateway Gatewayname 抓取到特定端口的 TCP 或 UDP 数据包: tcpdump -i eth0 host hostname and port 80 数据包捕获的注意事项在使用 Tcpdump 时，应注意系统的存储空间，以防数据包超过硬盘容量。此外，如果需要分析捕获的数据包，建议使用 -w 参数将数据包保存到文件，然后借助其他工具进行深入分析。 例如，执行以下命令将抓取的数据包保存为文件： tcpdump -w captured_packets.pcap 之后，可以使用 Wireshark 等工具对文件进行详细解码分析。 通过适当地使用 Tcpdump 的各种功能，可以高效、准确地对网络流量进行监控和调试，为网络安全和性能优化提供支持。","categories":["1.平台","Linux","网络"]},{"title":"局域网扫描","path":"/2024/11/29/1-平台-Linux-网络-局域网扫描/","content":"使用 Nmap 进行局域网扫描使用 Nmap 进行局域网扫描是一种常见且有效的方法，可以帮助确定网络中活跃的设备及其相应的 MAC 地址。这一过程涉及多种命令，用于不同类型的扫描和信息收集。 基础扫描步骤 局域网扫描:使用以下命令可以扫描整个子网并打印出响应的主机： nmap -sP 192.168.1.0/24 此命令使用 -sP 参数进行 ping 扫描，目标是在指定的子网（192.168.1.024）中寻找存活的主机。运行这条命令时，需要输入执行这一操作的用户的密码。以下是命令执行后生成的报告示例： Nmap scan report for promote.cache-dns.local (192.168.1.1)Host is up (0.066s latency).MAC Address: A8:57:4E:A7:53:F8 (Unknown) 从输出结果可以看到，nmap 报告了多个 IP 地址以及对应的 MAC 地址和延迟。例如，IP 地址 192.168.1.1 是活动的，延迟为 0.066 秒，而其 MAC 地址为 A8:57:4E:A7:53:F8。有些设备的制造商信息也可以被识别出来，例如： Nmap scan report for promote.cache-dns.local (192.168.1.100)Host is up (0.91s latency).MAC Address: 90:4C:E5:C6:92:71 (Hon Hai Precision Ind. Co.) 这里，Hon Hai Precision Ind. Co. 是设备的制造商。最终报告显示，总共扫描了 256 个 IP 地址，其中有 7 台设备处于活动状态，耗时约 15.85 秒。 可以通过管道将输出结果与 grep 结合，以过滤出存活的主机，例如： nmap -sP 192.168.1.0/24 | grep up 这将只返回状态为“up”的主机，有助于快速识别活动设备。 列出主机:如果想仅列出网络中的所有主机，而不发送任何报文到目标主机，可以使用： nmap -sL 192.168.1.0/24 端口扫描:为了探测目标主机开放的特定端口，可以指定端口列表。示例如下： nmap -PS 192.168.1.234 -p 22,23,25,80 该命令会探测 IP 为 192.168.1.234 的主机是否开放了 22、23、25 和 80 端口。-PS 表示使用 TCP SYN 包进行探测。 UDP 探测:使用 UDP ping 探测主机的命令如下： nmap -PU 192.168.1.0/24 UDP 探测能够识别出那些未响应 TCP 请求的设备。 半开放扫描:同样常用的还有声称为 SYN 扫描的半开放扫描。这种扫描方式不会完成 TCP 三次握手，因此执行速度非常快： nmap -sS 192.168.1.0/24 ARP 缓存查看在执行完扫描后，可以查看 ARP 缓存表，以获取 IP 地址对应的 MAC 地址。使用以下命令： cat /proc/net/arp 此时显示的表格将提供已知主机的 IP 和相应的 MAC 地址。 Nmap 在 Linux 中的使用安装 Nmap在 CentOS 中，可以通过以下命令安装 Nmap： yum install nmap 常用扫描命令示例以下是几种常用的 Nmap 扫描举例： 针对 C 段存活主机的探测: nmap -sP 1.1.1.1/24 SYN 扫描指定端口:这将扫描指定 IP 范围内的端口 80： nmap -sS 1.1.1.1-30 -p 80 端口服务及版本探测:执行如下命令可扫描所有 1 至 65535 端口，抓取服务版本信息： nmap -sV 1.1.1.1 -p 1-65535 操作系统探测:使用以下命令可以探测操作系统类型和版本： nmap -O 1.1.1.1 或使用： nmap -A 1.1.1.1 后者不仅探测操作系统，还会进行服务版本、脚本扫描等全面信息收集。 使用 shell 脚本编写 shell 脚本是一种有效的方法，可以批量处理多个任务，特别是网络扫描。以下是一个简单的脚本 ip_disc.sh，它通过发送 ping 请求来检查特定子网中的设备是否在线： $ cat ip_disc.sh#!/bin/bashfor i in `seq 1 254`doping -c5 192.168.1.$i /dev/null echo 192.168.1.$i is alivedonewait 这个脚本使用 for 循环遍历 1 到 254 的所有 IP 地址。对于每个地址，它执行 ping 命令，发送 5 个包（-c5），并将输出重定向到 /dev/null 以避免干扰。在 ping 成功后，脚本会输出相应的 IP 地址，表示该设备是存活的。在脚本的结尾，wait 命令确保所有后台进程完成后再结束执行。 执行该脚本后，输出结果可能如下： $ ./ip_disc.sh192.168.1.113 is alive192.168.1.111 is alive192.168.1.1 is alive192.168.1.114 is alive192.168.1.110 is alive192.168.1.100 is alive192.168.1.105 is alive192.168.1.122 is alive 这样，脚本成功识别了多个有效的设备 IP 地址，便于管理员进行后续的网络管理和故障排查。 Nmap 概述Nmap（网络映射工具）支持多种扫描技术，能够有效探测网络中的设备与服务。这些技术包括： UDP 扫描 TCP connect()扫描 TCP SYN（半开扫描） FTP 代理（Bounce 攻击） 反向标志扫描 ICMP 扫描 FIN 扫描 ACK 扫描 圣诞树（Xmas Tree）扫描 Null 扫描 此外，Nmap 还提供了一些高级特性，包括： 操作系统探测：根据 TCPIP 协议栈的特征识别主机操作系统类型。 秘密扫描：隐蔽方式探测服务。 动态延时与重传计算：优化探测方法。 并行扫描：同时探测多个主机。 诱饵扫描：通过伪装请求绕过防火墙检测。 直接 RPC 扫描：无需进行端口映射。 碎片扫描：分段数据包传输，以规避某些类型的监控。 Nmap 通常会返回知名端口的服务名称、端口号、状态和协议等信息。端口的可能状态包括： open：表示目标主机的端口可被连接。 filtered：防火墙或包过滤器阻止 Nmap 探测该端口状态。 unfiltered：端口关闭，但未受到防火墙的阻隔。 大多数情况下，未被过滤的端口会呈现为 unfiltered 状态，但如果大多数端口受限，则该状态的端口才会被报告。 此外，Nmap 还可以报告其他诸如操作系统、TCP 序列、运行在每个端口上的应用程序的用户名、DNS 名、主机地址等信息。可以使用命令 nmap -h 快速查看所有功能选项的列表。 Nmap 语法Nmap 的基本扫描命令结构为： nmap [Scan Type(s)] [Options] 扫描类型-sTTCP connect()扫描：这是最基础的 TCP 扫描方式。通过操作系统提供的 connect()系统调用打开连接。如果目标端口上有程序监听，connect()就会成功返回，否则将报告该端口不可达。此方法的一个明显优点是，不需要 root 权限，任意 UNIX 用户均可使用。然而，因为会在目标主机的日志中留下连接请求的痕迹，这种扫描方式容易被监测到。 -sSTCP SYN 扫描：此类扫描被称为半开扫描（half-open），因为它发送一个 TCP SYN 包。但只有收到的响应会被记录：如果对方返回 SYN|ACK 包，表示目标端口正在监听；如果返回 RST 包，则表明没有程序在监听。操作系统内核会自动发送 RST 包以断开连接，不会被记录到日志。这种技术虽然隐蔽，但需要 root 权限以发送自定义 SYN 包。 -sF, -sX, -sN秘密 FIN 数据包扫描、圣诞树（Xmas Tree）扫描、Null 扫描：这些扫描方式在使用 SYN 扫描未果时，作为高级手段进行探测。它们利用了以下原理：关闭的端口需要对探测包返回 RST 包，而开放的端口会选择忽略这些异常包（参考 RFC 793 第 64 页）。FIN 扫描发送 FIN 包，而圣诞树扫描则打开 FIN、URG 和 PUSH 标志。值得注意的是，Windows 系统不完全遵循此标准，因此这些扫描在 Windows 平台上往往无效。 -sPPing 扫描：为确认网络中的活跃主机，Nmap 会向每个 IP 地址发送 ICMP echo 请求。若目标主机正常运行，它将响应请求。然而，一些域名（如 microsoft.com）可能阻止 ICMP 请求。在此情况下，Nmap 还会尝试向 80 端口发送 TCP ACK 包以获取响应。常规上，对于非 root 用户，Nmap 将使用 connect()方法进行探测。 以默认设置（root 用户），Nmap 将并行使用 ICMP 与 ACK 技术进行探测。仅在主机处于运行状态时，Nmap 才会进行后续扫描。 -sUUDP 扫描：若需了解主机开放的 UDP 服务，Nmap 会向每个 UDP 端口发送一个 0 字节包。若接收到端口不可达的 ICMP 消息，则认为该端口关闭；否则假设为开放。UDP 服务如 SNMP、TFTP、NFS 等均基于 UDP 协议。UDP 扫描可能较慢，因为许多主机对 ICMP 错误消息的返回频率有所限制。例如，Linux 系统每 4 秒返回不超过 80 条 ICMP 不可达消息，而 Solaris 每秒仅允许大约 2 条，这导致 UDP 扫描变得慢，而对于 Windows 系统则没有此限制。 -sAACK 扫描：这项高级扫描技术帮助穿透防火墙，通常用于判断防火墙的复杂程度。向特定端口发送 ACK 包, 若返回 RST 包，则标记为 unfiltered 状态；若无响应或收到不可达的 ICMP 消息，则标记为 filtered 状态。 -sW滑动窗口扫描：该技术与 ACK 扫描相似，但有时可以识别开放端口，因为某些操作系统可报告其滑动窗口的大小。这种方法适用于多种操作系统，一些如 AIX 和 OpenBSD 等。 -sRRPC 扫描：此方法与其他扫描结合，向所有开放的端口发出 RPC 程序的 NULL 命令，确定其是否为 RPC 端口，并获取对应软件及版本信息。通过此技术，可能获得一些防火墙的信息。 -bFTP 反弹攻击（Bounce 攻击）：FTP 协议允许通过代理 FTP 连接，利用此特性进行 TCP 端口扫描。只需连接到前置 FTP 服务器，便可以对目标进行扫描，甚至向目标端口发送数据。此功能需要指定一个具备可读写目录的代理 FTP 服务器。 通用选项这些选项不是必需的，但可提供额外的功能： -P0：在扫描前不进行 ping，以便在 ICMP 被阻止的网络中执行扫描。 -PT：在扫描前使用 TCP ping 确认主机是否运行，通常向端口 80 发送 ACK 包。 -PS：对于 root 用户，使用 SYN 包替代 ACK 包进行扫描，收到 RST 包即表示主机运行。 -PI：使用 ICMP echo 请求确认主机运行，此选项还能观察子网广播地址。 -PB：默认的 ping 扫描选项，结合 ACK 与 ICMP 两种方法并行扫描。 -O激活 TCPIP 指纹特征扫描，识别远程主机的操作系统和网络协议栈特征，通过比较已知指纹数据库确定目标主机的操作系统类型。 -I开启反向标志扫描，利用 ident 协议确定进程拥有者的用户名。这一扫描需在目标端口建立完整的 TCP 连接才能成功。 -f使用分片 IP 数据包发送各种探测包（如 SYN、FIN、XMAS、NULL），增加包过滤和入侵检测系统识别探测意图的难度。然而，使用此选项可能导致某些程序运行上的问题。 -v冗余模式，提供扫描过程中的详细信息，使得用户更清楚操作进度。使用 -d 选项可提高详细程度。 -h快速参考选项，简洁展示所有可用的命令与参数。 -oN -oM重定向扫描结果，前者为可读文件，后者为机器可解析的文件格式。可以输出到标准输出，覆盖正常输出并将错误信息发送到标准错误。 使用示例以下命令可用于扫描局域网上的 MAC 地址： nmap -sP -PI -PT -oN ipandmaclist.txt 192.168.1.0/24 执行后，结果将保存在文件 ipandmaclist.txt 中，以便查阅各 IP 对应的 MAC 地址。","categories":["1.平台","Linux","网络"]},{"title":"邮件协议和SendMail","path":"/2024/11/28/1-平台-Linux-网络-邮件协议和SendMail/","content":"电子邮件系统的组成电子邮件系统的基本构成包括多个组件，每个组件在邮件的发送、接收、存储和管理中扮演重要角色： 邮件用户代理（Mail User Agent, MUA）MUA 是用户与邮件系统交互的工具，如 Microsoft Outlook 和 Mozilla Thunderbird。它提供了一个用户友好的界面，允许用户阅读、撰写和管理他们的电子邮件。 邮件传输代理（Mail Transfer Agent, MTA）MTA 负责在邮件服务器之间传输邮件。它确保邮件从发件方转发到接收方。例如，Postfix 和 Exim 都是常见的 MTA。 邮件提交代理（Mail Submission Agent, MSA, 587 端口）MSA 通常在端口 587 运行，专门用于用户向邮件服务器提交邮件。它处理用户的认证和邮件的初步发送。 邮件投递代理（Mail Delivery Agent, MDA）MDA 将邮件投递到最终用户的邮箱。它会将邮件存储在特定的邮箱中，供用户后续访问，示例包括 procmail 和 Dovecot。 邮件访问代理（Mail Access Agent, MAA）MAA 使用户能够访问他们的邮件。通过 IMAP 或 POP3 协议，用户可以从各种设备上查看和管理邮件。 邮件协议电子邮件的传输和交互依赖若干关键协议： SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）SMTP 是实现邮件发送的基础协议。它规定了邮件如何在不同的邮件服务器之间传递，确保邮件能够被准确路由到目标地址。 POP3（Post Office Protocol，邮局协议，第 3 版本）POP3 允许用户从邮件服务器上下载电子邮件。下载后，邮件一般会从服务器上删除，用户只能在本地设备上查看。 IMAP（Internet Message Access Protocol，网际消息访问协议，第 4 版本）IMAP 允许用户在不同设备上同步和管理邮件。用户可以查看、标记和分类邮件，而邮件始终保留在服务器上。 MIME（Multipurpose Internet Mail Extension，多用途互联网邮件扩展）MIME 扩展了电子邮件的功能，使其能够处理文本以外的内容，如图像、音频和视频。它通过标识内容类型让电子邮件支持各种文件格式。 sendmail 简介sendmail 的主要功能包括： 接收 SMTP 邮件sendmail 可以接收来自其他邮件服务器的邮件，确保邮件能够准确送达。 为邮件选择路由sendmail 根据预设规则和状态选择最佳路线，确保快速有效的邮件传递。 传输 SMTP 邮件促进邮件在网络中的传递，保证邮件不被丢失。 使用邮件别名支持使用别名和邮件列表，简化邮件地址的管理。 错误检测及优化sendmail 能够检测并报告传输错误，同时优化发送速度和成本。 安装和启动 sendmail在 RedHat AS 4 系统中，sendmail 提供了 RPM 包，用户可以通过以下步骤进行安装： 安装 sendmail 和相关工具： # rpm -ivh m4-1.4.1-13.i386.rpm# rpm -ivh sendmail-8.12.8-4.i386.rpm# rpm -ivh sendmail-cf-8.12.8-4.i386.rpm# rpm -ivh sendmail-doc-8.12.8-4.i386.rpm 启动和停止 sendmail 服务： # service sendmail start# service sendmail stop# service sendmail restart RedHat9 中 sendmail 的默认配置基于安全考虑，sendmail 在 RedHat 9 中将其守护进程分为两类： sendmail处理邮件传输任务（MTA）。 Sm-client负责处理邮件提交任务（MSP）。 这两个守护进程分别使用不同的配置文件和邮件队列，确保各自功能的高效运行： 邮件队列目录： MTA 邮件队列：/var/spool/mqueue MSP 邮件队列：/var/spool/clientmqueue 配置文件： MTA 配置：/etc/mail/sendmail.cf MSP 配置：/etc/mail/submit.cf 启动命令行中，MTA 和 MSP 的守护进程通过以下命令运行： MTA： sendmail -L sm-mta -bd -q1h MSP： sendmail -L sm-msp-queue -Ac -q30m 安装配置和启动 MAA为了配置邮件访问代理（MAA），需要进行如下操作： 编辑配置文件： vi /etc/dovecot.conf#protocols = imap pop3 启动 MAA 服务： service dovecot start 测试 MAA 是否正常工作： 测试 POP3： # telnet localhost 110 测试 IMAP： # telnet localhost 143 sendmail 的配置方法sendmail 的配置方法主要有三种： 直接修改 cf 配置文件直接对 /etc/mail/sendmail.cf 进行修改以实现特定配置。 编写 mc 宏配置文件编写后缀为 .mc 的宏文件，然后使用 m4 工具将其转换为 .cf 文件。这个方法能提升配置的可读性和易用性。 使用 sendmail 数据库更新配置sendmail 支持使用数据库文件对配置进行管理和更新。 使用 sendmail 数据库更新配置local-host-names 数据库 作用：将所有内容视为本地主机名。该数据库相当于配置文件中的 Cw （设定本地主机名选项）。 修改和测试示例： 修改文件 /etc/mail/local-host-names，添加下列内容： # vi /etc/mail/local-host-namesshrike.jamond.netjamond.net 测试本地主机名配置是否生效： netstat -ln | grep 25 access 数据库 安全性考虑：由于 SMTP 协议不要求身份认证，任何人可以通过 telnet 访问本地服务器的 25 端口，从而发送邮件。为了防止不明身份用户利用服务器发送垃圾邮件，sendmail 默认禁止非认证用户的邮件发送。 配置说明：sendmail 读取 /etc/mail/access.db 文件内容，根据设置决定是否中继邮件。可通过以下命令，由文本文件 /etc/mail/access 生成 access.db： makemap hash /etc/mail/access /etc/mail/access.txt aliases 数据库 功能：实现 sendmail 别名功能，它允许将邮件按照别名转发到特定用户。 操作步骤： 配置文件 /etc/aliases，可使用 newaliases 命令生成数据库文件： # vi /etc/aliaseslrj: osmondpostmaster: rootabc: abc@yyy.com.cnnet_group: osmond, tom, stillman, patrcko 别名的用途： 为用户指定绰号（例如，使用 lrj 代替完整邮箱）。 将发给特殊用户的邮件自动转发给实际用户（例如，将 postmaster 的邮件转发到 root）。 实现邮件列表（例如，通过 net_group 同时发送邮件给多位用户）。 发匿名邮件发送匿名邮件的基本过程如下： HeloMail from: a@a.comRcpt to: it@nit-pro.orgData邮件内容邮件内容输入结束另起一行敲入一个“.”回车即可发送 这是通过 SMTP 交互的基本格式，通过这种方式，可以在没有显式身份的情况下发送邮件。","categories":["1.平台","Linux","网络"]},{"title":"FTP服务介绍及配置","path":"/2024/11/27/1-平台-Linux-网络-FTP-FTP服务介绍及配置/","content":"FTP 协议 文件传输协议（File Transfer Protocol，FTP）标准是在 RFC959 说明的。 FTP 协议是一个客户机服务器系统 。 FTP 协议定义了一个在远程计算机系统和本地计算机系统之间传输文件的一个标准。 FTP 运行在 OSI 模型的应用层，并利用传输控制协议 TCP 在不同的主机之间提供可靠的数据传输。 由于 TCP 是一种面向连接的、可靠的传输协议，正是这种可靠性保证了 FTP 文件传输的可靠性。 FTP 在文件传输中还具有一个重要的特点，支持断点续传功能，可以大幅度地减小 CPU 和网络带宽的开销。 FTP 的数据传输模式 主动传输模式– FTP 的数据连接和控制连接的方向是相反的，也就是说，是服务器向客户端发起一个用于数据传输的连接。客户端的连接端口是由服务器端和客户端通过协商确定的。 被动传输模式– FTP 的数据连接和控制连接的方向是一致的，也就是说，是客户端向服务器发起一个用于数据传输的连接。客户端的连接端口是发起这个数据连接请求时使用的端口号。 FTP 的典型消息|:—:|:—:| |消息号|含义| |125|数据连接打开，传输开始| |200|命令 OK| |226|数据传输完毕| |331|用户名 OK，需要输入密码| |425|不能打开数据连接| |426|数据连接被关闭，传输被中断| |452|错误写文件| |500|语法错误，不可识别的命令| FTP 服务的使用者 根据 FTP 服务器服务的对象不同可以将 FTP 服务的使用者分为三类：– 本地用户（real 用户）– 虚拟用户（guest 用户）– 匿名用户 Linux 环境下的 FTP 服务器 Wu-ftpd– 历史最久的非商业 ftp 服务器程序之一– 安全性较 Proftpd 和 vsftpd 差– Wu-ftpd 的主页为 http://www.wu-ftpd.org/ Proftpd– 完全独立而完整、重新改写的 FTP Server– 为了追求一个安全且易于设定的 FTP Server 而编制的– Proftpd 的主页为 http://www.proftpd.org/ vsftpd– 编制者的初衷就是代码的安全性– 性能稳定且速度快– vsftpd 的主页为 http://vsftpd.beasts.org/ 安装并启动 vsftpd • 安装– # rpm –ivh vsftpd-1.1.3-8.i386.rpm 启动和停止– # service vsftpd start – # service vsftpd stop– # service vsftpd restart vsftpd 的配置文件 etcvsftpdvsftpd.conf– 主配置文件 etcpam.dvsftpd– vsftpd 的 PAM 配置文件 etcvsftpd.ftpusers– 指定了哪些用户不能访问 FTP 服务器。 etcvsftpd.user_list– 当在etcvsftpdvsftpd.conf 中设置了 userlist_enable YES 且 userlist_denyNO 时，仅仅允许etcvsftpd.user_list 中指定的用户访问 FTP 服务器。 vsftpd 的默认配置 查看 RedHat 9.0 中的默认配置– # grep -v “#” etcvsftpdvsftpd.conf 默认配置说明– 允许匿名用户和本地用户登录；– 匿名用户的登录名为 ftp 或 anonymous，口令为一个 Email 地址；– 匿名用户不能离开匿名服务器目录varftp，且只能下载不能上传；– 本地用户的登录名为本地用户名，口令为此本地用户的口令；– 本地用户可以离开自家目录切换至有权访问的其他目录，并在权限允许的情况下进行上传下载；– 写在文件etcvsftpd.ftpusers 中的本地用户禁止登录。– 要使用户在下载文件时能够续传文件，必须保证文件对其他用户有读的权限。 配置访问速度和每客户的连接数限制 设置最大传输速率限制 例如下面的配置： local_max_rate50000 anon_max_rate30000 将使本地用户的最大传输速率为 50kbytessec，匿名用户的最大传输速率为 30kbytessec。 设置每客户的连接数限制 例如下面的配置： max_per_ip3 将指明每个客户机的最大连接数为 3。 配置允许匿名用户上传 允许匿名用户上传– anon_upload_enable– anon_mkdir_write_enable 注意– 只有设置 anon_world_readable_onlyNO 后，才能开放匿名用户的读权限，即：浏览此服务器中全部的内容。– 续传必须添加如下的配置语句 anon_other_write_enableYES– 匿名用户对varftpincoming 目录而言是其他用户，所以必须为此目录添加对其他用户的可写权限才可上传 ，即此目录权限的数字表示是 707 配置 chroot 如果希望用户登录后不能切换到自家目录以外的目录，则需要设置 chroot 选项，涉及如下选项：– chroot_local_user– chroot_list_enable– chroot_list_file 有两种设置 chroot 的方法：– 1. 设置所有的本地用户执行 chroot，只要将 chroot_local_user 的值设为 YES 即可，即： chroot_local_userYES– 2. 设置指定的用户执行 chroot 需要如下的设置： chroot_local_userNO chroot_list_enableYES chroot_list_file etcvsftpd.chroot_list 这样，只有etcvsftpd.chroot_list 文件中指定的用户才可以执行 chroot。 配置基于本地用户的访问控制 限制指定的本地用户不能访问，而其他本地用户可访问– userlist_enableYES– userlist_denyYES– userlist_file etcvsftpd.user_list– 使文件etcvsftpd.user_list 中指定的本地用户不能访问 FTP 服务器，– 而其他本地用户可访问 FTP 服务器。 限制指定的本地用户可以访问，而其他本地用户不可访问– userlist_enable YES– userlist_deny NO– userlist_file etcvsftpd.user_list– 使文件etcvsftpd.user_list 中指定的本地用户可以访问 FTP 服务器，– 而其他本地用户不可以访问 FTP 服务器。","categories":["1.平台","Linux","网络","FTP"]},{"title":"FTP服务搭建","path":"/2024/11/26/1-平台-Linux-网络-FTP-FTP服务搭建/","content":"安装 VSFTPD 默认使用**21端口作为服务端口，需要保证服务器的规则启用的21** 端口 vsftpd 是在 Linux 上被广泛使用的 FTP 服务器，根据其官网介绍，它可能是 UNIX-like 系统下最安全和快速的 FTP 服务器软件。 sudo apt install vsftpd 安装完成后，通过 sudo netstat -nltp | grep 21 查看到 vsftpd 已经启动并监听了 21 端口 或者手动开启 vsftpd 服务 sudo systemctl start vsftpd.service 配置用户访问目录新建用户主目录sudo mkdir /home/uftp 执行完后，在这里 homeuftp 就能看到新建的文件夹 uftp 了。 创建登录欢迎文件： sudo touch /home/uftp/welcome.txt 方便用户登录后可以看到欢迎信息，并且确定用户确实登录到了主目录上。 用户的主目录是用户通过 FTP 登录后看到的根目录 新建用户 uftp 并设置密码创建一个用户 uftp： sudo useradd -d /home/uftp -s /bin/bash uftp 为用户 uftp 设置密码： sudo passwd uftp 删除掉 pam.d 中 vsftpd，因为该配置文件会导致使用用户名登录 ftp 失败： sudo rm /etc/pam.d/vsftpd 限制该用户仅能通过 FTP 访问限制用户 uftp 只能通过 FTP 访问服务器，而不能直接登录服务器： sudo usermod -s /sbin/nologin uftp 修改 vsftpd 配置 sudo chmod a+w /etc/vsftpd.conf 修改 etcvsftpd.conf 文件中的配置（直接将如下配置添加到配置文件最下方）： # 限制用户对主目录以外目录访问 chroot_local_user=YES # 指定一个 userlist 存放允许访问 ftp 的用户列表 userlist_deny=NO userlist_enable=YES # 记录允许访问 ftp 用户列表 userlist_file=/etc/vsftpd.user_list # 不配置可能导致莫名的530问题 seccomp_sandbox=NO # 允许文件上传 write_enable=YES # 使用utf8编码 utf8_filesystem=YES 新建文件 /etc/vsftpd.user_list，用于存放允许访问 ftp 的用户： sudo touch /etc/vsftpd.user_list``sudo chmod a+w /etc/vsftpd.user_list 修改 /etc/vsftpd.user_list ，加入刚刚创建的用户： echo uftp /etc/vsftpd.user_list 设置访问权限设置主目录访问权限（只读）： sudo chmod a-w /home/uftp 新建公共目录，并设置权限（读写）： sudo mkdir /home/uftp/public sudo chmod 777 -R /home/uftp/public 重启 vsftpd 服务： sudo systemctl restart vsftpd.service 访问 FTP 服务根据个人的工作环境，选择一种方式来访问已经搭建的 FTP 服务 通过 FTP 客户端工具访问 FTP 客户端工具众多，下面推荐两个常用的： FileZilla - 跨平台的 FTP 客户端，支持 Windows 和 Mac WinSCP - Windows 下的 FTP 和 SFTP 连接客户端 ftp:liuluhua:密码@ip 地址","categories":["1.平台","Linux","网络","FTP"]},{"title":"FTP站点","path":"/2024/11/25/1-平台-Linux-网络-FTP-FTP站点/","content":"FTP（File Transfer Protocol）是一个基于客户端服务器架构的文件传输协议，支持两种工作模式： 主动模式：客户端向 FTP 服务器发送端口信息，服务器主动连接该端口。 被动模式：FTP 服务器开启并发送端口信息给客户端，客户端连接服务器的端口，服务器被动接受连接。 说明：大多数 FTP 客户端运行在局域网中，通常没有独立的公网 IP 地址，并且可能会被防火墙拦截。在主动模式下，FTP 服务器连接客户端将面临更多困难。因此，除非有特殊需求，否则建议将 FTP 服务器配置为被动模式。 FTP 支持以下三种认证模式： 匿名用户模式：允许任何人无需密码直接登录 FTP 服务器。此模式安全性最低，通常只用于存放不重要的公开文件，生产环境中不推荐使用。 本地用户模式：依赖于 Linux 系统的本地账号进行验证，相较于匿名模式更为安全。 虚拟用户模式：FTP 服务器专用的用户，限制访问 Linux 系统的其他资源，进一步提升 FTP 服务器的安全性。 本文主要介绍如何在被动模式下，使用本地用户访问 FTP 服务器的配置方法。关于匿名模式的配置方式、以及第三方 FTP 客户端工具的使用说明，请参见常见问题部分。 安装 vsftpd安装 vsftpd 运行以下命令进行安装： dnf install -y vsftpd 安装成功时，系统将显示类似如下的信息：vsftpd 3.0.3。 设置 FTP 服务开机自启动 使用以下命令： systemctl enable vsftpd.service 启动 FTP 服务 运行以下命令： systemctl start vsftpd.service 说明：如果提示错误信息 Job for vsftpd.service failed because the control process exited with error code，请排查以下问题： 如果网络环境不支持 IPv6，打开配置文件，修改 listen_ipv6=YES 为 listen_ipv6=NO： vim /etc/vsftpd/vsftpd.conf 检查 MAC 地址是否匹配。使用命令 ifconfig 查看 MAC 地址，并在 /etc/sysconfig/network-scripts/ifcfg-xxx 配置文件中新增或修改：HWADDR=MAC地址。 查看 FTP 服务的监听端口 使用以下命令： netstat -antup | grep ftp 如果看到输出中包含端口 21，表示 FTP 服务已成功启动。 此时，vsftpd 默认启用了本地用户模式，但还需要进行进一步配置才能正常使用 FTP 服务。 配置 vsftpd为了确保数据安全，本节将详细介绍如何在被动模式下配置本地用户以访问 FTP 服务器。 为 FTP 服务创建 Linux 用户使用以下命令创建一个名为 ftptest 的用户： adduser ftptest 设置用户密码运行命令： passwd ftptest 根据命令行提示设置 FTP 用户的密码。 创建 FTP 服务使用的文件目录用以下命令创建： mkdir /var/ftp/test 创建测试文件使用以下命令： touch /var/ftp/test/testfile.txt 更改目录的拥有者运行以下命令，确保 ftptest 用户对目录拥有权限： chown -R ftptest:ftptest /var/ftp/test 修改 vsftpd.conf 配置文件打开配置文件： vim /etc/vsftpd/vsftpd.conf 在打开的文件中按 i 进入编辑模式，进行以下配置： # 禁止匿名登录FTP服务器anonymous_enable=NO# 允许本地用户登录local_enable=YES# 启用IPv4listen=YES# 注释掉以下行以禁用IPv6# listen_ipv6=YES# 设置登录后所在目录local_root=/var/ftp/test# 用户被限制在主目录chroot_local_user=YES# 启用例外用户名单chroot_list_enable=YES# 指定例外用户列表文件（可不包含用户）chroot_list_file=/etc/vsftpd/chroot_list# 开启被动模式pasv_enable=YESallow_writeable_chroot=YES# 设置被动模式的公网IPpasv_address=FTP服务器公网IP地址# 设置被动模式下的端口范围pasv_min_port=port numberpasv_max_port=port number 重要：在修改配置文件时，请注意格式问题，如多余的空格会导致服务无法重启。 保存并退出编辑模式按 Esc 退出，然后输入 :wq 并按 回车 保存并关闭文件。 创建 chroot_list 文件运行以下命令： vim /etc/vsftpd/chroot_list 在文件中按 i 进入编辑模式，输入例外用户名单。如果没有例外用户，文件内容可以留空。 重启 vsftpd 服务使用以下命令生效配置： systemctl restart vsftpd.service 设置安全组在搭建完 FTP 站点后，需在实例的安全组设定入方向规则，放行 FTP 相关端口。具体操作见添加安全组规则。 说明：许多客户端位于局域网，IP 地址经过 NAT 转换，使用 ipconfig 或 ifconfig 返回的 IP 可能不是实际的公网 IP。若客户端无法登录 FTP 服务器，请再次检查其真实公网 IP。 在被动模式下，需要开放 21 端口，以及在配置文件 /etc/vsftpd/vsftpd.conf 中指定的 pasv_min_port 到 pasv_max_port 之间的所有端口。例如： 规则方向 授权策略 协议类型 端口范围 授权对象 入方向 允许 自定义 TCP 2121 所有要访问 FTP 服务器的客户端公网 IP 地址（多个地址用逗号隔开）如允许所有客户端访问则为 0.0.0.0/0。 入方向 允许 自定义 TCP pasv_min_portpasv_max_port 如：5000050010 所有要访问 FTP 服务器的客户端公网 IP 地址（多个地址用逗号隔开）如允许所有客户端访问则为 0.0.0.0/0。 客户端测试可以使用 FTP 客户端、Windows 命令行工具或浏览器来测试 FTP 服务器。们将以 Windows Server 2012 R2 64 位系统为例，介绍访问步骤： 在本地主机上，打开文件资源管理器。 在地址栏中输入 ftp://FTP服务器公网IP地址:FTP端口，例如：ftp://121.43.XX.XX:21。 在弹出的登录框中，输入之前设置的 FTP 用户名和密码，然后点击登录。 登录成功后，可以看到 FTP 服务器指定目录下的文件，例如： 测试文件 testfile.txt。 vsftp 配置文件及参数说明在 /etc/vsftpd 目录下的文件说明如下： /etc/vsftpd/vsftpd.conf：vsftpd 的核心配置文件。 /etc/vsftpd/ftpusers：黑名单文件，列出的用户将无法访问 FTP 服务器。 /etc/vsftpd/user_list：白名单文件，列出的用户可以访问 FTP 服务器。 配置文件 vsftpd.conf 参数说明如下：用户登录控制参数： 参数 说明 anonymous_enableYES 允许匿名用户访问 no_anon_passwordYES 匿名用户登录时不询问口令 anon_root(none) 匿名用户主目录 local_enableYES 允许本地用户登录 local_root(none) 本地用户的主目录 用户权限控制参数： 参数 说明 write_enableYES 允许用户上传文件（全局控制） local_umask022 本地用户上传文件的权限 file_open_mode0666 上传文件的权限，配合 umask 使用 anon_upload_enableNO 匿名用户不能上传文件 anon_mkdir_write_enableNO 匿名用户不能创建目录 anon_other_write_enableNO 匿名用户没有修改删除权限 chown_usernamelightwiter 匿名上传文件所属的用户名","categories":["1.平台","Linux","网络","FTP"]},{"title":"TFTP功能实现简介","path":"/2024/11/22/1-平台-Linux-网络-FTP-TFTP功能实现简介/","content":"服务端 Server 网络初始化 等待客户连接 接受命令 命令 动作 get filename 判断文件是否存在，如果不存在，发送错误编号；如果存在，打开文件，读取文件，写到读写套接字，关闭文件 put filename 创建文件，读套接字，写入文件，关闭文件 list 打开服务器共享目录，读目录，发送到套接字，关目录 客户机 Client 网络初始化 连接服务器 判断命令 命令 动作 get filename 在当前目录创建文件，读套接字，写入文件，关闭文件 put filename 打开文件，写入套接字，关闭文件 list 读套接字 quit 退出 help 打印帮助信息 通信内容ID+文件内容 FileContent ID 含义 0 正常通信 1 表示有错误 2 表示文件结束","categories":["1.平台","Linux","网络","FTP"]},{"title":"TFTP配置","path":"/2024/11/21/1-平台-Linux-网络-FTP-TFTP配置/","content":"配置 TFTP（文件传输协议）TFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于在计算机网络中进行文件的上传和下载。下面是详细的配置步骤，确保顺利地实现文件传输功能。 1) 安装 TFTP（已安装）首先，检查 TFTP 是否已经安装。如果未安装，可以通过以下命令安装所需的相关软件包： sudo apt-get install tftp-hpa tftpd-hpa 这里，tftp-hpa 是 TFTP 客户端，而 tftpd-hpa 是 TFTP 服务器。通过这条命令可以确保的系统中有适当的工具来进行文件传输。 2) 配置 TFTP接下来，需要配置 TFTP 服务器。使用下面的命令打开配置文件： sudo vi /etc/default/tftpd-hpa 在文件中，找到并修改以下内容： TFTP_DIRECTORY=/tftpboot 注意事项如果 /tftpboot 目录不存在，需要手动创建它： sudo mkdir /tftpboot 添加权限：确保 TFTP 服务器能够访问该目录，并允许读写操作。使用以下命令更改目录权限： sudo chmod 777 /tftpboot -R 这里，-R 参数表示递归更改权限，使所有子目录和文件都继承这个权限设置。选择 777 权限意味着所有用户（包括普通用户）都有读、写和执行权限，方便进行文件的上传和下载，但在实际生产环境中，建议根据安全需求设置更严格的权限。 3) 重启服务完成配置后，需要重启 TFTP 服务，以使更改生效。使用以下命令重启服务： sudo /etc/init.d/tftpd-hpa restart 重启服务后，TFTP 服务器将使用新的配置进行工作。 4) 测试测试步骤确保 TFTP 在本机正常运行。首先，选择一个目录： cd ~ 接下来，连接到本地 TFTP 服务器，使用以下命令： tftp 127.0.0.1 这里的 127.0.0.1 是本地回环地址，指向本机。连接后，将进入 TFTP 交互环境，可以使用以下命令进行文件 transfer： 从 tftpboot 下载文件： tftp get xx 这条命令会尝试从 /tftpboot 目录中下载名为 xx 的文件到当前目录。 将文件上传到 tftpboot： tftp put xx 这条命令会将当前目录下的名为 xx 的文件上传到 /tftpboot 目录中。 退出 TFTP 环境： tftp quit 输入 quit 命令可以安全退出 TFTP 客户端。 通过上述步骤，可以顺利配置并测试 TFTP 守护程序。确保在测试过程中，检查任何错误信息并根据需要调整配置或权限设置。","categories":["1.平台","Linux","网络","FTP"]},{"title":"快速搭建 FTP 服务","path":"/2024/11/13/1-平台-Linux-网络-FTP-快速搭建-FTP-服务/","content":"通过 yum 安装 vsftpd首先，打开终端并使用以下命令安装 vsftpd（非常安全的 FTP 服务器）： yum install -y vsftpd 此命令将从 CentOS 软件库中下载并安装 vsftpd 及其依赖包，安装完成后，便可以配置和启动 FTP 服务。 修改配置文件 etcvsftpdvsftpd.conf接下来，使用文本编辑器打开配置文件以进行自定义设置： vim /etc/vsftpd/vsftpd.conf 配置示例在文件中，可以看到一些原有的初始配置。以下是完整的具体配置，确保根据的需求进行适当调整： # 原有初始配置local_umask=022 # 设置用户在上传文件时的权限掩码dirmessage_enable=YES # 启用目录消息，允许用户在进入目录时看到消息xferlog_enable=YES # 启用传输日志，记录所有传输的信息connect_from_port_20=YES # 通过端口 20 进行数据连接xferlog_std_format=YES # 使用标准格式记录传输日志tcp_wrappers=YES # 启用 TCP 包裹（用于访问控制）local_enable=YES # 允许本地用户登录write_enable=YES # 允许写入权限pam_service_name=vsftpd # 定义 PAM 服务名# 不支持匿名访问anonymous_enable=NO # 禁用匿名用户访问，保护敏感数据# 所有用户都被限制在其主目录下chroot_local_user=YES # 将本地用户限制在其主目录中chroot_list_enable=NO # 禁止用户列表allow_writeable_chroot=YES # 允许可写的 chroot 目录# 支持 IPv4 及 IPv6, 监听端口 8021listen=NO # 不在 IPv4 上监听listen_ipv6=YES # 在 IPv6 上监听listen_port=8021 # 设置监听端口为 8021# 只允许 userlist_file 文件中的用户可访问 ftpuserlist_enable=YES # 启用用户列表功能userlist_deny=NO # 允许列表中的用户登录userlist_file=/etc/vsftpd/user_list # 指定用户列表文件的位置# ftp 用户主目录local_root=/data/ftp # 设置本地 FTP 用户的根目录# passive 模式，数据端口范围自定义(6000-6010)pasv_enable=YES # 启用被动模式pasv_min_port=6000 # 设置被动模式下的最小端口pasv_max_port=6010 # 设置被动模式下的最大端口 注意，可以根据需要修改端口和根目录的设置，以提供最适合网络环境的配置。例如，如果希望 FTP 服务在更常见的 21 端口上运行，可以将 listen_port 改为 21。 配置允许登录的用户 etcvsftpduser_list在同样的位置，编辑用户列表文件，以定义可以访问 FTP 的用户： vim /etc/vsftpd/user_list 在文件中输入允许登录的用户名，每个用户占一行，例如： ftpUser 添加的信息必须与将要创建的 FTP 用户名相符。如果将 userlist_deny 设置为 YES，则该文件中的用户将不被允许访问。 创建 ftp 登录用户接下来，创建一个组和用户来进行 FTP 登录： groupadd ftpGroup # 创建 FTP 用户组useradd -d /opt/reconciliation -s /sbin/nologin -g ftpGroup -G root ftpUser # 创建 FTP 用户passwd ftpUser # 为新用户设置密码 通过以上命令，创建了一个名为 ftpUser 的用户，并将其添加到 ftpGroup 中。注意，/opt/reconciliation 是该用户的主目录，可以根据需要进行调整。 创建 ftp 文件存放目录在创建用户之后，需要为 FTP 文件设置存放目录： mkdir -p /data/ftp # 创建 FTP 数据存放目录chown -R ftpUser /data/ftp # 赋予 ftpUser 用户对该目录的所有权 这将确保用户 ftpUser 有权在 /data/ftp 目录下读写文件。 启动 ftp 服务最后，启动 vsftpd 服务，使 FTP 功能生效： service vsftpd start # 启动 vsftpd 服务 可以通过以下命令确认服务的状态： systemctl status vsftpd # 检查 vsftpd 服务的状态 FTP 访问测试可以使用工具如 FileZilla 来进行连接测试。启动 FileZilla，输入以下信息进行连接： 主机：服务器 IP 地址 用户名：ftpUser 密码：相应的密码 端口：8021（或其他设置的端口） 连接成功后，可以通过左侧窗口拖拽文件到右侧窗口来上传文件，或从右侧窗口下载文件到本地。如果一切配置正确，应能顺畅地使用 FTP 服务。","categories":["1.平台","Linux","网络","FTP"]},{"title":"NFS服务的搭建","path":"/2024/11/12/1-平台-Linux-网络-NFS-NFS服务的搭建/","content":"NFS 简介NFS，即网络文件系统（Network File System），是一种广泛支持的文件系统。它允许不同操作系统之间共享文件和目录，使用户能够像访问本地文件一样，便捷地访问远程系统上的文件。这种功能使得 NFS 在网络环境中至关重要，尤其是在企业和开发者的日常工作中。 NFS 的共享机制建立在对于信任的基础上，因此在向其他用户开放共享资源之前，必须仔细确认对方的可靠性。某些敏感或重要数据不应在不信任的环境下共享，以避免数据泄露的风险。 NFS 的应用场景在嵌入式开发中，NFS 扮演着不可或缺的角色。通过将”根文件系统”保留在主机上，可以在开发板启动时，通过 NFS 轻松挂载主机上的根文件系统。这一过程不仅节省了时间，因为不需要每次都把文件系统烧写到开发板的存储设备上，而且还提高了开发的灵活性和效率。相比之下，使用 TFTP（Trivial File Transfer Protocol）需要多次进行单独的文件传输，而 NFS 提供了一个更为简便的解决方案。 NFS 的配置过程以 Ubuntu 为例，将详细讲解如何配置 NFS 服务。 Server（服务器端）： PCClient（客户端）： ARM (这里使用同一台机器进行模拟，主要展示安装过程)一、配置服务器端首先，需要安装 NFS 服务器程序。可以使用以下命令： sudo apt-get install nfs-kernel-server 在执行命令时，系统会提示输入密码。如果之前已经安装过 NFS，系统会显示”NFS kernel server is already the newest version.”，这意味着无需重复安装。 二、配置 NFS 资源NFS 允许挂载的目录和权限在 /etc/exports 文件中进行定义。因此，配置 NFS 服务器的关键在于编辑此文件。 可以使用以下命令查看和编辑 /etc/exports 文件： cat /etc/exports 在此文件中，需要按照以下方式定义共享目录： 共享目录的绝对路径，例如 /home/fs/qiang。 网络访问控制，使用 * 表示允许所有 IP 地址访问，或指明特定的 IP 地址，例如 192.168.3.51(rw)。 其他参数，如： insecure 表示 NFS 将通过 1024 以上的端口进行通信。 rw 表示给予读写权限。 async 允许系统在写入数据之前处理请求。 root_squash 意味着 root 用户的权限被限制，仅能以普通用户身份访问共享目录。 可以在 /etc/exports 文件中添加如下配置： /home/fs/qiang 192.168.3.51(rw)/home/fs/qiang *(insecure,rw,async,root_squash) 三、手动启动和停止 NFS 服务完成配置后，可以通过以下命令启动 NFS 服务： sudo /etc/init.d/nfs-kernel-server start 启动服务后，系统会输出正在导出目录的信息。如果配置没有问题，会显示 [ OK ]。 要停止 NFS 服务，请使用： sudo /etc/init.d/nfs-kernel-server stop 若要重新启动 NFS 服务，可以简单地执行： sudo /etc/init.d/nfs-kernel-server restart 要查看 NFS 服务当前状态，可以使用以下命令： sudo /etc/init.d/nfs-kernel-server status 四、查看 NFS 服务器的共享资源使用以下命令可以查看 NFS 服务器当前导出的共享资源： showmount -e 192.168.3.51 这将显示服务器上共享的文件和目录。 五、挂载共享资源在客户端，可以使用 mount 命令来挂载 NFS 共享资源。命令如下： sudo mount -t nfs 192.168.3.51:/home/fs/qiang /mnt/nfs 这里，-t 指明文件系统类型为 NFS，192.168.3.51 是服务端的 IP 地址，/home/fs/qiang 是服务端的共享目录，而 /mnt/nfs 是客户端的挂载点。 挂载成功后，客户端对挂载的文件系统的操作将与本地文件系统没有区别，用户可以自由地读取和写入数据。 六、卸载共享资源当完成对共享资源的操作后，可以使用以下命令卸载： sudo umount /mnt/nfs 请注意，如果有其他用户正在使用该共享目录的文件，则无法成功卸载。如果确实需要强制卸载，可以使用： sudo umount -f /mnt/nfs 通过以上步骤，可以顺利配置和使用 NFS，实现高效的文件共享与管理。","categories":["1.平台","Linux","网络","NFS"]},{"title":"NFS环境配置","path":"/2024/11/11/1-平台-Linux-网络-NFS-NFS环境配置/","content":"配置 TFTP 服务a. 安装 TFTP 服务使用以下命令在系统中安装 TFTP 服务及其守护进程： sudo apt-get install tftp tftpd-hpa 这一步骤确保拥有一个功能齐全的 TFTP（简易文件传输协议）服务，能够在网络环境中进行文件的传输和共享。 b. 修改配置文件编辑 TFTP 的默认配置文件，以便于调整服务参数： sudo vi /etc/default/tftpd-hpa 在该文件中，可以设置 TFTP 服务器的基本属性，例如服务启动的方式、监听的 IP 地址等。确保根据自己的需求对这些参数进行适当的配置。 c. 修改服务目录指定 TFTP 服务的根目录，不同于默认目录： /home/fs/tftpboot 确保该目录的存在，并具备足够的存储空间以存放要共享的文件。 d. 重启 TFTP 服务保存配置文件后，通过下面的命令重启 TFTP 服务，以应用上述配置： sudo service tftpd-hpa restart 这将重新加载 TFTP 服务，确保新的配置被正确应用。 e. 拷贝内核文件为了保证开发环境能够从虚拟机中下载内核文件，需要将 zImage 文件拷贝到 TFTP 服务的根目录： cp /path/to/zImage /home/fs/tftpboot/ 确保在拷贝之前，zImage 文件已经存在于指定路径。 常见报错 权限不允许检查权限设置，可通过以下命令更改 tftpboot 目录及其子目录的访问权限： chmod 777 /home/fs/tftpboot -R 文件名未找到确保 zImage 文件确实存在于 TFTP 根目录。 确认配置文件中定义的服务目录与实际运行的目录一致。 挂载目录a. 配置 NFS 文件编辑 NFS 导出文件以定义要共享的目录： sudo vi /etc/exports 添加共享目录的配置： /home/fs/nfsboot *(rw,sync,no_subtree_check) 这里 *(rw,sync,no_subtree_check) 的含义是所有客户端可以以读写模式访问这个目录，且文件同步时不会检查子目录。 b. 重启 NFS 服务虽然 NFS 服务默认情况下会一直运行，但在更改配置后，执行以下命令以确保更改生效： sudo service nfs-kernel-server restart c. 拷贝文件系统将 rootfs.tgz 文件系统拷贝到 NFS 的共享目录中： cp /path/to/rootfs.tgz /home/fs/nfsboot/ d. 解压文件解压刚才拷贝的 rootfs.tgz 文件，以便使用： sudo tar -zxvf /home/fs/nfsboot/rootfs.tgz 此命令将文件解压到 nfsboot 目录，方便后续访问。 e. 改变文件权限确保文件系统内的文件和目录对所有用户开放访问权限： sudo chmod 777 /home/fs/nfsboot/rootfs -R 开发板设置a. 设置开发相关 IP在开发板的环境中设置相关的网络参数： setenv serverip 192.168.2.2 // 服务器 IP 地址setenv ipaddr 192.168.2.3 // 开发板 IP 地址setenv netmask 255.255.255.0 // 子网掩码setenv gatewayip 192.168.1.1 // 网关 这些环境变量将确保开发板能够连接到网络和服务器。 b. 设置开发板启动参数定义启动命令，以通过 TFTP 从服务器下载内核文件并启动： setenv bootcmd tftp 20008000 zImage; go 20008000 当开发板启动时，它会自动执行该命令，通过 TFTP 从服务器（192.168.2.2）下载 zImage 文件到开发板内存地址 0x20008000，下载完成后，CPU 从该地址开始执行内核。 如果想使用 zImage_all 内核进行启动，可以按照以下步骤操作： 重启开发板。 设置新的启动命令： setenv bootcmd tftp 20008000 zImage_all; go 20008000 使用命令保存更改： save 启动开发板： boot c. 设置文件系统挂载方式配置开发板的启动参数，以指定 NFS 文件系统的相关信息： setenv bootargs root=nfs nfsroot=192.168.2.2:/home/fs/nfsboot/rootfs ip=192.168.2.3 init=/linuxrc console=ttySAC0,115200 这些设置将确保开发板在启动时通过 NFS 挂载指定的文件系统。 d. 保存设置注意，以上所有设置仅在内存中生效，重启后将会丢失。因此，需要将设置保存到非易失性存储中： saveenv 各种方式启动开发板 按电源键重启开发板。 在启动命令行输入 boot 命令。 使用以下命令从 TFTP 下载内核： tftp 20008000 zImagego 20008000 通过以上步骤，可以轻松配置和启动开发板，以便于进行开发和测试。","categories":["1.平台","Linux","网络","NFS"]},{"title":"NFS配置","path":"/2024/11/08/1-平台-Linux-网络-NFS-NFS配置/","content":"配置 NFS（网络文件系统）NFS（Network File System）是一种允许用户在网络中访问和共享文件的协议。它使得跨不同机器访问文件成为可能，简化了文件管理。在实际应用中，比如在企业环境中，常常需要将配置文件、共享文档或应用程序集中管理。 主要功能 共享：通过网络将文件系统共享给所有需要的用户或计算机。 挂载：使得远程的文件系统像本地文件系统一样被访问。 1. 安装 NFS首先确保已经安装了 NFS 服务器，如果未安装，可以使用以下命令进行安装： sudo apt-get install nfs-kernel-server 请注意，可能需要有管理员权限才能执行此命令，通常需要输入密码。 2. 配置 NFS安装完成后，接下来需要配置 NFS。需要编辑 NFS 服务器的导出文件 /etc/exports，这是一个保存共享目录及其权限的配置文件。使用下面的命令打开文件： sudo vi /etc/exports 在文件的最后一行添加以下内容，以共享 /nfsboot 目录： /nfsboot * (rw,sync,no_subtree_check) nfsboot：这是希望共享的目录。 *****：表示允许所有主机访问该目录。可以修改为指定的 IP 地址或主机名来限制访问。 rw：表示读写访问权限。 sync：确保数据在响应请求之前写入磁盘，增加数据的安全性。 no_subtree_check：关闭子目录检查，可提高性能，特别是当一个大的目录被共享时。 如果 /nfsboot 目录不存在，需要先创建它。可以使用以下命令： sudo mkdir /nfsboot 然后，修改其权限以确保其他用户可以访问： sudo chmod 777 /nfsboot -R 这里的 777 权限允许所有用户进行读、写和执行操作。使用 -R 选项可以递归地更改权限，以确保目录内的文件也继承该权限。 3. 重启 NFS 服务修改配置后，需要重启 NFS 服务以应用更改。执行如下命令： sudo /etc/init.d/nfs-kernel-server restart 当看到 4 个连续的 “OK” 消息时，说明服务已经成功启动，且配置生效。 4. 测试 NFS 配置接下来，进行 NFS 的挂载测试。首先，创建一个临时挂载点： cd /mntsudo mkdir /mnt/tempsudo chmod 777 /mnt/temp -R 然后，执行挂载操作，将远程 NFS 目录挂载到本地的 /mnt/temp： sudo mount -t nfs 127.0.0.1:/nfsboot /mnt/temp 在这里，127.0.0.1 是本地主机的 IP 地址，/nfsboot 是之前配置的共享目录，/mnt/temp 是本地挂载点。 完成测试后，别忘了卸载 NFS 目录以释放挂载： sudo umount /mnt/temp 通过这些步骤，可以成功配置和测试 NFS。这样，的网络中的其他机器便可以轻松访问共享的文件系统。","categories":["1.平台","Linux","网络","NFS"]},{"title":"Linux驱动编写","path":"/2024/11/07/1-平台-Linux-驱动-Linux驱动编写/","content":"一、Linux 驱动简述及字符型驱动的框架（一）设备驱动概念设备驱动程序是操作系统内核和机器硬件之间的接口，为应用程序屏蔽 硬件细节，使硬件设备在应用程序 中表现为设备文件，可像操作普通文件一样操作硬件。例如，应用程序通过设备驱动程序 向打印机发送打印指令，而无需了解打印机的硬件 实现细节。设备驱动程序作为内核的一部分，具备以下功能： 设备初始化和释放：如在系统启动时初始化设备 ，在设备停 止使用时释放相关资源。 数据传输： 实现内核与硬件之间的数据交互，包括将数据从内核 传送到硬件 以及从硬件读取数据。 数据处理：读取应用程序传送 给设备 文件的数据，并回送应用程序请求的数据。 *错误检测与处理 *：及时检测设备出现的错误，并进 行相应处理，确保系统的稳定性。 设备、驱动、内核和应用程序之间存在特定的调用关系，形成了一个复杂但高效的接口系统。设备驱动作为内核与用户空间之间的桥梁，实现了硬件和软件的有效互动。以下是对关键环节的详细说明和示例。 内核模块与设备注册内核模块通过 init_module() 函数进行设备注册，这是一个至关重要的步骤。例如，当插入 USB 设备时，它的驱动程序会使用该函数告知内核一个新的设备已连接。内核将此信息记录在其设备树中，以便后续处理。这一过程确保了设备能被正确识别并进行相应的驱动。 驱动程序的功能与应用程序的交互驱动程序为应用程序提供了对设备的直接功能。应用程序通过系统调用接口与设备驱动进行交互，常见的系统调用包括： **write**：将数据写入设备，例如将文件内容写入打印机。 **read**：从设备读取数据，如从传感器获取温度信息。 **ioctl**：执行设备特定的控制操作，例如调整摄像头的焦距。 这些接口简化了开发过程，应用程序开发者不必深入掌握硬件细节即可利用复杂的设备功能。 标准核心服务的利用设备驱动程序广泛使用内核提供的标准核心服务。这包括： 内存分配：设备驱动可以动态分配内存，以存储接收的数据或配置参数，使用内存池等机制确保更高效的内存管理。 中断发送：硬件设备可以通过中断请求（IRQ）向内核报告事件，驱动程序在处理这些中断时能够响应设备状态的变化。 等待队列：当没有数据可读时，驱动程序可以让应用程序进入等待状态，直到有数据可用，从而提高系统的整体效率。 动态加载与用户配置多数 Linux 设备驱动程序支持动态加载，这意味着驱动可以在需要时被加载至内核，从而减少启动时所需的资源。例如，当用户插入新设备时，相应的驱动将自动加载，而当设备拔出后，该驱动可以被卸载。这种机制极大地提高了系统资源的利用率与灵活性。 此外，用户能够根据需求配置 Linux 设备驱动。这种灵活性表现为可以开启或关闭特定的驱动功能，比如修改设备的工作模式、带宽限制或其他参数，以更好地适应特定应用场景。 （二）Linux 设备分类 字符设备：字符设备完成输入输出操作时是以字节为单位进行的。它们通常不使用缓存，这意味着每次操作都直接与硬件交互，所以速度可能较慢。由于不支持随机访问，字符设备在处理数据时一般是顺序进行的。一个常见的例子是串口设备，如 /dev/ttyS0，它用于与调制解调器和其他串行设备通信。在与字符设备交互时，数据往往一字节一字节地流动，因此在数据传输时，可能需要考虑效率和时延问题。 块设备：块设备则与字符设备截然不同，采用了块为单位的数据传输方式，通常允许对文件系统进行高效的读写。它们使用 buffer 和 cache 来提升性能，支持随机访问，这意味着可以直接访问存储媒体上的任意位置，而不用依赖于顺序读取。块设备的一个典型例子是 IDE 硬盘，通常被挂载在如 /dev/sda1 的节点上。由于其灵活性，块设备不仅可以存储数据，还可以同时进行多个读写操作，提高了操作系统的整体性能，使用户能够同时使用多个应用程序而不感到延迟。 网络设备：网络设备与前两种设备完全不同，它们通过 BSD 套接字接口进行交互，专门用于网络数据的处理。网络设备的工作不依赖于传统的输入输出模式，而是围绕数据包的发送和接收进行组织。例如，eth0 是一个常见的网络接口，代表系统中的以太网连接。使用网络设备时，内核会调用与数据包处理相关的函数，这些函数负责发送、接收以及可能的重传请求，确保数据在网络中的正确传输。这种设备的设计使得网络通信高效且可扩展，适合处理现代网络应用的复杂需求。 （三） Linux 设备文件概念在 Linux 操作系统中，硬件设备并不是直接与应用程序交互，而是通过抽象为普通文件的方式进行管理。这种设计理念使得设备的操作与文件系统的方法相似，用户和程序通过标准的系统调用接口来进行设备的读写操作。在这一机制下，文件节点成为访问各种硬件设备的桥梁，其中包括字符设备和块设备。这些对应的文件统称为设备文件，存储于 /dev 目录中。 每个设备文件都有两个重要的标识符：主设备号和次设备号。主设备号用于标识设备的种类以及与之对应的驱动程序，而次设备号则用于区分同一驱动程序下的不同硬件设备。例如，/dev/tty1 代表一个字符设备文件。其主设备号指向的是字符终端设备的驱动程序，而次设备号用于区分 /dev/tty1 和其他终端设备，比如 /dev/tty2、/dev/tty3 等，从而实现对多个终端的管理。 实际应用示例： 字符设备文件： 例如，键盘和鼠标都被视为字符设备。每当键盘输入数据时，Linux 会通过字符设备文件将输入的字符传递给正在运行的程序。通过读取文件 /dev/input/event0，系统能够接收到来自键盘的实时输入信号。 块设备文件： 相比之下，块设备（如硬盘和闪存）则以块为单位进行数据管理。文件系统操作（如读、不管是写还是格式化操作）通常通过块设备文件进行。例如，/dev/sda1 代表第一个硬盘的第一个分区，允许用户和应用程序通过该设备文件进行数据存储和检索。 这种设计不仅提高了系统的灵活性，还简化了设备的使用方式，使得用户能够通过标准的文件操作命令，如 cat、echo 和 dd 等，轻松地与硬件设备进行互动。 （四）Linux 字符型驱动程序框架Linux 字符型驱动程序框架是与字符设备进行交互的重要组成部分，主要涉及注册设备、定义功能函数（如 open、read、write、ioctl 等）以及卸载设备。字符设备通常指的是能够以字符流的形式进行数据传输的硬件设备，比如串口、键盘或一些传感器等。 一个简单的字符驱动程序由七个主要函数和一个结构体组成。具体如下： **Open**：该函数在打开设备文件时被调用，并负责设备初始化的工作。它通常会检查设备的状态，确保设备可用。例如，在打开一个串口设备时，Open 函数可能需要配置波特率、数据位和停止位等参数。 **Release**：在关闭设备文件时会调用此函数。其主要作用是释放设备资源，例如关闭串口连接并保存配置信息。 **Write**：负责将数据从用户空间写入设备。此函数通常需要将用户提供的数据复制到内核空间，并处理具体的写入操作，比如将数据发送到串口。 **Read**：与 Write 相对应，负责从设备读取数据并将其传输回用户空间。此函数可能实现缓冲机制，以确保数据的高效读取。 **Ioctl**：实现设备特定的控制命令。称为输入输出控制（IO Control），这个函数允许用户空间的程序向驱动发送命令，比如获取设备信息或更改设备参数。 **Init**：在驱动程序加载时调用，用于初始化设备并注册到内核。一般情况下，Init 函数会调用 register_chrdev() 函数进行设备注册，并初始化必要的数据结构。 **Exit**：用于清理和卸载设备。此函数会在驱动程序被卸载时调用，通常执行反注册操作，确保设备资源被正确释放。 此外，驱动程序还需要定义一个结构体 struct file_operations，它包含对上面所述的操作进行函数指针的定义。这个结构体是与内核进行交互的桥梁，例如： struct file_operations my_fops = .owner = THIS_MODULE, .open = my_open, .release = my_release, .write = my_write, .read = my_read, .unlocked_ioctl = my_ioctl,; 在上面的示例中，my_fops 定义了各个函数的实现，使得内核能够在相应操作时调用这些函数。通过实现这些函数，驱动程序为设备提供了具体的操作功能，使得用户空间的应用程序能够方便地与硬件设备通信。这个框架为各种字符设备提供统一的接口，大大简化了设备驱动的开发过程。 二、基于 Gpio 的 Linux 字符型驱动设计（一）流水灯 Linux 驱动步骤 编写字符设备驱动在 /linux-3.2/drivers/char/sep4020_char/ 目录下，新建一个名为 sep4020_flowled.c 的文件。该文件需要定义一个设备相关的结构体，通常包括设备的基本信息和状态。驱动程序需要实现如下关键函数： open：设备打开时调用。在此函数中，可以初始化设备的硬件状态。 release：设备关闭时调用，通常用于释放资源和清理状态。 write：用于实现向设备写入数据的功能，当前可以先置空，以后根据需求添加功能。 read：用于从设备读取数据，当前也可以先置空。 ioctl：用于发送设备控制命令，处理用户空间的请求和设备的具体操作。 此外，代码中还需要包含设备的初始化和注销函数，以便在模块加载和卸载时正确地管理设备资源。 加载驱动程序驱动程序可以通过以下两种方式加载到内核中： 静态加载：在系统启动时，将驱动程序编译进内核。需要在内核配置中选择该驱动，并重新编译内核。在完成配置后，运行 make 命令，编译内核镜像。在设备启动后，会自动加载这个驱动。 动态加载：通常在系统启动后使用 insmod 命令手动加载驱动模块。针对调试阶段，动态加载可以便于频繁地测试和更新驱动。实例执行 insmod sep4020_flowled.ko 后，可使用 cat /proc/devices 命令查看驱动是否加载成功。 编写应用程序测试设备驱动新建一个名为 flowled.c 的文件，其中包含测试依赖驱动的应用程序代码。在 main 函数中，实现如下功能： 使用 open 系统调用打开设备文件，确保设备已准备就绪。 通过 ioctl 系统调用向设备发送控制命令，实现流水灯的亮灭效果。 最后，使用 close 关闭设备文件，确保资源的释放。 使用交叉编译工具，例如 arm-linux-gcc，将应用程序编译成可执行文件，并将其拷贝到开发板上运行进行测试。 （二）驱动程序实现细节 设备结构体定义定义名为 struct led_dev 的结构体，该结构体通常包含： struct cdev cdev：Linux 字符设备结构体，帮助内核管理设备。 int value：表示 LED 当前状态的值，可能取值 0 表示关闭，1 表示开启。 操作函数实现 open 和 release 函数：这两个函数在设备打开和关闭时被调用。在 open 函数中，可以执行设备初始化的相关操作。例如，通过 sep4020_flowled_open 函数调用 sep4020_flowled_setup 函数实现具体的硬件初始化步骤，可能涉及配置 GPIO 引脚的模式和状态。 write 和 read 函数：目前可以先保持为空。在进行进一步设计时，可以添加具体的数据写入和读取逻辑，以支持特定的功能。 ioctl 函数：该函数用于管理设备控制操作。具体实现中，sep4020_flowled_ioctl 函数根据传入的命令 cmd（例如定义常量 LED_ON、LED_OFF）来控制 LED 灯的点亮或熄灭。这通常通过对 GPIO_PORTE_DATA_V 寄存器的操作来实现。 设备初始化和注销 设备初始化函数 sep4020_flowled_init 执行以下操作： 动态申请设备号，或者按照先前预留的静态设备号进行注册。 动态分配设备结构体的内存以存储设备状态。 调用硬件初始化函数（可以在 open 函数中调整实现时机），例如设置 GPIO 引脚。 注册字符设备，创建设备文件节点，通常在 /dev/ 目录下访问。 设备注销函数 sep4020_flowled_exit 中，执行注销设备操作： 删除设备文件，确保不再访问设备。 释放分配给设备结构体的内存，防止内存泄漏。 注销设备号，确保该设备号后续不被占用。 （三）驱动加载与应用程序测试 驱动加载 动态加载： 在开发板上，将 sep4020_flowled.ko 文件复制到网络文件系统 /demo/ 目录中。 在 /dev/ 目录创建名为 flowled 的设备节点，使用命令 mknod flowled c 249 0。 通过 insmod sep4020_flowled.ko 命令加载驱动程序，使用 cat /proc/devices 命令确认驱动程序是否已成功加载。 静态加载： 在终端中导航至 Linux 根目录，输入 make menuconfig，将助手驱动配置为在内核中静态编译（选择 *）。 运行 make 命令编译内核以生成新镜像。 使用 mkimage 命令重新生成能够被 uboot 引导的内核。 将编译好的新内核拷贝到 tftp 目录，重启开发板，访问 /dev/ 目录，创建设备节点 flowled。 应用程序测试 新建一个名为 flowled.c 的文件。 在 main 函数中，实现如下步骤： 使用 open 系统调用打开设备文件，确保设备已成功加载。 通过 ioctl 调用控制流水灯的亮灭状态。 最后，使用 close 关闭设备文件，释放所占资源。 使用交叉编译工具 arm-linux-gcc 将测试程序编译为可执行文件 flowled，拷贝至开发板的 nfs 文件夹下，运行后观察输出结果并进行功能测试。 三、Linux 键盘驱动的设计（一）键盘硬件原理与驱动设计要点5X5 键盘采用列中断和行扫描原理。在此设计中，每行和每列连接至控制器。当某个按键被按下时，列线将产生中断信号。接着，系统会使用中断处理函数扫描所有行线，以确定按键的确切位置。为了消除按键抖动，即在按键动作时可能产生的误判，设计中会引入软件延时。当系统判断有按键按下后，再次确认键盘的状态以确保按键确实有效被按下。这一过程有效地减少了误触发的概率。 Linux 键盘驱动设计涉及诸多知识点，包括中断使用、定时器使用和信号量管理。同时，也需要设计高效的缓冲区，考虑用户的阻塞与非阻塞读取方式。例如，在多用户环境下，如多人同时使用系统或频繁操作键盘的情况下，合理的缓冲区设计能够有效防止数据的丢失或混乱，确保每个用户的输入都能被准确捕捉。 （二）Linux 中断与定时器使用 中断使用 注册中断处理程序：使用 request_irq 函数来注册中断，传入中断号、中断处理函数的指针和中断的标志等参数。例如，使用该语句 request_irq(INTSRC_EXTINT0, sep4020_key_irqhandler, SA_INTERRUPT, 4020KEY, NULL) 来完成中断的注册。 中断处理函数：即在中断发生时执行的函数。例如，sep4020_key_irqhandler 函数会在中断发生时清除中断标志，并可能启动定时器等处理。 注销中断：通过 free_irq 函数释放中断资源，如语句 free_irq(INTSRC_EXTINT0, NULL) 重复进行中断注销操作，确保释放相关资源。 定时器使用 定义定时器：可通过定义 struct timer_list 类型的变量来实现定时器，如 key_timer。 初始化定时器：使用 setup_timer 函数进行初始化，设置定时器的处理函数和相关参数，例如： setup_timer(key_timer, key_timer_handler, 0)。 定时器处理函数：当定时器到期时执行的函数，例如 key_timer_handler 函数内会进行按键状态的判断和键值的获取等操作。 启动和删除定时器：使用 add_timer 函数启动定时器，使用 del_timer 函数来删除不再需要的定时器。 （三）键盘驱动函数实现 Init 加载函数：负责注册中断函数，初始化字符设备结构体，设置定时器，完成字符设备的注册，并创建设备文件节点。 exit 卸载函数：此函数用于释放中断资源、删除字符设备、释放设备结构体的内存，并注销设备号，以确保系统资源的有效回收。 Open 函数：初始化按键状态，并调用 sep4020_key_setup 函数进行相关设置，包括初始化 GPIO 口线、设置输入输出方向、指定中断触发方式等。 中断处理函数：在这里，应当屏蔽按键中断，清除中断标志，确定按键状态为不确定，然后启动定时器。由于这是一个关键步骤，保证地位的稳定与准确，确保后续的数据能够正确处理。 Timer 到期的中断处理函数：当定时器到期时，此函数会读取按键状态，并根据状态判断按键是否被按下。如果判断为按下，则获取键值、更新按键状态，并再次启动定时器以备下次检测。 **获取键值函数 key_event**：通过读取特定寄存器获取当前按键信息，首先识别列数与行数，进而计算并返回键值。 Read 函数：此函数使用信号量来保护临界区，将当前按键状态复制到用户空间，并返回操作结果以供应用程序使用。 （四）信号量与用户空间内核空间交互 信号量使用 定义信号量：可定义 struct semaphore 类型的变量，例如 key_sem。 初始化信号量：通过 sema_init 或使用宏 DECLARE_MUTEX 来初始化信号量，以便后续操作。 获取信号量：使用 down、down_interruptible 或 down_trylock 函数获取信号量，其中 down_interruptible 可以在获取失败时使得进程被信号打断。若返回非 0 则应当及时返回错误码。 释放信号量：通过 up 函数释放信号量，唤醒正在等待的进程，确保并发环境下的资源有效利用。 用户空间和内核空间互访：由于内核空间与用户空间的内存不能直接访问，因此需要通过系统提供的函数来进行数据交换。例如，使用 copy_from_user 进行多字节的数据复制从用户空间到内核空间，使用 copy_to_user 则进行从内核空间回用户空间的多字节复制。此外，put_user 和 get_user 函数用于简单数据类型的转换。 （五）键盘驱动验证在验证阶段，将键盘驱动通过模块加载或静态方式加载至内核，并编写与之配合的应用程序。将应用程序进行交叉编译后，部署至开发板上运行。应用程序首先通过 open 打开设备文件，然后利用 read 函数读取按键值，最终关闭设备文件。这一系列操作能够有效验证键盘驱动是否正常工作，确保驱动的稳定性与可靠性。","categories":["1.平台","Linux","驱动"]},{"title":"中断申请","path":"/2024/11/06/1-平台-Linux-驱动-中断申请/","content":"在 Linux 中，中断处理机制的设计旨在提高系统的响应速度和效率。该机制分为两个主要部分：顶半（top half）和底半（bottom half）。顶半负责处理优先级较高的任务，并要求在中断触发后尽可能缩短处理时间。完成顶半任务后，系统会激活底半，用于处理其余的任务。 底半的处理方式主要有三种：soft_irq、tasklet 和 workqueue。每种方式的使用场景和适用条件不同。soft_irq 通常用于那些对处理时间要求较紧迫的重要任务，主要涉及系统的一些子模块。一般来说，设备驱动较少使用 soft_irq。相比之下，tasklet 和 workqueue 在常规设备驱动中使用较多。它们之间的主要区别在于：tasklet 是在中断上下文中执行，而 workqueue 则是在进程上下文中执行，因此 workqueue 能够处理可能会导致阻塞的操作。 在 Linux 内核 2.6.30 之后，新增了一个名为 request_threaded_irq() 的 IRQ 处理 API。这一更新具有重要意义，能够将中断处理的某些可重入性问题得到有效管理。 如何使用 request_threaded_irq()要启用 request_threaded_irq()，必须在 Linux 内核配置中定义 CONFIG_GENERIC_HARDIQS。这一配置的存在确保线程式中断（threaded IRQ）能够在内核中得到支持。 背景request_threaded_irq() 的引入旨在减少内核在等待硬件中断处理时所产生的延迟。这一机制的逻辑是，将中断后续的工作交给内核线程处理，从而避免直接在中断上下文中完成所有任务。通过这种方式，系统可以保持高效的响应，并降低因长时间处理而引发的内核延迟。 优点包括： 减少内核延迟时间：工作被分配到线程中处理，使得内核能够更快地响应新的中断。 简化中断类型判别：在处理中断时不再需要分辨是硬件中断还是软件中断。 便于除错：内核中断处理的逻辑更加清晰，有助于找到潜在的问题。 传统的中断处理将任务分为上半部和下半部，要求在上半部的硬件中断处理中尽量保持简单，以加快系统反应速度。通过 request_threaded_irq()，上半部的硬件中断处理仅需确认正在处理的设备，随后唤醒一个内核线程来完成后续任务。 缺点则包括： 相较于非 IRQ 中断，内核线程需要在原本的 task_struct 中新增 struct irqaction，这使得内存占用增加 4 到 8 字节。 关键差异request_threaded_irq() 与传统的顶半和底半处理机制不同，因为它受到 Linux 内核调度的控制。这意味着错误的底半代码将不再导致整个系统的延迟。此外，使用 RT（实时）调度策略以及 nice 值等工具，可以灵活调节各个线程的优先级，将其分配给负载较低的 CPU，利用内核本身对线程的各种管理能力，包括休眠、加锁和申请新的内存区域。 线程化的中断特别适合具有共享中断线的情况。在这些情境下，它不仅提升了响应速度，还简化了在同一段代码中处理多个设备中断的复杂性。与 tasklet 和 workqueue 相比，threaded IRQ 在使用上更为灵活，因为后两者需要在顶半和底半之间建立联系。 函数原型int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id); IRQF_SHARED：在共享中断的情况下，dev_id 不能为空。因为释放 IRQ 时，需要区分各个共享中断的设备。 irq：中断号。 handler：首次执行的硬中断处理函数。该函数可以通过返回 IRQ_WAKE_THREADED 唤醒线程，也可以返回 IRQ_HANDLED 而不执行中断线程。 thread_fn：中断线程，类似于底半部的功能。 最后三个参数与 request_irq() 中的一致。 IRQF_ONESHOT例如，在某些情况下，线程函数执行完成前，IRQ 不会重新启用。IRQF_ONESHOT 标记的加入，目的是使代码的实际情况显而易见。它可以确保识别出在 irq 冲突情况下，两驱动想要共享同一中断时所使用的标志。 IRQF_ONESHOT 和 IRQF_SHARED 不能同时使用。由于 IRQF_ONESHOT 会禁用中断线程的中断，因而在处理时间较长的情况下不适用。当 hardirq 函数为 NULL 时，必须声明 IRQF_ONESHOT，确保线程执行时禁止该中断，这在处理低电平信号时尤为必要。 使用示例request_threaded_irq(gpio_irq.irq, gpio_irqhandler, gpio_threadhandler, gpio_irq.flags, gpio_irq.name, (void*)0); 在 hardirq 和 thread_fn 同时存在时，处理 thread_fn 时，该中断是打开的。 err = request_threaded_irq(gpio_irq.irq, NULL, gpio_threadhandler, gpio_irq.flags, gpio_irq.name, (void*)0); 但当 hardirq 和 thread_fn 只有一个存在时，处理 thread_fn 时，中断是关闭的。 这种设计方式显著提升了中断处理的可靠性与灵活性，让设备驱动的开发更为高效，增强了 Linux 内核对实时应用的支持。 /* * gpio_irqTest.c * PB27 receive this signal as IRQ and make the LED linking on PB17 turn on or turn off * */ #include linux/types.h#include linux/kernel.h#include linux/module.h#include linux/init.h#include linux/platform_device.h#include linux/cdev.h#include linux/ioctl.h#include linux/fs.h#include linux/gpio.h#include linux/delay.h#include linux/cdev.h#include linux/interrupt.h#include asm/io.h#include asm/io.h#include mach/gpio.h#include mach/hardware.h#include mach/board.h#include mach/gpio.h#include mach/at91_pio.h#include mach/at91_aic.h#include mach/at91_pmc.hvoid led_on()// at91_set_gpio_output(AT91_PIN_PB17,1); printk(led on ); void led_off()// at91_set_gpio_output(AT91_PIN_PB17 ,0); printk(led off. ); struct light_dev *light_devp;int light_major = 200; struct light_dev struct cdev cdev; unsigned char value;; static void io_init(void) at91_set_GPIO_periph(AT91_PIN_PB27, 0); at91_set_gpio_input(AT91_PIN_PB27, 1); at91_set_deglitch(AT91_PIN_PB27, 1); struct gpio_irq_desc int pin; int irq; unsigned long flags; char *name;; static struct gpio_irq_desc gpio_irq=AT91_PIN_PB27, AT91_PIN_PB27,IRQF_TRIGGER_FALLING|IRQF_TRIGGER_RISING|IRQF_ONESHOT,PB27;static irqreturn_t gpio_irqhandler(int irq, void *dev_id) printk(KERN_INFO In hard irq handler. ); return IRQ_WAKE_THREAD;static irqreturn_t gpio_threadhandler(int irq, void *dev_id) int rst; rst = at91_get_gpio_value(gpio_irq.pin); printk(KERN_INFO gpio stat: %d , rst); if(rst == 0) led_on(); else led_off(); printk(KERN_INFO sleep 3000ms ); msleep(3000); printk(KERN_INFO awake after sleep ); return IRQ_HANDLED; int light_open(struct inode *inode,struct file *filp) int err; struct light_dev *dev; dev = container_of(inode-i_cdev,struct light_dev,cdev); filp-private_data = dev; printk(KERN_DEBUG %s, __FUNCTION__); io_init();// err = request_threaded_irq(gpio_irq.irq,gpio_irqhandler,gpio_threadhandler,gpio_irq.flags,gpio_irq.name,(void*)0); err = request_threaded_irq(gpio_irq.irq,NULL,gpio_threadhandler,gpio_irq.flags,gpio_irq.name,(void*)0); if(err) // free_irq(gpio_irq.irq,(void*)0); printk(KERN_DEBUG request irq failed. ); return -EBUSY; return 0; int light_release(struct inode *inode,struct file *filp) free_irq(gpio_irq.irq,(void*)0); return 0; int light_ioctl(struct inode *inode,struct file *filp,unsigned int cmd, unsigned long arg) struct light_dev *dev = filp-private_data; switch(cmd) case 0: at91_set_gpio_output(AT91_PIN_PB19,0); break; case 1: at91_set_gpio_output(AT91_PIN_PB19,1); led_off(); break; default: return -ENOTTY; // break; return 0; struct file_operations light_fops = .owner = THIS_MODULE, .open = light_open, .release = light_release, .unlocked_ioctl = light_ioctl,; static void light_setup_cdev(struct light_dev *dev,int index) int err,devno = MKDEV(light_major,index); cdev_init(dev-cdev,light_fops); dev-cdev.owner = THIS_MODULE; dev-cdev.ops = light_fops; err = cdev_add(dev-cdev,devno,1); if(err) printk(KERN_NOTICE Error %d adding LED%d,err,index); int __init light_init(void) int result; dev_t dev = MKDEV(light_major,0); if(light_major) result = register_chrdev_region(dev,1,gpio); if(result 0) printk(KERN_DEBUG %s: register char dev failed. , __FUNCTION__); return result; light_devp = kmalloc(sizeof(struct light_dev),GFP_KERNEL); if(!light_devp) result = - ENOMEM; goto fail_malloc; memset(light_devp,0,sizeof(struct light_dev)); light_setup_cdev(light_devp,0); printk(KERN_DEBUG %s done , __FUNCTION__); return 0; fail_malloc:unregister_chrdev_region(dev,light_devp); return result; void __exit light_cleanup(void) cdev_del(light_devp-cdev); kfree(light_devp); unregister_chrdev_region(MKDEV(light_major,0),1); module_init(light_init);module_exit(light_cleanup);MODULE_AUTHOR(Enzo Fang);MODULE_LICENSE(Dual BSD/GPL);","categories":["1.平台","Linux","驱动"]},{"title":"块设备驱动","path":"/2024/11/05/1-平台-Linux-驱动-块设备驱动/","content":"#include linux/module.h#include linux/moduleparam.h#include linux/init.h#include linux/sched.h#include linux/kernel.h\t/* 用于打印调试信息的printk() */#include linux/slab.h /* 分配内存的kmalloc() */#include linux/fs.h /* 处理文件系统的所有功能 */#include linux/errno.h\t/* 错误代码 */#include linux/timer.h#include linux/types.h\t/* 定义数据类型，如size_t */#include linux/fcntl.h\t/* 文件控制常量，例如O_ACCMODE */#include linux/hdreg.h\t/* 获取硬盘几何信息的HDIO_GETGEO */#include linux/kdev_t.h#include linux/vmalloc.h#include linux/genhd.h\t/* 通用块设备操作 */#include linux/blkdev.h\t/* 块设备接口 */#include linux/buffer_head.h\t/* invalidate_bdev，处理缓存的块 */#include linux/bio.h /* 生物输入输出结构体 */#include linux/version.h\t/* 获取Linux内核版本信息 */#define SIMP_BLKDEV_DEVICEMAJOR COMPAQ_SMART2_MAJOR // 定义块设备的主设备号#define SIMP_BLKDEV_DISKNAME sbull // 定义块设备的名称#define SIMP_BLKDEV_BYTES (16*1024*1024) // 定义块设备的总字节数static struct request_queue *simp_blkdev_queue; // 定义请求队列static struct gendisk *simp_blkdev_disk; // 定义通用块设备结构unsigned char simp_blkdev_data[SIMP_BLKDEV_BYTES]; // 用于在RAM中存储数据的数组/** * simp_blkdev_make_request - 处理输入输出请求 * @q: 请求队列 * @bio: 输入输出来生物（bio）结构体，包含读写请求的信息 * * 该函数是请求处理的核心，负责处理从上层发来的所有IO请求。 */static int simp_blkdev_make_request(struct request_queue *q, struct bio *bio) struct bio_vec *bvec; int i; void *dsk_mem; // 用于后续获取内存的指针 // 检查请求是否超出了设备的边界 if ((bio-bi_sector 9) + bio-bi_size SIMP_BLKDEV_BYTES) printk(KERN_ERR SIMP_BLKDEV_DISKNAME : bad request: block=%llu, count=%u , (unsigned long long)bio-bi_sector, bio-bi_size);#if LINUX_VERSION_CODE KERNEL_VERSION(2, 6, 24) bio_endio(bio, 0, -EIO); // 处理错误结束IO#else bio_endio(bio, -EIO); // 处理错误结束IO#endif return 0; // 返回0以表示处理完成 // 计算当前请求在设备数据中的起始地址 dsk_mem = simp_blkdev_data + (bio-bi_sector 9); // 遍历bio中的每个数据片段 bio_for_each_segment(bvec, bio, i) void *iovec_mem; switch (bio_rw(bio)) case READ: // 处理读取请求 case READA: // 将页指针转换成实际的虚拟地址 iovec_mem = kmap(bvec-bv_page) + bvec-bv_offset; memcpy(iovec_mem, dsk_mem, bvec-bv_len); // 从块设备内存复制到用户空间 kunmap(bvec-bv_page); // 解锁页 break; case WRITE: // 处理写入请求 iovec_mem = kmap(bvec-bv_page) + bvec-bv_offset; memcpy(dsk_mem, iovec_mem, bvec-bv_len); // 从用户空间复制到块设备内存 kunmap(bvec-bv_page); // 解锁页 break; default: // 处理未知的IO请求类型 printk(KERN_ERR SIMP_BLKDEV_DISKNAME : unknown value of bio_rw: %lu , bio_rw(bio));#if LINUX_VERSION_CODE KERNEL_VERSION(2, 6, 24) bio_endio(bio, 0, -EIO); // 处理错误结束IO#else bio_endio(bio, -EIO); // 处理错误结束IO#endif return 0; dsk_mem += bvec-bv_len; // 移动到下一个数据段 #if LINUX_VERSION_CODE KERNEL_VERSION(2, 6, 24) bio_endio(bio, bio-bi_size, 0); // 正常结束IO#else bio_endio(bio, 0); // 正常结束IO#endif return 0; // 返回0以表示处理完成// 定义块设备的操作函数struct block_device_operations simp_blkdev_fops = .owner = THIS_MODULE, // 模块拥有者;/** * simp_blkdev_init - 初始化块设备 * * 在模块加载时调用，分配请求队列和通用块设备结构。 * 分配成功后，设置相关参数，并添加到系统中。 */static int __init simp_blkdev_init(void) int ret; // 分配请求队列 simp_blkdev_queue = blk_alloc_queue(GFP_KERNEL); if (!simp_blkdev_queue) ret = -ENOMEM; // 内存分配失败 goto err_alloc_queue; // 设置请求处理函数 blk_queue_make_request(simp_blkdev_queue, simp_blkdev_make_request); // 分配通用块设备 simp_blkdev_disk = alloc_disk(1); // 创建1个块设备 if (!simp_blkdev_disk) ret = -ENOMEM; // 内存分配失败 goto err_alloc_disk; // 设置块设备的参数 strcpy(simp_blkdev_disk-disk_name, SIMP_BLKDEV_DISKNAME); simp_blkdev_disk-major = SIMP_BLKDEV_DEVICEMAJOR; simp_blkdev_disk-first_minor = 0; simp_blkdev_disk-fops = simp_blkdev_fops; // 设置操作函数 simp_blkdev_disk-queue = simp_blkdev_queue; // 设置请求队列 set_capacity(simp_blkdev_disk, SIMP_BLKDEV_BYTES 9); // 设置块设备容量 add_disk(simp_blkdev_disk); // 将设备添加到系统中 return 0; // 初始化成功err_alloc_disk: blk_cleanup_queue(simp_blkdev_queue); // 清理请求队列err_alloc_queue: return ret; // 返回错误代码/** * simp_blkdev_exit - 模块卸载时调用 * * 清理模块使用的资源，包括删除块设备和清理请求队列。 */static void __exit simp_blkdev_exit(void) del_gendisk(simp_blkdev_disk); // 从系统中卸载块设备 put_disk(simp_blkdev_disk); // 释放块设备的引用 blk_cleanup_queue(simp_blkdev_queue); // 清理请求队列// 指定模块加载和卸载的函数module_init(simp_blkdev_init);module_exit(simp_blkdev_exit);","categories":["1.平台","Linux","驱动"]},{"title":"ARP","path":"/2024/11/04/1-平台-Linux-网络-ARP/","content":"首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址，如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。 网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。 如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。 例如： A 的地址为：IP：192.168.10.1 MAC: AA-AA-AA-AA-AA-AA B 的地址为：IP：192.168.10.2 MAC: BB-BB-BB-BB-BB-BB 根据上面的所讲的原理，们简单说明这个过程：A 要和 B 通讯，A 就需要知道 B 的以太网地址，于是 A 发送一个 ARP 请求广播（谁是 192.168.10.2 ，请告诉 192.168.10.1），当 B 收到该广播，就检查自己，结果发现和自己的一致，然后就向 A 发送一个 ARP 单播应答（192.168.10.2 在 BB-BB-BB-BB-BB-BB）。","categories":["1.平台","Linux","网络"]},{"title":"网络驱动函数功能分析","path":"/2024/11/01/1-平台-Linux-驱动-网络驱动函数功能分析/","content":"open 函数在 Linux 内核中的设备驱动程序中，open 函数承担着关键作用，主要负责处理用户进程对设备文件的打开请求。具体来看，open 函数的主要任务包括以下几个方面： 1. 检查设备状态首先，open 函数会检查所请求打开的设备是否处于可用状态。这意味着函数需要确认设备没有被其他进程锁定，且没有发生硬件故障。例如，当一个设备正由另一个进程使用时，若再次尝试打开该设备，open 函数将返回一个错误码，通常是 -EBUSY。这种机制可以避免资源冲突，保证设备的稳定性和可靠性。 2. 初始化设备在确认设备状态后，open 函数进行必要的设备初始化。这可能包括设置设备特定的寄存器状态，准备数据缓冲区等操作。例如，在某些设备（如网络接口）的情况下，打开设备之前需要配置其网络协议栈，以确保后续的数据传输正常工作。 3. 管理资源open 函数需要分配和初始化与打开的设备实例相关的资源。这可能涉及到为设备分配内存，初始化数据结构以存储设备状态或上下文信息。例如，设备驱动程序可能需要分配一个结构体，来保存有关设备的当前状态信息，供后续操作使用。 4. 跟踪设备使用情况此外，open 函数负责跟踪设备的使用情况，例如增加设备的打开计数。通过这种方式，驱动程序可以监控设备的打开次数，以及是否应当拒绝新的打开请求。设备的状态管理有助于避免对设备的错误或不当使用，确保其正常运行。 open 函数通常是通过 file_operations 结构体中的 open 成员来实现的。file_operations 结构体是 Linux 设备驱动中一个重要组成部分，它定义了一系列设备文件的操作集合，包括打开、关闭、读写等操作。open 函数的一般原型如下： int (*open)(struct inode *inode, struct file *filp); 下面是一个简单字符设备驱动程序中 open 函数的示例： static int my_device_open(struct inode *inode, struct file *filp) // 检查设备是否已经被打开 if (device_open) return -EBUSY; // 设备处于忙碌状态，无法再次打开 // 标记设备为打开状态 device_open++; // 进行必要的初始化 try_module_get(THIS_MODULE); // 增加模块使用计数 return 0; // 打开成功static int my_device_release(struct inode *inode, struct file *filp) // 标记设备为关闭状态 device_open--; // 进行清理操作 module_put(THIS_MODULE); // 释放模块使用计数 return 0; // 关闭成功static struct file_operations fops = .open = my_device_open, .release = my_device_release, // 其他操作函数;static int __init my_device_init(void) int ret; // 注册字符设备 ret = register_chrdev(MAJOR_NUM, my_device, fops); if (ret 0) printk(KERN_ALERT 注册字符设备失败 ); // 输出错误日志 return ret; // 返回错误码 printk(KERN_INFO 字符设备注册成功 ); // 输出成功日志 return 0; // 初始化成功static void __exit my_device_exit(void) // 注销字符设备 unregister_chrdev(MAJOR_NUM, my_device); printk(KERN_INFO 字符设备已注销 ); // 输出注销日志module_init(my_device_init);module_exit(my_device_exit); 在以上示例中，my_device_open 函数处理设备文件的打开操作，而 my_device_release 函数则负责处理设备文件的关闭。这两个函数被定义在 file_operations 结构体 fops 中，以将它们与设备文件的操作关联。用户进程请求打开设备文件时，驱动程序中的 open 函数会被调用，并执行相应的函数以满足请求。通过这种方式，驱动程序能够有效地管理设备的生命周期，确保其可用性和稳定性。 probe 函数在 Linux 内核中，probe 函数是设备驱动程序中的一个核心组件，主要用于在设备与驱动程序成功匹配时进行各种初始化操作。具体而言，probe 函数包含几个重要任务，确保设备能够在系统中正常运行。以下是这些任务的详细说明： 资源分配probe 函数首先负责为设备分配必要的资源。这包括 IO 内存、IRQ（中断请求线）和其他硬件资源。例如，当一个新的设备连接到系统时，probe 函数会请求分配特定的内存地址，以便驱动程序能够与设备进行通信。资源分配的成功与否直接影响设备的后续操作。 硬件初始化probe 函数还执行硬件层面的初始化，以确保设备的基本功能正常。例如，对于图形卡，probe 函数可能会设置显卡的工作模式，配置显存的地址等。这一步骤通常涉及设置寄存器，以便设备能够按照预期的方式进行操作。 设备注册一旦设备被成功初始化，probe 函数会在内核中注册该设备。这一步使得设备可以被系统中的其他组件访问和使用，这对于系统的稳定性和协调性至关重要。注册的过程通常涉及将设备的信息添加到内核的设备列表中。 数据结构初始化最后，probe 函数会初始化驱动程序所需的内部数据结构。这些数据结构存储有关设备状态、驱动程序状态和其他运行时信息。例如，设备的状态可能包括是否处于活动状态，或是否允许某些特定操作。初始化这些结构不仅提升了驱动程序的效率，也增强了对设备操作的管理能力。 函数调用过程probe 函数通常在设备驱动程序注册时被调用。当内核检测到新设备并找到合适的驱动程序时，内核会触发该驱动程序的 probe 函数。其函数原型通常如下所示： int (*probe)(struct platform_device *pdev); 示例：PCI 设备驱动程序以一个 PCI 设备驱动程序为例，probe 函数可能如下所示： static int my_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent) int err; // 启用设备 err = pci_enable_device(pdev); if (err) return err; // 请求 I/O 端口、内存等资源 err = pci_request_regions(pdev, my_driver); if (err) goto disable_device; // 初始化设备的其他部分 err = my_device_init(pdev); if (err) goto release_regions; return 0;release_regions: pci_release_regions(pdev);disable_device: pci_disable_device(pdev); return err; 在上述代码示例中，my_pci_probe 函数负责启用设备、请求所需的资源，并对设备进行初步的设置和配置。如果在执行过程中任何步骤失败，例如无法启用设备或请求资源失败，函数会有效地进行清理操作，确保系统的稳定性，防止未正常初始化的设备造成问题。 通过以上方式，probe 函数确保了设备在与驱动程序匹配后能够正确初始化并顺利投入使用。这一过程对于整个操作系统与硬件之间的交互至关重要。 netdev_priv(ndev);netdev_priv(ndev) 是一个内核宏，用以获取与网络设备 (net_device) 相关联的私有数据结构的指针。在 Linux 网络设备驱动程序中，开发人员通常定义一个私有数据结构来存储特定于该驱动程序的状态信息和资源，以便在处理网络设备时可以方便地访问这些信息。这种设计不仅有助于提高代码的组织性，还将相关数据与网络设备实例关联，使得各个部分之间的信息流动更加清晰。 netdev_priv(ndev) 的工作原理依赖于偏移量的计算，具体来说，它通过访问 net_device 结构体末尾的私有数据部分来获取指针。在此，ndev 是指向 net_device 结构体的指针，这使得它能够直接返回指向私有数据结构的地址。 例如，假设一个网络设备驱动程序的私有数据结构定义如下： struct my_priv_data int some_field; // 存储设备状态的字段 // 其他特定于驱动程序的数据; 在设置网络设备时，开发人员需要分配和初始化 net_device 结构体，并将私有数据结构的大小传递给 alloc_netdev 函数。该函数负责为设备的结构体分配内存，并为私有数据分配额外的空间。 struct net_device *ndev;struct my_priv_data *priv;ndev = alloc_netdev(sizeof(struct my_priv_data), my_netdev, NET_NAME_UNKNOWN, my_setup);if (!ndev) printk(KERN_ERR Failed to allocate net_device ); return -ENOMEM; // 内存分配失败时返回错误priv = netdev_priv(ndev);priv-some_field = 0; // 将私有数据的初始值设为0 在这个例子中，alloc_netdev 函数不仅分配了 net_device 结构体的内存，还在其末尾附加了一块与 struct my_priv_data 大小相等的内存区域。通过 netdev_priv(ndev)，可以获得一个指向这一内存区域的指针，从而方便地访问和操作私有数据。 在驱动程序的其他部分，可以利用 netdev_priv 宏来读取和更新私有数据。例如，在网络设备打开或关闭时，可能需要访问和修改这些数据： static int my_open(struct net_device *ndev) struct my_priv_data *priv = netdev_priv(ndev); // 在设备打开时访问和修改私有数据 priv-some_field = 1; // 设置状态为已开启 return 0; // 成功打开设备static int my_stop(struct net_device *ndev) struct my_priv_data *priv = netdev_priv(ndev); // 在设备停止时进行清理 priv-some_field = 0; // 重置状态 return 0; // 成功停止设备static const struct net_device_ops my_netdev_ops = .ndo_open = my_open, .ndo_stop = my_stop, // 其他网络设备操作的实现; 通过 netdev_priv(ndev)，驱动程序能够有效地访问和管理与特定网络设备实例相关的私有数据，从而实现对设备状态和资源的全面控制。这种设计模式值得在多种设备驱动程序开发中采用，以提高代码的可读性和维护性。 ndev-netdev_ops = rockchip_can_netdev_ops;ndev-netdev_ops = rockchip_can_netdev_ops; 这一行代码的目的是将网络设备操作函数集 rockchip_can_netdev_ops 赋值给 ndev（即网络设备实例）的 netdev_ops 成员。这种做法是实现网络设备与其对应的操作的关键步骤，它允许操作系统有效地管理和交互这个网络设备。 在 Linux 内核中，每个网络设备实例都是通过 struct net_device 结构体来表示的。这个结构体中包含一个名为 netdev_ops 的成员，它是指向 net_device_ops 结构体的指针。net_device_ops 结构体包含了一系列的函数指针，这些指针指向定义了特定网络操作的函数，包括设备的启动、停止、数据包发送和接收等功能。 以下是 net_device_ops 结构体的简化定义，展示了其中的一些关键操作： struct net_device_ops int (*ndo_init)(struct net_device *dev); void (*ndo_uninit)(struct net_device *dev); int (*ndo_open)(struct net_device *dev); int (*ndo_stop)(struct net_device *dev); netdev_tx_t (*ndo_start_xmit)(struct sk_buff *skb, struct net_device *dev); // 其他操作函数...; 通过将 rockchip_can_netdev_ops 赋值给 ndev-netdev_ops，内核能够在对这个网络设备进行操作时使用 rockchip_can_netdev_ops 中预先定义好的函数。具体地，当设备需要被打开时，内核会自动调用 rockchip_can_netdev_ops 中的 ndo_open 函数。当有数据包需要发送时，则会调用 ndo_start_xmit 函数。 以下是一个示例，展示了 rockchip_can_netdev_ops 的结构体定义和初始化过程： static const struct net_device_ops rockchip_can_netdev_ops = .ndo_open = rockchip_can_open, // 设备打开操作 .ndo_stop = rockchip_can_stop, // 设备关闭操作 .ndo_start_xmit = rockchip_can_start_xmit, // 数据包发送操作 // 其他操作函数...; 接下来是 rockchip_can_probe 函数的示例，它负责分配、初始化网络设备实例 ndev，并将操作函数集赋值给这个实例的 netdev_ops 成员： static int rockchip_can_probe(struct platform_device *pdev) struct net_device *ndev; struct rockchip_can_priv *priv; ndev = alloc_netdev(sizeof(struct rockchip_can_priv), can%d, NET_NAME_UNKNOWN, rockchip_can_setup); if (!ndev) return -ENOMEM; // 如果分配失败，返回内存不足错误 priv = netdev_priv(ndev); // 获取网络设备的私有数据区域 // 初始化私有数据结构 priv-pdev = pdev; // 将平台设备指针存储在私有结构中 // 将操作函数集赋值给 net_device 实例 ndev-netdev_ops = rockchip_can_netdev_ops; // 注册网络设备到内核 register_netdev(ndev); return 0; // 成功完成 在这个例子中，rockchip_can_probe 函数首先通过 alloc_netdev 函数分配内存并初始化一个新的网络设备实例 ndev。接着，它会将 rockchip_can_netdev_ops 赋值给 ndev-netdev_ops，这样一来，当内核需要对这个设备进行操作时，就会调用相应的功能实现。最后，通过调用 register_netdev(ndev) 将新创建的网络设备注册到内核，使其可以被其他部分的系统识别并使用。这个步骤对于确保设备的正常运行和管理是至关重要的。 register interrupt handlererr = devm_request_irq(pdev-dev, ndev-irq, rockchip_can_interrupt, 0, ndev-name, ndev);if (err) dev_err(pdev-dev, request_irq err: %d , err);\treturn err;rcan-reset = devm_reset_control_array_get(pdev-dev, false, false);if (IS_ERR(rcan-reset)) if (PTR_ERR(rcan-reset) != -EPROBE_DEFER) dev_err(pdev-dev, failed to get rcan reset lines );\treturn PTR_ERR(rcan-reset);rcan-num_clks = devm_clk_bulk_get_all(pdev-dev, rcan-clks);if (rcan-num_clks 1) dev_err(pdev-dev, bus clock not found );\treturn -ENODEV;rcan-dev = pdev-dev;rcan-can.clock.freq = clk_get_rate(rcan-clks[0].clk);rcan-can.bittiming_const = rockchip_can_bittiming_const;rcan-can.do_set_mode = rockchip_can_set_mode;rcan-can.do_get_berr_counter = rockchip_can_get_berr_counter;rcan-can.ctrlmode_supported = CAN_CTRLMODE_BERR_REPORTING | CAN_CTRLMODE_LISTENONLY | CAN_CTRLMODE_LOOPBACK | CAN_CTRLMODE_3_SAMPLES;rcan-base = addr;platform_set_drvdata(pdev, ndev);SET_NETDEV_DEV(ndev, pdev-dev);pm_runtime_enable(pdev-dev);err = pm_runtime_get_sync(pdev-dev);if (err 0) dev_err(pdev-dev, %s: pm_runtime_get failed(%d) , __func__, err);\tgoto err_pmdisable; 这段代码的作用是在驱动程序的探测函数（probe 函数）中进行一系列的硬件初始化和资源分配，以便正确地设置和使用设备。具体来说： 注册中断处理程序：err = devm_request_irq(pdev-dev, ndev-irq, rockchip_can_interrupt, 0, ndev-name, ndev);if (err) dev_err(pdev-dev, request_irq err: %d , err); return err; 这部分代码注册一个中断处理程序。当设备产生中断时，rockchip_can_interrupt 函数会被调用。devm_request_irq 函数会自动管理中断的分配和释放，避免内存泄漏。 获取复位控制线：rcan-reset = devm_reset_control_array_get(pdev-dev, false, false);if (IS_ERR(rcan-reset)) if (PTR_ERR(rcan-reset) != -EPROBE_DEFER) dev_err(pdev-dev, failed to get rcan reset lines ); return PTR_ERR(rcan-reset); 这部分代码获取设备的复位控制线。devm_reset_control_array_get 函数会获取与设备关联的复位控制线，并在设备释放时自动释放。如果获取失败，会打印错误信息并返回错误码。 获取时钟资源：rcan-num_clks devm_clk_bulk_get_all(pdev-dev, rcan-clks); if (rcan-num_clks 1) { dev_err(pdev-dev, bus clock not found ); return -ENODEV; } 这部分代码获取与设备相关的所有时钟资源。devm_clk_bulk_get_all 函数会返回时钟资源的数量，如果数量少于 1，则表示未找到时钟资源，打印错误信息并返回错误码。 设置 CAN 控制器的参数：rcan-dev = pdev-dev;rcan-can.clock.freq = clk_get_rate(rcan-clks[0].clk);rcan-can.bittiming_const = rockchip_can_bittiming_const;rcan-can.do_set_mode = rockchip_can_set_mode;rcan-can.do_get_berr_counter = rockchip_can_get_berr_counter;rcan-can.ctrlmode_supported = CAN_CTRLMODE_BERR_REPORTING | CAN_CTRLMODE_LISTENONLY | CAN_CTRLMODE_LOOPBACK | CAN_CTRLMODE_3_SAMPLES; 这部分代码设置 CAN 控制器的各种参数，包括时钟频率、位定时常数、模式设置函数、错误计数器获取函数以及支持的控制模式。 设置设备基地址和其他参数：rcan-base = addr;platform_set_drvdata(pdev, ndev);SET_NETDEV_DEV(ndev, pdev-dev); 这部分代码设置设备的基地址，并将网络设备实例与平台设备关联起来。platform_set_drvdata 函数用于将网络设备实例存储在平台设备的私有数据中，SET_NETDEV_DEV 宏用于将网络设备与设备模型中的设备对象关联。 启用电源管理：pm_runtime_enable(pdev-dev);err = pm_runtime_get_sync(pdev-dev);if (err 0) dev_err(pdev-dev, %s: pm_runtime_get failed(%d) , __func__, err); goto err_pmdisable; 这部分代码启用设备的运行时电源管理，并同步获取设备的电源状态。如果获取电源状态失败，打印错误信息并跳转到错误处理代码。 总结起来，这段代码的主要目的是为设备分配和初始化所需的资源，设置设备参数，并确保设备的电源状态和中断处理都已正确配置。这些步骤是确保设备能够正常工作的基础。 接收struct net_device *ndev = (struct net_device *)dev_id;\tstruct rockchip_can *rcan = netdev_priv(ndev);\tstruct net_device_stats *stats = ndev-stats;\tu8 err_int = ERR_WARN_INT | RX_BUF_OV | PASSIVE_ERR | TX_LOSTARB | BUS_ERR_INT;\tu8 isr;\tisr = readl(rcan-base + CAN_INT);\tif (isr TX_FINISH) /* transmission complete interrupt */ stats-tx_bytes += readl(rcan-base + CAN_TX_FRM_INFO) CAN_DLC_MASK; stats-tx_packets++; rockchip_can_write_cmdreg(rcan, 0); can_get_echo_skb(ndev, 0); netif_wake_queue(ndev); can_led_event(ndev, CAN_LED_EVENT_TX); if (isr RX_FINISH) rockchip_can_rx(ndev);\tif (isr err_int) rockchip_can_clean_rx_info(rcan); if (rockchip_can_err(ndev, isr)) netdev_err(ndev, cant allocate buffer - clearing pending interrupts ); writel(isr, rcan-base + CAN_INT);\trockchip_can_clean_rx_info(rcan);\tnetdev_dbg(ndev, isr: 0x%x , isr);\treturn\tIRQ_HANDLED; 这段代码实现了一个中断处理函数，用于处理 Rockchip CAN 控制器的中断事件。具体作用如下： 获取设备和私有数据结构：struct net_device *ndev = (struct net_device *)dev_id;struct rockchip_can *rcan = netdev_priv(ndev);struct net_device_stats *stats = ndev-stats; 这部分代码通过中断处理函数的参数 dev_id 获取网络设备实例 ndev，然后通过 netdev_priv(ndev) 获取与该网络设备关联的私有数据结构 rcan。同时，获取网络设备的统计数据结构 stats。 定义错误中断标志：u8 err_int = ERR_WARN_INT | RX_BUF_OV | PASSIVE_ERR | TX_LOSTARB | BUS_ERR_INT; 这部分代码定义了一些错误中断标志，分别表示不同类型的错误中断。 读取中断状态寄存器：u8 isr;isr = readl(rcan-base + CAN_INT); 这部分代码从 CAN 控制器的中断状态寄存器读取当前的中断状态。 处理传输完成中断：if (isr TX_FINISH) /* transmission complete interrupt */ stats-tx_bytes += readl(rcan-base + CAN_TX_FRM_INFO) CAN_DLC_MASK; stats-tx_packets++; rockchip_can_write_cmdreg(rcan, 0); can_get_echo_skb(ndev, 0); netif_wake_queue(ndev); can_led_event(ndev, CAN_LED_EVENT_TX); 如果中断状态包含 TX_FINISH 标志，表示传输完成中断。此时： 更新统计数据 tx_bytes 和 tx_packets。 通过 rockchip_can_write_cmdreg 写入命令寄存器，完成传输操作。 调用 can_get_echo_skb 获取回显数据包。 调用 netif_wake_queue 重新启动网络队列。 调用 can_led_event 指示传输事件。 处理接收完成中断：if (isr RX_FINISH) rockchip_can_rx(ndev); 如果中断状态包含 RX_FINISH 标志，表示接收完成中断。此时调用 rockchip_can_rx 函数处理接收到的数据。 处理错误中断：if (isr err_int) rockchip_can_clean_rx_info(rcan); if (rockchip_can_err(ndev, isr)) netdev_err(ndev, cant allocate buffer - clearing pending interrupts ); 如果中断状态包含错误中断标志，表示发生错误中断。此时： 调用 rockchip_can_clean_rx_info 清理接收信息。 调用 rockchip_can_err 处理错误，如果处理失败，打印错误信息。 清除中断标志：writel(isr, rcan-base + CAN_INT);rockchip_can_clean_rx_info(rcan); 这部分代码将中断状态写回中断状态寄存器，以清除中断标志，并再次调用 rockchip_can_clean_rx_info 清理接收信息。 打印调试信息并返回：netdev_dbg(ndev, isr: 0x%x , isr);return IRQ_HANDLED; 打印调试信息，并返回 IRQ_HANDLED 表示中断已被处理。 总体而言，这段代码实现了对 Rockchip CAN 控制器中断的全面处理，包括传输完成、接收完成和错误中断的处理。","categories":["1.平台","Linux","驱动"]},{"title":"OpenMediaVault","path":"/2024/10/31/1-平台-NAS-OpenMediaVault/","content":"OpenMediaVault项目地址：OpenMediaVault OpenMediaVault 是一个基于 Debian Linux 的开源网络附加存储（NAS）解决方案，由 FreeNAS 核心开发者 Volker Theile 领导开发。此项目特别关注于家庭用户和小型办公环境，旨在简单易用，提供直观的界面和高效的功能。 镜像安装手册安装 OpenMediaVault 其实并不复杂，下面是一个详细的步骤指南，帮助用户顺利完成安装。 准备服务器硬件 确保的计算机或服务器具备足够的硬件资源。推荐的最低配置包括： CPU：双核处理器（如 Intel Core i3 或 AMD Athlon 双核） 内存：至少 2GB RAM（更高更好，以支持多个服务） 存储：200GB 以上的硬盘驱动器（HDD 或固态硬盘 SSD） 例如，可以使用旧的台式机，配备 4GB 内存和 500GB 硬盘来部署 OpenMediaVault。 下载 OpenMediaVault 镜像 访问 OpenMediaVault 官方下载页面，下载最新的 ISO 镜像文件。 可选择使用镜像写入工具（如 Rufus 或 balenaEtcher）创建一个可启动的 USB 驱动器。 创建安装媒体 使用 USB 驱动器将下载的 ISO 文件写入。插入 USB 驱动器，启动 Rufus，选择 ISO 文件并点击”开始”。 创建完成后，确保设置 BIOSUEFI 使其从 USB 驱动器启动。 启动安装程序 启动计算机，确保选定的 USB 驱动器为启动介质。 安装界面会出现，跟随提示进行语言、地区及时间设置的选择。 选择安装类型 在”分区”步骤中，可以选择整个硬盘或手动分区。根据需求选择适合的分区方法。 例如，如果硬盘上没有其他数据，可以选择将整个硬盘用于 OpenMediaVault。 完成安装 安装过程通常需要 10 到 20 分钟。完成后，系统会提示重启。 取出 USB 驱动器，重启系统。 访问 Web 界面 使用浏览器访问 http://your-server-ip，其中 your-server-ip 是安装 OpenMediaVault 的设备 IP 地址。 默认用户名为 admin，密码为 openmediavault。首次登录后建议立即更改密码以提高安全性。 配置存储和服务 登录后，可以在界面中设置存储设备、共享文件夹、用户权限以及其他网络服务（如 FTP、Samba）。 例如，创建一个共享文件夹用于备份，将其设置为 SMBCIFS，以便在 Windows 计算机上访问。 通过以上步骤，用户可以轻松安装并开始使用 OpenMediaVault，享受简洁高效的 NAS 解决方案。无论是个人文件存储还是家庭媒体共享，OpenMediaVault 都能提供可靠的服务。 Docker 下的 OpenMediaVault 部署手册环境准备在开始之前，请确保的系统满足以下要求： 操作系统: 推荐使用基于 Debian 的系统（如 Ubuntu 20.04 或 Debian 10）。 Docker: 确保已安装 Docker（版本应为 19.03 及以上），可以通过以下命令进行安装： sudo apt-get updatesudo apt-get install -y apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -add-apt-repository deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stablesudo apt-get updatesudo apt-get install -y docker-ce Docker Compose: 为了便于管理多个容器，将使用 Docker Compose。可以通过以下命令安装： sudo apt-get install -y docker-compose 拉取 OpenMediaVault 镜像接下来，需要从 Docker Hub 上拉取 OpenMediaVault 的镜像。在终端中执行以下命令： docker pull openmediavault 这个过程可能需要一些时间，具体取决于的网络速度和系统性能。 配置 Docker 网络为了让 OMV 能够访问网络和其他容器，需要创建一个自定义 Docker 网络。执行以下命令： docker network create omv-network 通过这种方式，OMV 容器将能和其他应用（如媒体服务器或备份软件）更高效地通信。 创建 Docker Compose 文件在的工作目录中，创建一个 docker-compose.yml 文件，并输入以下配置： version: 3.3services: openmediavault: image: openmediavault container_name: openmediavault networks: - omv-network ports: - 80:80 - 443:443 volumes: - omv_data:/var/lib/openmediavault - /etc/localtime:/etc/localtime:ro restart: unless-stoppednetworks: omv-network:volumes: omv_data: 在这个文件中，设定了以下内容： 服务名称：openmediavault，指定了使用的镜像。 网络设置：设置为之前创建的 omv-network。 端口映射：将本地 80 和 443 端口映射到容器内的相应端口，以便可以通过浏览器访问 OMV（HTTP 和 HTTPS）。 数据持久化：使用 Docker 卷 omv_data 来确保 OMV 的数据在容器重启时依然可用。 重启策略：设置为 unless-stopped，意味着除非手动停止，否则容器会在崩溃后自动重启。 启动 OpenMediaVault在 docker-compose.yml 文件所在的目录下，执行以下命令以启动 OMV 容器： docker-compose up -d 使用 -d 选项可以让容器在后台运行。可以使用以下命令来查看容器的运行状态： docker ps 访问 OpenMediaVault打开的浏览器，在地址栏中输入 http://的服务器IP，将看到 OpenMediaVault 的登录界面。默认的用户名是 admin，密码是 openmediavault。首次登录后，请务必改变默认密码以确保安全。 配置存储和服务登录后，可以通过 OMV 的 Web 界面配置存储、共享文件夹和各种服务，例如 FTP、SMBCIFS、NFS 等。以下是一些基本设置示例： 添加存储介质：在左侧菜单中选择”存储设备”，然后点击”创建”，选择需要格式化的磁盘，设置为 EXT4 格式。 创建共享文件夹：在”共享文件夹”选项中，点击”添加”，并指定刚才创建的存储设备。 设置服务：选择”服务”选项，启用 SMBCIFS 共享，以便 Windows 设备可以访问 OMV 上的文件。 后续管理在使用 OpenMediaVault 的过程中，可能需要定期检查系统更新与服务状态。可以通过命令行使用以下命令更新 Docker 容器： docker-compose pull 然后重启服务： docker-compose up -d","categories":["1.平台","NAS"]},{"title":"RK3568 软路由-OpenWRT","path":"/2024/10/30/1-平台-NAS-RK3568-软路由-OpenWRT/","content":"Firefly Linux 开发指南 1.1. 支持设备列表 主控 板卡型号 RK3568 ROC-RK3568-PCStation-P2 1.2. 登录 IP 、登录密码和 WIFI 名称固件默认登录 IP 为 192.168.1.1，登录密码为 firefly。 默认 WIFI 名称为 OpenWRT-XXXX，无密码 1.3. WAN 口和 LAN 口映射Station P2/ROC-3568-PC： 外壳 Linux 网卡 WAN 口 网口 1 eth0 LAN 口 网口 2 eth1 1.5. 固件烧录1.5.1. 烧写到 SD 卡（推荐）1.5.1.2. 使用 balenaEtcher 制作 SD 启动卡 1.5.2. 烧写到 EMMC1.5.2.1. 下载 RK 烧录工具 安装 RK 驱动助手 下载地址：https://www.t-firefly.com/doc/download/103.html#other_432 安装 Android Tools 烧写工具 下载地址：https://www.t-firefly.com/doc/download/103.html#other_431 下载 RK3566/RK3568 NorFlash2eMMCLoader 下载地址：https://www.t-firefly.com/doc/download/103.html#other_551 切换到 EMMC 存储器 断开电源，将 type-c 线接入开发板，长按 recovery 按键，插上电源上电，进入 maskrom 模式 烧写 RK356x_NorFlash2eMMC-Loader_xxx.img 烧写成功后等待 20s 左右，系统进入 Loader 模式 烧写到 EMMC 存储器 解压固件（注意烧写到 EMMC 的固件必须进行解压） 按下图右键添加一个”OpenWRT“选项，地址为 0，选择解压的固件，然后烧录 1.6. 固件编译1.6.1. 必要条件 安装好 Ubuntu18.04 及其以上版本的系统 1.6.2. 环境搭建sudo apt update -ysudo apt full-upgrade -ysudo apt install -y ack antlr3 asciidoc autoconf automake autopoint binutils bison build-essential \\bzip2 ccache cmake cpio curl device-tree-compiler fastjar flex gawk gettext gcc-multilib g++-multilib \\git gperf haveged help2man intltool libc6-dev-i386 libelf-dev libglib2.0-dev libgmp3-dev libltdl-dev \\libmpc-dev libmpfr-dev libncurses5-dev libncursesw5-dev libreadline-dev libssl-dev libtool lrzsz \\mkisofs msmtp nano ninja-build p7zip p7zip-full patch pkgconf python2.7 python3 python3-pip libpython3-dev qemu-utils \\rsync scons squashfs-tools subversion swig texinfo uglifyjs upx-ucl unzip vim wget xmlto xxd zlib1g-dev 1.6.3. 源码下载git clone https://github.com/FireflyTeam/ledecd lede./scripts/feeds update -a./scripts/feeds install -amake download -j$(nproc) 1.6.4. 源码编译 编译 ROC-RK3568-PC/Station-P2 cp config/station_p2_base_defconfig .configmake defconfigmake V=s -j$(nproc) 1.6.5. 编译成功之后编译成功之后，固件所在路径：bin/targets/rockchip/armv8/ -rw-r--r-- 1 user1 user1 26085956 8月 17 09:49 Station_P2_LEDE_GPT_RAW_20220817.zip 1.7. 扩展分区烧录完固件之后，一般只有几百 MB 的空间供使用，因此需要将分区进行扩展。这一步操作可以在 luci 界面进行配置： 进入磁盘管理，将剩余的空间创建为一个新分区 点击磁盘管理 修改磁盘 创建一个新分区 格式化新分区为 ext4 文件系统 进入挂载点，将新分区挂载到 /overlay 点击挂载点 添加一个新的挂载点 启用此挂载点，并把 UUID 所在分区新创建分区，挂载点为 /overlay 记得保存并应用 保存挂载点信息","tags":["clippings"],"categories":["1.平台","NAS"]},{"title":"CAN驱动500k接收导致CPU某核心满载","path":"/2024/10/29/1-平台-嵌入式-CAN驱动500k接收导致CPU某核心满载/","content":"当 CAN 作为接收端时，快速的数据接收会导致 CPU 4 处于满载状态。这种情况在断开 CAN 接口或者外部设备后恢复正常。在 CAN 接收中断中记录的日志显示，日志的打印时间是与接收到的数据的时间紧密相关。接收的数据速率过高可能在某种程度上影响了 CPU 的处理能力，导致其无法有效管理处理器资源，从而出现过载现象。 在驱动程序 rockchip_canfd.c 中禁用 NAPI 后，系统恢复正常。NAPI（新型自适应中断处理机制）旨在提高网络处理性能，针对不同硬件和软件环境，NAPI 的效果和表现可能存在差异，可能不是最佳选择。 例如，某些硬件可能原本设计用于处理低速率数据，这就使得在高速数据接收时，即便使用了 NAPI，反而会因频繁的中断和处理导致 CPU 负载过重，最终引发性能瓶颈。在这样的情况下，可能需要重新评估数据接收和中断管理策略，为特定的硬件环境优化接收方案或中断处理方式。 // SPDX-License-Identifier: GPL-2.0/* * Copyright (c) 2020 Rockchip Electronics Co. Ltd. * Rockchip CANFD driver */#include linux/delay.h#include linux/iopoll.h#include linux/pinctrl/consumer.h#include linux/clk.h#include linux/errno.h#include linux/init.h#include linux/interrupt.h#include linux/io.h#include linux/kernel.h#include linux/module.h#include linux/netdevice.h#include linux/of.h#include linux/of_device.h#include linux/platform_device.h#include linux/skbuff.h#include linux/spinlock.h#include linux/string.h#include linux/types.h#include linux/can/dev.h#include linux/can/error.h#include linux/can/led.h#include linux/reset.h#include linux/pm_runtime.h#include linux/rockchip/cpu.h/* registers definition */enum rockchip_canfd_reg CAN_MODE = 0x00,\tCAN_CMD = 0x04,\tCAN_STATE = 0x08,\tCAN_INT = 0x0c,\tCAN_INT_MASK = 0x10,\tCAN_LOSTARB_CODE = 0x28,\tCAN_ERR_CODE = 0x2c,\tCAN_RX_ERR_CNT = 0x34,\tCAN_TX_ERR_CNT = 0x38,\tCAN_IDCODE = 0x3c,\tCAN_IDMASK = 0x40,\tCAN_TX_CHECK_FIC = 0x50,\tCAN_NBTP = 0x100,\tCAN_DBTP = 0x104,\tCAN_TDCR = 0x108,\tCAN_TSCC = 0x10c,\tCAN_TSCV = 0x110,\tCAN_TXEFC = 0x114,\tCAN_RXFC = 0x118,\tCAN_AFC = 0x11c,\tCAN_IDCODE0 = 0x120,\tCAN_IDMASK0 = 0x124,\tCAN_IDCODE1 = 0x128,\tCAN_IDMASK1 = 0x12c,\tCAN_IDCODE2 = 0x130,\tCAN_IDMASK2 = 0x134,\tCAN_IDCODE3 = 0x138,\tCAN_IDMASK3 = 0x13c,\tCAN_IDCODE4 = 0x140,\tCAN_IDMASK4 = 0x144,\tCAN_TXFIC = 0x200,\tCAN_TXID = 0x204,\tCAN_TXDAT0 = 0x208,\tCAN_TXDAT1 = 0x20c,\tCAN_TXDAT2 = 0x210,\tCAN_TXDAT3 = 0x214,\tCAN_TXDAT4 = 0x218,\tCAN_TXDAT5 = 0x21c,\tCAN_TXDAT6 = 0x220,\tCAN_TXDAT7 = 0x224,\tCAN_TXDAT8 = 0x228,\tCAN_TXDAT9 = 0x22c,\tCAN_TXDAT10 = 0x230,\tCAN_TXDAT11 = 0x234,\tCAN_TXDAT12 = 0x238,\tCAN_TXDAT13 = 0x23c,\tCAN_TXDAT14 = 0x240,\tCAN_TXDAT15 = 0x244,\tCAN_RXFIC = 0x300,\tCAN_RXID = 0x304,\tCAN_RXTS = 0x308,\tCAN_RXDAT0 = 0x30c,\tCAN_RXDAT1 = 0x310,\tCAN_RXDAT2 = 0x314,\tCAN_RXDAT3 = 0x318,\tCAN_RXDAT4 = 0x31c,\tCAN_RXDAT5 = 0x320,\tCAN_RXDAT6 = 0x324,\tCAN_RXDAT7 = 0x328,\tCAN_RXDAT8 = 0x32c,\tCAN_RXDAT9 = 0x330,\tCAN_RXDAT10 = 0x334,\tCAN_RXDAT11 = 0x338,\tCAN_RXDAT12 = 0x33c,\tCAN_RXDAT13 = 0x340,\tCAN_RXDAT14 = 0x344,\tCAN_RXDAT15 = 0x348,\tCAN_RXFRD = 0x400,\tCAN_TXEFRD = 0x500,;enum ROCKCHIP_CANFD_MODE = 0,\tROCKCHIP_CAN_MODE,\tROCKCHIP_RK3568_CAN_MODE,\tROCKCHIP_RK3568_CAN_MODE_V2,;#define DATE_LENGTH_12_BYTE\t(0x9)#define DATE_LENGTH_16_BYTE\t(0xa)#define DATE_LENGTH_20_BYTE\t(0xb)#define DATE_LENGTH_24_BYTE\t(0xc)#define DATE_LENGTH_32_BYTE\t(0xd)#define DATE_LENGTH_48_BYTE\t(0xe)#define DATE_LENGTH_64_BYTE\t(0xf)#define CAN_TX0_REQ BIT(0)#define CAN_TX1_REQ BIT(1)#define CAN_TX_REQ_FULL ((CAN_TX0_REQ) | (CAN_TX1_REQ))#define MODE_FDOE BIT(15)#define MODE_BRSD BIT(13)#define MODE_SPACE_RX BIT(12)#define MODE_AUTO_RETX BIT(10)#define MODE_RXSORT BIT(7)#define MODE_TXORDER BIT(6)#define MODE_RXSTX BIT(5)#define MODE_LBACK BIT(4)#define MODE_SILENT BIT(3)#define MODE_SELF_TEST BIT(2)#define MODE_SLEEP BIT(1)#define RESET_MODE 0#define WORK_MODE BIT(0)#define RX_FINISH_INT BIT(0)#define TX_FINISH_INT BIT(1)#define ERR_WARN_INT BIT(2)#define RX_BUF_OV_INT BIT(3)#define PASSIVE_ERR_INT BIT(4)#define TX_LOSTARB_INT BIT(5)#define BUS_ERR_INT BIT(6)#define RX_FIFO_FULL_INT\tBIT(7)#define RX_FIFO_OV_INT BIT(8)#define BUS_OFF_INT BIT(9)#define BUS_OFF_RECOVERY_INT\tBIT(10)#define TSC_OV_INT BIT(11)#define TXE_FIFO_OV_INT BIT(12)#define TXE_FIFO_FULL_INT\tBIT(13)#define WAKEUP_INT BIT(14)#define ERR_TYPE_MASK GENMASK(28, 26)#define ERR_TYPE_SHIFT 26#define BIT_ERR 0#define STUFF_ERR 1#define FORM_ERR 2#define ACK_ERR 3#define CRC_ERR 4#define ERR_DIR_RX BIT(25)#define ERR_LOC_MASK GENMASK(15, 0)/* Nominal Bit Timing Prescaler Register (NBTP) */#define NBTP_MODE_3_SAMPLES\tBIT(31)#define NBTP_NSJW_SHIFT 24#define NBTP_NSJW_MASK (0x7f NBTP_NSJW_SHIFT)#define NBTP_NBRP_SHIFT 16#define NBTP_NBRP_MASK (0xff NBTP_NBRP_SHIFT)#define NBTP_NTSEG2_SHIFT\t8#define NBTP_NTSEG2_MASK\t(0x7f NBTP_NTSEG2_SHIFT)#define NBTP_NTSEG1_SHIFT\t0#define NBTP_NTSEG1_MASK\t(0x7f NBTP_NTSEG1_SHIFT)/* Data Bit Timing Prescaler Register (DBTP) */#define DBTP_MODE_3_SAMPLES\tBIT(21)#define DBTP_DSJW_SHIFT 17#define DBTP_DSJW_MASK (0xf DBTP_DSJW_SHIFT)#define DBTP_DBRP_SHIFT 9#define DBTP_DBRP_MASK (0xff DBTP_DBRP_SHIFT)#define DBTP_DTSEG2_SHIFT\t5#define DBTP_DTSEG2_MASK\t(0xf DBTP_DTSEG2_SHIFT)#define DBTP_DTSEG1_SHIFT\t0#define DBTP_DTSEG1_MASK\t(0x1f DBTP_DTSEG1_SHIFT)/* Transmitter Delay Compensation Register (TDCR) */#define TDCR_TDCO_SHIFT 1#define TDCR_TDCO_MASK (0x3f TDCR_TDCO_SHIFT)#define TDCR_TDC_ENABLE BIT(0)#define TX_FD_ENABLE BIT(5)#define TX_FD_BRS_ENABLE\tBIT(4)#define FIFO_ENABLE BIT(0)#define RX_FIFO_CNT0_SHIFT\t4#define RX_FIFO_CNT0_MASK\t(0x7 RX_FIFO_CNT0_SHIFT)#define RX_FIFO_CNT1_SHIFT\t5#define RX_FIFO_CNT1_MASK\t(0x7 RX_FIFO_CNT1_SHIFT)#define FORMAT_SHIFT 7#define FORMAT_MASK (0x1 FORMAT_SHIFT)#define RTR_SHIFT 6#define RTR_MASK (0x1 RTR_SHIFT)#define FDF_SHIFT 5#define FDF_MASK (0x1 FDF_SHIFT)#define BRS_SHIFT 4#define BRS_MASK (0x1 BRS_SHIFT)#define DLC_SHIFT 0#define DLC_MASK (0xF DLC_SHIFT)#define CAN_RF_SIZE 0x48#define CAN_TEF_SIZE 0x8#define CAN_TXEFRD_OFFSET(n)\t(CAN_TXEFRD + CAN_TEF_SIZE * (n))#define CAN_RXFRD_OFFSET(n)\t(CAN_RXFRD + CAN_RF_SIZE * (n))#define CAN_RX_FILTER_MASK\t0x1fffffff#define NOACK_ERR_FLAG 0xc200800#define CAN_BUSOFF_FLAG 0x20#define DRV_NAME\trockchip_canfd/* rockchip_canfd private data structure */struct rockchip_canfd struct can_priv can;\tstruct device *dev;\tstruct napi_struct napi;\tstruct clk_bulk_data *clks;\tint num_clks;\tstruct reset_control *reset;\tvoid __iomem *base;\tu32 irqstatus;\tunsigned long mode;\tint rx_fifo_shift;\tu32 rx_fifo_mask;\tbool txtorx;\tu32 tx_invalid[4];\tstruct delayed_work tx_err_work;\tu32 noack_cnt;\tu32 delay_time_ms;;static inline u32 rockchip_canfd_read(const struct rockchip_canfd *priv, enum rockchip_canfd_reg reg)\treturn readl(priv-base + reg);static inline void rockchip_canfd_write(const struct rockchip_canfd *priv, enum rockchip_canfd_reg reg, u32 val)\twritel(val, priv-base + reg);static const struct can_bittiming_const rockchip_canfd_bittiming_const = .name = DRV_NAME,\t.tseg1_min = 1,\t.tseg1_max = 128,\t.tseg2_min = 1,\t.tseg2_max = 128,\t.sjw_max = 128,\t.brp_min = 1,\t.brp_max = 256,\t.brp_inc = 2,;static const struct can_bittiming_const rockchip_canfd_data_bittiming_const = .name = DRV_NAME,\t.tseg1_min = 1,\t.tseg1_max = 32,\t.tseg2_min = 1,\t.tseg2_max = 16,\t.sjw_max = 16,\t.brp_min = 1,\t.brp_max = 256,\t.brp_inc = 2,;static int set_reset_mode(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\treset_control_assert(rcan-reset);\tudelay(2);\treset_control_deassert(rcan-reset);\trockchip_canfd_write(rcan, CAN_MODE, 0);\tnetdev_dbg(ndev, %s MODE=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_MODE));\treturn 0;static int set_normal_mode(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tu32 val;\tval = rockchip_canfd_read(rcan, CAN_MODE);\tval |= WORK_MODE;\trockchip_canfd_write(rcan, CAN_MODE, val);\tnetdev_dbg(ndev, %s MODE=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_MODE));\treturn 0;/* bittiming is called in reset_mode only */static int rockchip_canfd_set_bittiming(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tconst struct can_bittiming *bt = rcan-can.bittiming;\tconst struct can_bittiming *dbt = rcan-can.data_bittiming;\tu16 brp, sjw, tseg1, tseg2;\tu32 reg_btp;\tbrp = (bt-brp 1) - 1;\tsjw = bt-sjw - 1;\ttseg1 = bt-prop_seg + bt-phase_seg1 - 1;\ttseg2 = bt-phase_seg2 - 1;\treg_btp = (brp NBTP_NBRP_SHIFT) | (sjw NBTP_NSJW_SHIFT) | (tseg1 NBTP_NTSEG1_SHIFT) | (tseg2 NBTP_NTSEG2_SHIFT);\tif (rcan-can.ctrlmode CAN_CTRLMODE_3_SAMPLES) reg_btp |= NBTP_MODE_3_SAMPLES;\trockchip_canfd_write(rcan, CAN_NBTP, reg_btp);\tif (rcan-can.ctrlmode CAN_CTRLMODE_FD) reg_btp = 0; brp = (dbt-brp 1) - 1; sjw = dbt-sjw - 1; tseg1 = dbt-prop_seg + dbt-phase_seg1 - 1; tseg2 = dbt-phase_seg2 - 1; if (dbt-bitrate 2200000) u32 tdco; /* Equation based on Boschs ROCKCHIP_CAN User Manuals * Transmitter Delay Compensation Section */ tdco = (rcan-can.clock.freq / dbt-bitrate) * 2 / 3; /* Max valid TDCO value is 63 */ if (tdco 63) tdco = 63; rockchip_canfd_write(rcan, CAN_TDCR, (tdco TDCR_TDCO_SHIFT) | TDCR_TDC_ENABLE); reg_btp |= (brp DBTP_DBRP_SHIFT) | (sjw DBTP_DSJW_SHIFT) | (tseg1 DBTP_DTSEG1_SHIFT) | (tseg2 DBTP_DTSEG2_SHIFT); if (rcan-can.ctrlmode CAN_CTRLMODE_3_SAMPLES) reg_btp |= DBTP_MODE_3_SAMPLES; rockchip_canfd_write(rcan, CAN_DBTP, reg_btp); if (bt-bitrate 200000) rcan-delay_time_ms = 1;\telse if (bt-bitrate 50000) rcan-delay_time_ms = 5;\telse rcan-delay_time_ms = 20;\tnetdev_dbg(ndev, %s NBTP=0x%08x, DBTP=0x%08x, TDCR=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_NBTP), rockchip_canfd_read(rcan, CAN_DBTP), rockchip_canfd_read(rcan, CAN_TDCR));\treturn 0;static int rockchip_canfd_get_berr_counter(const struct net_device *ndev, struct can_berr_counter *bec)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tint err;\terr = pm_runtime_get_sync(rcan-dev);\tif (err 0) netdev_err(ndev, %s: pm_runtime_get failed(%d) , __func__, err); return err; bec-rxerr = rockchip_canfd_read(rcan, CAN_RX_ERR_CNT);\tbec-txerr = rockchip_canfd_read(rcan, CAN_TX_ERR_CNT);\tpm_runtime_put(rcan-dev);\tnetdev_dbg(ndev, %s RX_ERR_CNT=0x%08x, TX_ERR_CNT=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_RX_ERR_CNT), rockchip_canfd_read(rcan, CAN_TX_ERR_CNT));\treturn 0;static int rockchip_canfd_start(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tu32 val;\t/* we need to enter the reset mode */\tset_reset_mode(ndev);\trockchip_canfd_write(rcan, CAN_INT_MASK, 0);\t/* RECEIVING FILTER, accept all */\trockchip_canfd_write(rcan, CAN_IDCODE, 0);\trockchip_canfd_write(rcan, CAN_IDMASK, CAN_RX_FILTER_MASK);\trockchip_canfd_write(rcan, CAN_IDCODE0, 0);\trockchip_canfd_write(rcan, CAN_IDMASK0, CAN_RX_FILTER_MASK);\trockchip_canfd_write(rcan, CAN_IDCODE1, 0);\trockchip_canfd_write(rcan, CAN_IDMASK1, CAN_RX_FILTER_MASK);\trockchip_canfd_write(rcan, CAN_IDCODE2, 0);\trockchip_canfd_write(rcan, CAN_IDMASK2, CAN_RX_FILTER_MASK);\trockchip_canfd_write(rcan, CAN_IDCODE3, 0);\trockchip_canfd_write(rcan, CAN_IDMASK3, CAN_RX_FILTER_MASK);\trockchip_canfd_write(rcan, CAN_IDCODE4, 0);\trockchip_canfd_write(rcan, CAN_IDMASK4, CAN_RX_FILTER_MASK);\t/* set mode */\tval = rockchip_canfd_read(rcan, CAN_MODE);\t/* rx fifo enable */\trockchip_canfd_write(rcan, CAN_RXFC, rockchip_canfd_read(rcan, CAN_RXFC) | FIFO_ENABLE);\t/* Mode */\tval |= MODE_FDOE;\t/* Loopback Mode */\tif (rcan-can.ctrlmode CAN_CTRLMODE_LOOPBACK) val |= MODE_SELF_TEST | MODE_LBACK;\t/* Listen-only mode */\tif (rcan-can.ctrlmode CAN_CTRLMODE_LISTENONLY) val |= MODE_SILENT;\trockchip_canfd_write(rcan, CAN_MODE, val);\trockchip_canfd_set_bittiming(ndev);\tset_normal_mode(ndev);\trcan-can.state = CAN_STATE_ERROR_ACTIVE;\tnetdev_dbg(ndev, %s MODE=0x%08x, INT_MASK=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_MODE), rockchip_canfd_read(rcan, CAN_INT_MASK));\treturn 0;static int rockchip_canfd_stop(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\trcan-can.state = CAN_STATE_STOPPED;\t/* we need to enter reset mode */\tset_reset_mode(ndev);\t/* disable all interrupts */\trockchip_canfd_write(rcan, CAN_INT_MASK, 0xffff);\tnetdev_dbg(ndev, %s MODE=0x%08x, INT_MASK=0x%08x , __func__, rockchip_canfd_read(rcan, CAN_MODE), rockchip_canfd_read(rcan, CAN_INT_MASK));\treturn 0;static int rockchip_canfd_set_mode(struct net_device *ndev, enum can_mode mode)\tint err;\tswitch (mode) case CAN_MODE_START: err = rockchip_canfd_start(ndev); if (err) netdev_err(ndev, starting CAN controller failed! ); return err; if (netif_queue_stopped(ndev)) netif_wake_queue(ndev); break;\tdefault: return -EOPNOTSUPP; return 0;static void rockchip_canfd_tx_err_delay_work(struct work_struct *work)\tstruct rockchip_canfd *rcan = container_of(work, struct rockchip_canfd, tx_err_work.work);\tstruct net_device *ndev = dev_get_drvdata(rcan-dev); rockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) | MODE_SPACE_RX);\trockchip_canfd_write(rcan, CAN_CMD, CAN_TX0_REQ);\trockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) (~MODE_SPACE_RX));\trcan-noack_cnt++;\tschedule_delayed_work(rcan-tx_err_work, msecs_to_jiffies(rcan-delay_time_ms));\tif (rcan-noack_cnt 50) cancel_delayed_work(rcan-tx_err_work); rockchip_canfd_write(rcan, CAN_INT_MASK, 0xffff); can_bus_off(ndev); rcan-noack_cnt = 0;\t/* transmit a CAN message * message layout in the sk_buff should be like this: * xx xx xx xx ff ll 00 11 22 33 44 55 66 77 * [ can_id ] [flags] [len] [can data (up to 8 bytes] */static int rockchip_canfd_start_xmit(struct sk_buff *skb, struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tstruct canfd_frame *cf = (struct canfd_frame *)skb-data;\tu32 id, dlc;\tu32 cmd = CAN_TX0_REQ;\tint i;\tunsigned long flags;\tif (can_dropped_invalid_skb(ndev, skb)) return NETDEV_TX_OK;\tnetif_stop_queue(ndev);\tif (rockchip_canfd_read(rcan, CAN_CMD) CAN_TX0_REQ) cmd = CAN_TX1_REQ;\t/* Watch carefully on the bit sequence */\tif (cf-can_id CAN_EFF_FLAG) /* Extended CAN ID format */ id = cf-can_id CAN_EFF_MASK; dlc = can_len2dlc(cf-len) DLC_MASK; dlc |= FORMAT_MASK; /* Extended frames remote TX request */ if (cf-can_id CAN_RTR_FLAG) dlc |= RTR_MASK; else /* Standard CAN ID format */ id = cf-can_id CAN_SFF_MASK; dlc = can_len2dlc(cf-len) DLC_MASK; /* Standard frames remote TX request */ if (cf-can_id CAN_RTR_FLAG) dlc |= RTR_MASK; if ((rcan-can.ctrlmode CAN_CTRLMODE_FD) can_is_canfd_skb(skb)) dlc |= TX_FD_ENABLE; if (cf-flags CANFD_BRS) dlc |= TX_FD_BRS_ENABLE; if (rcan-txtorx rcan-mode = ROCKCHIP_RK3568_CAN_MODE cf-can_id CAN_EFF_FLAG) rockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) | MODE_RXSTX);\telse rockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) (~MODE_RXSTX));\tif (!rcan-txtorx rcan-mode = ROCKCHIP_RK3568_CAN_MODE cf-can_id CAN_EFF_FLAG) /* Two frames are sent consecutively. * Before the first frame is tx finished, * the register of the second frame is configured. * Dont be interrupted in the middle. */ local_irq_save(flags); rockchip_canfd_write(rcan, CAN_TXID, rcan-tx_invalid[1]); rockchip_canfd_write(rcan, CAN_TXFIC, rcan-tx_invalid[0]); rockchip_canfd_write(rcan, CAN_TXDAT0, rcan-tx_invalid[2]); rockchip_canfd_write(rcan, CAN_TXDAT1, rcan-tx_invalid[3]); rockchip_canfd_write(rcan, CAN_CMD, CAN_TX0_REQ); rockchip_canfd_write(rcan, CAN_TXID, id); rockchip_canfd_write(rcan, CAN_TXFIC, dlc); for (i = 0; i cf-len; i += 4) rockchip_canfd_write(rcan, CAN_TXDAT0 + i, *(u32 *)(cf-data + i)); can_put_echo_skb(skb, ndev, 0); rockchip_canfd_write(rcan, CAN_CMD, CAN_TX1_REQ); local_irq_restore(flags); return NETDEV_TX_OK; rockchip_canfd_write(rcan, CAN_TXID, id);\trockchip_canfd_write(rcan, CAN_TXFIC, dlc);\tfor (i = 0; i cf-len; i += 4) rockchip_canfd_write(rcan, CAN_TXDAT0 + i, *(u32 *)(cf-data + i));\tcan_put_echo_skb(skb, ndev, 0);\trockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) | MODE_SPACE_RX);\trockchip_canfd_write(rcan, CAN_CMD, cmd);\trockchip_canfd_write(rcan, CAN_MODE, rockchip_canfd_read(rcan, CAN_MODE) (~MODE_SPACE_RX));\tschedule_delayed_work(rcan-tx_err_work, msecs_to_jiffies(rcan-delay_time_ms));\treturn NETDEV_TX_OK;static int rockchip_canfd_rx(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tstruct net_device_stats *stats = ndev-stats;\tstruct canfd_frame *cf;\tstruct sk_buff *skb;\tu32 id_rockchip_canfd, dlc;\tint i = 0;\tu32 __maybe_unused ts, ret;\tu32 data[16];\tdlc = rockchip_canfd_read(rcan, CAN_RXFRD);\tid_rockchip_canfd = rockchip_canfd_read(rcan, CAN_RXFRD);\tts = rockchip_canfd_read(rcan, CAN_RXFRD);\tfor (i = 0; i ARRAY_SIZE(data); i++) data[i] = rockchip_canfd_read(rcan, CAN_RXFRD);\tif (rcan-mode = ROCKCHIP_RK3568_CAN_MODE) /* may be an empty frame */ if (!dlc !id_rockchip_canfd) return 1; if (rcan-txtorx) if (rockchip_canfd_read(rcan, CAN_TX_CHECK_FIC) FORMAT_MASK) ret = rockchip_canfd_read(rcan, CAN_TXID) CAN_SFF_MASK; if ((id_rockchip_canfd == ret) !(dlc FORMAT_MASK)) rockchip_canfd_write(rcan, CAN_TX_CHECK_FIC, ts | CAN_TX0_REQ); return 1; /* create zeroed CAN frame buffer */\tif (dlc FDF_MASK) skb = alloc_canfd_skb(ndev, cf);\telse skb = alloc_can_skb(ndev, (struct can_frame **)cf);\tif (!skb) stats-rx_dropped++; return 1; /* Change CAN data length format to socketCAN data format */\tif (dlc FDF_MASK) cf-len = can_dlc2len(dlc DLC_MASK);\telse cf-len = get_can_dlc(dlc DLC_MASK);\t/* Change CAN ID format to socketCAN ID format */\tif (dlc FORMAT_MASK) /* The received frame is an Extended format frame */ cf-can_id = id_rockchip_canfd; cf-can_id |= CAN_EFF_FLAG; if (dlc RTR_MASK) cf-can_id |= CAN_RTR_FLAG; else /* The received frame is a standard format frame */ cf-can_id = id_rockchip_canfd; if (dlc RTR_MASK) cf-can_id |= CAN_RTR_FLAG; if (dlc BRS_MASK) cf-flags |= CANFD_BRS;\tif (!(cf-can_id CAN_RTR_FLAG)) /* Change CAN data format to socketCAN data format */ for (i = 0; i cf-len; i += 4) *(u32 *)(cf-data + i) = data[i / 4]; stats-rx_packets++;\tstats-rx_bytes += cf-len;\tnetif_rx(skb);\tcan_led_event(ndev, CAN_LED_EVENT_RX);\treturn 1;static int rockchip_canfd_get_rx_fifo_cnt(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tint quota = 0;\tif (read_poll_timeout_atomic(rockchip_canfd_read, quota, (quota rcan-rx_fifo_mask) rcan-rx_fifo_shift, 0, 500000, false, rcan, CAN_RXFC)) netdev_dbg(ndev, Warning: get fifo cnt failed );\tquota = (quota rcan-rx_fifo_mask) rcan-rx_fifo_shift;\treturn quota;/* rockchip_canfd_rx_poll - Poll routine for rx packets (NAPI) * @napi:\tnapi structure pointer * @quota:\tMax number of rx packets to be processed. * * This is the poll routine for rx part. * It will process the packets maximux quota value. * * Return: number of packets received */static int rockchip_canfd_rx_poll(struct napi_struct *napi, int quota)\tstruct net_device *ndev = napi-dev;\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tint work_done = 0;\tquota = rockchip_canfd_get_rx_fifo_cnt(ndev);\tif (quota 6) quota = 6;\tif (quota) while (work_done quota) work_done += rockchip_canfd_rx(ndev); if (work_done) can_led_event(ndev, CAN_LED_EVENT_RX);\tif (work_done 6) napi_complete_done(napi, work_done); rockchip_canfd_write(rcan, CAN_INT_MASK, 0); return work_done;static void rockchip_canfd_tx_retry(struct net_device *ndev, u32 isr)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tu32 err_code = rockchip_canfd_read(rcan, CAN_ERR_CODE);\tu32 data[4], mode;\tint i = 0;\tif ((isr TX_LOSTARB_INT) || ((!(err_code 0x2000000)) (err_code 0x1ff0000))) mode = rockchip_canfd_read(rcan, CAN_MODE); for (i = 0; i ARRAY_SIZE(data); i++) data[i] = rockchip_canfd_read(rcan, CAN_TXFIC + i * 4); rockchip_canfd_write(rcan, CAN_INT_MASK, 0xffff); rockchip_canfd_start(ndev); rockchip_canfd_write(rcan, CAN_MODE, mode); for (i = 0; i ARRAY_SIZE(data); i++) rockchip_canfd_write(rcan, CAN_TXFIC + i * 4, data[i]);\tstatic int rockchip_canfd_err(struct net_device *ndev, u32 isr)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tstruct net_device_stats *stats = ndev-stats;\tstruct can_frame *cf;\tstruct sk_buff *skb;\tunsigned int rxerr, txerr;\tu32 sta_reg;\tskb = alloc_can_err_skb(ndev, cf);\trxerr = rockchip_canfd_read(rcan, CAN_RX_ERR_CNT);\ttxerr = rockchip_canfd_read(rcan, CAN_TX_ERR_CNT);\tsta_reg = rockchip_canfd_read(rcan, CAN_STATE);\tif (skb) cf-data[6] = txerr; cf-data[7] = rxerr; if (isr BUS_OFF_INT) rcan-can.state = CAN_STATE_BUS_OFF; rcan-can.can_stats.bus_off++; cf-can_id |= CAN_ERR_BUSOFF; else if (isr ERR_WARN_INT) rcan-can.can_stats.error_warning++; rcan-can.state = CAN_STATE_ERROR_WARNING; /* error warning state */ if (likely(skb)) cf-can_id |= CAN_ERR_CRTL; cf-data[1] = (txerr rxerr) ? CAN_ERR_CRTL_TX_WARNING : CAN_ERR_CRTL_RX_WARNING; cf-data[6] = txerr; cf-data[7] = rxerr; else if (isr PASSIVE_ERR_INT) rcan-can.can_stats.error_passive++; rcan-can.state = CAN_STATE_ERROR_PASSIVE; /* error passive state */ cf-can_id |= CAN_ERR_CRTL; cf-data[1] = (txerr rxerr) ? CAN_ERR_CRTL_TX_WARNING : CAN_ERR_CRTL_RX_WARNING; cf-data[6] = txerr; cf-data[7] = rxerr; if (rcan-can.state = CAN_STATE_BUS_OFF || ((sta_reg CAN_BUSOFF_FLAG) == CAN_BUSOFF_FLAG)) cancel_delayed_work(rcan-tx_err_work); rockchip_canfd_write(rcan, CAN_INT_MASK, 0xffff); can_bus_off(ndev); stats-rx_packets++;\tstats-rx_bytes += cf-can_dlc;\tnetif_rx(skb);\treturn 0;static irqreturn_t rockchip_canfd_interrupt(int irq, void *dev_id)\tstruct net_device *ndev = (struct net_device *)dev_id;\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tstruct net_device_stats *stats = ndev-stats;\tu32 err_int = ERR_WARN_INT | RX_BUF_OV_INT | PASSIVE_ERR_INT | BUS_ERR_INT | BUS_OFF_INT;\tu32 isr;\tu32 dlc = 0;\tu32 quota, work_done = 0;\tisr = rockchip_canfd_read(rcan, CAN_INT);\tif (isr TX_FINISH_INT) cancel_delayed_work(rcan-tx_err_work); dlc = rockchip_canfd_read(rcan, CAN_TXFIC); /* transmission complete interrupt */ if (dlc FDF_MASK) stats-tx_bytes += can_dlc2len(dlc DLC_MASK); else stats-tx_bytes += (dlc DLC_MASK); stats-tx_packets++; if (rcan-txtorx rcan-mode = ROCKCHIP_RK3568_CAN_MODE dlc FORMAT_MASK) rockchip_canfd_write(rcan, CAN_TX_CHECK_FIC, FORMAT_MASK); quota = rockchip_canfd_get_rx_fifo_cnt(ndev); if (quota) while (work_done quota) work_done += rockchip_canfd_rx(ndev); if (rockchip_canfd_read(rcan, CAN_TX_CHECK_FIC) CAN_TX0_REQ) rockchip_canfd_write(rcan, CAN_CMD, CAN_TX1_REQ); rockchip_canfd_write(rcan, CAN_TX_CHECK_FIC, 0); if (read_poll_timeout_atomic(rockchip_canfd_read, quota, !(quota 0x3), 0, 5000000, false, rcan, CAN_CMD)) netdev_err(ndev, Warning: wait tx req timeout! ); rockchip_canfd_write(rcan, CAN_CMD, 0); can_get_echo_skb(ndev, 0); netif_wake_queue(ndev); can_led_event(ndev, CAN_LED_EVENT_TX); rcan-noack_cnt = 0; if ((isr RX_FINISH_INT) || (isr RX_FIFO_OV_INT) || (isr RX_FIFO_FULL_INT)) if (rcan-mode == ROCKCHIP_RK3568_CAN_MODE_V2) //rockchip_canfd_write(rcan, CAN_INT_MASK, 0x1); work_done = 0; quota = (rockchip_canfd_read(rcan, CAN_RXFC) rcan-rx_fifo_mask) rcan-rx_fifo_shift; if (quota) while (work_done quota) work_done += rockchip_canfd_rx(ndev); else work_done = 0; quota = (rockchip_canfd_read(rcan, CAN_RXFC) rcan-rx_fifo_mask) rcan-rx_fifo_shift; if (quota) while (work_done quota) work_done += rockchip_canfd_rx(ndev); if (isr err_int) /* error interrupt */ if (rockchip_canfd_err(ndev, isr)) netdev_err(ndev, cant allocate buffer - clearing pending interrupts ); rockchip_canfd_tx_retry(ndev, isr);\trockchip_canfd_write(rcan, CAN_INT, isr);\treturn IRQ_HANDLED;static int rockchip_canfd_open(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tint err;\t/* common open */\terr = open_candev(ndev);\tif (err) return err;\terr = pm_runtime_get_sync(rcan-dev);\tif (err 0) netdev_err(ndev, %s: pm_runtime_get failed(%d) , __func__, err); goto exit; err = rockchip_canfd_start(ndev);\tif (err) netdev_err(ndev, could not start CAN peripheral ); goto exit_can_start; can_led_event(ndev, CAN_LED_EVENT_OPEN);//\tif (rcan-mode == ROCKCHIP_RK3568_CAN_MODE_V2)// napi_enable(rcan-napi);\tnetif_start_queue(ndev);\tnetdev_dbg(ndev, %s , __func__);\treturn 0;exit_can_start:\tpm_runtime_put(rcan-dev);exit:\tclose_candev(ndev);\treturn err;static int rockchip_canfd_close(struct net_device *ndev)\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tnetif_stop_queue(ndev);//\tif (rcan-mode == ROCKCHIP_RK3568_CAN_MODE_V2)// napi_disable(rcan-napi);\trockchip_canfd_stop(ndev);\tclose_candev(ndev);\tcan_led_event(ndev, CAN_LED_EVENT_STOP);\tpm_runtime_put(rcan-dev);\tcancel_delayed_work_sync(rcan-tx_err_work);\tnetdev_dbg(ndev, %s , __func__);\treturn 0;static const struct net_device_ops rockchip_canfd_netdev_ops = .ndo_open = rockchip_canfd_open,\t.ndo_stop = rockchip_canfd_close,\t.ndo_start_xmit = rockchip_canfd_start_xmit,\t.ndo_change_mtu = can_change_mtu,;/** * rockchip_canfd_suspend - Suspend method for the driver * @dev:\tAddress of the device structure * * Put the driver into low power mode. * Return: 0 on success and failure value on error */static int __maybe_unused rockchip_canfd_suspend(struct device *dev)\tstruct net_device *ndev = dev_get_drvdata(dev);\tif (netif_running(ndev)) netif_stop_queue(ndev); netif_device_detach(ndev); rockchip_canfd_stop(ndev); return pm_runtime_force_suspend(dev);/** * rockchip_canfd_resume - Resume from suspend * @dev:\tAddress of the device structure * * Resume operation after suspend. * Return: 0 on success and failure value on error */static int __maybe_unused rockchip_canfd_resume(struct device *dev)\tstruct net_device *ndev = dev_get_drvdata(dev);\tint ret;\tret = pm_runtime_force_resume(dev);\tif (ret) dev_err(dev, pm_runtime_force_resume failed on resume ); return ret; if (netif_running(ndev)) ret = rockchip_canfd_start(ndev); if (ret) dev_err(dev, rockchip_canfd_chip_start failed on resume ); return ret; netif_device_attach(ndev); netif_start_queue(ndev); return 0;/** * rockchip_canfd_runtime_suspend - Runtime suspend method for the driver * @dev:\tAddress of the device structure * * Put the driver into low power mode. * Return: 0 always */static int __maybe_unused rockchip_canfd_runtime_suspend(struct device *dev)\tstruct net_device *ndev = dev_get_drvdata(dev);\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tclk_bulk_disable_unprepare(rcan-num_clks, rcan-clks);\treturn 0;/** * rockchip_canfd_runtime_resume - Runtime resume from suspend * @dev:\tAddress of the device structure * * Resume operation after suspend. * Return: 0 on success and failure value on error */static int __maybe_unused rockchip_canfd_runtime_resume(struct device *dev)\tstruct net_device *ndev = dev_get_drvdata(dev);\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tint ret;\tret = clk_bulk_prepare_enable(rcan-num_clks, rcan-clks);\tif (ret) dev_err(dev, Cannot enable clock. ); return ret; return 0;static const struct dev_pm_ops rockchip_canfd_dev_pm_ops = SET_SYSTEM_SLEEP_PM_OPS(rockchip_canfd_suspend, rockchip_canfd_resume)\tSET_RUNTIME_PM_OPS(rockchip_canfd_runtime_suspend, rockchip_canfd_runtime_resume, NULL);static const struct of_device_id rockchip_canfd_of_match[] = .compatible = rockchip,canfd-1.0, .data = (void *)ROCKCHIP_CANFD_MODE\t, .compatible = rockchip,can-2.0, .data = (void *)ROCKCHIP_CAN_MODE\t, .compatible = rockchip,rk3568-can-2.0, .data = (void *)ROCKCHIP_RK3568_CAN_MODE\t,\t,;MODULE_DEVICE_TABLE(of, rockchip_canfd_of_match);static int rockchip_canfd_probe(struct platform_device *pdev)\tstruct net_device *ndev;\tstruct rockchip_canfd *rcan;\tstruct resource *res;\tvoid __iomem *addr;\tint err, irq;\tirq = platform_get_irq(pdev, 0);\tif (irq 0) dev_err(pdev-dev, could not get a valid irq ); return -ENODEV; res = platform_get_resource(pdev, IORESOURCE_MEM, 0);\taddr = devm_ioremap_resource(pdev-dev, res);\tif (IS_ERR(addr)) return -EBUSY;\tndev = alloc_candev(sizeof(struct rockchip_canfd), 1);\tif (!ndev) dev_err(pdev-dev, could not allocate memory for CANFD device ); return -ENOMEM; rcan = netdev_priv(ndev);\t/* register interrupt handler */\terr = devm_request_irq(pdev-dev, irq, rockchip_canfd_interrupt, 0, ndev-name, ndev);\tif (err) dev_err(pdev-dev, request_irq err: %d , err); return err; rcan-reset = devm_reset_control_array_get(pdev-dev, false, false);\tif (IS_ERR(rcan-reset)) if (PTR_ERR(rcan-reset) != -EPROBE_DEFER) dev_err(pdev-dev, failed to get canfd reset lines ); return PTR_ERR(rcan-reset); rcan-num_clks = devm_clk_bulk_get_all(pdev-dev, rcan-clks);\tif (rcan-num_clks 1) return -ENODEV;\trcan-mode = (unsigned long)of_device_get_match_data(pdev-dev);\tif ((cpu_is_rk3566() || cpu_is_rk3568()) (rockchip_get_cpu_version() == 3)) rcan-mode = ROCKCHIP_RK3568_CAN_MODE_V2;\trcan-base = addr;\trcan-can.clock.freq = clk_get_rate(rcan-clks[0].clk);\trcan-dev = pdev-dev;\trcan-can.state = CAN_STATE_STOPPED;\tswitch (rcan-mode) case ROCKCHIP_CANFD_MODE: rcan-can.bittiming_const = rockchip_canfd_bittiming_const; rcan-can.data_bittiming_const = rockchip_canfd_data_bittiming_const; rcan-can.do_set_mode = rockchip_canfd_set_mode; rcan-can.do_get_berr_counter = rockchip_canfd_get_berr_counter; rcan-can.do_set_bittiming = rockchip_canfd_set_bittiming; rcan-can.do_set_data_bittiming = rockchip_canfd_set_bittiming; rcan-can.ctrlmode = CAN_CTRLMODE_FD; /* IFI CANFD can do both Bosch FD and ISO FD */ rcan-can.ctrlmode_supported = CAN_CTRLMODE_LOOPBACK | CAN_CTRLMODE_FD; rcan-rx_fifo_shift = RX_FIFO_CNT0_SHIFT; rcan-rx_fifo_mask = RX_FIFO_CNT0_MASK; break;\tcase ROCKCHIP_CAN_MODE:\tcase ROCKCHIP_RK3568_CAN_MODE:\tcase ROCKCHIP_RK3568_CAN_MODE_V2: rcan-can.bittiming_const = rockchip_canfd_bittiming_const; rcan-can.do_set_mode = rockchip_canfd_set_mode; rcan-can.do_get_berr_counter = rockchip_canfd_get_berr_counter; rcan-can.ctrlmode_supported = CAN_CTRLMODE_BERR_REPORTING | CAN_CTRLMODE_LISTENONLY | CAN_CTRLMODE_LOOPBACK | CAN_CTRLMODE_3_SAMPLES; rcan-rx_fifo_shift = RX_FIFO_CNT0_SHIFT; rcan-rx_fifo_mask = RX_FIFO_CNT0_MASK; break;\tdefault: return -EINVAL; if (rcan-mode == ROCKCHIP_CAN_MODE) rcan-rx_fifo_shift = RX_FIFO_CNT1_SHIFT; rcan-rx_fifo_mask = RX_FIFO_CNT1_MASK; if (device_property_read_u32_array(pdev-dev, rockchip,tx-invalid-info, rcan-tx_invalid, 4)) rcan-txtorx = 1;\tif (rcan-mode == ROCKCHIP_RK3568_CAN_MODE_V2) rcan-txtorx = 0; //netif_napi_add(ndev, rcan-napi, rockchip_canfd_rx_poll, 6); ndev-netdev_ops = rockchip_canfd_netdev_ops;\tndev-irq = irq;\tndev-flags |= IFF_ECHO;\trcan-can.restart_ms = 100;\trcan-noack_cnt = 0;\tirq_set_affinity_hint(irq, get_cpu_mask(num_online_cpus() - 1));\tINIT_DELAYED_WORK(rcan-tx_err_work, rockchip_canfd_tx_err_delay_work);\tplatform_set_drvdata(pdev, ndev);\tSET_NETDEV_DEV(ndev, pdev-dev);\tpm_runtime_enable(pdev-dev);\terr = pm_runtime_get_sync(pdev-dev);\tif (err 0) dev_err(pdev-dev, %s: pm_runtime_get failed(%d) , __func__, err); goto err_pmdisable; err = register_candev(ndev);\tif (err) dev_err(pdev-dev, registering %s failed (err=%d) , DRV_NAME, err); goto err_disableclks; devm_can_led_init(ndev);\treturn 0;err_disableclks:\tpm_runtime_put(pdev-dev);err_pmdisable:\tpm_runtime_disable(pdev-dev);\tfree_candev(ndev);\treturn err;static int rockchip_canfd_remove(struct platform_device *pdev)\tstruct net_device *ndev = platform_get_drvdata(pdev);//\tstruct rockchip_canfd *rcan = netdev_priv(ndev);\tunregister_netdev(ndev);\tpm_runtime_disable(pdev-dev);//\tif (rcan-mode == ROCKCHIP_RK3568_CAN_MODE_V2)// netif_napi_del(rcan-napi);\tfree_candev(ndev);\treturn 0;static struct platform_driver rockchip_canfd_driver = .driver = .name = DRV_NAME, .pm = rockchip_canfd_dev_pm_ops, .of_match_table = rockchip_canfd_of_match,\t,\t.probe = rockchip_canfd_probe,\t.remove = rockchip_canfd_remove,;module_platform_driver(rockchip_canfd_driver);MODULE_AUTHOR(Elaine Zhang zhangqing@rock-chips.com);MODULE_LICENSE(GPL);MODULE_DESCRIPTION(Rockchip CANFD Drivers);","categories":["1.平台","嵌入式"]},{"title":"CS模型","path":"/2024/10/28/1-平台-Linux-网络-CS模型/","content":"","categories":["1.平台","Linux","网络"]},{"title":"网络协议","path":"/2024/10/24/1-平台-Linux-网络-网络协议/","content":"四层网络协议TCPIP（传输控制协议因特网协议）参考模型（四层模型）： 四层模型（TCPIP 参考模型）是实际互联网通信中使用较为广泛的模型。 TCPIP 参考模型是互联网通信所使用的一种协议参考模型，由互联网工程任务组（IETF）定义。它将网络通信划分为四个层次，每个层次负责不同的功能，从底层到应用层，依次为： 网络接口层：处理物理网络接口和链路层协议，例如以太网。 网络层：负责 IP 协议、路由和分组转发等。 传输层：提供端到端的数据传输服务，包括 TCP 和 UDP 协议。 应用层：包括各种应用层协议，例如 HTTP、FTP、SMTP 等。 七层网络协议OSI（开放系统互联）参考模型（七层模型）： 七层模型（OSI 参考模型）提供了更细粒度的分层和功能划分。 OSI 参考模型是国际标准化组织（ISO）制定的一种网络协议参考模型，用于描述计算机网络中不同层次的功能和协议。它将网络通信划分为七个不同的层次，每个层次负责不同的任务，从物理传输到应用层，依次为： 物理层：负责物理介质传输和电信号传输。 数据链路层：处理数据帧的传输、物理寻址和错误检测等。 网络层：负责逻辑寻址、路由和分组转发等。 传输层：提供可靠的端到端数据传输，包括流量控制和错误恢复等。 会话层：管理不同应用程序之间的会话和数据交换。 表示层：处理数据的表示和转换，包括数据加密和解密等。 应用层：提供特定应用程序的服务和接口。 网络接口和物理层MAC 地址（Data Link Layer）：MAC 地址是一个唯一标识网络设备（如网卡）的物理地址。 它属于数据链路层，在局域网中用于唯一标识设备并实现直接通信。 PPP（Point-to-Point Protocol）（Data Link Layer）：PPP 用于在点对点连接上进行数据通信。 它属于数据链路层，用于建立和管理点对点连接，通常用于拨号、串口等通信。 ARP（Address Resolution Protocol）（Network Layer）：ARP 用于将 IP 地址解析为对应的 MAC 地址。 它属于网络层，在局域网中实现 IP 地址和 MAC 地址之间的映射关系。 RARP（Reverse Address Resolution Protocol）（Network Layer）：RARP 允许根据 MAC 地址获取对应的 IP 地址。 它属于网络层，在特定场景下（如无磁盘终端设备引导）用于获取 IP 地址。 IP 地址(Internet protocol)（Network Layer）：IP 地址是一个用于在互联网中唯一标识设备和网络的逻辑地址。 它属于网络层，在网络中进行寻址和路由选择，实现跨网络的通信。 ICMP（Internet Control Message Protocol）（Network Layer）：ICMP Inetrnet 控制管理协议（ping 命令） 用于在 IP 网络上传递控制消息和错误报告。 它属于网络层，在 IP 通信中提供网络状况、错误检测、排错等功能。 IGMP（Internet Group Management Protocol）（Network Layer）：IGMP Inetrnet 分组管理协议（广播组播） 用于在 IP 网络上进行组播（Multicast）管理。 它属于网络层，在多播通信中，用于主机和路由器之间的组播组管理。","categories":["1.平台","Linux","网络"]},{"title":"nmcli进行无线网络管理","path":"/2024/10/23/1-平台-嵌入式-nmcli进行无线网络管理/","content":"nmcli 简介nmcli 是 NetworkManager 的命令行工具，允许用户通过终端界面便捷地管理网络连接。它提供了一种简单而有效的方式来配置网络设备，尤其在使用图形用户界面不方便或资源有限的情况下。 1. 安装 nmcli要安装 nmcli，首先需要确保的系统中有 NetworkManager。使用以下命令在 Ubuntu 系统上安装： sudo apt-get install network-manager 安装完 NetworkManager 后，nmcli 通常会随之安装。可以通过以下命令确认是否安装成功： nmcli --version 这条命令会返回 nmcli 的版本信息，说明安装成功。 2. 查看网络设备要查看当前系统中所有的网络设备，使用以下命令： sudo nmcli dev 执行后，系统会列出所有网络设备的状态。例如，可能看到以下输出： DEVICE TYPE STATE CONNECTIONeth0 ethernet connected Wired connection 1wlan0 wifi disconnected -- 这个列表会显示每个设备的名称、类型、状态以及连接的网络（如果有的话）。 3. 开启 WiFi如果 WiFi 处于关闭状态，可以使用以下命令来打开： sudo nmcli r wifi on 使用此命令后，系统将重新启用无线网络功能。确认 WiFi 是否已开启，可以使用 nmcli dev 命令，再次查看设备状态。 4. 扫描 WiFi一旦 WiFi 功能开启，可以使用以下命令扫描可用的无线网络： sudo nmcli dev wifi 这条命令会显示附近可用 WiFi 网络的列表，包含它们的名称（SSID）、信号强度和安全类型。例如： SSID BSSID MODE CH RATE SIGNAL BARS SECURITY MyNetwork 00:11:22:33:44:55 Infra 6 54 Mb/s 70 ▂▄▆_ WPA1 WPA2 AnotherNetwork 66:77:88:99:AA:BB Infra 11 130 Mb/s 80 ▄▄▆▆ WPA2 信号强度以 dBm 表示，数值越高（越接近 0）表示信号越强。 5. 连接 WiFi要连接到某个 WiFi 网络，使用以下命令： sudo nmcli dev wifi connect wifi名 password 密码 请将 wifi名 替换为要连接的 WiFi 名称，将 密码 替换为该网络的密码。例如： sudo nmcli dev wifi connect MyNetwork password mypassword123 成功连接后，会看到如下信息： Successfully activated connection MyNetwork. 这说明已经成功连接到指定的 WiFi 网络。使用 nmcli 命令非常方便，尤其是在没有图形界面的情况下，能快速管理和连接网络。","categories":["1.平台","嵌入式"]},{"title":"QEMU","path":"/2024/10/22/1-平台-嵌入式-QEMU/","content":"QEMU 简介QEMU（Quick EMUlator）是一个开源、跨平台的虚拟化工具和仿真器，最初由 Fabrice Bellard 于 2003 年开发。QEMU 的强大之处在于其能够在多种硬件和操作系统环境中运行，使用各种虚拟化和仿真技术实现硬件设备的虚拟化，主要应用于系统开发、测试及学习虚拟化技术。 QEMU 的两个主要功能是： 仿真器模式（Emulation）：它能模拟多种硬件架构，允许用户在一种硬件平台上运行其他架构的操作系统。例如，用户可以在 x86 架构的计算机上运行基于 ARM 或 MIPS 架构的操作系统，这对于开发与测试跨平台应用程序至关重要。 虚拟化模式（Virtualization）：利用硬件辅助的虚拟化技术，如 Intel VT-x 和 AMD SVM，QEMU 能够显著提升虚拟机的性能。这种强大的性能加速使得用户在虚拟环境中可以流畅运行应用程序，几乎没有性能损失。 QEMU 的特性 多架构支持：QEMU 支持多种 CPU 架构，包括 x86、ARM、PowerPC、MIPS 和 RISC-V 等。这种灵活性非常适合开发人员需要测试不同平台兼容性时的需求。 与 KVM 结合使用：当 QEMU 与 KVM（Kernel-based Virtual Machine）配合时，可以提供卓越的虚拟化性能。KVM 利用硬件虚拟化功能，几乎将虚拟机性能提升到近乎原生环境的水平。 用户空间仿真：QEMU 支持在用户空间中仿真，可以运行不同平台上的单个用户程序，这对于软件测试和开发者调试大型软件项目非常有帮助。 广泛应用场景：QEMU 被广泛应用于嵌入式开发、操作系统测试、系统镜像调试等。开发者可以使用它来模拟硬件环境，从而在主机上便捷地测试嵌入式系统或新操作系统。 QEMU 的简要使用方式1. 安装 QEMU在 Linux 操作系统中，可以通过其包管理器轻松安装 QEMU。以下是几种常见操作系统安装的示例： UbuntuDebian： sudo apt updatesudo apt install qemu qemu-system qemu-user-static 这条命令会安装 QEMU 及其相关的系统和用户模式模拟工具。 CentOSRHEL： sudo yum install qemu-kvm qemu-img 相应地，这将安装 KVM 支持的 QEMU。 Windows： 在 QEMU官方页面 下载 Windows 版 QEMU，并在安装过程中确保其路径添加到系统环境变量中，这样可以在命令提示符下轻松运行 QEMU。 2. 运行基本 QEMU 虚拟机以下是创建并运行一个简单虚拟机的示例命令： qemu-system-x86_64 -boot d -cdrom /path/to/your.iso -m 1024 qemu-system-x86_64：指定要运行 x86_64 架构的虚拟机。 -boot d：指定从光盘启动。 -cdrom：用来指定 ISO 文件的路径。 -m 1024：为虚拟机分配 1GB 内存，这对于运行大多数操作系统来说是足够的。 这种简单的命令使得任何人都能快速设置一个虚拟机来测试不同的操作系统或软件环境。 3. 创建虚拟磁盘镜像使用 qemu-img 工具创建虚拟磁盘的命令如下： qemu-img create -f qcow2 mydisk.qcow2 10G -f qcow2：指定磁盘的格式，qcow2 是 QEMU 的默认格式，支持快照等高级功能。 mydisk.qcow2：这是创建的虚拟磁盘文件的名称。 10G：指定虚拟磁盘的大小为 10GB，适合存放多个文件或系统映像。 接着可以通过以下命令运行虚拟机并挂载这个新创建的磁盘： qemu-system-x86_64 -hda mydisk.qcow2 -cdrom /path/to/your.iso -boot d -m 1024 这条命令将新创建的虚拟磁盘作为主硬盘挂载，从而可以安装操作系统或运行应用程序。 4. 加速虚拟化为了利用 KVM 加速 QEMU 虚拟机，可以执行以下命令： qemu-system-x86_64 -enable-kvm -hda mydisk.qcow2 -m 1024 -enable-kvm：启用 KVM 加速功能，这样用户可以充分利用现代 CPU 提供的硬件虚拟化特性，从而显著提升虚拟机性能。 这种方法对需要高实时性能的应用场景尤为重要，比如运行数据库或高负载网络服务器。 学习 QEMU 的途径学习 QEMU 的建议途径有： 阅读官方文档：QEMU 的官方文档内容详实，涵盖了从安装到使用技巧的各个方面。访问 QEMU官方文档 是了解其功能的最佳方式。 实验和实践：动手尝试在 QEMU 中运行不同架构的操作系统，例如 ARM 和 MIPS，实操中掌握其工作原理。 与 KVM 结合学习虚拟化：深入理解 QEMU 和 KVM 的结合使用，学习如何通过调优配置来提升性能。 调试和仿真嵌入式系统：利用 QEMU 模拟 ARM 开发板或 RISC-V 等平台，进行嵌入式项目开发，可以让在主机上调试和测试嵌入式应用。 QEMU 的优势 灵活性：能够支持多种架构和硬件平台，对开发需要兼容性测试的应用程序非常友好。 开源：QEMU 是开源软件，代码透明，用户可以根据需要对软件进行定制和学习。 优秀性能：结合 KVM 可以提供极高的虚拟化性能，使得开发和测试过程高效流畅。 QEMU 不仅是学习操作系统开发、嵌入式开发和硬件虚拟化的强大工具，也为开发者提供了一个仿真和调试的平台。通过不断地实践，用户能更深入理解虚拟化和仿真技术的核心原理。","categories":["1.平台","嵌入式"]},{"title":"启动过程分析","path":"/2024/10/21/1-平台-嵌入式-启动过程分析/","content":"嵌入式 Linux 系统组织结构嵌入式 Linux 系统的组织结构从软件角度可划分为四个关键组成部分：引导加载程序（Bootloader）、Linux 内核、文件系统和应用程序。这四个部分紧密协作，确保嵌入式系统能够高效并可靠地启动和运行。 1. 引导加载程序（Bootloader）引导加载程序在嵌入式系统启动时起着至关重要的作用。它负责加载操作系统内核，并为其提供必要的初始化过程。引导加载程序通常在系统上电或重启时首先执行，它将内存中的程序引导至 CPU 中。嵌入式系统中常用的引导加载程序包括： Blob：这是一个简单的引导工具，主要用于一些特定的硬件平台，它能够快速地加载和运行内核映像。 RedBoot：这个引导加载程序具有网络支持，可用于通过网络进行系统初始化和调试。它允许开发者通过网络加载应用程序，提高了开发的灵活性。 U-Boot：U-Boot 是目前最流行的开源引导加载程序，广泛应用于多种硬件架构，包括 ARM 和 PowerPC。它提供了丰富的配置选项，包括支持多种文件系统、网络启动以及与其他模块的集成能力。 2. Linux 内核Linux 内核是嵌入式系统的核心组件，负责管理硬件资源、提供系统调用接口，并实现进程调度和内存管理等功能。内核确保各个应用程序能够高效地使用系统资源，例如 CPU、内存和输入输出设备。内核将作为系统的守护者，不仅保障安全性，还增强系统的稳定性。常见的嵌入式 Linux 内核有： 实时内核（RTLinux）：它是优化过的版本，专门用于需要严格时序控制的应用场景，如工业控制。 定制内核：许多嵌入式开发人员根据项目要求，自行裁剪和配置内核，以仅包含所需的驱动和功能，从而减小内核的体积并提高性能。 3. 文件系统文件系统是嵌入式 Linux 系统的另一个重要组成部分，负责数据存储和管理。它定义了如何在存储设备中组织和存取文件，保证数据的完整性与可靠性。常用的嵌入式文件系统包括： JFFS2（Journaling Flash File System 2）：专为闪存设备设计，能够有效地管理闪存的磨损，保障数据在电源故障时不会丢失。 SquashFS：一种高压缩比的只读文件系统，适用于需要节省存储空间的场景，常见于嵌入式设备的固件分发。 4. 应用程序应用程序是用户与嵌入式 Linux 系统互动的界面，负责实现实际的功能需求。嵌入式系统中的应用程序可包括： 网络服务应用：如 HTTP 服务器，能够实现数据的远程操控与监控。 视觉和图像处理应用：在一些工业和医疗应用中，嵌入式系统需要处理图像数据，使用专门的算法进行分析。 用户接口应用：在嵌入式设备中，往往需要一个友好的用户界面，以提高可用性和用户体验。 这四个方面的组成部分在嵌入式 Linux 系统中发挥着各自的作用，协同工作，从而实现高效的系统启动与运行。在整个系统架构中，引导加载程序构建了系统的初始环境，Linux 内核通过安全的资源管理进行调度，而文件系统则为数据的组织和存储提供了基础保障，最终各类应用程序则实现了系统的智能化和自动化。 常见的嵌入式 Linux Bootloader 包括以下几种： 1. BlobBlob 是一种微型 Bootloader，通常用于驱动特定硬件平台的启动过程。它的设计旨在快速加载和执行，仅支持基本的引导功能。Blob 通常由硬件制造商提供，针对特定设备进行优化。例如，在某些智能手机和平板电脑中，Blob 可能负责在开机时初始化设备的硬件组件，然后加载主要操作系统。 2. RedBootRedBoot 是一个灵活且功能强大的 Bootloader，主要为嵌入式开发设计。它支持多种网络协议，使得在不同的网络环境下进行操作系统的下载和更新变得容易。RedBoot 具有启动多种格式的映像文件的能力，这让开发人员可以在调试和测试过程中轻松管理不同版本的操作系统。例如，RedBoot 可以通过 TFTP（Trivial File Transfer Protocol）从网络服务器下载映像文件，对于需要快速迭代开发的项目尤为重要。 3. U-BootU-Boot 是一个广泛使用的开源 Bootloader，在嵌入式 Linux 开发中非常流行。它提供了丰富的功能，支持多种处理器架构和硬件平台。U-Boot 的灵活性使其能够在多种存储介质上引导系统，比如闪存、SD 卡和网络。它还支持环境变量的配置，开发者可以根据需要任意修改启动参数。例如，使用 U-Boot，可以轻松切换启动的 Linux 内核版本或者加载不同的根文件系统以满足不同的开发需求。 通过了解这三种 Bootloader 的特点和功能，开发者能够选择最适合自己项目的引导方案，从而在嵌入式 Linux 环境中实现更高效的系统启动和管理。 Linux 内核的启动过程Linux 内核主要有两种映像格式：一种是非压缩内核，称为 Image，另一种是压缩版本，称为 zImage。根据内核映像的不同，Linux 内核的启动过程在最初阶段表现得有所不同。 zImage 是通过对 Image 进行压缩得到的，其大小通常小于 Image。为了使用 zImage，必须在其开头添加解压缩的代码，这样 zImage 才能被解压缩并执行，因此其执行速度通常比 Image 要慢。尽管如此，在嵌入式系统中，由于存储空间通常较小，使用 zImage 所占用的存储空间更少，这样在存储空间和性能之间的取舍是相对可接受的。因此，许多嵌入式系统选择使用压缩内核的方式。 在 Bootloader 将 Linux 内核映像复制到 RAM 之后，内核映像会被解压并进行初始化，后续的硬件平台相关的初始化工作完成。接着，会进行内核相关的一系列初始化，最后会调用第一个用户进程——init 进程，并等待其执行。这样，整个 Linux 内核的启动过程就完成了。在很多情况下，可以通过简单的 shell 脚本来启动所需的嵌入式应用程序。 每当系统上电或复位时，处理器会执行一段存储在 FlashROM 中的已知位置的代码，这段代码即为 Bootloader。其主要职责是初始化处理器和外设，随后调用 Linux 内核。Linux 内核在完成系统的初始化之后，需要挂载某个文件系统作为根文件系统（Root Filesystem），并加载必要的内核模块，最终启动应用程序。由此可见，Bootloader 在整个嵌入式 Linux 系统启动过程中扮演着至关重要的角色。 Bootloader 种类嵌入式 Linux 系统中，根据不同的处理器架构，存在多种 Bootloader。以下是根据处理器体系结构划分的 Bootloader 种类和它们的特性，如下表所示： Bootloader Mointor 描述 X86 ARM PowerPC LILO 否 Linux 磁盘引导程序 是 否 否 Grub 否 GNU 引导的 LILO 替代程序 是 否 否 Loadlin 否 从 DOS 引导 Linux 是 否 否 ROLO 否 从 ROM 引导 Linux 而不需要 BIOS 是 否 否 Etherboot 否 通过以太网启动 Linux 引导程序 是 否 否 Linux BIOS 否 完全替代 BIOS 的 Linux 引导程序 是 否 否 Blob 否 LART 等硬件平台的引导程序 否 是 否 U-Boot 是 通用引导程序 是 是 是 RedBoot 是 基于 eCos 的引导程序 是 是 是 引导加载程序（Bootloader）当嵌入式系统首次引导或被重置时，处理器会自动执行存放在 Flash 或 ROM 中已知位置的引导加载程序，这是系统启动的第一道程序，类似于个人计算机上的 BIOS 功能。Bootloader 的基本目的在于初始化处理器及外设，并随后调用 Linux 内核。了解 Bootloader 的功能，是理解嵌入式 Linux 系统启动过程的关键。 Bootloader 的基本功能Bootloader 的主要任务包括以下几个方面： 初始化 RAM Linux 内核通常会在随机存取存储器（RAM）中运行。因此，Bootloader 需要对 RAM 进行初始化，以确保为 Linux 内核的启动做好充分准备。这步包括设置 CPU 的控制寄存器和检测 RAM 的大小，确保系统能够正常使用 RAM。 初始化串口 串口在 Linux 启动过程中扮演关键角色，主要作为 Linux 内核与用户交互的信息通道。通过串口输出，用户可以追踪和调试系统启动的细节，了解内核的加载状态。 检测处理器类型 在调用 Linux 内核前，Bootloader 需要检测系统的处理器类型，并将信息保存以供内核使用。这对于确保内核能够正确初始化和配置各个组件至关重要。 设置 Linux 启动参数 Bootloader 在执行过程中还需设置和初始化 Linux 内核的启动参数，以便内核能够根据硬件配置进行适配。 调用 Linux 内核映像 Bootloader 的最终任务便是调用 Linux 内核。如果内核存储在 Flash 中且可以直接执行，Bootloader 会直接跳转到内核进行执行。然而，由于 Flash 决定了执行上的一些限制，通常嵌入式系统会将内核拷贝到 RAM 中再执行，这样可以充分利用 RAM 的速度优势。 Bootloader 的启动过程嵌入式 Linux 系统的启动开始于 Bootloader 的执行。当系统上电，Bootloader 开始初始化系统。在完成系统初始化任务后，它会将存储在非易失性存储器（如 Flash 或 DOC）中的 Linux 内核拷贝到 RAM 中，然后跳转到内核的第一条指令，启动 Linux 内核。 Bootloader 启动过程分为两个阶段： Stage 1: 初始化基本硬件 为加载 Stage 2 准备 RAM 空间 将内核映像和文件系统映像拷贝到 RAM 中 设置堆栈指针（SP） 跳转到 Stage 2 的入口点 Stage 2: 初始化本阶段所需的硬件设备 检测系统的内存映射 加载内核映像和文件系统映像 设置内核的启动参数 Bootloader 通常存放在 Flash 的起始位置，确保系统上电或复位后执行的第一段程序为 Bootloader。其在 Flash 中的存储示意图可视为： +------------------+| Bootloader |+------------------+| Linux Kernel |+------------------+| File System |+------------------+ Bootloader 的启动方式不同的启动方式适应不同的系统需求，以下是几种常见的 Bootloader 启动方式： 1. 网络启动方式这种启动方法让开发板无需搭载大量存储介质，像无盘工作站一样，不同的是，必须在 EPROM 或 Flash 中安装 Bootloader。通过以太网接口远程下载 Linux 内核映像或文件系统，通常使用 TFTP 网络协议，并通过 DHCP 配置 IP 地址。 2. 硬盘启动方式传统 Linux 系统通常运行在台式机或服务器上，这些计算机使用 BIOS 引导并利用硬盘作为存储介质。经典的引导程序如 LILO（Linux Loader）和 GRUB（Grand Unified Bootloader）广泛应用于 x86 架构的 Linux 系统。 3. Flash 启动方式绝大多数嵌入式系统使用 Flash 存储设备。Flash 存储的类型包括 NOR Flash、NAND Flash 和其他半导体存储设备。它们之间的主要差别在于： NOR Flash 支持芯片内执行（XIP，eXecute In Place），使得代码可以直接在 Flash 上执行，无需拷贝到 RAM。 NAND Flash 不支持 XIP，因此执行 NAND Flash 上的代码须首先将其拷贝到 RAM，再跳转到 RAM 中执行。 NOR Flash 的使用最为普遍。Bootloader 通常放在 Flash 的底端或顶端，具体取决于处理器的复位向量。可以将 Flash 设置为 MTD（Memory Technology Device）设备，以便进行 Flash 分区的访问。","categories":["1.平台","嵌入式"]},{"title":"嵌入式交叉编译","path":"/2024/10/18/1-平台-嵌入式-嵌入式交叉编译/","content":"Firefly Linux 开发指南 官方发布的 Buildroot 固件，默认支持 Wayland 桌面环境和一些 Qt 应用，如下图： 1.1. multivideoplayer多路视频播放器用于测试设备的多路视频播放能力、显示能力以及硬件解码能力。 1.2. qfmqfm 是一个文件浏览应用 1.3. qplayerqplayer 是一个多功能播放器，可以播放视频、音频和浏览图片。 1.4. qcameraqcamera 是一款相机应用，可以进行拍摄和录像。 设备连接摄像头的情况下启动 qcamera 将自动显示摄像头画面，右侧按钮： Image Mode: 照相模式，点击可切换为 Video Mode 视频录制模式。 Capture: 捕捉图像，在 Video Mode 下会变为 Record 录制按钮。 Exit: 退出。 1.5. qsettingqsetting 是系统设置工具，可以设置 WiFi ，蓝牙，恢复出厂以及固件升级。 2. 用户和密码 用户：root 密码：firefly 3. 以太网配置Buildroot 的网络配置需要使用到 /etc/network/interfaces 配置文件，配置完成之后，运行 /etc/init.d/S40network restart 即可重启网络。手动调试可以直接使用 ifdown -a 和 ifup -a 来重启网络。 3.1. 常用配置配置文件举例：如下配置文件将 eth0 网卡设置为动态 IP 地址，将 eth1 设置为静态 IP 地址 注意：/etc/network/interfaces 的文件格式要求比较严格，如果遇到 Error: either local is duplicate, or /24 is a garbage.，那么很有可能是配置文件中多了一个空格 auto loiface lo inet loopbackauto eth0iface eth0 inet dhcpauto eth1iface eth1 inet staticaddress 168.168.110.137netmask 255.255.0.0broadcast 168.168.1.255gateway 168.168.0.1 （1）inet static：定义静态 IP 地址。支持的选项有： address address Address (dotted quad/netmask) requirednetmask mask Netmask (dotted quad or number of bits) deprecatedbroadcast broadcast_address Broadcast address (dotted quad, + or -) deprecated. Default value: +metric metric Routing metric for default gateway (integer)gateway address Default gateway (dotted quad)pointopoint address Address of other end point (dotted quad). Note the spelling of point-to.hwaddress address Link local address or random.mtu size MTU sizescope Address validity scope. Possible values: global, link, host （2）inet dhcp：通过 DHCP 协议获取 IP 地址。支持的选项有： hostname hostname Hostname to be requested (pump, dhcpcd, udhcpc)metric metric Metric for added routes (dhclient)leasehours leasehours Preferred lease time in hours (pump)leasetime leasetime Preferred lease time in seconds (dhcpcd)vendor vendor Vendor class identifier (dhcpcd)client client Client identifier (dhcpcd)hwaddress address Hardware address. （3）inet manual：没有为接口定义 IP 地址。通常由作为桥接或聚合成员的接口，需要以混杂模式运行的接口（ 例如，端口镜像或网络 TAP ）或在其上配置了 VLAN 设备的接口使用。这是保持接口不带 IP 地址的一种方法。支持的选项有： hwaddress address Link local address or random.mtu size MTU size 3.2. 高级设置/etc/network/interfaces 支持设置在网卡关闭启动时，运行 Linux 命令行指令。由于 /etc/network/interfaces 支持的功能相对有限，这在配置静态路由、默认路由等网络配置时将会非常有帮助。 支持的可选选项有：pre-up、up、post-up、pre-down、down、post-down，在这些选项之后，加上命令行即可。 pre-up\t网卡启用前的动作up\t启用时候的动作post-up\t启用后的动作pre-down\t关闭前的动作down\t关闭时动作post-down\t关闭后动作说明：$IFACE自适应对于相应的网卡节点 配置举例：给 eth1 网卡配置一条静态路由 auto eth1iface eth1 inet staticaddress 192.168.3.1netmask 255.255.255.0broadcast 192.168.3.255post-up ip route add 192.168.4.0/24 via 192.168.3.2 dev $IFACE 配置举例：创建一个网桥，将 eth0，eth1 绑定到网桥，将其作为 LAN 口 auto loiface lo inet loopbackauto eth0iface eth0 inet manualpre-up ifconfig $IFACE uppost-down ifconfig $IFACE downauto eth1iface eth1 inet manualpre-up ifconfig $IFACE uppost-down ifconfig $IFACE downauto br0iface br0 inet staticaddress 192.168.2.1netmask 255.255.255.0broadcast 192.168.2.255pre-up brctl addbr $IFACEpre-up brctl addif $IFACE eth0pre-up brctl addif $IFACE eth1bridge_ports eth0 eth1post-down brctl delif $IFACE eth0post-down brctl delif $IFACE eth1post-down ifconfig $IFACE downpost-down brctl delbr $IFACE 4. WiFi 连接4.1. 修改配置文件的方式4.1.1. 方式 1通过 qsetting QT 应用进行配置。 4.1.2. 方式 2修改如下文件： vi /data/cfg/wpa_supplicant.confctrl_interface=/var/run/wpa_supplicantap_scan=1 添加如下配置项 network=ssid=WiFi-AP // WiFi 名字psk=12345678 // WiFi 密码key_mgmt=WPA-PSK\t// 加密方式# key_mgmt=NONE // 不加密 启动 wpa_supplicant 进程 wpa_supplicant -B -i wlan0 -c /data/cfg/wpa_supplicant.conf 4.2. 临时修改的方式修改如下文件： vi /data/cfg/wpa_supplicant.confctrl_interface=/var/run/wpa_supplicantap_scan=1 启动 wpa_supplicant 进程： wpa_supplicant -B -i wlan0 -c /data/cfg/wpa_supplicant.conf 4.2.1. 通过 wpa_cli 配置 WiFi常用命令： wpa_cli -i wlan0 scan // 搜索附近wifi网络wpa_cli -i wlan0 scan_result // 打印搜索wifi网络wpa_cli -i wlan0 add_network // 添加一个网络连接 如果要连接加密方式是[WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][ESS] (wpa 加密)，wifi 名称是 name，wifi 密码是：psk。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 psk pskwpa_cli -i wlan0 set_network 0 key_mgmt WPA-PSKwpa_cli -i wlan0 enable_network 0 //使能WiFi 如果要连接加密方式是[WEP][ESS] (wep 加密)，wifi 名称是 name，wifi 密码是 psk。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 key_mgmt NONEwpa_cli -i wlan0 set_network 0 wep_key0 pskwpa_cli -i wlan0 enable_network 0 如果要连接加密方式是[ESS] (无加密)，wifi 名称是 name。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 key_mgmt NONEwpa_cli -i wlan0 enable_network 0 使能保存 WIFI 连接信息 wpa_cli -i wlan0 set update_config 1 保存 WIFI 连接信息 wpa_cli -i wlan0 save_config 连接已有的连接 wpa_cli -i wlan0 list_network // 列举所有保存的连接wpa_cli -i wlan0 select_network 0 // 连接第1个保存的连接wpa_cli -i wlan0 enable_network 0 // 使能第1个保存的连接 关闭 WiFi 5. 音视频播放# 播放 wavaplay test.wavgstwavplay.sh test.wav# 播放 mp3mp3play.sh test.mp3gstmp3play.sh test.mp3# 播放 mp4gstmp4play.sh test.mp4gstvideoplay.sh test.mp4 6. SSH官方发布的 SDK 默认已开启 ssh，用户为”root”，密码为”firefly”。如果不需要修改用户登录密码，可以跳过此章节。 6.1. 修改方法 使能 SSH 相关选项 openssh 配置登录的账户 root 和密码 BR2_TARGET_ENABLE_ROOT_LOGIN=yBR2_TARGET_GENERIC_ROOT_PASSWD=firefly 修改配置文件 修改板卡里 /etc/ssh/sshd_config 文件 7. 外部存储设备Buildroot 支持自动挂载外部存储设备： U 盘挂载路径：/udisk TF 卡挂载路径：/sdcard 8. 恢复出厂设置注意：此出厂设置表示恢复为设备最后一次升级固件之后的初始状态。 8.1. 方法 1通过 qsetting QT 应用进行配置，点击 “Factory Reset” 功能选项进行操作。 8.2. 方法 2通过 update 命令 update# 或者update factory / update reset 9. 固件本地升级Buildroot 支持从外部存储设备升级固件，以下是升级流程说明。关于如何编译 Buildroot 固件请用户参考相应板卡维基的编译 Buildroot 固件页面。 9.1. 制作升级固件按照正常的固件编译流程，制作用于升级的固件。 升级固件不一定要全分区升级，可修改 package-file 文件，将不要升级的分区注释掉，或者改为 RESERVED （1）修改文件 tools/linux/Linux_Pack_Firmware/rockdev/package-file 例如，将 rootfs 的相对路径改为 RESERVED，这样就不会打包根文件系统，即不升级根文件系统分区。 # name relative path##hwdef hwdefpackage-file package-filebootloader image/miniloaderall.binparameter image/parameter.txttrust image/trust.imguboot image/uboot.imgmisc image/misc.imgboot image/boot.imgrecovery image/recovery.imgrootfs RESERVEDoem image/oem.imguserdata:grow image/userdata.imgbackup RESERVED （2）编译固件 将制作好的升级固件拷贝到 U 盘、TF 卡或者设备的 /userdata/ 目录下，重命名为 update.img。 注意： 若将升级固件放至设备的 /userdata/ 目录，则不要打包 userdata.img，将 image/userdata.img 改为 RESERVED。 9.2. 升级过程9.2.1. 方法 1通过 qsetting QT 应用进行配置。点击 “Update” 功能选项进行操作。 9.2.2. 方法 2通过 update 命令。 # U 盘update ota /udisk/update.img# TF 卡update ota /sdcard/update.img# /userdata/update ota /userdata/update.img 等待升级完成，升级成功后，设备会重新启动进入系统。 10. Weston 配置们可以通过配置 Weston 对显示进行一些自定义设置，下文对部分设置进行说明。 10.1. 状态栏设置Weston 支持在 weston.ini 配置文件的 shell 段设置状态栏的背景色、位置，以及在 launcher 段设置快捷启动程序，如： # /etc/xdg/weston/weston.ini[shell]# 颜色格式为 ARGB8888panel-color=0xff002244# top|bottom|left|right|nonepanel-position=bottom[launcher]icon=/usr/share/weston/terminal.pngpath=/usr/bin/weston-terminal[launcher]# 图标路径icon=/usr/share/weston/icon_flower.png# 快捷启动命令path=/usr/bin/qsetting 10.2. 背景设置Weston 支持在 weston.ini 配置文件的 shell 段设置背景图案、颜色，如： # /etc/xdg/weston/weston.ini[shell]# 背景图案(壁纸)绝对路径background-image=/usr/share/weston/background.png# scale|scale-crop|tilebackground-type=scale# 颜色格式为 ARGB8888，未设置背景图案时生效background-color=0xff002244 10.3. 待机及锁屏配置Weston 的超时待机时长可以在启动参数中配置，也可以在 weston.ini 的 core 段配置，如： # /etc/init.d/S50launcher start) ... # 0 为禁止待机，单位为秒 weston --tty=2 -B=drm-backend.so --idle-time=0 或者： # /etc/xdg/weston/weston.ini[core]# 设置 5 秒未操作后进入待机状态idle-time=5 10.4. 显示颜色格式配置Buildroot SDK 内 Weston 目前默认显示格式为 ARGB8888，对于某些低性能平台，可以在 weston.ini 的 core 段配置为 RGB565，如： # /etc/xdg/weston/weston.ini[core]# xrgb8888|rgb565|xrgb2101010gbm-format=rgb565 也可以在 weston.ini 的 output 段单独配置每个屏幕的显示格式，如： # /etc/xdg/weston/weston.ini[output]# output 的 name 可以查看 /sys/class/drm/card0-namename=LVDS-1# xrgb8888|rgb565|xrgb2101010gbm-format=rgb565 10.5. 屏幕方向设置Weston 的屏幕显示方向可以在 weston.ini 的 output 段配置，如： # /etc/xdg/weston/weston.ini[output]name=LVDS-1# normal|90|180|270|flipped|flipped-90|flipped-180|flipped-270transform=180 如果需要动态配置屏幕方向，可以通过动态配置文件，如： echo output:all:rotate90 /tmp/.weston_drm.conf # 所有屏幕旋转 90 度echo output:eDP-1:rotate180 /tmp/.weston_drm.conf # eDP-1 旋转 180 度 10.6. 分辨率及缩放配置Weston 的屏幕分辨率及缩放可以在 weston.ini 的 output 段配置，如： # /etc/xdg/weston/weston.ini[output]name=HDMI-A-1# 需为屏幕支持的有效分辨率mode=1920x1080# 需为整数倍数scale=2 如果需要动态配置分辨率及缩放，可以通过动态配置文件，如： echo output:HDMI-A-1:mode=800x600 /tmp/.weston_drm.conf # 修改 HDMI-A-1 分辨率为800x600 这种方式缩放时需要依赖 RGA 加速。 10.7. 冻结屏幕在启动 Weston 时，开机 logo 到 UI 显示之间存在短暂切换黑屏。如需要防止黑屏，可以通过以下种动态配置文件方式短暂冻结 Weston 屏幕内容： # /etc/init.d/S50launcher start) ... export WESTON_FREEZE_DISPLAY=/tmp/.weston_freeze # 设置特殊配置文件路径 touch /tmp/.weston_freeze # 冻结显示 weston --tty=2 -B=drm-backend.so --idle-time=0 ... sleep 1 rm /tmp/.weston_freeze # 1 秒后解冻 10.8. 多屏配置Buildroot SDK 的 Weston 支持多屏同异显及热拔插等功能，不同显示器屏幕的区分根据 drm 的 name (通过 sysclassdrmcard0-name 获取)，相关配置通过环境变量设置，如： # /etc/init.d/S50launcher start) ... export WESTON_DRM_PRIMARY=HDMI-A-1 # 指定主显为 HDMI-A-1 export WESTON_DRM_MIRROR=1 # 使用镜像模式(多屏同显)，不设置此环境变量即为异显 export WESTON_DRM_KEEP_RATIO=1 # 镜像模式下缩放保持纵横比，不设置此变量即为强制全屏 export WESTON_DRM_PREFER_EXTERNAL=1 # 外置显示器连接时自动关闭内置显示器 export WESTON_DRM_PREFER_EXTERNAL_DUAL=1 # 外置显示器连接时默认以第一个外显为主显 weston --tty=2 -B=drm-backend.so --idle-time=0 镜像模式缩放显示内容时需要依赖 RGA 加速。 同时也支持在 weston.ini 的 output 段单独禁用指定屏幕： # /etc/xdg/weston/weston.ini[output]name=LVDS-1mode=off# off|current|preferred|WIDTHxHEIGHT@RATE 10.9. 输入设备相关配置Weston 服务默认需要至少一个输入设备，如无输入设备，则需要在 weston.ini 中的 core 段特殊设置： # /etc/xdg/weston/weston.ini[core]require-input=false 11. Buildroot 开发Buildroot 是 Linux 平台上一个构建嵌入式 Linux 系统的框架。整个 Buildroot 是由 Makefile(*.mk) 脚本和 Kconfig(Config.in) 配置文件构成的。可以和编译 Linux 内核一样，通过 buildroot 配置，menuconfig 修改，编译出一个完整的可以直接烧写到机器上运行的 Linux 系统软件（包含 boot、kernel、rootfs 以及 rootfs 中的各种库和应用程序）。若要了解更多 Buildroot 开发相关内容，可以参考 Buildroot 官方的 《开发手册》。 下面以 RK356x 平台的 Buildroot 开发为例进行阐述。 11.1. 目录结构Buildroot SDK 位于 Firefly_Linux_SDK 目录，其目录结构如下： buildroot/├── arch # CPU 架构的构建、配置文件├── board # 具体单板相关的文件├── boot # Bootloaders 的构建、配置文件├── build├── CHANGES # Buildroot 修改日志├── Config.in├── Config.in.legacy├── configs # 具体单板的 Buildroot 配置文件├── COPYING├── DEVELOPERS├── dl # 下载的程序、源码压缩包、补丁等├── docs # 文档├── fs # 各种文件系统的构建、配置文件├── linux # Linux 的构建、配置文件├── Makefile├── Makefile.legacy├── output # 编译输出目录├── package # 所有软件包的构建、配置文件├── README # Buildroot 简单说明├── support # 为 Bulidroot 提供功能支持的脚本、配置文件├── system # 制作根文件系统的构建、配置文件├── toolchain # 交叉编译工具链的构建、配置文件└── utils # 实用工具 11.2. 配置选择默认配置文件： # 进入 Firefly_Linux_SDK 根目录cd path/to/Firefly_Linux_SDK/# 选择配置文件# \\`configs/rockchip_rk3568_defconfig\\`source envsetup.sh rockchip_rk3568 执行完成后会生成编译输出目录，output/rockchip_rk3568，后续也可以在该目录下执行 make 相关操作。 11.2.1. 软件包配置打开配置界面： 们可以在配置界面添加或裁剪一些工具，按需求定制系统功能。以添加 qt53d 为例： 输入 / 进入搜索界面，输入要查找的内容 qt53d，按回车进行搜索： 选择 1 跳转到对应页面，按空格选中配置： 配置完成后，移动到 Save 按回车保存到 .config；移动到 Exit 按回车退出。 保存配置文件： 将修改保存到配置文件 configs/rockchip_rk3568_defconfig。 11.2.2. Busybox 配置打开配置界面，进行配置： 配置完成后，移动到 Exit 按回车退出，在弹窗页面选择 Yes 保存到 .config。 保存配置文件： make busybox-update-config 将修改保存到配置文件 board/rockchip/common/base/busybox.config。 11.3. 编译配置好 Buildroot 后，直接运行 make 进行编译。 11.3.1. 编译说明运行 make 进行编译时，会执行以下过程： 下载源码； 配置、编译、安装交叉编译工具链； 配置、编译、安装选择的软件包； 按选择的格式生成根文件系统； 关于 make 的更多用法，可通过 make help 获得。 11.3.2. 编译软件包们可以执行 make package 单独编译某个软件包。软件包的编译主要包括下载，解压，打补丁，配置，编译，安装等过程，具体可以查看 package/pkg-generic.mk。 下载 Buildroot 会根据配置 package/package/package.mk，自动从网络获取对应的软件包，包括一些第三方库，插件，实用工具等，放在 dl/ 目录。 解压 软件包会解压在 output/rockchip_rk3568/build/package-version 目录下。 打补丁 补丁集中放在 package/packgae/ 目录，Buildroot 会在解压软件包后为其打上相应的补丁。如果要修改源码，可以通过打补丁的方式进行修改。 配置 编译 安装 编译完成后，会将需要的编译生成文件拷贝到 output/rockchip_rk3568/target/ 目录。 对于某个软件包，们可以通过 make package-target 调用软件包构建中的某一步骤，如下： Package-specific: pkg - Build and install pkg and all its dependencies pkg-source - Only download the source files for pkg pkg-extract - Extract pkg sources pkg-patch - Apply patches to pkg pkg-depends - Build pkgs dependencies pkg-configure - Build pkg up to the configure step pkg-build - Build pkg up to the build step pkg-graph-depends - Generate a graph of pkgs dependencies pkg-dirclean - Remove pkg build directory pkg-reconfigure - Restart the build from the configure step pkg-rebuild - Restart the build from the build step 11.4. 编译输出目录编译完成后，在编译输出目录 output/rockchip_rk3568 会生成子目录，说明如下： build/ 包含所有的源文件，包括 Buildroot 所需主机工具和选择的软件包，这个目录包含所有软件包源码。 host/ 主机端编译需要的工具，包括交叉编译工具。 images/ 包含压缩好的根文件系统镜像文件。 staging/ 这个目录类似根文件系统的目录结构，包含编译生成的所有头文件和库，以及其他开发文件，不过它们没有裁剪，比较庞大，不适用于目标文件系统。 target/ 包含完整的根文件系统，对比 staging/，它没有开发文件，不包含头文件，二进制文件也经过 strip 处理。 11.5. 交叉编译工具Buildroot 编译完成后，会在 output/rockchip_rk3568/host/ 目录下，生成交叉编译工具，们可以用来编译目标程序。 交叉编译工具目录 output/rockchip_rk3568/host/bin/ 编译示例 hello.c #include stdio.h#include stdlib.hint main(int argc, char *argv[]) printf(Hello World! ); return 0; 编译 .../host/bin/arm-buildroot-linux-gnueabihf-gcc hello.c -o hello 运行 将可执行程序 hello 拷贝到设备，运行 ./hello，则会看到打印信息 Hello World!。 11.6. 重建对于重建的具体说明，可以查看文档 buildroot/docs/manual/rebuilding-packages.txt。 11.6.1. 重建软件包在开发过程中，若修改了某个软件包的源码，Buildroot 是不会重新编译该软件包的。可以按如下方式操作： 方式一 方式二 # 删除软件包的编译输出目录rm -rf output/rockchip_rk3568/build/package-version# 编译make package 11.6.2. 完全重建当通过 make menuconfig，make xconfig 或其他配置工具之一更改系统配置时，Buildroot 不会尝试检测应重建系统的哪些部分。在某些情况下，Buildroot 应该重建整个系统，在某些情况下，仅应重建软件包的特定子集。但是以完全可靠的方式检测到这一点非常困难，因此 Buildroot 开发人员已决定不尝试这样做。 11.6.2.1. 何时需要完全重建 更改目标体系结构配置时，需要完全重建； 更改工具链配置时，需要完全重建； 将其他软件包添加到配置中时，不一定需要完全重建； 从配置中删除软件包时，Buildroot 不会执行任何特殊操作。它不会从目标根文件系统或工具链中删除此软件包安装的文件。需要完全重建才能删除这些文件； 更改软件包的子选项时，不会自动重建软件包； 对根文件系统框架进行更改时，需要完全重建； 一般而言，当遇到构建错误并且不确定所做的配置更改可能带来的后果时，请进行完全重建。具体说明可以查看文档 rebuilding-packages.txt。 11.6.2.2. 如何完全重建 方式一 直接删除编译输出目录，之后重新进行配置、编译。 方式二 执行如下命令，会删除编译输出并重新编译。 11.7. 新增本地源码包开发过程中，Buildroot 自带的软件包有时可能无法满足们的需求，为此们需要添加自定义的软件包。Buildroot 支持多种格式的软件包，包括 generic-package、cmake-package、autotools-package 等，们以 generic-package 举例说明。 创建工程目录 cd path/to/Firefly_Linux_SDK/mkdir buildroot/package/rockchip/firefly_demo/ 新建 Config.in 在 firefly_demo/ 下添加 Config.in： config BR2_PACKAGE_FIREFLY_DEMO bool Simple Firefly Demo 新建 firefly_demo.mk 在 firefly_demo/ 下添加 firefly_demo.mk： ################################################################# firefly_demo##############################################################ifeq ($(BR2_PACKAGE_FIREFLY_DEMO), y) FIREFLY_DEMO_VERSION:=1.0.0 FIREFLY_DEMO_SITE=$(TOPDIR)/../external/firefly_demo/src FIREFLY_DEMO_SITE_METHOD=localdefine FIREFLY_DEMO_BUILD_CMDS $(TARGET_MAKE_ENV) $(MAKE) CC=$(TARGET_CC) CXX=$(TARGET_CXX) -C $(@D)endefdefine FIREFLY_DEMO_CLEAN_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) cleanendefdefine FIREFLY_DEMO_INSTALL_TARGET_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) installendefdefine FIREFLY_DEMO_UNINSTALL_TARGET_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) uninstallendef$(eval $(generic-package))endif 创建源码目录 上文的 Makefile 文件里已经指定了源码目录 external/firefly_demo/src。 cd path/to/Firefly_Linux_SDK/mkdir external/firefly_demo/src 编写源码 firefly_demo.c 在 firefly_demo/src/ 下添加 firefly_demo.c： #include stdio.h#include stdlib.hint main(int argc, char *argv[]) printf(Hello World! ); return 0; 编写 Makefile 在 firefly_demo/src/ 下添加 Makefile： DEPS =OBJ = firefly_demo.oCFLAGS =%.o: %.c $(DEPS) $(CC) -c -o $@ $ $(CFLAGS)firefly_demo: $(OBJ) $(CXX) -o $@ $^ $(CFLAGS).PHONY: cleanclean: rm -f *.o *~ firefly_demo.PHONY: installinstall: cp -f firefly_demo $(TARGET_DIR)/usr/bin/.PHONY: uninstalluninstall: rm -f $(TARGET_DIR)/usr/bin/firefly_demo 修改上一级 Config.in 在 buildroot/package/rockchip/Config.in 末尾添加一行： source package/rockchip/firefly_demo/Config.in 配置软件包 打开配置菜单 make menuconfig，找到 firefly_demo 并选中配置。 编译 # 编译 firefly_demomake firefly_demo# 打包进根文件系统make# 若修改源码，重新编译软件包make firefly_demo-rebuild 11.8. rootfs-overlayrootfs-overly 是一个相当不错的功能，它能够在目标文件系统编译完成后将指定文件覆盖到某个目录。通过这种方式，们可以方便地添加或修改一些文件到根文件系统。 假设们要在根文件系统的 /etc/ 目录下添加文件 overlay-test，可以按如下步骤操作： 设置 rootfs-overlay 根目录 打开配置菜单 make menuconfig，通过设置 BR2_ROOTFS_OVERLAY 选项，添加用于覆盖的根目录。对于 RK3568，默认已添加了目录 board/rockchip/rk356x/fs-overlay/。 添加文件到覆盖目录 cd buildroot/board/rockchip/rk356x/fs-overlay/mkdir etc/touch etc/overlay-test 编译 下载根文件系统 将编译好的根文件系统 output/rockchip_rk3568/images/rootfs.ext2 下载到设备。启动设备，可以看到已添加文件 /etc/overlay-test。 也可以通过查看 target/ 目录，验证是否添加成功： ls buildroot/output/rockchip_rk3568/target/etc/overlay-test 11.9. Qt 交叉编译环境支持Firefly 提取了 Buildroot 的交叉编译工具链，支持 EGLFS、LinuxFB、Wayland 等插件，可以直接使用该工具链开发 Buildroot 上的 Qt 应用程序，而无需下载编译 SDK 代码。 版本：Qt-5.15.2主机：x86-64 / Ubuntu 18.04设备：Firefly RK3568 RK3566 / Buildroot 下载地址：Buildroot Qt 环境部署：详见 Qt5.1x.x_Release.md 文件。","tags":["clippings"],"categories":["1.平台","嵌入式"]},{"title":"嵌入式初始配置","path":"/2024/10/17/1-平台-嵌入式-嵌入式初始配置/","content":"Firefly Linux 开发指南 1.1. Ubuntu Desktop 系统Ubuntu Desktop 系统开机启动后，自动登录到 firefly 用户。 如果有连接调试串口，串口终端自动登录 root 用户。 firefly 用户密码： firefly root 用户：默认没有设置 root 密码，firefly 用户通过 sudo passwd root 命令自行配置 root 密码。 1.2. Ubuntu Minimal 系统 Ubuntu Minimal 系统开机启动后，自动登录到 root 用户，密码为 firefly。 系统已经添加 OpenGL ES, OpenCL, DRM 支持。 1.3. Buildroot 系统 用户：root 密码：firefly 2. ADB 使用2.1. ADB用 Type-C data cable 连接设备和主机，然后输入以下命令： 2.2. 网络 ADB查看开发板 IP 地址，PC 端通过网络访问： adb connect + IPadb shell 注意点： AIO-3399-JD4 AIO-3399J 要支持使用 ADB 需要修改 kernel/arch/arm64/boot/dts/rockchip/rk3399-firefly-aio.dtsi，将 usbdrd_dwc3_0 设置为 peripheral 模式，之后该 usb 只能作为从设备使用。 usbdrd_dwc3_0 dr_mode = peripheral;; 同理，AIO-3399Pro-JD4 要支持使用 ADB 需要修改 kernel/arch/arm64/boot/dts/rockchip/rk3399pro-firefly-aioc.dts。 然后重新编译和烧写 Kernel。 4. 导出设备系统当用户已经在一台设备上完成工作环境的部署，需要将当前环境完整导出，以批量部署到其它同设备上，可以通过导出设备文件系统来备份当前的开发环境。 导出设备系统分为两步： 在设备上导出 Ubuntu 根文件系统 rootfs； 二次打包完整固件，将 Ubuntu rootfs 与发布固件的其他分区组合，完成二次打包，生成新的完整固件。 4.1. 导出 rootfs注意以下操作均在设备端上操作！ 在设备的 Ubuntu 环境下，安装 fireflydev： sudo apt updatesudo apt install fireflydev 安装 fireflydev 后，就能使用 ff_export_rootfs 脚本导出根文件系统 建议使用容量较大的移动硬盘 导出工具会执行 apt clean 等操作以减小文件系统大小 将根文件系统导出，例如导出到 /media/firefly/AC91-C4AE/ 目录（需要等待一定时间）： ff_export_rootfs /media/firefly/AC91-C4AE/ 压缩文件系统，删除不必要的空白空间以减少存储器资源的占用： # 有部分客户说导出的 rootfs 大小为 3.3G，可实际只用了 3G，原因是没有对 rootfs 进行压缩e2fsck -p -f Firefly_Ubuntu_18.04.6_rootfs.imgresize2fs -M Firefly_Ubuntu_18.04.6_rootfs.img 4.2. 二次打包完整固件注意以下操作均在 PC 机端（x86-64 架构）上操作！ 安装必要的软件包：sudo apt-get install lib32stdc++6 下载二次打包工具：firefly-linux-repack（提取码：1234） 解压二次打包工具： tar -xzf firefly-linux-repack.tgzcd firefly-linux-repack 目录如下： firefly-linux-repack ├── bin │ ├── afptool │ └── rkImageMaker ├── pack.sh # 打包脚本 ├── Readme_en.md ├── Readme.md └── unpack.sh # 解包脚本 解包操作： 把官方发布的 Ubuntu 固件拷贝到 firefly-linux-repack 根目录，重命名为 update.img，执行解包脚本 unpack.sh。解包完成后，各分区文件在 output 目录下。 mv /path/to/ROC-RK3566-PC_Ubuntu18.04-r21156_v1.2.4a_220519.img update.img./unpack.sh 打包操作：保持当前目录结构，文件名等不变，接入移动硬盘到 PC 机，把前面导出的 Ubuntu rootfs 替换 output/Image/rootfs.img，然后执行打包脚本 pack.sh。 cp /media/customer/1878-4615/Firefly_Ubuntu_18.04.6_rootfs.img /path/to/firefly-linux-repack/output/Image/rootfs.img./pack.sh 新的完整固件为当前目录的 new_update.img。 5. GPIO 配置与使用GPIO, 全称 General-Purpose InputOutput（通用输入输出），是一种软件运行期间能够动态配置和控制的通用引脚。 以下通过控制 ROC-RK3399-PC Pro 的 LED 为例，对于其他设备，方法是类似的。 ROC-RK3399-PC Pro 的主控是 RK3399，RK3399 有 5 组 GPIO bank：GPIO0GPIO4，每组又以 A0A7, B0B7, C0C7, D0~D7 作为编号区分。 5.1. GPIO 编号计算ROC-RK3399-PC Pro 板载两个 LED，如下： DIY_LED 网络是接到引脚 GPIO0_B5： PIO pin 脚计算公式： GPIO 小组编号计算公式： 例如 GPIO0_B5： bank = 0; // GPIO0_B5 = 0, bank ∈ [0,4]group = 1; // GPIO0_B5 = 1, group ∈ (A=0), (B=1), (C=2), (D=3)X = 5; // GPIO0_B5 = 5, X ∈ [0,7]number = group * 8 + X = 1 * 8 + 5 = 13;pin = bank * 32 + number = 0 * 32 + 13 = 13; 注意：这个引脚在官方发布的固件中默认已被 LED 子系统占用，因此首先需要找到以下节点将其 disable！ ROC-RK3399-PC Pro 是定义在 arch/arm64/boot/dts/rockchip/rk3399-roc-pc.dtsi： user status = disabled; // 添加这一行 label = firefly:yellow:user; linux,default-trigger = ir-user-click; default-state = off; gpios = gpio0 13 GPIO_ACTIVE_HIGH; pinctrl-names = default; pinctrl-0 = led_user;; 然后编译与重新烧写内核固件。 5.2. 用户态使用 GPIO1、申请 GPIO echo 13 /sys/class/gpio/export 2、配置引脚方向 查看默认引脚方向： cat /sys/class/gpio/gpio13/direction 配置成输出方向： echo out /sys/class/gpio/gpio13/direction 3、配置引脚输出电平 从前面的原理图可知，输出高电平为点亮 LED： echo 1 /sys/class/gpio/gpio13/value 熄灭 LED： echo 0 /sys/class/gpio/gpio13/value 5.3. 设备树使用 GPIO在设备树中配置 GPIO，需要配置引脚的功能复用与电气属性 对于 rockchip 引脚，配置如下： rockchip,pins = PIN_BANK PIN_BANK_IDX MUX phandle 其中： PIN_BANK：引脚所在的 bank PIN_BANK_IDX：引脚所在 bank 的引脚号 MUX：功能复用配置，0 表示普通 GPIO，1-N 表示特殊的功能复用 phandle：引脚一般配置，例如内部上拉、电流强度等，在 Documentation/devicetree/bindings/pinctrl/pinctrl-bindings.txt 文件中描述 配置 GPIO0_B5 引脚： rockchip,pins = 0 13 RK_FUNC_GPIO pcfg_pull_none; 此处的含义： PIN_BANK 等于 0 PIN_BANK_IDX 等于 13 RK_FUNC_GPIO 代表使用普通 GPIO 功能 pcfg_pull_none 代表普通配置 对于 LED，Linux 定义了一套 GPIO 子系统，设备树的配置如下： / gpio_led: gpio-led compatible = gpio-leds; diy_led: diy-led label = diy-led; default-state = on; // 默认打开 linux,default-trigger = default-on; // 默认触发 gpios = gpio0 13 GPIO_ACTIVE_HIGH; // 引脚设置 pinctrl-names = default; pinctrl-0 = diy_led_pin; // 引用 pinctrl ;\t;;pinctrl gpio-led-pin diy_led_pin: diy-led-pin rockchip,pins = 0 13 RK_FUNC_GPIO pcfg_pull_none; ;\t;; 然后编译与重新烧写内核固件，重启系统会看到 LED 默认点亮。 如果希望 LED 具有闪烁效果，可以修改 linux,default-trigger 属性实现： linux,default-trigger = timer; 配置该属性后，LED 默认每 500ms 间隔闪烁。 更多属性配置可以参考 Documentation/devicetree/bindings/leds/leds-gpio.txt。 以上设备树配置可以在 arch/arm64/boot/dts/rockchip/firefly-gpio-demo.dtsi 找到！有需求的用户在板极设备树中包含该文件即可（记得要首先 disable rk3399-roc-pc.dtsi 里面冲突部分）： #include firefly-gpio-demo.dtsi 6. 网络配置6.1. 以太网口通用参数配置6.1.1. 查看以太网通用参数以太网的通用参数包括：自协商，双工模式和接口速率 6.1.2. 配置以太网通用参数6.1.2.1. 打开或关闭自协商ethtool -s port_name autoneg on | off 6.1.2.2. 修改双工模式ethtool -s port_name duplex half | full 注意： 当以太网接口工作在自协商模式时，缺省情况下双工模式是和对端接口协商得到的。 当以太网接口工作在非自协商模式时，缺省情况下双工模式为全双工模式。 6.1.2.3. 修改速率ethtool -s port_name speed 10 | 100 | 1000 注意： 当以太网接口工作在自协商模式时，缺省情况下接口速率是和对端接口协商得到的。 当以太网接口工作在非自协商模式时，缺省情况下接口速率为接口支持的最大接口速率。 6.1.3. 配置举例手动设置 eth0 的接口速率为 100，工作在全双工模式下。 ethtool -s eth0 autoneg offethtool -s eth0 speed 100ethtool -s eth0 duplex full 6.2. 使用 Netplan 管理网络Netplan 是一个用于在 linux 系统上轻松配置网络的实用程序。只需创建所需网络接口的 YAML 描述以及每个应配置的功能。根据此描述，Netplan 将为选择的渲染器工具生成所有必要的配置。在 Ubuntu18.04 及其以上版本进行了支持。 6.2.1. 配置要配置 netplan，请 /etc/netplan/ 使用 .yaml 扩展名（例如 /etc/netplan/config.yaml）保存配置文件，然后运行 sudo netplan apply. 此命令解析配置并将其应用于系统。 注意： 如果 netplan apply 报错，说明的 yaml 配置文件未被系统支持，请仔细检查 对于以太网口，必须保证有网线接入，并且网卡灯闪烁，才能保证 Netplan 配置生效 下面根据最常使用的工作场景进行配置，需要更多的配置案例教程，请阅读 netplan官方实例 6.2.2. 基础配置Netplan 支持 networkd 和 NetworkManager 两种网络后端，一般为 networkd network: version: 2 renderer: networkd 如果不存在 networkd，可以使用 NetworkManager，都是一样的。 network: version: 2 renderer: NetworkManager 6.2.3. 以太网连接：动态 IPnetwork: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes eth1: dhcp4: yes 6.2.4. 以太网连接：静态 IPnetwork: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.10.10.3/24 nameservers: addresses: [202.96.128.86] routes: - to: 0.0.0.0/0 via: 10.10.10.1 eth1: addresses: - 10.10.10.2/24 nameservers: addresses: [202.96.128.86] routes: - to: 0.0.0.0/0 via: 10.10.10.1 6.2.5. WIFI 连接：静态 IPnetwork: version: 2 renderer: networkd wifis: wlan0: dhcp4: no dhcp6: no addresses: [192.168.1.200/24] nameservers: addresses: [202.96.128.86] access-points: NETGEAR25: password: ceshizhuanyong routes: - to: 0.0.0.0/0 via: 192.168.1.1 6.2.6. WIFI 连接：动态 IPnetwork: version: 2 renderer: networkd wifis: wlan0: dhcp4: yes access-points: NETGEAR25: password: ceshizhuanyong 6.3. 使用 nmcli 管理网络nmcli 是用来管理 NetworkManager 网络连接的命令行工具 6.3.1. 常用命令 显示所有连接 显示连接信息 nmcli connection show connection_name 显示网络设备列表、其状态以及使用该设备的连接 激活连接 nmcli connection up connection_name 取消激活连接 nmcli connection down connection_name 删除连接 nmcli connection del connection_name 6.3.2. 以太网连接：静态 IP假设进行配置以太网网卡为 eth0，IP 为 192.168.1.1024，默认网关为 192.168.1.1，DNS 服务器为 202.96.128.86 为以太网连接添加新的连接 nmcli connection add con-name Example-Connection ifname eth0 type ethernet 设置 IPv4 地址 nmcli connection modify Example-Connection ipv4.addresses 192.168.1.10/24 将 IPv4 连接方法设置为 manual nmcli connection modify Example-Connection ipv4.method manual 设置 IPv4 默认网关 nmcli connection modify Example-Connection ipv4.gateway 192.168.1.1 设置 IPv4 DNS 服务器地址 nmcli connection modify Example-Connection ipv4.dns 202.96.128.86 激活连接 nmcli connection up Example-Connection 6.3.3. 以太网连接：动态 IP 为以太网连接添加新的连接 nmcli connection add con-name Example-Connection ifname eth0 type ethernet 激活连接 nmcli connection up Example-Connection 6.3.4. WIFI 连接：动态 IP 确保 WiFi 被启用（默认） 刷新可用的 Wi-Fi 连接列表： 查看可用的 Wi-Fi 接入点： nmcli dev wifi listIN-USE SSID MODE CHAN RATE SIGNAL BARS SECURITY... MyCafe Infra 3 405 Mbit/s 85 ▂▄▆█ WPA1 WPA2 使用 nmcli 连接到 Wi-Fi 连接： nmcli dev wifi connect SSID-Name password wireless-password 例如： nmcli dev wifi connect MyCafe password wireless-password 请注意，如果要禁用 Wi-Fi 状态： 6.4. 快速创建无线 AP 热点6.4.1. 对无线热点的 IP 局域网段无要求在这种情况下，只需要使用 nmcli 命令创建一个无线 AP 热点即可： nmcli device wifi hotspot ifname wlan0 con-name MyHostspot ssid MyHostspotSSID password 12345678 说明： con-name：连接名称：这里设置为 MyHostspot（可自定义） ssid：创建的 AP 热点的名称：这里设置为 MyHostspotSSID（可自定义） password：创建的 AP 热点的密码：这里设置为 12345678（可自定义） 6.4.2. 对无线热点的 IP 局域网段有要求请阅读章节《创建桥接无线 AP》 6.5. 创建桥接无线 AP 热点6.5.1. 功能需求假设有一局域网，网段为 10.10.0.0，掩码为 255.255.255.0。Firefly 的开发板，以下简称 Firefly Board，其网口通过路由器 Router，获取到本局域网内的动态 IP 地址：为 10.10.0.2。 需求：将系统配置成软路由，具体要求如下： （1）Firefly Board 开启一个无线 AP 热点，平板和手机等外设通过该无线 AP 热点访问网络，进行上网。 （2）Firefly Board 开启的无线热点局域网为：192.168.4.1 （3）Firefly Board 如果有多个网口，要求 eth0 作为 WAN 口功能，自动从路由器获取 IP 地址，eth1 作为 LAN 口功能，能够为接入的设备分配 192.168.4.0/24 网段的 IP 地址。 网络拓扑如下： 6.5.2. 安装管理 AP 热点必要的软件包安装 hostapd：hostapd 可以用来模拟软 AP，所以是实现该功能必须的： 允许 hostapd 开机启动，这样重启之后无线 AP 热点会自动打开 systemctl unmask hostapdsystemctl enable hostapd 安装 isc-dhcp-server：isc-dhcp-server 用于为接入无线 AP 的设备自动分配 IP 地址和 DNS 服务器地址 apt install isc-dhcp-server 允许 isc-dhcp-server 开启启动 systemctl enable isc-dhcp-server 安装 netfilter-persistent iptables-persistent：用于保存防火墙规则 apt install netfilter-persistent iptables-persistent 安装 bridge-utils：用于创建虚拟网桥 6.5.3. 配置 Netplan目的是创建网桥 br0，网桥 IP 为 192.168.4.1。允许系统 eth0 网卡分配 IP 地址，禁止系统为 eth1 网卡分配 IP 地址，将 eth1 网卡绑定到网桥 br0。 假设 netplan 的配置文件为：/etc/netplan/netplan.yaml，内容如下所示： network: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes eth1: dhcp4: no bridges: br0: dhcp4: no addresses: - 192.168.4.1/24 interfaces: - eth1 接着运行如下命令启用网络配置： 6.5.4. 配置 hostapd创建一个 hostapd.conf 配置文件，用来设置无线热点的名称，密码，信道等属性 在其中写入如下内容： country_code=CNinterface=wlan0bridge=br0ssid=Example-Wifi-Namehw_mode=gchannel=11macaddr_acl=0auth_algs=1ignore_broadcast_ssid=0wpa=2wpa_passphrase=12345678wpa_key_mgmt=WPA-PSKwpa_pairwise=TKIPrsn_pairwise=CCMP 重要参数说明： country_code：国家码，中国使用 CN interface：开启无线 AP 热点的无线网卡 bridge：绑定到 br0 网桥，使得无线 AP 热点和以太网口在同一个局域网内 hw_mode：设置无线模式 channel：信道 ssid：无线 AP 名称，这里设置 Example-Wifi-Name wpa_passphrase：无线 AP 密码，这里设置为 12345678 关于更多，hostapd.conf 的配置无疑是非常复杂的，hw_mode 支持的模式有 a，g，channel 信道与 hw_mode，country_code 等都有关系，这里不再展开。如果需要对这些无线参数进行更自动化且紧密的配置，可以使用 OpenWRT 软路由系统来代替 Ubuntu 系统。 接下来，需要配置 hostapd 的全局配置文件 取消 DAEMON_CONF 的注释，设置它的值为上面创建的 /etc/hostapd.conf # Defaults for hostapd initscript# # See /usr/share/doc/hostapd/README.Debian for information about alternative# methods of managing hostapd.## Uncomment and set DAEMON_CONF to the absolute path of a hostapd configuration# file and hostapd will be started during system boot. An example configuration# file can be found at /usr/share/doc/hostapd/examples/hostapd.conf.gz#DAEMON_CONF=/etc/hostapd.conf# Additional daemon options to be appended to hostapd command:-# -d show more debug messages (-dd for even more)# -K include key data in debug messages# -t include timestamps in some debug messages## Note that -B (daemon mode) and -P (pidfile) options are automatically# configured by the init.d script and must not be added to DAEMON_OPTS.##DAEMON_OPTS= 重启 hostapd 服务 systemctl restart hostapd 到此，已经可以通过手机等设备，查看到有一个无线 AP 热点开启，名称为”Example-Wifi-Name“，但是连接之后无法为设备分配 IP 地址，设备会立即断开。 6.5.5. 配置 isc-dhcp-serverisc-dhcp-server 作为一个 dhcp 服务器，为接入无线 AP 节点的设备，比如拓扑图中的 Laptop1 和 Laptop2 自动分配 IP 地址和 DNS 服务器地址。 编辑 /etc/dhcp/dhcpd.conf， 用如下内容进行替换： # 为设备指定DNS地址，多个DNS使用,隔开option domain-name-servers 202.96.128.86,202.96.128.166,8.8.8.8,114.114.114.114;default-lease-time 600;max-lease-time 7200;ddns-update-style none; ddns-updates off;subnet 192.168.4.0 netmask 255.255.255.0 range 192.168.4.2 192.168.4.200; option routers 192.168.4.1; option broadcast-address 192.168.4.255; option subnet-mask 255.255.255.0; 重要参数说明： domain-name-servers：DNS 服务器地址列表，为接入 192.168.4.0/24 网段的设备，分配 DNS subnet 192.168.4.0 netmask 255.255.255.0：定义子网网段 192.168.4.0/24 range 192.168.4.2 192.168.4.200：分配的 IP 地址范围 option routers 192.168.4.1：默认路由 option broadcast-address 192.168.4.255：广播地址 option subnet-mask 255.255.255.0：子网掩码 重启 isc-dhcp-server，让配置生效： systemctl restart isc-dhcp-server 6.5.6. 开启 IP 转发经过如上内容的配置，接入 eth1 的设备，和连接入无线 AP 热点的设备，都能获取到 192.168.4.0/24 网段的 IP，且都能 ping 通 192.168.4.1，也可以查看到设备获取到的 DNS 服务器地址。但是设备还无法访问 internet。 开启 IP 转发 sysctl -w net.ipv4.ip_forward=1 设置 MASQUERADE（地址欺骗）。MASQUERADE 与 SNAT 作用大致一样，MASQUERADE 不用指定明确的 IP，会动态的将报文的源地址修改为指定网卡上可用的 IP 地址。 iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 注意，这里指定为 eth0，让 Firefly Board 所有的 IP 包全部转发到 eth0，让外设能够进行上网，这里也可以指定为任何能访问外网的网卡，比如 4G 网卡 usb0，wwan0，举一反三。 现在保存 IPv4（包括上面的规则）和 IPv6 的当前防火墙规则，以便在启动时由 netfilter-persistent 服务加载： netfilter-persistent save 6.6. 使用 ip 和 netplan 配置 IP 地址和路由6.6.1. 静态 IP 地址配置一个网口接口上可以同时配置多个 IP 地址，这些 IP 地址可以属于同一网络，也可以不属于同一网络。第一个配置的 IP 地址默认为接口的主 IP 地址，后面配置的 IP 地址为接口的从 IP 地址。 6.6.1.1. 常用的 IP 配置命令：// 设置接口的 IP 地址ip address add PREFIX [ broadcast ADDR ] dev IFNAME// 删除接口的 IP 地址ip address del PREFIX dev IFNAME// 查看接口的 IP 地址ip address show/list [ dev IFNAME ]// 清空接口的所有 IP 地址ip address flush [ dev IFNAME ] 6.6.1.2. 配置举例：为 eth0 接口配置主 IP：192.168.2.2，从 IP：192.168.2.3 临时配置 ip address add 192.168.2.2/24 dev eth0ip address add 192.168.2.3/24 dev eth0 持久化配置：使用 Netplan network: version: 2 renderer: networkd ethernets: eth0: dhcp4: no addresses: - 192.168.2.2/24 - 192.168.2.3/24 6.6.2. 动态 IP 地址配置操作系统一般都会为网络接口自动分配 IP 地址。对于 buildroot 系统中，dhcpcd 服务会发送 dhcp 请求到 DHCP 服务器（这里的 DHCP 服务器大概率是的路由）请求接口的 IP 地址。而在 Ubuntu 系统中，会由 NetworkManager 来完成这一过程。 临时配置 udhcpc -i eth0/eth1# 或者dhclient eth0/eth1 持久化配置：使用 netplan network: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes 6.6.3. 静态路由配置与静态路由相对的是动态路由，动态路由有 OSPF 和 RIP，这两个协议只存在于路由器中。对于非路由器设备，如果某个目的网段无法直接到达，需要配置静态路由，告诉设备目的网段，出接口，下一跳的 IP 地址。 6.6.3.1. 常用的配置命令：# 查看路由表route -n # 或者netstat -rn# 添加 IP 静态路由ip route add PREFIX via ADDRESS dev IFNAME [ metric METRIC ]# 删除 IP 静态路由ip route del PREFIX via ADDRESS dev IFNAME [ metric METRIC ]# 清空 IP 路由ip route flush dev IFNAME 6.6.3.2. 配置举例：假设存在这样的一个网络拓扑，图中的 Router1 和 Router2 是们的开发板设备，运行的系统是 Ubuntu 操作系统。在这个网络中，对于 Router1，网段 192.168.2.024 和网段 192.168.3.024，它们对于 Router1 属于直连网段，意味着对于 PC-A 来说，访问网段 192.168.2.024 和网段 192.168.3.024 是没有问题的，但是却不能访问网段 192.168.4.024。这是因为对于网段 192.168.4.024，对 Router1 来说是不可见的。需要在 Router1 配置静态路由，这条静态路由表明到目的网段 192.168.4.024，需要经过下一条 IP 地址为 192.168.3.224，出接口为 Router1 的 eth1。同样的，对于 Router2 来说，网段 192.168.3.024 和网段 192.168.4.024 属于直连网段，PC-B 也同样无法访问 192.168.2.024 网段，需要在 Router2 配置一条静态路由，表明到目的网络 192.168.2.024，需要经过下一跳 IP 地址为 192.168.3.124，出接口为为 Router2 的 eth1。 临时配置 对于 Router1： # 开启IP转发功能echo 1 /proc/sys/net/ipv4/ip_forward# 设置eth0, eth1的IP地址ip addr add 192.168.2.1/24 dev eth0ip addr add 192.168.3.1/24 dev eth1# 配置静态路由ip route add 192.168.4.0/24 via 192.168.3.2 dev eth1 对于 Router2： # 开启IP转发功能echo 1 /proc/sys/net/ipv4/ip_forward# 设置eth0, eth1的IP地址ip addr add 192.168.4.1/24 dev eth0ip addr add 192.168.3.2/24 dev eth1# 配置静态路由ip route add 192.168.2.0/24 via 192.168.3.1 dev eth1 持久化配置 对 Router1 和 Router2，执行以下命令永久开启 IP 转发 sysctl -w net.ipv4.ip_forward=1 对于 Router1，配置 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.2.1/24 eth1: addresses: - 192.168.3.1/24 routes: - to: 192.168.4.0/24 via: 192.168.3.2 对于 Router2，配置 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.4.1/24 eth1: addresses: - 192.168.3.2/24 routes: - to: 192.168.2.0/24 via: 192.168.3.1 6.6.4. 默认路由配置 临时配置 对于通过 DCHP 服务动态获取 IP 地址的接口，操作系统会自动为其分配一条默认路由。对于静态 IP 地址配置，需要手动为其设置默认路由。 还是以上面的例子来讲解，假设 PC-A 是一个 Linux 操作系统，们需要进行如下配置： # 配置网卡 IP，假设其网卡为eth0ip addr add 192.168.2.2/24 dev eth0# 配置默认路由ip route add 0.0.0.0/0 via 192.168.2.1 dev eth0 持久化配置：使用 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.2.2/24 routes: - to: 0.0.0.0/0 via: 192.168.2.1 6.6.5. 调整默认路由顺序在双网口的开发板中，如果两个网口的 IP 地址是通过 DHCP 自动获取的，那么操作系统会生成两条默认路由，每个网口分别有一条默认路由，先插入网线的网口或者先获得 IP 的网口，会获得更高的路由优先级。如下所示，有两条默认路由，eth0 网卡的默认路由优先级高于 eth1。这就意味着开发板默认通信的时候，使用的是 eth0 网卡。 root@firefly:~# ip route listdefault via 168.168.0.1 dev eth0 proto dhcp metric 100 default via 168.168.0.1 dev eth1 proto dhcp metric 101 168.168.0.0/16 dev eth0 proto kernel scope link src 168.168.110.72 metric 100 168.168.0.0/16 dev eth1 proto kernel scope link src 168.168.110.111 metric 101 6.6.5.1. 配置举例：假设存在一种情况，Wireless Router1 的网段为 192.168.3.024，Wireless Router2 的网段为 192.168.2.024，此时对于 Firefly Board 来说，eth0 和 eth1 都是动态获取 IP 地址，如果 eth0 的默认路由的优先级比 eth1 的默认路由优先级高，通信时将使用 eth0 的默认路由，由于 eth0 所在网络无外网连接，Firefly Board 就无法访问 Internet，此时可以通过修改默认路由的优先级来解决。 其 Netplan 配置如下，eth1 的 metric 数值小于 eth0，数值越小优先级越高 network: version: 2 ethernets: eth0: dhcp4: yes dhcp4-overrides: route-metric: 200 eth1: dhcp4: yes dhcp4-overrides: route-metric: 100 6.7. iptables NAT 配置网络转换技术也称为 NAT（Network Address Translation）技术，它的基本作用就是实现私有 IP 地址和公有 IP 地址之间的转换。 在 Linux 系统中，NAT 可以细化为 SNAT（Source Network Address Translation）和 DNAT（Destinationnetwork address translation）。SNAT 也称为源地址转换技术，用于当私网主机向外网主机发起网络通信时，IP 数据包在到达外网网络之前，将 IP 数据包中的源 IP 修改为路由器或者防火墙的 IP 地址，这样外网主机就无法获知内网主机的私网 IP 地址。DNAT 也称为目标地址转换技术，用于当外网主机需要访问内网主机提供的网络服务时，比如 http，IP 数据包到达路由器或者防火墙时，由它们将 IP 数据包中的目标 IP 改为提供网络服务的私网主机 IP。 6.7.1. 常用命令们可以通过配置 iptables 的 nat 表，来实现 SNAT 和 DNAT # 查看nat规则iptables -t nat -vnL# 清空nat规则iptables -t nat -F# 添加一个SNAT规则，将内网的IP，映射到外网的IPiptables -t nat -A POSTROUTING -s LocalIP -j SNAT --to-source ExtIP# 添加一个DNAT规则，将外网的IP和端口，映射到内网的IP和端口iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination LocalIP[:PORT] iptables 也支持 MASQUERADE（地址欺骗），它的作用与 SNAT 基本相同，也可以起到源地址转换的作用。在一种特殊情况中，如果外网的 IP 地址不是一个固定且长期有效的 IP 地址，比如是通过 pppoe 进行拨号动态获取的 IP 地址，就可以使用 MASQUERADE 来实现源地址转换。MASQUERADE 则不用指定明确的 IP，会动态的将报文的源地址修改为指定网卡上可用的 IP 地址。 # 添加一个MASQUERADE规则，将内网的IP，映射到外网网卡所在的IP（这里的内网IP可以省略，则默认将所有内网的IP，都映射到外网网卡所在的IP）iptables -t nat -A POSTROUTING [-s LocalIP] -o IFNAME -j MASQUERADE 6.7.2. 配置举例假设存在这样的一个网络拓扑，用 10.1.0.016 来模拟一个公网网络，用 192.168.1.024 来模拟私有网络。图中的机器都是用 Linux 主机进行模拟的机器。 对于 Router1，是一个连接内外网的路由器，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.3/24 eth1: addresses: - 10.1.0.7/16 同时对于 Router1，需要开启 IP 转发功能： echo 1 /proc/sys/net/ipv4/ip_forward 对于 Internet PC，是一个外网的个人主机，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.1.0.6/16 对于 Web Server，是一个私网服务器，提供 http 服务，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.100/24 routes: - to: 0.0.0.0/0 via: 192.168.1.3/24 6.7.3. SNAT需求：目前的网络结构中，内网主机是无法访问外网的。 添加一条 SNAT 规则，修改内网主机发往外网的 IP 数据包，将源 IP 地址为 192.168.1.024 网段的 IP，修改为 10.1.0.7 iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 10.1.0.7 验证方法： 在内网的 Web Server，ping 外网的 Internet PC ~ ping -c 4 10.1.0.6 ok PING 10.1.0.6 (10.1.0.6) 56(84) bytes of data.64 bytes from 10.1.0.6: icmp_seq=1 ttl=63 time=2.15 ms64 bytes from 10.1.0.6: icmp_seq=2 ttl=63 time=2.12 ms64 bytes from 10.1.0.6: icmp_seq=3 ttl=63 time=1.99 ms64 bytes from 10.1.0.6: icmp_seq=4 ttl=63 time=2.14 ms--- 10.1.0.6 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 7msrtt min/avg/max/mdev = 1.989/2.098/2.147/0.063 ms 在内网的 Web Server，抓包 root@firefly:/# tcpdump -i eth1 -nn icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes03:33:37.503348 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 1, length 6403:33:37.503603 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 1, length 6403:33:38.503348 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 2, length 6403:33:38.503560 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 2, length 6403:33:39.504601 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 3, length 6403:33:39.504812 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 3, length 6403:33:40.505347 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 4, length 6403:33:40.505557 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 4, length 64 6.7.4. DNAT需求：内网 Web Server 提供 http 服务，外网主机想要访问内网的 web 网页。 添加一条 DNAT 规则，修改外网发往内网的 IP 数据包，将目的 IP 地址，和端口号，修改为内网 Web 服务器的 IP 和端口号。 iptables -t nat -A PREROUTING -d 10.1.0.7 -p tcp --dport 8000 -j DNAT --to-destination 192.168.1.100:8000 验证方法： 在外网 Internet PC 访问内网 Web Server 的 Web 服务 root@firefly:/# wget http://10.1.0.7:8000/index.html--2021-02-19 03:31:12-- http://10.1.0.7:8000/index.htmlConnecting to 10.1.0.7:8000... connected.HTTP request sent, awaiting response... 200 OKLength: 41323 (40K) [text/html]Saving to: ‘index.html’index.html 100%[===================] 40.35K --.-KB/s in 0.001s 2021-02-19 03:31:12 (29.8 MB/s) - ‘index.html’ saved [41323/41323] 6.7.5. MASQUERADE需求：如果连接内外网的 Router1，它的外网网卡只有一个，为 eth1，且 IP 地址动态获取。 解决方法：添加一条 MASQUERADE 规则，将内网 192.168.1.024 发往外网的 IP 数据包，修改其源 IP 地址为 eth1 网卡的 IP 地址。 iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth1 -j MASQUERADE 6.8. iptables filter 配置iptables 的 filter 表（过滤规则表），用于控制数据包是否允许进出及转发。filter 表可以控制的链路有 INPUT、FORWARD 和 OUTPUT。常用的动作有 ACCEPT，DROP，REJECT。 6.8.1. 通用命令# 清空filter表iptables -t filter -F# 显示filter表iptables -t filter -nvL 6.8.2. ACCEPT：允许数据包通过配置举例：默认情况下 ssh 使用 22 端口进行 tcp 通信，如果要开启远程访问，需要开启 22 端口的 tcp 连接。 iptables -A INPUT -t filter -p tcp --dport 22 -j ACCEPT 开启 ssh 访问，允许 192.168.0.024 网段进行访问 iptables -A INPUT -t filter -p tcp -s 192.168.0.0/24 --dport 22 -j ACCEPT 开启 ssh 访问，允许收到的数据包来源于 eth0 网卡 iptables -A INPUT -t filter -p tcp -i eth0 --dport 22 -j ACCEPT 开启 ssh 访问，允许 192.168.0.024 网段中 MAC 地址为 00:50:8D:FD:E6:32 的主机进行访问 iptables -A INPUT -t filter -p tcp -s 192.168.0.0/24 --dport 22 -m mac --mac-source 00:50:8D:FD:E6:32 -j ACCEPT 6.8.3. REJECT：拒绝数据包通过REJECT 动作的常用选项为–reject-with（使用–reject-with 选项，可以设置提示信息，当对方被拒绝时，会提示对方为什么被拒绝） 对于 ICMP 协议，可用值如下，如果不提供，默认为 icmp-port-unreachable icmp-net-unreachableicmp-host-unreachableicmp-port-unreachable,icmp-proto-unreachableicmp-net-prohibitedicmp-host-pro-hibitedicmp-admin-prohibited 配置举例：拒接外部 ping，并提示”Destination Host Unreachable” iptables -A INPUT -t filter -p icmp -j REJECT --reject-with icmp-host-unreachable 6.8.4. DROP：丢弃数据包配置举例：直接将外部 ping 包丢弃 iptables -A INPUT -t filter -p icmp -j DROP 7. Qt 支持7.1. Qt 环境支持Firefly 设备系统如果是 Ubuntu 22.04 可以直接通过 apt 安装 Qt 环境： # 安装基础环境apt updateapt install -y qtcreator qtbase5-dev# 安装额外组件与开发环境，例如apt install -y libqt5multimedia5 qtmultimedia5-dev libqt5quick5 qtdeclarative5-dev 安装后直接在设备上进行开发。 Ubuntu 18.04 或者 Ubuntu 20.04 需要借助电脑进行交叉编译，详情请看下一章 7.2. Qt 交叉编译环境支持Firefly 发布了两个 Qt 交叉编译工具链，适用于以下环境，请根据需求选择: Qt: 5.12.2 Host: x86-64 Ubuntu 18.04 Target: Firefly RK3568 RK3566 RK3399 RK3328 PX30 Ubuntu 18.04 MinimalDesktop 和 Qt: 5.15 Host: x86-64 Ubuntu 20.04 Target: Firefly RK3588 RK3568 RK3566 Ubuntu 20.04 Desktop 工具链完整支持 wenEngine, 支持 EGLFS LinuxFB XCB 等 backend。 下载地址 点击 下载链接(提取码：FFQT) 部署 详情参见工具链中的 Qt5.1x.x_Release.md 文件 注意，文档中所有路径的名称不可更改，否则会导致编译或者运行出错。 编译 在 host 端，进入 Qt 工程目录，qmake make 即可. 运行 工具链中含有例程，用户在部署完成后，可以在 host 端 build demo，在 tartget 端运行 demo 以测试部署是否成功。 确定了使用哪个后端，就可以修改设备中 etcprofile.dtarget_qtEnv.sh 文件，去除对应平台环境变量前面的 # 使其一直生效 # 例如，使用 XCB ，则将文件内 XCB 部分前面的 # 删除#XCBexport QT_QPA_PLATFORM=XCBexport QT_QPA_EGLFS_INTEGRATION=XCB_EGL 7.3. Qt 双屏异显Firefly Ubuntu 系统可以使用 Qt 应用实现双屏显示和操作。 （1）进入桌面环境 export XAUTHORITY=/home/firefly/.Xauthorityexport DISPLAY=:0 （2）设置环境变量 export QT_QPA_PLATFORM=xcbexport QT_QPA_EGLFS_INTEGRATION=XCB_EGL （3）运行 Demo ./firefly_arm64_qt5.12.2_18.04/demo/double_panel_demo （4）Demo 代码目录 firefly_arm64_qt5.12.2_18.04/example/double_panel_demo （5）代码编译 （6）添加自己的 Qt 工程 在 example 目录下添加用户自己的 Qt 项目工程。 编辑 example 目录下 gui.pro 文件。 假设工程目录名为 double_panel_demo，则在 gui.pro 文件中追加 SUBDIRS += double_panel_demo。 执行命令 qmake make。 （7）运行效果 7.4. Qt Creator目标平台的系统是 Ubuntu 22.04 则不用看本章节，直接在设备上使用 qtcreator，无需特殊设置。 其他版本系统需要交叉编译 qt，请继续往下看： 下面介绍主机上 Qt Creator 的使用说明，在操作前，请先安装、配置好 Qt 交叉编译环境和运行环境。 7.4.1. 安装进入 Qt 官方下载页面，选择一个版本下载 qt-creator-opensource-linux-x86_64-x.x.x.run，下载完成之后，在终端执行 ./xxxx.run 运行安装，注意文件需要有执行权限。 7.4.2. 配置下面以 firefly-qt-5.12.2-aarch64 环境作为例子进行配置，目标平台是 Buildroot 系统： 目标平台系统不同，配置也稍有不同，所以请仔细查看文字说明，图片仅供参考，不要照搬图片中的配置 安装完成后，启动 Qt Creator，打开菜单 Tools - Options，找到 Kits。 配置 Qt Versions 点击右侧 add 按钮添加，选择 Qt 环境安装位置中的 qmake 即可 qmake：/opt/firefly-qt-5.12.2-aarch64/host/bin/qmake 配置 Compilers 点击右侧 add 按钮添加 gcc 和 g++ 交叉编译器的位置 如果主机安装了 crossbuild-essential-arm64，则编译器就在 /usr/bin/ 下 如果使用了第三方的交叉编译器，找到安装位置并添加即可 如果目标平台是 Buildroot，则需要使用 Buildroot Qt 环境包中的编译器 g++：/opt/firefly-qt-5.12.2-aarch64/host/bin/aarch64-buildroot-linux-gnu-g++ gcc：/opt/firefly-qt-5.12.2-aarch64/host/bin/aarch64-buildroot-linux-gnu-gcc 为方便调试，配置 Debuggers 和 Devices 用于在线调试： 配置 Debuggers 首先主机中安装 gdb-multiarch：apt install -y gdb-multiarch 检查目标机上是否存在 usrbingdbserver，没有的话需要安装：apt install -y gdbserver (Buildroot 自带，无需安装) 回到主机的 Qt Creator，点击右侧 add 按钮添加 gdb 选择主机中的 gdb-multiarch ：/usr/bin/gdb-multiarch 配置 Devices 设置好设备的 IP、用户名 (root) 和密码 (firefly) 。为了方便调试，可以在设备上设置静态 IP。 GDB server 设置为 /usr/bin/gdbserver 配置 Kits 将前面设置的配置项添加到 Kits。 如果目标平台是 Ubuntu 系统，这一步也需要添加 sysroot 的路径 7.4.3. 编译运行打开 demo 程序，Welcome - Open Project，选择要使用的 Kits： 之后打开 Projects - Run，配置命令行参数，这里设置为 -platform wayland： 目标平台是 Ubuntu 则使用 -platform xcb (Ubuntu 桌面环境)，或者根据需要选择 linuxfb、eglfs 配置环境变量，即 export XDG_RUNTIME_DIR=/tmp/.xdg： RK356X Buildroot 则需要使用 /var/run 而不是 /tmp/.xdg 目标平台是 Ubuntu 则需要根据之前设置的 platform 添加不同的环境变量，详情在 Qt 环境包中的说明文件中 如果目标平台的运行环境(本文开头提到的)之前已经配置好并成功运行 demo，此时可以直接点击右侧 Fetch Device Environment 获取目标的环境变量 编译运行： 点击 Build 交叉编译 Qt 程序；点击 Run 或 Debug 在设备上运行或调试程序。要重新运行程序时，记得手动点击 Stop 关闭已经运行的程序。 编译生成目录和 demo 目录在同一位置。 8. Docker 支持Firefly 发布的普通固件一般不满足 Docker 的运行要求，如果有需求，可以使用 SDK 打开内核的相关配置，重新编译烧录内核以支持 Docker。 （RK356X v1.2.4a 及以后版本 、RK3399RK3588 默认支持 Docker，可直跳到 安装 Docker 步骤） 以下案例是基于 Firefly Ubuntu 20.04，内核配置部分是通用的！ 8.1. 检查 Kernel 配置首先需要通过工具检查当前设备的内核缺少了哪些 Docker 需要的配置。检测脚本 check-config.sh 可以前往 社区论坛 获取。 获取到脚本之后，开始进行检测： #将脚本拷贝到SDK的kernel目录下cp check-config.sh PathToSDK/kernel/cd PathToSDK/kernelchmod +x check-config.sh#获取当前内核配置make ARCH=arm64 firefly_linux_defconfig#检测./check-config.sh .config 执行后的结果如下，主要是两部分： Generally Necessary:- cgroup hierarchy: properly mounted [/sys/fs/cgroup]- apparmor: enabled and tools installed- CONFIG_NAMESPACES: enabled- CONFIG_NET_NS: enabled- CONFIG_PID_NS: enabled- CONFIG_IPC_NS: enabled- CONFIG_UTS_NS: enabled- CONFIG_CGROUPS: enabled......Optional Features:- CONFIG_USER_NS: enabled- CONFIG_SECCOMP: enabled- CONFIG_SECCOMP_FILTER: enabled- CONFIG_CGROUP_PIDS: enabled- CONFIG_MEMCG_SWAP: enabled...... Generally Necessary: 表示必要的配置，如果有显示 missing 的地方，就需要在内核配置中打开它。 Optional Features: 是可选配置，根据需要打开。 8.1.1. 开启需要的配置从上面的检测结果中得知需要打开哪些配置后，即可使用 make ARCH=arm64 menuconfig 进入菜单，搜索对应项目将其打开。请认真查看菜单中的操作说明，遇到不可选中的项目请注意依赖关系。 开启所有必要配置以及部分可选配置后，注意保存： make ARCH=arm64 savedefconfigmv defconfig arch/arm64/configs/firefly_linux_defconfig 之后进行编译内核： #退回到SDK目录cd ..#编译内核./build.sh kernel 8.2. 安装 Docker烧录完新内核之后，可以开始在设备上安装 Docker (此安装方法同样适用于 PC)： 步骤 1：快速安装 # 这里仅介绍直接使用脚本快速安装apt-get updatewget -qO- https://get.docker.com/ | sh 等待安装成功之后应该会看见 Docker 版本信息 步骤 2：检查 docker 存储位置（该步骤仅适用于 PC 安装 docker） 如果在 Firefly 设备中安装 docker，请跳过步骤 2 # 执行docker info | grep -i dir# 执行结果 Docker Root Dir: /var/lib/docker 返回的信息显示了 docker 的默认存储位置，该位置在不同电脑上可能不一样 镜像和容器会占用大量空间，因此，如果默认的位置空间不大，需要修改到空间充足的位置 再次强调，此步骤只用于 PC，Firefly 设备中，修改此位置会导致 docker 无法工作，请直接跳到下一步 # 先关闭 docker 服务sudo systemctl stop docker# 修改文件 /lib/systemd/system/docker.servicesudo vim /lib/systemd/system/docker.service# 在这一行末尾添加想要修改的位置 --graph /home/firefly/docker/dataExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --graph /home/firefly/docker/data# 重启 docker 服务sudo systemctl daemon-reloadsudo systemctl start docker# 检查位置是否修改成功docker info | grep -i dir Docker Root Dir: /home/firefly/docker/data 步骤 3：将自己的用户添加到 docker 组 sudo usermod -a -G docker firefly# 添加后重启sudo reboot 步骤 4：重启后运行 demo 测试是否正常： firefly@firefly:~# docker run hello-worldUnable to find image hello-world:latest locallylatest: Pulling from library/hello-world93288797bd35: Pull completeDigest: sha256:cc15c5b292d8525effc0f89cb299f1804f3a725c8d05e158653a563f15e4f685Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the hello-world image from the Docker Hub. (arm64v8) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 9. ROS 支持9.1. 安装 ROS首先按照官方安装教程安装，根据系统选择对应 ROS 版本安装。 官方安装教程 9.1.1. 安装 GLX 库rviz,gazebo 是基于 GLX 编写的，们系统目前只支持 EGL，所以他们无法使用 GPU 加速，同时需要安装 GLX 库才能能够正常运行。 apt install -y libgl1-mesa-glx libgl1-mesa-dri libglx-mesa0reboot 9.2. 更新 libqt5opengl5-dev如果遇到 rviz 还不能运行，rqt 报 QOpenGLTimeMonitor 等错误，需要更新官方的 libqt5opengl5-dev， 执行下面操作，再尝试运行 rqt、rviz 和 gazebo 等程序 sed -i s/.*wiki.t-firefly.com.*/\\#/ /etc/apt/sources.listapt install libqt5opengl5-devsed -i /.*wiki.t-firefly.com.*/s/^#// /etc/apt/sources.list 9.3. wayland 下运行 rviz，rqt 和 gazebo 等程序XWayland说明 基于 GLX 的程序在 wayland 运行，需要使用 XWayland。使用 QT_QPA_PLATFORMxcb 强制 Qt 应用程序使用 X11 QT_QPA_PLATFORM=xcb rvizQT_QPA_PLATFORM=xcb rqtQT_QPA_PLATFORM=xcb gazebo# 也可以将该环境设置到.bashrc，就可以直接运行rviz等程序。echo export QT_QPA_PLATFORM=xcb /~/.bashrc 9.4. ROS教程10. 显示架构支持对于 Rockchip 平台，主要有以下几种显示架构可供选择： Qt + Wayland Qt + EGLFS EGL program + X11 Wayland None 多窗口的功能需求，选择： X11 Wayland 桌面的功能需求，选择： X11 4K 视频播放 + 全屏： Qt + Wayland Qt + EGLFS X11 Wayland 4K 视频播放 + 多窗口： X11 Qt + Wayland Wayland 如果对显示架构的技术不太理解，可以继续往下阅读。 10.1. X11X11 是 X 显示协议的第 11 个版本。 X 协议已经延用了 30 年，X 协议的 ClientServer 结构起初是为了在以前硬件性能太弱的情况下，设备（Client 端）通过发送渲染请求给 X server（以前 X server 是运行在另一个独立的硬件）渲染显示。 但是随着现代硬件性能不断提升，同一个硬件系统上可以同时运行 Client 和 Server 了，但是这种远程通讯结构运用在本地机器上带来的后果就是性能的丢失，目前在 Debian 官方已经有分支在开发 Wayland 用于替换掉 X11，但是目前 Wayland 对现有软件兼容性并不好所有还没有正式替换使用。 参考资料: https://en.wikipedia.org/wiki/X.Org_Serverhttps://www.comptechdoc.org/os/linux/howlinuxworks/linux_hlxwindows.htmlhttps://dri.freedesktop.org/wiki/DDX/https://www.freedesktop.org/wiki/Software/Glamor/https://en.wikipedia.org/wiki/X.Org_Server 10.2. Qt + EGLFSQt + EGLFS 是 Qt 自己实现的一个 GUI 系统，不支持多窗口，但也因此少了 window composite。 Qt + EGLFS 和 dri2 的方式类似，区别就在于 Qt + EGLFS 的 font buffer 在自己用 gpu composite 后，是直接送给 DRM 显示，而 X 里是送至 Window manager 做 composite，所以 EGLFS 在效率上是有优势的。 10.3. Qt + Wayland在 Wayland 中，Weston 是 Wayland 显示协议中的具体实现，其对应关系就好比 Xorg （X server）和 X 的关系一样。 目前 Wayland 和 X 对比唯一缺点就是在兼容性上了，所以目前主流的系统版本中依然大部分使用 X。 Weston 不再使用 X 的 ClientServer 的结构，而是直接由合成器接受内核事件，并传递给 Client 端，由 Client 端直接渲染，只向合成器发送需要更新的区域，再由合成器通知内核安排翻页。 需要注意的是由于 UbuntuDebian 已经有 X11，所以 SDK 默认是在 Buildroot 添加了 Weston 的支持，实际上如果 UbuntuDebian 需要安装 Weston 的话也可以在 Minimal 版本上搭建。 （Firefly Ubuntu 20.04，将会默认自带 Wayland 和 X，并且可以自由切换。） 建议使用 BuildrootYocto 做 Wayland 的开发。效率上 Wayland 要比 X11 好点，主要是兼容性问题。 如果不需要桌面，又要多窗口，可以尝试使用 Wayland。 10.4. None除了 X11 和 Wayland 之外，还有 None，这也是嵌入式上接触比较多的。比如 MiniGUI，SDL 皆是如此。 若要支持到 DRM 和 opengl 的话，就只能选择 Qt 了。 MiniGUI 是一个定位于轻量级的嵌入式图形库，对系统资源的需求完全考虑到了嵌入式设备的硬件情况，如 MiniGUI 库所占的空间最小可以裁剪到 500K 左右。 针对 Buildroot 系统适配在硬件资源比较紧张的设备上的特性，MiniGUI 搭配 Buildroot 是再适合不过了。 参考资料: https://wayland.freedesktop.org/architecture.htmlhttps://en.wikipedia.org/wiki/Wayland","tags":["clippings"],"categories":["1.平台","嵌入式"]},{"title":"Xenomai实时框架","path":"/2024/10/16/1-平台-嵌入式-RealTime-Xenomai实时框架/","content":"Xenomai 概述Xenomai 是一个专门为 Linux 平台设计的实时框架，它允许各种实时操作系统（RTOS），如 VxWorks 和 QNX，的应用程序接口（API）在 Linux 环境中使用。这种创新的技术集成显著提升了 Linux 系统的实时性能，提供了硬实时调度的保障，使开发者能够在 Linux 上实现严格的时间响应要求。这对许多需要快速反应的应用来说至关重要，比如自动化控制、机器人技术和高频交易。 Xenomai 不仅能够在主流的 Linux 内核上运行，还支持多种嵌入式平台。这一点对于大多数工业或消费类设备至关重要，因为很多设备依赖嵌入式系统来执行关键任务。Xenomai 官方支持多种嵌入式硬件，开发者可以通过访问 Xenomai 官方嵌入式设备列表 来了解适合特定项目的设备。 总体来看，Xenomai 为开发人员提供了强大的工具，可以帮助完成以下关键任务： 实时应用程序的设计与开发：利用 Xenomai 的强大功能，可以在 Linux 上设计和运行需要高实时性的应用程序。例如，自动化生产线的控制系统必须在毫秒内对传感器输入做出反应，Xenomai 能够提供所需性能以满足这些要求。 RTOS 应用程序的移植：如果已有在 RTOS 上开发的应用程序，Xenomai 使得它们顺利迁移到 Linux 成为可能。比如，许多机器人控制程序最初是在 VxWorks 上开发的，通过 Xenomai，开发者可以保留原有代码并在 Linux 环境中继续使用，极大简化了开发流程。 以 Linux 原生应用程序方式运行 RTOS 应用：Xenomai 能够让像运行 Linux 应用一样直接运行 RTOS 应用程序，例如 VxWorks、pSOS、VRTX、uITRON 和 POSIX。这意味着，如果团队已经习惯于在 Linux 环境中开发，也可以轻松接入这些 RTOS 系统的应用，提升工作效率，减少学习成本。 通过这些功能，Xenomai 不仅极大提升了 Linux 的实时处理能力，也为开发者创造了一个灵活且高效的工作环境。 Xenomai 架构双内核结构Xenomai 采用双内核架构来实现其实时操作。一个是高优先级的微内核（co-kernel），另一个是传统的 Linux 内核。co-kernel 负责执行实时任务，而 Linux 内核则维持其常规的服务功能。两个内核由 Adeos 进行管理，每个内核被分配到不同的域。 需要注意的是，微内核可能会切换到 Linux 内核域，这会破坏 Xenomai 的实时性。这种情况可能发生在实时任务中使用了 Linux 的一些系统调用时，因此在设计实时任务时，需要谨慎使用 Linux 系统调用。 AdeosAdeosi-pipe 是实现双内核结构的核心，它是 Xenomai 和 RTAI 等系统的基础。在基于 Adeos 的系统中，操作系统在独立的域内运行，每个域有独立的地址空间及类似进程、虚拟内存等的软件抽象层，且这些资源可以在域间共享。 在计算机系统中，操作的执行主要依赖于内部和外部的中断与异常，例如系统时钟中断是操作系统中最重要的中断。Adeos 通过管理硬件中断，并根据域的优先级依次调用相应域的中断服务程序，来驱动系统的运行。同时，Adeos 还提供了域间通信机制，实现域的调度等功能。 为了有效管理中断及控制域间的优先，这里引入了”中断管道（Interrupt Pipe）”的概念。通过中断管道，Adeos 在不同域之间传播中断，并提供机制让域能够调整自身在中断管道中的优先级。 Xenomai 在 Adeos 系统中的域优先级高于 Linux 域，意味着每当中断发生时，Adeos 首先调度 Xenomai 来处理该中断并执行相应的实时任务，只有在 Xenomai 没有实时任务和中断需要处理时，Adeos 才会调度 Linux，这确保了 Xenomai 的中断响应速度和实时任务不受 Linux 的干扰，从而提供了可预测的实时性能。 性能测试Xenomai 提供了一系列性能测试工具，安装完 Xenomai 后，这些工具会位于 Xenomai 安装目录的 bin/ 文件夹。以下是一些关键测试工具的列表及其功能： clocktest：用于测试 CPU 时钟的精度和性能。 cyclictest：用于测试 Xenomai POSIX 周期定时器的性能。 dohell：生成系统负载以测试系统的承载能力。 irqbench：对中断请求（IRQ）进行性能测试。 irqloop：用于更深入的 IRQ 测试。 klatency：内核空间时延测试工具，评估内核操作的延迟。 latency：用于测量定时器的时延，确保定时器精度。 switchbench：测试任务切换延迟，以评估系统的切换效率。 switchtest：用于测量进程上下文切换的时间。 xeno-test：运行用户定义的脚本，以评估最佳和最差延迟。 这些工具为开发者提供了强有力的手段，以监控和优化实时应用程序的性能，确保系统在真实环境中能够满足预期的实时性要求。","categories":["1.平台","嵌入式","RealTime"]},{"title":"嵌入式实时性优化","path":"/2024/10/15/1-平台-嵌入式-RealTime-嵌入式实时性优化/","content":"Firefly Linux 开发指南 为了满足用户对系统实时性的需求，官方在 SDK 源码的内核基础上支持升级 Linux 到 RTLinux。 们 RTlinux 支持有 preempt 和 xenomai 两个版本,下面以 preempt 版本来测试。 1.1. RTLinux 系统固件支持支持 RK3562、RK356X 及 RK3588 等芯片平台，可前往对应机器版型下载固件页面下载实时固件。如需要源码请联系商务。 1.2. 测试实时效果测试实时性能需要 cyclictest,可以使用 apt 安装。 apt updateapt install rt-tests 1.2.1. 测试 RTLinux 的实时效果使用 stress 或 stress-ng 模拟通用的压力场景，使 CPU 处于满负荷状态。 # 根据芯片核心数运行cpu压测线程、io压测线程及内存压测线程stress --cpu 4 --io 4 --vm 4 --vm-bytes 256M --timeout 259200s 执行以下命令测试每个核心实时响应延迟，将进行为期 3 天的测试，测试完成后的测试结果输出到 output 文件。 cyclictest -m -S -p99 -i1000 -h800 -D3d -q output 们执行以上操作分别在 rk3568、rk3562 及 rk3588 进行 3 天的延迟测试。其中 rk3568 和 rk3562 将 CPU3 从内核 SMP 平衡和调度算法中剔除，而 rk3588 将 CPU6 和 CPU7 从内核 SMP 平衡和调度算法中剔除，以便观察芯片最好的实时性能。 为了便于观察，们将 rk3568、rk3562 及 rk3588 的测试结果转换成直方图和表，如下所示。 在本次测试中，RK3562 的 CPU2 核心 Max Latencies 值最大，为 152us，隔离 CPU3 核心（从内核 SMP 平衡和调度算法中剔除的核心）的 Max Latencies 值最小，为 20us。 RK3568 的 CPU0 核心的 Max Latencies 值最大，为 135us，隔离 CPU3 核心的 Max Latencies 值最小，为 18us。 RK3588 的 CPU0 核心的 Max Latencies 值最大，为 45us，隔离 CPU7 核心的 Max Latencies 值最小，为 3us。 由此可见，在同芯片平台下隔离核心的实时性最好。所以尽量将们的实时任务绑定到隔离核心运行，以获得最好的实时效果。 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 Total 420738794 420738789 420738773 420738757 Min Latencies 00003 00003 00003 00002 Avg Latencies 00009 00008 000012 00003 Max Latencies 00074 00078 00152 00020 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 Total 259200000 259199935 259199824 259199769 Min Latencies 00004 00003 00003 00003 Avg Latencies 000017 000015 000017 00004 Max Latencies 000135 000112 00107 00018 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 Total 259200000 259199978 259199943 259199926 259199914 259199930 259199871 259199898 Min Latencies 00003 00003 00003 00003 00001 00001 00001 00001 Avg Latencies 00007 00006 00006 00006 00003 00003 00001 00001 Max Latencies 00045 00037 00035 00033 00024 00020 00004 00003 1.2.1.1. 其他压力场景不同场景的延迟测试结果不尽相同，为了尽可能接近们的生产环境，可同时制作其他压力场景，如： 制造网络压力： #使用iperf进行上下行同时测试，使网卡的发送和接收处于满负载状态iperf -c 192.168.1.220 -p 8001 -f m -i100 -d -t 259200 制造 gpu 压力： #无限地运行，从最后一个基准循环到第一个基准glmark2-es2-wayland --run-forever 1.2.2. Cyclictest 标准测试threads 选项(-t)用于指定 Cyclictest 在检测延迟时将使用的测量线程数。通常，在系统上的每个 CPU 上只运行一个测量线程是一个标准的测试方案。可以使用亲和性选项(-a)指定线程必须在其上执行的 cpu。 这些选项对于最小化运行 Cyclictest 对观察到的系统的影响至关重要。在使用 Cyclictest 时，确保在任何给定时间只执行一个测量线程是很重要的。如果两个或多个 Cyclictest 线程的预期执行时间重叠，则 Cyclictest 的测量将受到其自己的测量线程所造成的延迟的影响。确保在给定的时间只执行一个测量线程的最好方法是在给定的 CPU 上只执行一个测量线程。 例如，如果要分析三个特定 cpu 的延迟，则指定应该使用这些 cpu(使用-a 选项)，并指定应该使用三个测量线程(使用-t 选项)。在这种情况下，为了最小化 Cyclictest 的开销，请确保收集度量数据的主 Cyclictest 线程没有运行在三个隔离的 cpu 之一上。主线程的关联性可以使用 taskset 程序设置，如下所述。 1.2.2.1. 在评估一组隔离的 cpu 上的延迟时，减小 cyclictest 的影响在测量 cpu 子集上的延迟时，确保主 Cyclictest 线程正在未被评估的 cpu 上运行。例如，如果一个系统有两个 CPU，并且正在评估 CPU 0 上的延迟，那么主 Cyclictest 线程应该固定在 CPU 1 上。Cyclictest 的主线程不是实时的，但是如果它在被评估的 CPU 上执行，它可能会对延迟产生影响，因为会有额外的上下文切换。在启动 Cyclictest 之后，可以使用 taskset 命令将主线程限制为在 cpu 的某个子集上执行。例如，针对 CPU1 到 CPU3 的延时测试: #CPU1到CPU3运行实时程序，主线运行在CPU0上taskset -c 0 ./cyclictest -t3 -p99 -a 1-3 taskset 程序还可以用于确保系统上运行的其他程序不会影响隔离 CPU 上的延迟。例如，启动程序 top 查看线程并固定到 CPU 0 上，使用下面的命令: taskset --cpu 0 top -H -p PID#top打开之后点击f键，光标移动到 P 选项，空格选中，然后点击 q建退出，便可查看到实时线程在哪些CPU上运行。 1.3. 提高实时策略1.3.1. 抑制控制台消息及禁止内存过度使用#可以使用内核参数quiet启动内核，或者启动之后抑制，如下：echo 1 /proc/sys/kernel/printk#禁用内存过度使用以避免 Out-of-Memory Killer产生的延迟echo 2 /proc/sys/vm/overcommit_memory 1.3.2. 不使用桌面或者使用轻量级窗口管理器为了更好的实时，们不建议使用带桌面的系统，因为这将为 CPU 延迟带来很大的挑战。建议使用 minimal ubuntu、自己的 QT 程序等。 356x 的 rt 固件默认不使用桌面，而是使用窗口管理器 weston，显示协议是 Wayland。 1.3.2.1. 切换 X11 环境如果需要 X11 的环境，可手动切换到 X11 sudo set_display_server x11reboot#sudo set_display_server weston 可再次切换回weston，重启生效 1.3.2.1.1. 使用 openbox 窗口管理器启动切换到 X11 环境默认使用桌面，如果需要使用轻量级的窗口管理器 在etclightdmlightdm.conf 指定 ession 使用 openbox 窗口管理器： cat /etc/lightdm/lightdm.conf.d/20-autologin.conf [Seat:*]user-session=openboxautologin-user=firefly 1.3.2.1.2. 只运行自己的 X11 程序若是不用登录管理器启动 X 显示服务，可使用 xinit 手动启动 Xorg 显示服务。 执行 xinit 和 startx 时，它们将寻找.xinitrc 做为 shell 脚本运行以启动客户端程序。 若是.xinitrc 不存在，startx 将运行默认值etcX11xinitxinitrc(默认的 xinitrc 启动一个 Twm，xorg-xclock 和 Xterm 环境)。 首先关闭 lightdm 服务 systemctl disable lightdm 然后使用 startx 启动自己的程序 也可修改默认 startx 指定的 client 的 xinitrc 文件,默认的会运行 Xorg vim /etc/X11/xinit/xinitrc-------------------------------------------------------------#!/bin/sh # /etc/X11/xinit/xinitrc## global xinitrc file, used by all X sessions started by xinit (startx)# invoke global X session script#. /etc/X11/Xsession#chromium --window-size=1920,1080chromium --start-maximized 1.3.3. 绑定核心实时要求高的事件固定到某个核心上处理，系统及其它实时要求不高的事件集中到一个核心上处理。例如特定的中断，实时程序等事件可以用专门的核心为他们服务。 1.3.3.1. 任务绑定核心rt 应用可由特定核心处理，将 rt 应用绑定到 cpu3 1.3.3.2. 中断绑定核心由于 arm 将所有外设中断全部由 cpu0 处理，对于重要的中断可以在系统启动之后将中断绑定到其他核心。 例如将 eth0 中断绑定到 cpu2 root@firefly:~# cat /proc/interrupts | grep eth0 38: 28600296 0 0 0 GICv3 64 Level eth0 39: 0 0 0 0 GICv3 61 Level eth0root@firefly:~# cat /proc/irq/38/smp_affinity_list 0-3root@firefly:~# echo 2 /proc/irq/38/smp_affinity_listroot@firefly:~# cat /proc/irq/38/smp_affinity_list 2root@firefly:~# cat /proc/interrupts | grep eth0 38: 29009292 0 52859 0 GICv3 64 Level eth0 39: 0 0 0 0 GICv3 61 Level eth0 1.3.4. 使用 smp+amp 方案对于实时要求更高的，可以使用 amp 方案，以达到更好的实时控制。 rk3568 支持了 amp（非对称多核架构），可以定制某些核心跑定制的系统。 比如 0～2 核心跑 kernel，3 核心跑 rt-thread 等；支持 Linux(Kernel-4.19、rt-kernel-4.19)、 Baremetal(HAL)、RTOS(RT-Thread) 组合 AMP 构建形式，可任意搭配。 不同内核之间可以使用核间通信来进行信息交互。","tags":["clippings"],"categories":["1.平台","嵌入式","RealTime"]},{"title":"3399部署Tengine框架","path":"/2024/10/14/1-平台-嵌入式-应用软件移植-3399部署Tengine框架/","content":"Tengine 简介及其优势Tengine 是 OPEN AI LAB 开发的一款轻量级神经网络推理引擎，特别针对 Arm 嵌入式平台进行了优化。它为 Android 和 Linux 系统提供了出色支持，确保广泛适用性。更为重要的是，Tengine 不依赖专用的 AI 芯片，支持利用具有 AI 加速功能的 GPU、NPU 等模块进行运算，同时也能在通用 CPU 上运行。这使得许多 Arm 平台的用户能够通过 Tengine 框架最大程度地挖掘硬件算力，从而高效运行各种 AI 应用。 RK3399 开发板环境OPEN AI LAB 在 GitHub 上提供了开源的 Tengine 版本，并附有详细的参考文档，因此用户可以直接下载源码并按照文档进行编译。由于 RK3399 拥有强大的性能，能够直接在开发板上下载和编译源代码，这避免了多数交叉编译所带来的不便。 Tengine AI 框架的部署在 RK3399 开发板上部署 Tengine AI 框架需要以下步骤： 1. 下载源码git clone --recurse-submodules https://github.com/OAID/tengine/ 在下载源码时，确认使用 --recurse-submodules 参数，确保代码完整。 2. 安装依赖执行以下命令安装必需的库和工具： apt install libprotobuf-dev protobuf-compiler libopencv-dev pkg-config 3. 修改配置文件Tengine 源码中，default_config 目录提供了针对 arm32、arm64 和 x86 三个平台的配置文件。由于 RK3399 是 Arm64，所需的配置文件为 arm64_linux_native.config。在执行编译前，必须在配置文件中打开 BUILD_SERIALIZER=y 选项，如果遗漏可能会导致运行时出现以下错误：Shared library not found: libcaffe-serializer.so: cannot open shared object file: No such file or directory。 4. 编译在源码根目录中执行以下命令进行编译： ./linux_build.sh default_config/arm64_linux_native.config 5. 模型AI 应用运行时需要加载相应的 model 文件。将 model 文件放在 Tengine 源码根目录下的 models 文件夹。 6. 运行 benchmark完成编译后，默认情况下在 build/benchmark/bin/ 目录下生成两个用于测试的 benchmark 文件，可以直接执行这些文件，验证是否成功编译。 ./build/benchmark/bin/bench_sqz./build/benchmark/bin/bench_mobilenet 7. 编译并运行测试 DemoTengine 的源码中还包含了一些图像识别相关的测试 Demo，适合进行 AI 相关的基础学习。这些 Demo 的源码存放在 examples 目录中。编译前需要修正 linux_build.sh 脚本，确保 Tengine 的准确路径。比如我下载编译的 Tengine 代码在 /root/rockdev/tengine 目录下，然后在 examples 目录下执行如下命令： mkdir buildcd build/../linux_build.sh make 编译后的主要 Demo 包括 faster_rcnn、lighten_cnn、mobilenet_ssd、mtcnn、ssd、yolov2 和 YuFaceDetectNet。 Faster R-CNN：由 Ross B. Girshick 于 2016 年提出的模型，是在 RCNN 和 Fast RCNN 的基础上进一步发展，具有更高的性能和更快的检测速度。执行此 Demo 之后，可以监测到目标物体，生成一张对检测到的物体进行标注后的图像。例如识别结果为 Dog、Bicycle、Car。 **YOLO (You Only Look Once)**：2016 年 CVPR 上发表的目标检测方法，YOLO v2 在 2017 年再次推出，论文《YOLO9000: Better, Faster, Stronger》获得 CVPR 2017 颁发的最佳论文荣誉提名。采用此模型的检测速度几乎快了 6 倍。 **SSD (Single Shot MultiBox Detector)**：由 Wei Liu 提出的通用物体检测算法。 Mobilenet 和 SSD 结合：这种组合更友好于移动设备。在相同的测试图片上，虽然检测速度更快，但仍有遗漏。 YuFaceDetectNet：由深圳大学的于仕琪老师开源的人脸检测库，声称为最快的人脸检测库。 MTCNN：另一种人脸检测方案，其结果与 YuFaceDetectNet 相当，时间差距不大。","categories":["1.平台","嵌入式","应用软件移植"]},{"title":"MySQL移植","path":"/2024/10/07/4-软件-数据库-MySQL移植/","content":"关注点在进行 MySQL 移植之前，有几个关键问题需要特别关注，以确保整个过程顺利进行： -MySQL 目前尚未支持交叉编译的版本**： - 由于 MySQL 的某些版本不支持交叉编译，因此在执行 configure 脚本时，必须手动注释掉多个不支持交叉编译的命令。这一步骤至关重要，因为如果不处理这些命令，配置过程将无法顺利完成。比如，某些特定的库或功能在交叉编译环境中可能无法正常工作，导致编译失败。 交叉编译需要 libncurses.a 库： libncurses.a 是一个用于处理终端输入和输出的静态库。在交叉编译 MySQL 之前，必须使用 ncurses-5.6 中的 libncurses.a 库，而不是动态链接库 libncurses.so.5。这意味着需要先手动交叉编译 libncurses.a，以确保在 ARM 平台上能够正确运行。静态库的使用可以避免在运行时依赖动态库，确保程序在目标平台上的兼容性。 gen_lex_hash 命令的处理： 在编译过程中，需要运行 gen_lex_hash 命令。然而，该命令的 ARM 格式版本无法在 PC 上运行。为了解决这个问题，建议先在 PC 上编译出一个可用的 MySQL 版本，然后从相应目录中拷贝可用的 gen_lex_hash 文件，覆盖掉 ARM 格式的文件。这样可以确保在 ARM 编译过程中不会因为缺少该文件而导致编译失败。 openssl： OpenSSL 是为应用程序提供安全通信的库，确保数据在网络传输过程中的安全性。在编译 MySQL 时，确保 OpenSSL 库的正确版本和路径是至关重要的。 boost： Boost 是一个广泛使用的 C++ 库集，提供多种功能增强项，包括数据结构、算法、文件系统等。MySQL 的某些功能可能依赖于 Boost，因此确保其版本与 MySQL 兼容是必要的。 依赖库的版本： 每个 MySQL 版本所依赖的库版本不能随意选择，具体依赖关系可以通过查阅 MySQL 官方文档或相关文献获得。确保所有依赖库的版本与 MySQL 版本匹配，可以避免在编译和运行时遇到不必要的错误。 准备工作 下载 MySQL 的 tar 包：例如：mysql-5.1.51.tar.gz 下载链接：MySQL Tar 包 和 MySQL Archives。选择带有 Boost 的 Generic Linux 版本，这样可以避免额外安装 Boost 库。 http://www.mirrorservice.org/sites/ftp.mysql.com/Downloads/MySQL-5.1/mysql-5.1.51.tar.gzhttp://download.chinaunix.net/download.php?id=34712ResourceID=7159 下载 ncurses-5.6 的 tar 包：访问官方网站或镜像站点，确保下载到正确版本的 ncurses，以便后续编译使用。 安装 g++ 编译器：确保系统中安装了 g++ 编译器，以便进行 C++ 代码的编译。 确保已安装交叉编译器：确保交叉编译器已正确安装，并在终端中设置好相应的环境变量，以便在编译过程中能够找到交叉编译工具。可以通过运行 arm-none-linux-gnueabi-gcc --version 来验证交叉编译器的安装情况。 编译 MySQL PC 版本MySQL 源码包： 步骤 a: 解压 MySQL 5.1.51 tar zxvf mysql-5.1.51.tar.gz -C /opt/ 步骤 b: 进入解压后的目录 cd /opt/mysql-5.1.51 编译 步骤 c: 配置编译目录 ./configure --prefix=/usr/local/mysql 安装 MySQL 数据库时，运行 ./configure 命令可能会遇到以下错误信息： error: No curses/termcap library found 这个错误提示的原因是缺少 ncurses 安装包，ncurses 是一个用于终端处理的库，MySQL 需要这个库来完成用户界面的显示和控制。 安装 ncurses 首先执行命令更新软件包列表： sudo apt-get update 接着检查是否已经安装 libncurses5-dev： sudo apt-cache search ncurses 安装 libncurses5-dev： sudo apt-get install libncurses5-dev 步骤 d: 编译 make 注意：此步骤不需要运行 make install，主要为了生成 gen_lex_hash 库。 安装 步骤 e: 重命名文件夹以备份 mv mysql-5.1.51 mysql-5.1.51-pc （同时确保 gen_lex_hash 库被单独备份。） 交叉编译 MySQL - ARM 版本由于 Boost 库已经包含在下载的 MySQL 包中，因此无需单独安装 Boost。在执行以下步骤之前，可以创建一个 mysqlbuild 文件夹，将下载的 MySQL、ncurses 和 openssl 包传入该文件夹，以便于管理。 安装 ncurses 步骤 a: 下载 ncurses wget ftp://ftp.gnu.org/gnu/ncurses/ncurses-5.9.tar.gz 步骤 b: 解压到 opt tar zxvf ncurses-5.9.tar.gz -C /opt/ 步骤 c: 进入 ncurses 目录 cd /opt/ncurses-5.9 步骤 d: 配置编译选项 ./configure --prefix=/home/farsight/ncurses CC=arm-none-linux-gnueabi-gcc --host=arm-none-linux-gnueabi --enable-static --enable-shared 步骤 e: 编译 make 步骤 f: 安装 ncurses sudo make install 注意：可能会出现权限错误，解决方案是以超级用户身份运行： sudo -i; make install 安装 OpenSSL可以通过 3rd-part 下的脚本进行 OpenSSL 的安装，执行以下命令前需要修改 open_src_conf.xml 文件，将 OpenSSL 的版本号替换为 openssl-1.1.1g： cd /path/to/openssl./auto_install_opensrc.sh openssl 编译 ARM 版本的 MySQL 步骤 a: 解压 MySQL 5.1.51 tar zxvf mysql-5.1.51.tar.gz -C /opt/cd /opt/mysql-5.1.51 步骤 b: 修改配置文件 使用文本编辑器打开 configure 文件，查找以下几行并进行修改：找到以下四个对应行（26453、48175、48282、48485），并注释掉不允许交叉编译的部分。如果代码块看起来像下面这样， if test $cross_compiling = yes; then # ...else 修改为： if test $cross_compiling = yes; then echo skip .....! # ...else 注意：共需替换四部分代码，确保全部修改。 步骤 c: 配置 ARM 版本的 MySQL，配置时，增加 ncurses 库的路径： ./configure --host=arm-linux --enable-static --with-named-curseslibs=/usr/local/ncurse/lib/libncurses.a --prefix=/usr/local/mysql --without-debug --without-docs --without-man --without-bench --with-charset=gb2312 --with-extracharsets=ascii,latin1,utf8 步骤 d: 修改 sql_parse.cc 文件以定义 STACK_DIRECTION 在 /opt/mysql-5.1.51/sql/sql_parse.cc 的某行之前添加： #define STACK_DIRECTION 1 该宏在 ARM 中设定以防编译错误。 步骤 e: 复制 PC 版本的 gen_lex_hash 文件到当前目录,用 PC 版本的 gen_lex_hash 文件覆盖 ARM 格式的文件，以确保编译成功。 cp /opt/mysql-5.1.51-pc/sql/gen_lex_hash sql/touch -m sql/gen_lex_hashcp /opt/mysql-5.1.51-pc/sql/lex_hash.h sql/touch -m sql/lex_hash.h 这样可以防止因缺少文件而导致的错误。 步骤 f: 编译 ARM 版本 make 步骤 g: 安装 ARM 版本 sudo make install 在构建目录中创建 mysql 目录并移动到该目录： cd mysql-8.0.22mkdir buildcd build 执行 CMake 配置编译选项： cmake ... -LH -DCMAKE_INSTALL_PREFIX=/home/mysqlbuild/mysql-8.0.22/install \\-DMYSQL_DATADIR=/home/mysqlbuild/mysql-8.0.22/install/data \\-DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci \\-DENABLED_LOCAL_INFILE=1 \\-DCMAKE_CXX_COMPILER=/opt/hisi-linux/x86-arm/aarch64-himix100-linux/bin/aarch64-himix100-linux-g++ \\-DCMAKE_C_COMPILER=/opt/hisi-linux/x86-arm/aarch64-himix100-linux/bin/aarch64-himix100-linux-gcc \\-DWITH_BOOST=/home/mysqlbuild/mysql-8.0.22/boost/boost_1_73_0 \\-DWITH_SSL=/home/mysqlbuild/install \\-DWITH_SASL=/home/mysqlbuild/install \\-DCMAKE_SYSTEM_PROCESSOR=arm \\-DCURSES_INCLUDE_PATH=/home/mysqlbuild/install/include \\-DCURSES_LIBRARY=/home/mysqlbuild/install/lib/libncurses.a \\-DCMAKE_BUILD_TYPE=RELEASE -DWITH_TEST_TRACE_PLUGIN=0 -DIGNORE_AIO_CHECK=1 -DBUILD_CONFIG=mysql_release \\-DWITH_UNIT_TESTS=0 -DWITH_LIBEVENT=bundled -DEVENT__DISABLE_TESTS=ON \\-DRESOLV_LIBRARY=/opt/hisi-linux/x86-arm/aarch64-himix100-linux/aarch64-linux-gnu/libc/usr/lib/libresolv.so 在这个过程中，可能会遇到多个错误，解决方法如下： 错误处理 错误：CMake Error at CMakeLists.txt:1374（需要安装 patchelf 工具） 解决方法：注释掉 CMakeLists.txt 中的检查部分。 错误：LIBEVENT version must be at least 2.1, found .l 解决方法：注释掉 libevent 检查的相关代码段，因为自带的 libevent 版本已经是 2.1.11。 错误：cannot execute binary file（多个二进制文件不能执行） 解决方法：将 x86-64 版可执行文件从先前的编译目录复制到编译目录中。例如： cp /home/mysqlbuild/mysql-8.0.22pc/mysql-8.0.22/runtime_output_directory/uca9dump /home/mysqlbuild/mysql-8.0.22/build/runtime_output_directory/ 其他相似的文件（如 json_schema_embedder、comp_sql、gen_lex_token 等）同理处理。 错误：homemysqlbuildmysql-8.0.22storageinnobaseincludeos0atomic.ic:194:2: error: #error “Unsupported platform” 解决方法：在 storage/innobase/include/os0atomic.h 中添加一个宏定义 HAVE_ATOMIC_BUILTINS。 错误：usrlib64libresolv.so: error adding symbols: File in wrong format 解决方法：在 CMake 配置中指定使用交叉编译工具链里的 libresolv.so： -DRESOLV_LIBRARY=/opt/hisi-linux/x86-arm/aarch64-himix100-linux/aarch64-linux-gnu/libc/usr/lib/libresolv.so 错误：‘os_compare_and_swap_thread_id’ was not declared in this scope 解决方法：将所有出现的 os_compare_and_swap_thread_id 改为 os_compare_and_swap_lint。 将相应文件移植到 ARM 平台 步骤 a: 拷贝编译好的 MySQL 至开发板 如果使用 NFS 调试，执行以下命令： cp -r /usr/local/mysql /opt/EmbedSky/root_nfs/usr/local/mysql 步骤 b: 将 ARM 的 MySQL 库打包备份 tar -zcvf mysql-arm-5.1.51.tar.gz mysql 步骤 c: 复制配置文件模版 cp /opt/mysql-5.1.51/support-files/mymedium.cnf /opt/EmbedSky/root_nfs/etc/my.cnf my.cnf 的位置根据手册建议修改。数据目录和安装目录的默认位置分别是 /var/lib/mysql 和 /usr/local/mysql。 MySQL 初始化 步骤 a: 进入 MySQL BIN 目录 cd /usr/local/mysql/bin 步骤 b: 运行初始化命令 ./mysql_install_db -u root 可能遇到的错误需处理，比如： Neither host EmbedSky nor localhost could be looked up with ... 这可以通过设置 hostname 或者使用 --force 选项来解决。 步骤 c: 创建必要的 PID 文件 mkdir /usr/local/mysql/var/run/mysqldtouch /usr/local/mysql/var/run/mysqld/mysqld.pid 步骤 d: 复制启动脚本 cp /opt/mysql-5.1.51/support-files/mysql.server /opt/EmbedSky/root_nfs/etc/init.d/mysqld 步骤 e: 修改启动文件并设定权限 chmod +x /opt/EmbedSky/root_nfs/etc/init.d/mysqld 启动 MySQL 服务由于开发板不支持 service 指令，需手动启动： ./etc/init.d/mysqld start 遇到的错误如“ERROR! Manager of pid-file quit without updating file”需查看日志获取更多信息： tail -f /var/lib/mysql/[hostname].err 在完成编译及调整后，执行 ./mysqld 查看程序是否可以正常启动。初次运行时可能会遇到缺少如 libprotobuf-lite.so.3.11.4 的错误，需将该库拷贝至 lib64 下，并创建软链接。之后，使用 ldd mysqld 确认依赖库没有问题。最终使用以下命令启动 MySQL： ./mysqld --basedir=/usr/local/mysql --datadir=/home/rundir/mysql/data --plugin-dir=/home/rundir/arm_build/install/lib/plugin --user=mysql --innodb-flush-method=O_DIRECT --skip-ssl --auto-generate-certs=FALSE --skip-sha256-password-auto-generate-rsa-keys --log-error=/home/rundir/mysql/data/mysqld_safe.log --pid-file=/home/rundir/mysql/data/mysql.pid --innodb_force_recovery=0 --admin-ssl=FALSE --caching-sha2-password-auto-generate-rsa-keys=FALSE 经过反复尝试，发现该命令能够正常启动 MySQL 实例，一切准备就绪后，可以进行数据库的具体操作。 测试 ARM 平台下的 MySQL 步骤 a: 设置 MySQL root 密码 mysqladmin -u root password hahaha 步骤 b: 进入 MySQL 环境 mysql -h 127.0.0.1 -u root -p 步骤 c: 创建数据库及表 show databases;create database at91;use at91;create table node (id int(5) auto_increment not null primary key, node_ID char(40), param_ID_values varchar(900));","categories":["4.软件","数据库"]},{"title":"更改自启动图片","path":"/2024/10/03/1-平台-嵌入式-应用软件移植-更改自启动图片/","content":"一、内核文件修改更换图片格式为 .ppm在内核文件的修改过程中，第一步是将更换的图片转换为 .ppm 格式，这是内核能够读取的格式之一。为了实现这一转换，可以利用 netpbm 工具包，这是一组命令行工具，专门用于图像的转换、处理和生成。 安装 netpbm 工具包如果的 Linux 开发主机尚未安装 netpbm，可以通过网络轻松安装。打开终端，输入以下命令： linux@ubuntu:~$ sudo apt-get install netpbm 执行完这个命令后，系统将自动下载并安装所需的工具包。如果的系统没有互联网连接，可能需要手动下载并安装这些工具，这通常会比较复杂。 转换图片格式安装完成后，便可以开始转换希望用作启动 logo 的图片。例如，如果想要转换的图片名为 logo.png，可以按照以下步骤进行操作。 步骤说明 文件准备：首先，将需要转换的 logo.png 文件拷贝到 Linux 主机的主目录下。可以使用以下命令： linux@ubuntu:~$ cp /path/to/your/logo.png ~/ 这里的 /path/to/your/ 是存放 logo.png 的路径。 执行转换命令：接下来，在终端中输入以下命令来生成所需的 .ppm 文件： linux@ubuntu:~$ pngtopnm logo.png | ppmquant 224 | pnmtoplainpnm logo_linux_clut224.ppm pngtopnm 是将 .png 文件转换为 .pnm 的命令。 ppmquant 224 对图像进行量化处理，将其色彩数量精简为 224 种，以减少文件大小且保持图像质量。 pnmtoplainpnm 将量化后的数据转化为纯净的 .ppm 格式。 logo_linux_clut224.ppm 将最终结果输出为名为 logo_linux_clut224.ppm 的文件。 生成的 logo_linux_clut224.ppm 文件会存储在当前目录下，可以通过执行以下命令确认文件已创建： linux@ubuntu:~$ ls 这一系列操作完成后，的启动 logo 图片就成功转换为内核所需的格式，并准备好用于后续步骤。 二、内核文件编译1. 拷贝内核源码首先，将内核源码文件复制到的家目录下。为了方便管理，建议创建一个专门的文件夹命名为 Linux_src。接下来，进入该文件夹并解压内核源码文件。使用以下命令： linux@ubuntu:~/Linux_src$ tar xvf kernel-imx-3.14.28.tar.xz 在这个步骤中，将看到一系列的文件和文件夹被解压出来。这些文件包含了内核的源代码以及后续编译所需的各种工具和配置文件。 2. 替换图片接下来，需要替换内核启动时显示的图像。将已经转换好的 logo_linux_clut224.ppm 文件拷贝到以下目录中： linux@ubuntu:~/Linux_src/kernel-imx-3.14.28/drivers/video/logo 这一步将原有的 logo_linux_clut224.ppm 文件替换成自己的文件，从而实现更换内核启动画面的目的。确保新文件的格式和尺寸与原文件相匹配，以避免可能的兼容性问题。 3. 进行内核编译在开始编译之前，需要在系统的 /var 目录下创建一个新的文件夹，命名为 tftpboot。这可以通过执行以下命令完成： linux@ubuntu:/var$ sudo mkdir tftpboot 创建好文件夹后，就可以开始内核的编译过程。进入内核源码目录，执行编译命令： linux@ubuntu:~/Linux_src/kernel-imx-3.14.28$ sudo ./build.sh 在此过程中，需要耐心等待编译完成。编译时间可能因为计算机的性能而有所不同，通常在几分钟到数小时之间。 如果在编译过程中遇到如下错误信息： /bin/sh : 1: lzop: not found 这说明的系统缺少 lzop 工具，导致编译无法进行。要解决这个问题，可以依次执行以下命令以更新软件包列表，并安装 lzop： linux@ubuntu:/var$ sudo rm /var/lib/apt/lists/* -vflinux@ubuntu:/var$ sudo apt-get updatelinux@ubuntu:/var$ sudo apt-get install lzop 这三条命令的作用分别是清理软件包列表，更新软件包信息，然后安装缺失的 lzop 工具。完成安装后，可以重新执行内核编译命令，成功编译内核后，一切准备就绪，就可以使用新内核来启动的系统了。 三、其他1. 更换开机自启图片 在更换开机自启图片时，务必注意以下步骤：首先，不要对源代码做任何修改，直接进行编译。这一步很重要，因为任何细微的改动都可能导致意外的编译错误。编译完成并确认无误后，将转换好的 ppm 格式的图片文件复制到指定目录。确保文件路径和名称准确无误，一旦图片被放置到正确的位置，再次进行编译，以保证更换生效。 2. png 格式图片转换问题 当使用 netpbm 工具将 png 格式的图片转换成 ppm 格式时，可能会遇到错误或图像失帧的现象。这通常与以下几个因素有关： 图片分辨率限制：输入的 png 图片分辨率必须不超过 LCD 显示器的分辨率。例如，如果的 LCD 分辨率是 800x600 像素，那么输入的 png 图像不能大于这个尺寸，可以允许尺寸更小，但绝对不能更大。 调色板限制：ppm 格式的图像调色板是从 0x20 开始编写的，因此最多能表示 224 种颜色。0-0x1f 的 32 种颜色是不可靠的，这意味着这些颜色的显示可能会出错或不一致，因此在设计图像时要避免使用这些颜色代码。 3. logo 显示不居中 为了解决 logo 显示不居中的问题，可以通过以下步骤调整代码： 打开文件 drivers/video/fbmem.c，找到函数 fb_show_logo_line。 替换以下两行代码： image.dx = 0; image.dy = y; 修改为： image.dx = (info-var.xres / 2) - (X / 2); image.dy = (info-var.yres / 2) - (Y / 2); 在这里，info-var.xres 和 info-var.yres 分别代表显示器的水平和垂直分辨率，而 X 和 Y 是 logo 图片的尺寸。通过计算，将 logo 定位到屏幕的中心。 然后，在文件 drivers/video/console/fbcon.c 中找到函数 fbcon_prepare_logo，在以下代码行后添加内容： logo_height = fb_prepare_logo(info, ops-rotate); 紧接着增加这一行： logo_height += (info-var.yres / 2) - (Y / 2); 这样可以确保 logo 的垂直位置调整得当。 4. 将开机图片更改为一张 更改开机图片为一张新图像时，请确保图像文件符合上述 ppm 格式的要求，包括分辨率和颜色限制。同时，还要确保在系统启动时能正确找到并加载新图片，以便替换原有的开机图像。 5. TF 卡制作问题 如果 TF 卡制作成功，但在 SD 模式启动时没有反应，建议使用 Class 4 低速 TF 卡。因为高速 TF 卡可能在某些情况下因为驱动能力不足而无法被识别。此外，确保该 TF 卡只有一个分区，并且格式化为 FAT32。这是因为某些启动程序对存储设备的分区和格式要求较为严格，错误的设置可能导致启动失败。","categories":["1.平台","嵌入式","应用软件移植"]},{"title":"构建weston桌面","path":"/2024/10/02/1-平台-嵌入式-应用软件移植-构建weston桌面/","content":"简介Wayland 是一个现代化的显示服务器协议，网站地址为 Wayland官网。它的设计理念是取代已有近三十年历史的 X 图形系统。相比于 X，Wayland 的架构在灵活性和性能上有显著提升。在 Wayland 中，Wayland compositor 与客户端之间直接进行通信，而传统的 X 系统则依靠一个中央的 X Server 来连接客户端、硬件和合成器。随着时间的推移，X Server 中许多功能已经逐渐转移至内核或独立库之中，使得其显得臃肿不堪。Wayland 通过去掉这一中间层，简化了架构，提升了系统的效率。 相关资源 Wayland 官网: http://wayland.freedesktop.org/ 构建指南: Wayland Building Guide 下载工具库在开始安装和构建之前，需准备好相关工具和库。以下命令将帮助用户安装必需的工具： sudo apt install python3-pip git ninja-build cmakepip3 install --user mesonsudo apt install libffi-dev libxml2-dev graphviz doxygen xsltproc xmlto 上述命令中： python3-pip 是 Python 的包管理工具，便于安装 Python 库。 git 用于版本控制和代码管理，下载项目代码。 ninja-build 和 cmake 是构建工具，用于管理软件构建流程。 meson 是一个高效、用户友好的构建系统，适合处理多种编程语言的项目。 安装 Ninja接下来，下载并安装 Ninja 构建系统： git clone https://github.com/ninja-build/ninja.gitcd ninja./configure.py --bootstrapcp ./ninja /usr/bin/ 这里的步骤包括从 GitHub 克隆 Ninja 的源代码，配置构建环境，并将构建好的 ninja 文件复制到系统可执行路径中。 设置环境变量在安装 Weston 前，需根据是否希望将其安装在系统路径中做出相应设置。 如果希望安装在用户特定路径export WLD=$HOME/installexport LD_LIBRARY_PATH=$WLD/libexport PKG_CONFIG_PATH=$WLD/lib/pkgconfig/:$WLD/share/pkgconfig/export PATH=$WLD/bin:$PATH 在这段代码中，WLD 变量指定了安装位置，LD_LIBRARY_PATH 负责链接动态库。PKG_CONFIG_PATH 用于找到库的配置文件，而 PATH 则确保命令行可以找到可执行文件。 如果希望将 Weston 安装在系统路径export WLD=/usr# 之后所有 meson 构建命令更改为以下命令meson build/ --prefix=$WLD --libdir=/usr/lib --sysconfdir=/etcninja -C build/sudo ninja -C build/ install 这里设置了 WLD 为系统路径，后续的构建命令将依据新的路径安装 Weston。 构建 Wayland接下来开始下载和构建 Wayland： git clone https://gitlab.freedesktop.org/wayland/wayland.gitcd waylandmeson build/ --prefix=$WLDninja -C build/ install 在这个步骤中，首先是下载 Wayland 的源代码，接着使用 Meson 配置构建目录，并安装构建结果。 构建 Wayland Protocols构建 Wayland 的协议库也是一个重要步骤： git clone https://gitlab.freedesktop.org/wayland/wayland-protocols.gitcd wayland-protocolsmeson build/ --prefix=$WLDninja -C build/ install 这个过程和构建 Wayland 几乎相同，确保协议文件能够正确工作。 构建 Weston接下来，下载并构建 Weston： git clone https://gitlab.freedesktop.org/wayland/weston.gitcd westonmeson build/ --prefix=$WLDninja -C build/ install 通过这些命令，Weston 将从源代码构建并准备安装。 运行 Weston完成安装后，可以通过以下命令启动 Weston： weston 运行后，将会进入 Weston 的桌面环境。 Weston 的一些测试程序在 Weston 的终端中，可以通过输入下列命令启动一些示例应用，测试其功能： weston-terminal: 一个简单的终端仿真器，尽管不完全兼容，但对使用 bash 的基本需求足够满足。 weston-flower: 在屏幕上绘制一朵花，是对框架协议的测试。 weston-gears: 类似于 GLX Gears，用于测试 Wayland 的图形性能。 weston-smoke: 测试共享内存 (SHM) 的缓冲区。 weston-image: 加载并显示通过命令行传递的图像文件。 weston-view: 对 PDF 文件执行类似操作。 weston-resizor: 演示平滑的窗口大小调整，可通过上下键调整。 weston-eventdemo: 将 libtoytoolkit 的事件报告到控制台，提供相关帮助可通过 weston-eventdemo --help 获取。 这些测试程序能够帮助用户深入理解 Wayland 的构建效果及其工作方式。 参数配置weston 参考文档 weston.ini weston-drm manpages.org for weston.ini weston 的使用 CSDN博客关于weston使用的文章 CSDN博客关于weston设置的文章 X Keyboard配置 RK3399 平台 weston 桌面 平台： RK3399 系统： Linux 4.4 + Buildroot 相关文件 /etc/init.d/S31weston - weston 自启动程序 /etc/xdg/weston/weston.ini - weston 配置文件 /etc/profile.d/env.sh - 环境变量配置 /etc/init.d/S31weston#!/bin/sh## Start linux launcher...#case $1 in start) printf Starting weston source /etc/profile.d/env.sh weston -c /etc/xdg/weston/weston.ini --tty=2 --idle-time=0 --log=/var/log/weston.log ;; stop) killall weston printf stop finished ;; *) echo Usage: $0 start|stop exit 1 ;;esacexit 0 /etc/xdg/weston/weston.ini[core]# Boards could have not any input device, and only use# removable input device like usb(keyboard, mouse).#require-input=false[shell]panel-position=none /etc/profile.d/env.sh#!/bin/sh export LC_ALL=zh_CN.utf8export QT_QPA_PLATFORM=wayland#export WESTON_DRM_MIRROR=1export WESTON_DRM_KEEP_RATIO=1export QT_GSTREAMER_WINDOW_VIDEOSINK=waylandsinkmkdir -p /tmp/.xdg chmod 0700 /tmp/.xdgexport XDG_RUNTIME_DIR=/tmp/.xdgexport PATH=$PATH:/usr/bin/cmdexport QT_QPA_GENERIC_PLUGINS=evdevkeyboard weston 配置文件解析weston 可以从命令行和配置文件（weston.ini）获取配置信息，确保应用程序以合适的方式启动和运行。weston.ini 的多种存放路径确保灵活性，包括： $XDG_CONFIG_HOME/weston.ini（当设置了 $XDG_CONFIG_HOME 时） $HOME/.config/weston.ini（当设置了 $HOME 时） $XDG_CONFIG_DIR/weston/weston.ini（当设置了 $XDG_CONFIG_DIRS 时） /etc/xdg/weston/weston.ini（当未设置 $XDG_CONFIG_DIRDS 时） weston.ini 文件的组成部分weston.ini 文件由多个部分构成，每个部分负责不同的功能，不同部分的顺序无关紧要。主要部分包括： **[core]**：选择启动合成器模块和常规选项。 **[libinput]**：用于配置输入设备。 **[shell]**：自定义桌面环境。 **[launcher]**：添加启动器到面板。 **[output]**：配置输出设置。 **[input-method]**：设置屏幕键盘输入法路径。 **[keyboard]**：设置键盘格式和参数。 **[terminal]**：配置终端应用程序（如 weston-terminal）。 **[xwayland]**：设置 XWayland 选项。 **[screen-share]**：屏幕共享选项。 旋转 weston 渲染的 qt 程序通过配置 output 字段并添加显示设备名称及旋转角度即可实现 QT 程序的旋转。例如： [output]name=DSI-1transform=90 运行 weston 的命令如下，启动日志将记录在 /var/log/weston.log 中： weston -c /etc/xdg/weston/weston.ini --tty=2 --idle-time=0 --log=/var/log/weston.log 使用以下命令可以查看显示设备名称，以确认成功配置： cat /var/log/weston.log | grep Output 示例输出： [06:35:51.270] Output repaint window is 15 ms maximum.[06:35:51.510] Output DSI-1, (connector 91, crtc 83) 相关内容查看当前 DRM 设备的命令： ls /sys/class/drm/ 示例输出： card0/ card0-DPI-1/ card0-HDMI-A-1/ card1/ controlD64/ renderD128/ renderD129/ version 在某些情况下，可能会出现多个输出设备配置： [output] name=HDMI-A-1 virtualIndex=0[output] name=DSI-1 virtualIndex=1","categories":["1.平台","嵌入式","应用软件移植"]},{"title":"内核移植","path":"/2024/10/01/1-平台-嵌入式-系统移植-内核移植/","content":"第一步：从 Linux 官网下载内核访问 Linux 官网 kernel.org，该网站是寻找并获取 Linux 内核源代码的主要渠道。主页上显示了多个内核版本的下载选项。为了确保版本与先前设备树教程一致，选择版本 4.14.2。点击下载链接后，下载将开始。下载完成后，将文件保存到 Ubuntu 系统内，这样后续步骤可以轻松访问。可以选择将其存放在个人工作目录或指定的项目文件夹，方便日后的组织和查找。 下载示例 打开终端。 输入以下命令，开始下载： wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.14.2.tar.xz 这将使用 wget 命令直接从服务器下载指定版本的 Linux 内核。 第二步：安装编译器编译器版本所需的编译器版本为 gcc-4.6.2-glibc-2.13-linaro-multilib-2011.12.tar.gz。这个版本的 GCC 是编译 ARM 架构内核和应用程序的重要工具。 Ubuntu 版本确认使用的 Ubuntu 版本为 Ubuntu 12.04。虽然这个版本比较老旧，但在某些项目中仍然能满足需求，尤其是那些依赖于特定库和工具链的情况。 将下载的编译器压缩包解压到 /usr/local/arm/ 目录下。解压后，会创建一个名为 gcc-4.6.2-glibc-2.13-linaro-multilib-2011.12 的目录，其中包含所需的编译器文件和相关工具。 解压示例 打开终端。 切换到目标目录以确保所需的文件位置： cd /usr/local/arm/ 解压文件： tar -zxvf gcc-4.6.2-glibc-2.13-linaro-multilib-2011.12.tar.gz 这一步将生成编译器的目录，该目录包含所有可执行文件以及支持库。 修改环境变量为确保系统能够找到新安装的编译器，需要配置环境变量。打开用户主目录下的 .bashrc 文件，并将以下行添加到文件末尾。这将确保新编译器的路径被系统正确识别。务必检查并注释掉其他可能冲突的编译器路径，避免在编译时出现不必要的问题。 # 其他编译器设置（如果存在，请屏蔽）export PATH=/usr/local/arm/gcc-4.6.2-glibc-2.13-linaro-multilib-2011.12/bin:$PATH 更新环境变量完成修改后，通过以下命令更新环境变量，使设定立即生效： source ~/.bashrc 为了确保所有设置生效，建议在此后的工作中重启 Ubuntu 系统。重启后，新的编译器将被系统识别。可以通过执行以下命令来验证编译器的安装： gcc --version 输出应显示所需的 GCC 版本，这表明内核下载和编译器安装的准备工作已完成。 第三步：配置内核 在 Ubuntu 上，进入解压后的 Linux 源代码目录，打开顶层的 Makefile 文件。 在 Makefile 中找到第 251 和 252 行，修改 ARCH 和 CROSS_COMPILE 变量，以匹配目标平台和交叉编译工具。例如，可能需要将 ARCH 设置为 arm，CROSS_COMPILE 设置为 arm-none-linux-gnueabi-。 生成配置文件 .config，可以直接使用官方提供的默认配置，执行以下命令： make exynos_defconfig 配置平台和调试串口。在内核源代码目录下输入命令 make menuconfig 以打开配置菜单。 选择芯片类型，导航至 System Type，然后选择 Samsung EXYNOS。 配置调试串口。返回 menuconfig 的主菜单，进入 Kernel hacking 选项，选择 Kernel low-level debugging functions (read help!)，紧接着选择 Kernel low-level debugging port (Use Samsung S3C UART 0 for low-level debug)，将调试串口配置为串口 2。 返回到主菜单，进入 Device Drivers，然后选择 Character devices，选中 Serial drivers，确保 Samsung SoC serial debug (NEW) 和 Support for console on Samsung SoC serial port 被选中。 再次返回到主菜单，并进入 Device Drivers，移除 DMA Engine support 的选项。 完成所有设置后，保存更改并退出。 第四步：编译内核在内核源代码目录下输入以下命令以进行编译，其中 LOADADDR=0x40007000 表示指定内核的加载地址： make uImage ARCH=arm CROSS_COMPILE=arm-none-linux-gnueabi- LOADADDR=0x40007000 -j4 编译过程中，系统会并行处理任务（通过 -j4 参数），加快编译速度。当出现提示 uImage is ready 时，表示内核编译成功。 第五步：修改 dts 文件 进入内核目录下的 arch/arm/boot/dts/，这里会有默认的设备树文件，例如 exynos4412-itop-scp-core.dtsi。 打开设备树文件并进行以下修改： 注释掉第 29 到 32 行的 firmware 节点代码，防止与后续配置冲突。 将第 71 行的 events 属性修改为 event，以符合设备要求。 根据 SCP 核心板的原理图，配置核心板电源芯片，这是确保硬件正常工作的关键步骤。 编译设备树，输入以下命令： make dtbs ARCH=arm CROSS_COMPILE=arm-none-linux-gnueabi 这一命令将我修改后的设备树文件编译成二进制设备树（DTB）文件。 第六步：烧写镜像最后，将编译生成的 uImage 和 dtb 文件复制到使用 Fastboot 工具的设备中。这可以通过 USB 连接，确保目标设备能正确识别和烧写这些映像文件，确保整个过程顺利完成。","categories":["1.平台","嵌入式","系统移植"]},{"title":"文件系统移植","path":"/2024/09/30/1-平台-嵌入式-系统移植-文件系统移植/","content":"根文件系统概述根文件系统是所有类 Unix 操作系统的重要组成部分，尤其在嵌入式 Linux 系统中更是与其他传统嵌入式操作系统的重要特征之一。根文件系统的设计为 Linux 提供了众多强大而灵活的功能，同时也增加了系统的复杂性。在进行定制时，需要细心选择必要的系统库、内核模块和应用程序，并配置初始化脚本文件，选择适合的文件系统类型以及将其放置在实际存储设备的合适位置。 文件系统的树型结构Linux 的根文件系统采用树型结构，为内核和系统管理提供了各种必需的文件和程序。根目录 / 下的顶层目录通常有固定的命名和用途。以下列出 Linux 根文件系统中常见的目录结构及其作用： /bin：存放二进制可执行命令的目录 包含所有用户可用的基本命令。在挂载其他文件系统之前，这些命令必须可用，因此 /bin 目录需与根文件系统在同一分区。常用命令包括：cat、chmod、ls 等。 /dev：存放设备文件的目录 设备文件是 Linux 中特有的文件类型，允许通过文件的形式访问各种设备。通过如 /dev/ttySAC0 文件，可以操作串口，而 /dev/mtdblock1 则用于访问 MTD 设备的特定分区。 /etc：存放系统管理和配置文件的目录 存储多种配置文件。在 PC 的 Linux 系统中，文件数量众多，但在嵌入式系统中通常会大幅精简，以适应资源受限的环境。 /home：用户主目录 每个普通用户在 /home 目录下都有一个以用户名命名的子目录，存放用户的相关配置文件，如用户 user 的主目录为 /home/user。 /lib：存放动态链接共享库的目录 存放共享库和可加载的驱动程序，维持基本的系统启动和其他程序的运行。 /sbin：存放管理员使用的管理程序的目录 存放特殊的系统命令，仅供管理员使用，如 shutdown、reboot。这些命令在挂接其他文件系统之前也需可用。 /tmp：公用的临时文件存储点 存放临时文件，程序生成的临时文件通常位于此，必须确保其存在且可访问。 /root：系统管理员的主目录 根用户的默认目录，相较之下，普通用户的主目录位于 /home 目录下。 /mnt：临时挂载其他文件系统的挂接点 用于临时挂载某些文件系统，通常为空目录，也可在其中创建子目录。 /proc：虚拟文件系统 作为 proc 文件系统的挂接点，不占用物理存储，目录和文件由内核动态生成，反映系统的运行状态。 /usr：存放应用程序与文件的庞大目录 此目录适合存放共享的、只读的程序和数据。内容可以在多个主机之间共享，符合 Filesystem Hierarchy Standard（FHS）。 /var：存放可变数据的目录 与 /usr 相反，这里存储诸如日志文件和邮件等动态生成的数据。 移植环境 发行版：Ubuntu 10.10 引导程序：u-boot.bin 目标平台：FS4412 交叉编译器：arm-none-linux-gnueabi-gcc 移植步骤1. 源码下载选择下载的版本为 busybox-1.17.3.tar.bz2，下载链接为 http://busybox.net/downloads/ 2. 解压源码$ tar xvf busybox-1.17.3.tar.bz2 3. 进入源码目录$ cd busybox-1.17.3 4. 配置源码通过 make menuconfig 进行相关的配置。 5. 编译使用以下命令进行编译： $ make 6. 安装安装程序将输出到 _install 目录。 7. 进入安装目录$ cd _install 8. 创建必要的目录$ mkdir dev etc mnt proc var tmp sys root 9. 添加库在 _install 目录下创建一个 lib 文件夹，拷贝工具链中的库到 lib 目录下。 $ mkdir lib$ cp /home/linux/x-tools/arm-cortex_a8-linux-gnueabi/arm-cortex_a8-linux-gnueabi/lib/* ./lib/ 设置配置选项以构建静态版本的 BusyBox： $ make menuconfig# 启用静态二进制构建 之后编译和安装： $ make$ make install 更深入地清理安装目录： $ cd _install$ rm *.o *.a$ arm-cortex_a8-linux-gnueabi-strip lib/* 10. 添加系统启动文件在 etc 目录下添加文件 inittab，内容如下： # thisis run first except when booting in single-user mode.::sysinit:/etc/init.d/rcS# /bin/sh invocations on selected ttys# Start an askfirst shell on the console (whatever that may be).::askfirst:-/bin/sh# Stuff to do when restarting the init process::restart:/sbin/init# Stuff to do before rebooting::ctrlaltdel:/sbin/reboot 在 etc 目录下添加文件 fstab，内容如下： # device mount-point type options dump fsck orderproc /proc proc defaults 0 0tmpfs /tmp tmpfs defaults 0 0sysfs /sys sysfs defaults 0 0tmpfs /dev tmpfs defaults 0 0 11. 设备文件创建在 /dev 下创建 console 节点，这是根文件系统中必须存在的设备节点。 如果新的文件系统尺寸超过 8M，则需要删除不需要的库文件以保持系统精简。 $ mknod dev/console c 51 1 此步骤确保设备文件正确创建，使得系统在启动时能够与硬件进行交互。","categories":["1.平台","嵌入式","系统移植"]},{"title":"文件系统裁剪论文学习","path":"/2024/09/27/1-平台-嵌入式-系统移植-文件系统裁剪论文学习/","content":"Linux根文件系统裁剪论文阅读笔记Linux裁剪方法研究 2006 2Linux裁剪原理： 2Linux嵌入式系统根文件系统的选择与制作 2006 3Linux嵌入式系统根文件系统的选择与制作 2006 3基于ARM的嵌入式Linux操作系统移植的研究 2006 5基于ARM的嵌入式文件系统研究与设计 2010 6基于嵌入式Linux的Ext2根文件系统制作分析 2015 6嵌入式Linux裁剪研究 2009 7嵌入式Linux根文件系统的构建与分析 2015 8嵌入式Linux共享库裁剪技术分析与改进 2009 8嵌入式Linux系统的裁剪优化和测试技术 2012 10嵌入式Linux系统的移植及其根文件系统的实现 2005 10面向应用的嵌入式Linux裁剪方法研究与实现 2009 11微型嵌入式实时操作系统文件系统 2015 12基于ARM的嵌入式Linux移植技术 2010 12基于ARM的嵌入式Linux移植与裁剪研究 2007 13基于ARM的嵌入式平台的研究与实现 2009 14基于ARM的嵌入式闪存驱动与UBIFS文件系统的分析与实现 2014 14精简型嵌入式文件系统设计 2010 15嵌入式Linux内核裁剪及移植的研究与实现 2009 18嵌入式存储设备上文件系统的设计与实现 2007 18嵌入式设备中基于NAND Flash的文件系统设计和优化 2013 18嵌入式文件系统的研究与设计 2007 19嵌入式Linux系统裁剪技术的分析与研究 2011 19嵌入式Linux系统定制和裁剪技术的研究与实现 2006 19嵌入式系统中NAND Flash文件系统的研究 2010 19 Linux 裁剪方法研究 2006Linux 系统的使用逐年增加，然而其庞大的体积和复杂性使得裁剪和优化变得具有挑战性。根据保留核心内核和系统必需文件的原则，现有的几种广泛应用的裁剪方法被详细介绍如下。 Linux 裁剪原理在裁剪 Linux 系统之前，有必要了解其启动过程、文件结构及软件安装方法。Linux 的启动过程可以分为几个主要步骤，包括： BIOS - 基本输入输出系统负责硬件自检及引导启动。 引导扇区 - 负责加载 Linux 内核。 内核 - 当内核启动后，它将初始化系统并挂载根文件系统。 根文件系统 - 包含了系统运行所需的文件和驱动程序。 根文件目录结构主要包括： /bin - 存放基本用户命令和工具。 /sbin - 存放系统管理只需的命令。 /usr - 存放软件包和用户工具。 /etc - 存放系统配置文件。 /dev - 设备文件目录。 /mnt - 挂载点。 /proc - 虚拟文件系统，提供内核和进程信息。 /lib - 系统库文件。 常见的几种裁剪方法包括： 定制安装法 - 在安装过程中选择性安装必要的组件。 rpm 裁剪法 - 利用 RPM 包管理器，选择需要的库和软件进行安装。 手工删除法 - 手动剔除不必要的文件和程序。 使用 BusyBox 可以极大地简化系统，但需调整原有的系统初始化过程。这是因为 BusyBox 中的命令和功能可能与传统 Linux 命令有所不同，这可能导致系统不能顺利初始化。此外，BusyBox 也可以进一步压缩整体系统体积，从而节省存储空间。 Linux 嵌入式系统根文件系统的选择与制作 2006Linux 的根文件系统是内核启动过程中最后一环，为嵌入式系统的重要组成部分。对根文件系统的类型、内容选择和制作方法进行系统性分析，确保系统能够高效运作。 Linux 嵌入式系统优势Linux 在嵌入式系统开发中提供了诸多优势： 工具链支持 - Linux 提供完整的开发工具链，便于自建开发环境和交叉编译环境，比方说工具如 GCC 和 Makefile 能够迅速建立交叉编译流程。 开放性内核 - 完全开放的内核允许设计真正的硬实时系统，软实时系统也可以通过优先级调度轻松实现。 网络支持 - 强大的网络协议栈支持，可以轻松实现嵌入式 TCPIP 通信。 对于特定目录的选择，考虑到嵌入式系统的需求，可以省略某些针对多用户的目录如 /home, /mnt, /opt, /root。此外，是否需要 /boot 目录取决于引导程序是否从根文件系统加载内核。 关于存放二进制文件的目录，存在如下区别： /bin - 包含用户及管理员必需命令。 /sbin - 主要供系统管理员使用，普通用户无需访问的命令。 /usr/bin - 存放非必需的用户命令。 /usr/sbin - 不属于管理员的必需命令。 库文件的选择也是至关重要的，可以选择 glibc 或 uClibc，后者体积更小但仍与前者兼容。必须包含的库文件有：libc.so, libpthread.so, libutil.so 等，以保证程序运行所需的基本功能。 根文件系统的选择原则 少 Flash，重 RAM：如果系统内存允许，选择 RAMdisk 通常是最佳方案。虽然 RAMdisk 提供了高压缩比，但必须注意 RAM 的消耗和价格。 CRAMFS 选项：如果系统有足够的 Flash 资源，同时还能保证 RAM 的可用性，则使用 CRAMFS 是不错的选择。虽然其压缩效率略逊于 RAMdisk，但对于通常不需持久储存的嵌入式应用来说，足以满足需求。 JFFS2 选择：如果需要频繁更新文件系统，JFFS2 以其优秀的垃圾回收和电源保护功能，尤其适合闪存设备。 基于 ARM 的嵌入式 Linux 操作系统移植的研究 2006ARM 架构的 Linux 系统支持多种 ARM 处理器系列，包括 ARM7 和 ARM9 等。这些处理器普遍配备内存管理单元（MMU），而对于不带 MMU 的 CPU，常用的替代方案是使用 uClinux。 基于 ARM 的嵌入式文件系统研究与设计 2010SD 卡及兼容 TF 卡以其小体积、简单接口、低成本和优秀性能在嵌入式存储设备市场中占据重要地位。FAT 格式因其良好的兼容性和安全性被广泛应用于嵌入式文件系统中。 基于嵌入式 Linux 的 Ext2 根文件系统制作分析 2015在 PowerPC 架构的 MPC8379E 处理器上，基于 Linux 2.6 内核制作 Ext2 根文件系统的过程不仅详尽清晰，还包括了实际的烧写测试结果。根文件系统包含百余个常用命令及基本库，压缩后的镜像仅为 2.3MB，满足了大部分系统需求。PowerPC 架构具有优越性能、低能耗及低热量排放的特点，适合多种嵌入式应用。 使用 BusyBox 构建根文件系统，原始文件大小达到 14.1MB，但经过 Ext2 压缩后有效减小至 2.3MB。 嵌入式 Linux 裁剪研究 2009尽管 Linux 操作系统最初设计为桌面环境，其通用性对于嵌入式系统构建并不完全适用。由于嵌入式系统对实时性、系统体积、功能、可移植性及可裁剪性等多方面的特殊需求，开发嵌入式 Linux 系统时需进行额外的优化和调整。 嵌入式 Linux 系统的实时性问题Linux 操作系统被设计为一种分时系统，能够同时处理多个进程。在这个系统中，有两种运行模式——用户态和内核态。当进程在用户态运行时，如果实时进程具有更高的优先级，则可以抢占正在运行的其他进程。然而，当操作系统运行在内核态时，实时进程无法优先于其他进程运行。此外，Linux 定时器的实现也暴露出一些缺陷： 定时器频率限制：Linux 的周期模式定时器的频率仅为 100Hz，这个频率对于许多要求严格的实时应用而言显得不足以满足需求。例如，在发动机控制系统或网络通信等应用中，理想的定时器频率应在几千赫兹以上。 软定时器的问题：软定时器的调度是依赖于全局时钟定时器的。当系统中的软定时器数量较多时，可能会导致因为竞争时钟资源而引发的冲突，进而影响系统的响应能力和实时性。 调度算法的影响：Linux 使用多级轮转调度算法，若一个进程未在其时间片内完成，优先级会降低。虽然实时进程存在较高的优先级，但系统并未为其设定严格的时间限制。大量的非实时进程也可能对实时进程的执行造成阻塞。 嵌入式 Linux 系统的 GUI 支持问题嵌入式 GUI 是为特定硬件和环境设计的图形用户界面系统。通常，这类系统具有轻量级、资源占用小、性能优越和可配置的特点。现有些较为成熟的嵌入式 GUI 解决方案包括： Microwindows：一个轻量级的窗口系统，适用于嵌入式环境。 MiniGUI：采用模块化架构，适合各种嵌入式平台。 OpenGUI：一个灵活且可扩展的 GUI 系统，适应于多种硬件配置。 嵌入式 Linux 系统的裁剪针对嵌入式 Linux 系统的裁剪策略主要有两种方式： 基于已安装系统的裁剪：在一个已经安装的 Linux 系统上，删除不需要的文件和组件来缩小系统的总体大小。这种方法在实践中往往难以奏效，因为随意删除文件可能会导致系统不稳定。 全新构建系统：从零开始，根据需求构建所需的功能和应用，逐步安装所需的软件包。这通常包含三个核心部分：Linux 内核、根文件系统和引导加载程序。 内核：提供操作系统的基本功能，包括内存管理、进程调度、文件系统及网络功能，同时还包括设备驱动程序。 根文件系统：涵盖维护系统运转所需的各种工具软件、库文件、脚本以及配置文件等，通常根文件系统位于特定的磁盘分区上。 引导加载程序：负责从引导设备加载内核并引导系统运行。常见的引导程序有 LILO 和 GRUB。 嵌入式 Linux 根文件系统的构建与分析（2015）Linux 系统移植包括三个主要环节：引导加载程序（bootloader）移植、内核移植和根文件系统移植。 嵌入式 Linux 共享库裁剪技术分析与改进（2009）在 Linux 系统中，主要的裁剪技术包含： 删除冗余文件：去除帮助文档、配置文件及不必要的辅助程序等。 共享库裁剪：针对嵌入式系统应用有限的特点，裁剪掉共享库中未使用的冗余代码。 替代软件包：通过选择更小存储占用的软件包替代原有较大功能重复的软件包，以实现有效管理资源。 源码修改：通过重新配置和编译去掉不必要的功能，精简内核。 应用程序与库之间可以选择静态链接或动态链接。静态链接时，链接器会将所需代码从库中复制到可执行文件中，这样磁盘和内存中会存在多个冗余拷贝。动态链接则允许多个应用程序共享内存中的库，从而节省存储空间。 在共享库和可执行文件中，包含多个符号表定义外部符号，分为导出符号（可被其他文件调用的函数）与导入符号（被调用但未定义的函数）。裁剪过程中的必要步骤是使用工具如 nm、readelf 或 objdump 导出二进制文件中的外部符号，并重复操作直到达到裁剪的极限。 不足之处包括：裁剪技术未能深入到目标文件级别；代码的编写未有统一标准，增加了裁剪难度；不同架构需采取不同的处理方式。 嵌入式 Linux 系统的裁剪优化和测试技术（2012）内核裁剪方法众多。其中，基于 Kbuild 体系的裁剪方法通过预定义变量和目标，使内核的编译和扩展变得更为方便，具备良好的可定制性。主要的选项包括： Y：将功能编译进内核； N：不将功能编译进内核； M：将功能编译为可在需要时动态插入的模块。 嵌入式 Linux 系统的移植及其根文件系统的实现（2005）在宿主机上制作一个 4MB 的随机磁盘根文件系统的流程如下： dd if=/dev/zero of=my_ramdisk bs=1k count=4096 mke2fs -vm0 my_ramdisk 4096 mount -o loop my_ramdisk /mnt/my_ramdisk_directorygzip my_ramdisk 面向应用的嵌入式 Linux 裁剪方法研究与实现（2009）函数调用关系图用于提取程序中各函数的调用关系，以展现整个程序的结构。该方法通过自上而下的代码分析，能够针对特定应用量身定制，达到较高的裁剪率。这在初期就已明确应用范围的嵌入式系统中尤为有效。 基于 ARM 的嵌入式 Linux 移植技术（2010）现如今，受广泛应用的嵌入式操作系统包括嵌入式 Linux、Windows CE、VxWorks、μCOS-II 和 Palm OS 等。它们各具特点： 嵌入式 Linux：开放源代码，技术支持强，内核稳定，经过裁剪后可以达到高效率。 Windows CE：功能模块化、结构化，适用于不同处理器，具有良好的图形用户界面。 VxWorks：具备强大的实时性和高可靠性，适合于工业控制等需求。 μCOS-II：以 ANSI C 编写，支持多种平台，结构小巧且可裁剪。 Palm OS：灵活性和移动性强，稳定性高，操作简单。 关于 Linux 内核裁剪的方法有三种： 使用自带的配置编译工具； 直接修改内核源代码； 基于系统调用关系对内核进行裁剪。 对于根文件系统的加载，嵌入式系统大多通过以下方法实现： 利用 Ramdisk 将根文件系统加载至 RAM。 通过 MTD 驱动实现 Flash 启动，传统文件系统如 YAFFS、JFFS2 等应用于此，MTD 设备驱动承担了读写和擦除的任务，并为用户层提供设备接口。 基于 ARM 的嵌入式平台的研究与实现 (2009)本论文中讲述了移植 Bootloader、内核及根文件系统的具体案例，这一研究与其他相关文献有其相似之处，但也引入了一些独到的见解与实践。 基于 ARM 的嵌入式闪存驱动与 UBIFS 文件系统的分析与实现 (2014)在这一年，针对传统通用文件系统的局限性进行了深入分析。大多数通用文件系统是为速度较慢的机械硬盘设计，这意味着它们在处理嵌入式系统时面临许多挑战。嵌入式系统通常在资源受限的环境中运行，使用缓存技术的高资源消耗与这些系统的设计目标产生了冲突。同时，通用文件系统的可靠性往往无法满足极端环境下的需求。此外，NAND Flash 的接口访问与传统硬盘存在显著差异，如果简单使用通用文件系统，将难以实现对 NAND Flash 必要的错误校验及坏块管理功能。 为了提高 NAND Flash 的使用寿命并缩短文件系统的挂载时间，UBIFS（Unsorted Block Image File System）应运而生。UBIFS 通过损耗平衡、垃圾收集和坏块管理机制，将嵌入式文件系统的性能提升至新的高度。与早期的 YAFFS 和 JFFS 系列相比，UBIFS 在启动速度和内存占用上表现得尤为出色，尤其适合于大容量 NAND Flash 的应用场合。值得注意的是，JFFS2 虽然提供了良好的读写速度，但其挂载速度的缺陷仍然是制约其广泛应用的一个重要因素。 Raw Flash 与其他 Flash 的区别UBI（Unsorted Block Image）系统仅能在 Raw Flash 上运行。它在 MTD（Memory Technology Device）分区之上提供卷分区、坏块管理和损耗均衡机制，而 UBIFS 则基于 UBI 卷，简化了与 MTD 层和 Flash 层的交互，提升了系统的高效性。UBIFS 还具备异地更新机制，这意味着文件的修改不会直接覆盖原有数据，从而有效减少数据丢失的风险。 从性能比较来看，UBIFS 比 YAFFS2 启动时间约快 5 秒，这在实际操作中能够显著提升用户体验。 精简型嵌入式文件系统设计 (2010)面对 Flash 存储介质的寿命问题，传统文件系统无法直接适用，必须添加 Flash 转换层（FTL），但 FTL 造成的性能瓶颈问题不容忽视。在文件修改或新建时，传统文件系统通常并不会立即写入相关的元数据（包含文件信息、权限、所有者及时间戳等），而是待空闲时再进行。这种设计在断电时会导致严重的不一致性问题，后果可能相当致命。因此，日志文件系统成为解决该问题的有效路径。 日志文件系统使用独立的日志文件跟踪磁盘内容的变化。在每次写入之前，系统会首先将改动记录到日志的尾部，确保在断电发生时，只需查看日志尾部即可快速恢复整个系统，极大缩短了恢复时间。该类文件系统主要分为两种： Log-Structured 日志文件系统：将整个磁盘视为一个大日志，所有写操作都发生在日志的尾部。每次写入后，数据记录在新地址，从而形成一系列过时的数据块。通过定期清理，这些过时块会被回收，保持日志的整洁性。 MetaData 日志文件系统：仅关注元数据的变化，通常在磁盘上划分专门区域或创建特殊文件来保存日志。此类文件系统使得元数据变更的追踪更为高效。 NTFS 文件系统的重要特性 通用索引功能：支持根据任何属性建立文件索引。 大磁盘和大文件支持：更有效处理非常大的磁盘和文件。 多数据流：文件的实际内容以字节流方式处理。 可恢复性：在发生故障时，NTFS 能够重建文件卷并恢复至一致状态，同时对重要数据进行冗余存储。 安全性：利用 Windows 对象模型实施强大的安全机制。 REFS 的特性REFS（Resilient File System）旨在针对 NAND Flash 存储介质优化嵌入式文件系统，其主要特性包括： 损耗平衡。 符合 NAND Flash 的页读写与块擦除特点。 坏块管理能力。 恢复文件与系统自我修复能力以提高可靠性。 良好的时间性能。 可移植和可扩展性。 嵌入式设备中基于 NAND Flash 的文件系统设计和优化 (2013)Flash 存储器的优势主要体现在以下几个方面： 一致的读性能：由于没有寻道和旋转操作，随机读性能与顺序读性能接近。 读写延迟降低：与机械磁盘相比，Flash 的读写延迟显著降低。 高可靠性：平均无故障时间（MTBF）比传统磁盘长一个数量级。 低能耗：单位时间内的能量消耗远低于 RAM 和磁盘存储器。 嵌入式 Linux 系统裁剪技术的分析与研究 (2011)从软件层面分析，嵌入式 Linux 通常由 Linux 内核、文件系统及应用程序组成。因此，现有 Linux 裁剪工作主要集中在以下三个方面： 内核裁剪：已在前文讨论中提及。 库裁剪：通过使用 uClibc 构建嵌入式 Linux 系统，可以显著减少占用空间，相比 glibc 更为高效。 应用程序裁剪：通常使用 BusyBox 替代传统 shell 程序，从而显著减小系统体积。","categories":["1.平台","嵌入式","系统移植"]},{"title":"根文件系统的制作","path":"/2024/09/26/1-平台-嵌入式-系统移植-根文件系统的制作/","content":"ARM Linux 根文件系统（Root Filesystem）的制作关于根文件系统的制作，网络上有许多相关的资源。然而，许多文章往往只提到创建几个基本目录，然后使用 Busybox 搭建一个简单的 Shell ，而忽视了许多关键细节。经过长时间的尝试和实践，成功实现了从零开始创建根文件系统。尽管对原理尚不完全理解，但以下是具体的制作过程，其中可能存在一些不足之处，欢迎指正。 根文件系统的组成部分根文件系统主要由以下几个部分组成：目录结构、Shell、库文件和脚本。逐一介绍如下。 目录根文件系统必须包含以下基本目录： /dev /bin /usr /sbin /lib /etc /proc /sys dev 目录是设备文件系统（devfs）或 udev 挂载点。在使用 devfs 内核的系统中，如果没有 /dev 目录，Shell 启动时将无法输出任何信息，因为内核无法找到 /dev/console。在使用 udev 的系统中，也需要手动在 /dev 下生成 console 和 null 这两个节点。关于 devfs 和 udev 的区别，可以查阅相关资料。如果内核不再支持 devfs（2.6.12 之后），可以手动使用 mknod 命令创建静态节点。 bin、usrbin、usrsbin 和 sbin 目录在编译 Busybox 时自动生成，用于存放二进制可执行文件。无需多加说明。 lib 目录用于存放动态链接库。虽然很多文章建议静态编译 Busybox 以简化构建流程，但这并不足以满足所有需求。即使静态编译能够使 Busybox 启动，自己编写或编译的软件包仍需依赖动态库。除非所有组件均静态编译，否则动态库的存在是不可避免的。 etc 目录用于存放初始化脚本及其他配置文件，具体内容将在后续部分详细说明。 proc 目录用于挂载虚拟文件系统——“proc 文件系统”。“proc 文件系统”可以在内核配置中启用。如果未启用，许多 Shell 命令将无法正常运行，例如 ifconfig。需要注意的是，“proc 文件系统”不会自动挂载，必须通过初始化脚本进行挂载。同时，udev 也依赖于“proc 文件系统”。 sys 目录用于挂载“sysfs 文件系统”，同样需要在内核中启用。这一文件系统通常为 udev 提供支持，必须使用初始化脚本进行挂载。 此外，还有其他非嵌入式系统必需的目录，例如 /tmp、/mnt、/swap、/var，将在后续讨论中提及。 ShellShell 的选择非常简单，使用 Busybox。可以通过以下链接下载 Busybox：Busybox 下载。有人提到 Busybox 与 arm-linux-gcc 存在兼容性问题，但通常这是由于早期版本造成的。根据实际使用经验，Busybox 1.8.2 与 arm-linux-gcc 3.4.13.3.2 可以良好兼容。 解压完成后，需找到 Makefile 文件，配置 ARCH 和 CROSS_COMPILE 变量： ARCH ?= armCROSS_COMPILE ?= /usr/local/arm/3.4.1/bin/arm-linux- CROSS_COMPILE 应根据自己的编译器路径进行设置。接下来的步骤如下： # make menuconfig# make# make install 在配置过程中，确保去掉一些针对 uCLinux 的选项，以免引起错误。另外，可以修改安装路径，默认在 Busybox 的 _install 目录中。 接下来，可以基于 Busybox 生成的 Shell 开始建立根文件系统。接下来的命令如下，假设 Busybox 存放在 /home/lxz/busybox，而根文件系统在 /home/lxz/rootfs： # mkdir /home/lxz/rootfs# cd /home/lxz/busybox/_install# cp -r ./ /home/lxz/rootfs # cd /home/lxz/rootfs# mkdir dev# mkdir etc# mkdir lib# mkdir proc# mkdir sys# mkdir tmp 如果不使用 devfs，需执行以下命令，并确保以 root 用户身份执行： # cd /home/lxz/rootfs/dev# mknod -m 660 console c 5 1# mknod -m 660 null c 1 3 如不创建这两个静态节点，console 的提示信息将无法显示，内核可能会提示“Warning: Unable to find an initial console”等信息。如果使用 udev，则需将 udevd、udevstart、udevadmin 三个文件放到 /sbin 目录下，以确保系统正常运行。 库库的处理可能是最复杂的部分。初学者可以复制已购买开发板上现有的文件系统中的库文件。如果开发板的文件系统为映像格式，只需将其挂载到某个目录即可方便访问。例如，假设映像为 rootfs.cramfs，则执行以下命令： # mkdir /home/lxz/evb_rootfs# mount -o loop rootfs.cramfs /home/lxz/evb_rootfs 然后，切换至普通用户后，复制库文件： # cd /home/lxz/evb_rootfs/lib# cp -r ./ /home/lxz/rootfs/lib 虽然开发板通常会带有必要的库，但文件总体积可能较大。可以删除一些不需要的库以减小体积，然而，初学者通常对此不太了解。为了自己编译更精简的库，可以使用 glibc 或 uclibc，这些步骤相对复杂。推荐的替代方案是使用 cross-tool，可在 cross-tool 下载地址 获取。 在成功制作交叉编译器后，可从 cross-tool 目录中提取 glibc。例如，如果 cross-tool 路径为 /home/lxz/cross-tool，编译器为 arm-linux-gnu-gcc（版本 3.4.5，glibc 版本 2.3.6），可按以下方式复制所需的库： # cd /home/lxz/cross-tool/build/arm-linux-gnu-gcc/gcc-3.4.5-glibc-2.3.6/build-glibc # ../glibc-2.3.6/configure --prefix=/home/lxz/glibc # make install 完成后，执行： # cd /home/lxz/glibc # cp -r lib /home/lxz/rootfs 至此，大部分库文件已成功复制，但仍需补充其它库文件。继续执行以下命令： # cd /home/lxz/cross-tool/build/arm-linux-gnu-gcc/gcc-3.4.5-glibc-2.3.6/build-gcc/gcc # cp libgcc_s.so* /home/lxz/rootfs/lib 接下来，处理缺失的 libtermcap 库，源代码包可从如下链接获取：Libtermcap 下载地址。假设其已下载至 /home/lxz/libtermcap，执行以下操作： # cd /home/lxz/libtermcap # rpm2cpio libtermcap-2.0.8-35.src.rpm | cpio -ivd# tar xvjf termcap-2.0.8.tar.bz2 接下来，需要逐个按顺序应用 13 个补丁： # patch -p0 -i termcap-2.0.8-shared.patch# patch -p0 -i termcap-2.0.8-setuid.patch# patch -p0 -i termcap-2.0.8-instnoroot.patch# patch -p0 -i termcap-2.0.8-compat21.patch# patch -p0 -i termcap-2.0.8-xref.patch# patch -p0 -i termcap-2.0.8-fix-tc.patch# patch -p0 -i termcap-2.0.8-ignore-p.patch# patch -p0 -i termcap-buffer.patch# patch -p0 -i termcap-2.0.8-bufsize.patch# patch -p0 -i termcap-2.0.8-colon.patch# patch -p0 -i libtermcap-aaargh.patch# patch -p0 -i termcap-2.0.8-glibc22.patch# patch -p0 -i libtermcap-2.0.8-ia64.patch 接着，修改 /home/lxz/libtermcap/termcap-2.0.8 内的 Makefile，更新 CC 和 AR 的位置： CC = /usr/local/arm/3.4.1/bin/arm-linux-gcc AR = /usr/local/arm/3.4.1/bin/arm-linux-ar 替换为合适的编译器路径。若觉得繁琐，可从其他资料网站下载已经适配的包（可在相关资源站点查找）。 完成库文件构建后，执行以下命令以剥离调试信息，减小库的体积（虽然保留并无影响）： # cd /home/lxz/rootfs/lib # arm-linux-strip *.so* 至此，库文件已完成制作。 脚本在拥有以上基本结构后，Shell 仍可能无法正常工作，通常会表现为内核提示“Free init memory: XXK”后没有任何输出。这常常是因为初始化脚本未能成功启动 Shell。接下来需配置这些脚本。 首先是 /etc/inittab。这是启动内核、挂载根文件系统后必需的文件，包含了启动 Shell 和进行系统初始化所需的命令。如果希望在启动时出现 Shell，只需添加一行如下配置： ::askfirst:/bin/ash 在此行代码之前，内核已启动，其它初始化过程中可以进一步配置。以下是一个示例的 inittab 内容，用于说明其功能： # Startup the systemnull::sysinit:/bin/mount -o remount,rw /null::sysinit:/bin/mount -t proc proc /procnull::sysinit:/bin/mount -anull::sysinit:/bin/hostname -F /etc/hostname # Now run any rc scripts::sysinit:/etc/init.d/rcS # Now invoke shell::askfirst:/bin/ash # Logging systemnull::sysinit:/bin/touch /var/log/messagesnull::respawn:/sbin/syslogd -n -m 0null::respawn:/sbin/klogd -n # Handling 3-finger salute (Ctrl+Alt+Del)::ctrlaltdel:/sbin/reboot # System shutdown tasksnull::shutdown:/usr/bin/killall klogdnull::shutdown:/usr/bin/killall syslogdnull::shutdown:/bin/umount -a -rnull::shutdown:/sbin/swapoff -a 将以上内容储存为 inittab 后启动系统，此时应出现两个提示。缺少 /etc/fstab 和 /etc/init.d/rcS 文件。根据理解，/etc/fstab 文件是用于执行 mount -a 命令的，其内容是文件系统的挂载表。以下是一个示例的 fstab 内容： # file system mount pt type options dump pass/dev/root / ext2 rw,noauto 0 1proc /proc proc defaults 通过这些步骤，基本的 ARM Linux 根文件系统已搭建完成，尽管还有更多优化和调整的空间，但已具备了基本的功能和结构。","categories":["1.平台","嵌入式","系统移植"]},{"title":"移植步骤","path":"/2024/09/25/1-平台-嵌入式-系统移植-移植步骤/","content":"嵌入式 Linux 系统移植的四大步骤在学习嵌入式 Linux 系统移植时，了解每个步骤的目的和过程至关重要。在这个过程中发现了一些常见问题，并努力找到解决方案。但对于开发结果，常常会感到不解。经过思考，意识到对开发环境的透彻理解是非常必要的。有时一个简单的命令可以实现复杂的功能，但如果没有深入思考这些命令的工作原理，们可能只是机械地完成任务，而无法真正掌握系统移植的精髓。 在进行每一步时，应该先问自己：为什么要这样做？正在做什么？一旦澄清了这些问题，无论之后面临何种平台、芯片或开发环境，都能够迅速上手。的学习方法是：从宏观上把握（解决”为什么”的问题），再微观上研究（解决”正在做什么”的问题）。以学习的 ARM Cortex-A8 开发板为例，下面将详细介绍嵌入式 Linux 系统移植的四大部分。 搭建交叉开发环境搭建交叉开发环境是移植的第一步。为了理解这一部分，们需要首先思考两个问题：什么是交叉开发环境？为什么需要它？ 什么是交叉开发环境？在嵌入式开发中，交叉开发是一个核心概念。交叉开发环境指的是在开发主机（通常是个人电脑）上编写的程序能够在目标机（通常是开发板）上运行。嵌入式系统往往因为其硬件限制，无法在自己身上直接进行开发。例如，大多数开发板在初始状态下无法运行任何程序，因此们需要在 PC 上进行编译、构建，并且将烧录到开发板中。 为什么需要交叉开发环境？ 硬件限制：嵌入式设备的处理速度和内存有限。比如，使用几百 MHz 主频的微控制器去编译 Linux 内核，结果会让人坐等得不耐烦。相比之下，个人电脑通常拥有更快的处理器和更丰富的内存资源，这让在这样的上进行开发变得更为高效。 体系结构和指令集差异：各个嵌入式系统的 MCU（微控制单元）往往有不同的体系结构和指令集。因此，们必须使用交叉编译器来生成可在目标平台（如 ARM、MIPS、PowerPC 等）上正常运行的程序。 硬件组成交叉开发环境主要由以下组成部分： 开发主机：通常是们常用的个人电脑。 目标机（开发板）：们要移植系统的设备。 连接介质：常用的连接方式包括： 串口线 USB 线 网络线 针对以上硬件部分，们还必须具备相应的软件支持： 串口调试助手：通常会用到 Putty 等工具来进行串口通信。 USB 驱动：例如三星芯片的 USB 下载可以用 DNW 软件完成。 网络协议支持： TFTP 服务：用于实现文件下载，可将需要测试的 bootloader、kernel 和文件系统直接下载到内存运行，而不需要提前烧录到 Flash 中。这种方式对于频繁的测试非常有用，因为 Flash 的擦写次数有限。 NFS 服务：用于实现网络文件系统的挂载，方便在开发板和开发主机之间共享文件，尤其是在制作文件系统测试时，可以直接挂载，而不必烧录到 Flash 中。 还有一个名为Samba的服务也值得关注，它实现的是 Windows 主机和 Linux 虚拟机之间的文件共享，便于进行不同平台之间的文件传输。 通过上述工具，嵌入式开发的效率得到了极大的提升。所有的工作过程都是围绕着测试进行的。测试完成后，们才会将相应的目标文件烧录到 Flash 中。 使用交叉编译器的必要性在搭建完交叉开发环境后，关键的一步是选择交叉编译器。交叉编译器是一个能够在一个平台（如 X86 架构的 PC）上生成适合另一种平台（如 ARM 架构的开发板）上运行的程序。通常所称的本地编译在当前平台上进行，因此编译得到的程序自然也只能在本地执行。为了确保在目标机上运行的程序可以正确生成，们必须使用交叉编译工具链。 交叉编译工具不仅仅是编译器，它包括编译器、链接器和调试器等组成部分，形成一个完整的开发环境。它的核心逻辑类似于构建嵌入式 Linux 内核，关注于们所需的组件，去掉不需要的部分。 构建交叉编译工具链的方法构建交叉工具链有三种主要方法： 分步编译和安装：这是最传统和困难的方法，适合希望深入学习交叉工具链构建的读者。 使用 Crosstool-ng 脚本工具：这是较为简便且易于实现的方法，更适合大多数开发者。 下载现成的交叉编译工具链：虽然这种方法简单省事，但往往因固定性和不灵活，可能引发各种意外错误。 Crosstool-ng 是一个流行的脚本工具，可以帮助们创建适合不同平台的交叉编译工具链。在使用之前，需要确保环境中安装了一些依赖软件，例如： $ sudo apt-get install g++ libncurses5-dev bison flex texinfo automake libtool patch gcj cvs cvsd gawk 下载 Crosstool-ng 脚本工具后，解压并进行配置，主要流程包括： 设定源码包路径和交叉编译器的安装路径。 修改交叉编译器针对的架构。 增加并行编译的进程数，以提高编译效率。 关闭 JAVA 编译器，减少编译时间。 开始编译。 添加环境变量并刷新。 测试交叉工具链的有效性。 到这里，嵌入式 Linux 系统移植的第一部分工作便已经完成，接下来可以进行电源选择、bootloader、内核等其他步骤的开发。 Bootloader 的选择和移植Boot Loader 概念Bootloader 是在操作系统内核运行之前的一段小程序。它的主要作用是初始化硬件设备、建立内存空间的映射关系，从而将系统的软硬件环境调整到一个合适的状态，以便为最终调动操作系统内核准备好正确的执行环境。因此，Bootloader 被称为引导加载程序（Boot Loader）。 为什么系统移植之前要先移植 Boot Loader？Bootloader 的任务是引导操作系统，具体来说，就是将内核加载到内存（RAM）中运行。那么首先要明确两个问题：谁负责把内核搬到内存中？内存是 SDRAM，和 SRAM 有哪些不同？SRAM 一上电就能够正常工作，但 SDRAM 则需要通过软件初始化。由此， Bootloader 首先要初始化 SDRAM，然后才能将内核加载到内存中。因此，可以得出结论：没有 Bootloader，们的系统无法启动。 Bootloader 的分类首先纠正一个常见误解：Bootloader 并不等同于 U-Boot，U-Boot 只是 Bootloader 的一种。Bootloader 拥有多种不同的实现和类型，不同类型的 Bootloader 各有其特定的使用范围。其中最受关注的就是 U-Boot，这是一款通用的引导程序，支持多种处理器架构，包括 X86、ARM 和 PowerPC 等。U-Boot，全称 Universal Boot Loader，遵循 GPL 条款，是由德国 DENX 团队开发的开源项目。它为多种嵌入式 CPU 提供支持，并对 Linux 的发展做出了重大贡献。 U-Boot 具有以下特点： 开放源码：开发者可以自由使用和修改源代码。 多操作系统支持：支持多种嵌入式操作系统内核，如 Linux、NetBSD、VxWorks、QNX、RTEMS、ARTOS 和 LynxOS。 多处理器架构兼容性：本身设计成可以支持 PowerPC、ARM、x86、MIPS 和 XScale 等多种处理器系列。 高可靠性和稳定性：在各类设备中的应用表现稳定。 灵活性：具有高度可配置的功能设置，适合调试、不同操作系统的引导需求，以及产品发布。 丰富的设备驱动：包括串口、以太网、SDRAM、FLASH、LCD、NVRAM、EEPROM、RTC、键盘等多个外设驱动。 详尽的开发文档，以及强大的网络技术支持。 从某种程度上说，可以把 U-Boot 理解为一个轻量级的操作系统。 U-Boot 的目录结构U-Boot 的文件结构如下： board：存放目标板相关文件，主要包含 SDRAM 和 FLASH 驱动。 common：包含独立于处理器的通用代码，例如内存大小探测与故障检测。 cpu：与处理器相关的文件，例如某处理器的串口、网络、LCD 驱动及中断初始化等。 driver：通用设备驱动，比如 CFI FLASH 驱动，目前对 Intel FLASH 支持相对较好。 doc：U-Boot 的说明文档。 examples：可在 U-Boot 下运行的示例程序，如 hello_world.c 和 timer.c。 include：U-Boot 的头文件，尤其是 configs 子目录中与目标板相关的配置头文件，这些文件在移植过程中经常需要修改。 lib_xxx：与处理器体系结构相关的文件库，例如 lib_ppc 和 lib_arm，分别包含 PowerPC 和 ARM 相关的代码。 net：与网络功能相关的文件目录，包括 bootp、nfs 和 tftp 等。 post：上电自检相关文件目录，尚在完善中。 rtc：RTC 驱动程序。 tools：用于创建 U-Boot S-RECORD 和 BIN 镜像文件的工具。 U-Boot 的工作模式U-Boot 的工作模式主要分为启动加载模式和下载模式。在启动加载模式下，Bootloader 是默认的工作模式，通常在嵌入式产品发布时使用。在这一模式下，Bootloader 将嵌入式操作系统自动从 FLASH 加载到 SDRAM 中运行。 而下载模式则是通过某些通信手段将内核映像、根文件系统映像等从 PC 机下载到目标板的 SDRAM 中。在这一模式下，用户可利用 Bootloader 提供的命令接口完成所需操作，主要用于开发和测试。 U-Boot 的启动过程大多数 Bootloader 都被划分为阶段 1（stage1）和阶段 2（stage2），U-Boot 也不例外。通常，依赖于 CPU 体系结构的基础代码（如设备初始化代码）放在阶段 1，并用汇编语言编写，而阶段 2 则用 C 语言实现，以便实现更复杂的功能和更好的可读性与移植性。 Stage1（start.s 代码结构）U-Boot 的 stage1 代码通常用汇编语言存放在 start.s 文件中，主要包括以下部分： 入口定义：一个可执行的映像必须有一个入口点，通常放置在 ROM（Flash）的 0x0 地址。 设置异常向量。 设置 CPU 的速度、时钟频率和中断控制寄存器。 初始化内存控制器。 将 ROM 中的程序复制到 RAM 中。 初始化堆栈。 跳转到 RAM 中执行，通常通过指令 ldrpc 实现。 Stage2（C 语言代码部分）在文件 lib_arm/board.c 中，start_armboot 是 C 语言实现的函数，也是整个启动代码中的主函数。它主要完成以下操作： 调用一系列的初始化函数。 初始化 FLASH 设备。 初始化系统内存分配函数。 如果目标系统包含 NAND 设备，则初始化相应设备。 如果有显示设备，则进行初始化。 初始化相关的网络设备，填写 IP 地址等信息。 进入命令循环，接受用户通过串口输入的命令，进行相应的操作。 基于 Cortex-A8 的 S5PC100 Bootloader 启动过程分析S5PC100 支持两种启动方式：USB 启动方式和 NAND Flash 启动方式。 S5PC100 USB 启动过程 执行 A8 reset，运行 iROM 中的程序。 iROM 程序根据 S5PC100 的配置管脚（SW1 开关 4，拨到 4 对面），判断启动来源（USB）。 iROM 程序初始化 USB，等待 PC 机下载程序。 利用 DNW 工具，从 PC 下载 SDRAM 的初始化程序到 iRAM 中运行，初始化 SDRAM。 SDRAM 初始化完毕后，iROM 程序接管 A8，并等待 PC 下载 Bootloader。 PC 利用 DNW 下载 Bootloader 到 SDRAM 中。 在 SDRAM 中运行 Bootloader。 S5PC100 NAND Flash 启动过程 执行 A8 reset，运行 IROM 中的程序。 iROM 程序根据 S5PC100 的配置管脚判断启动来源（NAND Flash）。 iROM 程序驱动 NAND Flash。 iROM 程序拷贝 NAND Flash 的前 16KB 到 iRAM 中。 前 16KB 程序（Bootloader 的前半部分）初始化 SDRAM，然后拷贝完整的 Bootloader 到 SDRAM 并运行。 Bootloader 拷贝内核到 SDRAM 中，并运行动态加载的内核。 内核运行后，挂载 rootfs，并运行系统初始化脚本。 U-Boot 移植（基于 Cortex-A8 的 S5PC100 为例） 下载稳定版本的源码包，如 2010.03 版本。 解压后，添加自己平台的信息，参考 SMDKC100 进行 S5PC100 开发板的移植。 修改相应目录的文件名及 Makefile，指定交叉工具链。 编译。 针对平台进行相应移植，主要包括修改 SDRAM 的运行地址（通常从 0x20000000 开始）。 开关相应的宏定义。 添加 NAND 和网卡的驱动代码。 优化 go 命令。 重新编译，执行 make distclean（彻底删除中间文件和配置文件），然后执行 make s5pc100_config（配置开发板）和 make（生成 u-boot.bin 镜像文件）。 设置环境变量，即启动参数，并将编译好的 u-boot 下载到内存中，具体步骤如下： 配置开发板网络 IP 地址配置: setenv ipaddr 192.168.0.6 保存环境变量到 NAND Flash 的参数区： saveenv 网络测试： ping 192.168.0.157 # 虚拟机的 IP 地址 如果网络测试失败，请检查以下几点： 网络线是否连接良好。 开发板和虚拟机的 IP 地址是否在同一网络段。 虚拟机网络设置必须选择桥接（VM → Setting → option）。 连接开发板时，虚拟机需要设置为静态 IP 地址。 在开发板上配置 TFTP 服务器（虚拟机）的 IP 地址： setenv serverip 192.168.0.157 # 虚拟机的 IP 地址saveenv 拷贝 u-boot.bin 到 /tftpboot（虚拟机上的目录）。 通过 TFTP 下载 u-boot.bin 到开发板内存： tftp 20008000 u-boot.bin # 下载到指定内存地址 如果上述命令无法正常下载，请检查： serverip 的配置是否正确。 TFTP 服务是否启动，必要时重启 TFTP 服务： sudo service tftpd-hpa restart 烧写 u-boot.bin 到 NAND Flash 的 0 地址： nand erase 0 40000 # 擦除 NAND Flash 0 - 256k 的区域nand write 20008000 0 40000 # 烧写大小 切换开发板的启动方式到 NAND Flash： 关闭开发板。 将 SW1 开关 4 拨到 4 的那边。 启动开发板，它将从 NAND Flash 启动。 Kernel 的配置、编译和移植Linux 源码首先，将下载下来的 linux-2.6.35.tar.bz2 文件移动或拷贝到主目录中。在 Linux 环境中，可以使用以下命令完成这一步骤： cp ~/Downloads/linux-2.6.35.tar.bz2 ~/ 接下来，可以使用下面的命令解压这个文件： tar -xvjf linux-2.6.35.tar.bz2 解压完成后，会在主目录中生成一个名为 linux-2.6.35 的文件夹，里面包含了 Linux 内核的所有源代码。 修改顶层目录下的 Makefile在进入 linux-2.6.35 的目录后，们需要修改顶层目录下的 Makefile。这一步骤很关键，因为它决定了们要编译的平台架构和使用的交叉编译器。可以通过文本编辑器打开 Makefile，找到如下代码： ARCH ?= $(SUBARCH)CROSS_COMPILE ?=CROSS_COMPILE ?= $(CONFIG_CROSS_COMPILE:%=%) 们要将这些行修改为： ARCH ?= arm # 体系架构是 arm 架构CROSS_COMPILE ?= arm-cortex_a8-linux-gnueabi- # 交叉编译器是 arm-cortex_a8 平台的 这两项设置非常重要，因为它们会直接影响到 Makefile 在编译时的行为。ARCH 变量定义了目标 CPU 的架构，而 CROSS_COMPILE 则指明了们将使用的交叉编译器，从而确保编译出的代码可以在 ARM 的 Cortex-A8 平台上运行。 拷贝标准版配置文件接下来，们需要拷贝一个标准版的配置文件，以便获取与们开发板相关的配置信息。使用以下命令： cp arch/arm/configs/s5pc100_defconfig .config 这一命令的目的是将 s5pc100_defconfig 文件复制到顶层目录下，并命名为 .config。这样做的好处是，它提供了一种快速的方法来选择与们的开发板相关的代码。Linux 支持的硬件平台非常庞大，不仅包括 ARM 架构，还包括多种其他架构。因此，在编译时，们只希望专注于与们具体开发板相关的代码，而不希望无谓地编译不相关的部分。 考虑到 Linux 源代码的文件数量超过一万，们需要确保选择的配置文件能够有效地过滤出所需的代码。这一过程设计得非常巧妙，内核开发者早就预见了这个需求，针对不同的硬件平台设定了对应的配置文件，只需通过简单的文件复制操作，们的 .config 文件便可自动记录下与平台相关的信息。 当们首次执行 make menuconfig 命令时，系统会自动解析 .config 文件中的配置，根据们之前选择的平台信息，选取合适的代码和模块。此时，们只需要进入该配置界面，做一些简单的修改，最后选择保存即可。这样，系统会将所有与们目标平台相关的信息保存到顶层目录的 .config 文件中。这种操作方式不仅高效，而且减少了人为错误的可能，使得内核的配置和编译变得更加简便。 配置内核运行以下命令以进入配置界面： $ make menuconfig 在第一次进入这个配置界面时，无需进行任何修改，直接退出。当系统提示是否保存配置信息时，一定要选择”YES”。通过此步骤，们将开发平台的信息保存至 .config 文件中，这个文件对于后续的编译和配置至关重要。 make menuconfig 的过程在执行 make menuconfig 时，们需要理解系统到底进行了哪些操作。特别地，为什么会出现图形化的界面？而这个界面中的内容又是从哪里来的呢？ 图形化界面的实现该图形化界面是通过一个名为 ncurses 的图形库实现的。当们首次执行 make menuconfig 时，如果系统没有安装 ncurses 库，会导致报错并显示缺少 ncurses-devel 的信息。在这种情况下，可以通过以下命令安装所需的库： sudo apt-get install libncurses5-dev 有了 ncurses 的支持，系统才能正常显示图形化界面，让用户进行配置。 图形界面内容的来源在解决了图形界面问题后，们必须明确图形界面里的内容是如何生成的。这个问题的答案与 Linux 内核的设计理念密切相关。Linux 内核采用模块化的组织方式。这种设计使得内核不再是一个庞大的单一实体，而是由多个独立的模块组成，每个模块负责特定的功能。 在 Linux 2.6 内核的源码树中，通常可以找到两个重要的文件：Kconfig 和 Makefile。分布在各个目录下的多个 Kconfig 文件共同构成了一个分布式的内核配置数据库。每个 Kconfig 描述了其所在目录下源文件相关的内核配置菜单。这意味着每个目录都可存放与功能相对独立的信息。 例如，在 /dev/char/ 目录下，存放了所有字符设备的驱动程序。这些驱动程序的代码在内核中以模块的形式存在。这就意味着，当系统需要某个驱动时，会将其以模块的形式编译进内核，分为静态编译和动态编译。静态编译的内核体积普遍比动态编译的大。 Kconfig 文件的作用Kconfig 文件中保存了目录下可用模块的信息。如果将某个目录的 Kconfig 文件内容全部删除，图形化界面将无法显示该模块的信息，用户也就无法进行相应的配置。 在内核配置过程，如运行 make menuconfig 或 xconfig 时，系统会自动从 Kconfig 文件中读取配置菜单。用户在界面中进行的配置被保存到 .config 文件中，该文件生成在顶层目录。.config 文件包含了所有的配置信息，记录了用户对内核配置的具体情况。主 Makefile 会引用 .config，以了解用户的内核配置。 扩展驱动的步骤如果想要在内核源码中添加新驱动，可以通过修改 Kconfig 文件来增设该驱动的配置菜单，以便用户能够选择。而如果希望使这个驱动被编译，必须修改该驱动所在目录下的 Makefile 文件。当添加新的驱动时，通常需要关注两个文件：Kconfig 和相关目录的 Makefile。尽管这两者是最为关键的，实际上，整个系统移植过程中还可能涉及其他多个文件的修改。因此，Kconfig 和相应目录的 Makefile 是添加或删除内核模块的核心文件。 编译内核通过运行以下命令： $ make zImage 们能够在 arch/arm/boot 目录下生成一个 zImage 文件。这是经过压缩的内核镜像，通常用于嵌入式系统。zImage 通常比未压缩的内核镜像小，能够更快地加载到内存中，从而提升系统启动速度。 内核的编译过程相当复杂。需要注意的是，这里的编译是静态编译，们执行的是顶层目录下的 Makefile 中定义的 zImage 命令。这个过程中，编译系统会依据当前目录的 .config 文件来选择需要的源代码，而这个 .config 文件中包含了关于内核各个组件的配置信息，例如启用或禁用特定的驱动程序或功能模块。 整个编译内核的过程包括多个步骤，如配置、编译和链接，具体步骤诸如： 配置内核选项：使用 make menuconfig 或 make xconfig 生成 .config 文件。 编译内核：执行 make zImage 开始编译。 生成压缩镜像：最终生成的 zImage 文件将放置在适当的目录中。 由于整个过程的复杂性，编译内核的细节们可以在后续的文章中进行深入探讨。 通过 TFTP 网络服务下载测试内核使用下面的命令设置引导参数： setenv bootcmd tftp 20008000 zImage; go 20008000 在这个命令中，20008000 是目标内存地址，这个地址是在开发板的内存中用于加载内核镜像的。zImage 是们之前编译得到的内核镜像。go 命令会从指定的地址启动内核，整个过程是通过 TFTP（Trivial File Transfer Protocol）完成的。 接下来，们设置内核启动的参数： setenv bootargs nfs nfsroot=192.168.1.199:/source/rootfs ip=192.168.1.200 init=/linuxrc ttySAC0,115200 这里的 nfsroot 指明了 NFS 服务器的 IP 地址和根文件系统的路径。ip 用于指定开发板的 IP 地址，以便于网络通信。init=/linuxrc 表示启动后将执行的第一个用户进程，ttySAC0,115200 则设置了串口的配置，其中 ttySAC0 是开发板的串口设备，波特率为 115200。 最后，保存以上环境变量并复位开发板，命令如下： saveenvreset 确认 NFS 文件系统已设置好，并能够成功挂载。这个过程相对复杂，特别是涉及到网络设置的问题，因此确保网络连接正常非常关键。要确保在启动之前，网络上的 NFS 服务器是可以访问的，否则启动过程将无法完成。在后续的文章中，们将详细介绍内核测试和启动的其他相关步骤。 根文件系统的介绍本部分以 Flash 存储中存放文件的分布图为起点，探讨文件系统的制作和移植，这通常是系统移植过程的最后一步。在此之前，们首先需要明确几个关键问题： 什么是文件系统？ 如何实现文件系统？ 常用的文件系统有哪些？为什么需要这些文件系统？ 接下来，们将逐一解答这些问题。 文件系统概述在们日常生活中，虽然很少有人直接提及”文件系统”这个名词，但其实际上无处不在，日常所称的资料库便是一个常见的例子。资料库中包含大量文件，而们该如何快速且准确地找到需要的那份文件呢？这正是文件系统所负责的。类比于学校图书馆，其一楼可能是哲学类书籍，二楼是社科类，三楼是电子类，四楼则是计算机类。采取这种分类和索引的方法的资料库，们称之为文件系统。 在计算机环境中，文件被视作数据的集合，存储于物理介质上，例如硬盘。用户无法直接访问物理介质上的文件，因此，所有文件的读写操作均需要通过程序来完成。为确保这一过程的顺畅，程序被划分为三个部分：物理介质驱动程序、内容存储程序和文件内容存储程序。物理介质驱动程序用于从物理介质读取和写入数据；内容存储程序的任务是将文件内容和其属性信息进行打包；文件内容存储程序则负责接收用户输入，从而形成文件内容，或者将读取的文件内容展示给用户。 文件系统的层次结构想象一下，们可以将一个文件系统（倒树形结构）分解成多个文件系统（倒树形结构），并将这些子系统分别存放至不同的存储介质上。例如，一个文件系统存储在光盘中，另一个则存储在硬盘中。在使用时，们将光盘中该文件系统的根目录挂载到硬盘文件系统的某个目录下。如此一来，访问这个特定目录就如同访问光盘的根目录一样，找到了根目录，们就能访问整个光盘上的文件系统。 “在 Linux 系统中一切皆是文件”，这句话在们学习 Linux 时常常能够听到，它虽然略显夸张，却有效揭示了文件系统在 Linux 中的重要性。实际上，文件系统在所有操作系统中都至关重要，它们通过文件的形式管理大部分的硬件设备和软件数据。以下是 Linux 系统中设备和数据管理的框架图： Linux 系统的文件系统结构 **VFS (Virtual File System)**：虚拟文件系统，管理特殊文件（如虚拟文件）、磁盘文件和设备文件。 fs_operations 结构：由一系列文件操作接口函数组成，由文件系统层来实现，为 VFS 提供文件操作。 文件系统层：在这一层，磁盘文件能实现多种文件系统，如 ext2，而设备文件则须实现各种抽象的设备驱动。 设备驱动层：重点在于磁盘驱动，需实现多种磁盘驱动程序，其他设备驱动负责具体设备的驱动。 物理层：这就是设备本身。 为什么会有不同的文件类型？由于存在多样的存储介质，单一的文件系统格式无法适用于所有介质，因此需要设计多种不同的存储格式，以优化存取效率和空间利用率。每种存储格式必须遵循特定的规范，这些规范被称为文件系统类型。 常见文件系统类型 DOS 系列： FAT16 Windows 系列： FAT16、FAT32、NTFS Linux 系列： Minix、ext、ext2、ext3、ISO9660、jffs2、yaffs、yaffs2、cramfs、romfs、ramdisk、rootfs、proc、sysfs、usbfs、devpts、tmpfs 和 ramfs、NFS 由此可见，Linux 支持的文件系统种类最为丰富。根据不同的介质进行分类如下展示： 磁盘：FAT16、FAT32、NTFS、ext、ext2、ext3、Minix 光盘：ISO9660 Flash 存储：jffs2、yaffs、yaffs2、cramfs、romfs 内存：ramdisk、tmpfs 和 ramfs 虚拟文件系统：rootfs、proc、sysfs、usbfs、devpts、NFS 理论上，常用的存储介质都可以支持所列的 Linux 文件系统。不过在嵌入式系统的应用中，由于受限于体积和便携特性，无法使用磁盘和光盘，因而只能选择 Flash 类型的存储设备、内存和虚拟存储设备。 Flash 存储和内存中的文件系统Flash 芯片的驱动程序由系统提供，因此其存取特性完全取决于 Flash 本身特点，因此需要更适合 Flash 的文件系统，如 JFFS、YAFFS、CramFS 和 ROMFS。这些文件系统都是在嵌入式 Linux 系统中常用的，并可根据各自特点进行选择，具体特点如下： 共同特点 基于 MTD 驱动 JFFS 针对 NOR Flash 的实现 基于哈希表的日志型文件系统 通常采用损耗平衡技术确保存储效能 支持数据压缩，可读写 提供崩溃掉电的安全保护 当文件系统接近满时，由于垃圾收集机制可能会影响运行速度 YAFFS 针对 NAND Flash 的实现 日志型文件系统 实施损耗平衡，确保存储均衡 可读写，不支持数据压缩 挂载时间短，内存占用少 自带 NAND Flash 驱动，无需外部 VFS 和 MTD CramFS 单页压缩，支持随机访问，压缩比最高可达 2:1 速度快，效率高 只读特性有助于保护文件系统，提高系统可靠性，但无法扩充内容 ROMFS 简单、紧凑、只读文件系统 顺序存放数据，支持 XIP（Execute In Place，片内运行），在系统运行时节省 RAM 空间 特有的文件系统类型：Ramdisk 文件系统在 Linux 系统中，Ramdisk 常用于存储文件系统，Ramdisk 分为两种：一种将物理内存视作物理存储介质，模拟磁盘；另一种则仅在内存中存储文件系统的逻辑结构，运用 tmpfs 和 ramfs 文件系统类型。 tmpfs ramfs 概述 物理内存模拟磁盘分区，挂载后可像读写磁盘文件一样读写文件，其操作速度显著高于磁盘文件。 一般应用场景包括： 速度要求快的文件可放置于此文件系统中 当磁盘分区为 Flash 时，将频繁读写的文件放置于此，并定期写回 Flash 系统的临时文件，如 /tmp 和 /var 目录下的文件 /dev 设备文件（因为设备文件随驱动和设备加载卸载而变化） 特点 数据保存在物理内存中，系统重启后，该文件系统的数据会全部丢失。 ramfs 在没有指定最大大小时会自行增长，直至占用所有物理内存，可能导致系统崩溃，因此建议在挂载时设定最大值。 tmpfs 如果指定大小，将在达到最大值后不再继续增长，且其占用的物理内存页可以换出到 swap 分区，而 ramfs 则不具备这一特性。 不同的文件系统拥有各自的构建方法。","categories":["1.平台","嵌入式","系统移植"]},{"title":"EMC","path":"/2024/09/24/1-平台-平台相关-EMC/","content":"EMC（电磁兼容性）的重要性电磁兼容性（EMC）是确保产品在特定电磁环境中能够正常工作的关键性能指标。EMC 不仅涉及到设备能否抵御外部干扰，还包括设备自身是否会向外界释放干扰。任何未能通过 EMC 测试的产品都可能面临严重后果，包括功能失常、设备损坏甚至安全隐患。 EMC 的基本概念电磁兼容性是指电气设备在其电磁环境中正常工作的能力，包括： 限制无意间产生的电磁能量：设备在运行过程中不会意外地通过 radiated 或 conducted 方式释放对其他设备的干扰。 抗干扰能力：设备在受到来自外界的电磁干扰（EMI）时，保持稳定和正常的工作状态。 例如，心脏起搏器这样的医疗设备，其对电磁干扰的敏感性极高。如果周围存在强电磁干扰，它可能会影响起搏器的工作，导致心脏停跳等严重后果，这是 EMC 保障生命安全的重要体现。 EMC 研究的三大关键问题 能量来源：电磁能量的产生可能源于各类电气设备，包括家用电器、工业机床、甚至网络设备。识别并控制这些干扰源是 EMC 研究的重要一环。 抗干扰能力：设备应具备强大的抗干扰能力，这是决定电气设备故障率的重要因素。例如，某些高端服务器测得抗干扰能力能在遭遇 RFI 时，依然保持 99.9%的正常运行时间。 耦合路径：研究干扰是如何通过电缆、空气或其他媒介耦合到敏感设备上的，以便有效实施防护措施。 常见的 EMC 测试 抗扰度测试：这包括了诸如静电放电测试、脉冲群抗扰度测试、雷击浪涌测试等。通过向设备施加特定的电磁干扰，观测其是否依旧保持正常工作。 传导辐射测试：测量设备在工作状态下，向外释放的电磁干扰水平，例如电源线的传导测试。这些测试确保设备对外界的影响在规定标准之内。 电磁失效的表现EMC 干扰的影响千万不可小觑，可能导致一系列功能失效： 系统死机无响应：例如，某应用因读取到错误的输入值，程序陷入死锁而无法响应。 执行意外指令：比如，指向错误内存地址，数据丢失导致软件行为异常。 IO 表现异常：这可能表现为显示屏闪烁、按键失灵、传感器数据出现噪声等。 软件对策的实施 看门狗技术：看门狗能够监测系统是否死机并重新启动系统。这是一个务实的解决方案，特别是在多个 EMC 测试等级中，只要系统能在干扰后恢复正常，就算是通过了。 数据冗余技术：在关键功能操作中引入备份参数。例如在航空、医疗等领域，开发者往往会为关键数据采用双重存储机制，以确保即使在最复杂的电磁干扰情况下也能迅速恢复。 管理未使用的中断：对于系统中未被使用的中断，关闭相应寄存器，并通过异常中断服务例程记录并处理这些中断。 谨慎的 IO 策略：对于输入信号，可以采用滤波策略，比如多次采样以消除抖动。在模拟信号处理中，使用数字滤波器技术以确保数据的准确性。 掉电检测存储技术：结合硬件设计，采用掉电检测及瞬时 UPS 电路。系统在交替供电的条件下，如果检测到即将掉电，能及时保存关键参数以防止数据丢失。 健壮的通信协议设计：增加 CRC 校验、错误重传机制和通信故障检测，以提升设备在通信过程中的鲁棒性。","categories":["1.平台","平台相关"]},{"title":"Linux启动","path":"/2024/09/23/1-平台-平台相关-Linux启动/","content":"Linux 系统Linux 系统内核Linux 系统内核是这个操作系统的核心部分，它负责管理计算机的硬件资源。内核提供了硬件抽象层，使得应用程序可以方便地与硬件互动，而不必关心具体的硬件实现细节。例如，内核会管理 CPU 的调度、内存的分配以及硬盘的读写操作。 此外，内核支持多任务功能，允许多个程序同时运行，从而提升了计算机的使用效率。在 Linux 系统中，内核处理与硬件的所有交互，这样用户和开发者就可以关注他们的应用程序，而不必担心底层的硬件管理。 Linux 发行套件系统Linux 发行套件系统（Linux distribution）是对 Linux 内核及其周边软件的一个集合。它不仅包含了 Linux 内核，还包括了各种常用的软件工具和库，使得用户可以直接安装和使用。例如，Ubuntu、CentOS 和 Fedora 是三种流行的 Linux 发行版，每种都有其独特的特点和适用场景。 这些发行版通常会预装一些流行的软件，如文本编辑器、浏览器和开发工具，使得用户在安装系统后，可以立即开始使用。此外，许多发行版还提供了软件包管理系统，用户可以轻松地添加或更新软件，提高了系统的可用性和灵活性。比如，Ubuntu 使用了 APT 包管理系统，允许用户通过简单的命令来安装新软件，而无需手动处理依赖关系。 通过这种方式，Linux 发行套件不仅使得系统的配置变得更加简单，还使得新用户能够更快地上手，避免了繁琐的设置步骤。 分区Linux 系统按照 FHS（Filesystem Hierarchy Standard，文件系统层次结构标准）对不同目录进行了明确的定义和功能划分。这种组织结构使得用户和管理员能够轻松找到文件和程序，并确保系统的高效运作。 主要目录及其功能 （根目录） 根目录是文件系统的起点，所有其他目录都在这个目录中进行层级组织。例如，/home、/etc、/var 等都源自于根目录。 bin 存放基本的用户命令和系统工具，如 ls、cp 和 mv 等。这些命令是系统启动和操作的必要组成部分。 etc 包含系统和应用程序的配置文件。比如，/etc/fstab 文件中定义了系统的文件系统挂载点，/etc/hosts 文件用于 DNS 查找。 home 每个用户的个人目录都在此目录下，用户可以在这里存储自己的文档、设置和配置。例如，/home/username 是用户 username 的专属空间。 lib 存放系统运行所需的共享库文件，这些库支持 /bin 和 /sbin 目录中的可执行文件。例如，/lib/x86_64-linux-gnu/libc.so.6 是常用的 C 标准库。 usr 存储用户程序和数据的目录，通常包含许多重要的应用程序和工具。例如，/usr/bin 目录中放置了许多用户可用的命令行工具，如 git、python 和其他应用程序。 var 存放经常变化的数据，例如日志文件 (/var/log)、邮件 (/var/mail)、缓存和临时文件。日志文件有助于系统管理员排查问题。 tmp 用于存放临时文件，系统重启后会被清空。比如，安装软件时可能需要在此目录中写入中间文件。 举例说明假设是一名系统管理员，需要检查用户的登录记录。知道登录记录存放在 /var/log/wtmp 文件中。可以使用 last 命令查看这些记录，而 last 命令会从该文件中提取信息，列出所有用户的登录时间和持续时长。 这种清晰的目录结构不仅使系统的管理变得简单明了，也有助于提升安全性和可维护性。因此，了解这些目录的用途对于任何使用或管理 Linux 系统的人来说都是至关重要的。 重置 root 密码在进行系统的安全管理时，重置 root 密码是一项重要的技能。如果发现自己忘记了 root 用户的密码，可以按照以下步骤进行重置。 步骤如下： 启动计算机在计算机启动时，注意观察 GRUB 引导加载器的界面。这个界面通常会显示多个启动选项，尤其是在有多个操作系统时。 进入编辑模式当 GRUB 加载出现在屏幕上时，选择想要启动的内核选项，然后按下 e 键。这将使进入编辑模式，会看到几个参数配置。 修改启动参数找到包含”ro”（只读）字母的行，通常是以”linux”开头的行。将”ro”更改为”rw”，这样可以让系统以读写方式启动。然后在这一行的末尾添加 init=/bin/bash。这一步是为了让系统进入一个带有 bash 的紧急模式，方便重置密码。 示例： linux /vmlinuz-xxx ro quiet 修改为： linux /vmlinuz-xxx rw init=/bin/bash 启动修改后的内核修改完后，按下 Ctrl+x 或 F10 来启动系统。此时，系统会进入 bash 命令行界面。 更新 root 密码在 bash 命令行界面中，输入以下命令来更新 root 用户的密码： passwd 系统会提示输入新的密码。请务必选择一个强密码，最好包含字母、数字和特殊字符。确认输入后，系统会显示密码已成功更新的消息。 重启系统更新完密码后，输入以下命令以重启系统： exec /sbin/init 或者也可以使用： reboot 使用新密码登录系统重启后，使用刚刚设置的新密码进行登录。 完成这些步骤后，成功地重置了 root 密码，能够顺利访问系统。务必注意，重置 root 密码需要一定的权限，因此请确保是系统的合法管理员。 初始化进程在 Linux 系统中，启动过程是一个复杂而又重要的流程，涉及多个阶段和组件。整个启动过程通常遵循以下顺序： BIOS：计算机开机时，首先会通过 BIOS（基本输入输出系统）进行硬件自检并初始化硬件组件。 BootLoader：完成硬件初始化后，BIOS 将控制权交给 BootLoader（引导加载程序），例如 GRUB。BootLoader 负责加载操作系统内核。 加载系统内核：BootLoader 加载 Linux 内核到内存中。 内核初始化：内核开始初始化系统硬件（如 CPU、内存、硬盘等），并准备进行用户空间的运行。 启动初始化进程：内核启动第一个用户空间进程，通常是 init，这时 Linux 系统的初始化工作正式开始。 初始化进程初始化进程是 Linux 系统中第一个被创建的进程，其进程 ID（PID）为 1。它的主要任务是完成各种初始化工作，以确保用户能够拥有一个稳定和可用的工作环境。在现代 Linux 系统中，systemd 取代了传统的 System V init，引入了一些更为高效和灵活的特性。 初始化进程服务类型System V initSystem V init 采用传统的运行级别（runlevel）机制，每个运行级别定义了系统不同的状态和可用的服务。以下是一些常见的运行级别及其对应的 Systemd 目标名称和作用： System V Init 运行级别 Systemd 目标名称 作用 0 runlevel0.target, poweroff.target 关机 1 runlevel1.target, rescue.target 单用户模式 2 runlevel2.target, multiuser.target 等同于级别 3 3 runlevel3.target, multiuser.target 多用户的文本界面 4 runlevel4.target, multiuser.target 等同于级别 3 5 runlevel5.target, graphical.target 多用户的图形界面 6 runlevel6.target, reboot.target 重启 emergency emergency.target 紧急 Shell systemd与 System V init 不同，systemd 采用并发启动机制，能够并行启动多个服务，从而显著加快启动过程。systemd 使用目标（target）来替代传统的运行级别，提供了更灵活的服务管理功能。 .systemctl 和 System V init 的对比systemctl 是 systemd 的命令行工具，用于管理系统服务。以下是一些常见的 System V init 命令与相应的 systemctl 命令的对比： System V init 命令 systemctl 命令 作用 service foo start systemctl start foo.service 启动服务 service foo restart systemctl restart foo.service 重启服务 service foo stop systemctl stop foo.service 停止服务 service foo reload systemctl reload foo.service 重新加载配置文件（不终止服务） service foo status systemctl status foo.service 查看服务状态 chkconfig foo on systemctl enable foo.service 开机自动启动 chkconfig foo off systemctl disable foo.service 开机不自动启动 chkconfig foo systemctl is-enabled foo.service 查看特定服务是否为开机自启动 chkconfig –list systemctl list-unit-files –typeservice 查看各个级别下服务的启动与禁用情况 通过使用 systemd 和 systemctl，用户能够更高效地管理服务和系统状态，同时也简化了服务的控制和配置。 基于 ARM 体系的内核启动解析Bootloader 的基本初始化准备在内核被引导加载之前，Bootloader 必须完成以下核心任务，确保系统能够顺利启动。 1. 设置并初始化 RAM (必须)引导加载程序必须找到并初始化系统的所有 RAM，以便它可以用于存储易失性数据。这一过程取决于机器架构。引导加载程序可以采用内部算法自动确定 RAM 的大小，或者利用机器的已知特性来完成初始化。例如，对于某些 ARM 设备，引导加载程序可能会读取硬件提供的 RAM 扩展信息，从而确定可用的内存范围。 2. 设置设备树 dtb (必须)设备树 Blob（dtb）必须按照 8 字节对齐，且最大不能超过 2 兆字节。这是为了确保设备树能够被有效地映射到系统中。值得注意的是，在 v4.2 之前的版本要求 dtb 放置在 512 MB 区域内。所以，在用户设计系统时，需要审核 dtb 的位置和大小，以避免初始化失败。 3. 解压缩内核映像 (可选)目前 AArch64 内核没有提供内置的解压缩器，这意味着如果使用压缩的内核映像（如 Image.gz），引导加载程序必须负责解压。对于那些没有实现此功能的引导加载程序，可以选择编译一个不压缩的内核映像。 4. 调用内核映像 (必须)内核映像的头部包含多项必要的信息，例如： u32 code0; /* 可执行代码 */u32 code1; /* 可执行代码 */u64 text_offset; /* 加载偏移，小端 */u64 image_size; /* 有效映像尺寸，小端 */u64 flags; /* 内核标志, 小端 */ 进入内核进入内核之前，必须满足一系列关键性条件，以确保系统的稳定和安全性。下面是这些条件的详细说明： 禁止 DMA 功能的设备为了防止内存因虚假的网络数据包或损坏的磁盘数据而被意外损坏，所有具有 DMA（直接内存访问）功能的设备必须被禁用。例如，网络适配器或存储控制器在内核加载前都应停止数据传输，以避免不合规操作造成的内存污染。 主 CPU 通用寄存器设置主 CPU 的通用寄存器必须进行特定的初始化。具体设置如下： x0：需设置为系统 RAM 中设备树 Blob（Device Tree Blob，简称 dtb）的物理地址。这一地址对于内核初始化至关重要，因为它提供了系统硬件的描述信息。 x1x2x3：应设置为 0，预留供将来使用。这通常意味着目前未定义的功能可以在将来进行扩展和优化。 CPU 模式在 CPU 模式方面，以下要求必须得到满足： 所有形式的中断都要在 PSTATE.DAIF 中屏蔽。这包括调试中断（Debug），系统错误（SError），标准中断（IRQ）和快速中断（FIQ）。通过阻止这些中断，系统可以专注于内核的安全加载。 CPU 必须在 EL2（异常级别 2）或非安全的 EL1 下运行。选择 EL2 作为推荐模式是因为这为虚拟化扩展提供了访问权限，这对于现代系统至关重要。 Caches 和 MMUs MMU（内存管理单元）必须关闭。这是确保内核能够准确管理内存映射的重要步骤。 指令缓存可以选择开启或关闭，根据具体的应用场景来决定。 与加载的内核映像相对应的地址范围必须被清除到 PoC（一致性点）。例如，如果某个设备正在使用系统缓存，这些缓存必须确保在内核加载之前处于干净状态。 若存在系统缓存或启用了缓存的其他相关主服务器，操作时通常应通过虚拟地址（VA）维护缓存，而非直接通过物理地址。 架构定时器在内核的启动过程中，所有 CPU 上的计时器必须根据其频率设置 CNTFRQ，并且必须一致地设置 CNTVOFF。如果内核在 EL1 级别启动，则 CNTHCTL_EL2 的 EL1PCTEN 位（即位 0）必须在可用时被设置。 连贯性当内核启动时，所有由内核引导的 CPU 必须属于同一一致性域。这一要求确保了 CPU 之间在访问共享内存时的一致性，避免了潜在的数据损坏。初始化时，每个 CPU 的维护操作必须通过定义的实现进行。 系统寄存器所有处于异常级别的可写架构系统寄存器都必须由更高异常级别的软件初始化。这是为了防止在 UNKNOWN 状态下执行，避免出现无法预知的系统行为。 CPU 进入内核的条件 所有 CPU 必须以相同的异常级别进入内核。 主 CPU 直接跳转到内核映像的第一条指令，以确保高效和迅速的启动过程。 主 CPU 还需保证传递的设备树 Blob，对于每个 CPU 节点包含一个”启用方法”属性。支持的启用方法如下所述，且这些属性由引导加载程序生成，并在内核入口之前插入到 blob 中。 启用方法示例 旋转表（Rotation Table）启用方法的 CPU，其 cpu 节点必须包含”cpu-release-addr”属性。此属性指向一个自然对齐的 64 位零初始化内存位置，用于 CPU 的安全启用。 psci（Power State Coordination Interface）启用方法的 CPU 应该在内核外部保留，确保其在内存节点之外或通过 /memreserve/ 描述给内核的内存区域。 此外，内核将根据 ARM 文档编号 ARM DEN 0022A 的说明发出 CPU_ON 调用，以将 CPU 引入内核，确保系统整合的顺畅。 第二 CPU 通用寄存器设置对于第二个 CPU，通用寄存器 x0x1x2x3 都应设置为 0，进一步预留以便未来使用。 通过确保上述所有条件都得以满足，内核能够在一个安全、稳定的环境中顺利启动，进而进行后续操作。 内核启动 init 总过程内核启动有两种主要方式：压缩格式和不压缩格式。在压缩模式下，内核的入口代码位于 arch/架构名/boot/compressed/head.S。这段代码的主要职责是进行前期初始化，准备工作是解压内核并为后续的启动做好基础环境。 一旦解压完成，控制便会跳转到 arch/架构名/kernel/head.S，此处则开始正式启动内核。这一过程中的每一步都至关重要，它不仅决定了系统的启动效率，也直接关系到系统能否成功进入正常运行状态。 本文专注于不压缩方式的内核启动过程。通过对内核代码的逐行解析，能够整理出内核启动过程的部分顺序，以帮助读者更好地理解这一复杂的过程。 以下是一个简化的不压缩启动过程的概述： **引导加载程序(bootloader)**：首先，系统的引导加载程序会被加载到内存。这是启动流程的第一步，引导加载程序负责把内核映像加载到内存中。例如，GRUB（GRand Unified Bootloader）就常用于这种情境。 内核入口点：从引导加载程序中，系统将控制权转交给内核的入口点，通常是 start_kernel。这是内核意识到自身被启动的地方。 内核初始化：在 start_kernel 中，根本的初始化过程和设置工作进行，例如设置内存管理单元（MMU）、中断系统，以及初始化调度器等。这一阶段确保内核能够处理多任务。 启动进程：经过一系列必要的初始化步骤后，内核会启动系统的第一个进程，通常是 init 进程。这一进程的 PID（进程标识符）为 1，是所有用户空间进程的父进程。init 进程负责启动其他用户空间服务和进程。 正常运行：当 init 进程完成启动后，系统便进入到正常的运行状态，各种服务和应用程序开始正常加载。 内核启动流程详解内核的启动过程与 U-Boot 的启动方式类似，前期同样是由一段汇编代码开始，随后跳转至 C 代码的执行。汇编代码的入口点位于 ./arm/kernel/head.S 文件中，符号名为 __HEAD，该文件还包含了 head-common.S。 从启动用户空间的第一个进程 init 来看，可以将这一过程大致分为四个步骤： head.S 处理：该步骤主要进行通用环境的初始化，这一部分与具体的芯片架构无关。 start_kernel 函数：当 head.S 完成后，控制会跳转到 start_kernel 函数。这一函数定义在 ./init/main.c 中。 rest_init 函数：在这一阶段，内核会创建 init 进程和 kthreadd 进程，其中 init 进程的进程号为 1，而 kthreadd 是内核的线程管理进程。 启动调度器：此时内核调度器开始运行，并执行 kernel_init 函数。kernel_init 函数会调用包含在根文件系统中的 init 进程，至此，用户空间的 init 进程启动完成。 head.S 和 head-common.S 的作用深入分析汇编代码的功能有些繁琐，但可以简要总结其主要作用： 检查架构：验证处理器和机器类型，以确保系统正确识别目标硬件。 配置 MMU：设置内存管理单元（MMU），构建页表条目，并启用虚拟内存。MMU 是现代计算机中用于管理物理内存的关键组件，它允许操作系统使用虚拟地址空间，让程序彼此隔离。 调用 start_kernel：在 init/main.c 文件中执行 start_kernel 函数。 所有架构的代码是相同的，因此使用汇编语言可以避免为不同芯片管理大量重复的代码。 start_kernel 阶段在 start_kernel 函数中，内部主要完成了以下工作： 锁依赖检测模块初始化：初始化 Lockdep 模块，以防止内核中可能出现的死锁。在 Lockdep 中，当锁被获取或释放时，会记录下这一事件以及相关详细信息，例如当时处理器是否正在处理中断。 RCU 机制初始化：RCU（Read-Copy Update，读-拷贝修改）是一种优化并发读写操作的机制。它允许读者在不获取锁的情况下访问被保护的数据结构，而写者则需先拷贝数据，然后修改副本，最后在适当的时机更新指针。这种机制的有效性在于所有 CPU 完成对共享数据的操作后，才会更新指针。 SMP 初始化：对称多处理（SMP）初始化，完成 CPU ID 的创建，确保在多核系统中各核心能有效地调度和运行操作。 调试对象的早期初始化：设置调试对象，确保内核调试可以顺利进行。 解析从 bootloader 传入的引导命令行：调用 setup_arch(command_line) 函数，初始化控制台以打印启动日志，并设置其他子系统，如虚拟文件系统（VFS）、跟踪（trace）、内存管理、进程控制组（cgroup）、ACPI（高级可扩展固件接口）、proc 文件系统等。 调用 rest_init：随后进入 rest_init 阶段，创建 init 和 kthreadd 进程，启动内核调度器。 rest_init 阶段在 rest_init 函数中，主要表现如下： static noinline void __init_refok rest_init(void) int pid; rcu_scheduler_starting(); smpboot_thread_init(); // 创建 init 进程，第一个用户空间进程 kernel_thread(kernel_init, NULL, CLONE_FS); numa_default_policy(); // 创建 kthreadd 用于管理内核线程 pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES); // 让内核进程 kthreadd 处于就绪态 TASK_NORMAL complete(kthreadd_done); // 启动调度器 init_idle_bootup_task(current); schedule_preempt_disabled(); cpu_startup_entry(CPUHP_ONLINE); 这一段代码创建了第一个用户空间进程 init，进程号为 1，负责加载和启动其他用户空间应用。之后，创建 kthreadd 进程，该进程的进程号为 2，并用于管理内核线程。所有其他内核线程都作为 kthreadd 的子线程被创建，利用 kthread_create_list 来维护这些内核进程。 kernel_init 阶段当内核调度器开始运行后，控制权转移到 kernel_init 函数： static int __ref kernel_init(void *unused) int ret; kernel_init_freeable(); // 完成所有初始化操作 async_synchronize_full(); // 如果使能了 ramdisk 执行命令启动 init if (ramdisk_execute_command) ret = run_init_process(ramdisk_execute_command); if (!ret) return 0; pr_err(Failed to execute %s (error %d) , ramdisk_execute_command, ret); // 否则根据配置启动 init if (execute_command) ret = run_init_process(execute_command); if (!ret) return 0; panic(Requested init %s failed (error %d)., execute_command, ret); // 如果上述两项都未启用，则依次在根文件系统下寻找 init if (!try_to_run_init_process(/sbin/init) || !try_to_run_init_process(/etc/init) || !try_to_run_init_process(/bin/init) || !try_to_run_init_process(/bin/sh)) return 0; panic(No working init found. Try passing init= option to kernel. See Linux Documentation/init.txt for guidance.); 在这一阶段，内核尝试启动 init 进程，具体执行哪个 init 可执行文件则依赖于系统配置。常见的进程包括 BusyBox 的 init、SystemV 的 init 或 SystemD 的 init 等。根据不同的 Linux 发行版，所选择的 init 系统会有差异。","categories":["1.平台","平台相关"]},{"title":"Windows的启动","path":"/2024/09/20/1-平台-平台相关-Windows的启动/","content":"零、boot 的含义在计算机领域，”启动”这个词用英语是 boot。但这个词原本的意思是”靴子”，那么，启动与靴子之间有什么联系呢？其实，这个词源自于 bootstrap（鞋带）的缩写，来源于一句谚语：”pull oneself up by one’s bootstraps“。这句谚语的字面意思是”拉着鞋带把自己拉起来”，显然，这是个不可能完成的任务。 在计算机的早期，工程师们使用这个比喻来描述一个矛盾的过程：要启动计算机，必须先运行程序，但如果计算机未启动，就无法运行程序。实际上，早期计算机的启动过程确实如此。工程师们需想尽办法将一小段程序装入内存，之后计算机才能正常运行。逐渐地，”拉鞋带”的说法便被简化为 boot。 启动过程可以分为四个阶段。 第一阶段：BIOS在上世纪 70 年代初，只读内存（Read-Only Memory，简称 ROM）被发明。开机程序被写入 ROM 芯片中，当计算机通电后，第一件事便是读取这块芯片。这块芯片中的程序称为 基本输入输出系统（Basic InputOutput System），简称为BIOS。 1.1 硬件自检BIOS 程序首先进行 硬件自检（Power-On Self-Test，简称 POST），确认计算机硬件是否能满足运行的基本条件。如果硬件出现问题，主板会发送不同的蜂鸣声音来提示错误，从而启动过程也会中止。 反之，如果硬件正常，屏幕上将显示 CPU、内存、硬盘等硬件信息，确保一切就绪后，BIOS 会把控制权转给下一阶段的启动程序。 1.2 启动顺序硬件自检完成后，BIOS 需要确定”下一阶段的启动程序”存放在哪个设备上。为此，BIOS 会参考 启动顺序（Boot Sequence），这是一个设备的优先级列表，按照此顺序搜索可启动的设备。用户可以通过 BIOS 设置界面自定义此启动顺序。 第二阶段：主引导记录BIOS 根据启动顺序，将控制权转交给第一位的存储设备。计算机会读取该设备的第一个扇区，也就是前面 512 个字节。如果这 512 个字节的最后两个字节分别是 0x55 和 0xAA，这表示该设备能够用于启动；如果不是，则继续查找启动顺序中的下一个设备。 这部分 512 字节的内容称为 主引导记录（Master Boot Record，简称 MBR）。 2.1 主引导记录的结构MBR 总计 512 个字节，其中主要有三个组成部分： 第 1-446 字节：包含调用操作系统的机器码。 第 447-510 字节：称为 分区表（Partition Table），负责描述硬盘上各个分区的情况。 第 511-512 字节：主引导记录签名，表示 MBR 正常。 2.2 分区表分区的主要优势在于能够在一个硬盘上安装多个操作系统。分区表长仅 64 个字节，最多可以定义四个 主分区。每个主分区由独立的 16 个字节组成，包含多个信息，如激活状态、分区类型以及位置等。 对于最大分区容量的计算，如果每个扇区为 512 个字节，那么每个主分区最大可达 2TB，而整个硬盘的可利用空间也受到此限制。如需更大容量，可通过增加扇区字节数或分区数量来实现。 第三阶段：硬盘启动计算机此时需将控制权转交给硬盘触发的某个分区，情况大致分为三种。 3.1 情况 A：卷引导记录在四个主分区中，有且仅有一个是被激活的。计算机读取激活分区的第一个扇区，这部分数据称为 卷引导记录（Volume Boot Record，简称 VBR）。VBR 的关键作用在于指向操作系统在该分区内的具体位置，随后计算机会加载操作系统。 3.2 情况 B：扩展分区与逻辑分区随着硬盘的容量不断增加，四个主分区已显不足。为了解决这个问题，扩展分区（Extended Partition）的概念应运而生。扩展分区内可以包含多个 逻辑分区（Logical Partition）。 计算机首先会读取扩展分区的第一个扇区，称为 扩展引导记录（Extended Boot Record，简称 EBR）。在这个记录中，也有一个分区表，但仅限于两项，即两个逻辑分区。计算机接下来会继续从逻辑分区的分区表中读取，直到仅剩下自己的单一项。 3.3 情况 C：启动管理器在这种情况下，计算机读取 MBR 前 446 字节的机器码后，不会立即交给某一特定分区，而是运行预先安装的 启动管理器（Boot Loader），由用户选择想要启动的操作系统。在 Linux 环境中，最流行的启动管理器是 Grub。 第四阶段：操作系统当控制权被转交给操作系统后，操作系统的内核首先会被加载到内存中。以Linux为例，系统会首先加载 /boot 目录下的内核文件。内核加载成功后，系统会启动第一个程序 /sbin/init。 /sbin/init 的主要功能是根据配置文件（如 Debian 系统中的 /etc/inittab）生成 init 进程。这个进程是 Linux 系统启动后第一个被激活的进程，其进程编号是 1，之后所有其他进程均为其后代。 随后，init 线程将系统的各个模块加载进来，包括窗口程序和网络程序，最终执行 /bin/login 程序，展示登录界面，等待用户输入用户名和密码。 至此，整个计算机启动过程就此完成。","categories":["1.平台","平台相关"]},{"title":"开源协议","path":"/2024/09/19/1-平台-平台相关-开源协议/","content":"常见开源许可证介绍开源软件许可证是软件开发中的法律文件，它规定了软件的使用、复制、修改和分发的条件。不同类型的许可证具有不同的规则和条款。以下是一些常见的开源许可证及其特点。 LGPL（较宽松通用公共许可证）LGPL，即”Lesser General Public License”，允许开发者在软件中使用 LGPL 授权的库，而不必将整个软件项目都开放源代码。举例来说，如果使用了一个 LGPL 授权的图形库来开发应用程序，可以选择将的应用保密，前提是提供了对图形库的访问权限，并且在相同版本下允许用户将其替换。在进行更新或修改时，开发者有义务确保库的源代码能够被获取，从而维护了社区对软件的持续改进。 Mozilla 许可证Mozilla 许可证是一种宽松的开源许可证，允许开发者自由使用、修改及分发基于 Mozilla 的开源软件。与 GPL 不同，Mozilla 许可证不要求派生作品也必须是开源。这意味着，使用了 Mozilla 许可证的软件可以与闭源软件结合使用。例如，Mozilla Firefox 浏览器就是基于此许可证发布的，用户和开发者可以构建自己的插件或扩展，而不必将自己的代码开源。 GPL（通用公共许可证）GPL（General Public License）是最流行的开源许可证之一，强调”如果发布修改后的作品，必须同样以 GPL 的条款发布”。也就是说，一旦使用 GPL 授权的代码，的所有源代码也必须开放给用户。这可以确保软件自由使用的权利被保护。比如，著名的 Linux 操作系统就是以 GPL 授权发行，使得社区中许多开发者基于其内核创建了不同版本的 Linux 发行版。 BSD 许可证BSD 许可证是一种非常宽松的许可协议，允许用户自由使用、修改和分发源代码，甚至可以将其用作闭源软件。BSD 许可证的一个著名实例是 FreeBSD 操作系统，它提供了一种灵活的许可方式，让企业可以在其产品中使用 BSD 授权的软件，而无需公开源代码。这种自由使得 BSD 许可证在商业应用中非常受欢迎。 MIT 许可证MIT 许可证同样是一种非常宽松的许可证，允许软件的任何人在任何情况下使用、复制和修改该软件，几乎没有限制。有很多现代的开源项目，如 Ruby on Rails 和 Node.js，都是在 MIT 许可证下发布的。这种简单明了的授权方式，有助于吸引更多的贡献者，因为它允许开发者将自己的项目与任何其他项目无缝结合。 Apache 许可证Apache 许可证提供了一种灵活的使用和分发模式，允许用户修改和分发代码，甚至包括商用。与 MIT 和 BSD 不同，Apache 许可证特别重视贡献者的权利，要求对贡献者的名字进行相应的标注。Apache HTTP 服务器是利用该许可证发布的，它被广泛应用于互联网，是一个事实上的标准选择。 通过了解这些开源许可证，开发者和用户能够更好地遵循法律框架，同时在软件开发中保持开放与自由，推动技术创新。","categories":["1.平台","平台相关"]},{"title":"操作系统","path":"/2024/09/18/1-平台-平台相关-操作系统/","content":"操作系统什么是操作系统？操作系统（Operating System, OS）是计算机系统中管理硬件和软件资源的核心程序。它负责进行进程管理、内存管理和文件系统管理等多项关键功能。这些功能帮助用户和计算机之间进行有效的互动。 操作系统的主要组成部分 内核：内核是操作系统中最重要的部分，负责直接与计算机的硬件进行交互。它管理着系统调用、进程调度、内存分配等任务。例如，Linux 内核支持多用户和多任务，确保每个进程可以同样有效地访问 CPU 时间。 驱动程序：驱动程序使操作系统能够与硬件设备通信。每种硬件设备（如打印机、显卡）都需要相应的驱动程序，以实现高效的操作。例如，安装显卡的驱动程序后，用户可以充分利用设备的图形处理能力。 接口库：接口库提供了一系列 API（应用程序接口），使得开发者能够高效地编写软件，与操作系统进行交互。通过接口，程序可以轻松调用操作系统的功能，如文件操作、网络通信等。 什么是嵌入式操作系统？嵌入式操作系统是特定硬件设备中使用的操作系统，这些设备通常具有特定功能，如智能家居产品、汽车电子系统等。嵌入式操作系统通常是可裁剪的，这意味着开发者可以根据设备的需求定制其功能。此外，对可靠性和稳定性的要求非常高。例如，在医疗设备中，嵌入式操作系统必须确保在关键时刻稳定运行，关乎患者的安全。 什么是交换分区？交换分区是计算机在内存不足时所使用的一部分硬盘空间，临时用于存放不活跃或休眠状态的进程数据。通过将这些数据转存至交换分区，计算机能够释放内存，保证其他运行中的进程能继续流畅执行。举个例子，如果打开了多个大型应用，系统会将不再使用的应用的状态存放在交换分区，从而保持系统的运行效率。 什么是文件系统？文件系统是操作系统中负责文件管理的软件和数据的集合。它提供一种组织和存取文件的方式，使得用户可以轻松地创建、读取、写入和删除文件。在文件系统中，所有文件都被组织在一个层次结构的目录中，用户可以通过路径轻松访问文件。 Windows 和 Linux 的文件系统有何区别？Windows 和 Linux 在文件系统结构上存在显著差异： 在 Windows 中，目录结构在分区下进行组织，比如 C:\\、D:\\ 等。如果用户保存了一个文档，在文件管理器中，它会显示在 C:\\Documents\\MyFile.txt 这样的路径中。 而在 Linux 中，所有的设备和分区都挂载在一个统一的目录结构下，通常以根目录（）为起点。比如，可以将一个附加的硬盘分区挂载到 mnt 目录，用户看到的路径可以是 mntexternal_driveMyFile.txt。 硬盘分区硬盘分区是将一个物理硬盘划分为多个逻辑单元，以便更好地管理和使用硬盘空间。常见的分区类型包括： 主分区：直接从硬盘启动的分区，最多可以有四个主分区。 逻辑分区：在扩展分区内创建的分区，可以有多个逻辑分区，便于管理多量数据。 扩展分区：一种特殊类型的分区，允许在硬盘上创建额外的逻辑分区。 分区格式 Windows 通常使用 FAT（文件分配表）或 NTFS（新技术文件系统）格式，以支持文件权限和其他高级特性。 Linux 则主要使用 ext（扩展文件系统），如 ext2、ext3 和 ext4，各自支持不同的功能，如日志记录、文件权限管理等。 交换分区和虚拟内存交换分区和虚拟内存密切相关。交换分区是物理硬盘上的一块空间，而虚拟内存是操作系统为每个进程创建的一个逻辑地址空间。当物理内存不足时，操作系统将不活跃的数据或程序从 RAM 中移至交换分区，使得有效利用内存，提高系统处理能力。例如，在大量数据处理时，系统可能会将不常用的程序代码移入交换分区，以为活跃程序腾出更多内存。","categories":["1.平台","平台相关"]},{"title":"Apache和MySQL","path":"/2024/09/17/1-平台-服务器-Apache和MySQL/","content":"Web 的工作方式 Web 系统本质上是基于客户端服务器的架构，使得用户端（客户端）可以通过请求获取位于远程服务器上的资源。 在万维网（WWW）服务中，系统遵循 HTTP 协议，默认使用的 TCPIP 端口是 TCP 80，这意味着不需要在 URL 中指定端口，用户可以直接输入网址即可访问。 客户端与服务器之间的通信过程如下： Web Client 发送 HTTP 请求 到服务器，服务器收到请求后进行处理。 服务器响应 HTTP 应答，将结果返回给客户端，通过 Internet 完成信息的交互。 ASF（Apache 软件基金会） 早期版本的 Apache 服务器是由一个名为 Apache Group 的团队来维护。随着时间的发展，Apache 软件基金会（Apache Software Foundation，简称 ASF）于 1999 年成立，旨在支持开源软件项目。 ASF 维护着包括 Apache HTTP Server 在内的多个开源项目，例如 Perl、PHP、Java、Tcl 和 XML 等，这些项目广泛应用于开发和服务器管理中。 ASF 的官方网站是 http://www.apache.org，用户可以在此找到所有与 Apache 相关的资源和文档。 Apache 的特性－1.3 版本 Apache 1.3 版本引入了动态共享对象（DSO）功能，允许服务器在运行时动态地加载不同的功能模块，以增强服务器的灵活性。 通过采用预生成模式的技术，Apache 1.3 极大地提高了响应速度，使网站访问更加流畅。 支持最新的 HTTP 1.1 协议，其中包括更好的连接管理和扩展功能，促进了更复杂的网络应用。 配置方面也非常友好，简单而强大的基于文件的配置让用户能够轻松定制服务器环境。 支持虚拟主机功能，使得在同一个服务器上能够同时运行多个网站。 提供 HTTP 认证功能，保护敏感数据与资源。 支持许多第三方软件开发者提供的功能模块，用户可以根据需求扩展 Apache 的功能。 Apache 的特性－2.0 版本 Apache 2.0 几乎继承了 1.3 版本的所有特性，并进行了多项改进。 新增的组件——Apache Portable Runtime（APR），进一步提升了 Apache 的跨平台性能，允许开发者在不同平台上保持相似的行为。 2.0 版本引入了新的多处理模块（Multi-Processing Module，简称 MPM），el 通过它可以控制 Apache 在处理多个请求时的运行方式。Apache 可以采用三种处理模式： 预派生（Prefork）MPM：这是 Red Hat 9.0 及后续版本的默认模式，适合需要较高兼容性的情况； 工作者（Worker）MPM：相比 Prefork MPM，更加高效，适合同时处理大量连接； 独立子进程（Perchild）MPM：为每个请求分配独立的工作进程，从而增强了安全性。 安装和启动 Apache 安装 Apache 2.0 的命令如下： # rpm -ivh httpd-2.0.40-21.i386.rpm# rpm -ivh httpd-manual-2.0.40-21.i386.rpm 启动、停止和重启 Apache 的方法： # service httpd start # 启动服务# service httpd stop # 停止服务# service httpd restart # 重启服务# service httpd status # 检查服务状态# pstree | grep httpd # 查看当前 Apache 进程 检测 Apache 配置文件语法的正确性，可以使用以下命令： # apachectl configtest Apache 配置文件 配置文件的默认所在目录为： /etc/httpd/conf/ Apache 的主配置文件名为 httpd.conf，用户可以在该文件中修改各种设置以优化其服务器。 Apache 的基本配置 KeepAlive:开启此选项允许一个连接上发送多个请求。这样可以显著减少连接开销，提升浏览效率，因为避免了为每个请求都建立新的连接。 MaxKeepAliveRequests:设定每个连接中可以发送的最多请求数量。设置为 0，则没有限制，默认值为 100。 KeepAliveTimeout:此设置衡量在两个连续请求间的最大间隔时间（以秒为单位），若超过此时间，则视为连接断开。 MaxClients:限制在同一时间内可接入的最大连接数量。该值过高可能会影响服务器性能，默认设置为 150。 MinSpareServers 和 MaxSpareServers:设置空闲 httpd 进程的数量，保证始终有一定数量的空闲进程以应对快速增长的连接请求。若空闲进程少于 5，则会自动增加到 5，若超过 20 则减少到 20。 StartServers:定义 Apache 启动时初始的 httpd 进程数，默认值是 8。 ServerName:配置服务器的主机名，该名称将在远程连接中显示。默认情况下，这个名称是 localhost。 ServerAdmin:这里填写的是服务器管理员的邮件地址。当服务器发生错误时，可以向此邮件发送通知。 ServerRoot:指定 Apache 的配置文件和日志文件存放的路径，默认是 /etc/httpd。 DocumentRoot:该项设定 Apache 给定的网页文档根目录，所有网站文件应放在此目录或其子目录中。 Listen:用于设置 Apache 监听的端口，默认是 80 端口。 User Group:这两个选项分别设置 Apache 的执行用户和用户组。默认情况下，Apache 使用 apache 用户和 apache 组。 DirectoryIndex:用于指定当目录中没有特定文件时的默认索引文件列表。例如： DirectoryIndex index.html index.htm Options:此选项包括多种设置，例如： Indexes：当指定文件找不到时，生成目录列表。 FollowSymLinks：允许查询不在当前目录中的文件。 IndexOptions:提供用户自定义目录列表的方式，包括样式和排序功能，例如： FancyIndexing：为目录中的文件添加小图标以表示类型。 VersionSort：对文件版本进行排序。 **NameWidth***：自动调整文件名字段的宽度以适应最长文件名。 FoldersFirst：在列出目录的时候将文件夹优先展示。 配置 Apache－容器指令 容器指令通常包括在 ... / 的括号内。这些容器可以为配置提供更具体的上下文和控制。例如： Directory：用于设置特定目录的配置。 Files：用于设置特定文件的配置。 Location：用于设置 URL 路径的配置。 VirtualHost：为虚拟主机提供配置。 配置每个用户的 Web 站点要为每个用户配置 Web 站点，请遵循以下步骤： 修改主配置文件，以启用个别用户站点的配置。 修改主配置文件，配置每个用户站点目录的访问控制。 在用户的家目录下创建其网站的目录及相关网页文件。 UserDir 配置语句示例： UserDir disable root # 禁止 root 用户使用个人站点UserDir public_html # 指定每个用户的站点目录 组织和管理站点内容 符号链接：符号链接允许将存放在根文档目录之外的内容引入到站点中，可以通过以下命令实现： # cd /var/www/html# ln -s /usr/share/doc doc # 将 /usr/share/doc 目录链接到当前目录 别名：别名功能如下： 允许将根文档目录以外的内容加入到站点。 简化用户访问站点内复杂且深层的 URL。示例配置： Alias /ftp /var/ftp/pub # 将 /ftp URL 映射到 /var/ftp/pub 目录 配置访问控制 访问控制的配置指令:通过以下指令细化访问规则： Order：定义何时执行允许访问和拒绝访问的规则。 Deny：建立拒绝访问的列表。 Allow：建立允许访问的列表。 Order 指令的两种形式： Order Allow,Deny：先执行允许规则，再执行拒绝规则，默认为拒绝所有未明确允许的访问。 Order Deny,Allow：先执行拒绝规则，再执行允许规则，默认为允许所有未明确拒绝的访问。 Deny 和 Allow：在这两个指令下列出具体的访问列表。访问列表可使用如下形式定义： All：允许所有客户访问。 域名：如 jamond.net，允许域内的所有客户访问。 IP 地址：允许具体或部分的 IP 地址。 网络子网掩码：如 192.168.1.0/255.255.255.0。 CIDR 规范：如 192.168.1.0/24。 使用.htaccess 文件分割配置任务 何时使用 .htaccess 文件：当需要在多个用户之间分割配置，或希望实现不需要重启服务器的配置变更时，可以使用此文件。 启用并控制使用 .htaccess 文件的选项： AccessFileName .htaccessAllowOverride All # 控制允许在 .htaccess 文件中使用的指令 认证指令 认证相关的配置指令可以出现在主配置文件的 Directory 容器中，也可以在 .htaccess 文件中定义。以下是 Apache 的认证配置指令： 指令 指令语法 说明 AuthName AuthName 领域名称 定义受保护领域的名称 AuthType AuthType Basic 或 Digest 定义使用的认证方法 AuthGroupFile AuthGroupFile 文件名 指定认证组的口令文件位置 AuthUserFile AuthUserFile 文件名 指定认证用户的口令文件 授权指令在使用认证指令后，需为特定用户或组进行授权。Require 指令有三种使用格式： 指令语法格式 说明 Require user 用户名 [用户名] … 授权给指定的一个或多个用户 Require group 组名 [组名] … 授权给指定的一个或多个组 Require valid-user 授权给认证口令文件中的所有用户 管理认证用户口令文件和认证组文件 创建新的认证口令文件: # htpasswd -c 认证口令文件名 用户名 修改认证口令文件: # htpasswd 认证口令文件名 用户名 认证口令文件格式:每一行格式如：用户名：加密的口令。 管理认证组文件:这是一个简单的文本文件，每一行的格式为 组名：用户名 用户名 …。 MySQL 简介 MySQL 是一种高效、多用户和多线程的中小型 SQL 数据库系统，由一个服务器守护进程 mysqld 和多个不同的客户端程序及库组成。 当前最新版本为 4.0.13，用户可通过官方网站 http://www.mysql.com 下载。 MySQL 的主要特点包括： 支持多平台运行，用户可以在 Windows、Linux 等多种操作系统上使用 MySQL。 提供对多种数据库的支持，能够及时满足用户的多样需求。 支持多语言开发，开发者可以使用如 PHP、Python、Java 等多种语言与 MySQL 进行交互。 拥有非常完善的权限系统，可以高效地管理用户和权限。 安装和启动 MySQL 安装 MySQL 的步骤如下： # rpm -ivh perl-CGI-2.81-88.i386.rpm# rpm -ivh perl-DBI-1.32-5.i386.rpm# rpm -ivh mysql-3.23.54a-11.i386.rpm perl-DBD-MySQL-2.1021-3.i386.rpm# rpm -ivh mysql-server-3.23.54a-11.i386.rpm 启动、停止和重启 MySQL 服务器的命令： # service mysqld start # 启动数据库服务# service mysqld stop # 停止数据库服务# service mysqld restart # 重启数据库服务 在 Apache 上运行 CGI 程序 CGI（公共网关接口）：这是一种广泛应用于构建动态 Web 站点的技术，它最初由 NCSA（国家超级计算机应用中心）开发。CGI 定义了服务器如何与生成动态内容的程序交互，常用的编程语言包括 Perl 和 C。 在 Apache 上可以使用 mod_cgi 模块来运行这些 CGI 程序。 配置动态网站Apache + MySQL + PHP这种组合拓展了 Web 服务器的功能，形成了如下架构： Internet 使用者 - WebServer(Apache) - PHP - 数据库/网络功能/其他功能库 在 Apache 上安装和运行 PHP 安装 PHP 时所需的命令为： # rpm -ivh curl-7.9.8-5.i386.rpm# rpm -ivh gd-1.8.4-11.i386.rpm# rpm -ivh php-4.2.2-17.i386.rpm# rpm -ivh php-imap-4.2.2-17.i386.rpm# rpm -ivh php-mysql-4.2.2-17.i386.rpm PHP 作为 Apache 的一个模块运行，只需启动 Apache 即可自动加载，不需额外手动启用。 phpMyAdmin phpMyAdmin 是一种用 PHP 编写的基于 Web 的 MySQL 管理工具，为用户提供了图形化界面来管理 MySQL 数据库，用户可以通过访问 phpmyadmin.sourceforge.net 下载工具。 安装过程中，需解压和修改配置文件 config.inc.php 中的设置： $cfg[Servers][$i][auth_type] = http; $cfg[Servers][$i][password] = yourmysqlrootpasswd; Apache 上的虚拟主机 虚拟主机 是指在同一台服务器上实现多个网站，通过如下方式实现： 不同的虚拟主机可以指向不同的 IP 地址和端口号。 不同的虚拟主机通过不同的主机头（即域名）识别。 虚拟主机配置指令虚拟主机配置中常用的指令包括： ServerAdmin：指定虚拟主机管理员的 E-mail 地址； DocumentRoot：定义虚拟主机的根文档目录； ServerName：设置虚拟主机的名称及其所用的端口号； ErrorLog：指定虚拟主机的错误日志存放路径； CustomLog：指定虚拟主机的访问日志存放路径。 还可以在 VirtualHost 容器中使用 Directory 容器进行对目录的进一步访问控制配置。 配置虚拟主机 可以根据需要配置相同 IP 但不同端口号的虚拟主机，不同 IP 但相同端口号的虚拟主机，或者基于域名的虚拟主机。 通过这些配置，用户能够有针对性地优化自己的 Apache 服务器设置，以确保在各种环境下都能稳定、高效地运行各类 Web 应用与服务。","categories":["1.平台","服务器"]},{"title":"Obsidian在ios端利用git 同步","path":"/2024/09/16/1-平台-服务器-Obsidian在ios端利用git-同步/","content":"在 Apple Store 下载并安装 iSH 应用程序。iSH 是一个基于 Alpine Linux 的终端模拟器，允许用户在 iOS 设备上使用 Linux 环境。 打开已安装的 iSH 应用程序，并按照以下步骤执行命令： 安装 GitGit 是一个广泛使用的版本控制系统，它帮助开发者管理和跟踪文件的变化。在终端中输入以下命令以安装 Git： apk add git 这条命令会从 Alpine 软件包管理器（apk）中下载安装 Git。 创建名为 “obsidian” 的新文件夹通过下面的命令，可以在当前用户的主目录下创建一个新的文件夹，这个文件夹将用于存储与 Obsidian 相关的数据： cd ~ mkdir obsidian 这里的 cd ~ 切换到主目录，mkdir obsidian 则创建一个名为 “obsidian” 的新文件夹。 装载本地的 obsidian 文件夹到 iSH输入以下命令会打开手机的文件管理器，让选择本地存储中的 obsidian 文件夹。选择后点击完成，这一步骤确保 Obsidian 软件中的 “math” 文件夹与 iSH 上的 obsidian 文件夹相互连接。这样，在 Obsidian 中对 “math” 文件夹的任何修改都将及时同步到 iSH 环境中： mount -t ios . obsidian 进入 obsidian 文件夹输入以下命令切换到刚才创建的 obsidian 文件夹中： cd ~/obsidian 这一步使可以在 iSH 中查看和操作该文件夹内的文件。 克隆 Git 仓库到 obsidian 目录将的 Git 仓库克隆到 obsidian 文件夹中，输入以下命令并在提示时输入的 GitHub 账号和个人访问密钥（personal access token）： git clone https://xxxxxx.git 确保将 https://xxxxxx.git 替换为的实际 Git 仓库 URL。成功后，就能看到仓库中的所有文件在 obsidian 文件夹里。 打开 Obsidian 并配置 Git 账号密码启动 Obsidian 后，将看到之前克隆下来的仓库文件。接下来，打开 Obsidian 的 Git 设置，并输入的 Git 账号和密码。这一步是为了确保任何在 Obsidian 中进行的更改都能通过 Git 进行版本控制及同步，从而更好地管理工作。","tags":["clippings"],"categories":["1.平台","服务器"]},{"title":"WordPress搭建","path":"/2024/09/13/1-平台-服务器-博客-WordPress搭建/","content":"搭建 WordPress 网站在准备工作后首先是部署 LNMP 环境，LNMP 环境的部署详见 LNMP环境 MySQL 数据库配置首先，使用 root 用户登录到 MySQL 数据库。确保输入的是在搭建环境时为数据库设置的密码。可以通过以下命令登录： mysql -uroot -p 为 WordPress 网站创建数据库在 MySQL 中创建一个新的数据库，以便存放 WordPress 网站的数据。本教程中，数据库名称为 wordpress。执行以下 SQL 命令： create database wordpress; 创建新用户管理 WordPress 库为了提高安全性，创建一个新的用户来管理 WordPress 数据库。从 MySQL 5.7 版本开始，系统默认启用密码强度验证插件 validate_password。可以通过以下命令查看当前的密码强度规则： show variables like %password%; 在本教程中，将创建一个用户名为 user 的新用户，密码设置为 PASSword123.。执行以下命令创建新用户： create user user@localhost identified by PASSword123.; 接着，赋予新用户对 wordpress 数据库的所有权限： grant all privileges on wordpress.* to user@localhost; 为了使配置生效，执行： flush privileges; 最后，退出 MySQL 系统： exit; WordPress 配置接下来，下载 WordPress 并将其移动到网站根目录。首先，进入 Nginx 网站根目录，下载 WordPress 的压缩包。本示例中下载的是英文版本： cd /usr/share/nginx/htmlwget https://wordpress.org/wordpress-5.4.2.zip 如果需要安装 WordPress 的中文版本，则可以使用以下命令： wget https://cn.wordpress.org/latest-zh_CN.zip 请注意，后续操作中，需要将压缩包的文件名替换为 latest-zh_CN.zip。 解压 WordPress 压缩包： unzip wordpress-5.4.2.zip 在 WordPress 安装目录下，将 wp-config-sample.php 文件复制为 wp-config.php，并将原文件作为备份： cd /usr/share/nginx/html/wordpresscp wp-config-sample.php wp-config.php 接下来，编辑 wp-config.php 文件以添加数据库连接信息： vim wp-config.php 按 i 键切换至编辑模式，并根据已配置的 WordPress 数据库信息，修改以下 MySQL 相关配置： // ** MySQL 设置 - 具体信息来自正在使用的主机 ** ///** WordPress数据库的名称 */define(DB_NAME, wordpress);/** MySQL数据库用户名 */define(DB_USER, user);/** MySQL数据库密码 */define(DB_PASSWORD, PASSword123.);/** MySQL主机 */define(DB_HOST, localhost); 完成后，按下 Esc 键并输入 :wq，然后按回车键保存并退出配置文件。 Nginx 配置接下来，需要修改 Nginx 的配置文件以适配 WordPress。使用以下命令打开 Nginx 配置文件： vi /etc/nginx/conf.d/default.conf 在文件中按 i 键进入编辑模式，找到 location / 大括号内的 root 指令，将其替换为 WordPress 的根目录。例如： root /usr/share/nginx/html/wordpress; 同时，在 location ~ \\.php$ 大括号内，做相同的修改。完成后，按 Esc 键输入 :wq 保存并退出。 最后，重启 Nginx 服务以使配置生效： systemctl restart nginx 安装并登录 WordPress访问 https://localhost:80 ，这将引导进入 WordPress 的安装页面。按照说明填写网站的基本信息，然后单击”安装 WordPress”按钮。填写信息参数说明： 站点标题： WordPress 网站的名称，例如：demowp。 用户名：用于登录 WordPress 的用户名，建议选择安全性高的名称，例如：testwp。 密码：登录 WordPress 所需的密码，强烈建议使用安全性高的密码，例如：Wp.123456。 的电子邮件：用于接收重要通知的电子邮件，例如：1234567890@aliyun.com。 完成信息填写后，单击”登录”按钮。输入刚刚设置的用户名和密码，成功后将进入 WordPress 的管理后台。 其他问题WordPress 中设置固定链接后，跳转页面无法访问。为了让搜索引擎更好地收录的网站，建议在 WordPress 中设置伪静态链接。但在设置固定链接之前，需要在 Nginx 服务器中配置伪静态规则。打开 Nginx 配置文件： vi /etc/nginx/conf.d/default.conf 按 i 键进入编辑模式，在 location / 大括号内，添加以下代码： if (-f $request_filename/index.html)\trewrite (.*) $1/index.html break;if (-f $request_filename/index.php)\trewrite (.*) $1/index.php;if (!-f $request_filename)\trewrite (.*) /index.php; 保存退出文件后重启 Nginx 服务： systemctl restart nginx WordPress 中更新版本、上传主题或插件时，提示需要 FTP 登录凭证或无法创建目录。打开 WordPress 的配置文件： vim /usr/share/nginx/html/wordpress/wp-config.php 在文件的最下方，添加以下代码： define(FS_METHOD,direct);define(FS_CHMOD_DIR, 0777);define(FS_CHMOD_FILE, 0777); 保存并退出配置文件。返回 WordPress 仪表盘，刷新页面。这将有助于解决需要输入 FTP 登录凭证的问题。如果问题依然存在，可能需要更新 WordPress 网站根目录的权限，将其用户更新为 Nginx 对应的用户。在本示例环境中，这个用户是 nginx： chown -R nginx /usr/share/nginx/html/wordpress","categories":["1.平台","服务器","博客"]},{"title":"davfs2挂载webdav作为本地磁盘","path":"/2024/09/12/1-平台-服务器-工具-davfs2挂载webdav作为本地磁盘/","content":"Linux 使用 davfs2 挂载 webdav 作为本地磁盘并实现自动挂载当使用的操作系统硬盘容量有限时，例如在一些轻量级的设备或虚拟机上，除了添加物理或虚拟磁盘以增加存储空间之外，还有一个高效且经济的解决方案，即通过 WebDAV 来挂载网络磁盘。这种方式不仅成本低廉，而且灵活性高，适用性广泛。目前市场上有多种支持 WebDAV 的云存储服务，比如 Infini Cloud（注册时使用邀请码 32VVG 可获得额外 5GB 的空间），以及很多自建网盘程序，如 Cloudreve。同时，Alist 这种工具也可以将大部分云存储服务转换成 WebDAV 的形式。综上所述，利用 WebDAV 挂载网络磁盘的方式是一个值得考虑的选择。 使用 davfs2 挂载网盘1. 安装 davfs2在安装之前，请确保系统更新到最新版本。然后根据使用的 Linux 发行版，选择相应的命令来安装 davfs2： # CentOS 系统yum install davfs2# Ubuntu/Debian 系统apt install davfs2 2. 创建挂载目录首先，创建一个用于挂载 WebDAV 的目录。这可以是任何位置，但建议选择一个简洁明了的路径，例如： mkdir /path/webdav 这个目录将作为 WebDAV 内容的载体，所有通过 WebDAV 访问的文件都会展现于此。 3. 挂载 WebDAV要挂载 WebDAV，你需要运行以下命令，记得将 URL 替换为实际的 WebDAV 地址： mount -t davfs https://webdav.drive.com/dav /path/webdav 执行此命令后，系统将提示输入 WebDAV 的用户名和密码。建议提前查阅你的网盘官网或文档，以确保输入的信息准确无误。 完成后，使用 df -h 命令检查当前挂载状态。此命令将显示所有挂载的文件系统及其使用情况，确保你的 WebDAV 已成功挂载。 配置开机自动挂载如果每次重启后都需手动执行挂载命令，显然会造成不便。为了实现开机自动挂载，可以配置 davfs2 的相关文件，并利用 systemd 服务来简化这一过程。 1. 修改 davfs2.conf 配置文件使用文本编辑器打开 davfs2 的主配置文件： nano /etc/davfs2/davfs2.conf 在配置文件中找到 use_locks 参数，将其值从 1 修改为 0。这一修改的目的是关闭锁定机制，以避免在挂载时的潜在冲突。 2. 修改 davfs2 的 secrets 文件，添加认证信息接下来，添加 WebDAV 的认证信息。打开 secrets 文件： nano /etc/davfs2/secrets 在文件的末尾，添加以下内容以提供 WebDAV 地址及其对应的用户名和密码： https://webdav.drive.com/dav 用户名 密码 确保信息无误，这样可以在系统启动时自动完成身份验证。 3. 配置 systemd 文件为了使 WebDAV 在每次启动时自动挂载，需要创建一个 systemd 服务文件。以 /path/webdav 作为挂载点，创建名为 path-webdav.mount 的配置文件： nano /etc/systemd/system/path-webdav.mount 建议遵循命名约定，通常挂载单元文件的名称与要挂载的路径相匹配，比如 /mnt/data 挂载点的单元文件应命名为 mnt-data.mount。 在文件中输入以下内容： [Unit]Description=Mount WebDAV ShareAfter=network-online.targetWants=network-online.target[Mount]What=https://webdav.drive.com/dav # 根据实际情况修改Where=/path/webdav # 根据实际情况修改Type=davfs Options=_netdev,users,rw[Install]WantedBy=multi-user.target 保存文件后，重新加载 systemd 的配置，以确保新设置生效： systemctl daemon-reload 接下来，启用此挂载单元，使其在每次启动时都自动挂载： systemctl enable path-webdav.mount 重新启动系统后，再次使用 df -h 命令检查，观察 WebDAV 是否已成功挂载。这一过程确保在系统重启后，网络磁盘能够自动连接，无需手动干预。","categories":["1.平台","服务器","工具"]},{"title":"flask框架对接微信公众号","path":"/2024/09/11/1-平台-服务器-微信-flask框架对接微信公众号/","content":"使用说明第一步：找一台具有公网 IP 的服务器首先，确保有一台可以连接互联网并具有公网 IP 的服务器。这台服务器将用于部署 Flask 应用，并接收来自微信公众平台的请求。服务提供商如阿里云、腾讯云或 AWS 等都可以为提供这样的服务器。 第二步：安装 Python3，搭建 nginx+uwsgi+flask 环境使用 SSH 连接到的服务器后，执行以下命令来安装 Python3 及所需的软件： sudo apt updatesudo apt install python3 python3-pip nginxpip3 install flask uwsgi 安装完毕后，需要配置 nginx 和 uwsgi，使得它们能够协同工作。 创建 uwsgi 配置文件。例如，命名为 myapp.ini： [uwsgi]module = wsgi:appmaster = trueprocesses = 5socket = myapp.sockchmod-socket = 660vacuum = truedie-on-term = true 在 nginx 中配置网站，编辑 /etc/nginx/sites-available/default，加入如下内容： server listen 80; server_name wechat_pro.lehuoha.com; location / include uwsgi_params; uwsgi_pass unix:/home/wechat_pro/myapp.sock; 完成以上步骤后，确保 nginx 和 uwsgi 服务都已经启动。 第三步：在 PyCharm 上配置 Deployment在 PyCharm 中，将本地代码直接上传到服务器： 新建项目在 PyCharm 中新建项目，命名为 wechat_pro。确保的项目结构和将要在服务器上部署的一致。 设置 Deployment导航到 Tools - Deployment - Configuration，选择相应的连接方式，例如 FTP 或 SFTP。这里以 SFTP 为例： Connection Name: 开发测试服务器 Host: 输入的公网 IP 地址 Username: 输入的服务器登录名 Password: 输入的密码 点击”测试链接”确认连接成功。 映射本地与服务器路径在配置中设置本地目录与服务器目录路径的映射，确保甚至更新文件时本地代码能够上传到服务器的指定目录，如 /home/wechat_pro/。 第四步：nginx 配置文件中设置域名，配置好域名解析确保已经在域名服务提供商处配置好 DNS 解析，将 wechat_pro.lehuoha.com 指向的服务器公网上的 IP 地址。接下来，使用以下配置更新 nginx： server listen 80; server_name wechat_pro.lehuoha.com; location / include uwsgi_params; uwsgi_pass unix:/home/wechat_pro/myapp.sock; 保存配置文件后，使用命令重启 nginx 服务： sudo systemctl restart nginx app.py 文件代码 (注意文件权限)接下来，在 /home/wechat_pro/ 目录下创建 app.py 文件，内容如下。请确保文件权限设置正确，以便 web 服务能够执行。 #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flaskapp = Flask(__name__)@app.route(/)def index(): return hello world！if __name__ == __main__: app.run(host=0.0.0.0, port=80, debug=True) 确保这个文件有执行权限： chmod +x /home/wechat_pro/app.py 通过访问 http://wechat_pro.lehuoha.com 应该能看到”hello world！”的返回。 微信公众号开发对接在完成服务器配置后，进入微信公众平台官网，并登录到的公众号管理界面： 设置接口配置信息在后台的”开发者中心”中点击”修改配置”按钮。 URL: 填写的服务器地址，例如 http://wechat_pro.lehuoha.com/. Token: 填写一个自定义的安全 Token（例如：wechat_pro），这个值将在后续的请求校验中被使用。 EncodingAESKey: 由随机生成或手动填写，用于消息体加解密。 选择加解密方式确保选定的加解密方式准确。默认设置是明文模式，其他两种模式下需要预先做好代码配置。 在配置完成后，微信服务器会发送一个 GET 请求到指定的 URL，并携带以下四个参数： 参数 描述 signature 微信加密签名，结合 Token、timestamp 和 nonce 生成。 timestamp 请求发送的时间戳 nonce 随机数 echostr 随机字符串，在成功验证时返回该值 开发者的任务是校验这个请求的合法性。若请求的 signature 与自己程序生成的 signature 一致，则返回 echostr 以完成接入，否则返回错误信息。 Python 代码实现如下： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibapp = Flask(__name__)@app.route(/)def index(): token = wechat_pro data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 字典排序并 SHA-1 加密 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403if __name__ == __main__: app.run(host=0.0.0.0, port=8000, debug=True) 注意通常会遇到的错误是：”TypeError: Unicode-objects must be encoded before hashing”，这个错误主要是由于在进行 hash 加密时未指定编码。文中的 temp.encode(utf8) 是为了解决这个问题。 一旦接入成功，可以在测试平台网页上看到”配置成功”的提示信息。 公众号接收与发送消息1. 接收普通消息当普通微信用户向公众账号发送消息时，微信服务器将以 POST 方式将消息的 XML 数据包发送到开发者事先填写的 URL 地址。微信服务器会在五秒内无响应的情况下，会自动重试最多三次。开发者应该保证在五秒内处理完请求。 收到的消息使用 XML 数据包格式： xml ToUserName![CDATA[gh_866835093fea]]/ToUserName FromUserName![CDATA[ogdotwSc_MmEEsJs9-ABZ1QL_4r4]]/FromUserName CreateTime1478317060/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[好]]/Content MsgId6349323426230210995/MsgId/xml 注意：使用 ![CDATA[ ... ]] 保护的内容不会被 XML 解析器解析。 普通消息类别 文本消息 图片消息 语音消息 视频消息 小视频消息 地理位置消息 链接消息 2. 文本消息当接收到文本消息时，其 XML 数据格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1348831860/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[this is a test]]/Content MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，文本为 text Content 文本消息内容 MsgId 消息的 ID 3. 被动回复消息开发者可以在处理用户的消息后，返回特定格式的 XML 数据包，以便进行响应。支持的消息类型有文本、图片、语音等。当接收请求后，需要在 5 秒内做出响应，否则微信会对用户发送提示。 例如，回复文本消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[好]]/Content/xml 参数 是否必须 描述 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者微信号 CreateTime 是 消息创建时间 （整型） MsgType 是 消息类型，文本为 text Content 是 回复的消息内容 确保正确响应用户的消息，以体现良好的用户体验。 4. 代码实现在与微信服务器的交互过程中，们通过 HTTP 请求处理不同类型的请求。若接收到 GET 请求，系统会进行服务器验证，这一部分处理与上一步的逻辑相似，旨在确保请求来源的合法性。另一方面，若接收到 POST 请求，则需要进一步解析和处理请求内容。 基本的业务逻辑遵循”鹦鹉学舌”原则：用户发送的任何文本信息，系统会自动返回相同的信息，确保用户能感受到互动的即时性和流畅性。 以下是代码的详细解析： # 根据请求方式进行判断if request.method == POST: # 获取微信服务器post过来的xml数据 xml = request.data # 将xml格式的数据进行处理，转换成字典形式以便提取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是否是文本 if text == req.get(MsgType): # 获取用户的信息，并开始构造响应数据 # 这里将用户发送的信息原封不动地返回，保持字典格式 resp = ToUserName: req.get(FromUserName), # 接收方的用户唯一标识 FromUserName: req.get(ToUserName), # 开发者微信号 CreateTime: int(time.time()), # 消息创建时间 MsgType: text, # 消息的类型 Content: req.get(Content) # 用户发送的内容 # 将构造的字典转换成xml格式以便返回 xml = xmltodict.unparse(xml: resp) # 返回构造好的XML数据 return xml else: # 如果消息类型不是文本，返回一条固定信息 resp = ToUserName: req.get(FromUserName, ), # 接收方的用户唯一标识 FromUserName: req.get(ToUserName, ), # 开发者微信号 CreateTime: int(time.time()), # 消息创建时间 MsgType: text, # 消息的类型 Content: I LOVE ITCAST # 固定的返回内容 xml = xmltodict.unparse(xml: resp) # 转换为XML格式 return xml 特别注意事项： QQ 表情、Emoji 表情及自定义表情的处理都需要认真对待。QQ 表情在技术上被视为文本消息，因其实际上是字符的转义。而 Emoji 表情也是 Unicode 字符，因此同样视为文本信息。至于自定义表情，它既不属于文本也不是图片，而是微信未提供处理的格式，开发者需谨慎应对。 完整代码示例： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibimport xmltodictimport timeapp = Flask(__name__)@app.route(/, methods=[GET, POST])def index(): if request.method == GET: # 设置token，开发者配置中使用 token = wechat_pro # 获取微信服务器发送过来的参数 data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 对参数进行字典排序并拼接字符串 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) # 加密 if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403 # 根据请求方式进行判断 if request.method == POST: # 获取微信服务器post过来的xml数据 xml = request.data # 将xml格式的数据进行处理，转换成字典形式以便提取值 req = xmltodict.parse(xml)[xml] if text == req.get(MsgType): resp = ToUserName: req.get(FromUserName), FromUserName: req.get(ToUserName), CreateTime: int(time.time()), MsgType: text, Content: req.get(Content) xml = xmltodict.unparse(xml: resp) return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml: resp) return xmlif __name__ == __main__: app.run(host=0.0.0.0, port=8000, debug=True) 5. 接收其他普通消息接收图片消息图片消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1348831860/CreateTime MsgType![CDATA[image]]/MsgType PicUrl![CDATA[this is a url]]/PicUrl MediaId![CDATA[media_id]]/MediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 image PicUrl 图片链接 MediaId 图片消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 MsgId 消息 ID，64 位整型 接收视频消息视频消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[video]]/MsgType MediaId![CDATA[media_id]]/MediaId ThumbMediaId![CDATA[thumb_media_id]]/ThumbMediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 video MediaId 视频消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 ThumbMediaId 视频消息缩略图的媒体 ID MsgId 消息 ID，64 位整型 接收小视频消息小视频消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[shortvideo]]/MsgType MediaId![CDATA[media_id]]/MediaId ThumbMediaId![CDATA[thumb_media_id]]/ThumbMediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 shortvideo MediaId 小视频消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 ThumbMediaId 小视频消息缩略图的媒体 ID MsgId 消息 ID，64 位整型 接收语音消息语音消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[voice]]/MsgType MediaId![CDATA[media_id]]/MediaId Format![CDATA[Format]]/Format MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 voice MediaId 语音消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 Format 语音格式，如 amr，speex 等 MsgId 消息 ID，64 位整型 注意：如果公众号已开通语音识别功能，当用户发送语音消息时，微信会在推送的语音消息 XML 数据包中增加一个 Recognition 字段。在这种情况下，格式字段会继续显示语音格式，其它系统不会受影响。 回复其他普通消息回复图片消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[image]]/MsgType Image MediaId![CDATA[media_id]]/MediaId /Image/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间（整型） MsgType 是 消息类型，值为 image MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 回复语音消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[voice]]/MsgType Voice MediaId![CDATA[media_id]]/MediaId /Voice/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间戳 （整型） MsgType 是 消息类型，值为 voice MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 回复视频消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[video]]/MsgType Video MediaId![CDATA[media_id]]/MediaId Title![CDATA[title]]/Title Description![CDATA[description]]/Description /Video/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间 （整型） MsgType 是 消息类型，video MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 Title 否 视频消息的标题 Description 否 视频消息的描述 可以使用微信提供的网页调试工具进行测试：https://mp.weixin.qq.com/debug/cgi-bin/apiinfo?t=index 关注取消关注事件当用户关注或取消关注公众号时，微信会推送相关事件到开发者设置的 URL。为了确保消息的可靠性，若微信服务器在五秒内未收到响应，它将断开连接并重新发起请求，总共会重试三次。开发者需注意，如果服务器无法保证在五秒以内处理完请求，可以直接回复一个空串，此时微信服务器不会发起重试。 接收关注事件的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[FromUser]]/FromUserName CreateTime123456789/CreateTime MsgType![CDATA[event]]/MsgType Event![CDATA[subscribe]]/Event/xml 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 event Event 事件类型，值为 subscribe（订阅）或 unsubscribe（取消订阅） 代码实现如下： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibimport xmltodictimport timeimport requestsimport jsonapp = Flask(__name__)@app.route(/, methods=[GET, POST])def index(): if request.method == GET: # 设置token, 开发者配置中心使用 token = wechat_pro # 获取微信服务器发送过来的参数 data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 对参数进行字典排序并拼接字符串 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) # 加密 if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403 if request.method == POST: xml = request.data req = xmltodict.parse(xml)[xml] MsgType = req.get(MsgType) if text == MsgType: resp = ToUserName: req.get(FromUserName), FromUserName: req.get(ToUserName), CreateTime: int(time.time()), MsgType: text, Content: 这是一个文本消息！ elif event == MsgType: if subscribe == req.get(Event): resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: u感谢的关注！ else: resp = None else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: 无法识别该消息！ xml = xmltodict.unparse(xml: resp) return xmlif __name__ == __main__: app.run(host=0.0.0.0, port=80, debug=True) 微信网页授权要实现一个在微信内访问的网页，该网页能够展示微信用户的个人信息，用户必须授权才能访问这些数据。授权后，开发者服务器会接收到一个”授权书”（code），利用这个 code 向微信服务器请求访问令牌（access_token）以及用户的身份号码（openid）。之后，开发者可以使用 access_token 和 openid 提取用户的个人信息。 流程概览 用户同意授权，获取 code 通过 code 换取网页授权 access_token 拉取用户信息（需 scope 为 snsapi_userinfo） 如何获取授权 code？用户授权的过程由微信发起。用户首先需要访问微信的授权链接。如果用户同意授权，微信将用户重定向到开发者指定的网页，附带 code 参数。这一过程被称为网页回调，类似于程序编写中的回调函数，都是通过回调的方式进行信息交互。 1. 设置网页授权回调域名在请求用户网页授权之前，开发者需要登录微信公众号平台，在开发者中心配置授权回调域名。注意，填入的应为域名的字符串形式，不能包含 http: 等协议前缀。例如，如果需要进行网页授权的域名是 www.qq.com，则配置后，该域名下的任何页面，例如： http://www.qq.com/music.html http://www.qq.com/login.html 都可以进行 OAuth2.0 授权。但是，如下域名则无法进行 OAuth2.0 鉴权： http://pay.qq.com http://music.qq.com http://qq.com 2. 用户同意授权，获取 code开发者应引导用户访问以下链接： https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPIDREDIRECT_URIresponse_typecodescopeSCOPEstateSTATE#wechat_redirect 当 scope 设置为 snsapi_userinfo 时，用户将看到授权页面。如果用户选择同意，页面将重定向至 redirect_uri/?code=CODEstate=STATE；如果用户拒绝，则将重定向至 redirect_uri?state=STATE，此时不会附带 code 参数。 3. 通过 code 换取网页访问 access_token请求方法 向微信服务器发起请求： https://api.weixin.qq.com/sns/oauth2/access_token?appidAPPIDsecretSECRETcodeCODEgrant_typeauthorization_code 参数说明 在请求中，需提供对应的参数，即 appid、secret、code 和 grant_type。 返回值 成功时，微信服务器返回的 JSON 数据如下： access_token: ACCESS_TOKEN, expires_in: 7200, refresh_token: REFRESH_TOKEN, openid: OPENID, scope: SCOPE 如果请求出现错误，比如 code 无效，微信会返回如下 JSON 数据： errcode: 40029, errmsg: invalid code 4. 拉取用户信息 (需 scope 为 snsapi_userinfo)请求方法 使用以下格式请求用户信息： https://api.weixin.qq.com/sns/userinfo?access_tokenACCESS_TOKENopenidOPENIDlangzh_CN 参数说明 此请求 2 需要提供 access_token 和 openid 的参数。 返回值 如果请求成功，返回的 JSON 数据格式如下： openid: OPENID, nickname: NICKNAME, sex: 1, province: PROVINCE, city: CITY, country: COUNTRY, headimgurl: http://wx.qlogo.cn/mmopen/g3MonUZtNHkdmzicIlibx6iaFqAc56vxLSUfpb6n5WKSYVY0ChQKkiaJSgQ1dZuTOgvLLrhJbERQQ4eMsv84eavHiaiceqxibJxCfHe/46, privilege: [PRIVILEGE1, PRIVILEGE2], unionid: o6_bmasdasdsad6_2sgVt7hMZOPfL 如果出现错误，例如 openid 无效，返回如下 JSON 数据： errcode: 40003, errmsg: invalid openid","tags":["clippings"],"categories":["1.平台","服务器","微信"]},{"title":"公众号介绍","path":"/2024/09/10/1-平台-服务器-微信-公众号介绍/","content":"公众号类型订阅号 普通订阅号：普通订阅号是最基本的公众号类型，适合个人用户和小型企业用来发布信息和与用户互动。普通订阅号的功能相对简单，只能群发消息，每个用户在公众号列表中只能看到一条消息，无法发送服务消息。 认证订阅号：相比于普通订阅号，认证订阅号可以提供更多的接口和功能，比如自定义菜单、信息推送和品牌展示等。认证后，可以享受更高的用户信任度及服务质量。 服务号 普通服务号：针对中大型企业，具有较强的服务功能，比如提供更复杂的支付、客服以及信息推送功能。普通服务号每月只能群发 4 条消息，但更接近于用户的需求。 认证服务号：认证服务号是服务号的加强版，提供完整的 API 接口，支持更多复杂的应用，如企业内部管理、客户服务等。认证后，服务号可以定制更多增值服务和功能，适合需要广泛与用户进行互动的大型企业。 服务方式 公众号消息会话：这一功能允许公众号与用户之间进行消息的双向交流。包括被动回复，即用户主动发送信息后，公众号可以根据内容进行智能回复，这样可以极大提升用户体验。 公众号内嵌网页：通过内嵌网页，公众号可以直接提供一些服务，如在线商城、活动报名等，用户可以在微信中完成更多操作，无需跳转到外部浏览器。 公众号消息类型 群发消息：公众号可以定期向所有关注的用户发送一条消息，保持用户的活跃度和对品牌的关注。 被动回复消息：用户主动给公众号发送消息后，公众号可以在不主动发布内容的情况下，做出相应。这让用户与公众号的互动显得自然且流畅。 客服消息：当用户主动发消息到公众号，公众号在 48 小时内可以无限制地回复。这对于解决用户问题、提供支持以及加强客户关系至关重要。 模板消息：公众号可以利用特定的模板来向用户发送内容丰富的消息，比如订单状态更新、活动通知等，保持用户的系统性关注。 公众号的网页接口 接口 1：该接口能让网页获取用户的基本信息，简化用户的登录和交互体验。开发者需要在其网页中添加相关代码。 接口 2：微型 JS-SDK 允许开发者轻松使用微信的功能，比如拍照、录音、定位等，增强网页用户的互动体验。 微信公众号开发 先注册一个微信公众号：访问 注册页面，按步骤完成注册。 注册成功后的设置：登录后，进入微信公众号管理后台，进行公众号设置，包括上传头像、生成二维码以及设定公众号名称等。 微信号设置：设置后，用户可以通过微信号轻松找到的小程序。 注意事项：对接微信公众平台 填写服务器配置： URL：需设定为可访问的域名或直接的 IP 地址加端口，HTTP 需为 80 端口，HTTPS 则为 443 端口。 Token：用于生成签名，帮助微信服务器识别公众号的服务器。 EncodingAESKey：设置消息加解密密钥，确保消息安全。 验证服务器地址的有效性开发者需自行架设服务器。当填写 URL 并提交后，微信服务器发送 GET 请求到开发者的服务器，携带四个参数，用于验证。 校验流程 对 token、timestamp、nonce 三个参数进行字典序排序。 拼接字符串并进行 SHA1 加密。 比较加密后的字符串与微信返回的 signature，确认请求来源。 校验经典代码示例可以使用以下代码实现上述校验，适用于 Django、Flask、web.py 等框架： import hashlibdef handle(request): try: signature = request.get(signature) timestamp = request.get(timestamp) nonce = request.get(nonce) echostr = request.get(echostr) token = xxxx # 自定义token # 字典序排序 params_list = [token, timestamp, nonce] params_list.sort() temp = .join(params_list) # SHA1加密 sha1 = hashlib.sha1(temp.encode(utf-8)) hashcode = sha1.hexdigest() # 校验 if hashcode == signature: return echostr else: return except Exception as e: return str(e) 使用第三方包 wechatpy 实现通过 wechatpy 简化开发，可以通过如下代码实现： from wechatpy.utils import check_signaturefrom flask import Flask, requestapp = Flask(__name__)def get_all_args(req_dict): echostr = req_dict.get(echostr) signature = req_dict.get(signature) timestamp = req_dict.get(timestamp) nonce = req_dict.get(nonce) return echostr, signature, timestamp, nonce@app.route(/wechat_verify/, methods=[GET])def wechat_verify(): rq_dict = request.args if not rq_dict: return tuple_args = get_all_args(rq_dict) token = current_app.config.get(TOKEN) try: check_signature(token, tuple_args[1], tuple_args[2], tuple_args[3]) except InvalidSignatureException as e: logger.error(e, exc_info=True) return else: return tuple_args[0] 消息发送流程当普通用户向公众号发消息时，微信服务器会将消息以 XML 格式的 POST 数据包发送给开发者设定的 URL。此时，公众号可以覆盖微信提供的自动回复功能，实现更加个性化的响应。 基于 XML 的消息处理微信消息通信使用 XML 数据格式，可以使用 xmltodict 模块处理： **xmltodict.parse()**：将 XML 数据转换为 Python 字典。 **xmltodict.unparse()**：将字典转换为 XML 字符串。 消息格式示例 文本消息： xml ToUserName![CDATA[公众号]]/ToUserName FromUserName![CDATA[粉丝号]]/FromUserName CreateTime1460537339/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[欢迎开启公众号开发者模式]]/Content MsgId6272960105994287618/MsgId/xml 回复文本： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[好吗]]/Content/xml 图片消息： xml MsgType![CDATA[image]]/MsgType PicUrl![CDATA[this is a url]]/PicUrl MediaId![CDATA[media_id]]/MediaId/xml 视频消息： xml MsgType![CDATA[video]]/MsgType MediaId![CDATA[media_id]]/MediaId/xml 语音消息： xml MsgType![CDATA[voice]]/MsgType MediaId![CDATA[media_id]]/MediaId Format![CDATA[Format]]/Format/xml 视图处理原则建议将普通消息处理放在一个视图中进行判断和处理，简化视图数量。当处理时间超过 5 秒未完成时，先返回成功或空字符串，避免触发微信的错误处理机制。 实现内嵌网页内嵌网页的实现分为三个步骤： 用户同意授权，获取 code，这是用户的授权书。 通过 code 换取网页授权 access_token，这是微信下发的通信凭证。 拉取用户信息（需 scope 为 snsapi_userinfo）。 设置网页授权回调域名需填写域名，不包括 http:// 等前缀，也可填写 IP 和端口。 获取微信公众号 access_token 接口凭证访问接口： https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=APPIDsecret=APPSECRET 获取微信 IP 地址访问接口： https://api.weixin.qq.com/cgi-bin/getcallbackip?access_token=ACCESS_TOKEN 自定义菜单接口可以通过以下接口自定义微信公众号的菜单按钮： https://api.weixin.qq.com/cgi-bin/menu/create?access_token=ACCESS_TOKEN 支持定义不同的按钮类型，包括扫码、跳转网页等，增强用户参与度。 微信开发文档欲了解更多详细信息和最新更新，访问 微信开发文档。","categories":["1.平台","服务器","微信"]},{"title":"公众号消息推送","path":"/2024/09/09/1-平台-服务器-微信-公众号消息推送/","content":"步骤 1：注册微信公众号测试号注册微信公众号的第一步是访问 微信公众号平台的测试号申请页面。在这里，将能够创建一个测试号，以便进行开发和测试。 步骤 2：获取 appID 和 appsecret一旦成功注册，将能够在微信公众号平台的后台查看到相关的 appID 和 appsecret。这两个值是调用微信公众号接口的凭证，确保妥善保存。 步骤 3：获取 access_tokenaccess_token 是公众号调用各类接口的重要凭证，它的有效期为 2 小时。要最大化利用这个凭证，需要时刻监控它的有效期，并在过期后及时获取。特别注意的是，每天最多可获取 2000 次 access_token。 API 调用：获取 access_token 的接口如下： GET https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=APPIDsecret=APPSECRET 步骤 4：获取粉丝的 openidopenid 是关注公众号的用户的唯一标识。例如，如果想给某位粉丝发送消息，首先要通过接口获取他们的 openid。这可以通过以下方法调用： GET https://api.weixin.qq.com/cgi-bin/user/get?access_token=ACCESS_TOKENnext_openid=NEXT_OPENID 步骤 5：发送消息发送消息的接口如下： POST https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=ACCESS_TOKEN 下面是使用 “客服消息” 接口发送消息的代码示例。 # -*- encoding:utf-8 -*-import requestsimport jsonclass SendMessage(): def __init__(self): self.appID = xxxx self.appsecret = xxxx self.access_token = self.get_access_token() self.opend_ids = self.get_openid() def get_access_token(self): 获取微信公众号的access_token值 url = https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=secret=.format(self.appID, self.appsecret) headers = User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 response = requests.get(url, headers=headers).json() access_token = response.get(access_token) return access_token def get_openid(self): 获取所有粉丝的openid next_openid = url_openid = https://api.weixin.qq.com/cgi-bin/user/get?access_token=%snext_openid=%s % (self.access_token, next_openid) ans = requests.get(url_openid) open_ids = json.loads(ans.content)[data][openid] return open_ids def sendmsg(self, msg): 给所有粉丝发送文本消息 url = https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=.format(self.access_token) if self.opend_ids: for open_id in self.opend_ids: body = touser: open_id, msgtype: text, text: content: msg data = bytes(json.dumps(body, ensure_ascii=False).encode(utf-8)) response = requests.post(url, data=data) result = response.json() print(result) else: print(当前没有用户关注该公众号！) def upload_media(self, media_type, media_path): 上传临时文件到微信服务器，并获取该文件的media_id url = https://api.weixin.qq.com/cgi-bin/media/upload?access_token=type=.format(self.access_token, media_type) meida = media: open(media_path, rb) response = requests.post(url, files=meida) parse_json = json.loads(response.content.decode()) return parse_json.get(media_id) def send_media_to_user(self, media_type, media_path): 给所有粉丝发送媒体文件，媒体文件以media_id表示 media_id = self.upload_media(media_type, media_path) url = https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=.format(self.access_token) if self.opend_ids: for open_id in self.opend_ids: if media_type == image: body = touser: open_id, msgtype: image, image: media_id: media_id elif media_type == voice: body = touser: open_id, msgtype: voice, voice: media_id: media_id data = bytes(json.dumps(body, ensure_ascii=False).encode(utf-8)) response = requests.post(url, data=data) result = response.json() print(result) else: print(当前没有用户关注该公众号！)if __name__ == __main__: data = Hello,3Nod! sends = SendMessage() sends.sendmsg(data) sends.send_media_to_user(image, ./test.png) 功能说明 获取 access_token: get_access_token 方法根据 appID 和 appsecret 查询并返回 access_token，确保接口调用的顺利进行。 获取粉丝的 openid: get_openid 方法获取当前所有粉丝的 openid，以便后续可以发送消息。 发送文本消息: sendmsg 方法接收消息内容，利用 access_token 和粉丝的 openid 发送指定的文本消息。 上传媒体: upload_media 方法用于上传临时文件（如图片、音频等），并返回其 media_id 以便后续发送。 发送媒体文件: send_media_to_user 根据文件类型（图像或语音）准备相应的消息体，并将文件发送给所有粉丝。 通过这些步骤，能够有效地使用微信公众号的 API 实现与粉丝的互动，无论是发送简单的文本信息还是上传和分享多媒体内容。","categories":["1.平台","服务器","微信"]},{"title":"公众号配置","path":"/2024/09/06/1-平台-服务器-微信-公众号配置/","content":"微信公众号端配置需要配置公众号的相关信息，以确保能够接收微信的消息。在公众号管理后台，找到消息服务器设置，修改以下信息： URL: 填入的云服务器的 IP 地址，后面加上路径，如 /chatgpt。注意: 由于默认只能使用 80 端口，所以不要在 URL 后添加端口号。 Token: 这里填写之前设置的 token，以确保消息的安全接入。 EncodingAESKey: 随机生成一个字符串，用作消息加解密的密钥。 云服务器端配置基础配置 修改云服务的安全组，确保开放 80 端口。 服务端代码这里需要自定义处理用户发送过来的消息。首先，确保安装必要的依赖，werobot 是微信公众号官方推荐的用于自定义消息处理的模块。可以通过以下命令安装： pip install werobotpip install openai 下面是一个示例代码，展示了如何创建一个基础的微信机器人。 import werobot # token 是微信公众号用来指定接入当前云服务器的服务凭证，起到认证的作用robot = werobot.WeRoBot(token=123456) @robot.handler def hello(messages): # messages.content 是用户发送的消息内容 print(messages.content) return hello! # 配置机器人监听的主机和端口robot.config[HOST] = 0.0.0.0 robot.config[PORT] = 80 # 启动机器人robot.run() 运行时需要加上 sudo 在这段代码里，不管用户发送什么消息，机器人都会回复 “hello!”。通过更改 hello 函数里的返回值，可以自定义机器人的回复内容。 import werobot from openai import OpenAI# 设置 OpenAI 的 API 密钥client = OpenAI( # defaults to os.environ.get(OPENAI_API_KEY) api_key=YOUR API KEY, base_url=https://api.chatanywhere.tech/v1)# 初始化 WeRoBot 实例robot = werobot.WeRoBot() class RobotConfig(object): HOST=0.0.0.0 PORT=80 TOKEN=your token # 微信公众号的接入凭证robot.config.from_object(RobotConfig) # 非流式响应def generate_response(prompt): 为提供的对话消息创建新的回答 Args: messages (list): 完整的对话消息 messages = [role: user,content: prompt,] completion = client.chat.completions.create(model=gpt-3.5-turbo, messages=messages) return (completion.choices[0].message.content) @robot.handler def hello(messages): print(messages.content) return generate_response(messages.content) if __name__ == __main__: robot.run() #流式传输def gpt_35_api_stream(messages: list): 为提供的对话消息创建新的回答 (流式传输) Args: messages (list): 完整的对话消息 stream = client.chat.completions.create( model=gpt-3.5-turbo, messages=messages, stream=True, ) for chunk in stream: if chunk.choices[0].delta.content is not None: print(chunk.choices[0].delta.content, end=)if __name__ == __main__: # 流式调用 gpt_35_api_stream(messages) 这段代码集成了 ChatGPT 服务。机器人会对用户发送的每一条消息生成一个基于 ChatGPT 的响应。只需替换 的api_key 和 your token 为实际使用的密钥。 增加语音消息支持-待补充 语音消息识别转文字 文字输入以上 API 发送定时消息提醒-待补充爬取某页面并自动回复这是一个结合了 WeRoBot、OpenAI API 和网页爬取功能的微信自动回复机器人，以下是详细的功能模块和工作原理： 模块依赖 werobot：一个流行的微信机器人开发框架，它提供了接收和回复微信消息的接口，允许开发者快速建立与用户的互动。 openai：用于调用 OpenAI 的 API，例如 GPT-3.5，它能够生成高质量的文本响应，进行智能对话。 requests：一个专门用于发送 HTTP 请求的库，能方便地获取网页数据，例如获取网页的 HTML 内容。 BeautifulSoup：用于解析 HTML 数据的库，能够帮助提取网页中的有用信息，如特定的链接或文本。 pandas、re 和其他模块：虽然这些模块在本代码中未被使用，但通常用于数据处理、正则表达式匹配等功能，可以使数据操作更高效。 配置参数 headers：包含用户代理（User-Agent）、授权信息（Authorization）和 Cookies，可以模拟一个正常用户的浏览行为，例如避免被网站的防爬虫机制阻止。 OpenAI 客户端：配置 API key 和 base URL，以便正确调用 OpenAI 的服务。 WeRoBot 实例：初始化一个微信机器人实例，用于处理消息和与微信 API 交互。 RobotConfig 类：存储服务器配置参数，提供可变的连接配置： HOST 和 PORT：指定服务器监听的主机地址和端口号，例如 HOST 可设置为 0.0.0.0（监听所有可用网络）以允许外部访问。 TOKEN：用于微信公众号接入时的校验凭证，以确保接入的安全性。 GPT 回复 当用户发送消息时，系统将用户的消息作为 prompt 传递给 OpenAI API，获取 GPT-3.5 模型生成的回复。 发送的 messages 参数将模拟对话历史，目前只包含用户的提问，未来可以扩展包括机器人的回复，以便实现更连贯的对话。 爬取某网页 通过 HTTP 请求获取指定网页的数据，并使用 BeautifulSoup 进行解析。 查找网页中的所有链接，特别过滤出特定内容，比如包含特定网址（如 https://********.com/）。 进行二次爬取时，再次提取所有以 https://pan.quark 开头的链接，并将其拼接成字符串返回，以供后续处理。 该功能可以用于根据关键词抓取特定网页中的相关链接，方便用户快速获取目标信息。 微信消息处理逻辑 使用 @robot.handler 装饰器来定义消息处理函数，负责处理用户的微信输入。 如果用户输入的消息以”夸克”开头： 从用户的输入中提取关键词，将其拼接至基本 URL 后，形成完整的链接。 调用 getUrl 函数，爬取相关网页并返回抓取的结果。 当输入不以”夸克”开头时，则调用 generate_response，通过 GPT-3.5 自动生成智能回复。 最终返回构建的字符串 retMsg，作为微信消息的回复内容。 import werobot#import openaifrom openai import OpenAIimport reimport jsonimport requestsimport pandas as pdfrom bs4 import BeautifulSoupfrom functools import partialfrom datetime import datetime, timedeltaheaders = User-Agent: ********, Authorization: ********, Cookie: ********client = OpenAI( # defaults to os.environ.get(OPENAI_API_KEY) api_key=********, base_url=********)# 初始化 WeRoBot 实例robot = werobot.WeRoBot()class RobotConfig(object): HOST=******** PORT=80 TOKEN=******** # 微信公众号的接入凭证robot.config.from_object(RobotConfig)def generate_response(prompt): messages = [role: user,content: prompt ,] 为提供的对话消息创建新的回答 Args: messages (list): 完整的对话消息 completion = client.chat.completions.create(model=gpt-3.5-turbo, messages=messages) return (completion.choices[0].message.content)def getUrl(url): response = requests.get(url,headers=headers) str= # 检查请求是否成功 if response.status_code == 200: # 解析HTML内容 soup = BeautifulSoup(response.content, html.parser) #print(soup) # 查找所有class为info790的元素 elements = soup.find_all(class_=container) for links in elements: link = links.find_all(a, href=True) # 找到所有带有href属性的a标签 for a in link: #print(a[href]) if(a[href].startswith(https://********.com/)): response2 = requests.get(a[href],headers=headers) if response2.status_code == 200: # 解析HTML内容 soup2 = BeautifulSoup(response2.content, html.parser) #print(soup) # 查找所有class为info790的元素 elements2 = soup2.find_all(a, href=True) # 找到所有带有href属性的a标签 for b in elements2: if(b[href].startswith(https://pan.quark)): str += b[href]+ \\r else: str = (f请求失败，状态码: response.status_code) return str@robot.handlerdef weChatReturn(messages): #print(messages.content) msg = messages.content; #msg = messages retMsg = if msg.startswith(夸克): url = https://********.com/?q= url += msg[3:] retMsg += getUrl(url) else: retMsg += generate_response(msg) return retMsg;if __name__ == __main__: robot.run() 公众号返回超时问题","categories":["1.平台","服务器","微信"]},{"title":"C语言函数速查","path":"/2024/09/05/2-语言-C语言-C语言函数速查/","content":"字符串函数（string） bcmp比较字符串 s1 和 s2 的前 n 个字节是否相等。这可用于检验两个子串是否相同，常用于验证数据完整性或校验。 bcopy将字符串 src 的前 n 个字节复制到 dest 中。这个函数用于在内存中快速地移动数据，常见于操作字符串或缓冲区时的复制需求。 bzero将字节字符串 s 的前 n 个字节置为零。在初始化数据结构时常用，比如清空一个数组，确保没有垃圾值存在。 memccpy从 src 所指内存区域复制不超过 count 个字节到 dest，如果遇到字符 ch 则停止复制。该函数可以在复制途中查找特定字符，十分适合处理需要分隔的数据。 memchr从 buf 所指内存的前 count 字节中查找字符 ch。返回指向首次出现该字符的指针，如果未找到则返回 NULL。适合查找数据包中的特定标志。 memcmp比较内存区域 buf1 和 buf2 的前 count 个字节。这可以用于二进制数据比较，例如在网络协议中校验接收数据是否正确。 memcpy将从 src 所指内存区域复制 count 个字节到 dest 中。这个函数负责精准无误的字节拷贝操作，常用于数据管理和缓冲。 memicmp比较内存区域 buf1 和 buf2 的前 count 个字节，但不区分字母的大小写。非常适合需要忽略大小写的字符串比较情况。 memmove类似于 memcpy，但它支持在内存重叠时的安全复制。这意味着数据可以在重叠内存区域间安全移动，例如在数组元素排序时。 memset将 buffer 所指内存区域的前 count 个字节设置为字符 c。可以快速清理或初始化内存空间，例如填充数组。 movmem由 src 所指内存区域复制 count 个字节到 dest。它和 memmove 类似，主要用于特定情况下的内存移动。 setmem将 buf 所指内存区域的前 count 个字节设置为字符 ch，有助于统一数据格式或初始化。 stpcpy将 src 所指的以 NULL 结束的字符串复制到 dest 所指的数组中，并返回指向结果字符串末尾的指针。这对于字符串的进一步处理和拼接十分方便。 strcat将 src 所指字符串添加到 dest 结尾，并在末尾添加一个 \\0。例如，将一个文件的路径附加到根目录路径后，形成完整路径。 strchr查找字符串 s 中首次出现字符 c 的位置，返回指向该位置的指针。如果没有找到，返回 NULL。这个功能对查找特定字符非常实用。 strcmp比较字符串 s1 和 s2，返回值用于判断字典序关系。它是处理字符串排序和查找的重要函数。 strcmpi不区分字母大小写地比较 s1 和 s2。对于需要用户输入不敏感的比较场景非常有用。 strcpy将 src 指向的以 NULL 结束的字符串复制到 dest 指向的数组中，适合一般字符串初始化。 strcspn在字符串 s1 中搜寻 s2 中出现的字符，并返回首次出现的位置，适合过滤特定字符集。 strdup复制字符串，创建该字符串的新副本。可以用于动态内存管理中，例如需要存储复制字符串而不影响原字符串的场合。 stricmp不区分字母大小写地比较 s1 和 s2，有助于执行用户输入的比较时忽略大小写。 strlen计算字符串 s 的长度。该函数在字符串处理时非常基础且关键。 strlwr将字符串 s 转换为小写形式，适合于标识符规范化和统一格式。 strncat将 src 字符串的前 n 个字符追加到 dest 的末尾，并添加 \\0，有助于控制合并的长度。 strncmp比较字符串 s1 和 s2 的前 n 个字符，适合需要部分比较的场合。 strncmpi类似于 strncmp ，但不区分字母大小写，针对用户输入时可用。 strncpy将 src 指向的以 NULL 结束的字符串的前 n 个字节复制到 dest 中，适合在宽度限制下处理字符串。 strnicmp不区分大小写地比较 s1 和 s2 的前 n 个字符，适合在不关注大小写的前提下执行部分比较。 strpbrk在字符串 s1 中寻找 s2 中的任意字符匹配，返回第一个匹配字符的位置，适合行为匹配查找。 strrev将字符串 s 的所有字符的顺序颠倒（不包括 NULL），此功能用于加密和加扰数据时非常实用。 strset将字符串 s 中的所有字符都设置成字符 c，可用于初始化或格式化。 strstr从字符串 haystack 中寻找 needle 第一次出现的位置，并返回指针，适合简单的子串查找。 strtok分解字符串为一组标记串，使用指定的分隔符。此函数对解析输入数据格式尤其有效。 strupr将字符串 s 转换为大写形式，适合需要大小写统一的申请场合。 数学函数（math） abs返回整数的绝对值，例如 abs(-5) 返回 5，用于处理数值标准化。 acos计算给定值的反余弦值，反应角度的大小，适用于三角函数和物理计算。 asin计算给定值的反正弦值，常用于三角函数应用在几何图形解析上。 atan计算一个数的反正切值，通常用于科学计算和工程分析。 atan2利用 y 和 x 值计算反正切，常在极坐标和直角坐标之间转换。 ceil返回大于或等于 x 的最小整数，适用于向上取整的场合。 cos计算给定角度的余弦值，广泛应用于波形和周期函数计算。 cosh计算给定值的双曲余弦，常在物理和工程等领域使用。 exp计算 e 的指定次幂，适用于指数增长和衰减计算。 fabs返回浮点数的绝对值，避免数值为负时候的误处理。 floor返回小于或等于 x 的最大整数，适合向下取整使用。 fmod计算浮点数的余数，常用于循环和排列计算。 frexp将浮点数分解为尾数和指数，便于科学计数和存储。 hypot根据两条直角边计算斜边长度，直接适用在毕达哥拉斯定理中。 ldexp载入浮点数，允许以指数形式进行浮点运算。 log计算自然对数，很多数学、物理公式都会涉及对数运算。 log10计算常用对数，广泛应用于科学和工程领域中的数据处理。 modf分解浮点数为整数和小数部分，有助于处理复杂的浮点算式。 pow计算 x 的 y 次方，基础的指数运算功能。 pow10计算 10 的 x 次方，便于大数处理和科学计算。 sin计算给定角度的正弦值，适用于周期性现象。 sinh计算双曲正弦的值，常用于相对论和波动方程。 sqrt返回给定数的平方根，处理几何和代数运算时不可或缺。 tan计算正切值，涉及角度时的各种物理现象。 tanh计算给定值的双曲正切，适合在信号处理等领域。 输入输出函数（stdio） getchar从键盘上读取一个字符，并返回该字符的键值，非常适合用户输入。 getch是 getchar 的宏定义，通常用于无回显情况下获取单个字符。 kbhit检测键盘是否有键按下。如果有键按下，返回对应键值；否则返回零。这个函数快速有效，无需等待用户输入。 printf格式化字符串输出，支持多种输出格式，提供了对数据展示的灵活控制。例如： 格式 描述 %c 输出单个字符 %d 输出十进制整数 %f 输出十进制浮点数 %o 输出八进制数 %s 输出字符串 %u 输出无符号十进制数 %x 输出十六进制数 常用的修饰符： 修饰符 含义 - 左对齐输出 + 输出带符号数时加上正负号 0 用零填充域宽 putchar在屏幕上显示字符 c，字符会在当前光标位置输出。可以通过 move 或 gotoxy 移动光标到指定位置。 系统函数system ClearScreen清屏，清除屏幕缓冲区及液晶显示缓冲区，光标位置回到屏幕的左上角。这在重置显示器状态时非常方便。 DispBCD用于在七段数码管上显示数字，根据调用显示对应数字，最大为 999，常用于数字显示。 SetScrollBar显示一个滚动条，可以用于长列表的目的。 TextOut在屏幕上的指定位置输出字符串，适合在图形界面应用开发中显示信息。 UpdateLCD以指定模式刷新屏幕，适用于需要更新显示内容的场合。 bell发出声音信号。 block涉及特定的系统操作。 clrscr清除屏幕，类似于 ClearScreen 函数。 cursor控制光标的显示和隐藏。 delay短暂延时，延时 msec*4 毫秒，常用于控制程序运行节奏。 get_chi_font获取中文字体设置。 get_eng_font获取英文字体设置。 getkey从键盘读取按键信息。 getpixel获取指定坐标的像素值。 gotoxy移动光标到指定坐标位置。 line在屏幕上绘制线段。 move操控光标位置。 noidle确保程序在无用户活动时不进入空闲状态。 outtextxy在指定坐标输出文本。 putpixel设置指定坐标的像素值。 pyfc与自定义函数有关的操作。 rectangle在屏幕上绘制一个矩形。 sleep暂停程序的执行，等待一段时间。 textmode设置文本显示模式。 time获取系统当前时间，返回 struct tm，其中包括小时、秒、分钟等信息，用于精准时间处理。 struct tm int hsec; /* 半秒数 [0-119] */ int sec; /* 秒 [0-59] */ int min; /* 分钟 [0-59] */ int hour; /* 小时 [0-23] */ int day; /* 天 [0-30] */ int wday; /* 星期 [0-6] */ int mon; /* 月 [0-11] */ int year; /* 年 - 1881 */; write_chi_font将中文字符输出到屏幕。 write_eng_font将英文字符输出到屏幕。 stdlib exit结束程序的执行，常用于处理异常情况或正常退出。 itoa将整数 i 转换成字符串，适用于需要显示数字的 UI。 字符函数（ctype） isalnum判断字符 c 是否为字母或数字，适合输入校验和过滤。 isalpha判断字符 c 是否为英文字母，常用于字符集验证。 iscntrl判断字符 c 是否为控制字符，例如 0x00-0x1F 或 0x7F，通常用于数据清理。 isdigit判断字符 c 是否为数字字符，有助于输入验证。 islower判断字符 c 是否为小写字母，适合对字母大小写的处理。 isascii判断字符 c 是否为 ASCII 字符，确保输入在合理范围内。 isgraph判断字符 c 是否为可打印字符（不包括空格），有助于字符输出控制。 isprint判断字符 c 是否为可打印字符（包含空格），用于界面输出时的字符处理。 ispunct判断字符 c 是否为标点符号，有助于分隔文本中的重要部分。 isspace检查字符是否为空白符，含空格、制表符等，常在文本解析中使用。 isupper判断字符 c 是否为大写字母，适用于大小写转换的场景。 isxdigit判断字符 c 是否为十六进制数字，适合处理需要十六进制数据的功能。 toascii将字符 c 转换为 ASCII 码，清除高位只保留低七位，确保数据在标准字符集内。 tolower将字母 c 转换为小写，适合用户输入的统一处理。 toupper将字母 c 转换为大写，适合文档标识中的要求。 内存管理函数（alloc） calloc为具有 num_elems 个长度为 elem_size 的数组分配内存，确保所有初始值为零，避免数据污染。 free释放指针 p 所指向的内存空间，防止内存泄漏。 malloc分配长度为 num_bytes 字节的内存块，创造新的内存区域，后续需通过 free 手动释放。 realloc改变 mem_address 所指的内存区域大小为 newsize，适用于动态增长或缩小数据结构的场景。","categories":["2.语言","C语言"]},{"title":"man帮助手册","path":"/2024/09/04/2-语言-C语言-man帮助手册/","content":"什么是 man 帮助手册在 Linux 系统中，”man”是”manual”的缩写，意指手册。它为用户提供了一种方便的方式来查找和浏览已经安装在系统上的各种命令、函数和配置文件的详细信息。”man”命令则是一个命令行工具，用于访问这些手册。 当在命令行中输入”man”后跟特定的命令、函数或配置文件名时，系统会显示出相应的帮助页面。这些页面不仅解释了该命令或函数的基本用法，还列出其各种选项和参数。例如，使用命令 man ls 可以查看关于 ls 命令的详尽信息。页面通常还会包含示例，以便于用户理解如何在实际应用中使用该功能。 帮助页面通常依照不同层级的详细程度划分为多个部分，从基础到复杂应有尽有。可以根据需要使用”man”命令的选项来访问特定部分的信息。例如，输入 man 1 ls 将为展示关于”ls”命令的帮助信息，而 man 2 open 则将提供更深层次的关于”open”系统调用的说明。 “man”帮助手册是 Linux 用户必不可少的资源之一。无论是新手还是经验丰富的用户，它都为提供了深入理解和学习各种系统命令、函数，以及遇到问题时的解决方案的重要支持。 man 后面加数字代表什么在 Linux 中，”man”命令后面加上数字，表示想查看帮助页面的特定部分。这些部分涉及到不同类型的命令和功能。具体来说，这里有一些常见的数字及其对应的帮助页部分： 1：标准命令。这部分提供了常见命令行工具和可执行程序的信息，如 ls、cp 等。 2：系统调用。这里包含与操作系统核心功能相关的函数的文档，例如处理文件和进程的系统调用，如 open() 和 fork()。 3：库函数。这部分聚焦于 C 语言中的标准库函数，涵盖如 printf() 和 malloc() 等函数的使用。 4：特殊设备。这部分涉及设备驱动程序、字符设备及块设备的说明，帮助用户理解如何与硬件交互。 5：文件格式。这部分描述系统配置文件、数据库文件及其他文件格式的相关信息，如 passwd 文件的格式和用法。 6：游戏和玩具。这部分列出一些可以在终端运行的小游戏，像 nethack 和其他趣味命令。 7：杂项。提供一些其他文档、约定和标准的信息，可能包括协定或者特殊情况下的使用说明。 8：管理员命令。这部分专门为系统管理员设计，包含如 shutdown 和 useradd 等命令的文档。 9：其他与 Linux 特定相关的内容，主要包含内核例行程序文档。 举个例子，使用命令 man 1 ls 能迅速取得关于 ls 命令的全面指导，而输入 man 5 passwd 则能了解 passwd 配置文件的详细内容。 请注意，并非所有命令或主题都与每个数字对应某个帮助页面。了解这些细分区域可以帮助更高效地查找信息，并利用 Linux 系统的强大功能。","categories":["2.语言","C语言"]},{"title":"stat函数_获取文件信息","path":"/2024/09/03/2-语言-C语言-stat函数-获取文件信息/","content":"Linux stat 函数详解表头文件在使用 stat 函数之前，需要包含以下头文件： #include sys/stat.h#include unistd.h 定义函数stat 函数的基本原型如下： int stat(const char *file_name, struct stat *buf); 函数说明stat 函数用于获取指定文件（通过 file_name 参数给出）的详细信息，并将获取到的信息保存在 buf 指向的 struct stat 结构体中。这一结构体包含了文件的多种属性，例如大小、权限和时间戳等。 示例以下是一个使用 stat 函数的简单示例： #include sys/stat.h#include unistd.h#include stdio.hint main() struct stat buf; if (stat(/etc/hosts, buf) == 0) printf(/etc/hosts file size = %lld , (long long)buf.st_size); else perror(stat failed); 在这个示例中，程序尝试获取 /etc/hosts 文件的信息。如果成功，将打印出文件的大小；如果失败，则输出错误信息。 返回值 成功时：stat 函数返回 0。 失败时：返回 -1，并且错误信息存储在 errno 中。 错误代码以下是 stat 函数可能返回的一些错误代码，及其含义： ENOENT：指定的 file_name 不存在。 ENOTDIR：路径中的某个部分存在，但不是一个目录。 ELOOP：由于过多的符号链接而导致的循环问题，通常上限为 16。 EFAULT：buf 为无效指针，指向无法访问的内存空间。 EACCESS：尝试访问文件时被拒绝。 ENOMEM：内存不足。 ENAMETOOLONG：指定的路径名称过长。 struct stat 结构体struct stat 是用于存储文件信息的结构体，包含以下成员： struct stat dev_t st_dev; // 文件所在设备的编号 ino_t st_ino; // 文件的节点号 mode_t st_mode; // 文件类型和访问权限 nlink_t st_nlink; // 连接到该文件的硬连接数 uid_t st_uid; // 文件所有者的用户ID gid_t st_gid; // 文件所有者的组ID dev_t st_rdev; // 设备类型（若该文件为设备文件） off_t st_size; // 文件的字节数（即文件大小） unsigned long st_blksize; // 块大小（文件系统的 I/O 缓冲区大小） unsigned long st_blocks; // 文件占用的块数 time_t st_atime; // 最后访问时间 time_t st_mtime; // 最后修改时间 time_t st_ctime; // 状态最后改变时间（包括属性更改）; 文件类型和权限的定义st_mode 字段中定义了一系列不同的文件类型和权限，如下： S_IFMT 0170000：文件类型的位遮罩 S_IFSOCK 0140000：套接字 S_IFLNK 0120000：符号链接 S_IFREG 0100000：普通文件 S_IFBLK 0060000：区块设备 S_IFDIR 0040000：目录 S_IFCHR 0020000：字符设备 S_IFIFO 0010000：先进先出 S_ISUID 04000：文件的 set user-id on execution 位 S_ISGID 02000：文件的 set group-id on execution 位 S_ISVTX 01000：文件的 sticky 位 S_IRUSR (S_IREAD) 00400：所有者可读 S_IWUSR (S_IWRITE) 00200：所有者可写 S_IXUSR (S_IEXEC) 00100：所有者可执行 S_IRGRP 00040：用户组可读 S_IWGRP 00020：用户组可写 S_IXGRP 00010：用户组可执行 S_IROTH 00004：其他用户可读 S_IWOTH 00002：其他用户可写 S_IXOTH 00001：其他用户可执行 在 POSIX 中定义了检查这些类型的宏： S_ISLNK(st_mode)：判断是否为符号链接 S_ISREG(st_mode)：判断是否为普通文件 S_ISDIR(st_mode)：判断是否为目录 S_ISCHR(st_mode)：判断是否为字符设备文件 S_ISBLK(st_mode)：判断是否为区块设备 S_ISSOCK(st_mode)：判断是否为套接字 在一个目录上设置了 sticky 位（由 S_ISVTX 表示）时，该目录下的文件只能被文件所有者、目录所有者 或 root 用户删除或重命名。 struct statfs 结构体除了获取文件信息，statfs 函数也可以获取文件系统的信息，通过以下结构体定义： struct statfs long f_type; // 文件系统类型 long f_bsize; // 块大小 long f_blocks; // 总块数 long f_bfree; // 空闲块数 long f_bavail; // 可用块数 long f_files; // 文件节点总数 long f_ffree; // 空闲文件节点数 fsid_t f_fsid; // 文件系统 ID long f_namelen; // 文件名最大长度 long f_spare[6]; // 备用字段; stat、fstat 和 lstat 函数在 UNIX 中有三个相关函数，分别为 stat、fstat 和 lstat。 int stat(const char *restrict pathname, struct stat *restrict buf); 提供文件名，获取文件的属性。一般用于文件尚未打开时的情况。 int fstat(int filedes, struct stat *buf); 通过文件描述符获取文件的属性。适用于文件已经打开的情况。 int lstat(const char *restrict pathname, struct stat *restrict buf); 获取文件属性，涉及到符号连接(directory symlink)时，返回的是符号连接本身的信息，而不是连接的目标文件的信息。 函数返回值这三个函数的返回值一致：成功则返回 0，出错则返回 -1。 赋予一个 pathname，stat 函数会返回关于这个文件的信息，fstat 适用于已经在文件描述符 filedes 上打开的文件，lstat 则专门处理符号连接，并返回符号连接的信息。 struct stat 结构体中成员的详细说明每个成员都提供了关于文件属性的重要数据： st_mode：文件类型和权限，表示文件的种类（如目录或文件）以及访问控制。 st_ino：唯一的节点编号，用于在文件系统中标识文件。 st_rdev：设备编号，专门针对字符和块设备。 st_nlink：表示和该文件相关的硬链接数量。 st_uid 和 st_gid：文件所有者的用户 ID 和组 ID，对于权限控制非常重要。 st_size：普通文件的字节数。 st_atime：最后一次访问该文件的时间，这对了解文件使用情况很关键。 st_mtime：文件内容最后一次被修改的时间。 st_ctime：文件状态变化的时间，包括元数据的修改。 st_blksize：文件系统实现针对文件的最佳块大小。 st_blocks：已分配给该文件的 512 字节块的数量。 通过这些函数和结构体，用户可以方便地获取文件的全方位信息，管理和操作文件，也因而在 UNIXLinux 系统中 stat 函数是不可或缺的工具。","categories":["2.语言","C语言"]},{"title":"CPU参数说明","path":"/2024/09/02/1-平台-Linux-系统参数-CPU参数说明/","content":"在 Linux 系统中使用 top 命令查看 CPU 相关参数时有以下内容 us: “user CPU time” 用户空间占用 CPU 百分比 sy: “system CPU time” 内核空间占用 CPU 百分比 ni: is meaning of” nice CPU time” 用户进程空间内改变过优先级的进程占用 CPU 百分比 id: “idle” 空闲 CPU 百分比 wa: “iowait” 等待输入输出的 CPU 时间百分比即等待磁盘写入完成时间 hi：”hardware irq” 硬件中断消耗时间 si : “software irq” 软件中断消耗时间 st : “steal time” 分配给其他虚拟机的时间 使用率 CPU 在处理任务时所花费的时间占总时间的比例。可以通过以下公式计算： CPU 使用率 = us + sy + ni + hi + si 这表示了 CPU 忙于实际处理任务的时间，不包括空闲时间（id）和 IO 等待时间（wa）。 负载负载通常指的是系统的任务排队情况，也就是在等待 CPU 处理的进程数。它通常由操作系统的负载均衡器来计算，考虑到运行队列中的任务数量和平均等待时间。 CPU 负载需要结合任务队列长度、等待时间以及 CPU 调度情况来衡量，可以通过 uptime、w 命令查看 CPU 平均负载，使用 top 命令还能看到 CPU 负载总体使用率以及各个进程占用 CPU 的比例。 如果单核 CPU 的话，负载达到 1 就代表 CPU 已经达到满负荷的状态了，超过 1，后面的进行就需要排队等待处理了。如果是多核多 CPU，假设现在服务器是 2 个 CPU，每个 CPU 有 2 个核，那么总负载不超过 4 都没什么问题。 参数查看查看物理 CPU 个数 cat /proc/cpuinfo| grep physical id| sort | uniq| wc -l 查看每个物理 CPU 中 core 的个数(即核数) cat /proc/cpuinfo| grep cpu cores | uniq 查看逻辑 CPU 的个数 cat /proc/cpuinfo| grep processor| wc -l 负载高利用率低CPU 负载很高，利用率却很低，说明处于等待状态的任务很多，负载越高，代表可能很多僵死的进程。通常这种情况是 IO 密集型的任务，大量任务在请求相同的 IO，导致任务队列堆积。 负载低利用率高这表示 CPU 的任务并不多，但是任务执行的时间很长，大概率就是写的代码本身有问题，通常是计算密集型任务，生成了大量耗时短的计算任务。 通过 top 找到 CPU 占用率高的进程 通过 top -Hp pid 命令查看 CPU 占比靠前的线程 ID 再把线程 ID 转化为 16 进制，printf “0x%x ” 74317，得到 0x1224d 在比对程序中的线程 ID 找到有问题的部分","categories":["1.平台","Linux","系统参数"]},{"title":"编译内存不足","path":"/2024/08/30/1-平台-VMware-编译内存不足/","content":"当在 Linux 环境下编译 C++程序时遇到 fatal error: Killed signal terminated program cc1plus 的问题，可能是因为内存不足。解决方法是创建 swap 分区，通过增加虚拟内存来缓解。步骤包括创建 swap 文件，设置权限，激活 swap，最后确认 swap 已正确配置。若不再需要，可使用 swapoff 和 rm 命令移除。 问题描述在 Linux 系统中进行 C++编译时，出现如下报错，导致编译中止： C++: fatal error: Killed signal terminated program cc1pluscompilation terminated. 解决方法查阅相关信息后，认为是虚拟机内存不足造成的。通过创建 swap 分区解决了这个问题，编译成功。下面总结一下 swap 分区的创建和激活等操作： # 创建分区路径sudo mkdir -p /var/cache/swap/# 设置分区的大小# bs=64M是块大小，count=64是块数量，所以swap空间大小是bs*count=4096MB=4GBsudo dd if=/dev/zero of=/var/cache/swap/swap0 bs=64M count=64# 设置该目录权限sudo chmod 0600 /var/cache/swap/swap0# 创建SWAP文件sudo mkswap /var/cache/swap/swap0# 激活SWAP文件sudo swapon /var/cache/swap/swap0# 查看SWAP信息是否正确sudo swapon -s swap0 文件的路径在varcacheswap下，编译完后, 如果不想要交换分区了, 可以删除。 删除交换分区的命令： sudo swapoff /var/cache/swap/swap0sudo rm /var/cache/swap/swap0 释放空间命令： sudo swapoff -a#详细的用法：swapoff --help#查看当前内存使用情况：free -m","categories":["1.平台","VMware"]},{"title":"中文字符无法正常显示","path":"/2024/08/29/1-平台-WSL-中文字符无法正常显示/","content":"WSL 中没有相应中文字体库，显示为小方框。 们直接使用 Windows 自带的字体链接到 WSL 下 sudo ln -s /mnt/c/Windows/Fonts /usr/share/fonts/font 扫描字体目录，并生成字体信息的缓存 fc-cache -fv","categories":["1.平台","WSL"]},{"title":"信号量","path":"/2024/08/28/1-平台-Linux-IO-信号量/","content":"介绍Linux 的信号量是一种进程间通信机制，用于控制进程对共享资源的访问。信号量是一个计数器，用于表示某个共享资源的可用数量。进程可以使用信号量来申请共享资源的访问权限，也可以使用信号量来释放已经申请到的资源。 Linux 中的信号量包括两种类型：二进制信号量和计数信号量。二进制信号量只有两个取值，分别表示资源的空闲和占用状态。计数信号量的取值可以是任意正整数，表示可用资源的数量。 进程可以使用 semget() 函数创建一个信号量集，使用 semop() 函数对信号量进行操作。semop() 函数可以对信号量进行加锁和解锁操作，还可以等待信号量的值达到某个条件。当某个进程占用了一个资源时，它需要对相应的信号量进行加锁操作，以防止其他进程同时访问该资源。当进程释放资源时，需要对相应的信号量进行解锁操作，以便其他进程可以访问该资源。 SIG 簇函数在 Linux 中，信号量通常用于进程间的同步和互斥操作。例如，多个进程需要访问同一个共享文件时，可以使用信号量来控制对该文件的访问。 在 Linux 中，SIG 簇函数是一组用于处理信号的系统调用函数，可以用来注册信号处理函数、发送信号、阻塞信号等操作。这些函数的名称都以 “sig” 开头，例如 sigaction、sigprocmask、sigqueue 等。 下面是一些常用的 SIG 簇函数： sigaction 函数：用于注册信号处理函数。该函数可以指定一个函数指针作为信号处理函数，当接收到指定信号时，系统会自动调用该函数进行处理。sigaction 函数还可以设置信号的处理方式，例如忽略信号、执行默认操作、执行指定的处理函数等。 sigprocmask 函数：用于设置进程的信号屏蔽字。进程可以使用该函数屏蔽某些信号，以免在处理某个信号时被其他信号中断。当某个信号被屏蔽后，它将被暂时忽略，直到该信号被解除屏蔽。 sigpending 函数：用于获取当前进程的未决信号集。未决信号是指已经发送给进程但尚未处理的信号。sigpending 函数可以获取当前进程的未决信号集，并将其保存在一个 sigset_t 类型的变量中。 sigsuspend 函数：用于挂起当前进程，直到收到指定信号为止。该函数可以用于等待某个信号的到来，并阻塞当前进程，直到收到指定信号后才会继续执行。 sigqueue 函数：用于向指定进程发送信号，并可以携带一个整数值作为附加数据。该函数可以用于进程间的通信，例如向另一个进程发送通知消息等。 这些 SIG 簇函数可以帮助们更好地处理信号，实现进程间的通信和同步操作。在使用这些函数时，需要注意信号的处理顺序和优先级，以免出现意外的结果。 信号量用作定时器信号量可以用作定时器的一种实现方式。具体来说，可以使用 setitimer 函数设置一个定时器，当定时器到期时，系统会自动向当前进程发送一个指定的信号，进程可以通过信号处理函数来处理该信号。 以下是一个使用信号量实现定时器的示例代码： #include stdio.h#include stdlib.h#include signal.h#include unistd.h#include sys/time.h#include sys/sem.h#define SEM_KEY 0x12345678static int sem_id;union semun int val;\tstruct semid_ds *buf;\tunsigned short *array;;void handler(int signum)\tprintf(Timer expired. );void set_timer(int sec)\tstruct itimerval timer;\ttimer.it_value.tv_sec = sec;\ttimer.it_value.tv_usec = 0;\ttimer.it_interval.tv_sec = 0;\ttimer.it_interval.tv_usec = 0;\tsetitimer(ITIMER_REAL, timer, NULL);void init_sem()\tunion semun arg;\targ.val = 0;\tsem_id = semget(SEM_KEY, 1, IPC_CREAT | 0666);\tsemctl(sem_id, 0, SETVAL, arg);void wait_sem()\tstruct sembuf sb;\tsb.sem_num = 0;\tsb.sem_op = -1;\tsb.sem_flg = 0;\tsemop(sem_id, sb, 1);void post_sem()\tstruct sembuf sb;\tsb.sem_num = 0;\tsb.sem_op = 1;\tsb.sem_flg = 0;\tsemop(sem_id, sb, 1);int main()\tsignal(SIGALRM, handler);\tinit_sem();\tset_timer(5);\twait_sem();\tprintf(Exiting... );\treturn 0; 在上面的示例代码中，们使用了 setitimer 函数来设置一个 5 秒的定时器，当定时器到期时，系统会向当前进程发送 SIGALRM 信号。们在程序中注册了 SIGALRM 信号的处理函数 handler，当收到该信号时，会输出一条消息。 为了实现等待定时器到期的功能，们使用了信号量。在程序开始时，们调用了 init_sem 函数来初始化信号量。在程序中，们使用了 wait_sem 函数来等待信号量的值变为 0，这个函数会阻塞当前进程直到收到信号量为止。在信号处理函数中，们调用了 post_sem 函数来将信号量的值加 1，这样就可以让等待信号量的进程继续执行了。 当程序运行时，它会等待 5 秒钟，然后输出一条消息并退出。如果需要更长或更短的定时器，可以修改 set_timer 函数中的参数。 Linux 中的信号量和 Qt 的信号槽机制Linux 中的信号量和 Qt 中的信号槽都是用于实现进程间通信和事件处理的机制，但实现方式和应用场景有所不同。 Linux 中的信号量是一种进程间通信机制，用于控制进程对共享资源的访问。信号量是一个计数器，用于表示某个共享资源的可用数量。进程可以使用信号量来申请共享资源的访问权限，也可以使用信号量来释放已经申请到的资源。Linux 中的信号量通常用于进程间的同步和互斥操作，例如多个进程需要访问同一个共享文件时，可以使用信号量来控制对该文件的访问。 Qt 中的信号槽是一种事件处理机制，用于在对象之间传递消息和处理事件。当一个对象发生某个事件时，它会发送一个信号，其他对象可以连接到该信号并定义一个槽函数来处理该事件。Qt 中的信号槽机制可以用于实现对象之间的通信和协作，例如在一个窗口中点击一个按钮时，可以发送一个信号来通知其他对象执行相应的操作。 虽然 Linux 中的信号量和 Qt 中的信号槽机制都可以用于进程间通信和事件处理，但它们的实现方式和应用场景有所不同。在 Linux 中，信号量通常用于控制对共享资源的访问，而在 Qt 中，信号槽机制通常用于处理事件和实现对象之间的通信。 sigactionsigaction 和 Qt 的信号槽机制都是用于处理信号的机制，sigaction 主要用于实现进程间通信和事件处理，而 Qt 的信号槽机制主要用于处理 GUI 事件和实现对象之间的通信。 sigaction 是 Linux 中用于处理信号的函数，可以设置信号处理函数、信号屏蔽字等。当进程接收到某个信号时，会自动调用对应的信号处理函数来处理该信号。sigaction 主要用于实现进程间通信和事件处理，例如在多进程编程中，可以使用 sigaction 实现进程间的同步和互斥操作。 Qt 中的信号槽机制是一种事件处理机制，用于在对象之间传递消息和处理事件。当一个对象发生某个事件时，它会发送一个信号，其他对象可以连接到该信号并定义一个槽函数来处理该事件。Qt 中的信号槽机制可以用于实现对象之间的通信和协作，例如在一个窗口中点击一个按钮时，可以发送一个信号来通知其他对象执行相应的操作。","categories":["1.平台","Linux","IO"]},{"title":"裸机驱动的开发步骤","path":"/2024/08/27/1-平台-ARM-裸机驱动的开发步骤/","content":"最简例子 LED 灯控制 看电路图 找到要控制的设备 找到设备在 CPU 侧的控制管脚(如 GPX27) 看芯片手册 先看相关的中文文档，熟悉设备再看手册) 搜索电路图里对应控制管脚的名称(如 GPX2) 看目录找到对应的控制模块(如:6General Purpose InputOutput(GPIO)Control) 看该模块的 overview 了解该模块的大概功能 看控制寄存器(REGISTER DESCRIPTION)重点，难点 如果寄存器比较多，看技术支持提供的 demo，找到需要修改的寄存器(通常情况下只有几个)。部分厂商会提供配置软件，通过界面去配置功能，们只需使用配置好的寄存器值就可以 编程 定义要控制的寄存器的宏(与手册里的寄存器地址对应起来) 设备初始化(如设置 GPI0 为输出状态) 把功能分成最基本的小块:逐个实现,如点亮灯-在灭灯-加延时-闪烁-跑马灯","categories":["1.平台","ARM"]},{"title":"Linux子系统的GUI","path":"/2024/08/26/1-平台-Windows-Linux子系统的GUI/","content":"项目地址WSLg GitHub 页面 WSLg 介绍WSLg 是 Windows Subsystem for Linux GUI 的缩写。该项目的主要目的是支持在 Windows 系统中无缝运行 Linux GUI 应用程序，包括但不限于 X11 和 Wayland 应用程序。这项技术显著提升了开发者、科学家以及开源爱好者的工作效率，尤其是在需要同时使用两种操作系统工具的场景中。 目标用户WSLg 尤其适合那些需要在同一台计算机上运行 Windows 和 Linux 应用程序的用户。比如，一位数据科学家可能需要使用 Python 或 R 在 Linux 上进行数据分析，而同时又希望使用 Windows 上的图形化工具进行可视化。通过使用 WSLg，用户可以避免繁琐的双系统或虚拟化设置，节省大量时间和系统资源。 传统解决方案的局限性在使用双系统设置时，用户需要重启计算机来切换操作系统，而在虚拟机中则可能面临性能下降和资源消耗的问题。此外，使用 XServer 将 Linux 应用投射到 Windows 上也常常需要复杂的配置和额外的维护，使得用户难以获得流畅的使用体验。 WSLg 的优势WSLg 的设计旨在让 Linux GUI 应用程序在 Windows 上的使用体验像本地应用程序一样自然。具体来说，WSLg 提供了以下功能： “开始”菜单集成：用户可以轻松找到并启动 Linux 应用程序，像访问任何 Windows 应用程序一样方便。 任务栏融合：Linux 应用程序的图标可以在 Windows 的任务栏上显示，用户可以直观地识别和访问它们。 跨平台的快捷键切换：用户可以通过 alt-tab 快速切换 Windows 和 Linux 应用程序，保持高效的工作流。 无缝的剪切粘贴功能：例如，用户可以在 Windows 上复制文本，然后直接粘贴到运行在 WSLg 中的 Linux 应用程序里，反之亦然。 这些功能共同为用户提供了 Windows 和 Linux 应用程序之间的无缝桌面体验，消除了在多系统环境中常见的繁琐和不便。无论是开发应用程序还是进行日常任务，WSLg 都能使用户的工作更加顺畅高效。","categories":["1.平台","Windows"]},{"title":"内核补丁","path":"/2024/08/23/1-平台-Linux-内核-内核补丁/","content":"内核补丁（.patch 文件）是用于对 Linux 内核源代码进行修改的文件。补丁通常用于修复漏洞、引入新功能、优化性能或修正错误。 什么是内核补丁内核补丁是一个包含源代码更改的文本文件，通常由 diff 或 git diff 生成。它描述了如何从当前版本的源代码生成一个新版本，包括添加、删除或修改的代码行。 补丁文件通常包含以下部分： 文件头：指示补丁适用于哪个文件。 上下文信息：显示修改的代码周围的几行代码，以帮助理解更改的位置。 更改信息：实际的代码差异，标记为添加（+）、删除（-）或修改。 内核补丁的作用 修复漏洞和错误 内核是操作系统的核心部分，任何漏洞或错误可能都会导致系统不稳定或受到攻击。通过应用补丁，开发人员可以修复这些问题，而不需要等待完整的新内核版本发布。 添加新功能 Linux 内核是一个快速发展的项目，新的硬件支持、新的文件系统、新的安全功能等，都是通过补丁引入的。开发人员通过提交补丁来贡献新功能，其他开发者可以在自己的内核中应用这些补丁进行测试和使用。 性能优化 补丁还可以用于性能优化，尤其是在高性能计算或嵌入式系统中。开发人员可以通过调整内核代码，优化资源使用和响应时间，从而提高系统整体性能。 自定义内核 有些用户和开发人员需要定制内核以满足特定需求，如在特定硬件上运行、启用特定功能或优化某些工作负载。通过应用特定的补丁，内核可以被调整和定制。 如何使用内核补丁以下们使用一个 linux4.19 的内核在 ubuntu24 中编译时出现报错的示例来说明如何使用一个内核补丁。 编译内核源码，在编译内核源码时出现以下错误： 2024-08-24T13:51:26 In file included from /usr/include/signal.h:328,2024-08-24T13:51:26 from ./signal.h:52,2024-08-24T13:51:26 from c-stack.c:49:2024-08-24T13:51:26 c-stack.c:55:26: error: missing binary operator before token (2024-08-24T13:51:26 55 | #elif HAVE_LIBSIGSEGV SIGSTKSZ 163842024-08-24T13:51:26 | ^~~~~~~~......2024-08-24T13:51:26 make[4]: *** [Makefile:1674: all] Error 22024-08-24T13:51:26 make[3]: *** [Makefile:1572: all-recursive] Error 12024-08-24T13:51:26 make[2]: *** [Makefile:1528: all] Error 22024-08-24T13:51:26 make[1]: *** [package/pkg-generic.mk:231: /mnt/c/Users/Administrator/Desktop/12.GitHub/CodeWork/00.HoldDev/OK3568-linux-source/buildroot/output/OK3568/build/host-m4-1.4.18/.stamp_built] Error 22024-08-24T13:51:26 make: *** [/mnt/c/Users/Administrator/Desktop/12.GitHub/CodeWork/00.HoldDev/OK3568-linux-source/buildroot/output/OK3568/Makefile:16: _all] Error 2Command exited with non-zero status 1you take 7:43.42 to build builrootERROR: Running build_buildroot failed!ERROR: exit code 1 from line 565: /usr/bin/time -f you take %E to build builroot $COMMON_DIR/mk-buildroot.sh $BOARD_CONFIG 下载们需要的补丁文件 cd OK3568-linux-sourcewget https://toolchains.bootlin.com/downloads/releases/sources/m4-1.4.18/0003-c-stack-stop-using-SIGSTKSZ.patch 具体补丁文件内容如下 c-stack: stop using SIGSTKSZIt’s been proposed to stop making SIGSTKSZ an integer constant:https://sourceware.org/pipermail/libc-alpha/2020-September/118028.htmlAlso, using SIGSTKSZ in #if did not conform to current POSIX.Also, avoiding SIGSTKSZ makes the code simpler and easier to grok.* lib/c-stack.c (SIGSTKSZ): Remove.(alternate_signal_stack): Now a 64 KiB array, for simplicity.All uses changed.[Retrieved (and backported) from:https://git.savannah.gnu.org/cgit/gnulib.git/patch/?id=f9e2b20a12a230efa30f1d479563ae07d276a94b]Signed-off-by: Fabrice Fontaine fontaine.fabrice@gmail.comdiff -Nura m4-1.4.18.orig/lib/c-stack.c m4-1.4.18/lib/c-stack.c--- m4-1.4.18.orig/lib/c-stack.c 2021-04-11 19:12:14.086494029 +0200+++ m4-1.4.18/lib/c-stack.c 2021-04-11 19:48:46.316862760 +0200@@ -50,15 +50,16 @@ #if ! HAVE_STACK_T ! defined stack_t typedef struct sigaltstack stack_t; #endif-#ifndef SIGSTKSZ-# define SIGSTKSZ 16384-#elif HAVE_LIBSIGSEGV SIGSTKSZ 16384-/* libsigsegv 2.6 through 2.8 have a bug where some architectures use- more than the Linux default of an 8k alternate stack when deciding- if a fault was caused by stack overflow. */-# undef SIGSTKSZ-# define SIGSTKSZ 16384-#endif++/* Storage for the alternate signal stack.+ 64 KiB is not too large for Gnulib-using apps, and is large enough+ for all known platforms. Smaller sizes may run into trouble.+ For example, libsigsegv 2.6 through 2.8 have a bug where some+ architectures use more than the Linux default of an 8 KiB alternate+ stack when deciding if a fault was caused by stack overflow. */+static max_align_t alternate_signal_stack[(64 * 1024+ + sizeof (max_align_t) - 1)+ / sizeof (max_align_t)]; #include stdlib.h #include string.h@@ -128,19 +129,6 @@ #if (HAVE_SIGALTSTACK HAVE_DECL_SIGALTSTACK \\ HAVE_STACK_OVERFLOW_HANDLING) || HAVE_LIBSIGSEGV-/* Storage for the alternate signal stack. */-static union-- char buffer[SIGSTKSZ];-- /* These other members are for proper alignment. Theres no- standard way to guarantee stack alignment, but this seems enough- in practice. */- long double ld;- long l;- void *p;- alternate_signal_stack;- static void null_action (int signo __attribute__ ((unused))) @@ -205,8 +193,8 @@ /* Always install the overflow handler. */ if (stackoverflow_install_handler (overflow_handler,- alternate_signal_stack.buffer,- sizeof alternate_signal_stack.buffer))+ alternate_signal_stack,+ sizeof alternate_signal_stack)) errno = ENOTSUP; return -1;@@ -279,14 +267,14 @@ stack_t st; struct sigaction act; st.ss_flags = 0;+ st.ss_sp = alternate_signal_stack;+ st.ss_size = sizeof alternate_signal_stack; # if SIGALTSTACK_SS_REVERSED /* Irix mistakenly treats ss_sp as the upper bound, rather than lower bound, of the alternate stack. */- st.ss_sp = alternate_signal_stack.buffer + SIGSTKSZ - sizeof (void *);- st.ss_size = sizeof alternate_signal_stack.buffer - sizeof (void *);-# else- st.ss_sp = alternate_signal_stack.buffer;- st.ss_size = sizeof alternate_signal_stack.buffer;+ st.ss_size -= sizeof (void *);+ char *ss_sp = st.ss_sp;+ st.ss_sp = ss_sp + st.ss_size; # endif r = sigaltstack (st, NULL); if (r != 0)diff -Nura m4-1.4.18.orig/lib/c-stack.h m4-1.4.18/lib/c-stack.h--- m4-1.4.18.orig/lib/c-stack.h 2021-04-11 19:12:14.098494042 +0200+++ m4-1.4.18/lib/c-stack.h 2021-04-11 19:17:42.138848378 +0200@@ -34,7 +34,7 @@ A null ACTION acts like an action that does nothing. ACTION must be async-signal-safe. ACTION together with its callees- must not require more than SIGSTKSZ bytes of stack space. Also,+ must not require more than 64 KiB bytes of stack space. Also, ACTION should not call longjmp, because this implementation does not guarantee that it is safe to return to the original stack. 在合适的位置使用内核补丁（.patch 文件）来修改 Linux 内核的源代码 patch -p1 /path/to/my_patch.patch -p1 是一个常用选项，它告诉 patch 命令忽略路径前的一个目录部分。如果补丁文件的路径与源代码目录结构不一致，可能需要调整 -p 选项的值。 用来将补丁文件的内容传递给 patch 命令。 在这里，实际应用时，们在编译源码目录下 wget 下载补丁文件，之后进入指定位置应用补丁： OK3568-linux-source$ cd ./buildroot/output/OK3568/build/host-m4-1.4.18/OK3568-linux-source/buildroot/output/OK3568/build/host-m4-1.4.18$ patch -p1 ../../../../../0003-c-stack-stop-using-SIGSTKSZ.patchpatching file lib/c-stack.cpatching file lib/c-stack.h 检查应用结果，可以检查应用补丁后的文件，确保补丁已正确应用。 回滚补丁，如果补丁引入了问题或不需要了，可以回滚补丁： patch -p1 -R /path/to/patch.patch","categories":["1.平台","Linux","内核"]},{"title":"Docker下配置wordpress","path":"/2024/08/22/1-平台-Docker-Docker下配置wordpress/","content":"DockerCompose 方式安装 WordPress 及 Mysql准备存储目录Docker 容器中的数据不是持久的。这意味着如果停止容器并再次运行它，将丢失所有数据，里面将不再有任何数据。这可以通过添加 Docker 数据卷来避免。 创建 docker-compose.yml在 Docker Compose 中，运行容器所需的所有资源都必须在名为 .yaml 的 YAML 文件中定义 docker-compose.yaml。然后 Docker Compose 将读取此类文件并与 Docker 守护程序通信以创建、配置或销毁定义的资源。 在们的例子中，该 docker-compose.yaml 文件将包含们的 dockerized WordPress 设置的服务定义。此外，Docker Compose 允许们将这些服务与共享网络和卷链接在一起。 因此，让们从使用 Vim 编辑器在srvwordpress 目录中创建一个新文件 docker-compose.yaml 开始 。示例内容如下： version: 3.3services:\tmysql: image: mysql:latest #安装mysql镜像 volumes: #映射位置 mysql_data:/var/lib/mysql restart: always environment: #环境变量 MYSQL_ROOT_PASSWORD: liuluhua MYSQL_DATABASE: wordpress MYSQL_USER: liuluhua MYSQL_PASSWORD: liuluhua\twordpress: depends_on: #需要mysql mysql image: wordpress:latest #安装wordpress镜像 ports: 80:80 #端口映射 restart: always environment: #环境变量 WORDPRESS_DB_HOST: mysql:3306 WORDPRESS_DB_USER: liuluhua WORDPRESS_DB_PASSWORD: liuluhua WORDPRESS_DB_NAME: wordpressvolumes:\t./wp-content:/var/www/html/wp-contentvolumes:\tmysql_data: 这里定义了两个自动互相链接的服务 mysql 和 wordpress 使用最新的 mysql 和 wordpress 的 docker 镜像 设置了 MYSQL 和 WordPress 的环境 WordPress 映像基于 Apache，它通过 derfault 在端口 上运行 80。将默认 Apache 端口映射到 8080 本地计算机的端口。 mysql_data：流入这个数据库的数据将被持久化到一个命名卷 mysql_data，这样即使删除了容器，数据仍然存在于的机器上，并且可以再次安装在新的容器中。 volumes 参数 wordpress 是告诉 Docker 的 wp-content 在本地文件系统中显示目录。现在，们为 WordPress 站点的某些部分（例如 wp-content 目录）提供了持久存储。在 wp-content 包含所有用户提供的内容。基本上，可以上传到网站的任何内容都会在此处结束。 只要同时拥有数据库和 wp-content 文件夹，就可以随时恢复的站点，即使其他所有内容都丢失了。 启动和停止docker-compose -f docker-compose.wordpress.yml up -d #后台运行docker-compose -f docker-compose.wordpress.yml down #停止并删除服务````- 如果有错误，查看启动日志：```cppsudo docker-compose logs 如果需要进入容器内命令行： sudo docker-compose exec -it 容器名称 /bin/bash Docker 命令行命令行方式安装docker pull wordpressdocker pull mysql 命令行方式启动docker run -d --name mysql \\\t-v mysql-data:/var/lib/mysql \\\t-e MYSQL_ROOT_PASSWORD=liuluhua \\\t-e MYSQL_DATABASE=wordpress mysql \\docker run -d \\\t-e WORDPRESS_DB_HOST=mysql:3306 \\\t--link mysql \\\t-p 8000:80 wordpress 参数说明 -d 后台运行-p 端口映射 访问 wordpress打开 http://localhost 插件配置WP Githuber MD支持 markdown 配置上传文件大小在 yaml 文件中 volumes 中新增一行： ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini 默认为文件夹，删除修改为文件就行，修改文件内容为： file_uploads = Onmemory_limit = 5Gupload_max_filesize = 5Gpost_max_size = 5Gmax_execution_time = 0 #上传时间限制，修改为0则无限制 之后安装 WP Maximum Upload File Size 插件进行修改即可，最大支持到 2GB 如果要修改超过 2GB： 卸载 WP Maximum Upload File Size 插件，编辑 uploads.ini 编辑 html/wp-config.php @ini\\_set( upload\\_max\\_filesize , 4G );@ini\\_set( post\\_max\\_size, 4G);@ini\\_set( memory\\_limit, 8G );@ini\\_set( max\\_execution\\_time, 0 );@ini\\_set( max\\_input\\_time, 0 ); 编辑 html/wp-content/.htaccess php_value upload_max_filesize 4Gphp_value post_max_size 4Gphp_value memory_limit 8Gphp_value max_execution_time 0php_value max_input_time 0","categories":["1.平台","Docker"]},{"title":"keyring库","path":"/2024/08/21/1-平台-Linux-加密-keyring库/","content":"使用 keyring 库安全地存储和检索敏感信息（如密码）。 keyring 提供了一个安全的方式来管理这些信息，而不是将明文存储在代码或配置文件中。但是 keyring 库不是 Linux 内核的密钥保留服务，而是一个独立的 C++ 库，提供了跨平台的密码管理功能。它通常会使用操作系统提供的安全存储机制（如 Linux 的 Secret Service API 或 Windows 的 Credential Manager）来实现其功能。 #include keyring/keyring.h#include iostream#include stringint main() std::string service_name = foo; std::string account = bar; std::string password_input = password; std::string password_output = ; keyring::set_password(service_name, account, password_input); keyring::get_password(service_name, account, password_output); std::cout password_output std::endl; return 0;","categories":["1.平台","Linux","加密"]},{"title":"内核密钥保留服务","path":"/2024/08/20/1-平台-Linux-加密-内核密钥保留服务/","content":"Linux 内核提供了密钥保留服务(Key Retention Service),可以用于应用程序加密。Linux 密钥保留服务（Linux key retention service 是在 Linux 2.6 中引入的，它的主要意图是在 Linux 内核中缓存身份验证数据。远程文件系统和其他内核服务可以使用这个服务来管理密码学、身份验证标记、跨域用户映射和其他安全问题。它还使 Linux 内核能够快速访问所需的密钥，并可以用来将密钥操作（比如添加、更新和删除）委托给用户空间。 启用密钥保留服务 在内核配置中启用密钥服务选项: ## Security options#CONFIG_KEYS=yCONFIG_KEYS_DEBUG_PROC_KEYS=yCONFIG_SECURITY=yCONFIG_SECURITY_NETWORK=yCONFIG_SECURITY_CAPABILITIES=y 安装 keyutils 包,提供密钥管理工具: sudo apt install keyutils 内核层 API register_key_type 定义新的密钥类型。如果存在名称相同的密钥类型，返回 EEXIT。 int register_key_type(struct key_type *type) unregister_key_type 用来取消密钥类型的注册 void unregister_key_type(struct key_type *type); key_alloc 分配指定类型的密钥 struct key *key_alloc(struct key_type *type, const char *desc, uid_t uid, gid_t gid, struct task_struct *ctx, key_perm_t perm, unsigned long flags); key_instantiate_and_link 对密钥进行实例化并将它链接到目标 keyring int key_instantiate_and_link(struct key *key, const void *data,size_t datalen, struct key *keyring,struct key *instkey); request_key 搜索与给定的描述匹配的密钥 struct key *request_key(const struct key_type *type,const char *description,const char *callout_string); lookup_user_key 用于在内核中查找指定 ID 的密钥 key_ref_t lookup_user_key(key_serial_t id, unsigned long flags, key_perm_t perm) key_put 发布一个密钥 void key_put(struct key *key); 应用层 APILinux 内核提供了密钥保留服务(Key Retention Service)服务提供三个新的系统调用，用来在用户空间中操作密钥。 add_key()用于用户空间程序向指定的密钥环中添加新密钥或更新现有密钥。 long add_key(const char *type, const char *description, const void *payload, size_t plen, key_serial_t keyring); add_key 系统调用用来创建类型为 type、长度为 plen 的密钥。密钥描述由 desc 定义，它的有效内容由 payload 指定。密钥链接到 keyring ring。密钥类型可以是 user 或 keyring。其他任何密钥类型必须已经通过内核服务向内核注册，然后才能使用。如果密钥是 keyring 类型的，有效内容就应该是 NULL，plen 应该是零。 request_key()用于请求访问一个密钥。 key_serial_t request_key(const char *type, const char *description, const char *callout_info, key_serial_t dest_keyring); 它允许程序请求访问一个已存在的密钥，如果密钥不存在，还可以触发创建密钥的过程。 keyctl()多功能系统调用,用于执行各种密钥管理操作。其基本用法如下: long keyctl(int operation, ...); keyctl()支持多种操作,包括但不限于: KEYCTL_DESCRIBE 描述一个密钥。 KEYCTL_READ 从一个密钥读取有效内容数据。 KEYCTL_UPDATE 更新指定的密钥。 KEYCTL_LINK 将一个密钥链接到一个 keyring。 KEYCTL_UNLINK 将密钥或 keyring 与另一个 keyring 的链接取消。 KEYCTL_JOIN_SESSION_KEYRING 将一个会话 keyring 替换为新的会话 keyring。 KEYCTL_REVOKE 取消一个密钥。 KEYCTL_CHOWN 修改密钥的所有者。 KEYCTL_SETPERM 修改密钥的权限掩码。 KEYCTL_CLEAR 清除一个 keyring。 KEYCTL_SEARCH 在一个 keyring 树中搜索密钥。 KEYCTL_INSTANTIATE 对部分构造好的密钥进行实例化。 KEYCTL_NEGATE 取消对部分构造好的密钥的实例化。 查看内核中是否支持以下函数： // 读取密钥内容long keyctl_read(key_serial_t key, char *buffer, size_t buflen)// 更新密钥内容 long keyctl_update(key_serial_t key, const void *payload, size_t plen)// 撤销密钥long keyctl_revoke(key_serial_t key) 使用密钥保留服务创建密钥通过密钥保留服务密钥会被存储在内核中,而不是应用程序的内存空间,提高了安全性 内核层模块在它的 init 函数中调用 register_key_type() 来注册这个新密钥类型（名为 mykey）。 #include linux/key-type.hstatic struct key_type my_key_type = .name = mykey,\t.instantiate = my_instantiate_key,\t.describe = my_key_describe,\t.match = my_key_match,\t.destroy = my_key_destroy,;static int __init my_module_init(void) int ret = register_key_type(my_key_type);\tif (ret) pr_err(Failed to register key type ); return ret; pr_info(My key type registered );\treturn 0;static void __exit my_module_exit(void) unregister_key_type(my_key_type);\tpr_info(My key type unregistered );module_init(my_module_init);module_exit(my_module_exit); 当内核模块收到 ioctl 请求时，它首先调用 key_alloc() 来分配一个新的密钥，从而创建一个会话 keyring。 struct key *key;key = key_alloc(my_key_type, my_key, current_uid(), current_gid(), current_cred(), KEY_POS_ALL, 0);if (!IS_ERR(key)) const char *data = secret_data;\tkey_instantiate_and_link(key, data, strlen(data), NULL, NULL); 在成功调用 key_alloc() 之后，调用 key_instantiate_and_link() 对密钥进行实例化。 int ret = key_instantiate_and_link(key, NULL, 0, NULL, NULL);if (ret 0) key_put(key); return ret; 在创建并实例化会话 keyring 之后，为用户的会话创建密钥。 同样，依次调用 key_alloc() 和 key_instantiate_and_link()。 成功完成这些调用之后，用户空间会话就有了一个新密钥。 应用层keyctl add user mykey mysecretvalue @u 使用密钥在应用程序中使用密钥: #include keyutils.h#include stdio.hint main() key_serial_t key; char buffer[256]; long buflen; key = request_key(user, mykey, NULL, KEY_SPEC_SESSION_KEYRING); if (key == -1) perror(request_key); return 1; buflen = keyctl_read(key, buffer, sizeof(buffer)); if (buflen == -1) perror(keyctl_read); return 1; printf(Key data: %.*s , (int)buflen, buffer); return 0; 注意事项 需要内核支持(2.6 及以上版本) libkeyutils.so 是 C 库，在 C++工程中会出现 undefined reference add_key 等错误，头文件 keyutils.h 需要 extern 包含，且需要注意链接时需要添加 LIB += -lkeyutils 一定要初始化 keyutils 库,具体方法如下: int rc = 0;rc = keyctl(KEYCTL_LINK,KEY_SPEC_USER_KEYRING,KEY_SPEC_SESSION_KERING); 只有此处调用成功后,才能调用 add_key(“user”,…);否则,即使 add_key 成功,最后调用 request_key 也会失败，找不到才加入到 keyring 中的 KEY.在内核中调用 request_key 也会失败,返回 NOKEY. 状态查看[root@phoenix set.5]# keyctl showSession Keyring-3 --alswrv 0 0 keyring: session.262139044642 --alswrv 0 0 \\_ mykey: New key type[root@phoenix set.5]# cat /proc/keys00000001 I----- 1 perm 1f3f0000 0 0 keyring _uid_ses.0: 1/400000002 I----- 5 perm 1f3f0000 0 0 keyring _uid.0: empty0253c622 I--Q-- 1 perm 3f3f0000 0 0 mykey New key type: 011a490da I--Q-- 2 perm 3f3f0000 0 0 keyring session.2621: 1/413670439 I--Q-- 2 perm 1f3f0000 0 0 keyring _ses.1977: 1/4159d39b8 I--Q-- 5 perm 1f3f0000 0 0 keyring _ses.1976: 1/43a14f259 I--Q-- 3 perm 1f3f0000 0 0 keyring _ses.1978: 1/4[root@phoenix set.5]# cat /proc/key-users0: 8 7/7 5/100 136/1000043: 2 2/2 2/100 56/1000048: 2 2/2 2/100 56/1000081: 2 2/2 2/100 56/10000786: 4 4/4 4/100 113/10000keyctl describe ``Key`` command gives the description of key.[root@phoenix set.5]# keyctl describe -3-3: alswrvalswrv------------ 0 0 keyring: session.2621[root@phoenix set.5]# keyctl describe 3904464239044642: alswrvalswrv------------ 0 0 mykey: New key type[avinesh@phoenix set.5]$ keyctl search -3 mykey New key type39044642[root@phoenix set.5]# exitexitNow back to our previous state[root@phoenix set.5]# keyctl showSession Keyring-3 --alswrv 0 0 keyring: _ses.19762 --alswrv 0 0 \\_ keyring: _uid.0[root@phoenix set.5]# rmmod ./kernel.land/newkey.koUnloading the module.Unregistered learning_key 内核中的密钥管理内核密钥管理在 proc 文件系统中创建了两个只读文件：prockeys 和prockey-users。它们没有被创建在procpid 目录下，而是被直接创建在了 proc 文件系统的根目录下。这就造成了进程根本无法查看到别的进程的密钥。 prockeys 文件列出当前进程可查看的密钥，所以不同的进程读出的内容会不同。如果一个进程希望了解它可以查看哪些密钥，它可以通过读取 prockeys 获得这些信息。列出的内容包括序列号、过期时间、访问允许位、uid、gid、类型、描述等。在配置内核时，必须启用这个文件，因为它允许任何用户列出密钥数据库。 prockey-users 列出密钥的统计信息，包括 uid、使用计数、密钥总数量和实例化数量、密钥数量的配额信息、密钥占用内存的配额信息。","categories":["1.平台","Linux","加密"]},{"title":"SSH服务","path":"/2024/08/19/1-平台-Windows-SSH服务/","content":"WindowsSSH 服务端配置在 Windows 中配置 SSH 服务端的步骤如下（根据 win 版本不一致可能位置不同）： 打开”设置”。 选择”系统”。。 选择”可选功能”。 点击”添加功能”，然后搜索并安装”OpenSSH 服务器”和”OpenSSH 客户端”。 手动安装如果无法添加，这里提供下手动安装的方式 下载 OpenSSH https://github.com/PowerShell/Win32-OpenSSH/releases 解压缩 OpenSSH-Win64.zip，以管理员权限打开 cmd，执行 powershell.exe -ExecutionPolicy Bypass -File install-sshd.ps1 启动 SSH 服务 sc config sshd start= auto #设置SSH服务自动启动net start sshd #开启SSH服务 验证在命令提示符（cmd）中输入以下命令以验证 SSH 客户端是否已正确安装： ssh localhost 启动 SSH 服务要启动 SSH 服务，请在命令提示符中运行以下命令： net start sshd 停止 SSH 服务要停止 SSH 服务，请在命令提示符中运行以下命令： net stop sshd SSH 客户端Windows 10 和更高版本自带 SSH 客户端，可以在命令提示符中使用以下命令进行连接： ssh 用户名@用户ip LinuxSSH 服务端在 Linux 中安装和配置 SSH 服务端的步骤如下： 更新软件包列表： sudo apt update 安装 OpenSSH 服务器： sudo apt install openssh-server 启动 SSH 服务： sudo systemctl start ssh 设置 SSH 服务开机自启： sudo systemctl enable ssh SSH 客户端在 Linux 中使用 SSH 客户端连接到远程主机的命令如下： ssh 用户名@用户ip 例如，连接到本地机器： ssh username@127.0.0.1 拷贝使用 scp 命令从 Linux 拷贝文件到 Windows： scp /linux/folder/copyfilename Winusername@Winip:/c:/user/username/Desktop 免密码连接要实现免密码连接，可以使用 sshpass 工具。首先安装 sshpass： sudo apt install sshpass 然后使用以下命令进行免密码拷贝： sshpass -p passwd scp /linux/folder/copyfilename Winusername@Winip:/c:/user/username/Desktop 通过以上步骤，可以在 Windows 和 Linux 系统上成功配置和使用 SSH 服务。","categories":["1.平台","Windows"]},{"title":"FTP 配置","path":"/2024/08/16/1-平台-Linux-网络-FTP-FTP-配置/","content":"FTP 配置 - 用于图床安装 FTP 服务端首先，需要在的服务器上安装 FTP 服务端软件。将使用 vsftpd，这是一个广泛使用且安全的 FTP 服务器。可以通过以下命令进行安装： sudo apt install vsftpd -y 这个命令会自动下载并安装 vsftpd 及其依赖项。安装完成后，将能够配置和使用 FTP 服务。 修改配置文件接下来，需要编辑 vsftpd 的配置文件，以确保服务器的安全性和功能性。使用以下命令打开配置文件： sudo vi /etc/vsftpd.conf 在配置文件中，需要进行以下更改： 禁止匿名访问：为了保护的服务器，应该禁用匿名用户的访问。找到以下行并确保它们被设置为： anonymous_enable=NO 这将防止任何未授权的用户访问的 FTP 服务器。 接受本地用户：确保本地用户可以登录。找到并修改以下行： local_enable=YES 这允许服务器上的本地用户使用他们的凭据进行访问。 允许上传：为了使用户能够上传文件，需要启用写入权限。确保以下行被设置： write_enable=YES 更改创建文件权限：可以设置新创建文件的权限掩码，以控制文件的默认权限。将以下行添加或修改为： local_umask=022 这将确保新文件的权限为 755，即所有者可以读、写和执行，而组用户和其他用户只能读和执行。 重启服务完成配置文件的修改后，需要重启 vsftpd 服务，以使更改生效。使用以下命令重启服务： sudo service vsftpd restart 这将重新加载配置并启动 FTP 服务。 创建 FTP 用户最后，需要创建一个 FTP 用户，以便可以通过 FTP 访问的图床。使用以下命令创建用户： sudo useradd -d /home/lemonade -M lemonade 在这个命令中，-d 选项指定用户的主目录，而 -M 选项表示不创建用户的主目录。接下来，需要为新用户设置密码： sudo passwd lemonade 系统会提示输入并确认新用户的密码。完成后，就可以使用该用户通过 FTP 访问的服务器了。","categories":["1.平台","Linux","网络","FTP"]},{"title":"3566与3568与3588之间的差异","path":"/2024/08/15/1-平台-嵌入式-3566与3568与3588之间的差异/","content":"接口差异 外部存储接口: RK3568 支持 ECC 内存 RK3566 不支持 ECC 内存 PCI-E 接口: RK3568 支持 PCI-E 3.0 RK3566 仅支持 PCI-E 2.1 以太网接口: RK3568 配备双千兆网口 RK3566 只有单千兆网口 SATA 接口: RK3568 支持 3 个 SATA 3.0 接口 RK3566 仅支持 1 个 SATA 3.0 接口 显示输出: RK3568 支持三重显示 RK3566 支持双显示 技术参数差异表： Processor Rockchip RK3568 Rockchip RK3566 Rockchip RK3588 Market (main) Single-board computer Single-board computer High-performance single-board computer ISA ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) Microarchitecture Cortex-A55 Cortex-A55 Cortex-A76 + Cortex-A55 Family RK3500 RK3500 RK3500 Part number(s), S-Spec RK3568 RK3566 RK3588 Release date Q2 2020 Q2 2020 Q1 2022 Lithography 22 nm 22 nm 8 nm Cores 4 4 8 (4+4) Threads 4 4 8 Base frequency 2.0 GHz 1.8 GHz 2.4 GHz (A76), 1.8 GHz (A55) Turbo frequency - - - High performance cores 4x ARM Cortex-A55 @ 2.0 GHz 4x ARM Cortex-A55 @ 1.8 GHz 4x Cortex-A76 @ 2.4 GHz Cache memory 256 KB 256 KB 1 MB L3 Max memory capacity 8 GB 4 GB 32 GB Memory types LPDDR4-1600 DDR3, DDR3L, LPDDR3, DDR4, LPDDR4X LPDDR4X-3200, LPDDR5-2400 Max PCIe lanes 1 1 4 TDP 5 W 5 W 10-15 W GPU integrated graphics ARM Mali-G52 2EE MC2 ARM Mali-G52 MP2 ARM Mali-G610 MP4 GPU execution units 2 2 4 GPU shading units 32 32 - GPU base clock - 850 MHz 1000 MHz GPU boost clock 820 MHz 950 MHz - GPU FP32 floating point 54.4 GFLOPS 54.4 GFLOPS 614 GFLOPS Socket SoC SoC SoC Drystone MIPS 22,736 DMIPS 20,462 DMIPS - AI accelerator AI accelerator RKNN NPU - NPU AI computing operations per seconds 0.8 TOPS - 6 TOPS Crypto engine Cipher Engine, SHA-1, SHA-256224,SHA-512384, MD5, AES-128, AES-192,AES-256, DES, TDES, TRNG - - Max display resolution 4K@60fps - 8K@60fps Video decoding H.265H.264VP9 4K@60fps - 8K@60fps H.265VP9AVS2, 8K@30fps H.264 AVCMVC Video encoding H.265H.264 1080p@60fps - 8K@30fps H.265H.264 Max video capture MIPI-CSI - - Modem Gigabit Ethernet - 2.5 GbE Connectivity SATA 3.0, eMMC, HDMI 2.0,USB 3.0, USB 2.0 - PCIe 3.0, USB 3.1, HDMI 2.1 Wi-Fi WiFi 6 (802.11ax) - Wi-Fi 6 (802.11ax) Bluetooth Bluetooth 5.0 - Bluetooth 5.2 Audio SPDIF, PWM, SPI, I2S, I2C - - (Android 64-bit)Geekbench 4 single core 875 756 - (Android 64-bit)Geekbench 4 multi-core 2,375 1,997 - (Android)Geekbench 5 single core 161 108 ~800 (Android)Geekbench 5 multi-core 492 281 ~2800 (SGEMM)GFLOPS performance 21.2 GFLOPS 18.2 GFLOPS - (Multi-core watt performance)Performance watt ratio 475 pts W 399 pts W -","categories":["1.平台","嵌入式"]},{"title":"3568GPU负载查看及参数设置","path":"/2024/08/14/1-平台-嵌入式-3568GPU负载查看及参数设置/","content":"1.Look up the load@frequency of GPU 查看当前负载和频率 cat /sys/class/devfreq/*.gpu/load 2.Look up the supported mode or supported frquency for GPU 查看当前支持的模式和频率 cat /sys/class/devfreq/*.gpu/available_governorscat /sys/class/devfreq/*.gpu/available_frequencies 3.Set performance(the most high frequency) for GPU 设置性能模式 echo performance /sys/class/devfreq/*.gpu/governor 4.Set frequency for GPU 设置频率 #设置模式为用户模式echo userspace /sys/class/devfreq/*.gpu/governor#打印当前支持的频率cat /sys/class/devfreq/*.gpu/available_frequencies#将要设置的频率写入(ps: you should do step 2 to ensure the available_frequencies before you set) echo 800000000 /sys/class/devfreq/*.gpu/set_freq 5.Get a version 获取版本信息 strings libMali.so | grep rk_so_ver 6.Set power always on 关闭节能模式 echo always_on /sys/devices/*.gpu/power_policy 循环打印 GPU 负载脚本 #!/bin/shwhile [ 1 ]docat /sys/class/devfreq/fde60000.gpu/loadsleep 1done","categories":["1.平台","嵌入式"]},{"title":"OK4418平台","path":"/2024/08/13/1-平台-嵌入式-OK4418平台/","content":"连接开发板调试串口通过调试串口连接开发板，调试串口为 DB9，上位机直接连接，波特率为 115200，登录名为 root 网口通过网口连接，配置电脑的 IP 为 192.168.1.122，开发板的 IP 为 192.168.1.123，通过 ssh 连接，登录名为 root 下载文件通过 FileZilla Client 软件下载文件到开发板上，新建连接站点，主机地址为 192.168.1.123，通过 FTP 协议，端口为 21，不加密只使用普通 FTP，用户名为 root，密码为 forlinx。 连接成功后，将文件拷贝到opt 目录下，如果目录下有相同名字的文件，最好将原文件删除后，在拷贝文件。 配置自启动#!/bin/shexport PATH=/bin:/sbin:/usr/bin:/usr/sbinexport T_ROOT=/usr/local/tslibexport LD_LIBRARY_PATH=/usr/local/tslib/lib:$LD_LIBRARY_PATHexport TSLIB_CONSOLEDEVICE=noneexport TSLIB_FBDEVICE=/dev/fb0export TSLIB_TSDEVICE=/dev/input/event1export TSLIB_PLUGINDIR=$T_ROOT/lib/tsexport TSLIB_CONFFILE=$T_ROOT/etc/ts.confexport POINTERCAL_FILE=/etc/pointercalexport TSLIB_CALIBFILE=/etc/pointercalexport QTDIR=/forlinx/qtexport QT_QPA_PLATFORM=eglfsexport LD_LIBRARY_PATH=$QTDIR/lib:$LD_LIBRARY_PATHexport QT_QPA_GENERIC_PLUGINS=tslibexport QT_QPA_PLATFORM_PLUGIN_PATH=$QTDIR/pluginsexport QT_QPA_EGLFS_FB=/dev/fb0export QT_QPA_EGLFS_TSLIB=1export QWS_SIZEexport KEYPAD_DEV=/dev/input/event0export QWS_KEYBOARD=LinuxInput:/dev/input/keyboardexport LD_LIBRARY_PATH=/forlinx/qt/lib/plugins/imageformats:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/usr/local/opengl_lib_inc/libs:$LD_LIBRARY_PATHexport QT_PLUGIN_PATH=/forlinx/qt/lib/pluginsexport LD_PRELOAD=/lib/preloadable_libiconv.so#export QT_QPA_EGLFS_DISABLE_INPUT=1export QT_QPA_FONTDIR=$QTDIR/lib/fontsif [ -e /dev/input/event3 ];then export QT_QPA_EVDEV_KEYBOARD_PARAMETERS=/dev/input/event3fiif [ -e /usr/local/bluez5/var/run/dbus/pid ]then rm /usr/local/bluez5/var/run/dbus/pidfiexport DBUS_SESSION_BUS_ADDRESS=unix:path=/usr/local/bluez5/var/run/dbus/system_bus_socketTOUCH=`cat /etc/t2m` /dev/null 21if [ $TOUCH == M ];thenexport QWS_MOUSE_PROTO=Tslib:/dev/input/event1 mouseman:/dev/input/miceelseexport QWS_MOUSE_PROTO=Tslib:/dev/input/event1fi/opt/PCR -qws 配置脚本文件，如上所示，将该脚本文件拷贝到opt 目录下，修改etcinit.dS99app 注释掉forlinxbinapp.sh $ACTTION ，最后一行增加optStartPCR.sh 中文文本支持配置脚本文件，如上所示，将该脚本文件拷贝到opt 目录下，修改etcinit.dS99app 注释掉forlinxbinapp.sh $ACTTION ，最后一行增加optStartPCR.sh","categories":["1.平台","嵌入式"]},{"title":"最大打开文件数量","path":"/2024/08/09/1-平台-Linux-文件系统-最大打开文件数量/","content":"报错：Can’t open so many files 或者 too many open files 涉及参数 参数 说明 默认值 查询语句 nofile 单个进程的最大打开文件数 1024 ulimit -n 或者 cat procpidlimits nr_open 单个进程可分配的最大文件数 1024*10241048576 cat procsysfsnr_open file-max 系统内核一共可以打开的最大值 199708 cat procsysfsfile-max nofile 是 linux 操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接字数量） file-max 是设置系统所有进程一共可以打开的文件数量 。同时一些程序可以通过 setrlimit 调用，设置每个进程的限制。 nofile临时修改ulimit -SHn 1024000 分软限制和硬限制，加-H 就是硬限制，加-S 就是软限制。默认显示的是软限制，如果运行 ulimit 命令修改时没有加上-H 或-S，就是两个参数一起改变。 硬限制就是实际的限制，而软限制是警告限制，它只会给出警告。 永久修改一vi /etc/security/limits.conf * 表示所用的用户 二修改 /etc/profile 增加 ulimit -SHn 128000 etcprofile 是 Linux 系统中的一个重要配置文件，主要用于设置系统级的环境变量和启动程序。该文件在用户登录时被执行，适用于所有用户。 系统总限制临时修改echo 1200000 /proc/sys/fs/nr_openecho 200000 /proc/sys/fs/file-max 永久修改一在文件procsysfsnr_open 中加入如下代码：（1200000 为修改的参数值） fs.nr_open=1200000 在文件 procsysfsfile-max 中插入如下代码： fs.file-max=200000 保存并执行 reboot 重启服务器。 二在etcsysctl.conf 中设置 fs.nr_open 1200000 fs.file-max200000，然后执行 sysctl -p，使配置生效。无需重启。 查看系统下各个进程打开的文件描述符数量lsof -n |awk print $2|sort|uniq -c |sort -nr #匹配PID为696的进程lsof -fp | grep 696 | wc -l","categories":["1.平台","Linux","文件系统"]},{"title":"Yocto笔记","path":"/2024/08/08/1-平台-嵌入式-Yocto笔记/","content":"什么是 YoctoYocto Project 是一个开源协作项目，主要用于为嵌入式系统开发自定义的 Linux 操作系统。它提供了一整套工具和模板，使得开发者可以在多种硬件架构上构建功能齐全、轻量级且定制化的嵌入式 Linux 发行版。 Yocto 不仅仅是一个 Linux 发行版，它更像是一个构建系统，帮助从源代码生成一个完整的 Linux 系统，包括内核、根文件系统、工具链和应用程序。Yocto 项目通过 BitBake 构建系统和 OpenEmbedded 核心来实现这一切。 Yocto 的基本概念 BitBake: Yocto 构建系统的核心工具，类似于 GNU Make，但功能更强大。它使用 .bb、.bbclass 和 .conf 文件定义构建任务、元数据和配置。 Layer (层): Yocto 项目中的层是一组元数据文件，用于组织和管理构建配置。常见的层包括 meta 层（核心）、meta-oe（OpenEmbedded 扩展层）和 meta-raspberrypi（树莓派支持层）。 Recipe (配方): 配方是 Yocto 中的基本构建单元，它定义了如何获取源代码、应用补丁、编译和安装软件包。配方文件通常以 .bb 结尾。 Machine (机器): Yocto 为不同硬件架构和开发板定义了 machine 配置，这些配置决定了目标硬件的具体构建选项。 Distro (发行版): Yocto 的发行版配置定义了一个操作系统的核心部分，包括使用的包管理器、C 库以及其他系统级配置。 Image (镜像): 镜像是通过 Yocto 构建出的最终产品，它是一个可以直接在目标硬件上运行的文件系统和内核。 Yocto 如何使用1. 安装 Yocto 环境要使用 Yocto，首先需要安装构建环境，包括一些基本的开发工具和 Git。 sudo apt-get install gawk wget git-core diffstat unzip texinfo gcc-multilib build-essential chrpath socat libsdl1.2-dev xterm 2. 获取 Yocto 源代码需要从 GitHub 或 Yocto 官方仓库中克隆 Yocto 项目的源代码。以下是克隆一个常用的 Yocto 版本分支的示例： git clone -b kirkstone git://git.yoctoproject.org/poky.gitcd poky 3. 初始化构建环境在 Yocto 中，oe-init-build-env 脚本用于初始化构建环境，创建一个新的构建目录。 source oe-init-build-env 这个命令会在当前目录下创建一个新的 build 目录，并将切换到该目录中。所有的构建输出都将在这个 build 目录中生成。 4. 配置构建选项在 build 目录下，可以通过编辑 conf/local.conf 文件来配置构建选项，例如目标机器（MACHINE）、并行构建线程（BB_NUMBER_THREADS）和 DL_DIR（源码下载目录）等。 示例配置： MACHINE ?= qemuarm 如果要为 Raspberry Pi 构建系统，可以修改为： MACHINE ?= raspberrypi4 5. 添加层可以通过 bitbake-layers 工具来管理 Yocto 的层。例如，添加一个新的层： bitbake-layers add-layer ../meta-openembedded/meta-oe 这个命令将 meta-oe 层添加到构建环境中。 6. 构建镜像配置完成后，可以使用 bitbake 命令开始构建系统镜像。常见的构建目标包括 core-image-minimal、core-image-sato 等。 bitbake core-image-minimal 构建过程可能需要一些时间，这取决于的计算资源和网络速度。 7. 部署镜像构建完成后，生成的镜像文件会存放在 build/tmp/deploy/images/ 目录下。可以将这些文件烧录到目标硬件中，例如 SD 卡，或直接在 QEMU 中进行模拟测试。 Yocto 的常用工具 BitBake: 用于执行构建任务的核心工具。将主要使用它来编译配方并生成镜像。 devtool: 一个用于开发者的工具集，简化了 Yocto 项目的扩展和修改。例如，它可以自动生成新的配方或修改现有配方。 bitbake-layers: 用于管理和操作 Yocto 层的工具。它可以添加、删除或列出层。 hoban: 用于查看和分析 Yocto 项目生成的二进制文件和镜像内容的工具。 Toaster: Yocto 提供的一个基于 Web 的图形界面工具，帮助用户管理构建项目并分析结果。 menuconfignconfig: 用于配置 Linux 内核的工具，它们允许在图形界面中选择内核选项。 通过一个实例来详细说明如何在 Yocto 中添加 Mesa 的 OpenGL 驱动是一个很好的实践。这个过程将涵盖如何配置 Yocto 环境、修改配置文件、添加所需的软件包（如 Mesa 驱动），并构建包含 OpenGL 支持的 Linux 镜像。以一个基于 Raspberry Pi 4 的项目为例。 实例目标目标是使用 Yocto 构建一个为 Raspberry Pi 4 定制的 Linux 镜像，并在内核中增加 Mesa 的 OpenGL 驱动。 1. 设置 Yocto 环境1.1 克隆 Yocto Poky 仓库首先，从 Yocto 的官方 Git 仓库克隆 Poky，这包含 Yocto 的核心构建工具和基础层。 git clone -b kirkstone git://git.yoctoproject.org/poky.gitcd poky 1.2 获取 Raspberry Pi 层接下来，克隆 Raspberry Pi 支持的元数据层 meta-raspberrypi。 git clone -b kirkstone git://git.yoctoproject.org/meta-raspberrypi.git 1.3 初始化构建环境使用 Yocto 提供的脚本初始化构建环境，这将创建一个 build 目录。 source oe-init-build-env 1.4 添加层到构建环境在 build 目录中，通过 bitbake-layers 命令添加 meta-raspberrypi 和 meta-openembedded（包含 Mesa 的相关软件包）。 bitbake-layers add-layer ../meta-raspberrypibitbake-layers add-layer ../meta-openembedded/meta-oebitbake-layers add-layer ../meta-openembedded/meta-multimedia 或者创建一个新的层，创建新层后需要在新层中创建 Mesa 配方文件(mesa_%.bbappend) bitbake-layers create-layer meta-opengl PACKAGECONFIG_append = gallium-llvm gallium egl gles gbm driGALLIUMDRIVERS_append = ,swrastDRIDRIVERS_append = ,swrast 2. 配置构建选项2.1 配置 local.conf编辑 conf/local.conf 文件，设置目标机器为 Raspberry Pi 4，并启用 OpenGL 支持。 MACHINE ?= raspberrypi4 确保启用 GL 和 X11 支持，以便 Mesa 的 OpenGL 驱动能够正确构建： DISTRO_FEATURES_append = opengl x11 如果是新层则需要添加 BBLAYERS += $TOPDIR/../meta-opengl 2.2 添加 Mesa 软件包在 local.conf 中，添加以下行以确保 Mesa 和相关驱动程序被包含在构建中： IMAGE_INSTALL_append = mesa mesa-gl mesa-demos mesa: 主 Mesa 包，提供 OpenGL 实现。 mesa-gl: 提供 OpenGL 库。 mesa-demos: 包含一些 OpenGL 的演示程序，方便测试。 3. 构建镜像使用 bitbake 命令构建包含 Mesa OpenGL 驱动的系统镜像。 bitbake core-image-sato 这个过程可能需要一些时间，因为 Yocto 会从源代码编译所有需要的组件，包括 Mesa 驱动程序。 4. 部署和测试4.1 部署镜像构建完成后，生成的镜像文件会存放在 build/tmp/deploy/images/raspberrypi4/ 目录下。可以使用 dd 命令将镜像烧录到 SD 卡上。 sudo dd if=core-image-sato-raspberrypi4.rpi-sdimg of=/dev/sdX bs=4Msync 将 SD 卡插入 Raspberry Pi 4，然后启动设备。 4.2 测试 OpenGL启动 Raspberry Pi 后，通过 SSH 或直接在设备上打开终端，运行 Mesa 的 glxinfo 工具以验证 OpenGL 驱动是否正确安装。 glxinfo | grep OpenGL 应该能够看到与 Mesa 和 OpenGL 相关的输出信息，表明 OpenGL 驱动已正确加载。 此外，可以运行 glxgears（Mesa 的演示程序之一）来测试 OpenGL 的基本功能。 glxgears yocto SDK 目录结构 ├── build // 用户配置文件和工程构建输出目录├── conf├── meta-browser // Web浏览器配方├── meta-clang // 用来构架编译器的LLVM框架系统├── meta-openembedded // 用来交叉编译，安装和打包的元数据├── meta-poky - poky/meta-poky // Poky发行版本的配置数据├── meta-python2 // Python2配方├── meta-qt5 // Qt5官方推出的Qt5配方├── meta-rockchip // Rockchip层，包含Rockchip芯片BSP相关配方├── meta-rust // Rust与Cargo的OpenEmbedded/Yocto层└── poky // 用来构建Linux的构建系统 Yocto 的工程就是这么简单，仅仅只由这几个文件夹构成。yocto 由许许多多的配方构成，它通过配方获取软件源码编译下载构建并解决依赖，正因为如此，也造就了 yocto 不如 buildroot 容易入门的现状，工程虽小，但是编译的过程中需要消耗比较大的空间。 buid 目录下存放着，当前 SDK 存在的所有构建方案，可以看到在 rockchip 平台，该 SDK 当前支持的构建平台，其中，所有的方案均以 local.conf 文件所设置的信息为准。如果存在多个方案，可以在当前文件夹下多个方案文件夹，每个文件夹下均还有自己的方案对应的 conflocal.conf 信息文件。 在当前 SDK 平台中，没有这样做，所以选择方案需要使用 ln -sf **** local.conf 文件来进行方案的选择。 选择好方案之后，目前选择的方案是这样的： lrwxrwxrwx 1 jie jie 23 Aug 24 20:46 local.conf - rk356xroc-rk3568-pc.mk 选择好之后，开始构建 source oe-init-build-envbitbake core-image-minimal 使用构建参数构建出来的 yocto 系统仅仅只是一个能让设备启动的小镜像，没有启动界面。他的配置文件放在： meta-openembedded/meta-xfce/recipes-core/images/core-image-minimal-xfce.bb 可以查看：meta-rockchip/README.md 可以看到 rockchip 对自己命令的支持。 简单列举一下支持的其他命令： core-image-minimal : 一个能够让设备启动的小镜像，它无界面 core-image-sato : 一个支持 Sato 的镜像，它支持带有 Sato 主题和 Pimlico 应用程序的 X11，还包含终端、编辑器和文件管理器，它是一个基于 GNOME Mobile 的用户界面环境，使用 matchbox 作为窗口管理器 meta-toolchain：一个可编译出 gcc 交叉工具链安装程序的选项，生成的文件位于目录pathtoyoctobuildtmpdeploysdk，主要输出文件为.sh 安装文件 meta-ide-support：一个用于确保目录pathtoyoctobuild 包含有 IDE 工具链包的选项，生成的文件为 environment-setup-xxxxxx-neon-poky-linux-gnueabi，位于目录pathtoyoctobuildtmp，直接用 soucre 命令运行即可 更详细的可以查看 yocto 的配置文档： https://www.yoctoproject.org/docs/1.1/poky-ref-manual/poky-ref-manual.html#ref-images yocto 中编译出来的文件： 在 build 中： ├── abi_version├── buildstats├── cache├── deploy //生成的镜像文件├── hosttools //构建工具，当然还没有生成├── log //过程的log├── pkgdata ├── qa.log├── saved_tmpdir├── sstate-control├── stamps├── sysroots //生成的产品根文件系统├── sysroots-components├── sysroots-uninative├── uboot_img_prefix.tmp├── work //编译过程中生成的文件 第三方软件包就放在这里└── work-shared //编译过程中的源文件依赖 kernel 就放在这里 在 build 文件夹中可以使用如下命令快捷编译相关的工具： 编译 ubot bitbake virtual/bootloader 编译 kernel bitbake virtual/kernel 编译工具或者软件包 bitbake xxxxxx // xxxxx为配方 bb 文件之前的部分 具体可以使用 bitbake s 查看当前系统中都支持构建哪些包 如果没有自己想要的软件包，可以在 yacto 官网上下载自己需要的配方，添加进 yacto 中，再次查看是否添加进来。","categories":["1.平台","嵌入式"]},{"title":"嵌入式Qt的窗口系统","path":"/2024/08/07/1-平台-嵌入式-嵌入式Qt的窗口系统/","content":"自从 Qt 5.0 发布以来，Qt 不再包含自己的窗口系统（QWS）实现。对于单进程用例，Qt 平台抽象是一个优秀的解决方案。Wayland 可以支持多种图形化流程。 有多个平台插件在嵌入式 Linux 系统上可用：EGLFS，LinuxFB，DirectFB，Wayland。这些可用性取决于 Qt 的配置。在许多开发板上选择 eglfs 作为默认选项。如果默认值不合适，QT_QPA_PLATFORM 则可以使用环境变量参数来请求另一个插件。或者，对于快速测试，-platform 命令行可以使用相同的语法。 配置特定设备对于给定的设备构建 Qt 需要一个工具链和一个 sysroot。另外，一些设备需要针对 EGL 和 OpenGL ES 2.0 支持的供应商特定的适配代码。这与非加速平台无关，例如使用 LinuxFB 插件的平台，仅用于基于软件的渲染。 目录 qtbase mkspecs devices 包含许多设备的配置和图形适配代码。例如，linux-rasp-pi2-g++mkspec 包含构建设置，如 Raspberry Pi 2 设备的最佳编译器和链接器标志。mkspec 还包含有关 eglfs 钩子的实现（供应商特定的适配代码）的信息，或者是对适合的 eglfs 设备集成插件的引用。通过配置工具的-device 参数选择设备。在此参数之后的名称必须至少部分地匹配设备下的一个子目录。 以下是 Raspberry Pi 2 的示例配置。对于大多数嵌入式 Linux 板，configure 命令如下： ./configure -release -opengl es2 -device linux-rasp-pi2-g++ -device-option CROSS_COMPILE = $TOOLCHAIN/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian/bin/arm-linux-gnueabihf- -sysroot $ROOTFS -prefix /usr/local/qt5 最重要的参数是 -device 和 -sysroot。通过指定 -sysroot，configure 特征检测测试使用的包含文件和库以及 Qt 本身，取自指定的位置，而不是主机 PC 的标准位置。这意味着在主机上安装开发包是无关紧要的。例如，要获得 libinput 支持 libinput，在主机环境中安装开发头和库是不够的。相反，目标架构（例如 ARM）的标头和库必须存在于 sysroot。 pkg-config 在执行交叉编译时也得到支持。configure 自动设置 PKG_CONFIG_LIBDIR 为 pkg-config 基于 sysroot 代替主机的报告编译器和链接器设置。这通常功能很好，没有任何进一步的调整。但是，PKG_CONFIG_PATH 运行前，主机必须先设置环境变量 configure。否则，Qt 构建可能会尝试从主机系统使用不适当的头文件和库。 指定 -sysroot 在 --sysroot 调用编译器时自动设置参数的结果。在某些情况下，这是不可取的，可以通过传递 -no-gcc-sysroot 来禁用 configure。 -prefix，-extprefix 并 -hostprefix 控制 Qt 构建的目标目标目录。在上述示例中，Qt 的 ARM 版本预计将放置在 /usr/local/qt5 目标设备上。请注意，运行 make install 不会部署任何设备。相反，该 install 步骤将目标指定的目录 extprefix 默认为 sysroot+ prefix，因此是可选的。然而，在很多情况下，”污染”是不可取的，因此指定 -extprefix 变得重要。最后，-hostprefix 允许从目标的二进制文件分离主机工具，如 qmake，rcc，uic。给定时，这些工具将安装在指定的目录下，而不是 extprefix。 嵌入式 Linux 设备的平台插件EGLFSEGL 是 OpenGL 和本机窗口系统之间的接口。Qt 可以利用 EGL 进行上下文和表面管理，但其 API 不包含与平台特定内容相关的功能。这意味着创建本机窗口的过程（需要注意的是，这不一定是用户在屏幕上看到的实际窗口）仍然必须通过平台特定的方式来实现。因此，开发过程中需要编写适用于特定开发板或 GPU 的适配代码。这样的修改可以通过 eglfs 钩子来实现。这些钩子可以是单个源文件，编译到平台插件中，也可以作为动态加载的 EGL 设备集成插件提供。 EGLFS 是一个旨在运行在没有实际窗口系统（如 X11 或 Wayland）的环境中的平台插件，它支持在 EGL 和 OpenGL ES 2.0 之上运行 Qt5 应用程序。除了支持 Qt Quick 2 和本机 OpenGL 应用程序外，EGLFS 也可以渲染软件渲染的窗口（例如 QWidget）。在使用 QWidget 的情况下，这意味着小部件的内容会被 CPU 渲染成图像，然后上传给纹理，由插件进行合成处理。 EGLFS 是现代嵌入式 Linux 设备的重要插件，尤其在包含 GPU 的设备上表现优越。 使用 EGLFS 时，系统会强制第一个顶级窗口（这可以是 QWidget 或 QQuickView）以全屏模式运行。这个窗口也是被选为根部件窗口的地方，所有其他的顶级窗口小部件（例如对话框、弹出菜单或组合框的下拉列表）都将被合成到其中。这种设计是必需的，因为在 EGLFS 的运行环境中，总是会有一个本机窗口和一个 EGL 窗口表面，这些窗口由首个创建的窗口小部件或窗口生成。当主窗口在整个应用程序的生命周期中始终存在，并且其他窗口小部件是非顶层或在主窗口之后创建时，这种方法非常有效。 然而，对于基于 OpenGL 的窗口，EGLFS 还存在其他的限制。从 Qt 5.3 开始，EGLFS 支持一个全屏的 GL 窗口（例如基于 OpenGL 的 QWindow、QQuickView 或 QGLWidget）。需要注意的是，一旦试图打开额外的 OpenGL 窗口，或者将这些窗口与基于 QWidget 的内容混合，系统将不再支持此类操作，并会导致应用程序终止，同时会返回错误消息。这种限制可能对开发者构建复杂界面时产生一定影响，例如在需要多窗口显示的应用场景中。 如有必要，eglfs 可以使用以下环境变量进行配置： QT_QPA_EGLFS_INTEGRATION- 除了编译的钩子之外，还可以以动态加载的插件的形式提供设备或供应商特定的适配。这个环境变量强制执行一个特定的插件。例如，将其设置为 eglfs_kms 使用 KMS DRM 后端。这只是在设备 makepecs 中没有指定静态或编入钩子的选项。在实践中，传统的编入钩子很少被使用，几乎所有后端都被迁移到插件。设备制造商仍然包含相关 EGLFS_DEVICE_INTEGRATION 条目：该特定设备的首选后端的名称。这是可选的，但是非常有用，以避免在目标系统中存在多个插件的情况下设置此环境变量。DISPLAY 在桌面环境中，根据环境变量的存在，KMS 或 X11 后端是优先的。请注意，在某些电路板上使用特殊的值 none 而不是实际的插件。这表明使用 EGL 与 framebuffer 不需要特殊的集成，所以不能加载插件。 QT_QPA_EGLFS_PHYSICAL_WIDTH 和 QT_QPA_EGLFS_PHYSICAL_HEIGHT-物理屏幕宽度和高度以毫米为单位。在不能从帧缓冲设备 dev fb0 或其他方式查询值的平台上，使用默认 DPI 为 100。此变量可用于覆盖任何此类默认值。设置此选项很重要，因为基于 QWidget 或 Qt Quick Controls 的应用程序依赖于这些值。使用硬编码设置运行可能会导致用户界面元素大小不适合在使用中显示。 QT_QPA_EGLFS_ROTATION- 指定在基于 QWidget 的应用程序中应用于软件渲染内容的旋转。支持的值为 180,90 和-90。这不适用于基于 OpenGL 的窗口，包括 Qt Quick。Qt Quick 应用程序可以在 QML 场景中应用转换。无论应用程序类型如何，标准的 eglfs 鼠标光标总是考虑到该值，具有适当定位和旋转的指针图像。特殊光标实现（如 KMS DRM 后端的硬件光标）可能不支持旋转。 QT_QPA_EGLFS_FORCEVSYNC- 设置后，每次调用 eglSwapBuffers（）后，帧缓冲设备上的 eglfs 请求 FBIO_WAITFORVSYNC。这仅适用于依赖于 fbdevLinux 的传统子系统的后端。通常，默认交换间隔为 1，Qt 假定调用 eglSwapBuffers（）处理 vsync; 如果没有（例如，由于驱动程序错误），请尝试设置 QT_QPA_EGLFS_FORCEVSYNC 为非零值。 QT_QPA_EGLFS_FORCE888 - 设置时，在创建新的上下文，窗口或屏幕外表面时，将忽略红色，绿色和蓝色颜色通道大小。相反，插件要求每个通道 8 位配置。这对于在默认情况下选择具有小于 32 或 24 位像素（例如 5-6-5 或 4-4-4）的配置的设备可能是有用的，但是已知不是理想的，例如，由于绑带效应。而不是更改应用程序代码，此变量提供了一个更容易的快捷方式来强制 24 或 32 bpp 配置。 此外，以下较不常用的变量也可用： QT_QPA_EGLFS_FB - 覆盖帧缓冲设备。默认是devfb0。在大多数嵌入式平台上，这不是很相关，因为帧缓冲区仅用于查询显示维度等设置。然而，在某些设备上，该参数提供了指定要在多个显示设置中使用的显示的功能，类似于 LinuxFB 中的 fb 参数。 QT_QPA_EGLFS_WIDTH 和 QT_QPA_EGLFS_HEIGHT- 包含屏幕宽度和高度（以像素为单位）。在 eglfs 尝试从 framebuffer 设备 dev fb0 中确定尺寸时，但是这并不总是和手动指定大小可能变得必要。 QT_QPA_EGLFS_DEPTH - 覆盖屏幕的颜色深度。在 framebuffer 设备 dev fb0 不可用或查询不成功的平台上，使用默认值 32。此变量可用于覆盖任何此类默认值。请注意，这仅影响 QScreen 报告的颜色深度值。它与 EGL 配置和 OpenGL 渲染使用的颜色深度无关。 QT_QPA_EGLFS_SWAPINTERVAL- 默认情况下 1 将要求交换间隔。这使得能够与显示器垂直刷新同步。该值可以用此环境变量覆盖。例如，传递 0 将禁用交换阻塞，导致尽可能快地运行而没有任何同步。 QT_QPA_EGLFS_DEBUG - 设置时，调试输出上会打印一些调试信息。例如，输入的 QSurfaceFormat 和所选 EGL 配置的属性在创建新上下文时打印。与 Qt Quick 的 QSG_INFO 变量一起，可以为与 EGL 配置相关的故障排除提供有用的信息。 除此之外 QT_QPA_EGLFS_DEBUG，eglfs 还支持更现代的 Qt 分类日志记录系统。以下日志记录类别可用： qt.qpa.egldeviceintegration - 为动态加载的后端启用日志记录。非常有用的检查后端是否正在使用。 qt.qpa.input - 启用来自 evdev 和 libinput 输入处理程序的调试输出。检查给定输入设备是否被识别和打开非常有用。 qt.qpa.eglfs.kms - 在 KMS DRM 后端启用详细日志记录。 运行后 configure，确保检查其输出。由于相应的配置测试失败，没有启用必要的 eglfs 后端，libudev 或 libinput 是相当常见的问题，可以通过这种方式快速识别。当有不想要的”不”的结果，运行 configure 与-v 才能看到编译器和链接调用每个配置测试打开详细输出。 注意：关于缺少标题，库或似乎隐含的链接器故障的错误通常是不完整或破碎的 sysroot 的标志，与 Qt 无关，也不能被 Qt 解决。 例如，当使用 Broadcom 专有图形驱动程序定位 Raspberry Pi 时，输出应包含以下内容。如果不是这样，没有必要进一步进行构建，因为如果没有 Raspberry Pi 特定的后端，加速图形将不起作用，即使 Qt 的其余部分成功编译。 QPA 后端： EGLFS ................................yesEGLFS 详细信息：EGLFS i.Mx6 ........................ noEGLFS i.Mx6 Wayland ................ noEGLFS EGLDevice .................... noEGLFS GBM .......................... noEGLFS mali.........................EGLFS Rasberry Pi ..................yesXL 上的 EGL ......................... LinuxFB该插件通过 Linux 的 fbdev 子系统直接写入帧缓冲区。只支持软件渲染内容。请注意，在某些设置上，显示性能预计将受到限制。 从 Qt 5.9 开始，由于 fbdev 在 Linux 内核中被弃用，DRM dumb 缓冲区支持也是可用的。必须通过将 QT_QPA_FB_DRM 环境变量设置为非零值来请求。当设置时，只要系统支持哑缓冲区，传统的帧缓冲设备devfb0 就不会被访问。相反，通过 DRM API 设置渲染，类似于 eglfs_kmseglfs 的后端。输出将被双缓冲和页面翻转，为软件渲染内容提供适当的 vsync。 注意：当使用哑缓冲区时，以下所述的任何选项都不适用，因为物理和逻辑屏幕尺寸等属性都将被自动查询。 该 linuxfb 插件允许通过将它们传递给 QT_QPA_PLATFORM 环境变量或 -platform 命令行选项来指定其他设置。例如，QT_QPA_PLATFORM=linuxfb:fb=/dev/fb1 指定 /dev/fb1 必须使用帧缓冲设备而不是默认值 fb0。可以通过用冒号分隔多个设置来指定多个设置。 fbdevfbN - 指定帧缓冲设备。在多个显示设置上，这通常允许在不同显示器上运行应用程序。暂时没有办法从一个 Qt 应用程序使用多个帧缓冲区。 size=width xheight - 指定屏幕大小（以像素为单位）。插件尝试从 framebuffer 设备查询物理和逻辑的显示维度。然而，这可能并不总是导致正确的结果，因此可能需要明确指定值。 mmsize=width xheight - 物理宽度和高度（以毫米为单位）。 offset=width xheight - 指定屏幕左上角的像素偏移量。默认位置在(0, 0)。 nographicsmodeswitch - 不要将虚拟终端切换到图形模式（KD_GRAPHICS）。除了切换到图形模式外，闪烁的光标和屏幕消隐也通常被禁用。设置此参数时，也会跳过这些参数。 tty=/dev/ttyN - 覆盖虚拟控制台。仅在 nographicsmodeswitch 未设置时使用。 从 Qt 5.9 起，在窗口大小调整策略中，eglfs 和 linuxfb 的行为已被同步：第一个顶级窗口被迫使用两个平台插件覆盖整个屏幕。如果不想这样，环境变量设置 QT_QPA_FB_FORCE_FULLSCREEN 到 0 以恢复早期的 Qt 版本的行为。 输入当没有窗口系统存在时，鼠标，键盘，以及触摸输入是通过直接读取 evdev 或使用辅助库如 libinput 或 tslib。请注意，这要求 /dev/input/event* 用户可以读取设备节点。eglfs 并 linuxfb 具有编译的所有输入处理代码。 使用 libinputlibinput 是一个用于处理输入设备的库。它提供了 Qt 自己的 evdev 输入支持的替代方案。为了能够使用 libinput，请确保所开发的文件 libudev 和 libinput 配置和构建 Qt 时可用。xkbcommon 如果需要键盘支持，也是必需的。由于这些插件默认使用 eglfs，因此 linuxfb 无需进一步的操作 libinput。如果 libinput 支持不可用或环境变量 QT_QPA_EGLFS_NO_LIBINPUT 设置，Qt 自己的 evdev 处理程序进来玩。 输入 eglfs 和 linuxfb 而不用 libinput像设备节点名称参数可以在环境变量设置 QT_QPA_EVDEV_MOUSE_PARAMETERS，QT_QPA_EVDEV_KEYBOARD_PARAMETERS 和 QT_QPA_EVDEV_TOUCHSCREEN_PARAMETERS。用冒号分隔条目。这些参数作为传递-plugin 命令行参数中的设置的替代方法，并且对于某些后端，它们是至关重要的：eglfs 和 linuxfb 使用内置的输入处理程序，因此-plugin 在使用中没有单独的参数。 此外，内置的输入处理程序可以通过设置被禁用 QT_QPA_EGLFS_DISABLE_INPUT 或 QT_QPA_FB_DISABLE_INPUT 到 1。 鼠标鼠标光标每当出现 QT_QPA_EGLFS_HIDECURSOR（对于 eglfs）或 QT_QPA_FB_HIDECURSOR（对于 linuxfb）未设置，Qt 的基于 libudev 的设备发现报告至少有一个鼠标可用。当 libudev 不存在支持时，鼠标光标始终显示，除非通过环境变量显式禁用。 支持热插拔，但只有当 Qt 配置了 libudev 支持（即，如果 libudev 开发头在配置时在 sysroot 中存在）。这允许在应用程序运行时连接或断开输入设备。evdev 鼠标处理器支持以下额外的参数： /dev/input/... - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 nocompress - 默认情况下，与最后一个 Qt 鼠标事件相比，不会导致更改位置的输入事件被压缩; 在更改位置或按钮状态后，才会发送新的 Qt 鼠标事件。可以通过设置 nocompress 参数来禁用。 dejitter - 指定抖动限制。默认情况下禁用消隐功能。 grab - 当 1，Qt 将抓住设备专用。 abs - 一些触摸屏报告绝对坐标，不能与触摸板区分开来。在这种特殊情况下，通过 abs 表示设备正在使用绝对事件。 键盘该了 evdev 键盘处理程序支持以下额外的参数： /dev/input/... - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 grab - 启用抓取输入设备。 keymap - 指定自定义键盘映射文件的名称。 enable-compose - 启用合成。 repeat-delay - 设置自定义键重复延迟。 repeat-rate - 设置自定义键重复率。 在没有停用终端会话的嵌入式 Linux 系统上，由于输入事件由 Qt 应用程序和 tty 处理，按键上的行为可能会令人困惑。为了克服这一点，可以使用以下选项： EGLFS 和 LinuxFB 尝试通过设置 tty 的键盘模式来禁用应用程序启动时的终端键盘 K_OFF。这样可以防止键盘进入终端。如果由于某些原因需要恢复标准行为，请将环境变量设置 QT_QPA_ENABLE_TERMINAL_KEYBOARD 为 1。请注意，仅当应用程序从远程控制台（例如，通过 ssh）启动并且终端键盘输入保持启用时，该功能才起作用。 另一种方法是使用了 evdev 键盘处理程序的 grab 通过传递参数抢 1 在 QT_QPA_EVDEV_KEYBOARD_PARAMETERS。这样会导致尝试在输入设备上进行抓取。如果 grab 成功，只要 Qt 应用程序运行，系统中没有其他组件从中接收事件。这种方法更适合远程启动的应用程序，因为它不需要访问 tty 设备。 最后，对于许多专门的嵌入式 Linux 图像，首先启用标准终端会话是没有意义的。请参阅的构建环境的文档，了解如何禁用它们。例如，当使用 Yocto Project 生成图像时，取消设置将 SYSVINIT_ENABLED_GETTYS 导致 getty 任何虚拟终端无任何进程运行，从而导致无输入。 如果默认内置键盘映射不够，可以通过 keymap 参数或使用 eglfs 特定的 loadKeymap（）函数指定不同的键盘映射。后者允许在运行时切换键盘映射。但是请注意，这需要使用 eglfs 的内置键盘处理程序; 当通过-plugin 命令行参数加载键盘处理程序时，不支持它。 注意：目前不支持特殊的系统组合键，例如控制台切换（Ctrl + Alt + Fx）或 zap（Ctrl + Alt + Backspace），并被忽略。 要生成自定义键盘映射，可以使用 kmap2qmap 实用程序。这可以在 qttools 模块中找到。源文件必须是标准的 Linux kmap 格式，这是内核的 loadkeys 命令所理解的。这意味着可以使用以下源生成 qmap 文件： 在 Linux 控制台工具（LCT）项目。 Xorg X11 键盘映射可以转换 kmap 为该 ckbcomp 实用程序的格式。 由于 kmap 文件是纯文本文件，它们也可以手工制作。 kmap2qmap 是一个命令行程序，至少需要 2 个文件作为参数。最后一个是生成的.qmap 文件，而其他所有文件都被解析为输入.kmap 文件。例如： kmap2qmap i386 /qwertz/de-latin1-nodeadkeys.kmap include/compose.latin1.inc de-latin1-nodeadkeys.qmap 注意：kmap2qmap 不支持 Linux 内核支持的所有（伪）符号。转换标准键盘图时，会显示许多警告，关于 Show_Registers，Hex_A 等等; 这些消息可以安全地被忽略。 触摸对于一些电阻式单触摸触摸屏，可能需要退回使用 tslib 而不是依赖于 Linux 多点触控协议和事件设备。对于现代触摸屏，这是不必要的。tslib 可以通过设置环境变量 QT_QPA_EGLFS_TSLIB 或 QT_QPA_FB_TSLIB1 来启用支持。要更改设备，请 TSLIB_TSDEVICE 在命令行中设置环境变量或传递设备名称。请注意，tslib 输入处理程序生成鼠标事件并支持单触摸，而不是 evdevtouch 生成真正的多点触控 QTouchEvent 事件。 evdev 触摸处理器支持以下额外的参数： devinput… - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 rotate- 在某些触摸屏上，坐标必须旋转，这可以通过设置 rotate 为 90,180 或 270 进行。 invertx 和 inverty- 反转输入事件中的 X 或 Y 坐标，通过 invertx 或 inverty。 export QT_QPA_EVDEV_TOUCHSCREEN_PARAMETERS=/dev/input/event5:rotate=180 在启动应用程序之前，会导致明确指定的触摸设备并翻转坐标 - 当实际屏幕和触摸屏的方向不匹配时很有用。 笔式平板电脑该 evdevtablet 插件为 Wacom 和类似的基于笔的平板电脑提供了基本的支持。它仅生成 QTabletEvent 事件。要启用它，请传递 QT_QPA_GENERIC_PLUGINS=evdevtablet 给环境，或者 -plugin evdevtablet 在命令行中传递参数。插件可以使用设备节点参数，例如 QT_QPA_GENERIC_PLUGINS=evdevtablet:/dev/event1，Qt 的自动设备发现（基于 libudev 或演练devinputevent*）不起作用或行为不正常的情况。 调试输入设备通过启用 qt.qpa.input 日志规则，例如通过将 QT_LOGGING_RULES 环境变量设置为，可以向调试输出打印一些信息 qt.qpa.inputtrue。这对于检测正在使用哪个设备或对设备发现问题进行故障排除非常有用。 使用自定义鼠标光标图像eglfs 自带的 32x32 尺寸的鼠标光标图像。如果这些还不够，可以通过将 QT_QPA_EGLFS_CURSOR 环境变量设置为 JSON 文件的名称来提供自定义游标地图集。该文件也可以通过 Qt 的资源系统嵌入到应用程序中。 例如，每行具有 8 个光标图像的嵌入式光标图集可以指定如下： image：：/cursor-atlas.png\tcursorsPerRow：8，\t热点：[ [7，2] [12，3] [12，12] ...\t] 请注意，图像预计将紧紧地包装在图集中：光标的宽度和高度根据总图像大小和 cursorsPerRow 设置决定。地图集必须为所有支持的游标提供图像。 显示输出当连接多个显示器时，从一个单一 Qt 应用程序中定向一个或多个显示器的支持级别在平台插件之间变化，并且通常取决于设备及其图形堆栈。 eglfs 与 eglfs_kms 后端当 KMS DRM 后台正在使用时，eglfs 报告 QGuiApplication :: screens（）中的所有可用屏幕。应用程序可以使用不同的窗口通过 QWindow :: setScreen（）来定位不同的屏幕。 注意：每个屏幕的一个全屏窗口的限制仍然适用。使 QWindow 可见后更改屏幕也不受支持。因此，嵌入式应用程序必须在调用 QWindow :: show（）之前进行所有必要的 QWindow :: setScreen（）调用。 当开始在给定的嵌入式设备上开发时，通常需要验证设备和驱动程序的行为，并且所连接的显示器应该是正常工作的。一个简单的方法是使用 hellowindow 示例。用-platform eglfs –multiscreen –timeout 参数启动它在每个连接的屏幕上显示一个旋转的 Qt 标志几秒钟。 注意：下面描述的大多数配置选项适用于所有基于 KMS DRM 的后端，无论缓冲管理技术（GBM 或 EGLStreams）如何。 KMS DRM 后端还支持通过 JSON 文件进行自定义配置。将环境变量设置为 QT_QPA_EGLFS_KMS_CONFIG 文件的名称以启用此功能。该文件也可以通过 Qt 资源系统嵌入到应用程序中。示例配置如下： device：/ dev / dri / card1，\thwcursor：false，\tpbuffers：真的，\t输出：[ name：VGA1， 关闭模式 ， name：HDMI1， mode：1024x768 ] 这里们配置指定的设备 它不会使用硬件光标（通过 OpenGL 退回渲染鼠标光标;默认情况下，启用硬件光标，因为它们更有效）， 它将使用标准的 EGL pbuffer 表面返回 QOffscreenSurface（默认情况下，这是禁用的，而是使用 gbm 表面）， VGA 连接器上的输出被禁用，而 HDMI 处于活动状态，分辨率为 1024x768。 另外，这样的配置也禁用寻找设备 libudev，而是使用指定的设备。 何时 mode 未定义，系统选择报告为首选的模式。为可接受的值 mode 是：off，current，preferred，宽度 x 高度，或模式行字符串。 默认情况下，DRM 层报告的所有屏幕都将被视为一个大型虚拟桌面。鼠标光标实现将考虑到这一点，并按预期在屏幕上移动。尽管不推荐，虚拟桌面模式可以通过设置被禁用 separateScreens，以 false 在配置上，如果需要的话。 默认情况下，根据系统报告的连接器顺序，虚拟桌面从左到右形成。这可以通过设置 virtualIndex 为从 0 开始的值来更改。例如，以下配置使用首选分辨率，但确保虚拟桌面中的左侧是屏幕连接到 HDMI 端口，而右侧是屏幕连接到 DisplayPort： device：drm-nvdc，\t输出：[ name：HDMI1， virtualIndex：0 ， name：DP1， virtualIndex：1 ] 数组中的元素的顺序是不相关的。具有未指定虚拟索引的输出将放在其他虚拟索引之后，并保留 DRM 连接器列表中的原始顺序。 要创建一个垂直的桌面空间（即，从上到下而不是从左到右堆叠），添加一个 virtualDesktopLayout 属性后面 device 的值 vertical。 注意：建议虚拟桌面中的所有屏幕使用相同的分辨率，否则像鼠标光标那样的元素可能会在输入仅存在于一个给定屏幕上的区域时以意想不到的方式运行。 何时 virtualIndex 不够，该属性 virtualPos 可用于明确指定问题屏幕的左上角位置。以前面的例子，假设 HDMI1 的分辨率为 1080p，下面第一个基于 HDMI 的屏幕放在第一个： ...\t输出：[ ... name：HDMI2， virtualPos：0，1080 ] 注意：在需要鼠标支持时避免这样的配置。鼠标光标的行为可能是意想不到的非线性布局。Touch 应该没有问题。 在某些情况下，通过 DRM 自动查询物理屏幕尺寸可能会失败。通常 QT_QPA_EGLFS_PHYSICAL_WIDTH，QT_QPA_EGLFS_PHYSICAL_HEIGHT 环境变量将用于提供缺失值，但是当存在多个屏幕时，这并不适用。而是使用列表中的 physicalWidth 和 physicalHeight 属性 outputs 来指定以毫米为单位的大小。 注意：不同的物理尺寸和不同的逻辑 DPI 不鼓励，因为它可能会导致意外的问题，因为一些图形堆栈组件不知道多个屏幕，仅依靠第一个屏幕的值。 从每个有源输出 outputs 阵列对应于一个 QScreen 从报告实例 QGuiApplication ::屏幕（）。QGuiApplication :: primaryScreen（）报告的主屏幕是默认首先注册的屏幕。当不使用时 virtualIndex，这意味着决定是基于 DRM 连接器顺序。要覆盖这一点，属性设置 primary，以 true 对在所需的条目 outputs 列表。例如，为了确保与 VGA 输出相对应的屏幕将是主要的，即使系统首先报告 HDMI，则可以执行以下操作： device：/ dev / dri / card0，\t输出：[ name：HDMI1， name：VGA1，mode：1280x720，primary：true， name：LVDS1，mode：off\t] 为了进行故障排除，可能会启用 KMS DRM 后端的调试日志。为此，启用分类日志记录规则 qt.qpa.eglfs.kms。 注意：在嵌入式环境中，虚拟桌面比全窗口系统更为有限。应该避免 Windows 重叠多个屏幕，非全屏窗口和屏幕之间的移动窗口，并且可能无法正常运行。 多屏幕设置最常用和最受支持的用例是为每个屏幕打开一个专用的 QQuickWindow 或 QQuickView。使用 threadedQt Quick 场景图的默认渲染循环，这些窗口中的每个都将获得自己的专用渲染线程。这是很好的，因为线程可以基于 vsync 独立调节，并且不会相互干扰。通过 basic 循环，这可能会产生问题，动画可能会因此而恶化。 例如，发现所有连接的屏幕，并为每个屏幕创建一个 QQuickView 可以这样完成： int main(int argc, char **argv) QGuiApplication app(argc, argv); QVectorQQuickView *views; for(QScreen * screen : app.screens()) QQuickView * view = new QQuickView; view-setScreen(screen); view-setResizeMode(QQuickView::SizeRootObjectToView); view-setSource(QUrl(qrc:/main.qml)); QObject::connect(view-engine(), QQmlEngine::quit, qGuiApp, QCoreApplication::quit); views.append(view); view-showFullScreen(); int result = app.exec(); qDeleteAll(views); eglfs 与 eglfs_kms_egldevice 后端通常在 Tegra 设备上使用的这种后端与上述 KMS DRM 后端类似，不同之处在于它依赖于 EGLDevice 和 EGLStream 扩展而不是 GBM。 有关此方法的技术细节，请查看演示文稿。 截至 Qt 5.7，该后端与基于 GBM 的后端共享了许多内部实现。这意味着支持多个屏幕和高级配置通道 QT_QPA_EGLFS_KMS_CONFIG。一些设置，如 hwcursor 和 pbuffers 不适用。 默认情况下，后端将自动为每个输出的默认平面选择正确的 EGL 层。必要时，可以通过将 QT_QPA_EGLFS_LAYER_INDEX 环境变量设置为所需层的索引来覆盖。此方法目前不支持多个输出，因此其使用应限于具有单个屏幕的系统。要查看哪些层可用，并调试潜在的启动问题，请启用日志记录类别 qt.qpa.eglfs.kms。 在某些情况下，即使屏幕报告已经设置了所需分辨率，也可能需要执行应用程序启动时设置的视频模式。这通常是被优化的，但如果屏幕保持关闭状态，请尝试将环境变量设置为 QT_QPA_EGLFS_ALWAYS_SET_MODE 非零值并重新启动应用程序。 要配置后端使用的 EGLStream 对象的行为，请使用 QT_QPA_EGLFS_STREAM_FIFO_LENGTH 环境变量。这假定 KHR_stream_fifo 是目标系统支持的。默认情况下，流以邮箱模式运行。要切换到 FIFO 模式，请设置 1 或更大的值。该值指定流可以容纳的最大帧数。 在某些系统上，可能需要通过预定义的连接器来定位特定的覆盖平面。强制层索引通过 QT_QPA_EGLFS_LAYER_INDEX 不执行平面配置，因此本身不适用。相反，在这种特殊情况下，使用 QT_QPA_EGLFS_KMS_CONNECTOR_INDEX 和 QT_QPA_EGLFS_KMS_PLANE_INDEX 环境变量。当这些设置被设置时，只有指定的连接器和平面将被使用，所有其他输出将被忽略。后端将负责选择对应于所需平面的 EGL 层和配置平面。 在 KMS DRM 上有多个屏幕的系统中触摸输入触摸屏在多显示系统中需要额外的考虑因素，因为触摸事件必须路由到正确的虚拟屏幕，这需要触摸屏和显示器输出之间的正确映射。 映射通过 QT_QPA_EGLFS_KMS_CONFIG 前面部分中指定和描述的 JSON 配置文件完成。当 touchDevice 属性存在于 outputs 数组的元素中时，该值被视为设备节点，并且触摸设备与所讨论的显示输出相关联。 例如，假设们的触摸屏具有 dev input event5 的设备节点，并且是集成到通过 HDMI 连接的显示器作为辅助屏幕的触摸屏，以下配置确保正确的触摸（和合成鼠标）事件转换： device：drm-nvdc，\t输出：[ name：HDMI1， touchDevice：/ dev / input / event5， virtualIndex：1 ， name：DP1， virtualIndex：0 ] 注意：如有疑问，请 QT_LOGGING_RULES=qt.qpa.*=true 在启动应用程序之前通过设置环境变量来启用图形和输入子系统的日志记录。这将有助于识别正确的输入设备节点，并且可能会发现可能难以调试的输出配置问题。 注意：从 Qt 5.8 起，上述只支持 evdevtouch 输入后端。其他变体，例如基于 libinput 的变体，将继续将事件路由到主屏幕。要强制在具有多个输入后端的系统上使用 evdevtouch，请将环境变量设置 QT_QPA_EGLFS_NO_LIBINPUT 为 1。 eglfs 与其他后端通常基于通过供应商的 EGL 实现直接针对帧缓冲区或组合 API 的其他后端，通常对多个显示器提供有限或不支持的支持。在使用 Vivante GPU 的基于 i.MX6 的电路板上，与 linuxfb 类似，QT_QPA_EGLFS_FB 环境变量可用于指定要缓存的帧缓冲区。在 Raspberry Pi 上，QT_QPA_EGLFS_DISPMANX_ID 环境变量可用于指定要输出的屏幕。该值对应于其中一个 DISPMANX_ID_ 常量，请参考 Dispmanx 文档。请注意，与 KMS / DRM 不同，这些方法通常不允许从同一应用程序输出到多个屏幕。或者，驱动程序特定的环境变量或内核参数也可以用于控制所使用的帧缓冲区。 视频内存具有固定数量的专用视频内存的系统在运行基于 Qt Quick 的 Qt 应用程序或类似 QOpenGLWidget 的类之前，可能需要特别注意。对于这样的应用，默认设置可能不足，特别是当它们以高分辨率（例如，全高清）屏幕显示时。在这种情况下，他们可能以意想不到的方式开始失败。建议确保至少有 128 MB 的 GPU 内存可用。对于没有为 GPU 保留的固定内存量的系统，这不是一个问题。 linuxfb使用 fbplugin 参数指定要使用的 framebuffer 设备。 Unix 信号处理程序面向控制台的平台插件，如 eglfs 和 linuxfb 默认安装信号处理程序来捕获 interrupt（SIGINT），suspend 和 continue（SIGTSTP，SIGCONT）和 terminate（SIGTERM）。这样，当应用程序终止或由于 kill 或 Ctrl+C 或暂停时，可以恢复键盘，终端光标和可能的其他图形状态 Ctrl+Z。（尽管通过键盘终止或暂停只能在 QT_QPA_ENABLE_TERMINAL_KEYBOARD 设置时进行，如上面的”输入”部分所述）。然而，在某些情况下，捕获 SIGINT 可能是不合需要的，因为它可能会与远程调试冲突。因此，QT_QPA_NO_SIGNAL_HANDLER 提供环境变量以选择退出所有内置信号处理。 字体Qt 通常用于 fontconfig 提供对系统字体的访问。如果 fontconfig 不可用，Qt 会回退使用 QBasicFontDatabase。在这种情况下，Qt 应用程序将在 Qt 的 libfonts 目录中查找字体。Qt 会自动检测预渲染的字体和 TrueType 字体。可以通过设置 QT_QPA_FONTDIR 环境变量来覆盖此目录。 有关支持的格式的详细信息，请参阅嵌入式 Linux 字体的 Qt。 注意： Qt 不再在 libfonts 目录中装载任何字体。这意味着由平台（系统映像）提供必要的字体。 嵌入式 Linux 设备上的窗口系统的平台插件XCBXCB 是用于常规桌面 Linux 平台中的 X11 插件，它在许多嵌入式环境中得到应用。它提供了必要的 X11 组件及开发文件，使用方法上与在普通 PC 桌面上完全一致，让开发者能够使用熟悉的工具进行开发。 兼容性问题在某些嵌入式设备上，可能会遭遇兼容性问题。尤其是在 EGL 实现与 Xlib 不兼容的情况下，EGL 和 OpenGL 支持可能会缺失。对此，XCB 插件就会在没有 EGL 支持的情况下构建。这意味着开发者需要注意，基于 Qt Quick 2 或其他依赖 OpenGL 的应用程序在这样的环境下无法运行。 然而，有一些应用仍然能够在这种限制下正常工作。例如，使用 QWidget 的软件渲染应用程序可以在没有 OpenGL 加速的情况下顺利运行。因此，如果项目中没有对图形性能要求极高的情景，XCB 仍然可以是一个适合的选择。 性能考虑通常来说，XCB 在嵌入式设备系中并不是首选。这主要是因为仅使用 XCB 在性能和资源使用方面可能难以满足需求。在许多情况下，选择像 eglfs 这样的替代插件，会有效提升性能并实现硬件加速。这种方法能够更好地利用设备的图形处理能力，适合需要处理复杂图形或高帧率的应用场景。 WaylandWayland 是一个轻量级的窗口系统，它不仅是一个开源系统，更重要的是，它为客户端与显示服务器之间的通信提供了一种现代化的协议。这使得开发者能够在高效且灵活的环境中创建应用。 Qt Wayland 模块利用 Qt Wayland 模块，开发者可以实现与 Wayland 合成器的连接。这为 Qt 应用程序提供了直接与 Wayland 交互的能力。实际上，这一模块简化了对现代显示协议的支持，因此在开发中新手也能比较轻松地处理应用程序的显示逻辑。 输入设备问题需要注意的是，当使用 Weston 作为参考合成器时，可能会出现触摸屏输入问题。这种情况可能会影响用户体验，比如触摸事件无法被正确识别或反应迟缓等。开发者应该对此进行测试，并根据具体的触摸屏设备调整相关设置以确保应用能够正常响应用户操作。 在总结中，无论是选择 XCB 还是 Wayland，都需要根据具体的嵌入式设备规格以及应用需求来做出判断。不同插件在性能、兼容性和开发便利性上的表现存在差异，适合的选择将大大提升项目成功的可能性。","categories":["1.平台","嵌入式"]},{"title":"嵌入式介绍","path":"/2024/08/06/1-平台-嵌入式-嵌入式介绍/","content":"嵌入式 linux 开发介绍嵌入式系统简介 一般定义 以应用为中心、以计算机技术为基础、软件硬件可裁剪、适应应用系统，对功能、可靠性、成本、体积、功耗严格要求的专用计算机系统 广义上讲 凡是带有微处理器的专用软硬件系统都可称为嵌入式系统。 嵌入式系统又分为多个模块部分 ARM 重视理论实践 系统移植 重视流程 驱动 重视框架 嵌入式系统的组成 软件（linux，VXwork + 应用程序） 硬件（C51，stm32， arm，mips powerpc + DRAM emmc uart） win BIOS win 系统 文件系统加载驱动 应用程序 linux bootloader（引导程序） linux 内核 挂载文件系统驱动 应用程序 运行操作系统的优点： 方便开发 将硬件与软件隔离（保护硬件） 嵌入式 linnux 系统移植做哪些工作产品升级（产品添加某些功能模块，产品裁剪了某些功能模块，A8 –》 A9 嵌入式开发环境的搭建采用的交叉开发模式，即编译和运行不在同一台主机上 GCC 简介Gcc 的编译流程： 预处理 gcc -E 编译 gcc -S 汇编 gcc -c 链接 gcc gcc 工具集 readelf：功能：readelf 可以显示 elf 格式可执行文件的信息 size：功能：size 列出目标文件每一段的大小以及总体的大小 nm：功能：nm 可以列出目标文件中的符号。 strip 功能：strip 用来丢弃目标文件中的全部或者特定符号，减小文件体积。对于嵌入式系统，这个命令必不可少。 objcopy：功能：objcopy 可以进行目标文件格式转换 objcopy -O binary hello hello.bin objcopy -O binary u-boot u-boot.bin objdump: 功能：反汇编 objdump -d hello objdump -d hello hello.dis addr2line 功能：addr2line 能够把程序地址转换为文件名和行号，前提是这个可执行文件包括调试符号。 安装交叉编译工具链 解压 gcc-4.6… 到 tootchain 配置环境变量 sudo vi /etc/bash.bashrc export PATH=$PATH:/home/linux/toolchain/gcc-4.6.4/bin/ 重启 source etcbash.bashrc 测试 arm-none-linux-gnueabi-gcc –v TFTP 服务器的安装和配置tftp 是用来下载远程文件最简单的网络协议 修改配置文件，开启 tftp 服务 sudo vi /etc/default/tftp-hapa 修改成： TFTP_USERNAME=tftp TFTP_DIRECTORY=/tftpboot //指定tftp服务器的目录，将来要下载东西都是从这个目录下下载，需自行创建，然后修改权限为777TFTP_ADDRESS=0.0.0.0:69 //69： tftp 专有的端口TFTP_OPTIONS=-c -s -l //man tftpd可查看各个选项的含义//-c：表示可以在服务器目录下（/tftpboot）下创建新文件，默认不能创建新文件，只能修改或覆盖//-s: 改变 tftp 启动的根目录，也就是客户端在使用 tftp 时不需要输入/tftpboot 目录//-l：表示以监听模式启动 tftp 服务器 创建服务器的根目录tftpboot sudo mkdir /tftpbootchmod 777 /tftpboot -R 重启 tftp 服务器 sudo service tftpd-hpa restart 登录本机进行测试 tftp localhost 或者 tftp 192.168.1.111 或者 tftp 127.0.0.1tftp get xxx //从服务器（/tftpboot 目录）下载文件名为 XXX 的文件tftp put xxx //xxx 为想要往服务器（/tftpboot 目录）发送的文件tftp q //q 表示退出 nfs 服务器的安装和配置nfs 主要用来进行目录的共享（把本地的一个目录通过网络导出，其他设备可以远程访问该目录），们的测试程序不用通过下载到目标板，目标机可以通过共享目录访问，提高开发效率。 修改配置文件 sudo vi /etc/export 在最后一行添加： /source/rootfs *(rw,sync,no_subtree_check,no_root_squash)///source/rootfs 是指定的共享目录，需自己创建//rw：具有读写权限//sync：文件同步//no_subtree_check: 如果共享子目录，则不检查父目录的权限//no_root_squash: 如果客户端为 root 用户，则它对此目录有 root 权限 重启 nfs 服务 sudo service nfs-kernel-server restart 创建共享目录 mkdir /source/rootfs ubuntu 的网络配置配置虚拟机 IP（桥接），设置 IP 地址，sudo vi etcnetworkinterfaces auto eth0iface eth0 inet staticaddress 192.168.1.111netmask 255.255.255.0gateway 192.168.1.1 设置 DNS，sudo vi /etc/resolv.conf 在最后一行添加： nameserver 192.168.1.1 重启网络服务 sudo /etc/init.d/networking restart 开发环境测试SD 启动盘制作和 u-boot 的烧写制作 SD 卡目的：通过 SD 卡烧写 uboot 到开发板上 烧写 uboot 到 emmc 上 连接串口和板子，运行串口通信程序(putty 第一天工具中) 关闭开发板电源，将拨码开关 SW1 调至(1000)(SD 启动模式)后打开电源 将刚才做好的 SD 启动盘插入 SD 卡插槽 倒计时按下任意键，进入 uboot 界面 烧写 在终端上执行 sdfuse flashall 等待终端无输出是表示烧写结束 从网络下载内核、设备树，并挂载文件系统如何把服务器（ubuntu 中的tftpboot 目录）下的内核和设备树下载到开发板？ 将要下载的东西放到服务器目录下。 拷贝 uImage、exynos4412-fs4412.dtb 到 ubuntu 的tftpboot 目录下。 将第一天镜像文件rootfs.tar.xz 拷贝到 ubuntu 的 source 下并解压 开发板启动，在 u-boot 界面(倒计时按下任意键)进行下载。 Ubuntu IP: 192.168.9.120 开发板 IP: 192.168.9.233 #setenv serverip 192.168.9.120#setenv ipaddr 192.168.9.233#setenv bootcmd tftp 41000000 uImage\\;tftp 42000000 exynos4412-fs4412.dtb\\;bootm 41000000 - 42000000 console=ttySAC2,115200 init=/linuxrc ip=192.168.9.233#saveenv 重启开发板 从 EMMC 加载内核和文件系统烧写镜像到 emmc 中设置启动参数，从 emmc 加载镜像","categories":["1.平台","嵌入式"]},{"title":"构建工具的简要介绍","path":"/2024/08/05/1-平台-嵌入式-构建工具的简要介绍/","content":"嵌入式 Linux 系统构建工具在嵌入式系统的开发过程中，选择合适的构建工具至关重要。下面是一些常用的构建工具及其特点。 MakeMake 是一个广泛使用的构建自动化工具，特别适用于使用 CC++ 编写的程序。它根据 Makefile 文件中的规则来确定哪些文件需要重新编译，并管理编译过程。开发者可以自定义构建流程，比如添加特定的编译标志或定义测试目标，这使得 Make 成为高度灵活的选择。 示例： 通过编写一个简单的 Makefile，开发者可以指定如何将源代码编译为最终可执行文件，确保每次变更时自动触发重新构建。 CMakeCMake 是一个跨平台的构建系统生成器，它使用 CMakeLists.txt 文件来描述项目的构建过程。CMake 可以生成适合多种环境的 Makefile 或项目文件，比如用于 Visual Studio 和 Xcode 的项目文件。它的最大优势在于支持复杂的项目结构以及跨平台构建。 示例：一个包含多个模块的项目可以通过 CMake 的指令轻松管理，在不同操作系统上生成适配的构建文件，以确保一致的构建体验。 QMakeQMake 是 Qt 框架的构建工具，主要用于开发 Qt 应用程序。它提供了一种简单的方式来管理程序的构建过程，特别是在处理 GUI 应用时。QMake 使用 .pro 文件来定义项目设置，并能自动处理依赖关系，使得开发 Qt 应用变得高效。 示例： 当采用 QMake 创建一个新项目时，开发者只需在 .pro 文件中定义源文件和头文件，QMake 会自动生成适合平台的 Makefile。 MesonMeson 是一个现代化的构建系统，旨在提高构建速度和可维护性。其设计理念是为了帮助开发者更高效地管理大型项目的构建过程。以下是 Meson 的一些核心特点： 快速构建：Meson 利用并行构建和增量构建的策略，显著减少了构建时间。比如，在多个 CPU 核心上同时进行构建，当在机器上有 8 个内核的时候，构建时间可以缩短到单线程的五分之一。此外，通过仅编译变更的文件，Meson 优化了构建过程，使得每次修改代码后重新构建的效率更高。 易于使用：Meson 的配置文件采用人性化的简单语法，便于开发者理解。在 Meson 中，仅需要编写一个 meson.build 文件，定义项目的源文件、依赖关系和构建选项。例如，定义一个库只需几行代码，像这样： project(example, c)library(example_lib, src/example.c) 这种简洁的语法使得新手开发者能够快速上手，而经验丰富的开发者也能更高效地进行项目管理。 跨平台支持：Meson 支持多种平台和编译器，包括但不限于 Linux、Windows 和 macOS，以及 GCC、Clang 和 MSVC 等编译器。这种兼容性使得开发者可以在不同的开发环境中轻松切换，而不必担心构建工具的差异。无论是在本地开发，还是在云端构建，Meson 都能提供一致的体验。 BuildrootBuildroot 是一个简单高效的工具，专门用于生成嵌入式 Linux 系统。它利用 Makefile 和 Kconfig 配置系统，提供强大的交叉编译功能，使得用户能够快速构建一个精简的、功能完备的 Linux 系统。以下是 Buildroot 的主要特点，具体说明了其优势和适用场景： 简单易用：Buildroot 提供了类似于 Linux 内核的配置界面，如 menuconfig，让用户能够直观地选择所需的功能和软件包。用户只需几次点击，就可以完成复杂的配置工作。通常情况下，从配置到完成基本系统的构建只需 15 到 30 分钟。例如，对于一款需要运行基本网络服务的设备，用户能够快速选择适合的网络协议栈和相关工具，极大地缩短了开发周期。 高效性：Buildroot 非常适合资源有限的嵌入式环境，尤其是在快速迭代项目中十分有效。它支持大量的软件包，从基本的 C 标准库到复杂的网络应用程序都能轻松集成。举个例子，如果一家公司需要在 IoT 设备上运行一个轻量级的消息队列系统，Buildroot 可以快速选取并配置合适的软件包，从而快速投入生产。 构建时间短：相较于其他类似工具如 Yocto，Buildroot 通常具有更快的构建时间。这是因为 Buildroot 的构建过程更为简化，减少了不必要的复杂性。根据用户反馈，一个实例可能在 Yocto 中需要几个小时的构建时间，而在 Buildroot 中仅需 30 分钟或更短。 适用场景：Buildroot 特别适合小型项目和需要快速原型开发的情况。比如，开发者可以快速将一个新的硬件平台适配到 Linux 系统上，以便进行功能测试或用户反馈。有些初创企业使用 Buildroot 来快速验证他们的想法，从而在推向市场之前及时调整方向。 通过这些特点，Buildroot 为嵌入式开发者提供了一个灵活且高效的解决方案，使他们能更专注于软件的创新和功能的实现。 YoctoYocto Project 是一个开源项目，专为嵌入式 Linux 开发者设计，旨在提供创建自定义 Linux 系统的工具和模板。以下是其主要特点： 高度定制化：Yocto 支持复杂的依赖关系和层次结构，使得它特别适合于那些需要极高定制化程度和复杂功能的大型项目。例如，在考虑物联网（IoT）设备时，如果一个设备需要同时支持多个传感器、特定的中间件和定制的用户界面，Yocto 提供的灵活性允许开发团队精确配置他们的系统，以满足这些特定需求。 强大的构建系统：Yocto 使用 BitBake 作为其构建引擎。BitBake 不仅可以处理简单的构建任务，还能应对高度复杂的构建流程。这种能力对于开发者而言极为重要，因为在构建嵌入式系统时，往往需要从头开始构建一个独特的 Linux 发行版，BitBake 通过丰富的开源支持和灵活的任务调度功能，让这一过程变得高效。例如，它可以自动处理软件包的依赖关系，确保在构建系统时，所需的每一个组件都能被正确配置与链接。 灵活性：Yocto 允许开发者根据不同的硬件和软件需求，创建适合特定应用的 Linux 版本。这意味着，开发者在面对各种不同的硬件平台（如 ARM、x86 或 MIPS 架构）时，可以迅速创建相应的 Linux 系统。例如，一个医疗设备制造商需要在不同的硬件平台上运行相同的软件解决方案，Yocto 能够帮助他们构建兼容性强的系统，确保项目的统一性和可维护性。 适用场景：Yocto 特别适用于需要支持多个硬件平台和复杂软件栈的项目。比如，在汽车电子行业，一款车载娱乐系统需要在多种不同的汽车品牌和型号上安装，同时又要支持复杂的多媒体处理和实时数据传输等功能，Yocto 提供的模块化设计和层级管理能有效简化这一过程。开发者可以利用 Yocto 的功能，为每一个特定的硬件平台定制和优化软件，确保最佳的性能和用户体验。","categories":["1.平台","嵌入式"]},{"title":"飞凌OK3568的Docker支持","path":"/2024/08/02/1-平台-嵌入式-飞凌OK3568的Docker支持/","content":"编辑 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 增加以下内容 #add docker supportCONFIG_MEMCG=yCONFIG_VETH=yCONFIG_BRIDGE=yCONFIG_BRIDGE_NETFILTER=yCONFIG_NETFILTER_XT_MATCH_ADDRTYPE=yCONFIG_NETFILTER_XT_MATCH_CONNTRACK=yCONFIG_NETFILTER_XT_MATCH_IPVS=yCONFIG_NETFILTER_XT_MARK=yCONFIG_POSIX_MQUEUE=yCONFIG_CGROUP_BPF=yCONFIG_NETFILTER_ADVANCED=yCONFIG_NETFILTER_XTABLES=yCONFIG_IP_VS=yCONFIG_IP_PNP=yCONFIG_IP_PNP_DHCP=y 之后再编译烧写测试下 #更新软件源sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo apt install software-properties-common#添加仓库sudo add-apt-repository deb [arch=arm64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stablesudo apt-get update apt-cache madison docker-cesudo apt-get -y install docker-ce=5:20.10.1~3-0~ubuntu-focalsudo docker image ls","categories":["1.平台","嵌入式"]},{"title":"关于RTOS的Tick值","path":"/2024/08/01/1-平台-嵌入式-RealTime-关于RTOS的Tick值/","content":"什么是系统滴答系统滴答（SysTick），有些地方也叫时钟节拍、系统心跳等。 操作系统可以多任务间进行切换，就是靠一个系统定时器以固定频率中断，为操作系统提供调度（上下文切换）才能实现任务切换。 而这个定时器，就是本文说的系统滴答。早些年的 51、430 单片机，跑 RTOS，都是单独利用一个 Timer 定时器提供系统滴答。为了考虑跑 RTOS 这个问题，Cortex-M 内核自带系统滴答这个定时器。 会发现市面上很多单片机基本都自带有 SysTick 这个定时器，像 Cortex-M0、 M3、 M4 这些内核的单片机都有的，而且只要简单调用官方写好的 API 函数即可使用。 系统配置文件通常，系统滴答（OS_TICKS）位于系统配置文件中，对系统配置文件进行配置也是重要的一步。比如 FreeRTOSConfig.h ucos 系统的 os_cfg.h（一些系统通过图形化界面进行配置，其实也是对系统配置文件进行配置）。 OS_TICKS 一般是配置为 1000，从宏定义和注释很容易理解，就是每秒系统滴答的次数。系统滴答配置 1000，代表系统 1ms 要进行一次轮转调度，检查是否有更高优先级任务要执行（并切换任务）。100M 主频的单片机，执行一次调度（几十条语句），时间在 us 级别。1000 是一个比较适合的中等值，其他 100、10000，或者 2000 也可以，只是不利于系统以及编程。 如果滴答太大，10K，甚至 100K，对系统的负担比较大。因为自身调度会占用 CPU 时间。 1ms 滴答一次，方便编程系统延时。2k、10k 这种值，在用到系统延时时，不方便计算。 vTaskDelay(1000); 如果滴答值为 1000，则代表延时 1 秒； 如果滴答值为 2000，则代表延时 0.5 秒，很明显这种不利于编程； 实时操作系统的 SysTick，在没有特殊情况下，最好默认配置 1000； 在系统允许的情况下，SysTick 数值越大，系统实时性越高；反之实时性越差； 主频相对偏低（比如低于 10M）的处理器，SysTick 值可以适当配置低一点；","categories":["1.平台","嵌入式","RealTime"]},{"title":"Sqlite3移植","path":"/2024/07/31/4-软件-数据库-Sqlite3移植/","content":"Qt 交叉编译在使用 Qt 进行数据库操作时，可能会遇到如下错误提示： QSqlDatabase: QSQLITE driver not loaded 这个问题通常是由于交叉编译的 Qt 版本可能被裁剪过，缺少了 SQLite 驱动。为了解决这个问题，需要交叉编译 qsqlite 驱动。 步骤 下载 Qt 源码访问 Qt 官方下载页面，找到 qt-everywhere-opensource-src-5.3.2.tar.gz。确保下载的 Qt 版本与您使用的编译器版本一致，以避免兼容性问题。 解压源码使用以下命令解压下载的源码包： tar -xvf qt-everywhere-opensource-src-5.3.2.tar.gz 进入目录进入 SQLite 驱动的源代码目录： cd qt-everywhere-opensource-src-5.3.2/qtbase/src/plugins/sqldrivers/sqlite 执行编译使用 qmake 和 make 命令编译 SQLite 驱动： qmakemake 拷贝生成的库编译完成后，生成的库文件位于 qt-everywhere-opensource-src-5.3.2/qtbase/plugins/sqldrivers/libqsqlite.so。将 libqsqlite.so 拷贝到开发板的 /usr/lib/qt5/plugins/sqldrivers/ 目录。如果该目录不存在，可以使用以下命令创建： mkdir -p /usr/lib/qt5/plugins/sqldrivers Sqlite 使用有关 SQLite 的详细使用说明，请参考 Sqlite使用。 C 代码编写要使用 SQLite，首先需要下载其源代码，下载地址为 SQLite 官方网站。 SQLite 接口的基本元素包括两个对象和八个方法： // 数据库连接对象。通过创建 sqlite3_open，并通过析构 sqlite3_close。sqlite3// 准备好的语句对象。通过创建 sqlite3_prepare，并通过析构 sqlite3_finalize。sqlite3_stmt// 打开与新的或现有的 SQLite 数据库的连接。sqlite3 的构造函数。sqlite3_open()// 将 SQL 文本编译为字节代码，它将完成查询或更新数据库的工作。sqlite3_stmt 的构造函数。sqlite3_prepare()// 将应用程序数据存储到原始 SQL 的参数中。sqlite3_bind()// 将 sqlite3_stmt 前进到下一个结果行或完成。sqlite3_step()// 当前结果行用于在 → 列值 sqlite3_stmt。sqlite3_column()// sqlite3_stmt 的析构函数。sqlite3_finalize()// sqlite3 的析构函数。sqlite3_close()// 一个包装函数，对一个或多个 SQL 语句字符串执行 sqlite3_prepare()，sqlite3_step()，sqlite3_column() 和 sqlite3_finalize()。sqlite3_exec() 交叉编译 SQLite以下是交叉编译 SQLite 的步骤： cdmkdir sqlite3 # 在主机（如 Ubuntu）创建工作目录cd sqlite3 # 进入工作目录中tar zxvf sqlite-autoconf3080500.tar.gz # 解压cd sqlite-autoconf3080500 # 进入解压后的目录mkdir ../install # 创建安装目录export PATH=$PATH:/usr/local/arm-2010q1/bin # 将交叉编译工具路径加入系统环境变量./configure --host=arm-none-linux-gnueabi --prefix=/home/gary/sqlite3/installmakemake install --host：指定交叉编译工具，通常为 arm-linux、arm-linux-gnueabihf 等，具体取决于您使用的开发板。 --prefix：指定安装目录，编译后的文件将全部放在该目录中，必须使用绝对路径。 完成编译后，将生成的文件拷贝到开发板上即可。 DemoC 代码示例以下是一个简单的 C 代码示例，演示如何使用 SQLite： #includestdio.h#includesqlite3.h// exec传入 int callback(void* arg, int num, char** rowdata, char** title) static int flag = 0; int i = 0; if (flag == 0) printf(%d , num); for (; i num; i++) printf(%s , title[i]); printf( ); flag = 1; for (i = 0; i num; i++) printf(%s , rowdata[i]); printf( ); return SQLITE_OK;int main(int argc, char **argv) // 1. 打开数据库 sqlite3 *ppdb; int empty = 1; char *err = 0; int ret = sqlite3_open(./test.db, ppdb); if (ret != SQLITE_OK) perror(open sqlite3 fail); return -1; // 2. 执行 SQL 语句 char *sql = create table gec_94(id int primary key, msg varchar(128));; // 创建表 ret = sqlite3_exec(ppdb, sql, callback, empty, err); if (ret != SQLITE_OK) perror(exec sqlite3 create table fail); sqlite3_close(ppdb); return -1; ret = sqlite3_exec(ppdb, select * from gec_94;, callback, empty, err); if (ret != SQLITE_OK) perror(exec sqlite3 fail); sqlite3_close(ppdb); return -1; // 3. 关闭数据库 sqlite3_close(ppdb); return 0; Makefile 示例以下是一个简单的 Makefile 示例，用于编译上述 C 代码： TARGET=mainCC=arm-linux-gccSRCS=sqlit3.c sqlite3.cOBJS=$(patsubst %.c, %, $(SRCS))LIB=-lpthread -ldlINCLUDE=ADD=-Wno-psabi ADD1=-enable-static main: $(SRCS)\t$(CC) $^ -o $@ $(LIB)clean:\trm -f $(OBJS) main 这个 Makefile 定义了目标文件、编译器、源文件以及编译和清理的规则。使用 make 命令可以编译代码，使用 make clean 可以清理生成的文件。","categories":["4.软件","数据库"]},{"title":"嵌入式中的gsnap截屏","path":"/2024/07/30/1-平台-嵌入式-应用软件移植-嵌入式中的gsnap截屏/","content":"Linux 系统的 FrameBuffer 机制，会把屏幕上的每个点映射成一段线性内存空间，程序就可以通过改变这段内存的值来改变屏幕上某一点的颜色。屏幕色彩的原始数据保存在devfb0 文件。 cat /dev/fb0 fb.raw #读取该文件获得数据cat fb_data.raw /dev/fb0 #数据回显到 framebuffer 这种原始数据无法通过简单的工具直接查看，特别是在精简的嵌入式 Linux 系统上。因此，通过工具 gsnap。这个工具可以将 framebuffer 中的数据直接保存为 png 或者 jpeg 格式的图片。 打开 gsnap 的 Makefile 文件，该源码依赖 libpng、libjpeg、zlib、libmath 四种库。 交叉编译 libjpeg进入到源码目录，执行 ./configure --host=arm-linux --prefix=./jpeg_install/ 然后执行 makemake install 在安装目录 ./jpeg_install/ 得到交叉编译过的库。 交叉编译 zlib由于 zlib 中的 configure 并未提供–host 参数，因此需要为它手动指明交叉编译器： export CC=arm-fsl-linux-gnueabi-gcc./configure --prefix=./z_install/makemake install 交叉编译 libpngzlib 是 libpng 的依赖，因此在交叉编译 libpng 之前，必须首先编译 zliblibpng 中提供有 Linux 平台下的 Makefile 例程，可以直接修改使用。进入到 libpng 的源码目录，执行拷贝 cp scripts/makefile.linux Makefile，打开 Makefile 修改，修改交叉编译器名称和依赖的 zlib 的路径。执行 make、makeinstall 得到头文件和库文件。 交叉编译 gsnap将上述得到的库文件和头文件分别集中拷贝到自行建立的 lib 和 includes 目录下，并修改 gsnap 的 Makefile。执行 make 后就能得到可执行文件 gsnap。 将得到的 gsnap 可执行文件拷贝到目标板的usrbin 目录下，执行截屏命令： gsnap fb.jpg /dev/fb0","categories":["1.平台","嵌入式","应用软件移植"]},{"title":"OK3568的文件系统裁剪","path":"/2024/07/29/1-平台-嵌入式-系统移植-OK3568的文件系统裁剪/","content":"0. 概述现阶段在工作过程中使用的是飞凌嵌入式的 OK3568 开发板，需要对文件系统进行针对性裁剪，缩减文件系统大小，现裁剪前官方文件系统大小为 1.28GB，裁剪后文件系统大小为 0.7GB 1. 脚本分析在官方提供的开发包中，所有的编译过程都是由根目录下的 build.sh 控制的，跟踪该脚本发现编译文件系统的步骤如下： 执行 build.sh rootfs 通过 buildroot 方式编译文件系统 执行时，脚本调用其中的 build_rootfs 方法 build_rootfs 方法通过命令行输入参数判断当时用的 yocto 或 debian 或 distro 或 buildroot 的方式编译文件系统，当前选择的是 buildroot 调用 build_buildroot 方法，执行 device/rockchip/common 中的 mk-buildroot.sh 脚本 在 mk-buildroot.sh 脚本中调用 buildroot/build/envsetup.sh，envsetup.sh 用于初始化环境变量并设置 buildroot/configs/OK3568_defconfig 为 buildroot 编译文件系统的默认配置文件 读取 buildroot/configs/OK3568_defconfig 中的配置，并覆盖正在使用的配置文件，正在使用的配置文件位于 buildroot/.config，通过 buildroot/.config 配置文件系统 编译选项对文件系统大小的影响： 例.取消 BR2_PACKAGE_TENSORFLOW 选项不一定会使文件系统镜像大小变小，原因如下： 取消该选项只会影响到构建时是否编译 TensorFlow 软件包，对已经安装的软件包不会产生影响，因此对文件系统镜像大小的影响是有限的 TensorFlow 软件包可能并不占用很大的空间，因此取消该选项对文件系统镜像大小的影响也比较有限 因此，取消某一编译选项并不是一个有效的方法来减小文件系统镜像大小，可以考虑通过 删除不必要的文件 调整压缩参数 2.裁剪2.1 配置文件#include audio.config #音频相关的配置信息，例如采样率、声道数、编码格式等（已删）#include audio_gst.config\t#（已删）#include base.config #系统基本配置，例如时钟频率、内存分配、启动选项等#include base_extra.config#include benchmark.config #性能测试相关的配置信息，例如测试用例、测试参数#include bt.config #蓝牙相关的配置信息，例如蓝牙协议栈选项、蓝牙设备信息（禁删）#include camera.config #相机相关的配置信息，例如分辨率、曝光时间、帧率（已删）#include camera_gst.config\t#（已删）#include debug.config #调试相关的配置信息，例如日志级别、调试选项等#include debug2.config#include display.config #显示相关的配置信息，例如分辨率、屏幕旋转、色彩空间等#include gpu.config GPU #相关的配置信息，例如 GPU 频率、GPU缓存选项等#include network.config #网络相关的配置信息，例如 IP 地址、子网掩码、网络协议等；#include ntfs.config NTFS #文件系统相关的配置信息，例如文件系统选项、磁盘分区信息等；#include qt.config #QT 库相关的配置信息，例如 QT 版本、QT编译选项等；#include video_mpp.config #视频相关的配置信息，例如编码格式、分辨率、帧率等；（已删）#include video_gst.config （已删）#include video_gst_rtsp.config #RTSP 协议相关的配置信息，例如 RTSP服务器地址、端口号等；（已删）#include rk356x_arm64.config #开发板的硬件配置信息，例如 CPU 架构、内存大小、外设选项等；#include test.config #测试相关的配置信息，例如测试用例、测试参数等。BR2_PACKAGE_RECOVERY=y\t##启用Recovery软件包，用于在系统损坏或无法启动时恢复系统BR2_PACKAGE_RECOVERY_BOOTCONTROL=y\t#启用RecoveryBootControl软件包，用于控制系统启动时是否进入Recovery模式BR2_PACKAGE_RECOVERY_RETRY=y\t#启用RecoveryRetry软件包，用于在Recovery模式下重试更新操作BR2_PACKAGE_RECOVERY_USE_UPDATEENGINE=y\t#启用UpdateEngine软件包，用于在Recovery模式下进行系统更新BR2_PACKAGE_RECOVERY_UPDATEENGINEBIN=y\t#启用UpdateEngineBinary软件包，用于在Recovery模式下执行系统更新BR2_PACKAGE_RECOVERY_NO_UI=y\t#启用NoUIRecovery软件包，用于在Recovery模式下禁用UI界面BR2_TARGET_ENABLE_ROOT_LOGIN=y\t#启用root用户登录BR2_TARGET_GENERIC_ROOT_PASSWD=ubuntu\t#设置root用户的密码为ubuntuBR2_TARGET_GENERIC_GETTY_BAUDRATE_115200=y\t#设置终端波特率为115200BR2_TARGET_LOCALTIME=Asia/Shanghai\t#设置系统时区为亚洲/上海BR2_ROOTFS_OVERLAY=board/rockchip/ok3568/fs-overlay/\t#设置根文件系统的覆盖目录BR2_PACKAGE_TENSORFLOW=y\t#启用TensorFlow软件包（已删）BR2_PACKAGE_RKNPU2=y\t#启用RKNPU2软件包，用于支持Rockchip芯片的神经网络加速（已删）BR2_PACKAGE_RKAIQ_TOOL_SERVER=y\t#启用RKAIQToolServer软件包，用于支持Rockchip芯片的图像处理（已删）BR2_PACKAGE_FORLINX=y\t#启用Forlinx软件包BR2_PACKAGE_MATRIX_BROWSER=y\t#启用MatrixBrowser软件包，用于支持矩阵式键盘（已删）BR2_PACKAGE_DWKEYBOARD=y\t#启用DWKeyboard软件包，用于支持多语言输入法（已删）BR2_PACKAGE_QUECTELCM=y\t#启用QuectelCM软件包，用于支持Quectel无线模块（已删）BR2_PACKAGE_FORLINX_QT=y\t#启用ForlinxQt软件包BR2_PACKAGE_FORLINX_CMD=y\t#启用ForlinxCMD软件包BR2_PACKAGE_FFMPEG_AVRESAMPLE=y\t#启用FFmpegAvresample软件包，用于音频重采样（已删）BR2_PACKAGE_FFMPEG_SWSCALE=y\t#启用FFmpegSwscale软件包，用于视频缩放（已删）BR2_PACKAGE_HICOLOR_ICON_THEME=y\t#启用HicolorIconTheme软件包，用于支持高分辨率图标（已删）BR2_PACKAGE_QT5BASE_SQLITE_QT=y\t#启用Qt5BaseSQLiteQt软件包，用于支持SQLite数据库（已删）BR2_PACKAGE_QT5BASE_GIF=y\t#启用Qt5BaseGIF软件包，用于支持GIF图像格式（已删）BR2_PACKAGE_QT5CHARTS=y\t#启用Qt5Charts软件包，用于支持图表和统计数据的可视化（已删）BR2_PACKAGE_QT5SERIALBUS=y\t#启用Qt5SerialBus软件包，用于支持串行总线通信BR2_PACKAGE_QT5WEBKIT=y\t#启用Qt5WebKit软件包，用于支持Web浏览器（已删）BR2_PACKAGE_QT5WEBENGINE=y\t#启用Qt5WebEngine软件包，用于支持Web浏览器引擎（已删）BR2_PACKAGE_UBOOT_TOOLS=y\t#启用U-Boot工具软件包，用于支持U-Boot引导程序BR2_PACKAGE_PHP=y\t#启用PHP软件包，用于支持服务器端脚本语言（已删）BR2_PACKAGE_PHP_SAPI_CGI=y\t#启用PHPSAPICGI软件包，用于支持使用CGI接口运行PHP脚本（已删）BR2_PACKAGE_PHP_SAPI_CLI=y\t#启用PHPSAPICLI软件包，用于支持使用命令行接口运行PHP脚本（已删）BR2_PACKAGE_PHP_EXT_FILEINFO=y\t#启用PHPFileinfo扩展软件包，用于支持文件类型检测（已删）BR2_PACKAGE_PHP_EXT_OPCACHE=y\t#启用PHPOpcache扩展软件包，用于提高PHP脚本的执行效率（已删）BR2_PACKAGE_PHP_EXT_READLINE=y\t#启用PHPReadline扩展软件包，用于支持命令行编辑（已删）BR2_PACKAGE_PHP_EXT_ICONV=y\t#启用PHPIconv扩展软件包，用于支持字符集转换（已删）BR2_PACKAGE_PHP_EXT_MBSTRING=y\t#启用PHPMbstring扩展软件包，用于支持多字节字符集（已删）BR2_PACKAGE_PHP_EXT_JSON=y\t#启用PHPJSON扩展软件包，用于支持dJSON数据格式BR2_PACKAGE_PHP_EXT_TOKENIZER=y\t#启用PHPTokenizer扩展软件包，用于支持PHP代码解析（已删）BR2_PACKAGE_PHP_EXT_CURL=y\t#启用PHPcURL扩展软件包，用于支持HTTP请求（已删）BR2_PACKAGE_PHP_EXT_FTP=y\t#启用PHPFTP扩展软件包，用于支持FTP协议（已删）BR2_PACKAGE_PHP_EXT_SOAP=y\t#启用PHPSOAP扩展软件包，用于支持SOAP协议（已删）BR2_PACKAGE_PHP_EXT_XMLRPC=y\t#启用PHPXML-RPC扩展软件包，用于支持XML-RPC协议（已删）BR2_PACKAGE_TINYALSA=y\t#启用TinyALSA软件包，用于支持音频功能（已删）BR2_PACKAGE_LZO=y\t#启用LZO压缩软件包，用于支持数据压缩BR2_PACKAGE_LIBGTK3=y\t#启用GTK3库软件包，用于支持图形用户界面BR2_PACKAGE_OPENCV3=y\t#启用OpenCV3软件包，用于支持计算机视觉（已删）BR2_PACKAGE_OPENCV3_LIB_HIGHGUI=y\t#编译OpenCV3中的HighGUI库（已删）BR2_PACKAGE_OPENCV3_WITH_GTK3=y\t#启用GTK3支持（已删）BR2_PACKAGE_OPENCV3_LIB_PHOTO=y\t#Photo库（已删）BR2_PACKAGE_OPENCV3_LIB_SHAPE=y\t#Shape库（已删）BR2_PACKAGE_OPENCV3_LIB_STITCHING=y\t#Stitching库（已删）BR2_PACKAGE_OPENCV3_WITH_JASPER=y\t#启用Jasper支持（已删）BR2_PACKAGE_OPENCV3_WITH_JPEG=y\t#启用JPEG支持（已删）BR2_PACKAGE_OPENCV3_WITH_PNG=y\t#启用PNG支持（已删）BR2_PACKAGE_OPENCV3_WITH_PROTOBUF=y\t#启用ProtocolBuffers支持。（已删）BR2_PACKAGE_OPENCV3_WITH_TIFF=y\t#启用TIFF支持（已删）BR2_PACKAGE_OPENCV3_WITH_V4L=y\t#启用Video4Linux支持。（已删）BR2_PACKAGE_IPROUTE2=y\t#选中iproute2软件包进行编译BR2_PACKAGE_IPTABLES=y\t#选中iptables软件包进行编译BR2_PACKAGE_IPTABLES_BPF_NFSYNPROXY=y\t#编译iptables时启用BPF和nf_synproxy支持BR2_PACKAGE_IPTABLES_NFTABLES=y\t#编译iptables时启用nftables支持BR2_PACKAGE_LIGHTTPD=y\t#选中lighttpd软件包进行编译（已删）BR2_PACKAGE_LIGHTTPD_PCRE=y\t#编译lighttpd时启用PCRE支持（已删）BR2_PACKAGE_OPENSSH=y\t#选中OpenSSH软件包进行编译BR2_PACKAGE_VSFTPD=y\t#选中vsftpd软件包进行编译BR2_PACKAGE_RKWIFIBT=n\t#不选中rkwifibt软件包进行编译BR2_PACKAGE_USBMOUNT=n\t#不选中usbmount软件包进行编译BR2_PACKAGE_OPENCV3_LIB_PYTHON=y\t#编译OpenCV3中的Python库（已删）BR2_PACKAGE_LIBGTK3_BROADWAY=y\t#编译libgtk3时启用Broadway支持BR2_PACKAGE_LIBGTK3_WAYLAND=y\t#编译libgtk3时启用Wayland支持BR2_PACKAGE_OPENCV3_GUI_NONE=n\t#编译OpenCV3时启用GUI支持BR2_PACKAGE_QT5SERIALPORT=y\t#选中Qt5中的SerialPort模块进行编译 2.2 软件包Buildroot 的软件包配置文件位于 ~/buildroot/package/rockchip/Config.in，包含了多个软件包的配置，可以在基于 Rockchip 硬件的嵌入式系统上进行构建和安装。这些软件包并不是全部必须的，具体需要哪些软件包取决于嵌入式系统的具体需求和配置。 ROS\t机器人操作系统，提供了一种构建机器人应用的框架，包括硬件抽象、设备驱动、库、可视化工具、消息传递和软件包管理等功能\tLocalPlayer\t一个本地播放器，可以播放本地音频和视频文件\tAPL核心库\tAlexa Presentation Language（APL）的核心库，提供了一个用于构建Alexa智能屏幕体验的框架\tAVS设备SDK\tAlexa Voice Service（AVS）设备SDK，提供了一个用于构建Alexa智能设备的框架，包括语音识别、语音合成、音频处理、设备控制等功能\tAlexa智能屏幕SDK\t构建Alexa智能屏幕应用的SDK，包括模板、组件、样式、事件等功能\tACS\tAlexa客户端服务，提供了一个用于构建Alexa客户端应用的框架，包括设备授权、用户认证、设备状态管理等功能\tAlexa客户端SDK\t用于构建Alexa客户端应用的SDK，包括语音识别、语音合成、设备控制等功能\tMPP\tMedia Processing Platform，提供了一个用于嵌入式系统中音视频处理的框架，包括编解码、滤镜、音频处理等功能\td地址检查器\t提供了一种检查程序中地址错误的工具，帮助开发人员在程序开发过程中发现和纠正地址错误\tGStreamer1 Rockchip\t基于GStreamer1的Rockchip硬件加速插件，提供了硬件加速的音视频编解码和渲染功能\td相机引擎CIFISP\t用于Rockchip芯片的ISP引擎，提供了图像处理、白平衡、自动曝光、自动对焦等功能\tdWakeWordAgent\t唤醒词引擎，提供了唤醒词检测和响应的功能\tdPCBA\tPCB组装和测试工具，用于测试和组装PCB板\tdSoftAP\t软件接入点，提供了一个基于软件的Wi-Fi接入点，可以让其他设备连接到嵌入式系统的Wi-Fi网络\tdSoftAP服务器\t提供了一个Web服务器，可以通过Web界面配置和管理SoftAP\tdWifiautoSetup dGStreamer1 IEP\t基于GStreamer1的IEP插件，提供了硬件加速的视频编解码和渲染功能\tdrkwifibt dRockchip实用工具\t提供了一些用于Rockchip硬件的实用工具，包括升级工具、调试工具、驱动程序等\tmdev挂载\t提供了一种自动挂载U盘、SD卡等外部存储设备的工具\tALSA捕获\t提供了一个用于ALSA音频捕获的应用程序，可以从音频设备中捕获音频数据\tdUVC应用程序\t提供了一个用于UVC摄像头的应用程序，可以捕获视频数据并进行处理\tdUAC应用程序\t提供了一个用于USB音频类设备的应用程序\tdlibmali\tArm Mali GPU的用户空间驱动程序\tlibhdmiset\t提供了一个用于HDMI设置的库\tddialserver\t提供了一个用于远程管理设备的服务器\tlinux-rga\tRockchip Graphics Accelerator（RGA）的Linux内核驱动程序\tlinux-serial-test\t提供了一个用于Linux串口测试的应用程序\tdiflytekSDK\t提供了一个用于讯飞语音识别的SDK\tdeq_drc_process\t提供了一个用于音频均衡和动态范围控制的库\tdalsa_ladspa\t提供了一个用于ALSA音频的LADSPA插件库\tdrockchip_test\t提供了一些用于Rockchip硬件测试的工具\tQStressTest\t提供了一个用于系统压力测试的工具\trockchip_modules\t提供了一些用于Rockchip硬件的内核模块\tbroadcom_bsa\tBroadcom蓝牙栈的用户空间库\tcypress_bsa\tCypress蓝牙栈的用户空间库\tpm-suspend-api\t提供了一个用于系统挂起和恢复的API\trtw_simple_config\t提供了一个用于Realtek Wi-Fi芯片的简单配置工具\tdrecovery\t提供了一个用于恢复系统的工具\tmodeset\t提供了一个用于显示模式设置的工具\trkjpeg\t提供了一个用于Rockchip JPEG编解码的库\tdjpegdemo\t提供了一个用于JPEG编解码的演示程序\tdueventd\t提供了一个用于处理Linux系统事件的守护进程\trkupdate\t提供了一个用于Rockchip系统升级的工具\trktoolkit\t提供了一些用于Rockchip硬件的工具集\trkmedia\t提供了一个用于Rockchip媒体处理的框架\tdrockit\t提供了一个用于音视频处理的框架\tdrkadk\t提供了一个用于Rockchip AI开发的工具集\tdmusic\t提供了一个用于音乐播放的应用程序\tdvideo\t提供了一个用于视频播放的应用程序\tdcamera carmachine\t提供了一个用于车载娱乐系统的应用程序\tdgallery\t提供了一个用于图库管理的应用程序\tdQLauncher\t这是一个基于 Rockchip 平台的启动器，用于启动设备上的应用程序和服务\tQFacialGate\t这是一个用于人脸识别的软件包，可以在 Rockchip 平台上实现人脸识别功能\tdsettings\t这是一个提供设置和配置选项的软件包，可以帮助用户配置设备并进行各种设置\tQcamera dqfm\t这是一个文件管理器软件包，可以帮助用户管理设备上的文件和文件夹\tqplayer dMultivideoplayer dMulticamera dQsetting dpowermanager\t这是一个用于管理设备电源的软件包，可以帮助用户管理设备的电源状态和电池寿命\taudioservice\t这是一个用于管理设备音频的软件包，可以帮助用户管理设备的音频输入和输出\tdsecurityAuth recoverySystem\t这是一个用于设备恢复和修复的软件包，可以帮助用户在设备出现问题时进行恢复和修复操作\tLed_control_app dNpu_powerctrl dNpu_powerctrl_combine dN4 Cae_vad Ipc_share_memory Rk_hw_vad minigui\t这是一个轻量级的 GUI（图形用户界面）框架，可以帮助开发人员构建简单的 GUI 应用程序\tMinigui_demo Kernel_modules tensorflow Rknpurknpu2rknpu-fwrknn_demo\t这些软件包都与瑞芯微的神经处理单元（NPU）相关，可以帮助开发人员构建和优化神经网络模型\tdficial_gateRkfacialpose_bodyface_detect\t这些软件包都与面部识别相关，可以帮助开发人员构建和优化面部识别模型\tdrockx\t这是一个 Rockchip 平台上的计算机视觉库，提供了各种计算机视觉算法和工具\tdrockface\t这是一个人脸识别库，可以在 Rockchip 平台上实现人脸识别功能\tdmtp\t这是一个用于在计算机和移动设备之间传输文件的协议，可以帮助用户快速地在设备之间传输文件\tdalsa-config\t这是一个用于配置 ALSA（Advanced Linux Sound Architecture）的软件包，可以帮助用户配置设备的音频输入和输出\tdlibcapsimage\t这是一个用于处理图像的库，可以帮助开发人员处理和优化图像\tdrkscript\t这是一个用于运行脚本的工具，可以帮助用户在设备上运行各种脚本\tDeviceiodeviceio_release\t这是用于设备输入输出的软件包，可以帮助开发人员编写和优化输入输出驱动程序\tDui\t这是一个用于开发 UI（用户界面）应用程序的库，可以帮助开发人员构建和优化 UI 应用程序\tble_wificonfig\t这是一个用于配置蓝牙和 Wi-Fi 连接的软件包，可以帮助用户配置设备的无线连接\tdlibavb、libavb_ablibavb_user\t这些软件包都与 AVB（Android Verified Boot）相关，可以帮助用户验证设备的启动过程和系统完整性\tdlibv4l-rkmpp\t这是一个用于处理视频的库，可以帮助开发人员处理和优化视频\tdBootcontrolLinuxAB\t这些软件包都与启动控制相关，可以帮助用户管理设备的启动过程和控制\tsensor-daemon\t这是一个用于管理设备传感器的软件包，可以帮助用户管理设备的传感器和数据\trtc_demo\t这是一个用于管理设备 RTC（Real-Time Clock）的软件包，可以帮助用户管理设备的时间和日期\trk_webui\t这是一个用于开发 Web UI 应用程序的库，可以帮助开发人员构建和优化 Web UI 应用程序\tdcommon_algorithm\t这是一个用于处理常见算法的库，可以帮助开发人员处理和优化算法\tipcweb-backendLibgdbuslibIPCProtocollibrkdb\t这些软件包都与进程间通信相关，可以帮助开发人员实现进程间通信和数据传输\tDbserverNetserverstorage_managerMediaserveraiserver\t这些软件包都与设备管理和服务相关，可以帮助用户管理设备和服务\trk_oem\t这是一个用于 OEM和定制化的软件包，可以帮助设备制造商定制和优化设备\trootfs_ubi_use_custom_filesystem\t这是一个用于创建和管理 UBI（Unsorted Block Images）文件系统的软件包，可以帮助用户管理设备的文件系统\trkbar\t这是一个用于管理设备底部导航栏的软件包，可以帮助用户管理设备底部导航栏\tminilogger\t这是一个用于记录日志的工具，可以帮助用户记录设备的运行日志\tipc-daemonCallFunIpcisp2-ipc\t这些软件包都与进程间通信相关，可以帮助开发人员实现进程间通信和数据传输\tsmart_display_service\t这是一个用于管理设备智能显示的软件包，可以帮助用户管理设备的显示和显示设置\tonvif_server\t这是一个用于实现 ONVIF（Open Network Video Interface Forum）协议的软件包，可以帮助用户实现网络视频监控功能\tdeptz_demo\t这是一个用于实现电子变焦和电子云台功能的软件包，可以帮助用户实现更好的视频监控功能\tdrksl 和 sl_lock\t这些软件包都与设备安全相关，可以帮助用户保护设备安全和数据隐私\tmult_uvc_demo\t这是一个用于管理多个 UVC（USB Video Class）摄像头的软件包，可以帮助用户管理多个摄像头并进行视频捕捉和处理\tdpcba_adb_test\t这是一个用于测试设备 PCBA（Printed Circuit Board Assembly）的软件包，可以帮助用户测试设备硬件和连接性\tcamera_factory_test_server\t这是一个用于测试设备摄像头的软件包，可以帮助用户测试设备摄像头的性能和质量\tdthunderboot\t这是一个用于启动控制和固件更新的软件包，可以帮助用户管理设备的启动过程和固件更新\tstartup_app_ipc\t这是一个用于进程间通信的软件包，可以帮助开发人员实现进程间通信和数据传输\trkaiq_tool_server\t这是一个用于调试和优化 ISP（Image Signal Processor）的软件包，可以帮助开发人员调试和优化设备的图像处理功能\tdrkiio\t这是一个用于管理设备输入输出的软件包，可以帮助用户管理设备的输入输出\tlvgl\t这是一个用于开发 GUI 应用程序的库，可以帮助开发人员构建和优化 GUI 应用程序\tcvr_app\t这是一个用于Rockchip芯片的视频录制应用程序，可以在嵌入式系统上运行。它支持多种视频格式，包括H.264和H.265。该应用程序可以通过配置文件进行配置，以满足不同的录制需求。例如，可以设置录制分辨率、帧率、码率等参数\tdrkipc\t这是一个用于Rockchip芯片的IPC（Inter-Process Communication）库，用于在嵌入式系统中实现进程间通信。它提供了多种IPC机制，包括共享内存、消息队列、信号量等。该库可以用于不同的应用程序之间进行通信，例如音视频采集、编码、解码等\trkfsmk\t这是一个用于Rockchip芯片的文件系统制作工具，用于制作嵌入式系统中的文件系统。它支持多种文件系统格式，包括ext2、ext3、ext4等。该工具可以根据配置文件生成文件系统镜像，以便在嵌入式系统中使用","categories":["1.平台","嵌入式","系统移植"]},{"title":"多核处理器的负载均衡","path":"/2024/07/25/1-平台-Linux-内核-多核处理器的负载均衡/","content":"现阶段多核处理器的应用范围越来越广泛，在通常情况下应用程序的调度都是交由操作系统进行管理，操作系统对应用程序进行调度，使其在不同的核上轮番运行。 多核操作系统的关注点在于进程的分配和调度。进程的分配将进程分配到合理的物理核上，因为不同的核在共享性和历史运行情况都是不同的。有的物理核能够共享二级 cache，而有的却是独立的。如果将有数据共享的进程分配给有共享二级 cache 的核上，将大大提升性能；反之，就有可能影响性能。 在一般情况下，操作系统的默认调度机制可以应付大部分的情况，但是针对于需要高运行效率的进程来说，就有必要考虑将其固定在一个核上运行，避免在不同的核上调度造成的额外开销。 对于绑定的进程来说，该进程将会一直在指定的核上运行，不会在被调度到其他的核上，但是被绑定的核上仍然有可能运行其他进程。 在多核处理器的 Linux 系统中,可以通过几种方法实现应用程序线程在指定 CPU 核上运行,从而提高性能并减少不同核心间切换的开销. 需要注意的是,手动绑核应谨慎使用,因为它可能会影响系统的整体负载均衡. 在大多数情况下,操作系统的默认调度策略已经能够很好地管理线程分配. 查看 cpu 有几个核cat /proc/cpuinfo 使用系统调用 sysconf 获取 cpu 核心数： #include unistd.hint sysconf(_SC_NPROCESSORS_CONF);/* 返回系统可以使用的核数，但是其值会包括系统中禁用的核的数目，因 此该值并不代表当前系统中可用的核数 */int sysconf(_SC_NPROCESSORS_ONLN);/* 返回值真正的代表了系统当前可用的核数 *//* 以下两个函数与上述类似 */#include sys/sysinfo.hint get_nprocs_conf (void);/* 可用核数 */int get_nprocs (void);/* 真正的反映了当前可用核数 */ taskset 命令taskset 可以在命令行中将进程或线程绑定到特定的 CPU 核心. 查看进程绑定情况 taskset -p [pid] 绑定进程到指定 CPU 核（cpuid 的标号是从 0 开始的） taskset -cp [cpuid] [pid] 例如:（将进程 9865 绑定到 1,2,5-11 号核） taskset -cp 1,2,5-11 9865 在启动时绑定可以在启动应用程序时使用 taskset 命令直接绑定: taskset -c 0,1 ./your_program sched_setaffinity 系统调用在程序代码中可以使用 sched_setaffinity 函数来设置线程的 CPU 亲和性: #define _GNU_SOURCE#include sched.h/* 设置进程号为pid的进程运行在mask所设定的CPU上 * 第二个参数cpusetsize是mask所指定的数的长度 * 通常设定为sizeof(cpu_set_t) * 如果pid的值为0,则表示指定的是当前进程 */int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);/* 获得pid所指示的进程的CPU位掩码,并将该掩码返回到mask所指向的结构中 */int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);cpu_set_t mask;CPU_ZERO(mask);CPU_SET(0, mask); // 设置亲和性为 CPU 0sched_setaffinity(0, sizeof(mask), mask); 测试代码#includestdlib.h#includestdio.h#includesys/types.h#includesys/sysinfo.h#includeunistd.h#define __USE_GNU#includesched.h#includectype.h#includestring.h#includepthread.h#define THREAD_MAX_NUM 200 //1个CPU内的最多进程数int num=0; //cpu中核数void* threadFun(void* arg) //arg 传递线程标号（自己定义） cpu_set_t mask; //CPU核的集合 cpu_set_t get; //获取在集合中的CPU int *a = (int *)arg; int i; printf(the thread is:%d ,*a); //显示是第几个线程 CPU_ZERO(mask); //置空 CPU_SET(*a,mask); //设置亲和力值 if (sched_setaffinity(0, sizeof(mask), mask) == -1)//设置线程CPU亲和力 printf(warning: could not set CPU affinity, continuing... ); CPU_ZERO(get); if (sched_getaffinity(0, sizeof(get), get) == -1)//获取线程CPU亲和力 printf(warning: cound not get thread affinity, continuing... ); for (i = 0; i num; i++) if (CPU_ISSET(i, get))//判断线程与哪个CPU有亲和力 printf(this thread %d is running processor : %d , i,i); return NULL;int main(int argc, char* argv[]) int tid[THREAD_MAX_NUM]; int i; pthread_t thread[THREAD_MAX_NUM]; num = sysconf(_SC_NPROCESSORS_CONF); //获取核数 if (num THREAD_MAX_NUM) printf(num of cores[%d] is bigger than THREAD_MAX_NUM[%d]! , num, THREAD_MAX_NUM); return -1; printf(system has %i processor(s). , num); for(i=0;inum;i++) tid[i] = i; //每个线程必须有个tid[i] pthread_create(thread[i],NULL,threadFun,(void*)tid[i]); for(i=0; i num; i++) pthread_join(thread[i],NULL);//等待所有的线程结束，线程为死循环所以CTRL+C结束 return 0; pthread_setaffinity_np 函数对于 POSIX 线程,可以使用 pthread_setaffinity_np 函数来设置线程亲和性: #define _GNU_SOURCE#include pthread.hint pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);cpu_set_t cpuset;CPU_ZERO(cpuset);CPU_SET(2, cpuset);pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), cpuset); 测试代码#include pthread.h#include stdio.h#include stdlib.h#include unistd.h#include sched.h#include sys/types.h#include sys/syscall.hpid_t gettid(void) return syscall(SYS_gettid);/** * @brief print_running_cpu * pthread_setaffinity_np函数用于设置线程的CPU亲和度。 * CPU_SET和CPU_ZERO用于设置和清除CPU掩码。 * print_running_cpu函数通过系统命令查询线程当前运行的CPU核，并打印出来。 */void print_running_cpu() char qry_cmd[1024] = 0 ; sprintf(qry_cmd, ps -o pid,spid,psr -T -p %d | grep %d | tail -n 1 | awk print $3, getpid(), gettid()); FILE *fp = popen(qry_cmd, r); if(fp == NULL) return; char cpu_id_str[200] = 0 ; fgets(cpu_id_str, 80, fp); fclose(fp); printf([%d] : current thread(%d@%d) is running on cpu(%d) , gettid(), gettid(), getpid(), atoi(cpu_id_str));void bind_thread_to_cpu(int cpu_id) cpu_set_t cpu_mask; CPU_ZERO(cpu_mask); CPU_SET(cpu_id, cpu_mask); pthread_setaffinity_np(pthread_self(), sizeof(cpu_mask), cpu_mask);void* thread_func(void* p_arg) int bind_cpu_id = *(int *)p_arg; printf([%d] : setting cpu affinity for thread(%d@%d) to cpu(%d) , gettid(), gettid(), getpid(), bind_cpu_id); bind_thread_to_cpu(bind_cpu_id); print_running_cpu(); while(1) // 模拟工作负载 long loop = 4000000000; while(loop--) sleep(0); print_running_cpu(); return NULL;int main(int argc, char *argv[]) int cpu_id_1 = 1; int cpu_id_2 = 2; pthread_t thr_id_1, thr_id_2; // 创建并绑定线程1到CPU 1 pthread_create(thr_id_1, NULL, thread_func, cpu_id_1); sleep(1); // 确保线程1已经绑定 // 创建并绑定线程2到CPU 2 pthread_create(thr_id_2, NULL, thread_func, cpu_id_2); // 等待线程结束 pthread_join(thr_id_1, NULL); pthread_join(thr_id_2, NULL);","categories":["1.平台","Linux","内核"]},{"title":"ARM和X86","path":"/2024/07/24/1-平台-平台相关-ARM和X86/","content":"ARM 是基于 RISC 的产品，而 PC 的代言人是 x86，基于 CISC。ARM、x86 之争，其实就是 RISC 和 CISC 之争。 RISC 和 CISC计算机科学中两种主要理念之间的分歧：简化程序员的工作简化微处理器的工作。 要想使用计算机执行任何高效的操作，操作系统及其执行的程序需要与中央处理器（CPU）以及其他硬件（如内存、存储器和网卡）进行交互。CPU 发挥着在操作系统（和上面运行的程序）与这些硬件之间进行调解的作用。为了简化程序员的工作，CPU 有一组预定义的操作和计算，称为指令集或 ISA（指令集架构）。操作系统及其执行的程序（均由程序员编写）依赖这些指令来执行低层功能，例如： CPU 与硬件（内存、存储器、网络等）之间的交互 算术函数（加法、减法等） 数据操作（二进制移位等）。 CISC最初的 x86 CPU 拥有（并且现在仍然拥有）非常丰富的指令集。一条指令可以完成整个计算（如乘法）或将一块数据直接从内存中的一个位置移动到另一个位置。这听起来没什么大不了，但在内存中的不同位置之间进行乘法计算和移动数据确实需要在低层执行大量指令。对于 x86 计算机，这一系列复杂的操作可以在一个周期内完成。具有这种类型指令集的处理单元被称为复杂指令集计算机（CISC，Complex Instruction Set Computer）。 然而，CISC 计算机中的指令如此强大，也意味着它需要更多的晶体管，从而会占用空间并消耗能量。 RISC精简指令集计算机，Reduced Instruction Set Computer 在现实中，大多数计算机仅使用 CISC 计算机所提供的大量指令中的一小部分。最终，精简指令集计算机（RISC）处理器设计应运而生。RISC 处理器也有一个指令集，但其中每条指令仅代表一个能耗较低的简单操作。这就使汇编语言程序员的工作变得更加复杂，但却简化了处理器的工作。利用 RISC 处理器和先进的 RISC 计算机，可以通过运行多条指令或通过将复杂工作推给编译器（而不是 CPU 内核）来执行复杂操作。 其中离不开一些权衡与取舍。x86 CPU 往往具有非常快的计算能力，并且在编程和指令数量方面会更加清晰或简单，但它的代价，就是更大、更昂贵且具有大量晶体管的芯片。ARM 处理器对于某些类型的操作而言可能非常快，但单个指令的重复循环可能会减慢它的速度，这是因为操作更为复杂，并且定义和执行操作的更多工作被推给了编程（和程序员），而不是指令集。 此外，鉴于以上差异，们可能难以计算其 MIPS（每秒百万条指令，一种对计算机原始处理能力的常用度量），因为不同类型的处理器在执行同一活动时需要用到不同的指令集。 ARM 与 x86 的能耗RISC 架构源自为小型计算机或微型计算机（最终成为 PC）制造性能更好、外形更小的芯片的需求。于是，这就引出了第二个基本设计问题：究竟是侧重于芯片性能（处理速度或时钟速度）还是能源消耗（功耗）。 由于 ARM 处理器集成到了 SoC 上，因此长期以来围绕的焦点就是整体资源管理，包括低能耗和更低的热量生成。例如，ARM 架构（如 ARMv8）往往没有简单的散热系统（手机上没有风扇）。而另一方面，x86 CPU 倾向于支持高端处理速度，而不是以低功耗为目标。 虽然两种 CPU 设计都具有高性能（ARM 和 x86 阵营都有速度在世界上数一数二的超级计算机），但 ARM 设计往往侧重于更小巧的外形、电池使用时间、尺寸、免除散热要求和成本（这也许是最重要的）等方面。这就是 ARM 处理器主导智能手机、平板电脑甚至树莓派系统等小型电子产品和移动设备的原因。而 x86 架构在服务器、PC 甚至笔记本电脑中更为常见，因为这些领域需要实时的速度和灵活性，并且对散热和尺寸的限制较少。","categories":["1.平台","平台相关"]},{"title":"CISC和RISC","path":"/2024/07/23/1-平台-平台相关-CISC和RISC/","content":"CISC 与 RISC 的区别CISC（复杂指令集）复杂指令集（CISC）CPU 设计了一系列丰富的汇编指令，以便用较少的指令完成复杂的操作。举个例子，CISC 可以通过一条指令同时执行乘法、加法及其他运算，这样在处理数据时，CPU 只需一个机器周期就能完成运算。这样，这种设计在某些应用上展示出强大的性能，尤其是在需要执行复杂计算的任务时。 然而，CISC 的硬件设计较为复杂，这导致其内部结构需要较多的组件，以及相应的处理时间和能耗。尽管如此，目前绝大多数个人计算机（PC）使用的处理器仍是 CISC 结构，例如 Intel 和 AMD 的主流处理器。此外，许多嵌入式系统，比如 51 单片机，也采用 CISC 架构，确保能够处理多种复杂任务。 RISC（精简指令集）相比之下，精简指令集（RISC）采用了更简化的设计，其汇编指令数量大幅减少，从而简化了 CPU 的设计。通过 RISC，当需要完成运算（例如：计算（1+1）×（2-1））时，需分多个步骤进行：首先计算 1+1 得到 2，再计算 2-1 得到 1，最后进行 2×1 的乘法，整个过程可能需要经历多个机器周期。因此，整体运算效率相较于 CISC 显得更低。 随着技术的进步，CPU 的主频在材料技术约束下难以提高，因此 RISC 的单核 CPU 在效率上往往不及 CISC。为了弥补这一不足，现代手机和其他移动设备通常通过增加核心数量来提升处理效率，从而在多任务并行处理上获得更好的性能。 地址总线、数据总线和控制总线的区别地址总线（Address Bus）在数据处理过程中，地址总线负责发送内存地址，帮助 CPU 找到待处理的数据。例如，当 CPU 确定要读取某一地址的数据时，地址总线会发起寻址请求。地址总线的宽度直接决定了可以寻址的数据量。如果一条地址总线宽度为 32 位，它能访问最大 4GB 的地址空间。然而，地址总线的设计为单向，即只能由 CPU 发起寻址请求，无法被外部设备主动使用，因此其工作模式为高电平、低电平和高阻态。 数据总线（Data Bus）一旦地址确定，数据总线就拿到角色。它负责将读取或写入操作的数据传输到 CPU。例如，CPU 需要将某地址的数据读入内存或存储到外部设备中，这时数据总线通过转发信号来实现数据的读写。数据总线是双向的，可以在读取数据时发送信号，也可以在写入数据时接收信号，传输的宽度即为单次可以传输的数据量。 控制总线（Control Bus）控制总线承担指挥所有操作的责任，在 CPU 与外设间传递控制信号，比如读写请求和状态信息。由于它需要对所有外设进行控制，因此其通信为双向，并相对灵活。控制总线的宽度通常不固定，而是根据连接至系统的外设数量而异，从而确保所有设备都能收到指令并进行相应的操作。 统一编址和独立编址的区别在讨论统一编址与独立编址之前，了解寻址过程是必要的。在 CPU 进行数据处理时，控制总线会首先发送控制信号，然后寻址外设（包括 IO 设备和内存）。寻址方式由 CPU 所定义的地址编址方式决定，主要分为统一编址和独立编址两种类型。 统一编址在统一编址中，CPU 通过地址总线直接寻址 IO 设备。由于地址总线宽度是固定的，这意味着统一编址会占用一定的地址空间，导致可操作内存的地址范围缩小。例如，如果一个 32 位地址总线可以寻址 4GB 内存，但因 IO 设备占用了部分地址，实际可用的内存就会低于 4GB，这显得不够高效。 独立编址与之相比，独立编址允许 CPU 使用专门的操作指令来处理 IO 设备，这意味着地址总线的操作仅用于内存地址。这样的设计确保了内存地址的最大化利用，因此，独立编址的内存大小与地址总线的宽度相等，可以更高效地使用系统资源。 哈佛结构和冯诺依曼结构的区别在程序编写与执行的过程中，程序可以被分为两种不同的部分：不再需要修改的逻辑代码和随着程序运行而不断变化的变量值。哈佛结构与冯诺依曼结构的不同就在于这两部分代码的存储方式。 哈佛结构哈佛结构将逻辑代码和变量值分开存放，这种方式确保两种数据不会相互干扰。例如，51 单片机的逻辑代码存放在只读存储器（ROM）中，而变量则存储在随机存取存储器（RAM）中。ARM 架构虽然逻辑代码和变量都存放在 RAM 中，但内部内存仍划分为逻辑代码和变量的区域，从而避免了读写冲突。通过将两者分开，哈佛结构能够有效地降低程序出现 BUG 时由于相互干扰而引发的问题。 冯诺依曼结构冯诺依曼结构则采用统一存储的方式，将逻辑代码和变量存储在同一个内存空间，通常按执行顺序排列。当程序运行时，逻辑代码和变量数据混合存储，这会导致一个潜在问题：如果逻辑代码的读写不被限制，当程序出现 BUG 时，逻辑代码也可能遭到修改，可能引发系统崩溃或死机。然而，冯诺依曼结构的一个好处是能高效利用内存空间，使得 CPU 能够在程序执行时更为方便，不需要在多个存储区域间切换。","categories":["1.平台","平台相关"]},{"title":"Portainer","path":"/2024/07/19/1-平台-Docker-Portainer/","content":"Portainer can be used to manage Docker containers through a web interface. CE 社区版本部署 首先，创建 Portainer Server 用于存储其数据库的卷： docker volume create portainer_data version: 3services: portainer: image: portainer/portainer-ce:latest container_name: portainer ports: - 9094:9000 volumes: - portainer_data:/data - /var/run/docker.sock:/var/run/docker.sock restart: unless-stoppedvolumes: portainer_data: 现在安装已完成，访问以下网址登录 Portainer Server 实例： https://localhost:9094","categories":["1.平台","Docker"]},{"title":"内核模块","path":"/2024/07/18/1-平台-Linux-内核-内核模块/","content":"内核模块是一段可以动态加载到内核中的代码，这使得开发人员可以扩展内核的功能而无需重启系统或重编译整个内核。 内核模块的编译编写内核模块代码一个简单的内核模块通常包括初始化和清理函数。以下是一个基本的”Hello, World”内核模块示例： #include linux/init.h#include linux/module.h#include linux/kernel.hMODULE_LICENSE(GPL);MODULE_AUTHOR(Your Name);MODULE_DESCRIPTION(A Simple Hello World Module);static int __init hello_init(void) printk(KERN_INFO Hello, World! ); return 0; // 返回0表示成功static void __exit hello_exit(void) printk(KERN_INFO Goodbye, World! );module_init(hello_init);module_exit(hello_exit); 创建 Makefile要编译内核模块，需要一个 Makefile。以下是一个简单的 Makefile 示例： obj-m += hello.oall: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modulesclean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean obj-m：定义需要编译的模块对象文件。 -C libmodules$(shell uname -r)build：指定内核源代码树的路径。 M$(PWD)：指定当前目录。 编译模块在模块源代码所在目录中运行以下命令进行编译： make 这个命令会在当前目录下生成一个 .ko 文件，这是编译后的内核模块。 内核模块的安装加载模块编译完成后，可以使用 insmod 命令将模块加载到内核中： sudo insmod hello.ko insmod：加载指定的内核模块。 hello.ko：编译生成的内核模块文件。 验证模块是否加载可以通过 lsmod 命令检查模块是否已成功加载： lsmod | grep hello 也可以通过 dmesg 查看内核日志，检查模块的输出： dmesg | tail 卸载模块如果需要卸载模块，可以使用 rmmod 命令： sudo rmmod hello 内核模块的调试使用 printk 调试在开发内核模块时，最常用的调试方法是使用 printk 函数输出调试信息。这些信息会被记录在内核日志中，可以通过 dmesg 查看。 printk(KERN_INFO This is a debug message with value: %d , value); KERN_INFO 是一个日志级别，表示信息性消息。还有其他日志级别，如 KERN_DEBUG、KERN_ERR 等。 使用 dmesg 命令可以查看内核输出的调试信息。 使用调试器使用调试器（如 gdb）调试内核模块是可能的，但需要一些额外的设置。典型的步骤包括： 启动一个虚拟机或使用内核调试器（KGDB）来远程调试运行中的内核。 在内核配置中启用 CONFIG_DEBUG_INFO 以生成调试符号。 使用 gdb 连接到内核，加载符号文件，然后进行调试。 使用内核日志和跟踪工具除了 printk，还可以使用以下工具进行调试： ftrace：Linux 内核的内建跟踪工具，用于跟踪函数调用和性能分析。 perf：强大的性能监视和分析工具，适用于分析内核模块的性能问题。 KprobeseBPF：用于动态插入调试探针，以监视内核行为。 常见问题排查编译错误确保内核头文件与运行的内核版本匹配。 检查 Makefile 中的路径是否正确，尤其是内核源代码目录。 模块加载失败检查 dmesg 输出是否有错误信息。 确保模块使用的符号在内核中可用。 检查模块的许可证是否与内核兼容（如 GPL）。 调试信息不足使用更高的 printk 日志级别（如 KERN_DEBUG）来捕获更多详细信息。 使用 dmesg -n 调整 printk 的日志级别过滤器。","categories":["1.平台","Linux","内核"]},{"title":"网络设备驱动的中断处理","path":"/2024/07/17/1-平台-Linux-驱动-网络设备驱动的中断处理/","content":"devm_request_irqdevm_request_irq 用于注册中断处理程序的设备管理函数，主要特点是它自动管理资源，减少了开发人员的负担。使用此函数时，一旦设备驱动程序被卸载，系统会自动释放相关的中断资源。这种机制可以有效地防止资源泄漏和其他潜在问题，确保系统的稳定性和可靠性。 函数原型： int devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t handler, unsigned long irqflags, const char *devname, void *dev_id); 参数说明： dev：指向设备结构体的指针。例如，在一个网络设备驱动中，可以传递 net_dev-dev 来指向网络设备结构体。 irq：要申请的中断号，通常由硬件文档提供，确保指定的中断号未被其他设备使用。 handler：中断处理程序的函数指针，在中断发生时系统调用这个函数。这个函数可以像以下示例一样，执行特定的硬件处理任务： static irqreturn_t my_irq_handler(int irq, void *dev_id) // 执行中断处理 return IRQ_HANDLED; irqflags：中断标志，可以设置为 IRQF_SHARED，表示允许其他设备共享此中断。 devname：设备名称，用于显示和调试，便于追踪和排查问题。 dev_id：设备标识，通常传入设备结构体的指针，帮助区分多个设备共享同一中断的场景。 request_threaded_irqrequest_threaded_irq 可以注册一个中断处理程序，并能够使用线程处理耗时的任务。这种线程化中断处理程序在中断上下文之外运行，使得可以执行更复杂的操作而不至于阻塞立即处理。适用于处理需等待长时间的操作，例如数据传输。 函数原型： int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id); 参数说明： irq：要申请的中断号，确保这个中断号没有被其他设备注册。 handler：顶半部中断处理程序的函数指针，可以为 NULL。该函数通常用于快速处理中断，可以进行一些轻量级的操作。如果操作较为复杂，可以选择只使用线程化处理。 thread_fn：线程化中断处理程序的函数指针，系统在中断发生时会调用此函数，该参数不能为 NULL。示例代码可能如下所示： static int my_thread_fn(unsigned long data) // 执行耗时的处理 return 0; irqflags：中断标志，可以根据需求设置，例如 IRQF_SHARED，表示可以共享中断。 devname：设备名称，用于显示和调试，帮助识别中断来源。 dev_id：设备标识，通常传入设备结构体的指针，用于在共享中断的情况下进行区分。 通过合理使用这两个函数，驱动程序开发人员可以非常高效地管理和响应硬件中断，提升系统性能并简化开发过程。","categories":["1.平台","Linux","驱动"]},{"title":"关于U盘被占用无法弹出","path":"/2024/07/16/1-平台-Windows-U盘被占用无法弹出/","content":"按下 Win+R 键，这会打开一个名为 运行 的对话框，其中允许快速启动程序或打开系统工具。 在 运行 对话框中，输入 eventvwr.msc，然后按 回车 键。这一操作会打开 事件查看器，一个 Windows 内置工具，用于记录系统、应用和安全事件的日志。 打开事件查看器后，左侧的导航窗格中会显示 **事件查看器(本地)**，点击它以展开包含不同日志类别的菜单。 在展开的菜单中，找到并点击 Windows 日志，然后选择 系统。这部分记录与 Windows 操作系统本身有关的事件，例如硬件故障、驱动程序问题或系统服务故障。 浏览系统日志，寻找最近的 警告 事件，特别是源于 Kernel-PnP 的警告。这类警告通常是与设备驱动程序或插拔硬件相关的事件。它们可能与 USB 设备、打印机或其他外部硬件相关。 找到该警告后，双击它，系统将弹出一个新窗口，显示警告的详细信息。在此窗口中，查找 进程 ID 为 **** 的应用程序已停止删除或弹出设备 的信息，这里用”****”表示具体的进程 ID。 记下这个进程 ID，因为它可以帮助进一步调查相关应用程序或设备，并对可能存在的问题进行更深入的分析或修复。例如，如果发现某个设备在不断出现警告，可能需要更新或重新安装其驱动程序。","categories":["1.平台","Windows"]},{"title":"加密方式介绍","path":"/2024/07/12/1-平台-Linux-加密-加密方式介绍/","content":"加密技术通常分为两大类”对称式”和”非对称式”","categories":["1.平台","Linux","加密"]},{"title":"程序加载","path":"/2024/07/11/1-平台-Linux-程序-程序加载/","content":"Linux 中分为用户态和内核态，执行 ELF 文件在用户态的表现就是执行 execve 系统调用，随后陷入内核进行处理。 内核空间内核空间对 execve 的处理其实可以单独用一篇文章去介绍，其中涉及到进程的创建、文件资源的处理以及进程权限的设置等等。这里主要关注其中 ELF 处理相关的部分即可，实际上内核可以识别多种类型的可执行文件，ELF 的处理代码主要在 fsbinfmt_elf.c 中的 load_elf_binary 函数中。 对于 ELF 而言，Linux 内核所关心的只有 Program Header 部分，甚至大部分情况下只关心三种类型的 Header，即 PT_LOAD、PT_INTERP 和 PT_GNU_STACK。以 3.18 内核为例，load_elf_binary 主要有下面操作: 对 ELF 文件做一些基本检查，保证 e_phentsize sizeof(struct elf_phdr)并且 e_phnum 的个数在一定范围内； 循环查看每一项 program header，如果有 PT_INTERP 则使用 open_exec 加载进来，并替换原程序的 bprm-buf; 根据 PT_GNU_STACK 段中的 flag 设置栈是否可执行； 使用 flush_old_exec 来更新当前可执行文件的所有引用； 使用 setup_new_exec 设置新的可执行文件在内核中的状态； setup_arg_pages 在栈上设置程序调用参数的内存页； 循环每一项 PT_LOAD 类型的段，elf_map 映射到对应内存页中，初始化 BSS； 如果存在 interpreter，将入口(elf_entry)设置为 interpreter 的函数入口，否则设置为原 ELF 的入口地址； install_exec_creds(bprm)设置进程权限等信息； create_elf_tables 添加需要的信息到程序的栈中，比如 ELF auxiliary vector； 设置 current-mm 对应的字段； 从内核的处理流程上来看，如果是静态链接的程序，实际上内核返回用户空间执行的就是该程序的入口地址代码；如果是动态链接的程序，内核返回用户空间执行的则是 interpreter 的代码，并由其加载实际的 ELF 程序去执行。 为什么要这么做呢？如果把动态链接相关的代码也放到内核中，就会导致内核执行功能过多，内核的理念一直是能不在内核中执行的就不在内核中处理，以避免出现问题时难以更新而且影响系统整体的稳定性。事实上内核中对 ELF 文件结构的支持是相当有限的，只能读取并理解部分的字段。 用户空间内核返回用户空间后，对于静态链接的程序是直接执行，没什么好说的。而对于动态链接的程序，实际是执行 interpreter 的代码。ELF 的 interpreter 作为一个段，自然是编译链接的时候加进去的，因此和编译使用的工具链有关。对于 Linux 系统而言，使用的一般是 GCC 工具链，而 interpreter 的实现，代码就在 glibc 的 elfrtld.c 中。 interpreter 又称为 dynamic linker，以 glibc2.27 为例，它的大致功能如下: 将实际要执行的 ELF 程序中的内存段加载到当前进程空间中； 将动态库的内存段加载到当前进程空间中； 对 ELF 程序和动态库进行重定向操作(relocation)； 调用动态库的初始化函数(如 .preinit_array, .init, .init_array)； 将控制流传递给目标 ELF 程序，让其看起来自己是直接启动的； 其中参与动态加载和重定向所需要的重要部分就是 Program Header Table 中 PT_DYNAMIC 类型的 Segment。前面提到在 Section Header 中也有一部分参与动态链接的 section，即.dynamic。在自己解析动态链接文件的时候发现，实际上 .dynamic section 中的数据，和 PT_DYNAMIC 中的数据指向的是文件中的同一个地方，即这两个 entry 的 s_offset 和 p_offset 是相同。每个元素的类型如下: typedef struct Elf32_Sword\td_tag; /* Dynamic entry type */ union Elf32_Word d_val; /* Integer value */ Elf32_Addr d_ptr; /* Address value */ d_un; Elf32_Dyn; d_tag 表示实际类型，并且 d_un 和 d_tag 相关。同样的，标准中定义了几十个 d_tag 类型，比较常用的几个如下: DT_NULL: 表示 _DYNAMIC 的结尾 DT_NEEDED: d_val 保存了一个到字符串表头的偏移，指定的字符串表示该 ELF 所依赖的动态库名称 DT_STRTAB: d_ptr 指定了地址保存了符号、动态库名称以及其他用到的字符串 DT_STRSZ: 字符串表的大小 DT_SYMTAB: 指定地址保存了符号表 DT_INITDT_FINI: 指定初始化函数和结束函数的地址 DT_RPATH: 指定动态库搜索目录 DT_SONAME: Shared Object Name，指定当前动态库的名字(logical name) 其中有部分的类型可以和 Section 中的 SHT_xxx 类型进行类比，完整的列表可以参考 ELF 标准中的 Book III: Operating System Specific 一节。 在 interpreter 根据 DT_NEEDED 加载完所有需要的动态库后，就实现了完整进程虚拟内存映像的布局。在寻找某个动态符号时，interpreter 会使用广度优先的方式去进行搜索，即先在当前 ELF 符号表中找，然后再从当前 ELF 的 DT_NEEDED 动态库中找，再然后从动态库中的 DT_NEEDED 里查找。 因为动态库本身是位置无关的(PIE)，支持被加载到内存中的随机位置，因此为了程序中用到的符号可以被正确引用，需要对其进行重定向操作，指向对应符号的真实地址。 Interpreter Hack假设现在面对两种场景: 目标环境的可写磁盘直接 mount 为 noexec，无法执行代码 目标环境内核监控任何非系统路径的程序的执行都会直接告警 运用上面学到的 ELF 知识，利用 interpreter 进行执行。示例如下: $ cat hello.c#include stdio.hint main() return puts(hello!);$ gcc hello.c -o hello$ ./hellohello!$ chmod -x hello$ ./hellobash: ./hello: Permission denied$ /lib64/ld-linux-x86-64.so.2 ./hellohello!$ strace /lib64/ld-linux-x86-64.so.2 ./hello 21 | grep execexecve(/lib64/ld-linux-x86-64.so.2, [/lib64/ld-linux-x86-64.so.2, ./hello], 0x7fff1206f208 /* 9 vars */) = 0 /lib64/ld-linux-x86-64.so.2 本身应该是内核调用执行的，但这里可以直接进行调用。这样一方面可以在没有执行权限的情况下执行任意代码，另一方面也可以在一定程度上避免内核对 execve 的异常监控。 利用(滥用)interpreter 还可以做其他有趣的事情，比如通过修改指定 ELF 文件的 interpreter 为自己的可执行文件，可让内核在处理目标 ELF 时将控制器交给的 interpreter，这可以通过直接修改字符串表或者使用一些工具如 patchelf 来轻松实现。 对于恶意软件分析的场景，很多安全研究人员看到 ELF 就喜欢用 ldd 去看看有什么依赖库，一般 ldd 脚本实际上是调用系统默认的 ld.so 并通过环境变量来打印信息，不过对于某些 glibc 实现(如 glibc2.27 之前的 ld.so)，会调用 ELF 指定的 interpreter 运行，从而存在非预期命令执行的风险。 加固脱壳与逆向分析比较相关的就是符号表，一个有符号的程序在逆向时基本上和读源码差不多。因此对于想保护应用程序的开发者而言，最简单的防护方法就是去除符号表，一个简单的 strip 命令就可实现。strip 删除的主要是 Section 中的信息，因为这不影响程序的执行。去除前后进行 diff 对比可看到删除的 section 主要有下面这些: $ diff 0 11c1 There are 35 section headers, starting at offset 0x1fdc:--- There are 28 section headers, starting at offset 0x1144:32,39c32 [27] .debug_aranges PROGBITS 00000000 00104d 000020 00 0 0 1 [28] .debug_info PROGBITS 00000000 00106d 000350 00 0 0 1 [29] .debug_abbrev PROGBITS 00000000 0013bd 000100 00 0 0 1 [30] .debug_line PROGBITS 00000000 0014bd 0000cd 00 0 0 1 [31] .debug_str PROGBITS 00000000 00158a 000293 01 MS 0 0 1 [32] .symtab SYMTAB 00000000 001820 000480 10 33 49 4 [33] .strtab STRTAB 00000000 001ca0 0001f4 00 0 0 1 [34] .shstrtab STRTAB 00000000 001e94 000145 00 0 0 1--- [27] .shstrtab STRTAB 00000000 00104d 0000f5 00 0 0 1 其中 .symtab 是符号表，.strtab 是符号表中用到的字符串。 仅仅去掉符号感觉还不够，熟悉汇编的人放到反编译工具中还是可以慢慢还原程序逻辑。通过前面的分析知道，ELF 执行需要的只是 Program Header 中的几个段，Section Header 实际上是不需要的，只不过在运行时动态链接过程会引用到部分关联的区域。大部分反编译工具，如 IDA、Ghidra 等，处理 ELF 是需要某些 section 信息来构建程序视图的，所以可以通过构造一个损坏 Section Table 或者 ELF Header 令这些反编译工具出错，从而干扰逆向人员。 当然，这个方法并不总是奏效，逆向人员可以通过动态调试把程序 dump 出来并对运行视图进行还原。一个典型的例子是 Android 中的 JNI 动态库，有的安全人员对这些 so 文件进行了加密处理，并且在.init.initarray 这些动态库初始化函数中进行动态解密。破解这种加固方法的策略就是将其从内存中复制出来并进行重建，重建的过程可根据 segment 对 section 进行还原，因为 segment 和 section 之间共享了许多内存空间，例如: $ readelf -l main1... Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .plt.got .text .fini .rodata .eh_frame_hdr .eh_frame 03 .init_array .fini_array .dynamic .got .got.plt .data .bss 04 .dynamic 05 .note.ABI-tag .note.gnu.build-id 06 .eh_frame_hdr 07 08 .init_array .fini_array .dynamic .got 在 Section to Segment mapping 中可以看到这些段的内容是跟对应 section 的内容重叠的，一个 segment 可以包含多个 section，但是依然可以根据内存的读写属性、内存特征以及对应段的一般顺序进行区分。 如果程序中有比较详细的日志函数，还可以通过反编译工具的脚本拓展去修改.symtab.strtab 段来批量还原 ELF 文件的符号，从而高效地辅助动态调试。 Binary Fuzzing考虑这么一种场景，在分析某个 IoT 设备时发现了一个定制的 ELF 网络程序，类似于 httpd，其中有个静态函数负责处理输入数据。现在想要单独对这个函数进行 fuzz 应该怎么做？直接从网络请求中进行变异是一种方法，但是网络请求的效率太低，而且触达该函数的程序逻辑也可能太长。 既然已经了解了 ELF，那就可以有更好的办法将该函数抽取出来进行独立调用。在介绍 ELF 类型的时候其实有提到，可执行文件可以有两种类型，即可执行类型(ET_EXEC)和共享对象(ET_DYN)，一个动态链接的可执行程序默认是共享对象类型的: $ gcc hello.c -o hello$ readelf -h hello | grep Type Type: DYN (Shared object file) 而动态库(.so)本身也是共享对象类型，他们之间的本质区别在于前者链接了 libc 并且定义了 main 函数。对于动态库，可以通过 dlopendlsym 获取对应的符号进行调用，因此对于上面的场景，一个解决方式就是修改目标 ELF 文件，并且将对应的静态函数导出添加到 dynamic section 中，并修复对应的 ELF 头。 这个思想其实很早就已经有人实现了，比如 lief 的 bin2lib。通过该方法，就能将目标程序任意的函数抽取出来执行，比如 hugsy 就用这个方式复现了 Exim 中的溢出漏洞(CVE-2018-6789)。","categories":["1.平台","Linux","程序"]},{"title":"进程脱离终端后台运行","path":"/2024/07/10/1-平台-Linux-系统参数-进程脱离终端后台运行/","content":"运行一个连接到控制终端的进程，作为用户将会在的终端上看到这个进程数据的许多行的输出，也包含错误信息。同样，当关闭一个控制终端，的进程和子进程都将会终止。为了解决上面两个问题，需要从一个控制终端完全脱离一个进程。 如何在后台运行一个进程如果一个进程已经运行，按下 Ctrl+Z 就可以暂停它，然后输入命令 bg 就可以继续以一个任务在后台运行了。但是，标准输入（STDIN）、标准输出（STDOUT）和标准错误（STDERR）依旧掺杂到控制台中。可以通过输入 jobs 查看所有的后台任务。 $ tar -czf home.tar.gz .$ bg$ jobs 也可以直接使用符号 在后台运行一个进程： $ tar-czf home.tar.gz . $ jobs 虽然是作为一个后台任务开始的，但是错误信息依旧发送到终端，这表示，进程依旧和控制终端关联在一起。 disown们将使用 disown 命令，它在一个进程已经运行并且被放在后台之后使用，它的作用是从 shell 的活动任务列表中移走一个 shell 任务，因此，对于该任务，将再也不能使用 fg 、 bg 命令了。而且，当关闭控制控制终端，这个任务将不会挂起（暂停）或者向任何一个子任务发送 SIGHUP 信号。 $ sudo rsync Templates/* /var/www/html/files/ $ jobs$ disown -h %1$ jobs nohup也可以使用 nohup 命令，这个命令也可以在用户退出 shell 之后保证进程在后台继续运行。 $ nohup tar -czf iso.tar.gz Templates/* $ jobs devnull对于图形用户界面 (GUI) 的程序例如 firefox 来说，使用下面的命令行格式会更有效： $ firefox /dev/null 在 Linux 上，devnull 是一个特殊的文件设备，它会忽略所有的写在它上面的数据，上述命令，输入来源和输出发送目标都是 devnull。","categories":["1.平台","Linux","系统参数"]},{"title":"重装系统无法识别硬盘","path":"/2024/07/08/1-平台-Windows-重装系统无法识别硬盘/","content":"Win11 重新安装系统时，由于缺少 RST 驱动，导致进入 PE 后无法识别到硬盘，需要安装该驱动，搜索 intel_rst_technology 并下载， https://global-download.acer.com/GDFiles/Driver/IRST/IRST_Intel_19.2.0.1003_W11x64_A.zip?acerid=637907037961464459Step1=Step2=Step3=SF314-71OS=ALLLC=enBC=ACERSC=PA_6 之后在重装系统时选择 load driver 加载该驱动即可识别硬盘","categories":["1.平台","Windows"]},{"title":"RK3568系统移植分析","path":"/2024/07/05/1-平台-嵌入式-RK3568系统移植分析/","content":"写入硬件时间 hwclock-uw在现代嵌入式系统中，处理时间和日期的正确性至关重要。这一功能通常通过硬件时钟来实现，尤其是在如 hwclock-uw 这样的小型工具中。hwclock-uw 的主要功能是读取或设置硬件时钟的时间，从而确保系统时间的准确无误。 3568 的内核配置文件路径该系统使用多种配置文件来管理构建与设备的设置。主要的配置文件路径如下： 编译配置文件：device/rockchip/common/build.sh板级配置文件：device/rockchip/ok3568/BoardConfig-ok3568.mkbuildroot 配置文件：buildroot/configs/OK3568_defconfiguboot 配置文件：u-boot/configs/OK3568-C_defconfig 编译配置文件配置文件 device/rockchip/common/build.sh 是整个编译过程的核心，定义了编译所需的环境变量和选项。例如，这个脚本可能包含对编译工具链的设置、库文件路径的定义以及其他必要的参数，使得编译过程顺利进行。此外，BoardConfig-ok3568.mk 文件中会涉及到特定于板子的配置，包括设备 ID、内存配置和外设的启用状态。 文件系统映射位置在开发过程中，了解文件系统的结构至关重要。以下图片展示了具体的文件系统映射位置，便于开发者快速定位所需文件： 在日常开发中，合理利用这些配置文件和文件系统映射可以大大提高工作的效率，确保系统能够正常运行和进行各种操作。","categories":["1.平台","嵌入式"]},{"title":"随手记","path":"/2024/07/04/1-平台-嵌入式-随手记/","content":"MIPI 接口的含义 MIPI 中的 DSI 和 CSI 显示 DSI = display 摄像头 CSI = camera 设备树中的标识符 设备树中的 引用节点 @ 指定设备地址 串口设备树配置 串口的硬流控和软流控 linux 查看版本 lsb_release -a gpu 信息及使用率查看 clinfo 查看 gpu 信息 查看 gpu 使用率 cat sysdevicesffa30000.gpudvfs 修改 IPvi /etc/network/interfaces.d/eno0 修改网关vi /etc/resolv.conf","categories":["1.平台","嵌入式"]},{"title":"实时OS和分时OS","path":"/2024/07/03/1-平台-嵌入式-RealTime-实时OS和分时OS/","content":"实时操作系统（RTOS）RTOS，英文全称 Real Time Operating System，即实时操作系统。 实时操作系统定义实时操作系统（RTOS）是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统作出快速响应，并控制所有实时任务协调一致运行的操作系统。 因而，提供及时响应和高可靠性是其主要特点。 实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的。 软实时则只要按照任务的优先级，尽可能快地完成操作即可。们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。 实时操作系统是保证在一定时间限制内完成特定功能的操作系统。例如，可以为确保生产线上的机器人能获取某个物体而设计一个操作系统。在”硬”实时操作系统中，如果不能在允许时间内完成使物体可达的计算，操作系统将因错误结束。 在”软”实时操作系统中，生产线仍然能继续工作，但产品的输出会因产品不能在允许时间内到达而减慢，这使机器人有短暂的不生产现象。一些实时操作系统是为特定的应用设计的，另一些是通用的。 一些通用目的的操作系统称自己为实时操作系统。但某种程度上，大部分通用目的的操作系统，如微软的 Windows NT 或 IBM 的 OS390 有实时系统的特征。这就是说，即使一个操作系统不是严格的实时系统，它们也能解决一部分实时应用问题。 实时操作系统的特征 多任务 有线程优先级 多种中断级别 小的嵌入式操作系统经常需要实时操作系统，内核要满足实时操作系统的要求。 实时操作系统的相关概念基本概念 代码临界段：指处理时不可分割的代码。一旦这部分代码开始执行则不允许中断打入； 资源：任何为任务所占用的实体； 共享资源：可以被一个以上任务使用的资源； 任务：也称作一个线程，是一个简单的程序。每个任务被赋予一定的优先级，有它自己的一套 CPU 寄存器和自己的栈空间。典型地，每个任务都是一个无限的循环，每个任务都处在以下五个状态下：休眠态，就绪态，运行态，挂起态，被中断态； 任务切换：将正在运行任务的当前状态（CPU 寄存器中的全部内容）保存在任务自己的栈区，然后把下一个将要运行的任务的当前状态从该任务的栈中重新装入 CPU 的寄存器，并开始下一个任务的运行； 内核：负责管理各个任务，为每个任务分配 CPU 时间，并负责任务之间通讯。分为不可剥夺型内核于可剥夺型内核； 调度：内核的主要职责之一，决定轮到哪个任务运行。一般基于优先级调度法； 关于优先级的问题任务优先级：分为优先级不可改变的静态优先级和优先级可改变的动态优先级； 优先级反转：优先级反转问题是实时系统中出现最多的问题。共享资源的分配可导致优先级低的任务先运行，优先级高的任务后运行。解决的办法是使用”优先级继承”算法来临时改变任务优先级，以遏制优先级反转。 互斥虽然共享数据区简化了任务之间的信息交换，但是必须保证每个任务在处理共享共享数据时的排他性。使之满足互斥条件的一般方法有：关中断，使用测试并置位指令（TAS），禁止做任务切换，利用信号量。 因为采用实时操作系统的意义就在于能够及时处理各种突发的事件，即处理各种中断，因而衡量嵌入式实时操作系统的最主要、最具有代表性的性能指标参数无疑应该是中断响应时间了。中断响应时间通常被定义为： 中断响应时间中断延迟时间+保存 CPU 状态的时间+该内核的 ISR 进入函数的执行时间。 中断延迟时间MAX(关中断的最长时间，最长指令时间) + 开始执行 ISR 的第一条指令的时间。 分时操作系统（TSOS）TSOS，英文全称 Time-sharing Operating System，即分时操作系统。 使一台计算机同时为几个、几十个甚至几百个用户服务的一种操作系统叫分时操作系统。把计算机与许多终端用户连接起来，分时操作系统将系统处理机时间与内存空间按一定的时间间隔，轮流地切换给各终端用户的程序使用。 由于时间间隔很短，每个用户的感觉就像他独占计算机一样。分时操作系统的特点是可有效增加资源的使用率。例如 UNIX 系统就采用剥夺式动态优先的 CPU 调度，有力地支持分时操作。 产生分时系统是为了满足用户需求所形成的一种新型 OS 。它与多道批处理系统之间，有着截然不同的性能差别。用户的需求具体表现在以下几个方面: 人—机交互 共享主机 便于用户上机 分时系统的基本思想时间片：是把计算机的系统资源（尤其是 CPU 时间）进行时间上的分割，每个时间段称为一个时间片，每个用户依次轮流使用时间片。 分时技术：把处理机的运行时间分为很短的时间片，按时间片轮流把处理机分给各联机作业使用。 分时操作系统：是一种联机的多用户交互式的操作系统。一般采用时间片轮转的方式使一台计算机为多个终端服务。对每个用户能保证足够快的响应时间，并提供交互会话能力。 设计目标：对用户的请求及时响应，并在可能条件下尽量提高系统资源的利用率。 适合办公自动化、教学及事务处理等要求人机会话的场合。 工作方式一台主机连接了若干个终端；每个终端有一个用户在使用；交互式地向系统提出命令请求；系统接受每个用户的命令；采用时间片轮转方式处理服务请求；并通过交互方式在终端上向用户显示结果；用户根据上步结果发出下道命令 分时系统实现中的关键问题：及时接收。及时处理。 特征 交互性：用户与系统进行人机对话。 多路性：多用户同时在各自终端上使用同一 CPU。 独立性：用户可彼此独立操作，互不干扰，互不混淆。 及时性：用户在短时间内可得到系统的及时回答。 影响响应时间的因素：终端数目多少、时间片的大小、信息交换量、信息交换速度。 区别RTOS 和 TSOS 各有各的特点，RTOS 一般用于相对低速的 MCU，比如运动控制类、按键输入等动作要求实时处理的系统，一般要求 ms 级，甚至 us 级响应。 分时：现在流行的 PC，服务器都是采用这种运行模式，即把 CPU 的运行分成若干时间片分别处理不同的运算请求。 实时：一般用于单片机上，比如电梯的上下控制中，对于按键等动作要求进行实时处理。","categories":["1.平台","嵌入式","RealTime"]},{"title":"文件系统","path":"/2024/07/02/1-平台-平台相关-文件系统/","content":"文件系统存储限制FAT32 文件系统对单个文件的大小有限制。具体来说，FAT32 文件系统支持的最大文件大小是 4 GB (gigabytes)。这是因为 FAT32 使用 32 位字段来记录文件大小，而 32 位的最大值是 4,294,967,295 字节，约等于 4 GB。 如果需要存储超过 4 GB 的单个文件，可以考虑使用其他文件系统，例如： exFAT：支持非常大的文件，适用于大容量存储设备，例如 USB 闪存驱动器和 SD 卡。 NTFS：Windows 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 ext4：Linux 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 文件系统选择建议 USB 闪存驱动器SD 卡：如果需要兼容性且文件大于 4 GB，建议使用 exFAT。 Windows 系统硬盘：NTFS 是默认且最适合的选择。 Linux 系统硬盘：ext4 是默认且最适合的选择。 转换文件系统的步骤如果需要将 FAT32 文件系统转换为 exFAT 或 NTFS，可以通过以下步骤实现： 将 FAT32 转换为 exFAT（在 Windows 中） 备份数据：转换文件系统会格式化驱动器，因此请先备份所有数据。 格式化为 exFAT： 打开”文件资源管理器”。 右键点击需要转换的驱动器。 选择”格式化”。 在文件系统选项中选择”exFAT”。 点击”开始”。 将 FAT32 转换为 NTFS（在 Windows 中） 备份数据：虽然有非破坏性转换方法，但仍建议备份数据以防万一。 非破坏性转换（不会丢失数据）：convert X: fs:ntfs。其中 X: 是要转换的驱动器号。","categories":["1.平台","平台相关"]},{"title":"计算机概念","path":"/2024/07/01/1-平台-平台相关-计算机概念/","content":"冯·诺依曼结构计算机的原理所有的计算机语言，不管是 Java, Python, Go, C, C++, PHP…… ， 最终都要变成基本的二进制指令，在冯·诺依曼结构计算机上按规矩执行。 了解 CPU 和内存是怎么工作的： CPU 从内存取出指令，进行译码和执行，执行时从内存中取出数据放到寄存器中， 进行计算， 然后把结果写回到内存。如果是跳转指令， CPU 则取出跳转目的地的指令继续执行。基本的指令组成了顺序、循环、分支等基本的程序结构，形成了更为强大的编程语言的基础。 CPU 和内存、硬盘等设备的速度不匹配，是冯·诺依曼结构计算机的一个核心问题，为了解决这个问题，科学家们绞尽脑汁，想尽了办法， 又引出了一堆概念： 缓存，DMA， 同步，异步，阻塞…. 进程和线程所有的程序要么会成为一个独立的进程去执行，要么是进程中的一个线程 。几乎所有的编程语言都会涉及到对多进程或者多线程编程的支持， 特别是多线程的并发编程。 进程是对一个运行中的程序的抽象，没有这个概念。对于 CPU 来讲， 只是从某个地方取指令，译码执行，它不会意识到执行的程序已经发生了切换，另外一个程序（准确地讲叫进程）已经成功地抢班夺权。 每个进程都有一个被操作系统维护的进程控制块， 里边保存了这个进程在运行时的重要信息，是进程能来回切换的重要保证。而线程则寄居于进程之内 ， 共享进程提供福利（代码和数据）的同时， 还拥有自己的一亩三分地。 线程的出现，提升了系统的性能、吞吐量和响应性。 但是多进程多线程编程也带来了一系列问题： 同步，通信，锁， 死锁。。。 虚拟内存虚拟内存的重要作用就是给各进程提供一个由虚拟地址组成的独立区域，每个进程在自己的独立区域里执行，互不影响。指令必须在物理内存中才能被执行， 操作系统把每个进程的虚拟地址映射到实际地址上去，其中实现分段，分页，页表，动用 CPU 的 TLB 来加速。 程序并不是一下子全部装载到内存的， 而是用到的时候才进行装载。 网络的核心概念核心概念是： 分组交换， TCPIP 参考模型， socket , http(s)。 网络数据是被切分成适合网络传输的小块，给每个小块编上号， 每个小块都独立地走相同甚至不同的网络路径， 到达这里，重新排序，组合，然后才展示给， 这就是分组交换。使用分组交换可以充分的利用网络带宽： 在不使用的间隙，别人也可以利用。 但是一个很明显的问题就是分组数据丢失了怎么办？ 如何检测， 怎么重发，如何缓存已经收到分组数据等一系列烦人的问题接踵而来。 这就是 TCP 要干的事情。如果能体会到 TCP 是在端系统实现的，中间节点一无所知，想就 Get 到了分组交换和分层的真谛。 TCPIP 参考模型定义了 5 层： 应用层，传输层，网络层，链路层，物理层。一定得理解所谓的分层只不过是把的数据层层包装而已，在传输的过程层中每到一个节点都会拆开某一层的包装，查看一下数据， 然后再次包装，转发出去，直到终点。 Hash 和 RSA如果说 Https 是网络安全通信的一大基石， 那 Hash 和 RSA 则是基石的基石。 RSA 有一对钥匙， 一个是私有的、保密的， 另外一个是公有的。RSA 的概念很简单， 但是为了实现真正的安全消息传输，作为第一步必须得有数据签名做保证，需要理解如何对消息用 Hash 形成摘要，然后用私钥签名，又是如何验证这个签名的。","categories":["1.平台","平台相关"]},{"title":"0个部署服务器的功能","path":"/2024/06/28/1-平台-服务器-0个部署服务器的功能/","content":"完成对 Alist 的启动与关闭 完成对 photoprism 的启动与关闭 完成 frp 的穿透 完成 devtunnel 的穿透 完成更新 devtunnel 并获取最新的 IP 地址导入 photo.html 完成仓库的更新 【√】80 端口：TVBOX 订阅 9050：本地Hexo 博客部署端口 博客Hexo部署 【√】9080：FRP 映射对接端口 内网穿透方案 【√】9081：FRP 的 DashBoard内网穿透方案 【√】9082: Docker 管理面板 Portainer 【√】9083 Qexo 管理页面 Qexo本地部署 【√】9084：Alist 映射端口 Alist网盘搭建 【√】9085：PDF 处理工具搭建到云服务器 【√】9086：Daily Hot 每日热点9071API 【√】9090：SSH 端口 【√】9091：3D 打印机的 Mainsail 端口 3D打印机环境配置 9092：OK3568portainer 9093： PhotoprismPhotoprism照片备份方案 9094：Photoprism_ 的 9082：NAS 映射端口 NAS相关配置 9090：1Panel 服务器运维管理面板 9091: GitServer markdown 软件和 wordpress 联动 wordpress 部署在云服务器，利用 docker 部署 云服务器部署 git 云服务器部署数据仓库 云服务器部署 3D 打印机服务 云服务器部署微信公众号对接，chatgpt 对话 云服务器部署微信聊天，对话转发 写一个 python 脚本来爬取","categories":["1.平台","服务器"]},{"title":"DailyHot部署","path":"/2024/06/27/1-平台-服务器-工具-DailyHot部署/","content":"前端项目地址 https://github.com/imsyy/DailyHot API 项目地址 https://github.com/imsyy/DailyHotApi API 部署clone 项目后进入项目目录执行 docker-compose.yml 文件 docker compose up -d#如果卡在npm install -g pnpm则通过docker run 命令行启动docker run -p 6688:6688 -d imsyy/dailyhot-api:latest 项目启动，访问 http://localhost:6688 前端部署clone 项目后进入目录执行 npm install 修改.env 文件中的 API 地址为自己部署的 API 地址 修改 vite.config.js 中的 port 为自己想使用的端口 运行 npm run dev -- --host 打包 npm run build 打包之后生成的页面在当前目录下的 dist 文件夹中，拷贝到varwww 目录下，在 nginx 中增加配置 server listen 9086 default_server; listen [::]:9086 default_server; root /var/www/dist; server_name _; location / index index.html; 之后重启 nginx 服务 sudo systemctl restart nginx.service 访问 IP:9086 即可访问","categories":["1.平台","服务器","工具"]},{"title":"Photoprism照片备份方案","path":"/2024/06/26/1-平台-服务器-工具-Photoprism照片备份方案/","content":"PhotoPrism 配置官方脚本选择下载官方脚本 #Linux wget https://dl.photoprism.app/docker/docker-compose.yml#Windowscurl.exe -o docker-compose.yml https://dl.photoprism.app/docker/windows/docker-compose.yml 自定义进行自定义选项，默认需要依赖数据库 可以选择不依赖数据库镜像 自定义访问端口 自定义相册文件映射地址，其中photoprismimport 为需要导入的照片地址，photoprismoriginals 为已经导入的照片地址 services: photoprism: image: photoprism/photoprism:latest restart: unless-stopped stop_grace_period: 10s security_opt: - seccomp:unconfined - apparmor:unconfined ports: - 5246:2342 environment: PHOTOPRISM_ADMIN_USER: username # admin login username PHOTOPRISM_ADMIN_PASSWORD: password # initial admin password (8-72 characters) PHOTOPRISM_AUTH_MODE: password # authentication mode (public, password) PHOTOPRISM_SITE_URL: http://localhost:2342/ # server URL in the format http(s)://domain.name(:port)/(path) PHOTOPRISM_DISABLE_TLS: false # disables HTTPS/TLS even if the site URL starts with https:// and a certificate is available PHOTOPRISM_DEFAULT_TLS: true # defaults to a self-signed HTTPS/TLS certificate if no other certificate is available PHOTOPRISM_ORIGINALS_LIMIT: 5000 # file size limit for originals in MB (increase for high-res video) PHOTOPRISM_HTTP_COMPRESSION: gzip # improves transfer speed and bandwidth utilization (none or gzip) PHOTOPRISM_DEBUG: false # run in debug mode, shows additional log messages PHOTOPRISM_READONLY: false # do not modify originals folder; disables import, upload, and delete PHOTOPRISM_EXPERIMENTAL: false # enables experimental features PHOTOPRISM_DISABLE_CHOWN: false # disables updating storage permissions via chmod and chown on startup PHOTOPRISM_DISABLE_WEBDAV: false # disables built-in WebDAV server PHOTOPRISM_DISABLE_SETTINGS: false # disables settings UI and API PHOTOPRISM_DISABLE_TENSORFLOW: false # disables all features depending on TensorFlow PHOTOPRISM_DISABLE_FACES: false # disables face detection and recognition (requires TensorFlow) PHOTOPRISM_DISABLE_CLASSIFICATION: false # disables image classification (requires TensorFlow) PHOTOPRISM_DISABLE_VECTORS: false # disables vector graphics support PHOTOPRISM_DISABLE_RAW: false # disables indexing and conversion of RAW images PHOTOPRISM_RAW_PRESETS: false # enables applying user presets when converting RAW images (reduces performance) PHOTOPRISM_SIDECAR_YAML: true # creates YAML sidecar files to back up picture metadata PHOTOPRISM_BACKUP_ALBUMS: true # creates YAML files to back up album metadata PHOTOPRISM_BACKUP_DATABASE: true # creates regular backups based on the configured schedule PHOTOPRISM_BACKUP_SCHEDULE: daily # backup SCHEDULE in cron format (e.g. 0 12 * * * for daily at noon) or at a random time (daily, weekly) PHOTOPRISM_INDEX_SCHEDULE: # indexing SCHEDULE in cron format (e.g. @every 3h for every 3 hours; to disable) PHOTOPRISM_AUTO_INDEX: 300 # delay before automatically indexing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_AUTO_IMPORT: -1 # delay before automatically importing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_DETECT_NSFW: false # automatically flags photos as private that MAY be offensive (requires TensorFlow) PHOTOPRISM_UPLOAD_NSFW: true # allows uploads that MAY be offensive (no effect without TensorFlow) PHOTOPRISM_SITE_CAPTION: AI-Powered Photos App PHOTOPRISM_SITE_DESCRIPTION: # meta site description PHOTOPRISM_SITE_AUTHOR: # meta site author ## Video Transcoding (https://docs.photoprism.app/getting-started/advanced/transcoding/): # PHOTOPRISM_FFMPEG_ENCODER: software # H.264/AVC encoder (software, intel, nvidia, apple, raspberry, or vaapi) # PHOTOPRISM_FFMPEG_SIZE: 1920 # video size limit in pixels (720-7680) (default: 3840) # PHOTOPRISM_FFMPEG_BITRATE: 32 # video bitrate limit in Mbit/s (default: 50) working_dir: /photoprism # do not change or remove ## Storage Folders: use / not \\ as separator, ~ is a shortcut for C:/user/username, . for the current directory volumes: # C:/user/username/folder:/photoprism/folder # example # - ~/Pictures:/photoprism/originals # original media files (photos and videos) # - D:/example/family:/photoprism/originals/family # *additional* media folders can be mounted like this # - E:/:/photoprism/import # *optional* base folder from which files can be imported to originals - E:/01.照片/:/photoprism/import - ./original/:/photoprism/originals - ./videos:/photoprism/originals/videos - ./storage:/photoprism/storage # *writable* storage folder for cache, database, and sidecar files (never remove)## Create named volumes, advanced users may remove this if they mount a regular host folder## for the database or use SQLite instead (never remove otherwise)volumes: database: driver: local PhotoPrismPhotoPrism 是一款强大的工具，可以帮助高效管理个人相册和视频资料。无论是摄影爱好者还是家庭用户，这款软件都能让的照片与视频整理得井井有条，便于查找和分享。 服务器资源要运行自己的 PhotoPrism，需要为其准备服务器资源。可以考虑以下几种选择： 云服务资源：比如阿里云、亚马逊 AWS 等提供的虚拟服务器，适合需要随时访问的用户。 家庭私有服务器：如果希望在家中搭建一个专属的媒体管理系统，使用 Raspberry Pi 或 NAS 设备都是不错的选择。 自己的电脑或笔记本：可以利用现有的设备进行部署，尤其是在个人使用的场景下非常方便。 安装 PhotoPrism准备一个服务资源之后，就可以开始安装 PhotoPrism。正如前面提到的，可以选择云服务、家庭服务器，或者直接在的电脑上进行安装。 适用的操作系统非常广泛，包括： Windows macOS Linux 最低资源需求要确保 PhotoPrism 顺利运行，最低配置要求为： CPU：2 核心 内存：3 GB 准备 Docker 环境PhotoPrism 是基于 Go 语言开发的工具。虽然可以按照传统方式在本地安装 Go 来运行，但强烈建议使用 Docker 来进行部署。Docker 具备以下优势： 简单：部署过程直观，无需深入的系统配置。 方便：可以快速更新和回滚到不同的版本。 易于迁移：使用 Docker 可以轻松将服务迁移到另一台服务器上。 在本文中，将重点介绍基于 Docker 的安装方式。如果希望使用原生 Go，可以访问 PhotoPrism 的官方网站获取更多信息。 Docker 环境的选择虽然在 Linux 上安装 Docker 可能比较容易，但对于 Windows 和 macOS，可以考虑以下选项： macOS：使用 OrbStack（商业软件，个人用户免费）或 Lima（开源软件）来进行环境设置。 Windows：建议使用 WSL（Windows Subsystem for Linux）来搭建 Linux 环境，这样可以避免直接使用 Docker Desktop 带来的不良体验。 注意：Docker Desktop 在 Windows 下的性能不理想，并且镜像的体积比较庞大，尽量选择其他方案。 此外，请确保安装好 Docker Compose 工具，将在下面的步骤中使用 Docker Compose 来简化部署。Docker Compose 的配置文件以 YAML 格式编写，便于查看与修改配置信息。Docker命令 确定的数据库PhotoPrism 支持几种不同的数据库，主要包括 SQLite 3 和 MariaDB 10.5.12 以上版本。需要根据的使用需求选择合适的数据库： SQLite：适合初学者或小型项目，是一种轻量级的嵌入式数据库，非常易于上手和使用。 MariaDB：更适合需要较高性能和稳定性的场景，如果计划长期使用 PhotoPrism，建议选择 MariaDB。 需要注意的是，MySQL 的新版本由于缺少某些特性而不再被 PhotoPrism 所支持。 Docker Compose 配置创建一个空目录首先，在选择的位置创建一个空目录，例如命名为 photo。这个目录将用于存储所有的配置文件和数据。可以使用命令行工具或图形化界面来完成这个步骤。 在这个新创建的目录下，需要再创建三个子目录，分别为： import：用于存放需要导入的图像。 originals：用于保存原始图像文件。 storage：用于存储 PhotoPrism 处理后的文件。 最终的目录结构将如下所示： photo├── docker-compose.yml├── import├── originals└── storage 这三个子目录的具体用处将在后面的内容中详细解释。 编辑 docker-compose.yml最后一步是编辑 docker-compose.yml 文件。在这个文件中，需要定义 PhotoPrism 所需的服务及其配置，确保在部署时一切顺利进行。以下是一个基于 PhotoPrism 的 docker-compose 示例文件： version: 3.5services: photoprism: image: photoprism/photoprism:latest container_name: photoprism stop_grace_period: 10s restart: always security_opt: - seccomp:unconfined - apparmor:unconfined ports: - 2342:2342 environment: PHOTOPRISM_ADMIN_USER: admin # 用户名 PHOTOPRISM_ADMIN_PASSWORD: admin1234 # 用户密码(不少于8位) PHOTOPRISM_AUTH_MODE: password # 授权模式, public 或 password # 数据库配置, 这里配置了sql PHOTOPRISM_DATABASE_DRIVER: sqlite # 使用内置的SQLite数据库 # 正式使用,建议使用mariadb数据库 #PHOTOPRISM_DATABASE_DRIVER: mysql # 使用MariaDB 10.5 以上的数据库 #PHOTOPRISM_DATABASE_SERVER: 192.168.50.16:3306 # MariaDB数据库地址 (hostname:port) #PHOTOPRISM_DATABASE_NAME: photoprism # MariaDB数据库名称 #PHOTOPRISM_DATABASE_USER: photoprism # MariaDB用户名 #PHOTOPRISM_DATABASE_PASSWORD: photoprism # MariaDB密码 # 网站标题 PHOTOPRISM_SITE_CAPTION: 的相册 working_dir: /photoprism # 不要改动这一项 volumes: - ./originals:/photoprism/originals # 原始照片目录 - ./import/Z:/photoprism/import # 待导入照片目录 - ./storage:/photoprism/storage # photoprism程序产生的各种缓存,文件,索引等目录 如果曾经使用过 docker-compose，那么上述内容应该能很快理解。 环境变量设置主要有几个关键的环境变量需要设置： PHOTOPRISM_ADMIN_USER、PHOTOPRISM_ADMIN_PASSWORD、PHOTOPRISM_AUTH_MODE：这三项用于设置基本的登录方式以及初始用户名和密码。可以在首次登录后，通过系统界面修改密码以增强安全性。 PHOTOPRISM_DATABASE_DRIVER：用于指定数据库类型，可以选择 sqlite 或 mysql。在当前的配置中，使用的是 sqlite。如果选择使用 mysql，请确保取消与 MariaDB 相关的参数开头的 # 注释符号，并将 PHOTOPRISM_DATABASE_DRIVER 的值改为 mysql。请注意，Photoprism 不再支持 mysql。 PHOTOPRISM_SITE_CAPTION：这是一个自定义选项，用于设定网站的标题。这可以让更加个性化地展示的摄影作品。 目录结构Photoprism 需要使用以下三个目录来管理照片： originals：这是原始照片的目录，可以将已有的照片放入此目录。所有上传到 Photoprism 的照片最终都会存放在这里。 import：新照片的导入目录，任何放在此目录中的照片都会等待被 Photoprism 处理。这一过程包括照片分析和索引，Photoprism 会将处理后的照片存入 originals 目录。 storage：这个目录用于保存 Photoprism 生成的各种文件，比如索引、照片缩略图和缓存。这些文件有助于提高系统的性能和用户体验。 启动服务要启动服务，请进入 Photoprism 的目录，并运行以下命令： docker-compose up -d 在第一次启动时，由于需要下载镜像，这可能会花费一些时间。一旦完成启动且没有问题，就可以访问 Photoprism 了。 访问 http://127.0.0.1:2342，如果一切正常，将看到登录页面。 登录页面使用在配置中设置的用户名和密码登录。初次登录后，可能会发现系统内没有任何照片，这是因为还没有导入任何照片。 第一次导入及索引使用 Docker 安装 Photoprism 实际上非常简单，这也是推荐在大多数情况下使用 Docker 的原因之一，因为这样无需担心各类环境和依赖问题。 此时，面临的需求主要有两个： 将已有的历史照片导入 Photoprism。 将来如何同步新的照片。 导入旧照片为了导入已有的照片并完成索引，需要了解以下的概念。索引是指 Photoprism 通过提取照片的元数据，比如照片的拍摄地点、大小和拍摄时间，来组织和管理照片。同时，Photoprism 会为每张照片生成各种尺寸的缩略图，这些缩略图在用户界面中显示，而非原始照片。 放入目录选择：可以将旧有的照片放置在 import 目录或 originals 目录中，但二者的处理方式不同。 originals 目录originals 是用于存放照片原文件的地方。所有 Photoprism 管理的照片原文件都将存放在此目录下。可以选择将旧相片直接放在这个目录中，但由于 Photoprism 不会自动对这些相片建立索引，需要在用户界面上启动全量索引操作。 全量索引进入数据库，点击索引页，然后可以执行一次完全重新扫描，以便 Photoprism 能够对现有的照片进行索引。 import 目录也可以选择将现有照片放入 import 目录。随后在数据库的导入页面中，选择该目录，导入的照片。 区别与建议可能会产生疑问，既然可以随意放置在这两个目录中，为什么要进行选择？其实二者之间存在重要的区别： 共同点：无论是 import 还是 originals 目录，Photoprism 都会对照片进行索引，提取元数据并生成缩略图。 不同点： 放在 import 目录的照片会按照拍摄日期重新命名，并随后存入 originals 目录。 import 目录类似于一个临时处理区，而 originals 则是存放原始照片的主要目录。 建议因此，决定将已有照片放入 import 还是 originals 的关键在于是否希望 Photoprism 重新命名的照片。如果的照片已经以有序的方式存放，建议将其放入 originals。相反，如果希望程序按照日期重新整理的照片，放入 import 目录会是一个更好的选择。 需要注意的是，索引是一项耗时的操作。以为例，当时有约 7000 张照片，索引过程花费了几个小时。 重新整理后的效果经过 Photoprism 的处理，所有照片被按照年份和月份分类整理，目录结构如下： 2000└── 01 ├── 20000101_090020_04FF387A.jpg ├── 20000101_090026_E7546984.jpg ├── 20000101_090027_4B306DB8.jpg ├── 20000101_090050_63B2D167.jpg ├── 20000101_090100_D17AE19A.jpg ├── 20000101_090111_D8648B18.jpg ├── 20000101_090131_FDA5E957.jpg ├── 20000101_090146_245BDD02.jpg ├── 20000101_090200_07FE3819.jpg ├── 20000101_090224_F0190680.jpg ├── 20000101_090341_3F2E89A5.jpg └── 20000101_090712_7D9EAF39.jpg 如上，这代表 2000 年 01 月份的照片，每张照片都以拍摄日期和一个随机代码命名。这种整理使得在迁移照片时，原本杂乱无章的照片变得井然有序，按日期存储的结构让管理变得轻松。 如何在各种设备上浏览这个服务?Photoprism 对浏览器的支持非常好，用户可以轻松地在不同的设备上通过浏览器访问该服务，无论使用的是个人电脑、平板还是智能手机。其响应式设计保证了在不同尺寸的屏幕上都能提供良好的用户体验。例如，使用 iPhone 或 Android 手机上访问 Photoprism，界面会自动调整，以适应屏幕尺寸。 Nginx 配置 Nginx配置如果选择在家里的服务器上部署 Photoprism，可以参考以下步骤来进行配置，从而将服务映射到外网进行访问: Nginx 配置: 为 Photoprism 配置 Nginx，以确保流量能正确转发。例如，可以在 Nginx 的配置文件中添加以下内容: server listen 80; server_name your_domain.com; # 的域名或IP地址 location / proxy_pass http://localhost:2342; # Photoprism 默认端口 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; 如何映射外网访问?内网穿透方案通过结合 Tailscale 和便宜的阿里云服务器，可以轻松地映射外网访问的家庭服务器。这种组合提供安全的远程连接，且配置过程相对简洁。首先，在家中的服务器上安装 Tailscale，接着，在阿里云服务器上注册并设置 Tailscale 账户。通过 Tailscale 生成的私有网络，就能从任何外部设备安全访问的家庭服务器。 如何同步设备上的相片?使用 Filestash 和 WebDAV 可以有效地批量上传的相片。具体步骤如下： Filestash: Filestash 是一个用户友好的文件管理工具，可以将的相片轻松上传到各类云存储服务。它支持多种云服务，比如 Google Drive、Dropbox、和 OneDrive 等。只需登录到 Filestash，然后选择所需上传的照片。界面直观，操作简单，允许一次性选择多张相片，避免了单独上传的麻烦，实现高效管理。 Rsync: 若要定期同步和备份原始相片数据到移动硬盘，可以借助 rsync 命令。这个命令具有强大的文件同步功能，特别适合进行增量备份。例如，可以设置一个 cron 任务，让这一命令每日凌晨自动运行。示例命令如下： rsync -av --delete /path/to/your/photos /path/to/your/external/harddrive 上述命令中的 -a 表示以归档模式同步，即保留文件的权限、时间戳等信息。-v 则是输出详细的操作过程，而 --delete 选项则确保目标目录与源目录完全一致，删除已不再存在的文件。这种方法确保始终拥有最新的相片备份，无论是在外出旅行还是在家中的日常记录。 使用 Alist要利用 Alist 来实现同步，按照以下步骤操作： 挂载 WebDAV: 首先，使用 mount 命令将 WebDAV 映射到本地文件系统。这样就可以像访问本地文件一样访问 WebDAV 上的文件。例如，执行以下命令： mount -t davfs https://your_webdav_url /mnt/webdav 这里的 https://your_webdav_url 是的 WebDAV 服务的实际地址，而 /mnt/webdav 是希望挂载的本地目录。这使得所有在 WebDAV 上的文件可以直接通过本地路径进行访问，提高了便利性。 修改 Docker-Compose 配置文件: 接下来，打开的 Docker-Compose 配置文件，修改数据的导入和存储路径，确保它指向新挂载的 WebDAV 位置。修改示例如下： volumes: - /mnt/webdav:/data # 将 WebDAV 目录挂载到 Alist 的数据目录 这个步骤确保 Alist 可以直接访问存储在 WebDAV 上的相片，并在应用中同步显示。 启动相册: 最后，通过 Docker 启动 Alist 服务。执行完成后，可以访问配置好的 WebDAV 目录，轻松查看并管理同步的照片和文件。在这个环境中，无论是个人相册还是多人共享的照片，都会变得一目了然，方便随时访问。 通过这些步骤，无论是在舒适的家中，还是趁着外出旅行，都能轻松管理、访问并备份的照片数据。如此一来，无论何时何地，都能保留美好瞬间。","categories":["1.平台","服务器","工具"]},{"title":"云服务管理软件-1panel","path":"/2024/06/25/1-平台-服务器-工具-云服务管理软件-1panel/","content":"云服务管理软件：开源的 1panel 创建 1panel 文件夹，进入后，执行以下命令安装： #先安装dockersudo apt install docker.iocurl -sSL https://resource.fit2cloud.com/1panel/package/quick_start.sh -o quick_start.sh sudo bash quick_start.sh 输入安全入口，之后登陆时需要安装 IP 地址 + 端口号 + 安全入口的形式进入管理页面 124.224.246:9090/liuluhua 输入登录用户名和密码 liuluhua-passwd 之后已完成 1panel 部署，可以方便的进行软件的管理","categories":["1.平台","服务器","工具"]},{"title":"内联函数","path":"/2024/06/24/2-语言-C语言-内联函数/","content":"内联函数在 C 语言中，如果一些函数被频繁调用，不断地有函数入栈，即函数栈，会造成栈空间或栈内存的大量消耗。为了解决这个问题，特别的引入了 inline 修饰符，表示为内联函数。 栈空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足所造成的程式出错的问题，函数的死循环递归调用的最终结果就是导致栈内存空间枯竭。 下面们来看一个例子： //函数定义为 inline 即:内联函数inline char* dbtest(int a)\treturn (i % 2 0) ? 奇 : 偶;int main()\tint i = 0;\tfor (i=1; i 100; i++) printf(i:%d 奇偶性:%s /n, i, dbtest(i)); 上面的例子就是标准的内联函数的用法，使用 inline 修饰带来的好处们表面看不出来，其实在内部的工作就是在每个 for 循环的内部任何调用 dbtest(i) 的地方都换成了 (i%20)?奇:偶 这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。 其实这种有点类似咱们前面学习的动态库和静态库的问题，使 dbtest 函数中的代码直接被放到 main 函数中，执行 for 循环时，会不断调用这段代码，而不是不断地开辟一个函数栈。 内联函数的编程风格定义关键字 inline 必须与函数定义体放在一起才能使函数成为内联，仅将 inline 放在函数声明前面不起任何作用。 如下风格的函数 Foo 不能成为内联函数： inline void Foo(int x, int y); // inline 仅与函数声明放在一起void Foo(int x, int y) 而如下风格的函数 Foo 则成为内联函数： void Foo(int x, int y);inline void Foo(int x, int y)// inline 与函数定义体放在一起 inline 是一种”用于实现的关键字”，而不是一种”用于声明的关键字”。一般地，在大多数教科书中内联函数的声明、定义体前面都加了 inline 关键字。 限制inline 只适合函数体内代码简单的函数使用，不能包含复杂的结构控制语句例如 while、switch，并且内联函数本身不能是直接递归函数(自己内部还调用自己的函数)。 慎用内联内联能提高函数的执行效率，但是是以代码膨胀（复制）为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。以下情况不宜使用内联： 如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。 如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。","categories":["2.语言","C语言"]},{"title":"字符串相关函数","path":"/2024/06/21/2-语言-C语言-字符串相关函数/","content":"putsputs 函数是 gets 函数的输出版本，主要用于将指定的字符串写入标准输出。此函数不仅将字符串打印到屏幕上，还在字符串末尾自动添加一个换行符。这使得每次调用 puts 后，输出都会开始于新的一行，增加了输出的可读性。例如，调用 puts(Hello, World!); 将在控制台上显示： Hello, World! getchar/*丢弃该行中包含最后一个数字的那部分内容*/while((ch = getchar()) != EOF ch != ) 当 scanf 函数处理输入值时，它只会读取实际需要的字符，留下该行最后部分未读取的字符。这些字符可能是单独的换行符，或者是其他意外输入内容。无论如何，while 循环将读取这些剩余字符并将其丢弃，从而防止它们被误解为有效数据。们可以分析以下表达式： (ch = getchar()) != EOF ch != 在这个表达式中，getchar 函数从标准输入读取一个字符并返回它的值。如果输入流到达文件的结束（EOF），该函数就会返回一个标志常量（EOF），以指示结束。值得注意的是，返回的值被赋给变量 ch，接着通过逻辑运算符进行比较。使用括号确保赋值操作在比较前执行，避免逻辑上的错误。如果 ch 的值是 EOF，整个表达式的结果变为假，循环随之终止。反之，如果 ch 是换行符，循环也会停止。只有在输入仍然可用且未遇到换行符时，循环才会继续执行。这样，这个循环可以有效去除当前输入行的最后部分。 与其他编程语言的写法相比，下面这种写法更为简洁和易读： ch = getchar();while(ch != EOF ch != ) ch = getchar(); 这个结构首先读取一个字符，若未到达输入的末尾且该字符不是换行符，则会继续读取下一个字符，直到满足退出条件。 getsgets 函数负责从标准输入读取一行文本，并将其存储在传递给它的字符数组中。整行输入由一串字符组成，最后以换行符结束。此函数在存储完成后会丢弃换行符，并在字符数组的末尾加上一个空字符（NUL 字节），用于表明字符串的结束。例如，通过调用 gets(myString);，会把用户输入的一行文本读入 myString，并在末尾添加 \\0。如果输入行无效（例如用户直接按下回车），gets 将返回 NULL，指示已到达输入的末尾（EOF）。 strchrstrchr 是一个用于在字符串中查找字符的函数。它接受两个参数：第一个参数是要搜索的字符串，第二个参数是需要查找的单个字符。这个函数会在字符串中寻找该字符第一次出现的位置。如果找到字符，则返回指向其位置的指针；如果未找到，则返回 NULL。例如，调用 strchr(Hello, World!, W); 会返回指向字符 ‘W’ 的指针。 strstr 函数与 strchr 类似，但其第二个参数是一个字符串而非单个字符。strstr 会搜索这些字符组成的字符串在第一个字符串中第一次出现的位置，这对于查找子串来说非常有用。 strcpystrcpy 和 strncpy 函数用于将字符串从一个位置复制到另一个位置。这两个函数都会返回一个指向目标字符串的指针，其中 strcpy 将会复制整个源字符串，包括终止的 NUL 字节；而 strncpy 允许用户指定要复制的最大字符数，以更好地控制内存使用。例如，调用 strcpy(destination, source); 将会将 source 字符串复制到 destination 中，确保 destination 是足够大的以容纳这段文本。","categories":["2.语言","C语言"]},{"title":"测量函数运行时间","path":"/2024/06/20/2-语言-C语言-测量函数运行时间/","content":"#include stdio.h#include stdlib.h#include time.hint main() // 定义一个大型整型变量，作为循环的计数器 long i = 10000000L; // 用于记录开始和结束时间的变量 clock_t start, finish; // 用于存储总耗时的变量 double Total_time; // 输出即将进行的操作提示信息 printf(Time to do %ld empty loops is , i); // 记录当前时间，作为计时的起始点 start = clock(); // 执行 i 次空循环，目的是用来消耗时间 while (i--) ; // 记录结束时间 finish = clock(); // 计算总时间，CLOCKS_PER_SEC 是每秒的时钟滴答数 Total_time = (double)(finish - start) / CLOCKS_PER_SEC; // 输出所耗费的时间，精确到秒 printf(%f seconds , Total_time); return 0; 该程序的主要目的是测量执行一系列操作所需的时间。在此示例中，它测量了执行 10,000,000 次空循环所需的时间。 在 C 语言中，可以使用 clock() 函数来获取程序在任意时刻的 CPU 使用时间。开始的时候记录时间，做完所有的循环后，再次记录时间，从而计算出所花费的总时长。 示例细节 定义的变量：long i 是一个长整型变量，初始化为 10,000,000。这个变量控制循环的次数，它的数量明显足够大，以便产生可测量的时间差。 时间测量逻辑：clock() 函数返回自程序启动以来的 CPU 时钟数，可以用来计算算法的时间复杂度。 循环操作：while (i--) ; 这里的空循环并没有实际兑现任何操作，唯一的目的就是消耗时间以进行测量。 结果输出：程序结束时，使用 printf 输出所需时间，表明经过 10,000,000 次空循环后，CPU 实际消耗的时间（以秒为单位）被打印出来。 输出示例如果运行这个程序，输出可能类似于： Time to do 10000000 empty loops is 0.123456 seconds 这里的 0.123456 秒是示例性的值，实际时间可能会根据计算机的性能和当前负载有所不同。此输出向说明了 CPU 执行这些空循环所需的时间，让能直观地理解该特定代码块的性能表现。","categories":["2.语言","C语言"]},{"title":"结构体占用字节大小计算","path":"/2024/06/19/2-语言-C语言-结构体占用字节大小计算/","content":"结构体的字节对齐在编程中，结构体的字节数占用通常依赖于其内部最大数据类型的字节长度。为了确保数据在内存中的正确对齐，有时会需要进行字节补齐。了解这一点，可帮助更有效地使用结构体。 字节对齐规则 最大数据类型：结构体的总字节数需是其最大成员数据类型所占字节数的倍数。这意味着，如果某个结构体包含不同的数据类型，必须根据占用字节数最多的类型来调整整个结构体的字节数。 示例： 如果结构体中最大的变量是 short（占用 2 个字节），那么整个结构体的大小必须是 2 的倍数。如果总占用字节数是 7，那么将增加 1 个字节，使其变为 8。 如果最大的是 int（占用 4 个字节），则结构体的大小需是 4 的倍数，例如 8 或 12。 示例结构体struct example1 char a; // 1 byte short b; // 2 bytes char c; // 1 byte char d; // 1 byte; // 总占用字节数为6，满足最大数据类型short的2的倍数要求struct example2 char a; // 1 byte short b; // 2 bytes char d; // 1 byte; // 总占用字节数为6，依然满足2的倍数要求struct example3 char a; // 1 byte char c; // 1 byte char d[5]; // 5 bytes; // 总占用字节数为7，不满足2的倍数，因此需要补齐至8struct example4 char a; // 1 byte short b; // 2 bytes char c[5]; // 5 bytes; // 总占用字节数为10，满足2的倍数要求（最大的是short）struct example5 char a; // 1 byte char c[5]; // 5 bytes short b; // 2 bytes; // 总占用字节数为8，满足2的倍数要求 字节非对齐设置通过设置结构体为字节非对齐的方式，开发者可以减少内存占用，但这种方法会引入潜在的性能问题。因为某些处理器对内存的访问要求严格，可能导致崩溃或严重降低访问速度。在实际开发中，应根据具体需要权衡字节对齐与内存使用的优劣。 结构体成员位设置开发者可以通过特定的编译器指令或展现形式来设置结构体成员所占位。 也可使使用 #pragma pack 可以强制编译器以特定的字节对齐方式来存储结构体，允许开发者控制每个成员的开始对齐位置。 各种数据类型的组合结构体能够包含不同类型的数据，只要它们的字节长度被系统明确规定。例如，结构体可以包含 int、float、double 等多种类型，进行复杂数据的组合和存储。然而，值得注意的是，结构体不能直接包含自身，但可以包含指向自身的指针，这使得在构建数据结构如链表时非常有效。","categories":["2.语言","C语言"]},{"title":"运算符优先级","path":"/2024/06/18/2-语言-C语言-运算符优先级/","content":"优先级C 语言中，运算符的运算优先级共分为 15 级。1 级最高，15 级最低。 在表达式中，优先级较高的先于优先级较低的进行运算。而在一个运算量两侧的运算符 优先级相同时，则按运算符的结合性所规定的结合方向处理。 结合性C 语言中各运算符的结合性分为两种，即左结合性(自左至右)和右结合性(自右至左)。例如算术运算符的结合性是自左至右，即先左后右。如有表达式 x-y+z 则 y 应先与”-“号结合，执行 x-y 运算，然后再执行+z 的运算。这种自左至右的结合 方向就称为”左结合性”。而自右至左的结合方向称为”右结合性”。最典型的右结合 性运算符是赋值运算符。如 xyz,由于””的右结合性，应先执行 yz 再执行 x(yz)运算。C 语言运算符中有不少为右结合性，应注意区别，以避免理解错误。 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 所有的优先级中，只有三个优先级是从右至左结合的，它们是单目运算符、条件运算符、赋值运算符。其它的都是从左至右结合。 具有最高优先级的其实并不算是真正的运算符，它们算是一类特殊的操作。()是与函数相关，[]与数组相关，而-及.是取结构成员。 其次是单目运算符，所有的单目运算符具有相同的优先级，因此在认为的 真正的运算符中它们具有最高的优先级，又由于它们都是从右至左结合的，因此p++与(p++)等效是毫无疑问的。 另外在 C 语言里，没有前置后置之分，因为++ – 是右结合所以右侧优先运算，表现为 “操作数后置优先级比较高” 的假象，前置和后置的区分是因为运算符重载而后加入 C++的 接下来是算术运算符，*、/、% 的优先级当然比 +、- 高了。移位运算符紧随其后。 其次的关系运算符中， = = 要比 == != 高一个级别，不大好理解。 所有的逻辑操作符都具有不同的优先级(单目运算符除外，!和~) 逻辑位操作符的”与”比”或”高，而”异或”则在它们之间。 跟在其后的 比 || 高。 接下来的是条件运算符，赋值运算符及逗号运算符。 在 C 语言中，只有 4 个运算符规定了运算方向，它们是 、| |、条件运算符及赋值运算符。 、| | 都是先计算左边表达式的值，当左边表达式的值能确定整个表达式的值时，就不再计算右边表达式的值。如 a = 0 b; 运算符的左边位 0，则右边表达式 b 就不再判断。 在条件运算符中。如 a?b:c;先判断 a 的值，再根据 a 的值对 b 或 c 之中的一个进行求值。 赋值表达式则规定先对右边的表达式求值，因此使 a = b = c = 6;成为可能。 口诀注释- 圆方括号、箭头一句号， 自增自减非反负、针强地址长度，- 乘除，加减，再移位，小等大等、等等不等，- 八位与，七位异，六位或，五与，四或，三疑，二赋，一真逗。- 圆方括号、箭头一句号指的是第 15 级的运算符。其中圆方括号很明显()、[]，箭头 指的是指向结构体成员运算符-，句号 指的是结构体成员运算符. ;- 自增自减非反负、针强地址长度指的是第 14 级的运算符。其中 非 指的是逻辑运算符!，反 指的是按位取反运算符~，负 指的是负号运算符-，针 指的是指针运算符*，强 指的是强制类型转换运算符，地址 指的是地址运算符，长度 指的是长度运算符sizeof ;- 乘除，加减，再移位移位指的是左移运算符和右移运算符，其中除法还包括了 取余运算符%;- 小等大等、等等不等 指的是第 10 级到第 9 级的运算符:、=、和=，等等指的是等于运算符==，不等指的是不等于运算符!=- 八位与，七位异，六位或其中 八位与 指的是第 8 级的 按位与 运算符，七位异 指的是第 7 级的按位异或运算符^，六位或 指的是第 6 级的按位或运算符|;- 五与，四或指的是第 5 级、第 4 级的逻辑与运算符和逻辑或运算符||;- 三疑，二赋，一真逗指的是第 3 级到第 1 级的运算符。其中，三疑指的是条件运算符?: (三有双重含义:即指优先级别是三，它的运算符类型也是三目，疑也取?之意)，二赋 指的是赋值运算符=、+=、-=、*=、/=、%=、=、=、=、^=和|= ，一真逗 指的是第 1 级的，运算符，真字只是为了语句需要罢了。 应用举例 赋值运算符: a=5; a=b=0; 第一个赋值语句将整数 5 赋给变量 a。第二个赋值语句同时把 0 赋给两个变量 b 和 a。这是因为赋值运算从右向左进行，首先执行 b=0，然后将 b 的值（0）赋给 a。因此，最终 a 和 b 的值都是 0。 复合赋值运算符: a=1; a+=3; 上述复合赋值可以理解为：首先将 1 赋给 a，然后执行 a+=3，它相当于 a=a+3。所以，3 加到原本的 1 上，最终结果为 4。因此，a 的最终值是 4。 算术运算符: Area=Height*Width; num=num1+num2/num3-num4; 第一个赋值语句将 Height 和 Width 的乘积赋给变量 Area。这用于计算矩形的面积，例如当 Height10，Width5 时，Area50。第二个赋值语句中，首先计算 num2 与 num3 的除法，之后将结果与 num1 相加，最后减去 num4。例如，如果 num1=10，num2=20，num3=5，num4=3，那么计算顺序依次是 20/5=4，然后 10+4-3=11，所以 num 的值为 11。 逻辑运算符: a=1, b=1; a||b-1; 这里 a=1 表示逻辑真，因此整个表达式 a || b-1 的结果也是逻辑真。在逻辑运算中，如果一个运算符的某个操作数为真，后面的部分就不再计算。例如，无论 b-1 的结果如何，总体表达式都为真。 关系运算符: if(a0)... 这个语句检查 a 是否大于 0。如果条件为真（即 a 的值确实大于 0），那么将执行 if 块内的内容；如果条件为假，则程序将跳过这个块。这通常用于控制程序的执行流程。 条件运算符: a=(b0)?b:-b; 运算中，如果 b 大于 0，则将 b 的值赋给 a；如果 b 不大于 0，则将 -b（即 b 的相反数）赋给 a。这个运算符的作用类似于获取 b 的绝对值，具体解释为当 b 为 -3 时，a 会得到 3。 逗号运算符: b=2, c=7, d=5; a=(++b, c--, d+3); 这里有三个表达式用逗号分隔。逗号运算符从左到右依次计算每一个表达式，但整个表达式的值等于最后一个表达式的值。在这个例子中，++b 和 c-- 的结果虽然被计算，但并没有被使用，最后 d+3 的计算结果是 8，因此 a=8。 位逻辑运算符 位逻辑运算符包括： （位与） |（位或） ^（位异或） ~（位取反） 以操作数 12 为例，数字 12 在二进制表示为 1100。位运算符将数字看作二进制位进行操作。比如： 表达式 1015 表示 1010 1111，返回值为 10，因为二进制的 1010 和 1111 在每一位上都进行了与运算，结果是 1010。 表达式 10|15 表示 1010 | 1111，返回值为 15，任何位中有值为 1 的都为真，因此结果为 1111。 表达式 10^15 表示 1010 ^ 1111，返回值为 5，只有在对应位不同时该位才为真，结果为 0101。 表达式 ~10 表示 ~1010，返回值为 -11，因为其按位取反，结果为 0101，在使用补码表示时为 -11。","categories":["2.语言","C语言"]},{"title":"C语言基础","path":"/2024/06/17/2-语言-C语言-C语言基础/","content":"基本数据类型char: 1 Bytes : 8 bitsshort:2 Bytes : 16 bitsint: 4 Bytes : 32 bitslong: 4 Bytes : 32 bitsfloat: 4 Bytes : 32 bitsdouble: 8 Bytes : 64 bitslong long: 8 Bytes : 64 bitslong double: 16 Bytes : 96 bits 数据类型存储数据在内存中以补码形式存储（溢出时截取补码的一段（然后求原码在输出）） char c;c = 1222;printf(%d %c ,c ,c); 关键字auto数据存放在栈上 register 不能用运算符获 取 regi ste r 变量的地址 register 变量的必须是 CPU 寄存器可以接受的值 register 关键字指明将变量存储在寄存器中 register 只是请求寄存 器变量， 但不一定成功，如果没有申请到空间，那么该变量与 auto 变量没有区别 static（将值放在了数据段，所以它的值在全局都具有继承性（但不具有访问性，只在该函数内部可以访问）） （限制作用域） stati c 关键字指明变量的”静态”属性 static 关键同时具有”作用域限定符”的意义 static 修饰的局部变量存储在程序静态区 static 的另一个意义是文件作用域标识符 static 修饰的全局变量作用域只是声明的文件中 static 修饰的函数作用域只是声明的文件中 为 何 static 在 fu n 函数中 定义为全局变量不行？ 局部变量生命周期为函数运行期间， 加上 stat ic 类型后，生命周期为程序运行期间，但只可在函数中进行访问 修改变量的储存类型（将数据从栈上放到了数据段）并不表示修改变量的作用域!它仍然只能在该代码块内部按名字访问。 extern外部参照引用（其他文件中（编译时应该一起）所有函数体外部说明的变量） （类似于声明？） （exter n 延长了全局变量的作用域（到其他文件中 用 exter n 引用），不具有改变值和类型的功能) （不分配内存，不能初始化）） （不可以改变类型） exter n 关键字的使用： （具 有 externa l 链接属性，储存于静态内存中） 如果一个变量声明于函数代码块内部，在它前面添 加 exter n 关键字将使它所引用的是全局变量，而非局部变量； 声明于函数最外层作用域的局部变量无法与形参同名，因为他们的作用域相同 局部变量生效的范围内，会自动屏蔽全局变量 exter n 使全局变 量 i 在 fu n 中可以被访问，如果没 有 extern 在函数中， i 将变为局部变量。 exter n 只是声明一个变量，该变量需在别处已被定义 const指定变量不可被当前线程改变（但有可能被系统或其他线程改变）。 关键字”static”，译成中文就是”静态的”，所以内部函数又称静态函数。但此处”static”的含义不是指存储方式，而是指对函数的作用域仅局限于本文件。 使用内部函数的好处是：不同的人编写不同的函数时，不用担心自己定义的函数，是否会与其它文件中的函数同名，因为同名也没有关系。 局部 static 变量 a.静态局部变量在函数内定义,生存期为整个源程序，但作用域与自动变量相同，只能在定义该变量的函数内使用。退出该函数后， 尽管该变量还继续存在，但不能使用它。 b.对基本类型的静态局部变量若在说明时未赋以初值，则系统自动赋予 0 值。而对自动变量不赋初值，则其值是不定的。 全局 static 变量 全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。但是他们的作用域，非静态全局 变量的作用域是整个源程序（多个源文件可以共同使用）。静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。 static 函数（也叫内部函数） 只能被本文件中的函数调用，而不能被同一程序其它文件中的函数调用。区别于一般的非静态函数（外部函数） static 在 c 里面可以用来修饰变量，也可以用来修饰函数。 先看用来修饰变量的时候。变量在 c 里面可分为存在全局数据区、栈和堆里。其实们平时所说的堆栈是栈而不包含对，不要弄混。 判断 ip 地址合法 判断大小端 堆栈区别，static const voliate 关键字存储模型全局静态变量全局变量(外部变量)的说明之前再冠以 static 就构成了静态的全局变量。全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。这两者在存储方式上并无不同。这两者的区别虽在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。 static 全局变量与普通的全局变量有什么区别：static 全局变量只初使化一次，防止在其他文件单元中被引用; static 局部变量和普通局部变量有什么区别：static 局部变量只被初始化一次，下一次依据上一次结果值； static 函数与普通函数有什么区别：static 函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝。 C 程序一直由下列部分组成： 正文段——CPU 执行的机器指令部分；一个程序只有一个副本；只读，防止程序由于意外事故而修改自身指令； 初始化数据段（数据段）——在程序中所有赋了初值的全局变量，存放在这里。 非初始化数据段（bss 段）——在程序中没有初始化的全局变量；内核将此段初始化为 0。 栈——增长方向：自顶向下增长；自动变量以及每次函数调用时所需要保存的信息（返回地址；环境信息）。 堆——动态存储分。 在全局变量之前加上关键字 static，全局变量就被定义成为一个全局静态变量。 内存中的位置：静态存储区（静态存储区在整个程序运行期间都存在） 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：全局静态变量在声明他的文件之外是不可见的。准确地讲从定义之处开始到文件结尾。 定义全局静态变量的好处： 不会被其他文件所访问，修改 其他文件中可以使用相同名字的变量，不会发生冲突。 局部静态变量在局部变量之前加上关键字 static，局部变量就被定义成为一个局部静态变量。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域随之结束。 注：当 static 用来修饰局部变量的时候，它就改变了局部变量的存储位置，从原来的栈中存放改为静态存储区。但是局部静态变量在离开作用域之后，并没有被销毁，而是仍然驻留在内存当中，直到程序结束，只不过们不能再对他进行访问。 当 static 用来修饰全局变量的时候，它就改变了全局变量的作用域（在声明他的文件之外是不可见的），但是没有改变它的存放位置，还是在静态存储区中。 静态函数在函数的返回类型前加上关键字 static，函数就被定义成为静态函数。函数的定义和声明默认情况下是 extern 的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。 定义静态函数的好处： 其他文件中可以定义相同名字的函数，不会发生冲突 静态函数不能被其他文件所用。 存储说明符 auto，register，extern，static，对应两种存储期：自动存储期和静态存储期。 auto 和 register 对应自动存储期。具有自动存储期的变量在进入声明该变量的程序块时被建立，它在该程序块活动时存在，退出该程序块时撤销。 关键字 extern 和 static 用来说明具有静态存储期的变量和函数。用 static 声明的局部变量具有静态存储持续期（static storage duration），或静态范围（static extent）。虽然他的值在函数调用之间保持有效，但是其名字的可视性仍限制在其局部域内。静态局部对象在程序执行到该对象的声明处时被首次初始化。 由于 static 变量的以上特性，可实现一些特定功能。 统计次数功能 声明函数的一个局部变量，并设为 static 类型，作为一个计数器，这样函数每次被调用的时候就可以进行计数。这是统计函数被调用次数的最好的办法，因为这个变量是和函数息息相关的，而函数可能在多个不同的地方被调用，所以从调用者的角度来统计比较困难。 C 语言中使用静态函数的好处： 静态函数会被自动分配在一个一直使用的存储区，直到退出应用程序实例，避免了调用函数时压栈出栈，速度快很多。 存储类 时期 作用域 链接 声明方式 自动 自动 代码块 空 代码块内 寄存器 自动 代码块 空 代码块内，使用关键字 register 具有外部链接的静态 静态 文件 外部 所有函数之外 具有内 部链接的静态 静态 文件 内部 所有函数之外 ，使用关键字 static 空链接的静态 静态 代码块 空 代码块内，使用关键字 static 变量类型 声明的位置 是否存于堆栈 作用域 如果声明 为 static 全局 所有代码块之外 否 从声明处到文件尾 不允许从其他源文件访问 局部 代码块起始处 是 整个代码块 变量不存储于堆栈中，它的值在程序整个执行期一直保持 形式参数 函数头部 是 整个函数 不允许 位的对齐字节对齐：在 32 位操作系统中，大多数计算机体系结构要求数据按照特定的字节边界对齐。常见的对齐边界是 4 字节（32 位）或 8 字节（64 位）。这是为了优化内存访问和数据传输的效率。如果数据没有按照正确的字节对齐方式存储，可能会导致额外的开销和性能下降。 结构体成员对齐：在结构体中，结构体成员的对齐方式可能会影响整个结构体的对齐方式。编译器通常会自动对结构体成员进行对齐，以满足所使用的编译器和平台的要求。默认情况下，大多数编译器会使用最大对齐方式，即按照结构体中最大成员的字节大小进行对齐。 指令对齐：在代码中，指令的对齐方式也是重要的。大多数处理器要求指令按照特定的字节边界对齐。指令对齐可以提高指令的执行速度和整体性能。 对于字节对齐，编译器通常会自动处理，但也可以通过编译器的指令或属性进行手动控制。在 C 语言中，可以使用特定的编译指令来控制结构体成员的对齐方式，例如使用 #pragma pack 指令。 以下是一个示例，展示了如何使用 #pragma pack 指令来设置结构体成员的对齐方式： #include stdio.h#pragma pack(push, 1) // 以1字节对齐方式压栈struct Example char a; int b; short c;;#pragma pack(pop) // 弹出对齐方式int main() struct Example ex; printf(Size of struct: %zu , sizeof(ex)); // 输出结构体的大小 return 0; 在上述示例中，通过使用 #pragma pack(push, 1) 指令将对齐方式设置为 1 字节，然后定义了一个名为 Example 的结构体，包含了 char、int 和 short 类型的成员变量。最后使用 #pragma pack(pop) 指令将对齐方式还原为默认值。 在运行示例程序后，可以观察到结构体 Example 的大小可能会受到对齐方式的影响。如果不进行任何对齐操作，默认情况下编译器可能会根据平台和编译器的要求进行对齐，大小会大于 1 字节。 总结来说，在 32 位的操作系统中，位的使用和对齐操作是为了优化内存访问和数据传输的效率。字节对齐、结构体成员对齐和指令对齐是常见的对齐方式，可以通过编译器的指令或属性进行手动控制，以满足特定的需求和平台要求。 函数指针利用函数指针，通过区分不同设备的设备号，通过函数指针的方式去调用不同的接口，从而完成一套程序可以支持多种不同的设备，完成各设备的通信协议的匹配工作， 宏定义操作符操作符#通常称为字符串化的操作符 #include stdio.h#define mkstr(s) #sint main(void)printf(mkstr(I like C))return 0; 替换结果 int main(void)printf(I like C);return 0; 操作符##可以把两个独立的字符串连接成一个字符串 #includestdio.h#define SORT(X) sortFunction##Xvoid main(void)\tchar *array;\tint elements , element size;\tSORT(3)(array , elements , element_size); 替换结果 void main(void)\tchar *array;\tint elements, element size;\tsortFunction3(array, elements,element size); 调试宏定义FILE 和 LINE 是 CC++ 编译器预定义的宏，用于获取当前源代码文件名和行号的信息。 __FILE__：它是一个字符串常量，表示当前源代码所在的文件名。编译器在编译过程中会将 FILE 替换为当前源代码文件的路径和名称。例如，如果的源代码文件名是 “example.c”，那么 FILE 的值将是一个字符串常量 “example.c”。 __LINE__：它是一个整数常量，表示当前源代码的行号。编译器会将 LINE 替换为当前源代码行号的数值。例如，如果在源代码的第 10 行使用了 __LINE__，那么它的值将是整数常量 10。 这些宏通常在调试和错误处理过程中使用，它们可以帮助程序员定位错误或记录特定代码位置的信息。通过在代码中使用 FILE 和 LINE 宏，可以在程序中动态地获取和打印出错位置，或者用于调试输出。 以下是一个示例，展示了如何使用 FILE 和 LINE 宏： #include stdio.hvoid printLocation() printf(Error occurred in file: %s , __FILE__); printf(Error occurred at line: %d , __LINE__);int main() int x = 42; if (x 50) printLocation(); return 0; 在上述示例中，定义了一个函数 printLocation()，它使用了 FILE 和 LINE 宏来打印错误发生的文件名和行号信息。在 main() 函数中，通过一个简单的条件判断来模拟错误情况，当 x 大于 50 时，调用 printLocation() 函数。 运行示例程序，如果条件满足，将输出类似以下内容的错误信息： Error occurred in file: example.cError occurred at line: 14 通过使用 FILE 和 LINE 宏，们可以方便地了解错误发生的具体位置，有助于调试和排查问题。","categories":["2.语言","C语言"]},{"title":"预处理和宏","path":"/2024/06/14/2-语言-C语言-预处理和宏/","content":"按照 ANSI 标准的定义，预处理程序负责处理一系列指令。这些指令都以符号 # 开始且必须独占一行。在 C 程序中，预处理阶段是一个重要的步骤，它在编译之前对代码进行分析和修改，使得源代码可以更灵活和高效地编译。 #define宏替换#define 指令用于定义一个标识符（称为宏名字）和一个字符串（字符集）。当源程序中出现该标识符时，它会被对应的字符串替换。宏代换的定义形式如下： #define macro-name char-sequence 注意，#define 语句不需要以分号结尾。宏名字和字符串之间可以有多个空白符，但字符串的结束只能以新行终止。例如，们可以使用两个 #define 指令来定义： #define LEFT 1#define RIGHT 0 每当在源程序中遇到 LEFT 或 RIGHT 时，编译程序都会将其替换为 1 或 0。定义宏之后，们还可以在其他宏定义中引用它，如： #define ONE 1#define TWO ONE + ONE 宏代换的实际作用在于用指定的字符串替换标识符，这使得代码更易于管理和维护。如果想要定义一条标准错误信息，可以如下操作： #define ERROR_MSG An error has occurred. 如果一个字符串长于一行，可以在其行尾使用反斜线 \\ 来继续到新一行。例如： #define LONG_STRING This is a very very long \\string that continues here. 宏体种不能递归包含自身的宏名，预处理的时候会把宏名看做字符串 带参宏们也可以在宏中定义函数。例如： #define SWAP(a, b) int temp = a; a = b; b = temp; 在调用 SWAP(a, b) 时，它会被替换为实际的代码块： int temp = a; a = b; b = temp; 宏定义函数 vs 外部调用函数宏定义和外部调用函数是以时间和空间进行权衡的策略：宏定义用更快的方式来替代代码，而函数则通过严格的类型检查和更好的内存管理来保证代码的安全性和可维护性。开发者在选择时，需根据实际需求，灵活选用合适的工具。例如，假设一个性能敏感的计算任务，使用宏可能是更合适的选择；而在需要复杂逻辑的应用场景中，外部函数则会显得更可靠。 宏定义函数宏实际上是可以理解为一段在编译时会被替换的代码片段。宏通过预处理器来实现，其传递的内容仅仅是字符串。与此关联的是，宏不会进行任何语法检查或数据类型校验。例如，在 C 语言中定义一个简单的宏： #define SQUARE(x) ((x) * (x)) 当在代码中使用 SQUARE(5) 时，预处理器会将其替换为 ((5) * (5))，直接在编译阶段进行文本替换。这意味着，程序运行时不会有额外的调用开销，宏的执行速度是非常快的。 优点: 使用宏时，程序的执行效率更高。由于编译时直接插入代码，这消除了函数调用所需的上下文切换和栈的操作，例如压栈和出栈的过程。 缺点: 由于宏不具备类型检查，当传递的参数类型不符合预期时，可能导致意想不到的结果。例如，如果使用 SQUARE(3.5)，则会产生 ((3.5) * (3.5))，这可能不是开发者的本意。同时，宏也不在运行时占用内存的释放过程，可能导致更高的内存消耗。 外部调用函数与宏不同，外部调用函数（通常被称为函数）则在运行时执行，并且在传递参数时会执行严格的类型匹配。例如，在 C 语言中定义一个求平方的函数如下： int square(int x) return x * x; 这里，函数 square 在运行时根据传入的参数来计算值。如果传入了不匹配的类型，例如浮点数，编译器会报错，从而帮助开发者及时发现问题。 优点: 函数提供了类型安全的参数传递机制，避免了许多潜在的错误。此外，函数在调用完成后可以灵活地释放资源，有助于优化内存使用。 缺点: 函数调用涉及到一定的开销，特别是在频繁调用的场景中，因为它需要在函数调用栈上安排内存，增加了执行时间。 #error#error 指令用于强制编译器停止编译，主要应用于调试阶段。它的一般形式是： #error error-message 例如，们可以定义标准错误信息如： #define ERROR_MSG Standard error on input #error ERROR_MSG 注意，宏字符串 error-message 不需要用双引号包围。当编译器遇到 #error 指令时，会显示指定的错误信息和其他可能的编译信息。 #include在程序中，#include 指令告诉编译器读取并编译另一个源文件。被包含的文件名可以用双引号 或尖括号 包围。例如，使用标准输入输出库包含头文件： #include stdio.h 被包含的文件中可以再次包含其他 #include 指令，这种行为称为嵌套包含。编译器对于嵌套包含的最大深度依赖于具体的实现。 文件名的包围方式决定了搜索文件的位置： 使用尖括号 时，编译器会按预定义目录搜索，一般用于标准库文件。 使用双引号 时，编译器首先在当前目录查找，如果没有找到再转向按尖括号方式搜索。 自定义包含路径在编译时，可以通过添加选项例如： gcc -I /home/fs/include 来指定搜索目录，如果 stdio.h 未在当前目录中找到，编译器会进一步查找 /home/fs/include，最后再查找系统默认目录。 通常，程序员在包含标准库文件时使用尖括号，而对于程序相关的文件则使用双引号。 条件编译指令条件编译允许程序员选择性地编译源代码的不同部分，这一过程称为条件编译。 #if #else #elif #endif条件编译指令中最常用的是 #if、#else、#elif 和 #endif。这些指令允许根据常数表达式的结果有条件地编译代码。 #if 的一般形式如下： #include stdio.h#if constant-expression Statement sequence#endif 如果 #if 后面的常数表达式为真，则执行 #if 和 #endif 之间的代码；否则，编译器将忽略这段代码。 #else 指令与 C 语言中的 else 相似，当 #if 失败时，可以作为备选指令。例如： #if MAX 99 printf(Compiled for array greater than 99. );#else printf(Compiled for small array. );#endif 这里 #else 既标记了 #if 块的结束，同时标记了 #else 块的开始。 为实现多重条件选择，可以使用 #elif： #if expression Statement sequence#elif expression1 Statement sequence#elif expression2 Statement sequence#else Statement sequence#endif #ifdef #ifndef条件编译的另一种方法是使用 #ifdef 和 #ifndef，用来判断宏是否已定义或未定义。 #define MAX 100int main(void) #ifdef MAX printf(MAX is defined. ); #else printf(MAX is not defined. ); #endif return 0; #ifndef MY_HEADER_H#define MY_HEADER_H // Header content#endif 在这个例子中，如果 MY_HEADER_H 未被定义，则包含头文件的内容。 #undef#undef 指令用于删除之前定义的宏名字，即 不定义 宏的功能。形式为： #undef macro-name #defined另一种检查宏是否已定义的方法是结合 #if 指令与 defined 操作符。形式如下： #if defined(MY) // Code if MY is defined#endif 可以通过感叹号 ! 来反转条件： #if !defined(DEBUG) printf(Final Version! );#endif #line #pragma#line#line 指令用于改变 __LINE__ 和 __FILE__ 的值，分别表示当前代码行号和文件名。形式为： #line number filename #pragma#pragma 是一种用于在编译过程中向编译器提供特殊指令或编译选项的预处理指令。不同的编译器可以定义自己的 #pragma 指令集，因此其行为在不同编译器中可能有所不同。使用 #pragma 指令时要确保其兼容性，尤其在跨编译器和跨平台开发中。常见的 #pragma 主要用于修改编译器的行为或进行代码的优化控制。#pragma 通常紧接其后的内容定义了具体的编译指令或选项。 #pragma 指令 编译器会忽略它不支持的 #pragma 选项，从而提高 C 源程序的可移植性。 常见用法 禁用或启用警告：可以临时禁用或启用特定的编译警告。 设置代码段：一些编译器支持使用 #pragma 来将代码放入指定的内存段。 优化设置：可以指定某个代码块的优化级别或其他优化相关选项。 指令对齐：控制结构对齐或数据对齐。 #pragma warning#pragma warning(push) // 保存当前警告状态#pragma warning(disable : 4996) // 禁用警告 4996（在 MSVC 中，常用于禁用安全函数相关的警告）#include stdio.hint main() char str[10]; gets(str); // 使用可能不安全的函数，编译器通常会发出警告 printf(%s , str); return 0;#pragma warning(pop) // 恢复之前的警告状态 在这个示例中，#pragma warning(disable : 4996) 用于禁用警告编号为 4996 的警告，通常与不安全的函数使用相关。 #pragma pack用途：调整结构体、联合体或类的成员对齐方式。它用于减少结构体的填充，优化内存占用。 #pragma pack(push, 1) // 设置对齐方式为 1 字节struct MyStruct char a; int b;;#pragma pack(pop) // 恢复默认对齐方式 #pragma pack(push, 1) 将结构体的成员对齐设置为 1 字节，这样可以减少结构体占用的内存，但在某些平台上可能影响性能。 #pragma once用途：防止头文件被多次包含。相比传统的头文件保护宏（如 #ifndef、#define），使用 #pragma once 可以简化头文件保护。 #pragma once// 头文件内容 #pragma once 是一种用于防止头文件被重复包含的指令，等效于传统的头文件保护宏： #ifndef HEADER_FILE_NAME#define HEADER_FILE_NAME// 头文件内容#endif 使用 #pragma once 可以简化编写头文件保护代码，避免重复包含问题。 #pragma GCC poison用途：禁止使用特定的标识符。如果在代码中使用了这些标识符，编译器将发出错误。 #pragma GCC poison printf scanf// 使用 printf 或 scanf 会导致编译错误 #pragma GCC optimize用途：控制特定代码段的优化选项，可以用于启用或禁用优化。 #pragma GCC optimize (O3) // 在此代码段启用最高优化级别void optimizedFunction() // 高度优化的代码 #pragma GCC target用途：为指定的函数设置特定的目标架构。这在编译器支持多种 CPU 指令集时非常有用。 #pragma GCC target (sse4.2)void sseOptimizedFunction() // 仅在支持 SSE4.2 的平台上进行优化 #pragma message用途：在编译时向用户显示自定义消息。 #pragma message This is a custom compile-time message 当编译器处理到这条指令时，会输出消息到编译器的输出中，方便开发者提醒或调试。 #pragma weak用途：定义弱符号，即使符号未被定义，链接器不会报错。通常用于库函数的替代实现。 #pragma weak myFunctionvoid myFunction() // 如果另一个 myFunction 实现存在，则不会使用此实现 预处理操作符 # 和 ##有两个预处理操作符可用于 #define 中： #：字符串化操作符，将宏参数转换为用双引号包围的字符串。 ##：拼接操作符，将两个标记结合形成新标记。 #define mkstr(s) #sprintf(mkstr(I like C)); // 转换为 I like C #define concat(a, b) a##bprintf(%d, concat(x, y)); // 假设 x 变量和 y 变量存在，将输出 xy 的值 ##粘连## 本质上是一个 胶水运算。在 C 语言中，## 运算符用于将参数宏中的形参与其它没有天然分割的内容粘连在一起。比如，们可以定义一个宏，让它自动地定义一个数组： #define def_u32_array(__name, __size) uint32_t array_##__name[__size]; 在实际使用时，们可能会这样调用这个宏： def_u32_array(sample_buffer, 64) 经过宏展开后，最终效果是： uint32_t array_sample_buffer[64]; 这里可以观察到，array_ 与形参 __name 是没有天然分隔符的，因此要将 array_ 与 name 所代表的内容粘连在一起，## 运算符是必不可少的。反之，name 与 [ 之间有天然分隔，编译器能够识别这两个部分。因此不用额外使用 ## 运算符。 连接可变参数宏## 运算符还有一个不太为人所知的用法。们需要提及另外一种参数宏扩展 — 可变参数宏。举个例子： #define safe_atom_code(...) \\ uint32_t int_flag = __disable_irq(); __VA_ARGS__ __set_PRIMASK(int_flag); \\ 这里定义了一个宏 safe_atom_code()，在括号中，无论填写任何内容，这些内容都会被放置到 __VA_ARGS__ 所在的位置。可以理解为括号里的 ... 实际上对应着 __VA_ARGS__。例如，们可以写如下代码： /** \\fn void wr_dat (uint16_t dat) * \\brief Write data to the LCD controller * \\param[in] dat Data to write */static __inline void wr_dat(uint_fast16_t dat) safe_atom_code( LCD_CS(0); GLCD_PORT-DAT = (dat 8); /* Write D8..D15 */ GLCD_PORT-DAT = (dat 0xFF); /* Write D0..D7 */ LCD_CS(1); ) 这个代码块确保在向寄存器 GLCD_PORT-DAT 写入数据的过程不会被其它中断打断。此时聪明的可能会提出疑问：这段宏与下面的写法有何区别？ #define safe_atom_code(__CODE) \\ uint32_t int_flag = __disable_irq(); __CODE __set_PRIMASK(int_flag); \\ 参数宏与预编译器的博弈参数宏通过 ,（逗号）作为分隔符来计算实际传入的参数个数。在使用参数宏的时候，预编译器实际上并不理解 C 语言语法 —— 在它眼中，除了它认识的少数符号外，其他的都是无意义的字符串。在处理括号内的内容时，预编译器只认识 , 和 ...。因此，当内容中的 , 增加时，编译器会认为参数的个数也增多。当使用参数宏时，传入的参数个数（需通过 , 分隔）必须与定义参数宏时的形参数量一致。如果不一致，预编译器通常不会直接报错，而是会无视所传递的内容，将其传递到编译阶段。如果出现未定义函数的错误，可能是因为宏本身被误认为是一个不存在的函数。可变参数宏解决了这一问题。可变参数宏中，... 只能位于形参列表的最后，当用户提供的参数个数超过定义的数量时，额外的参数就会通过 __VA_ARGS__ 进行处理。当用户提供的参数个数正好等于形参个数时，__VA_ARGS__ 等效于一个空字符串。 log_info 的使用回到上述的 safe_atom_code 宏，们再看看： #define log_info(__STRING, ...) printf(__STRING, __VA_ARGS__) 使用时，们可以这样调用： log_info(------------------------------------\\r );log_info( Cycle Count : %d, total_cycle_cnt); 这段代码会展开为： printf(------------------------------------\\r ,);printf( Cycle Count : %d, total_cycle_cnt); 看似没有问题，但注意到一个细节：此时第一个 printf() 函数的参数列表结尾多了一个 ,。尽管某些编译器（如 GCC）可能对此不予太多关注，但对于追求代码整洁的开发者来说，这种多余的逗号就显得很不舒服。 ANSI-C99 标准为了解决这种情况，引入了一个有用的语法：在 ,##__VA_ARGS__ 的组合使用时，如果 __VA_ARGS__ 为空字符串，前面的 , 将会被删除。这样，们可以将宏改写为： #define log_info(__STRING, ...) printf(__STRING,##__VA_ARGS__) 最终展开为： printf(------------------------------------\\r );printf( Cycle Count : %d, total_cycle_cnt); 这样最后的逗号就不会出现了，让代码更加干净整洁。 逗号表达式的灵活性结合前面关于 ,##__VA_ARGS__ 的用法，们可以意识到，这里的逗号不仅可以作为参数列表的分隔符，还是逗号表达式的运算符。因此，们可以写出类似这样的宏： #define EXAMPLE(...) ( 默认值 ,##__VA_ARGS__) 这种写法可以分为两种情况： 无参数调用：当使用时不填写任何内容，最终会展开为仅有默认值的情况： EXAMPLE(); // 展开为：( 默认值 ) 提供有效值：如果提供了有效值，则展开成逗号表达式： EXAMPLE(们提供的值); // 展开为：( 默认值, 们提供的值 ) 由于逗号表达式的特性，默认值会被丢弃，这虽然在某些编译器中可能报出无效的警告，但在用法上是完全合理的。 这一技巧在 API 封装上非常有效，可以为函数简化使用方式。例如，当用户调用初始化函数并通过结构体配置某些参数时，如果用户传入的配置为 NULL，系统则可以用默认的配置： #define XXXX_INIT(...) xxxx_init((NULL,##__VA_ARGS__)) 在消息处理方面，开发者可以设计类似机制，允许程序根据用户传入的参数自动处理必要的配置： #define def_msg_map(__name, ...) \\ const msg_t __name[] = __VA_ARGS__; #define add_msg(__msg, __handler, ...) \\ \\ .msg = (__msg), \\ .handler = (__handler), \\ .msk = (0xFFFF, ##__VA_ARGS__), \\ 这样，当用户省略参数时，系统就会提供默认值，例如： def_msg_map(iap_message_map, add_msg(SIGN_UP, iap_sign_up_handler), add_msg(WRITE_MEM, iap_write_mem, 0xFF00), add_msg(READ_MEM, iap_read_mem, 0xFF00)); 这条代码展示了如何让系统在处理消息时采用默认值，同时也允许用户自定义特定条件，从而实现灵活的消息管理。这让程序在运行时表现得更加智能和友好。 预定义宏C 语言规范了五个固有的预定义宏： __LINE__：当前编译的代码行号。 __FILE__：当前编译的源文件名。 __DATE__：源文件编译时的日期，格式为 month/day/year。 __TIME__：源代码编译时的时间，格式为 hour:minute:second。 __STDC__：如果内容是十进制常数 1，表示编译程序符合标准 C。 typedef 的应用在预处理和代码编写中，们经常使用 #define。需要注意的是，typedef 与 #define 用法相似，但它们有明确的区别： typedef 是 C 语言的关键字。 #define 是预处理命令。 typedef 常用于为现有数据类型定义新名字，在数据结构中尤为频繁。例如： typedef struct _node_ int data; struct _node_ *next; listnode, *linklist; 在此示例中，listnode 被定义为结构体类型，而 linklist 则是指向该结构体的指针类型。通过使用 typedef，程序员可以让代码更加清晰和易于维护。","categories":["2.语言","C语言"]},{"title":"位运算","path":"/2024/06/13/2-语言-C语言-位运算-位运算/","content":"原码与补码在计算机中，数字以不同的方式表示。例如，1000 0011 是原码，1111 1111 是补码。补码的好处是能简化计算机对负数的处理。 原码： 1000 0011补码： 1111 1111 对于 sizefof(2.2)，返回的数据是 8 字节，而 1000 0011 和 1111 1111 分别是原码与补码的表示方式。 1000 0000 0000 0000 0000 0000 0000 00111111 1111 1111 1111 1111 1111 1111cpp 1101 这里的数值和其对应的二进制补码表示也非常重要，特别是在进行算术运算时。 类型转换在编程中，类型转换是将一种数据类型的值转换为另一种数据类型。具体例如，使用 sizeof(2.2) 可能返回 8，表示所需的字节数。 强制类型转换强制类型转换可以让们明确地指定值的类型。 使用 printf 函数输出值时，可能看到不同的结果。例如： printf(%f, 23 / 2); // 输出整数，结果为 11.000000printf(%f, (float)23 / 2); // 输出浮点数，结果为 11.500000printf(%f, (float)(23 / 2)); // 输出浮点数，结果为 11.000000 这三个例子展示了不同的强制类型转换效果。 算术表达式算术表达式涉及使用算术运算符（如 +, -, *, /, %）来计算值。在处理除法时，确保分母不为零，取余运算要求操作数为整数。 运算符的优先级为： 1. ()2. * / %3. + - 而计算的结合性通常为从左到右： k = i+++j; // 等价于 (i++) + j 自增与自减运算符自增和自减运算符可以被用于不同类型： 对于将变量增 加 1，使用自增运算符是最佳选择，因为它的效率高。 如果增量不是 1，考虑使用复合赋值运算：i += 10; 等同于 i = i + 10; int i = 1;j = i+++i++; // j = 2, i = 2 赋值运算符赋值运算符有几个规则要遵循： 等号左侧只能是变量，不能是表达式、常量或数组名（形参数组名除外）。 右侧注意数据类型。 赋值表达式的值，即被赋值变量的值。 x = (y = 2, z = 3); // 先赋值y为2，再赋值z为3，x的值为3 复合赋值运算符复合赋值运算符结合了赋值与运算符。例如： x += 2; // 等价于 x = x + 2;a *= b + c; // 等价于 a = a * (b+c); 条件运算符条件运算符用于简化条件判断，如 ? : 语句。例如： y = (x 10) ? x / 10 : (x 0 ? x : -x); 逗号运算符逗号运算符用于依次执行多个表达式，返回最后一个表达式的结果。例如： y = (2, 3, 4); // y 的值为 4 位运算符位运算符针对二进制位进行操作，包括按位与 ()、按位或 (|)、按位取反 (~)、按位异或 (^)、左移 ()、右移 ()。 123 111; // 得到 107，因为111是0110 1111，0和0得到0，1和1得到1，其他皆为0。 对于一个存储单元清零，们可以使用与运算：num (~(1U n)); 同样可以用与运算提取某些位置的值。 位运算的操作 清零某指定位 当们处理数值 123（其二进制表示为 01111011）时，例如想要将第 4 位清零。们使用 123 (~(1U 4)) 的方法。这里的 1U 4 操作是将数字 1 左移 4 位，结果是 00010000（即十六进制的 0x10），取反后得到 11101111。将这个值与 123 进行与运算后，结果为 01101011，其中第 4 位被成功清零。 取出某指定位 假设们有一个整数 int a = 123（其二进制表示为 01111011），想要获取这个数的低 4 位值，们可以使用 a 0x0F。 保留某指定位 为了保留数值 123 的特定一位，比如第 n 位，可以通过 123 (1U n) 的方式操作。将 1 左移 n 位的结果会形成一个仅在第 n 位上的数字为 1 的位掩码，比如 n 2，掩码就是 00000100。与 123 进行与运算时，其他位不受影响，而只有第 n 位会保留下来，便于后续操作。如果想检查第 2 位的情况，如 123 (1U 2)，会得到 00000000，表示该位为 0。 设置若干个位 对于数值 123（二进制表示为 01111011），如果们想将第 4 到 7 位设置为二进制值 1001，可采用的操作是 num (-(0xf 4)) | (0x9 4)。首先，0xf（二进制为 1111）左移 4 位得到 11110000，然后取其负值获得 00001111 进行与运算会将原数的第 4 到 7 位清零。往后，0x9（即 00001001）左移 4 位变成 10010000，并与之前的结果进行或运算，最终将原数的第 4 到 7 位迁移为 1001。例如，原数是 01111011，经过这些位操作后，最终值将成为 00001011（即十进制的 11）。 操作符 和 ||尽管 操作符的优先级较低，但它仍然会对两个关系表达式施加控制。 操作符的左操作数总是首先进行求值 如果它的值为真，然后紧接着对右操作数进行求值。 如果左操作数的值为假，那么右操作数便不再进行求值，因为整个表达式的值肯定是假的，右操作数的值已无关紧要。 操作符 || 具有相同的特点，它首先对左操作数进行求值，如果它的值是真的，右操作数便不再求值，因为整个表达式的值此时已经确定。这个行为常常被称为短路求值（short-circuited evaluation）。 表达式的顺序必须确保正确。这点非常有用。下面这个例子在标准 Pascal 中是非法的： if ( x = 0 x MAX array[x] == 0) ... 在 C 中，这段代码首先检查 x 的值是否在数组下标的合法范围之内。如果不是，代码中的下标引用表达式便被忽略。由于 Pascal 将完整地对所有的子表达式进行求值，所以如果下标值错误，尽管程序已经费尽心思对下标值进行范围检查，但程序仍会由于无效的下标引用而导致失败。 警告：位操作符常与逻辑操作符混淆，但它们不可互换的。它们之间的第 1 个区别是 || 和 操作符具有短路性。 如果表达式的值取决于左操作数可决定，它就不再对右操作数进行求值。与之相反，| 和 操作符两边的操作数都需要进行求值。 其次，逻辑操作符用于测试零值和非零值，而位操作符用于比较它们的的操作数中的对应的位。这里有一个例子： if( a b c d )...if( a b c d )... 因为关系操作符产生的表达式是 0，或是 1，所以这两条语句的结果是一样的。但是，如果 a 是 1 而 b 是 2，下一对语句就不会产生相同的结果。 if( a b )...if( a b )... 因为 a 和 b 都是非零值，所以第 1 条语句的值为真，但第 2 条语句的值却是假，因为 a 和 b 的位模式中，没有一个位在两者中的值都是 1。 设置结构体内位域typedef int * INT32;#define INT64 int *struct node_t char a; char b:2; char d:3; char e:4; char c; __attribute__((packed));int main(int argc, const char *argv[]) printf(%d , sizeof(struct node_t)); struct node_t val; val.b = 5; printf(%d , val.b); 结构体 node_t 包含五个成员：a、b、d、e 和 c。 b:2、d:3 和 e:4 是位域，分别占用 2 位、3 位和 4 位。 __attribute__((packed)) 告诉编译器不要对该结构体进行内存对齐优化取消对齐填充，使其按定义的字节顺序紧凑存储。所以结构体的大小会是各个成员字节数和位域位数的总和。 char a 和 char c 各占 1 字节。 char b:2、char d:3 和 char e:4 共占 9 位，即 2 字节（因为位域不足一个字节，但会补齐到一个字节的最小单位）。总大小为 1 + 2 + 1 4 字节。 所以，sizeof(struct node_t) 的输出是 4。val.b 5 的值会被截断到 2 位，所以 printf(“%d ”, val.b); 的输出会是 1（因为 5 的二进制为 101，截断到 2 位为 01。 位操作的奇偶校验","categories":["2.语言","C语言","位运算"]},{"title":"大小端，字节序，位序，字节对齐，位域对齐","path":"/2024/06/12/2-语言-C语言-位运算-大小端，字节序，位序，字节对齐，位域对齐/","content":"测试用源代码：#includestdio.h#includestring.h#if 1struct Test unsigned short a:2; unsigned short b:3; unsigned short c:5; unsigned short d:8;;#elsestruct Test unsigned char a:2; unsigned char b:3; unsigned char c:5; unsigned char d:8;;#endifint main(void) struct Test t; memset(t, 0x00,sizeof(t)); t.a = 1; t.b = 1; t.c = 1; t.d = 1; printf(%08X , *(unsigned int *)t); return 0; 分析与结果： 总结： csdn 上很多文章称”位域不可以跨越字节”，错。正确说是位域不可以跨越变量类型。如图中中间的例子（测试用源代码里用#if #else分别测试了unsigned short 和 unsigned char 两种情况）。 字节对齐与位域对齐的规则网上有很多文章，图中给出了两种例子，其实原则都是一样的：以对齐要求为边界（通常是 4 字节为边界），能挤就挤。不能挤就再开一个。 面试时遇到这类题的解题思路如上图：1，先从低地址到高地址画出一张图；2，再把结构体成员按照字节对齐和位域对齐要求填入；3，再把成员变量的二进制值填入，小端与书写顺序相反（从右往左写值），大端符合书写和阅读习惯（从左往右）4，根据二进制的值计算出最终的输出。（注意小端低地址存的是数字的低位） MSB,LSB,结合大小端的问题：网上大多数文章的例子： 大端模式：一个多字节数据的高字节在前，低字节在后，以数据 0x1234ABCD 看例子：低地址 ——————— 高地址±±±±±±±±±±±±±±±| 12 | 34 | AB | CD |±±±±±±±±±±±±±±±小端模式：一个多字节数据的低字节在前，高字节在后，仍以 0x1234ABCD 看：低地址 ——————— 高地址±±±±±±±±±±±±±±±| CD | AB | 34 | 12 |±±±±±±±±±±±±±±± 这里有一个重大的存在可能误导的地方，就是上面只做了字节序的调整，没有做位序（比特序）的调整。严格的说这只是小端 CPU 里网络序与主机序的转换，而不是大小端的转换。 如果真要做大小端的转换呢？都知道上面的例子中小端模式十六进制的 CD 存在低地址。那小端模式十六进制的 CD 的二进制到底是怎么存的呢？ 看了上面的图例可以推测出”CD”的二进制形式在小端模式下，仍然是反书写顺序的（即从右往左看才能得到 CD）这里给出一个更直观的大小端对比图： 以上图再导出 MSB 与 LSB： MSB 与 LSB 是数字的高低位的概念，是数字就有最高位和最低位。 MSB first 与 LSB first 是传输或拷贝时的概念，常见于不同协议之间的转换（比如 32 位传输转换到到 8 位传输），以上图举例：如果是 LSB first ，这是在告诉传输或拷贝时，数据的低位放在前面，即从 2 的 0 次方开始传输或拷贝。 为什么 htonl()、ntohl()只做了字节转换？因为在以太网中，字节序是按照大端序来发送，但是位序（比特序）却是按照小端序的方式来发送（LSB first）结合上图，网络发送顺序为： 224 225 226 227 228 229 230 231 216 217 218 219 220 221 222 223 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 这里解释了为什么小端 CPU 的网络序与主机序的转换是 0x12345678,变成 0x78563412.（即比特序在一个字节内是没有变化的） 为什么只做字节序的转换就可以了，大小端之间传送不用做位序（比特序）的转换吗？是的，大小端之间传送不用做位序（比特序）的转换。重复上面的话，LSB first， MSB first 是协议约定，约定好了，之后自然再按约定还原即可。打个比方，快递一套家具，先要拆分，再打包，再发送，到了之后再组装还原。这个过程就是协议做的事情。对用户（读写程序）来说，看到的一直是一套完整的家具（数据）。 那为什么说大端不用做转换呢？大端 CPU 不用做字节转换，发送时的位序（比特序）的转换是协议的事情，当然发送的位序与内存里的位序是不一样的。怎么发送，是协议的事情。 小端机内存中（低地址到高地址） 字节转换后 以太网中 大端机内存中（低地址到高地址） 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 215 214 213 212 211 210 209 208 207 206 205 204 203 202 201 200 脚-下半身-上半身-头 上半身-头，脚-下半身 上半身-头，脚-下半身 头-上半身-下半身-脚 小端 CPU 要做字节转换，然后让以太网协议去传输，传输完成，最终的数据是一致的（大小端只是方向反了而已）。 可见从大端机到网络也是有”转换”的。只是编写上层的程序时不用考虑。驱动或硬件要考虑。 为什么小端机不做成驱动硬件自动字节转换？字节转换有长度问题，比如两个字节一转？还是四个字节一转？还是八个字节一转？而位转换只有一种，就是 8 个位一转。所以小端 CPU 要调用字节 转换函数。 带位域的 结构体 应该如何编写才能在网络上正确传输？先看几个例子： //linux-3.4/include/linux/netfilter/nf_conntrack_proto_gre.hstruct gre_hdr #if defined(__LITTLE_ENDIAN_BITFIELD) __u16 rec:3, srr:1, seq:1, key:1, routing:1, csum:1, version:3, reserved:4, ack:1;#elif defined(__BIG_ENDIAN_BITFIELD) __u16 csum:1, routing:1, key:1, seq:1, srr:1, rec:3, ack:1, reserved:4, version:3;#else#error Adjust your asm/byteorder.h defines#endif __be16 protocol;;//linux-3.4/include/linux/icmpv6.hstruct icmpv6_nd_advt #if defined(__LITTLE_ENDIAN_BITFIELD) __u32 reserved:5, override:1, solicited:1, router:1, reserved2:24;#elif defined(__BIG_ENDIAN_BITFIELD) __u32 router:1, solicited:1, override:1, reserved:29;#else#error Please fix asm/byteorder.h#endif u_nd_advt;struct icmpv6_nd_ra __u8 hop_limit;#if defined(__LITTLE_ENDIAN_BITFIELD) __u8 reserved:3, router_pref:2, home_agent:1, other:1, managed:1;#elif defined(__BIG_ENDIAN_BITFIELD) __u8 managed:1, other:1, home_agent:1, router_pref:2, reserved:3;#else#error Please fix asm/byteorder.h#endif __be16 rt_lifetime; u_nd_ra; 由上面三个内核源代码里的结构体可以看出规律：1. 以一个字节为单位，字节内的位域位置反转。2. 大端结构体里位域字段顺序与网络序相同，小端相反。 位域跨越字节应该如何处理？有没有跨字节的例子？有 802.1Q 协议里的 vlan 字段就跨了字节。 Type PRI CFI Vlan ID 16bits 3bits 1bits 12bits //linux-3.4/include/linux/if_vlan.h/** * struct vlan_ethhdr - vlan ethernet header (ethhdr + vlan_hdr) * @h_dest: destination ethernet address * @h_source: source ethernet address * @h_vlan_proto: ethernet protocol (always 0x8100) * @h_vlan_TCI: priority and VLAN ID * @h_vlan_encapsulated_proto: packet type ID or len */struct vlan_ethhdr unsigned char h_dest[ETH_ALEN]; unsigned char h_source[ETH_ALEN]; __be16 h_vlan_proto; __be16 h_vlan_TCI; __be16 h_vlan_encapsulated_proto;; 使用位移或位运算处理，占 2 个字节的 h_vlan_TCI 在网络序转主机序后，去掉高位的 4 位就是 vlan ID. 参考资料：https://www.linuxjournal.com/article/6788","tags":["clippings"],"categories":["2.语言","C语言","位运算"]},{"title":"校验","path":"/2024/06/11/2-语言-C语言-位运算-校验/","content":"纵向冗余校验 (LRC)纵向冗余校验（LRC）是用于数据完整性检查的重要机制，其校验区占用 1 个字节，包含 8 位二进制数据。具体的工作流程如下： LRC 值计算：发送设备负责计算 LRC 值。这个值是通过将信息中的每两个相邻 8 位字节相加而得出的。在此过程中，需要注意的是，如果加法运算产生进位，这些进位会被丢弃。计算完成后，LRC 值将被附加到信息中。 接收端的校验：接收设备在接收到信息后，会重新计算 LRC 值。这是通过相同的方式完成的，即将接收到的信息中的每两个 8 位字节相加，并丢弃进位。接收端比较自己计算出的 LRC 值与信息中包含的 LRC 值。如果两者不相符，表示在数据传输过程中出现了错误。 LRC 值的具体计算步骤： 相加：把信息中的所有字节（包括起始符号“：”和结束符 CRLF）相加，并将结果送入 8 位的 LRC 数据区，丢弃进位。 生成补码：使用 FFH（255 的十六进制表示）减去最终的和以生成补码。 加一操作：再加“1”来得到最终的二进制补码。 信息发送：在发送信息时，首先发送高位字符，然后发送低位字符。例：如果 LRC 值为 61H（0110 0001），则其传输顺序是先传输‘6’（高位），再传输‘1’（低位）。 C 语言示例代码static unsigned char LRC(unsigned char *auchMsg, unsigned short usDataLen) unsigned char uchLRC = 0; /* 初始化LRC字符 */ while (usDataLen--) /* 遍历数据缓冲器 */ uchLRC += *auchMsg++; /* 加缓冲器字节，且无进位 */ return ((unsigned char)(–((char)uchLRC))); /* 返回二进制补码 */ 循环冗余校验 (CRC)循环冗余校验（CRC）是一种强大的错误检测方法，其校验区占用 2 个字节，含有一个 16 位的二进制数据。其工作流程如下： 寄存器初始化：在开始计算 CRC 时，首先将 16 位的寄存器全部置为“1”。然后接收相邻的两个 8 位字节的数据。注意，仅数据部分用于计算 CRC，起始位、停止位和奇偶校验位被排除在外。 计算过程： 每 8 位数据与寄存器中的值进行异或运算，结果右移一位，并用“0”填充最高有效位(MSB)。 检查最低有效位(LSB)。如果 LSB 为“1”，则与预置的固定值异或；如果 LSB 为“0”，则不进行异或操作。 重复上述步骤直到右移 8 次。 处理完所有字节后，寄存器中的值即为 CRC 值。 具体计算步骤： 将 16 位 CRC 寄存器初始化为 FFFFH。 处理每个 8 位数据：第一个 8 位数据与 CRC 寄存器的低字节进行异或，结果放入 CRC 寄存器。 CRC 寄存器右移一位，MSB 填零，检查 LSB。 如果 LSB 为 0，继续右移一位；如果 LSB 为 1，则与预设值异或。 这一直续进行，直到全部 8 位数据被处理完毕。 信息发送：在发送信息时，先发送低 8 位，然后发送高 8 位。例：假设 CRC 值为 1241（0001 0010 0100 0001），发送顺序为先发送低位（0100 0001），后发送高位（0001 0010）。 C 语言示例代码unsigned short CRC16(unsigned char *puchMsg, unsigned short usDataLen) unsigned char uchCRCHi = 0xFF; /* 初始化高字节 */ unsigned char uchCRCLo = 0xFF; /* 初始化低字节 */ unsigned uIndex; /* CRC表索引 */ while (usDataLen--) /* 通过数据缓冲器 */ uIndex = uchCRCHi ^ *puchMsg++; /* 计算CRC */ uchCRCHi = uchCRCLo ^ auchCRCHi[uIndex]; uchCRCLo = auchCRCLo[uIndex]; return (uchCRCHi 8 | uchCRCLo); /* 返回CRC值，低字节在前 */ 通过上述过程，LRC 和 CRC 均为确保数据完整性的重要手段。每一种方法都有其独特的计算步骤和应用场景，能够在数据传输中有效检测和判断错误的发生。 高位字节表/* Table of CRC values for high–order byte */static unsigned char auchCRCHi[] = 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81,0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0,0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01,0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41,0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81,0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0,0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01,0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40,0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81,0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0,0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01,0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41,0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81,0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0,0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01,0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81, 0x40, 0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41,0x00, 0xC1, 0x81, 0x40, 0x01, 0xC0, 0x80, 0x41, 0x01, 0xC0, 0x80, 0x41, 0x00, 0xC1, 0x81,0x40 ; 低位字节表/* Table of CRC values for low–order byte */static char auchCRCLo[] = 0x00, 0xC0, 0xC1, 0x01, 0xC3, 0x03, 0x02, 0xC2, 0xC6, 0x06, 0x07, 0xC7, 0x05, 0xC5, 0xC4,0x04, 0xCC, 0x0C, 0x0D, 0xCD, 0x0F, 0xCF, 0xCE, 0x0E, 0x0A, 0xCA, 0xCB, 0x0B, 0xC9, 0x09,0x08, 0xC8, 0xD8, 0x18, 0x19, 0xD9, 0x1B, 0xDB, 0xDA, 0x1A, 0x1E, 0xDE, 0xDF, 0x1F, 0xDD,0x1D, 0x1C, 0xDC, 0x14, 0xD4, 0xD5, 0x15, 0xD7, 0x17, 0x16, 0xD6, 0xD2, 0x12, 0x13, 0xD3,0x11, 0xD1, 0xD0, 0x10, 0xF0, 0x30, 0x31, 0xF1, 0x33, 0xF3, 0xF2, 0x32, 0x36, 0xF6, 0xF7,0x37, 0xF5, 0x35, 0x34, 0xF4, 0x3C, 0xFC, 0xFD, 0x3D, 0xFF, 0x3F, 0x3E, 0xFE, 0xFA, 0x3A,0x3B, 0xFB, 0x39, 0xF9, 0xF8, 0x38, 0x28, 0xE8, 0xE9, 0x29, 0xEB, 0x2B, 0x2A, 0xEA, 0xEE,0x2E, 0x2F, 0xEF, 0x2D, 0xED, 0xEC, 0x2C, 0xE4, 0x24, 0x25, 0xE5, 0x27, 0xE7, 0xE6, 0x26,0x22, 0xE2, 0xE3, 0x23, 0xE1, 0x21, 0x20, 0xE0, 0xA0, 0x60, 0x61, 0xA1, 0x63, 0xA3, 0xA2,0x62, 0x66, 0xA6, 0xA7, 0x67, 0xA5, 0x65, 0x64, 0xA4, 0x6C, 0xAC, 0xAD, 0x6D, 0xAF, 0x6F,0x6E, 0xAE, 0xAA, 0x6A, 0x6B, 0xAB, 0x69, 0xA9, 0xA8, 0x68, 0x78, 0xB8, 0xB9, 0x79, 0xBB,0x7B, 0x7A, 0xBA, 0xBE, 0x7E, 0x7F, 0xBF, 0x7D, 0xBD, 0xBC, 0x7C, 0xB4, 0x74, 0x75, 0xB5,0x77, 0xB7, 0xB6, 0x76, 0x72, 0xB2, 0xB3, 0x73, 0xB1, 0x71, 0x70, 0xB0, 0x50, 0x90, 0x91,0x51, 0x93, 0x53, 0x52, 0x92, 0x96, 0x56, 0x57, 0x97, 0x55, 0x95, 0x94, 0x54, 0x9C, 0x5C,0x5D, 0x9D, 0x5F, 0x9F, 0x9E, 0x5E, 0x5A, 0x9A, 0x9B, 0x5B, 0x99, 0x59, 0x58, 0x98, 0x88,0x48, 0x49, 0x89, 0x4B, 0x8B, 0x8A, 0x4A, 0x4E, 0x8E, 0x8F, 0x4F, 0x8D, 0x4D, 0x4C, 0x8C,0x44, 0x84, 0x85, 0x45, 0x87, 0x47, 0x46, 0x86, 0x82, 0x42, 0x43, 0x83, 0x41, 0x81, 0x80,0x40 ;","categories":["2.语言","C语言","位运算"]},{"title":"互斥锁","path":"/2024/06/10/2-语言-C语言-多线程-互斥锁/","content":"在编程中，对象互斥锁的引入是为了确保对共享数据的操作具有完整性。每个对象都会有关联的标记，称为”互斥锁”，以保证在任何特定时刻，只有一个线程可以访问该对象。这一设计尤其重要，因为多个线程可能同时尝试修改同一数据，若没有适当的控制，数据的完整性将受到威胁。通过互斥锁，可以有效防止数据竞争和不可预测的行为。 1. 创建和销毁互斥锁在 POSIX 线程（也称 Pthreads）中，提供了一套专门用于线程同步的互斥锁函数。这些函数支持两种创建互斥锁的方法：静态和动态。 静态创建使用 PTHREAD_MUTEX_INITIALIZER 宏可以静态初始化互斥锁，示例如下： pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; 在 LinuxThreads 的实现中，pthread_mutex_t 是一个结构，而 PTHREAD_MUTEX_INITIALIZER 则被定义为一个结构常量。这种方式简单明了，便于在程序中快速创建互斥锁。 动态创建另一种方法是使用 pthread_mutex_init() 函数进行动态初始化。它的 API 定义如下： int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr); 其中，mutexattr 参数用于指定互斥锁的属性。如果该参数为 NULL，则会使用默认属性。这为程序设计者提供了灵活性，允许根据需要自行配置互斥锁的行为。 在使用后，需要销毁互斥锁，使用 pthread_mutex_destroy()，其 API 定义如下： int pthread_mutex_destroy(pthread_mutex_t *mutex); 销毁互斥锁的过程释放了其占用的资源，然而，在 Linux 中，互斥锁本身并不占用任何实际资源，因此 pthread_mutex_destroy() 主要用于检查锁的状态，如果锁处于已锁定状态，函数返回 EBUSY 错误。 2. 互斥锁属性互斥锁的属性设定在创建锁时进行。在 LinuxThreads 的实现中，主要有一种锁类型属性。不同的锁类型，在已经被锁定的互斥锁上加锁时会体现出不同的行为。 当前（以 glibc 2.2.3 和 linuxthreads 0.9 为例），可供选择的锁类型有： PTHREAD_MUTEX_TIMED_NP：这是默认的锁类型，表现为普通锁。当一个线程成功加锁后，其他请求该锁的线程会进入等待队列，解锁后线程将按优先级获取锁。这种锁策略能够保证资源分配的公平性，有助于避免饥饿现象。 PTHREAD_MUTEX_RECURSIVE_NP：该类型允许同一线程对同一锁多次加锁，需要通过多次解锁来释放。如果其他线程请求锁时，该锁仍被加锁，则它们必须竞争锁。 PTHREAD_MUTEX_ERRORCHECK_NP：这种类型用于错误检查。如果同一线程尝试请求同一锁，将返回 EDEADLK 错误，确保在不允许多次加锁的场景中不会出现最基本的死锁。 PTHREAD_MUTEX_ADAPTIVE_NP：这种锁类型行为简单，允许线程在解锁后重新竞争。 3. 锁操作锁的基本操作包括加锁、解锁和尝试加锁，具体函数如下： int pthread_mutex_lock(pthread_mutex_t *mutex);int pthread_mutex_unlock(pthread_mutex_t *mutex);int pthread_mutex_trylock(pthread_mutex_t *mutex); 对于各类锁，不能被两个不同线程同时获得。对于普通锁和适应锁，解锁可以由同进程内的任何线程执行。相对而言，检错锁则必须由加锁的线程进行解锁，如果由不同的线程尝试解锁，则返回 EPERM 错误。嵌套锁的解锁规定虽然是由加锁者执行，但观察到实验过程中并未强制执行这一限制。在同一进程中的线程若加锁而没有解锁，其他线程无法获取该锁。 pthread_mutex_trylock() 与 pthread_mutex_lock() 的行为相似，但当锁已被占用时，将返回 EBUSY，而不是挂起等待。这提供了一种非阻塞的方式来尝试获取锁。 4. 其他注意事项POSIX 线程锁机制在 Linux 的实现中并不是取消点，意味着延迟取消类型的线程不会因取消信号而退出加锁状态。需要注意的是，如果线程在加锁后但未解锁前被取消，该锁将保持锁定状态。因此，如果在关键区段内有取消点，此时可导致潜在死锁场景，因此建议在退出回调函数中执行解锁操作。 同时，互斥锁的使用并不具备异步信号安全，故不应在信号处理过程中访问互斥锁，以免引发死锁问题。互斥锁通过确保同一时间内仅有一个线程执行临界段代码，从而有序执行多个线程的操作，有效保护数据的安全性。 有关更改默认互斥锁属性，可通过声明和初始化属性对象来实现。通常，这在程序的开头进行，以便快速查找和修改。以下是管理互斥锁属性的相关函数： 表 4–1 互斥锁属性相关函数 操作 函数 初始化互斥锁属性对象 pthread_mutexattr_init 销毁互斥锁属性对象 pthread_mutexattr_destroy 设置互斥锁范围 pthread_mutexattr_setpshared 获取互斥锁范围 pthread_mutexattr_getpshared 设置互斥锁的类型属性 pthread_mutexattr_settype 获取互斥锁的类型属性 pthread_mutexattr_gettype 设置互斥锁属性的协议 pthread_mutexattr_setprotocol 获取互斥锁属性的协议 pthread_mutexattr_getprotocol 设置互斥锁的优先级上限 pthread_mutexattr_setprioceiling 获取互斥锁的优先级上限 pthread_mutexattr_getprioceiling 设置互斥锁的优先级上限 pthread_mutex_setprioceiling 获取互斥锁的优先级上限 pthread_mutex_getprioceiling 设置互斥锁的强健属性 pthread_mutexattr_setrobust_np 获取互斥锁的强健属性 pthread_mutexattr_getrobust_np 表 4–2 互斥锁范围比较 Solaris POSIX 定义 USYNC_PROCESS PTHREAD_PROCESS_SHARED 用于同步该进程与其他进程中的线程 USYNC_PROCESS_ROBUST 无 用于在进程间可靠地同步线程 USYNC_THREAD PTHREAD_PROCESS_PRIVATE 用于仅同步该进程中的线程 初始化互斥锁属性对象使用 pthread_mutexattr_init(3C) 函数可以将互斥锁对象的属性初始化为默认值。这一步骤至关重要，因为它确保线程系统为每个属性对象分配必要的存储空间，从而使得互斥锁的使用更为高效和安全。 pthread_mutexattr_init 语法#include pthread.hpthread_mutexattr_t mattr;int ret;ret = pthread_mutexattr_init(mattr); 在调用 pthread_mutexattr_init() 函数时，可以注意到，pshared 属性的默认值是 PTHREAD_PROCESS_PRIVATE。这一属性意味着创建的互斥锁是只在同一进程内有效的。例如，如果一个应用程序的多个线程需要协调资源，它们可以通过这种类型的互斥锁进行相互排斥，确保同一时刻只有一个线程可以访问共享资源。 mattr 是一个类型为 opaque 的结构，内部包含由系统分配的属性对象。此属性对象的可能值有： PTHREAD_PROCESS_PRIVATE：互斥锁适用于同一进程内。 PTHREAD_PROCESS_SHARED：互斥锁可以被多个进程共享，适用于需要跨进程通信的复杂场景。 请注意，PTHREAD_PROCESS_PRIVATE 是默认值，适用于大多数简单的多线程应用。 销毁互斥锁属性对象对于互斥锁属性对象，必须首先通过调用 pthread_mutexattr_destroy(3C) 函数将其销毁，才能重新初始化该对象。这意味着在完成使用后，务必要记得清理资源，以避免潜在的内存泄漏。调用 pthread_mutexattr_init() 时，会为该对象分配一个 opaque 类型的内存。若未及时销毁旧对象，就会导致内存资源的浪费，从而可能影响程序的性能。 pthread_mutexattr_init 返回值调用 pthread_mutexattr_init() 函数成功后，返回值为零。若函数未能成功执行，则返回一个非零值，表示发生了错误。以下是可能导致函数调用失败的一些情况： ENOMEM： 描述：表示内存不足，无法初始化互斥锁属性对象。如果系统未能分配足够的内存空间来创建新的属性对象，调用将失败，这时需要检查系统的内存使用情况。 确保处理返回值和错误情况是一个良好的编程习惯，它可以帮助追踪和解决潜在的问题。 销毁互斥锁属性对象pthread_mutexattr_destroy(3C) 函数用于释放与 pthread_mutexattr_init() 创建的互斥锁属性对象相关的存储空间。这是多线程编程中一个重要的资源管理步骤，确保程序有效地释放不再需要的资源，以防止内存泄露和其他潜在的问题。 pthread_mutexattr_destroy 语法int pthread_mutexattr_destroy(pthread_mutexattr_t *mattr); 示例代码： #include pthread.hpthread_mutexattr_t mattr; // 定义互斥锁属性对象int ret;// 初始化属性对象pthread_mutexattr_init(mattr);// 一些操作...// 销毁属性对象ret = pthread_mutexattr_destroy(mattr); 在这个例子中，首先定义了一个 pthread_mutexattr_t 类型的变量 mattr，然后通过 pthread_mutexattr_init 进行初始化。在完成必要的多线程操作后，调用 pthread_mutexattr_destroy 来销毁属性对象。 pthread_mutexattr_destroy 返回值pthread_mutexattr_destroy() 在成功完成后返回零，这表示资源已成功释放。然而，如果返回值不是零，则表示出现了错误，这时需要进行适当的错误处理。可能导致函数失败的情况包括： EINVAL描述: mattr 指向的值无效。在调用 pthread_mutexattr_destroy 时，如果传入的属性对象未被正确初始化，或者已经被销毁，都会导致该错误出现。例如，如果尝试销毁一个尚未初始化的属性对象，程序将返回 EINVAL。 设置互斥锁的范围pthread_mutexattr_setpshared(3C) 用于定义互斥锁变量的作用域，这一属性对于多线程编程至关重要。在设计多线程应用时，合理设置互斥锁的范围可以确保线程之间的有效同步，从而避免数据竞态和不一致现象。 pthread_mutexattr_setpshared 语法int pthread_mutexattr_setpshared(pthread_mutexattr_t *mattr, int pshared); 在使用这一函数之前，需要包含 pthread.h 头文件。以下是一个简单的示例，展示如何初始化互斥锁属性并设置它的共享属性： #include pthread.hpthread_mutexattr_t mattr;int ret;// 初始化互斥锁属性ret = pthread_mutexattr_init(mattr);// 设置互斥锁为进程专用ret = pthread_mutexattr_setpshared(mattr, PTHREAD_PROCESS_PRIVATE); 在此示例中，互斥锁变量可以被两种类型的作用域使用： 进程专用（PTHREAD_PROCESS_PRIVATE）：如果设置为这个值，互斥锁仅限于由同一进程内创建的线程访问。以此值创建的锁无法由其他进程中的线程使用。 系统范围内（PTHREAD_PROCESS_SHARED）：若将 pshared 属性设置为 PTHREAD_PROCESS_SHARED，则互斥锁可以在多个进程中的线程之间共享。这通常涉及在共享内存区域中创建互斥锁，这一行为与早期 Solaris 线程实现中 mutex_init() 函数中的 USYNC_PROCESS 标志是等效的。 例如，当多个进程需要对同一资源进行访问和修改时，使用 PTHREAD_PROCESS_SHARED 类型的互斥锁能够避免潜在的并发问题，这对于数据库管理系统的多个客户端连接尤为重要。 pthread_mutexattr_setpshared 返回值pthread_mutexattr_setpshared() 函数在成功执行时会返回零，表明属性设置成功。其他返回值则表示发生了错误。以下是一些可能出现的错误及其原因： EINVAL：这个错误代码表示由 mattr 指定的值无效，通常发生在 mattr 未正确初始化或参数值不被支持的情况。例如，尝试传入一个不存在的共享属性类型时，系统会返回 EINVAL。 获取互斥锁的范围pthread_mutexattr_getpshared(3C) 用于获取由 pthread_mutexattr_setpshared() 定义的互斥锁变量的共享范围。这种互斥锁的使用范围决定了它们是应用于单个进程，还是可以在多个进程之间共享。 pthread_mutexattr_getpshared 语法int pthread_mutexattr_getpshared(pthread_mutexattr_t *mattr, int *pshared); 使用此函数时，首先需要包含 pthread.h 头文件。下面是一个简单的代码示例，展示了如何获取互斥锁属性的共享模式： #include pthread.hpthread_mutexattr_t mattr;int pshared, ret;// 假设已在其他地方设置了 mattr 的属性ret = pthread_mutexattr_getpshared(mattr, pshared); 上述代码中，mattr 是互斥锁的属性对象，pshared 将用于存储获取到的当前共享模式。pthread_mutexattr_getpshared 函数可以将互斥锁的共享模式值存储在 pshared 中，可能的值为 PTHREAD_PROCESS_SHARED 或 PTHREAD_PROCESS_PRIVATE。 PTHREAD_PROCESS_SHARED：表示可在多个进程之间共享该互斥锁。这种模式适合于需要在多个进程间进行同步的场景，例如，当多个独立的程序共享同一块内存区域时。 PTHREAD_PROCESS_PRIVATE：表示该互斥锁仅在创建它的进程内有效。这种模式通常用于单线程应用程序或多线程应用程序内的线程同步。 pthread_mutexattr_getpshared 返回值当 pthread_mutexattr_getpshared() 函数成功执行后，会返回零。任何非零的返回值则表示出现错误。以下是几个可能的错误情况及其说明： EINVAL： 该错误码意味着由 mattr 指定的值无效。这通常发生在 mattr 没有被正确初始化或不符合预期的情况下。例如，如果 mattr 没有设置为有效的互斥锁属性对象，调用该函数时就会返回此错误。在这种情况下，应确保在调用获取共享模式之前，首先用相应函数初始化互斥锁属性。 设置互斥锁类型的属性pthread_mutexattr_settype(3C)该函数用于设置互斥锁的 type 属性，以便为特定多线程应用程序配置互斥锁的行为。选择合适的互斥锁类型能够帮助确保线程安全，从而有效地避免潜在的竞争条件和资源管理问题。 pthread_mutexattr_settype 语法#include pthread.hint pthread_mutexattr_settype(pthread_mutexattr_t *attr, int type); 默认值: 没有显式设置的情况下，类型属性的缺省值为 PTHREAD_MUTEX_DEFAULT。 type 参数详解type 参数指定互斥锁的具体类型。以下是有效的互斥锁类型及其详细描述： PTHREAD_MUTEX_NORMAL 描述: 这种类型的互斥锁不会检测死锁情况。如果一个线程试图在未解除互斥锁的情况下再次锁定该互斥锁，程序可能会陷入死锁。此类互斥锁解除时，若当前锁定是由其他线程完成的，则会导致不确定行为。同时，若线程尝试解除一个未被锁定的互斥锁，也会出现不确定行为。例如，如果线程 A 锁定了一个互斥锁，而线程 B 尝试在没有先解除锁的情况下再次锁定该互斥锁，线程 B 将会被阻塞，从而造成程序无法继续执行。 PTHREAD_MUTEX_ERRORCHECK 描述: 此类型提供了更安全的错误检查。尝试重新锁定已经由自身线程锁定的互斥锁时，函数将返回错误。若线程尝试解除由其他线程锁定的互斥锁，或解除未锁定状态的互斥锁，同样会返回错误。例如，如果线程 C 锁定了互斥锁而线程 D 试图对同一锁进行解除，将引发错误，避免潜在的逻辑漏洞和死锁。 PTHREAD_MUTEX_RECURSIVE 描述: 这种类型允许线程在尚未解除锁的情况下再次成功锁定该互斥锁。与 PTHREAD_MUTEX_NORMAL 类型不同，尝试重新锁定不会造成死锁。为释放该锁，必须进行同等次数的解除锁定，随后其他线程才能获取该互斥锁。若线程试图解除的互斥锁由其他线程锁定，或未被锁定，同样会返回错误。例如，假设线程 E 锁定了一个互斥锁，然后再次尝试锁定，这时将保持对该锁的控制，但必须在解除锁定 N 次后，其他线程才能访问该互斥锁。 PTHREAD_MUTEX_DEFAULT 描述: 这种类型在尝试递归锁定时会出现不确定行为。如果线程想要对一个不是自己锁定的互斥锁解除锁定，则将导致不稳定状态。若此互斥锁还未被锁定，同样会导致不确定行为。这种类型允许实施将其映射到其他互斥锁类型的实现。例如，在 Solaris 线程环境中，PTHREAD_MUTEX_DEFAULT 将被映射为 PTHREAD_MUTEX_NORMAL，提供默认行为。 pthread_mutexattr_settype 返回值 函数执行成功时返回零；如果出现错误则返回错误号，以下是可能的错误： EINVAL: 描述: 此错误表明传入的 type 值无效，可能是因为所传递的类型不在定义的类型列表中。 EINVAL: 描述: 此错误表示 attr 指定的值不符合预期，可能是未正确初始化互斥锁属性对象。确保在调用前正确创建并初始化 pthread_mutexattr_t 类型的变量。 获取互斥锁的类型属性pthread_mutexattr_gettype(3C) 函数用于获取由 pthread_mutexattr_settype() 设置的互斥锁的类型属性。这对于多线程编程中的同步机制至关重要。 pthread_mutexattr_gettype 语法#include pthread.hint pthread_mutexattr_gettype(pthread_mutexattr_t *attr, int *type); 参数说明 attr：指向互斥锁属性对象的指针。这个对象是在调用 pthread_mutexattr_init() 后创建的，包含了互斥锁的各种属性设置。 type：指向整数的指针，用于接收互斥锁的类型。 可用的互斥锁类型以下是 type 参数可以设置的有效互斥锁类型： PTHREAD_MUTEX_NORMAL这种类型的互斥锁不检查其归属，且若同一线程两次尝试获取同一互斥锁，行为是未定义的。适用于不需要严格错误检查的场景。 PTHREAD_MUTEX_ERRORCHECK这种类型的互斥锁提供错误检查。如果同一线程试图再次获取已经被锁定的互斥锁，函数会返回错误。这种类型在需要避免死锁的多线程环境中非常有用，特别是在复杂的系统中，可以减少潜在的编程错误。 PTHREAD_MUTEX_RECURSIVE此类型允许同一线程多次获取同一互斥锁，每次获取都必须对应一个释放。内核会跟踪锁的获取次数，确保线程可以安全地重复锁定。这种类型适用于当一个线程需要在调用深层函数时连续获取同一锁的情况。 PTHREAD_MUTEX_DEFAULT使用此类型将会得到与 PTHREAD_MUTEX_NORMAL 相同的行为。它被视为一个平台特定的默认选项。 有关每种类型的详细说明，请参阅 pthread_mutexattr_settype 函数的语法和相应文档。 pthread_mutexattr_gettype 返回值 如果调用成功，pthread_mutexattr_gettype() 函数返回值为 0，表示成功完成任务。 如果返回值为其他任意数，从而导致函数的执行失败，则表示出现了错误。这对于调试和错误处理至关重要，开发者可以通过检查返回值来确定属性的获取是否成功，并据此采取适当的处理措施。 设置互斥锁属性的协议pthread_mutexattr_setprotocol(3C) 函数用于设置互斥锁属性对象的协议属性，以便控制锁的行为。例如，某些复杂的多线程应用程序可能需要防止优先级倒置这一现象，使用合适的协议可以帮助实现这一目标。 pthread_mutexattr_setprotocol 语法#include pthread.hint pthread_mutexattr_setprotocol(pthread_mutexattr_t *attr, int protocol); attr：指向互斥锁属性对象的指针，该对象通常在之前调用 pthread_mutexattr_init() 时创建。 protocol：指定要应用于互斥锁属性对象的协议，可以是以下值之一： 协议类型PTHREAD_PRIO_NONE当设置为 PTHREAD_PRIO_NONE 时，线程的优先级和调度将不受互斥锁的拥有权影响。这意味着无论哪个线程持有锁，其调度和优先级都不受干扰。这在一些基本的场景中是有效的，但可能导致更高优先级的线程在等待低优先级线程释放锁时被阻塞，造成效率降低。 PTHREAD_PRIO_INHERIT使用 PTHREAD_PRIO_INHERIT 协议时，线程的优先级会受到影响。例如，假设有一个线程 thrd1 持有一个互斥锁，而另一个高优先级线程（如 thrd2）试图获取这个锁。当 thrd2 被阻塞时，thrd1 的调度会被提升到 thrd2 的优先级，这样可以防止优先级倒置的发生。 例如，假设线程 thrd1 是优先级为 10 的低优先级线程，而 thrd2 是优先级为 20 的高优先级线程，thrd2 想要获取 thrd1 的锁。若采用 PTHREAD_PRIO_INHERIT，thrd1 将被提升到优先级 20，优先级的提升允许 thrd1 更快地释放锁，从而避免高优先级线程长时间等待。 当某个互斥锁的属主失败（即出现崩溃等情况），被标记为 _POSIX_THREAD_PRIO_INHERIT 的互斥锁将执行特殊处理，确保资源在属主昏迷后的状态得到恢复。 PTHREAD_PRIO_PROTECT设置为 PTHREAD_PRIO_PROTECT 时，线程在拥有的互斥锁期间，即使其他线程的优先级提高，也不会影响当前线程的调度。这种设计允许线程在持有重要资源时保持其优先级。例如，一个监控线程可能需要在时刻保持较高的响应性，即使其他任务的优先级增加，它也不会被调度到执行队列的末端。 pthread_mutexattr_setprotocol 返回值如果函数成功执行，将返回 0，表示属性已经成功设置。如果返回值不是零，则表明出现错误。可能的错误代码包括： ENOSYS：当前实现不支持该函数，原因可能是选项 _POSIX_THREAD_PRIO_INHERIT 和 _POSIX_THREAD_PRIO_PROTECT 未定义。 ENOTSUP：指定的 protocol 值在当前实现中不受支持。 EINVAL：无效的 attr 或 protocol 指定值。 EPERM：调用该函数的线程没有相应的权限。 获取互斥锁属性的协议pthread_mutexattr_getprotocol(3C) 是一个重要的函数，用于获取互斥锁属性对象的协议。这对于多线程编程中的资源竞争处理至关重要，确保线程安全和优先级管理。 pthread_mutexattr_getprotocol 语法#include pthread.hint pthread_mutexattr_getprotocol(const pthread_mutexattr_t *attr, int *protocol); 参数说明： attr：这是一个指向之前通过 pthread_mutexattr_init() 创建的互斥锁属性对象的指针。这个对象包含了各种互斥锁的配置选项，允许程序员自定义相应的行为。 protocol：这是一个指向存储协议属性的整数指针，调用成功后，相关的协议值会被写入此内存位置。 协议属性： PTHREAD_PRIO_NONE：表示互斥锁没有优先级继承策略。 PTHREAD_PRIO_INHERIT：此值表明互斥锁支持优先级继承，低优先级的线程在持有互斥锁时，其优先级将提升为持有锁的高优先级线程的优先级。 PTHREAD_PRIO_PROTECT：此值表示互斥锁保护高优先级线程，防止低优先级线程的干扰。 pthread_mutexattr_getprotocol 返回值 成功：如果执行成功，pthread_mutexattr_getprotocol() 将返回 0，这表示该函数调用正常完成，互斥锁的协议属性已获得。 错误情况： ENOSYS：说明 _POSIX_THREAD_PRIO_INHERIT 和 _POSIX_THREAD_PRIO_PROTECT 选项都未定义。这通常出现在某些平台或实现不支持这些功能的情况下。例如，在某些简单或旧的嵌入式操作系统中，线程优先级管理可能未实现。 EINVAL：当提供的 attr 参数无效时返回。例如，如果该指针未正确初始化，或指向的内存区域被破坏，这将导致函数无法正确获取协议属性。 EPERM：当调用方没有足够的权限执行该操作时返回此值。这可能发生在尝试从不拥有锁的上下文中获取属性时，确保权限检查的一致性。 设置互斥锁属性的优先级上限pthread_mutexattr_setprioceiling(3C) 是一个函数，用于设置互斥锁属性对象的优先级上限。这对于确保在多线程环境中的资源访问安全至关重要。 pthread_mutexattr_setprioceiling 语法#include pthread.hint pthread_mutexattr_setprioceiling(pthread_mutexattr_t *attr, int prioceiling, int *oldceiling); attr: 指向在调用 pthread_mutexattr_init() 时创建的互斥锁属性对象的指针。这个属性对象包含了互斥锁的各种候选设置，允许开发者根据需要进行定制。 prioceiling: 指定已初始化互斥锁的优先级上限。优先级上限定义了在执行互斥锁保护的临界段时，线程必须达到的最低优先级。这一设置是确保在高优先级线程需要访问资源的情况下，不会被低优先级线程阻塞的有效方法。例如，若有多个线程竞争同一锁，设置合适的优先级上限可以防止线程优先级降低，从而避免优先级反转问题。 oldceiling: 一个指向整数的指针，用于存放之前设置的优先级上限值。这在需要恢复原来的设置时非常有用。 pthread_mutexattr_setprioceiling 返回值如果 pthread_mutexattr_setprioceiling() 成功执行，则返回 0；任何其他值则表示遇到错误。处理这些错误信息对于调试非常重要，理解错误的根源能够帮助开发者调整代码。 可能的错误信息 ENOSYS描述: 该选项 _POSIX_THREAD_PRIO_PROTECT 未定义，意味着该实现不支持此函数。通常发生在某些系统环境中，它们未遵循所有的 POSIX 线程特性。 EINVAL描述: 提供的 attr 或 prioceiling 值无效。这可能是因为指向的互斥锁属性对象不存在或未初始化，或是优先级上限超出了允许的范围。例如，如果设定了一个小于最低所需优先级的值，系统会拒绝这一设置。 EPERM描述: 调用方无权执行该操作。这种情况可能发生在尝试设置一个锁的属性，但当前线程并不具有更改该锁属性的权限时，常见于线程不具备足够的访问权限。 获取互斥锁属性的优先级上限pthread_mutexattr_getprioceiling(3C) 是一个函数，用于获取互斥锁属性对象中的优先级上限属性。这个属性对于多线程编程至关重要，因为它帮助避免优先级倒置现象，确保关键资源在高优先级的线程之间能够有效管理。 pthread_mutexattr_getprioceiling 语法#include pthread.hint pthread_mutexattr_getprioceiling(const pthread_mutexattr_t *attr, int *prioceiling); attr：指向以前通过调用 pthread_mutexattr_init() 初始化的属性对象的指针。 prioceiling：这是一个输出参数，用于返回已设置的互斥锁的优先级上限。 注为了使 attr 互斥锁属性对象包括优先级上限属性，必须定义 _POSIX_THREAD_PRIO_PROTECT 符号。如果该符号未定义，则该特性将不可用。 调用 pthread_mutexattr_getprioceiling() 后，prioceiling 将保存互斥锁的优先级上限。这个优先级上限确定了在执行互斥锁保护的临界段时的最低允许优先级。因此，要有效地管理线程之间的资源竞争，确保设置的 prioceiling 至少要高于将潜在锁定该互斥锁的所有线程的最高优先级，通常这些优先级在 SCHED_FIFO 的定义范围内。 pthread_mutexattr_getprioceiling 返回值 如果函数调用成功，pthread_mutexattr_getprioceiling() 将返回 0。 如果返回其他值，则表示出现错误，调用方需要调查问题的原因。 可能返回值的具体描述 ENOSYS 描述： 如果 _POSIX_THREAD_PRIO_PROTECT 选项未定义，该实现不支持此函数，导致调用失败。 EINVAL 描述： 如果传入的 attr 参数指向的值无效，函数将返回此错误。 EPERM 描述： 如果调用方没有执行该操作的权限，函数将返回此错误。 设置互斥锁的优先级上限pthread_mutexattr_setprioceiling(3C)此函数用于设置互斥锁的优先级上限，以确保当多个线程同时请求该锁时，优先级较高的线程能够优先获得锁。这对于实时系统尤为重要，避免高优先级线程被低优先级线程阻塞。 pthread_mutex_setprioceiling 语法#include pthread.hint pthread_mutex_setprioceiling(pthread_mutex_t *mutex, int prioceiling, int *old_ceiling); 该函数的主要目的是更改指定互斥锁 mutex 的优先级上限，修改为 prioceiling 所指定的值。 函数详细说明 锁定互斥锁：在调用 pthread_mutex_setprioceiling 时，如果互斥锁未被锁定，函数将尝试锁定它。如果互斥锁已经被其他线程锁住，该调用将会阻塞，直到锁被释放并成功锁定。 优先级保护协议：在锁定过程中，不需要遵循任何优先级保护协议，这意味着即使高优先级线程在等待锁，低优先级线程仍然可以持有该锁并继续执行。 返回旧的优先级上限：如果 pthread_mutex_setprioceiling 成功执行，它会将旧的优先级上限值写入 old_ceiling 参数中，方便后续的管理和调试。 保持不变的优先级上限：如果该函数执行失败，互斥锁的优先级上限值将不会发生变化，保持原有状态以确保系统稳定性和预期的行为。 pthread_mutex_setprioceiling 返回值 返回值为 0：表示优先级上限成功更改。 其他返回值：表示遇到错误。调用者需要根据返回值采取适当的措施。 可能的错误及其描述 ENOSYS描述：选项 _POSIX_THREAD_PRIO_PROTECT 未定义，且该实现不支持此函数。这意味着当前系统不支持设定互斥锁的优先级上限特性。 EINVAL (优先级无效) 描述：请求的 prioceiling 超出了允许的优先级范围，调用者需要确认采用的优先级在系统允许的范围内。 描述：指定的 mutex 变量并未引用当前存在的互斥锁。这可能因为该互斥锁尚未初始化或已经被销毁。 ENOSYS (功能未实现)描述：在该系统实现中，互斥锁的优先级上限协议不可用。这限制了线程的优先级控制能力。 EPERM (权限不足)描述：调用方没有足够的权限进行该操作，可能是由于互斥锁由另一个线程持有，而该线程没有足够的权限修改优先级设置。 获取互斥锁的优先级上限pthread_mutexattr_getprioceiling(3C) 函数用于获取互斥锁的优先级上限。这对于确保在多线程环境中，某个线程在 Higher Priority Mutex 被锁住时不会出现优先级反转（Priority Inversion）问题至关重要。 pthread_mutex_getprioceiling 语法#include pthread.hint pthread_mutex_getprioceiling(const pthread_mutex_t *mutex, int *prioceiling); 该函数的作用是返回指定互斥锁的优先级上限，通过指针参数 prioceiling 传递。互斥锁的优先级上限是用于调节线程调度的一个关键参数，有助于提升系统的响应速度和稳定性。 pthread_mutex_getprioceiling 返回值如果函数成功完成，返回值为 0，这表明函数执行没有错误。如果返回值是其他任何数值，表示出现了错误。 常见错误及其含义 ENOSYS 描述: _POSIX_THREAD_PRIO_PROTECT 选项未定义，这意味着当前实现不支持该函数。这种情况通常出现在一些较为基础的或老旧的操作系统和库中。 EINVAL 描述: mutex 指定的值并未引用当前存在的互斥锁。这通常是由于传递的指针无效或已被销毁，导致无法检索到正确的互斥锁状态。确保在调用前 mutex 是有效的，并且在多线程环境中未被意外释放。 ENOSYS 描述: 当前实现不支持互斥锁的优先级上限协议。在某些特定的实现中，该功能可能未被实现，这需要查阅相关文档以确认所使用的系统或库的功能支持状况。 EPERM 描述: 调用方没有执行该操作的权限。如果当前线程没有足够的权限去获取互斥锁的优先级上限，则会出现此错误。具体的权限要求可能取决于系统的安全策略。确保所调用的线程拥有足够的权限来执行相关操作是非常重要的。 设置互斥锁的强健属性pthread_mutexattr_setrobust_np(3C) 用于设置互斥锁属性对象的强健属性，以增强多线程程序在处理资源时的稳定性和安全性。 pthread_mutexattr_setrobust_np 语法#include pthread.hint pthread_mutexattr_setrobust_np(pthread_mutexattr_t *attr, int *robustness); 注：仅当符号 _POSIX_THREAD_PRIO_INHERIT 被定义时，pthread_mutexattr_setrobust_np() 才适用。 attr：一个指向通过调用 pthread_mutexattr_init() 创建的互斥锁属性对象的指针。 robustness：定义在互斥锁属主失败时的行为。pthread.h 中定义了两种可能的 robustness 值： PTHREAD_MUTEX_ROBUST_NP PTHREAD_MUTEX_STALLED_NP 默认值为 PTHREAD_MUTEX_STALLED_NP。 PTHREAD_MUTEX_ROBUST_NP如果互斥锁的属主由于故障而失效，则在后续调用 pthread_mutex_lock() 时，所有调用将以不确定的方式被阻塞。这意味着其他线程在尝试获取该互斥锁时可能会陷入等待状态，直到获得锁或超时。此行为确保了即使属主线程在执行中出现问题，系统依然能够掌控资源的安全性。 PTHREAD_MUTEX_STALLED_NP在互斥锁的属主失效的情况下，互斥锁将被解锁，新的属主将获取该互斥锁，并返回错误 EOWNERDEAD。这意味着新的属主在获取锁时会观察到前一个属主的失效，程序需要对此进行相应的处理。示例代码如下： if (pthread_mutex_lock(mutex) == EOWNERDEAD) // 处理属主失效的情况 注：应用程序必须检查 pthread_mutex_lock() 的返回值，特别是查找返回错误 EOWNERDEAD 的情况。新的属主应确保在访问互斥锁保护的数据时保持状态一致性。由于上一个属主的失效，互斥锁保护的状态可能会变得不一致。 如果新的属主能够使状态保持一致，应该使用 pthread_mutex_consistent_np() 来确认互斥锁的状态一致，然后正常解锁。例如： pthread_mutex_consistent_np(mutex);pthread_mutex_unlock(mutex); 如果新的属主无法确保一致性，则不应调用 pthread_mutex_consistent_np()，只需解除锁定该互斥锁。所有等待的线程都会被唤醒，之后的所有 pthread_mutex_lock() 调用都将返回错误 ENOTRECOVERABLE。为恢复互斥锁的正常工作状态，可通过调用 pthread_mutex_destroy() 来破坏互斥锁，然后再通过调用 pthread_mutex_init() 重新初始化该互斥锁。 如果已经获取该锁的线程由于故障返回 EOWNERDEAD，这将导致下一个属主在尝试获取该锁时同样返回 EOWNERDEAD，进一步确保多线程环境的健壮性。 pthread_mutexattr_setrobust_np 返回值如果函数成功执行，pthread_mutexattr_setrobust_np() 将返回 0。 любые其他返回值都表明出现了错误。 以下是可能导致函数失败的错误及其描述： ENOSYS：表示选项 _POSIX_THREAD_PRIO_INHERIT 未定义，或者该实现不支持 pthread_mutexattr_setrobust_np()。 ENOTSUP：表示 robustness 指定的值不受支持。 EINVAL：表示 attr 或 robustness 指定的值无效。","categories":["2.语言","C语言","多线程"]},{"title":"文件IO","path":"/2024/06/07/1-平台-Linux-IO-文件IO/","content":"文件 IO文件描述符 进程的概念文件输入输出的过程涉及从硬盘到内存再到 CPU 的动态数据流转。每当一个进程需要访问文件时，操作系统负责协调这个过程。 唯一性在每个进程内部，每个打开的文件都对应于内核管理的一块特定区域。这个区域确保在同一时刻，一个进程内的文件描述符是唯一的，不会与其他进程的文件描述符发生冲突。 整型值内核会为用户分配一个整型值，这个值是用来告诉内核将要操作的具体文件。这种设计使得文件操作能够简化为通过描述符来标识文件。 默认值当进程第一次请求文件描述符时，系统会使用当前可用的最小值进行分配。通常情况下，这些默认值从 0 开始，通常包括标准输入（0）、标准输出（1）和标准错误（2）等。 缺省文件描述符 硬件设备映射每个文件描述符实际上映射到一个硬件设备，如终端、网络连接或者存储设备。这意味着底层操作能够直接与硬件通信。 系统默认打开的文件操作系统在启动时会打开一些文件描述符以供使用，例如，控制台输入和输出。这样程序在运行时能够及时接收和显示数据。 文件 IO API编程接口提供了一系列用于文件操作的函数： 打开文件 fp = open(pathname, flag);fp = open(pathname, flag, mode); 其中，pathname 是文件的路径，flag 是打开文件的选项（如只读、可写等），而 mode 用于指定新文件的权限（在创建文件时）。 读取与写入 ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, const void *buf, size_t count); read 函数从指定的文件描述符 fd 中读取最多 count 字节的数据到 buf 中。 write 函数则将 buf 中的 count 字节数据写入到指定的文件描述符 fd。 关闭文件 close(fd); 关闭指定的文件描述符 fd，释放系统资源。 文件偏移 lseek(); 该函数用于在文件中更改读写位置，实现对“空洞文件”的支持，使得可以高效地跳过未使用的区域。 文件和目录文件属性 获取文件信息使用以下几种方法可以获取文件的属性： stat(pathname, struct stat p);fstat(int fd, ....);lstat(.., ....); 这些函数能返回文件的详细信息，包括大小、权限、修改时间等。 用户和组信息通过以下函数获取用户和组的信息： getpwuid(); // 根据 uid 获取用户信息getgrgid(); // 根据 gid 获取组信息 这些函数能根据用户 ID 和组 ID 返回相应的结构体信息，包含用户名和组名等。 时间处理使用 localtime() 函数可以将时间戳转换为本地时间格式，便于人类可读性。 结构体定义在处理文件和目录时，通常需要用到几个重要的结构体: 文件信息结构体struct stat ... ; 用于保存文件的元数据。 用户信息结构体struct passwd ; 用于保存用户的信息。可以通过 pw = getpwuid(sb.st_uid); 获取用户的详细信息。 组信息结构体struct group ; 用于保存组的信息，提供组名和组成员信息。 时间结构体struct tm ; 用于日期和时间的表示与处理。 文件夹操作 打开目录 DIR *opendir(); 读取目录项 struct dirent * readdir(); 关闭目录 closedir(); 目录项结构体struct dirent ; 包含目录项的各类信息，如文件名等。 拓展 短参数获取 getopt(); // 用于获取短参数，例如执行命令 ls -la 文件权限和存在性检查 access(); // 检查文件是否存在以及用户对文件的权限 改变当前工作目录 chdir(); // 改变进程的当前工作目录 这些函数和结构体为文件和目录的管理提供了基本的工具，使得开发者能够高效地进行文件操作。","categories":["1.平台","Linux","IO"]},{"title":"切换开销","path":"/2024/06/06/2-语言-C语言-多线程-切换开销/","content":"进程屏蔽了 CPU 调度、内存管理等底层硬件细节，从而定义了一个简单易懂的概念，让应用程序能够更专心地实现自己的业务逻辑。这样一来，多个进程在有限的 CPU 资源上可以”同时”执行多个任务，比如同时响应成千上万的用户请求。然而，这种便利性也伴随着额外的开销。以下图示例为例，在一个进程得以运行的时间里，CPU 虽然忙于事务，却可能并未完成任何实际的用户工作，这正是进程机制带来的额外开销。 当进程 A 切换到进程 B 时，系统会先保存进程 A 的上下文信息，以确保其未来恢复时能够继续执行下一条指令。接着，系统会将进程 B 的上下文恢复到 CPU 寄存器中。这个过程称为上下文切换。上下文切换的开销在进程数量较少且切换频率不高的场景下问题不大，但在现代 Linux 操作系统中，随着高并发网络程序后端服务器的普及，这一开销变得不容忽视。在单台机器上支持成千上万个用户请求时，进程在执行网络 IO 操作（如访问 Redis 或 MySQL）时或当时间片耗尽时，都会触发上下文切换。 为了直观了解一次上下文切换需要多长时间，让们进行一个实验。实验方法是创建两个进程，互为令牌的发送者和接收者。其中一个进程在接收令牌时会引发阻塞，而另一个进程在发送令牌后等待其被接收时也处于阻塞状态。们可以统计经过一定次数往返传送后的平均单次切换时间开销。实验代码见 test04： # gcc main.c -o main# ./main 在实验运行后，们得到如下结果： Before Context Switch Time: 1565352257 s, 774767 usAfter Context Switch Time: 1565352257 s, 842852 us 经过多次运行，们发现平均每次上下文切换耗时约为 3.5 微秒。值得注意的是，这一数值会因具体机器配置和负载而有所差异，因此建议在实际机器上进行测试。之前测试系统调用时，最低值是 200 纳秒，因此可以明显看出上下文切换的开销比系统调用更为显著。系统调用仅需在用户态和内核态之间切换，而上下文切换则需要进行进程间的切换，工作量显然更大。 上下文切换的开销来源上下文切换时，CPU 的开销可分为直接开销和间接开销。 直接开销：在上下文切换过程中，CPU 必须完成的操作，包括： 切换页表全局目录 切换内核态堆栈 切换硬件上下文（在恢复进程前，必须将数据加载到寄存器中） **ip (instruction pointer)**：指向当前执行的下一条指令 **bp (base pointer)**：栈帧的栈底地址 **sp (stack pointer)**：栈帧的栈顶地址 cr3：页目录基址寄存器，保存页目录表的物理地址 刷新 TLB（Translation Lookaside Buffer） 执行系统调度器代码 间接开销：即便切换到了新进程，由于缓存热度下降，运行速度往往会减缓。这种影响特别明显当进程跨 CPU 切换时，因为原先在缓存（如 L1、L2、L3）中热度高的代码和数据，随着进程的切换会失效，从而增加了内存 IO 的开销。们的实验对这种间接开销的测量并不理想，实际上下文切换的开销可能会大于 3.5 微秒。 对于想深入了解更多的同学，可以参考《深入理解 Linux 内核》中的相关章节。 尝试使用专业测试工具 - lmbenchlmbench 是一款开源的基准测试工具，旨在评估系统性能，包括文档读写、内存操作、进程创建与销毁开销，以及网络性能等。其操作方法简单，但有时候运行速度较慢，感兴趣的同学可以自行尝试。这个工具的优势在于进行多组实验，分别对 2 个、8 个、16 个进程进行测试，使用不同大小的数据，能较好地模拟缓存未命中的情况。 使用 lmbench 测试后得到如下结果： Host OS 2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64Kctxsw ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw -----------------------------------------------------------------------bjzw_46_7 Linux 2.6.32- 2.7800 2.7800 2.7000 4.3800 4.0400 4.75000 5.48000 从 rsyslog 的数据来看，进程上下文切换耗时在 2.7 微秒到 5.48 微秒之间。 线程上下文切换耗时接下来们测试 Linux 下的线程，以确定其切换是否比进程更迅速。实际上在 Linux 中并不存在真正的线程，其实是为开发者实现的轻量级进程，这种进程与普通进程相比，虽有独立的 task_struct 进程描述符和 pid，却可以共享内存地址空间、代码段、全局变量以及打开的文件集合。因此，同一进程下的线程调用 getpid() 时显示的 pid 是相同的，其实 task_struct 中还有一个 tgid 字段，意味着多线程程序的线程实际上是共享某个特定进程的标识符。 们再次进行实验，代码见 test06。实验原理与进程测试类似，创建 20 个线程，使用管道互传信号。接收到信号后，线程会被唤醒，并传递信号给下一个线程，而自己则进入睡眠状态。实验中统计了管道传递信号的额外开销。 # gcc -lpthread main.c -o main 实验结果显示为： 0.508250 4.363495 经过多次实验后，线程切换的平均耗时大约为 3.8 微秒。从上下文切换的耗时上来看，Linux 下的线程（即轻量级进程）与进程的切换差异不大。 Linux 类相关命令既然们清楚了上下文切换带来的 CPU 时间消耗，何不利用一些工具观察 Linux 系统中的上下文切换情况呢？如果上下文切换对整体性能造成影响，们也许可以识别问题的进程并作相应优化。 利用以下命令： # vmstat 1 可以输出系统当前的进程状态、内存使用情况等信息。 procs -----------memory---------- --swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st ... 另外，可以用以下命令获取每秒的上下文切换信息： # sar -w 1 此命令将展示一段时间内的进程创建次数及上下文切换次数。例如： proc/s cswch/s 11:19:20 AM proc/s cswch/s... 在实验环境中，这台配置为 8 核 8G 的 KVM 虚拟机，上面运行的是 nginx + fpm（数量为 1000），每秒平均处理的用户请求约 100 左右。其中 cswch 列指示了在 1 秒内系统发生的上下文切换次数，达到大约 4 万次。这意味着每个 CPU 在 1 秒内产生约 5 千次的上下文切换，每秒消耗近 20 毫秒用于上下文切换。 为了更深入了解频繁上下文切换的源头，们可以使用以下命令： # pidstat -w 该命令会显示各个进程的上下文切换情况，如下表所示： PID cswch/s nvcswch/s Command32316 4.00 0.00 php-fpm32508 160.00 34.00 php-fpm32726 131.00 8.00 php-fpm... 由于 fpm 运行处于阻塞模式，每当请求 Redis、Memcached 或 MySQL 时会触发自愿上下文切换，而非自愿上下文切换仅在时间片耗尽时发生，因此大多数切换都是自愿的。 如果需要查看特定进程的总上下文切换情况，可以进入 /proc 目录下查看： grep ctxt /proc/PID/status 通过这种方式，们能够直接看到 voluntary_ctxt_switches 和 nonvoluntary_ctxt_switches 的总数。这些数据无须记住上下文切换所做的具体操作，只需知道一个结论：实验结果显示上下文切换的开销在 2.7 微秒到 5.48 微秒之间，而也可以借助提供的代码和工具进行测试，lmbench 的测试结果更为准确，因为它考虑到了后续缓存未命中的影响。","categories":["2.语言","C语言","多线程"]},{"title":"多线程","path":"/2024/06/05/2-语言-C语言-多线程-多线程/","content":"传统多任务操作系统中一个可以独立调度的任务（或称之为顺序执行流）是一个进程。每个程序加载到内存后只可以唯一地对应创建一个顺序执行流，即传统意义的进程。 每个进程的全部系统资源是私有的，如虚拟地址空间，文件描述符和信号处理等等。使用多进程实现多任务应用时存在如下问题： 任务切换，即进程间上下文切换，系统开销比较大。（虚拟地址空间以及 task_struct 都需要切换） 多任务之间的协作比较麻烦，涉及进程间通讯。（因为不同的进程工作在不同的地址空间） 所以，为了提高系统的性能，许多操作系统规范里引入了轻量级进程的概念，也被称为线程。 通常线程指的是共享相同地址空间的多个任务。线程最大的特点就是在同一个进程中创建的线程共享该进程的地址空间；但一个线程仍用 task_struct 来描述，线程和进程都参与统一的调度。所以，多线程的好处便体现出来： 大大提高了任务切换的效率；因为各线程共享进程的地址空间，任务切换时只要切换 task_struct 即可； 线程间通信比较方便；因为在同一块地址空间，数据共享； 当然，共享地址空间也会成为线程的缺点，因为共享地址空间，如果其中一个线程出现错误（比如段错误），整个线程组都会崩掉！ Linux 之所以称呼其线程为 LWP( Light Weight Process )，因为从内核实现的角度来说，它并没有为线程单独创建一个结构，而是继承了很多进程的设计： 继承了进程的结构体定义 task_struct ； 没有专门定义线程 ID，复用了 PID； 更没有为线程定义特别的调度算法，而是沿用了原来对 task_struct 的调度算法。 线程已经替代原来的进程称为调度的实际最小单位。 原来的进程概念可以看成是多个线程的容器，称之为线程组；即一个进程就是所有相关的线程构成的一个线程组。传统的进程等价于单线程进程。 每个线程组都有自己的标识符 tgid (数据类型为 pid_t )，其值等于该进程(线程组)中的第一个线程(group_leader)的 PID。 线程根据其调度者的不同可以被分为两大类：用户级线程（User-Level Threads, ULT）和核心级线程（Kernel-Level Threads, KLT）。这两种线程在程序并发执行时，各自解决的问题和实现的机制存在显著差异。 用户级线程主要关注上下文切换（Context Switching）的问题。上下文切换是指 CPU 在不同线程之间切换执行状态的过程。用户级线程的调度算法和调度过程完全由用户在应用层决定，这意味着在运行时不需要内核的直接支持。这种设计的优点在于提高了线程的创建和切换速度，因为用户空间的操作通常比内核空间的操作要快。 常用的就是这类用户级线程，其中 POSIX 标准提供了一套完整的用户级线程接口。以下是一些基本的线程操作相关函数： 基本线程操作相关函数 线程的创建与结束 线程的互斥与同步 使用信号量控制线程 线程的基本属性配置 互斥与同步机制基本函数 函数 说明 pthread_create() 创建新的线程并开始执行相关线程的函数，运行结束后线程退出。 pthread_exit() 用于结束当前线程的函数，区别于 exit()（结束整个进程）。 pthread_join() 阻塞当前线程，等待指定线程结束。如果目标线程已结束，则立即返回，返回值 0 代表成功。 pthread_cancel() 向指定线程发送终止信号，成功返回 0，但并不保证线程立即停止。 pthread_testcancel() 在没有取消点的代码段中创建一个取消点，以允许响应取消请求。 pthread_setcancelstate() 设置当前线程对取消信号的反应，以控制线程何时响应取消请求。 pthread_setcanceltype() 设置取消状态，决定线程是否立即取消或等到下一个取消点再取消。 pthread_setcancel() 修改当前线程的取消状态。 互斥锁基本函数 函数 说明 pthread_mutex_init() 初始化互斥锁以保护共享资源。 pthread_mutex_lock() 尝试锁定互斥锁，如果互斥锁已被其他线程锁定，则会阻塞等待。 pthread_mutex_trylock() 试图非阻塞地锁定互斥锁，如果锁定失败则立即返回错误。 pthread_mutex_unlock() 释放互斥锁，以允许其他线程访问被保护的共享资源。 pthread_mutex_destroy() 销毁互斥锁，释放与该互斥锁相关的资源。 信号量控制线程的基本函数（默认无名信号量） 函数 说明 sem_init() 初始化一个定位在指定地址的匿名信号量。 sem_wait() 使信号量减 1。如果信号量当前值为 0，则进入阻塞状态。 sem_trywait() 尝试非阻塞地减少信号量值，如果信号量当前值为 0 则返回错误。 sem_post() 增加信号量的值，确保原子操作。 sem_getvalue() 将当前信号量的值存储到指定的整数变量中。 sem_destroy() 销毁指定的匿名信号量，释放相关资源。 线程属性配置相关函数 函数 说明 pthread_attr_init() 初始化线程属性对象，准备设置线程的属性。 pthread_attr_destroy() 清除已设置的线程属性，释放资源。 pthread_attr_setscope() 设置线程的可见性属性，可以是系统范围或者进程范围。 pthread_attr_setschedparam() 设置线程的调度参数，如线程优先级。 pthread_attr_getschedparam() 获取当前线程的调度参数。 线程创建int pthread_create(pthread_t *thread,const pthread_attr_t *attr,void *(* routine)(void *), void *arg)# 函数参数# thread ：创建的线程ID# attr ：指定线程的属性，NULL表示使用缺省属性# routine ：线程执行的函数# arg ：传递给线程执行的函数的参数 创建成功返回 0，否则返回-1 routine 是回调函数（callback），函数类型由内核来决定，这里将地址传给内核； 函数并不是线程创建了就会执行，而是只有当其被调度到 cpu 上时才会被执行 arg 是线程执行函数的参数，，使用时需要先进行类型转换，才能使用； 如果 arg 参数不止一个，可以将其放入到结构体中，传入结构体指针； 在调用 pthread_create() 函数后，当前线程将继续执行它的任务，而新创建的线程则会开始执行指定的线程函数。此时，两个线程之间的执行并不是线性顺序的，而是由 Linux 的异步调度机制来决定哪个线程在何时运行。 线程的执行顺序 原线程的继续执行: 原线程在调用 pthread_create() 后，不会停止或等待新线程的建立，而是立即恢复执行。这意味着，在某些场景中，原线程可能会在新线程之前或之后执行部分逻辑。 例如，原线程可能会立即进行一些初始化操作，比如加载文件、设置共享数据结构等，这些操作可能是新线程所依赖的。 新线程的启动: 新线程则根据操作系统的调度策略，可能很快或者相对较晚才开始执行其线程函数。例如，如果系统有许多任务在运行，新的线程可能在其创建后还需排队等待分配 CPU 时间。 Linux 的调度机制Linux 操作系统使用抢占式调度，意味着即使一个线程正在执行，操作系统也可能会中断它的执行，将 CPU 时间片分配给其他线程。如此一来，程序无法依赖于线程执行的顺序，这给并发编程带来了复杂性。 举例来说，如果一个原线程在创建后立即进行计算，而新线程负责处理用户输入，二者的执行完全依赖于系统调度。 这种不确定性意味着，可能会出现竞争条件或死锁等问题。为了避免这些问题，通常会使用互斥锁、信号量等同步机制来协调线程之间的执行顺序和数据共享。 因此，在多线程编程中，确保线程间的正确协作和资源状态的管理至关重要。 线程属性const pthread_attr_t *attr; 在多线程编程中，线程属性（pthread_attr_t）用于定义创建线程时的多种参数。这些属性可以影响线程的调度优先级、栈大小、是否分离等特性。通过使用线程属性，可以在创建线程之前，精确地控制线程的行为，满足特定的应用需求。 主要属性 栈大小（Stack Size）线程的栈为线程执行所需的局部变量和函数调用准备了存储空间。如果栈太小，可能导致栈溢出，程序崩溃。可以使用 pthread_attr_setstacksize 函数来指定一个合适的栈大小，例如： pthread_attr_setstacksize(attr, 1024 * 1024); // 设置栈大小为1MB 调度策略和优先级（Scheduling Policy and Priority）调度策略确定了线程的运行顺序，例如 FIFO、轮询等。通过 pthread_attr_setschedpolicy 和 pthread_attr_setschedparam 可以设置这些参数，以便在高负载情况下优化性能。例如： struct sched_param sched_param;sched_param.sched_priority = 20; // 设置线程优先级为20pthread_attr_setschedparam(attr, sched_param); 线程分离状态（Detach State）线程可以被设置为分离状态，这意味着它运行后就不能被其他线程联合（join），资源会在结束后自动回收。可以通过 pthread_attr_setdetachstate 来启用分离状态。举个例子： pthread_attr_setdetachstate(attr, PTHREAD_CREATE_DETACHED); // 设置为分离状态 信号屏蔽（Signal Mask）线程属性还允许设置线程的信号屏蔽字，从而控制线程在执行期间接收哪些信号。这样可以防止在处理某些关键任务时被中断。相关函数为 pthread_sigmask。 使用示例创建线程时，可以将属性结构体传入线程创建函数，这样确保新线程继承了预设的属性。例如： pthread_t thread;pthread_attr_t attr;pthread_attr_init(attr); // 初始化属性对象pthread_attr_setstacksize(attr, 1024 * 1024); // 设置栈大小为1MBpthread_create(thread, attr, thread_func, NULL); // 创建线程，指定属性pthread_attr_destroy(attr); // 线程创建后，销毁属性对象 线程管理在多线程编程中，线程管理是确保各个线程有效协作的关键部分。与进程管理中的 exit() 和 wait() 函数相似，pthread_join 和 pthread_exit 也在两个线程之间起到协调作用。 pthread_joinpthread_join 函数用于在一个线程中等待另一个线程的结束。它的基本语法如下： pthread_join(thread, [线程返回的参数]); 这里的 thread 参数是一个线程的标识符，通常在创建线程时使用 pthread_create 函数获得。调用 pthread_join 的线程会被阻塞，直到指定的线程结束运行为止。这可以确保在进行线程间的数据共享时，只有在相关线程完成其任务时，主线程或其他线程才会继续执行。 例如，一个线程负责计算数据，而另一个线程需要获取这个计算结果。如果没有适当的同步，获取的结果可能是无效的。以下是一个具体示例： #include pthread.h#include stdio.hvoid* calculate(void* arg) int result = 42; // 模拟的计算结果 pthread_exit((void*)result); // 结束线程并返回结果int main() pthread_t thread; int rc; int result; // 创建线程 rc = pthread_create(thread, NULL, calculate, NULL); if (rc) printf(Error creating thread ); return -1; // 等待线程结束并获取返回值 pthread_join(thread, (void**)result); printf(The result is %d , result); // 输出计算结果 return 0; pthread_exitpthread_exit 函数用于终止当前线程的执行，并允许线程返回一个值，供其他线程访问和使用。该函数的基本语法如下： pthread_exit([线程返回的参数]); 调用 pthread_exit 时，线程不会立即终止。具体来说，调用此函数的线程会结束其活动过程，并将控制权返回给调度器。这一设计使得一个线程可以安全地将执行结果传递给其他线程，从而促进线程之间的数据共享和协作。 例如，考虑以下代码片段： void* calculate(void* arg) int result = 42; // 假设计算结果为42 pthread_exit((void*)result);int main() pthread_t tid; pthread_create(tid, NULL, calculate, NULL); void* retval; pthread_join(tid, retval); printf(计算结果: %d , (int)retval); return 0; 在这个示例中，calculate 函数通过 pthread_exit 返回计算的结果 42。主线程使用 pthread_join 函数等待 calculate 线程结束，并获取其返回值。这样，主线程就可以处理计算结果，确保整个程序在多线程环境下有序进行。 合理地应用 pthread_join 和 pthread_exit 可以有效避免数据竞争情况，例如当多个线程尝试访问和修改共享数据时，可能造成不可预期的结果。另外，合理的线程管理能够减少资源浪费，提升程序的性能。在多线程程序中保持良好的协调可以提高系统的整体效率，实现资源的最佳使用。 pthread_cancelpthread_cancel 是 POSIX 线程（Pthreads）库中的一个函数，主要用于请求取消一个正在运行的线程。它的基本语法如下： int pthread_cancel(pthread_t thread); 参数 thread：这是要取消的目标线程的标识符，通常是通过 pthread_create 创建线程时返回的 pthread_t 值。 返回值 返回 0 表示成功。 返回错误代码，表示取消失败，常见错误包括： ESRCH：指定的线程不存在。 EINVAL：线程标识符无效。 工作原理当调用 pthread_cancel 取消某个线程时，这并不会立即终止线程的执行。相反，它向目标线程发送一个取消请求。目标线程会检查其取消状态，以决定是否响应这一请求。默认情况下，线程的取消状态是启用的，但可以通过 pthread_setcancelstate 函数修改。 线程的取消类型线程的响应方式取决于线程的取消类型。主要有两种类型： 异步取消（ASYNCHRONOUS）：一旦请求被发送，线程会在下一个取消点立即被终止。通过 pthread_setcanceltype 设置为 PTHREAD_CANCEL_ASYNCHRONOUS。 线程取消点（DEFERRED）：线程会在设定的取消点上检查是否需要被取消。这些取消点可以是系统调用、pthread_testcancel、pthread_join 等。这是默认设置，减少了线程被非预期取消的风险。 取消点示例下面是一个简单示例，展示了如何在一个线程中设定取消点： #include stdio.h#include stdlib.h#include pthread.h#include unistd.hvoid *thread_function(void *arg) while (1) printf(Thread is running... ); // 设置一个取消点 pthread_testcancel(); // 检查取消请求 sleep(1); // 模拟线程工作 int main() pthread_t thread; pthread_create(thread, NULL, thread_function, NULL); sleep(3); // 让线程运行一段时间 pthread_cancel(thread); // 请求取消线程 pthread_join(thread, NULL); // 等待线程结束 printf(Thread has been cancelled. ); return 0; 在这个示例中，线程执行一个循环，不断打印信息。在循环的每一轮中，pthread_testcancel 会检查是否收到了取消请求。如果收到了请求，线程将安全地终止执行。 使用注意事项 不应当在同一个线程内调用 pthread_cancel 来取消自己，可能会导致不确定的行为。 在设计程序时，应该考虑良好的线程资源管理，确保避免泄露和确保线程安全。 尽量使用资源清理机制，例如 pthread_cleanup_push 和 pthread_cleanup_pop，在取消请求发生时清理资源。 线程函数参数的传递在多线程编程中，线程能够并行执行任务，提升程序的性能和响应速度。然而，为了让每个线程能够接收到相应的参数，合理地传递线程函数参数至关重要。 参数传递的几种方式直接传递某些编程语言和框架支持在创建线程时直接传递参数。例如，在 Python 的 threading 模块中，可以使用 args 参数来传递一个元组，包含线程函数所需的所有参数。 import threadingdef worker(num): print(fWorker: num)# 创建线程，并传递参数thread = threading.Thread(target=worker, args=(1,))thread.start() 在这个例子中，数字 1 被传递给线程函数 worker，线程在执行时会输出 Worker: 1。 使用类或结构体在某些情况下，传递多个参数可能会比较繁琐。这时可以考虑使用一个类、结构体或字典来封装参数组。例如，在 C++ 中，可以定义一个结构体： #include iostream#include threadstruct ThreadData int value; std::string message;;void threadFunction(ThreadData data) std::cout data.message data.value std::endl;int main() ThreadData data = 42, Value is:; std::thread t(threadFunction, data); t.join(); 在该示例中，结构体 ThreadData 将两个参数封装在一起，传递给线程函数便于管理和使用。 共享全局变量全局变量也是可以在多个线程间共享的参数传递方式。虽然使用全局变量比较简单，却可能引发数据竞争和一致性问题，因此通常需要使用锁（例如互斥量）来保护数据： import threading# 全局变量count = 0lock = threading.Lock()def increment(): global count for _ in range(100000): with lock: count += 1# 创建多个线程threads = [threading.Thread(target=increment) for _ in range(10)]for thread in threads: thread.start()for thread in threads: thread.join()print(fTotal count: count) 在这个例子中，使用锁确保在自增操作中只有一个线程可以更改 count 变量，避免数据竞争的风险。 参数传递的注意事项 上下文关联：确保传递给线程的参数在其生命周期内是有效的；特别是在使用局部变量时，避免在函数返回后线程仍然访问这些变量。 性能考虑：过多的参数传递，特别是大型数据结构，会增加开销。尽量只传递必要的信息。 通过上述几种方式，线程函数的参数可以方便而安全地传递，确保多线程程序的稳定运行与性能优化。选择合适的方式不仅能够简化代码，还能降低潜在的错误风险。 同步和互斥临界资源：某些资源来说，其在同一时间只能被一段机器指令序列所占用。这些一次只能被一段指令序列所占用的资源就是所谓的临界资源。 临界区：对于临界资源的访问，必须是互斥进行。也就是当临界资源被一个指令序列占用时，另一个需要访问相同临界资源的指令序列就不能被执行。指令序列不能执行的实际意思就是其所在的进程线程会被阻塞。所以定义程序内访问临界资源的代码序列被称为临界区。 互斥：是指同事只允许一个访问者对临界资源进行访问，具有唯一性和排它性。但互斥无法限制访问这个对资源的访问顺序，即访问时无序的。 同步：是指在互斥的基础上，通过其他机制实现访问者对资源的有序访问。 线程间互斥引入互斥(mutual exlusion)锁的目的是用来保证共享数据的完整性。 互斥锁主要用来保护临界资源。每个临界资源都有一个互斥锁来保护，任何时刻最多只能有一个线程能访问该资源；线程必须先获得互斥锁才能访问临界资源，访问完资源后释放该锁。如果无法获得锁，线程会阻塞直到获得锁为止； 通常，在临界区前上锁，临界区后解锁； //初始化互斥锁int pthread_mutex_init (pthread_mutex_t *mutex, pthread_mutexattr_t *attr )//申请互斥锁int pthread_mutex_lock(pthread_mutex_t *mutex)//释放互斥锁int pthread_mutex_unlock(pthread_mutex_t *mutex) 同步同步(synchronization) 指的是多个任务（线程）按照约定的顺序相互配合完成一件事情；线程间同步——P V 操作 信号量信号量是一种重要的同步机制，用于管理某一类资源的访问。信号量的值代表系统中该资源的当前可用数量。例如，在一个打印任务的系统中，信号量可以用来表示可用打印机的数量。若值为 3，意味着系统中有三台打印机可以被任务使用。 信号量是一个受保护的变量，其访问仅限于以下三种操作： 初始化信号量int sem_init (sem_t *sem,int pshared,unsigned int value) 函数参数 sem：要初始化的信号量。 pshared：指示信号量的共享范围。当值为 0 时表示信号量供线程间使用；当值非零时，表示信号量供进程间使用。 value：信号量的初始值，表示可用资源的数量。 函数返回值 成功时返回 0。 出错时返回 -1。 例如，在一个多线程环境中，初始设置一个信号量 sem 表示有 2 台资源可用： sem_init(sem, 0, 2); P 操作（申请资源）P 操作用于申请资源，通常被称为 sem_wait。 int sem_wait (sem_t *sem) 函数参数 sem：要等待的信号量。 函数返回值 成功时返回 0。 出错时返回 -1。 操作逻辑如果信号量的值大于 0，任务可以继续运行，同时信号量的值减一。如果信号量的值为 0，表示没有资源可用，相关任务将被阻塞，等待资源的释放。举个例子，某个线程尝试打印文档，在信号量的值大于 0 的情况下，任务将继续执行并调用打印机，当资源被使用后，信号量减一。 if (sem_wait(sem) == 0) // 继续执行打印任务 V 操作（释放资源）V 操作用于释放资源，常被称为 sem_post。 int sem_post(sem_t *sem) 函数参数 sem：要释放的信号量。 函数返回值 成功时返回 0。 出错时返回 -1。 操作逻辑如果没有任务在等待该资源，信号量的值将增加一，表示资源可用的数量增加。如果有任务在等待，系统会唤醒第一个等待的任务，让其继续运行。例如，在完成打印任务后，相关线程会调用 sem_post 释放资源，信号量的值将加一，并且如果有其他线程在等待资源，该线程会被唤醒继续执行。 sem_post(sem); // 释放资源，用于等待的任务可继续执行 通过这三种操作，信号量有效地帮助协调对共享资源的访问，确保系统的稳定性和效率。 条件变量简介条件变量是一种用于线程间同步的机制，主要依赖于两个基本动作：一个线程在等待”条件变量的条件成立”而阻塞，而另一个线程则通过发出信号来通知条件已成立。这种机制有效地防止了线程间的竞争（Race Condition），确保了多线程环境下的安全性与效率。 条件变量的相关名词 中文名: 多线程的条件变量 外文名: pthread_cond_wait 主要动作 动作一: 等待条件变量 动作二: 发出条件成立信号 目的为了防止线程之间的竞争，确保线程正确地处理共享资源。 创建与注销条件变量创建条件变量有两种方式：静态和动态。静态方式通过 PTHREAD_COND_INITIALIZER 初始化，如下所示： pthread_cond_t cond = PTHREAD_COND_INITIALIZER; 动态方式则是通过调用 pthread_cond_init() 函数，API 定义如下： int pthread_cond_init(pthread_cond_t *cond, pthread_condattr_t *cond_attr); 尽管 POSIX 标准中为条件变量定义了属性（cond_attr），但在某些实现中，比如 LinuxThreads，并没有实际支持，因此在这里常常将 cond_attr 设置为 NULL，并被相应地忽略。 要注销条件变量，可以调用 pthread_cond_destroy()。需要注意的是，只有在没有其他线程等待该条件变量的情况下才能成功注销，若有线程正在等待，则会返回错误代码 EBUSY。因为在 Linux 实现的条件变量中并没有分配特定的资源，注销操作只需确保没有等待的线程。API 定义如下： int pthread_cond_destroy(pthread_cond_t *cond); 等待与激发条件在多线程编程中，有两种方式来等待条件： 条件等待: 使用 pthread_cond_wait() 计时等待: 使用 pthread_cond_timedwait() 其中，计时等待方式如果在给定时间段内条件未满足，则返回 ETIMEDOUT，并结束等待。计时的绝对时间格式与 time() 函数相同，时间 0 表示从 1970 年 1 月 1 日 00 时 00 分 0 秒开始。 必须与一个互斥锁（mutex）配合使用，防止多个线程同时请求 pthread_cond_wait()（或 pthread_cond_timedwait()），造成竞争条件。在调用 pthread_cond_wait() 前，mutex 必须由当前线程加锁（pthread_mutex_lock()），并在条件满足且离开 pthread_cond_wait() 前重新加锁。确保在阻塞时，线程处于解锁状态，以避免死锁情形的发生。 激发条件信号有两种形式： pthread_cond_signal(): 激活一个等待该条件的线程，优先激活在等待队列中按先后顺序排在前的线程。 pthread_cond_broadcast(): 激活所有等待线程，这在需要同时通知多个消费者时非常有用。 代码实例下面是一个典型的多线程应用示例，采用了条件变量和互斥锁。这个示例展示了如何实现一个简单的生产者-消费者模型，其中消费者可以是多个线程。 #include stdio.h#include stdlib.h#include pthread.h#include unistd.hstatic pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;struct node int n_number; struct node *n_next; *head = NULL;/* 清理处理函数 */static void cleanup_handler(void* arg) printf(Clean up handler of the second thread. ); free(arg); (void)pthread_mutex_unlock(mtx);/* 线程函数 */static void* thread_func(void* arg) struct node *p = NULL; pthread_cleanup_push(cleanup_handler, p); pthread_mutex_lock(mtx); // Protects the waiting period of wait while (1) while (head == NULL) pthread_cond_wait(cond, mtx); // 一旦被唤醒，获取节点 p = head; head = head-n_next; printf(Got %d from front of queue , p-n_number); free(p); pthread_mutex_unlock(mtx); // 释放互斥锁 pthread_cleanup_pop(0); return 0;int main(void) pthread_t tid; int i; struct node *p; pthread_create(tid, NULL, thread_func, NULL); for (i = 0; i 10; i++) p = (struct node *)malloc(sizeof(struct node)); p-n_number = i; pthread_mutex_lock(mtx); // 对临界资源加锁 p-n_next = head; head = p; pthread_cond_signal(cond); pthread_mutex_unlock(mtx); // 解锁 sleep(1); printf(Thread 1 wants to end the cancel thread 2. ); pthread_cancel(tid); // 取消线程 pthread_join(tid, NULL); printf(All done -- exiting ); return 0; 这个示例展示了如何通过互斥锁保护共享资源 head，并使用条件变量 cond 在有新数据时唤醒消费者线程。 对于线程的取消，使用了 pthread_cancel()，实现了外部线程的安全退出。 清理处理函数确保在资源释放时正确解锁，以防止程序在意外情况下陷入死锁状态。","categories":["2.语言","C语言","多线程"]},{"title":"守护进程","path":"/2024/06/04/2-语言-C语言-多线程-守护进程/","content":"可以将下述概念类比为一次通过 QQ 聊天的全过程： 控制终端 好比 QQ 软件的打开，每次开启都代表开始一次新的会话。 进程 则是聊天时发送的每一条信息，每条信息都可能是个人观点或回复。 作业 体现为聊天内容中的某一主题或事件，可以是讨论某款游戏、分享一则新闻等，其中每个言谈交互就像是进程的操作。 会话 是从开启聊天到结束聊天的完整过程，即使其中话题不断变化。 进程组进程组是一个或多个进程的集合，方便对多个进程进行统一控制。在有大量进程运行的情况下，向进程组发送信号比逐一向每个进程发送信号更加高效和简便。每个进程组都有一个唯一的 ID，这个 ID 由组长进程的进程 ID 决定。组长进程创建进程组，但它并不能决定进程组的存活时长。只要进程组内还有一个进程存在，整个进程组依然有效。这意味着即使组长进程已终止，只要至少还有一个成员进程在运行，整个组仍然存活。 会话会话（session）是一个或多个进程组的集合。会话的生命周期从用户登陆终端开始，到用户退出登陆时结束。可以把会话理解为用户与操作系统之间一次完整的互动。例如，当用户通过终端登录到系统后，启动的一系列操作和进程将会被包含在同一个会话中，这种互动过程包括专注于任务的时间段及过程中的各种输入和反馈。 在每个会话中，通常会包含一个控制进程、一个前台进程组及若干后台进程组。控制进程负责与终端建立连接，而会话只能有一个控制终端。这个控制终端通常是用户登录时所用的终端设备或伪终端。会话的前台进程组中所有进程都将接收到来自控制终端的输入及信号。 控制终端每当使用终端工具（如 SSH、Bash 等）打开本地或远程 shell 时，便开启了一个控制终端。通过 ps 命令，可以查找与该终端对应的进程，命令显示的 command 为 ttyn ，这对应于 Linux dev 目录下的一个文件。例如，如果运行 ps -t pts/0，会列出与该终端相关的所有进程信息，便于用户监控和管理。 作业作业的概念与进程组类似，也是由多个进程组成的。作业可以被分为前台作业和后台作业。每个会话通常会有一个前台作业和多个后台作业。需要注意的是，作业内某个进程的子进程并不自动归属该作业。 如同用户在处理多个任务时，作业可以理解为正在进行的一项具体工作，而每个进程就像是这一过程中不同的步骤。例如，用户在同一会话中可能同时启用了多个下载任务和文件编辑任务，每个都对应于一个独立的进程，而它们共同组成了该作业的完整性。 后台执行在终端窗口执行命令时，进程通常会占用终端，直到其结束。在此期间，无法继续对终端进行输入操作。同时，如果终端窗口被关闭或网络连接中断，已启动的进程也会被中断。原因在于，用户注销或网络断开时，SIGHUP 信号将被发送给会话中的所有子进程。如果程序没有捕捉此信号，进程便会终止。 实现后台执行主要有两个关键目标： 使进程在后台执行，不干扰前台终端。 使进程不再受终端关闭影响，例如不应该在终端关闭后因接收到 SIGHUP 信号而退出。 在实际操作中，最常见的方式是使用 符号，将其附加在命令后面，如 command ，此命令可让进程在后台执行，而不会占用前台界面。然而，值得一提的是， 符号只实现了让进程让出前台终端的功能，并未改变进程受到 SIGHUP 信号的影响。 nohupnohup 是另一个常用命令，其作用是使进程不受 SIGHUP 信号的影响。使用如 nohup php test.php 后，虽进程在前台终端仍存在，但即使终端关闭或连接断开，程序依然会继续运行。在执行此命令时，用户会发现当前目录下产生了一个名为 nohup.out 的文件，这是因为 nohup 会将进程的输出保存到该文件中。 如果进程对输出没有需求且不想产生文件，可以通过重定向标准输出和标准错误输出来避免创建 nohup.out。例如，可以使用以下命令将输出重定向到 /dev/null ， 大家通常会结合使用 nohup 和 以确保后台进程能独立于终端存在，如：nohup command /dev/null 21 。 setsidsetsid 是另一个用于背景执行的命令，其作用是启动一个新的会话并运行指定的进程。使用格式为 setsid command。因为终端关闭后进程退出是由于会话的首进程发送了 SIGHUP 信号，而 setsid 可以直接打开一个新的会话执行命令，使原会话的终端状态不再影响该进程。 使用 pstree 可以查看通过 setsid 和 nohup ... 启动的进程时的进程树状态。例如： pstree -a | grep -C 6 test|-sshd| `-sshd| `-sshd| `-bash| `-sudo -s| `-bash| |-grep -C 6 test| |-php test.php| `-pstree -a 在远程通过 SSH 登录时，可以观察到 test.php 进程挂在 sshd 进程下。若 sshd 终止，test.php 也将随之退出。不过，当使用 setsid 后，执行 pstree -a | grep -C 6 test 会显示： |-nscd|-php test.php|-php-fpm--|-sshd| `-sshd 此时， test.php 进程已与 sshd 进程同级，成为 init 进程的子进程。虽然 setsid 未为进程分配输出终端，进程仍会输出到当前终端。 setsid 的坑值得一提的是，在终端中直接使用 setsid command 启动进程时，终端的前台并不会被影响，命令 command 将在后台默默运行。但在 shell 脚本中，执行 setsid 的进程会阻塞，直到 command 执行结束。这是由于 setsid 作为进程组长，在 fork() 子进程时，不会 wait() 子进程，会立即退出。相对地，在 shell 脚本内，setsid 不是进程组长，bash 会 fork() 一个子进程并 wait() 它，从而导致这一行为差异。 解决上述问题的办法有： 使用 setsid php test.php ，强行将其放到后台执行。 利用 . 或 source 命令由终端执行 setsid。 除了上述命令，还有诸如 screen 和 tmux 等会话工具，它们各自具有复杂的使用规范。在掌握了本文中的关键命令后，便可自如运用 Linux 进程控制。不过，对于深入新知识的求知者，学习更高级的工具也非常有益。 作业命令在后台执行的命令时，可能会面临一些小问题，涉及到作业管理。终端中运行的每个命令都可以理解为一个作业，部分作业占用前台终端，部分在后台悄然运行。其帮助调度作业的基本命令包括： jobsjobs 是用于查看当前会话中所有正在运行的作业的命令。例如，执行 jobs 命令后，可以看到如下输出： jobs[1]- Running php test.php [2]+ Stopped php test.php 方括号内的数字是作业 ID，用于后续操作的标识。接下来是作业的状态和执行的命令名称。 ctrl+zctrl+z 并不是专门的作业命令，它向当前运行的进程发送一个 SIGSTOP 信号，促使进程进入暂停状态（stopped）。在这一状态下，进程的状态会被操作系统保存，而此进程将被置入作业队列中。可以利用 ctrl+z 暂停占用终端的进程，而不完全停止该进程，从而获得继续输入其他命令的空间。 bg若被放在后台的进程执行时间过长，并且没有使用 nohup，此时终端一旦断开，进程将导致重新运行。因此，如果希望在不中断进程的情况下让其让出前台终端，可以使用 bg 命令（代表 “background” 的缩写）。bg %id 的作用是将已暂停作业放入后台，继续执行。 结合使用 ctrl+z 与 bg，可以将正在占用终端的进程暂停并转为后台执行，从而避免一些潜在问题。 fgfg 命令则与 bg 相对，可以将作业从后台调回前台执行。它非常适合于需要再次交互的命令或作业，便于用户继续操作。 disowndisown 用于将作业移出作业列表，即使在会话结束后，也不再向该作业发送 SIGHUP 信号。这一特性尤其有助于解决进程在终端关闭后仍需继续存在的问题。 守护进程前面介绍的是一些临时性进程的控制手段，而将进程转变为守护进程是长期后台运行进程的最佳选择。 守护进程守护进程（daemon）是一种生存期较长的进程，通常在操作系统启动时启动，并在系统关闭时负责停止。这类进程没有控制终端，也不会向终端输出。诸如服务器、后台进程管理（如 PHP-FPM）等，都是以守护进程的形式存在。 创建过程创建守护进程的基本步骤如下： 必选步骤： Fork 子进程：创建一个子进程并退出父进程，以使子进程成为孤儿进程，接下来由 init 进程收养。 **使用 setsid**：打开新会话，确保进程脱离终端控制，成为会话组长。 设置信号处理：特别是对子进程退出的处理。 可选步骤： **使用 chdir**：改变进程的工作目录，通常设为根目录，避免占用可卸载的文件系统。 用 umask 重设文件权限掩码：避免继承父进程的文件权限设置。 关闭父进程打开的文件描述符：确保资源有效释放。 代码示例以下是用 PHP 创建守护进程的简易伪代码示例： $pid = pcntl_fork();if ($pid 0) exit; // 父进程直接退出 elseif ($pid 0) throw_error(); // 进程创建失败posix_setsid(); // setsid成为会话领导进程chdir($dir); // 切换工作目录umask(0); // 重置文件权限maskclose_fd(); // 关闭父进程的文件描述符pcntl_signal($signal, $func); // 注册信号处理函数while (true) do_job(); // 处理进程任务 pcntl_signal_dispatch(); // 分发信号处理 以上伪代码展示了创建守护进程所需的基本步骤，确保进程可以在没有用户干预的情况下一直运行。守护进程的管理和创建是高效处理 Linux 系统中长期后台作业的核心，了解其原理及实现能够显著提升工作效率和系统稳定性。 创建守护进程创建守护进程是操作系统中的一个常见任务，尤其在需要后台持续运行的服务时。例如，网络服务器和定时任务管理系统都依赖于守护进程来确保其正常运行。下面是创建守护进程的具体步骤： 创建子进程使用 fork() 函数创建一个新的子进程。在此步骤中，父进程可以选择调用 exit() 函数，这样可以立即释放终端资源并退出。此操作确保父进程结束后，子进程能够继续独立运行。例如： pid_t pid = fork();if (pid 0) // 父进程可以执行其他任务或直接退出 exit(0); 将子进程设为新的会话调用 setsid() 函数将子进程设为新的会话组的首进程。这使得子进程脱离当前的终端会话，确保在用户注销或关闭终端时不会受到影响。这一步对于确保守护进程的长期稳定运行至关重要。 更改工作目录使用 chdir() 函数将工作目录更改为根目录 /。这可以避免守护进程占用可能被删除的文件系统路径，因为根目录是始终存在的。例如： chdir(/); 更改文件的权限掩码通过 umask() 函数更改文件权限掩码。这是为了确保守护进程创建的文件具有适当的权限。例如： umask(027); // 限制文件权限，仅允许同组用户访问 关闭文件描述符使用 close() 函数关闭不再需要的文件描述符，尤其是标准输入、输出和错误流。因守护进程不需要与终端交互，这一步骤能够防止不必要的输出。例如，可以通过如下代码关闭标准输入、输出和错误描述符： close(0); // 关闭标准输入close(1); // 关闭标准输出close(2); // 关闭标准错误输出 使用 getdtablesize() 函数可以调用 getdtablesize() 函数来获取当前进程的最大文件描述符数量。这对于在需要的情况下合理管理文件描述符非常重要。例如，定义并关闭所有可以关闭的文件描述符。 daemon 函数在 POSIX 中，daemon 函数提供了一种更简便的方法来创建守护进程。其函数原型如下： #include unistd.hint daemon(int nochdir, int noclose); 参数说明 nochdir: 参数设为 0 时，守护进程会将当前工作目录更改为根目录 /。 noclose: 参数设为 0 时，守护进程会将标准输入、输出和错误重定向到 /dev/null，即消除与终端的连接，此时任何来自标准流的输入都将丢弃。这样做可以避免进程因终端输入而产生的干扰。 通过这些步骤，可以有效地创建并管理一个守护进程，确保其能够在后台可靠地运行，同时避免与用户的交互干扰进程的正常功能。 fork请问下面的程序一共输出多少个”-“？ #include stdio.h#include sys/types.h#include unistd.h int main(void) int i; for(i=0; i2; i++) fork(); printf(-); wait(NULL); wait(NULL); return 0; 要分析这个程序输出多少个”-“，首先要了解 fork() 函数的工作方式。fork() 用于创建一个新的进程。每当调用 fork() 时，当前进程将自身复制一个新的子进程。每个进程执行相同的代码，从调用 fork() 的那一行开始。以下是对程序流程的详细分析： 初始化：程序从 main 函数开始，当 i=0 时，开始执行 for 循环。 第一次循环（i0）： 调用 fork()，创建第一个子进程。 现在有两个进程（父进程和子进程），分别继续执行 printf(-)。 每个进程都会输出一个 -，因此这时输出总数为 2 个 -。 第二次循环（i1）： 两个进程（上一步中创建的两个进程）各自再次调用 fork()，每个进程再创建一个子进程。 父进程会创建一个新的子进程，子进程也会创建一个新的子进程。此时，总共有四个进程： 第一个父进程 第一个父进程创建的子进程 第二个父进程（第一个子进程） 第二个子进程（子进程的子进程） 每个进程在这次循环中都输出一个 -，因此输出增加了 4 个 -。 将这两个步骤的结果相加： 第一次循环输出：2 个 - 第二次循环输出：4 个 - 最终，程序的总输出为 2 + 4 6 个 -。程序的每次 fork() 调用都会使得运行中的进程数翻倍，最终导致输出累积至 6 个 -。然而，实际情况却存在一些破坏常规的因素，使得程序总共输出了 8 个”-“。 理解 fork() 的特性要想清楚为什么会输出 8 个”-“，首先需要理解 fork() 系统调用的特性。每次调用 fork()，操作系统会创建一个新的进程，该进程是调用它的父进程的副本。在这段代码中，该副本会继承父进程的所有状态，包括它的输出缓存。 具体来说，printf(-); 这一语句是将”-“放入缓存，而不是立即输出到标准输出。这一缓存机制使得当 fork() 被调用时，父进程和子进程中都会存在相同的输出缓存。这里的关键在于，输出的操作尚未实际发生，因此二者中都存在了相同的内容。 例如，第一次循环调用 fork()，产生两个进程（父进程和子进程），接着它们各自执行 printf(-);，此时缓存中已经各有一个”填充”。当第二次循环再次调用 fork() 时，父进程和子进程又各自生成了新进程。最终，这样递归的操作会使得缓存中的信息复制给每一个子进程。 如果采用了 wait(NULL); 来确保父进程在子进程执行结束后再继续，则每个进程会在各自的缓冲区内再次输出那些已经缓存的”-“。由于缓存被复制，那么在输出结束后，总共产生了 8 个”-“。 输出机制与缓冲区进一步了解 Unix 下设备的分类可以提供更多背景信息。Unix 系统中，设备通常分为两类：块设备和字符设备。块设备，例如磁盘和内存，允许以块的形式进行数据存取，通常带有缓存。而字符设备（如键盘和串口）则一次处理一个字符，不具备缓存的特性。 在上面的案例中，在输出字符时，可以避免出现多余的”-“的办法就是修改 printf(-); 这一语句为： printf(- ); 或者 printf(-); fflush(stdout); 这样做是因为，当程序遇到换行符 或通过 fflush(stdout) 明确请求刷新时，缓存的内容会被强制输出，从而避免了多余的缓存复制，最终只会输出 6 个”-“。 进一步认识 fork()fork() 是 Unix 系统中创建新进程的系统调用，它有一个显著的特点：一次调用会产生两个进程（父进程和子进程），并且每个进程都将继续执行之后的代码。返回值为 0 时，表示当前进程为子进程；若返回值大于 0，说明当前进程为父进程，此时返回值为子进程的进程 ID。 在进行 fork() 的时候，父进程的整个运行时环境会被复制至子进程中，包括变量、缓冲区等。因此，所有在 fork() 之前的状态都会被延续到子进程中。 示例代码为了加深理解，可以看以下的代码示例： #include stdio.h#include sys/types.h#include unistd.h#include wait.hint main(void) int i; for(i=0; i2; i++) fork(); printf(ppid=%d, pid=%d, i=%d , getppid(), getpid(), i); sleep(10); // 让进程停留十秒，以便使用 pstree 查看进程树 return 0; 运行后，输出的进程树形状如下： ppid=8858, pid=8518, i=0 ppid=8858, pid=8518, i=1 ppid=8518, pid=8519, i=0 ppid=8518, pid=8519, i=1 ppid=8518, pid=8520, i=1 ppid=8519, pid=8521, i=1 使用 pstree -p | grep fork 可以得到如下进程树，显示出父进程和所有子进程的关系： |-bash(8858) |-fork(8518) |-fork(8519) `-fork(8520) 通过这样的可视化，上图中的颜色可以帮助理解进程间的关系。每个相同颜色的进程是相互关联的，显而易见的，正是在这多个进程中，输出缓冲区的内容被复制，这导致了”-“的重复输出。这种细微而复杂的机制是理解进程与输出之间关系的关键。 vfork在使用 vfork 创建的子进程中，调用 return 会导致整个程序崩溃，而使用 exit() 则不会。以下是一个简单的示例代码，运行后程序会挂掉，但若将子进程中的 return 改为 exit(0) 则不会出现这种情况。 #include stdio.h#include stdlib.h#include unistd.hint main(void) int var; var = 88; pid_t pid; if ((pid = vfork()) 0) printf(vfork error); exit(-1); else if (pid == 0) /* 子进程 */ var++; return 0; // 这里使用 return 会导致程序崩溃 printf(pid=%d, glob=%d, var=%d , getpid(), glob, var); return 0; 基础知识fork 与 vfork 的区别fork 和 vfork 主要区别在于内存处理方式。fork 创建一个子进程，并复制父进程的内存数据，而 vfork 则是创建一个子进程，双方共享父进程的内存数据。 根据手册页说明，vfork 的工作机制如下： 确保子进程会优先执行。 当子进程调用 exit() 或 exec() 时，父进程才会继续执行。 为何引入 vfork？早期的 fork 需要复制完整的调用者数据空间，资源消耗大，许多情况下随后就会调用 exec()。因此，BSD 系统推出 vfork()，以更高效的方式共享父进程的内存。 历史描述在 Linux 系统中，fork(2) 使用写时复制（copy-on-write）技术实现，因此开销主要来自于父进程页表的复制以及子进程的任务结构的唯一创建。然而，在早期版本的系统中，fork 需要对调用者的数据空间进行完整复制，通常是没必要的。这在内存开销上造成了不必要的负担。 return 与 exit 的差异使用 return 会导致子进程的 main() 函数返回，进而改变程序的函数栈。随着子进程的 main() 函数返回，相关的局部变量被释放，栈的状态也随之变化，而父进程正在等待子进程的结束。如果此时父进程尝试访问状态已改变的栈，程序就会发生错误。 子进程的 main() 函数返回，导致函数栈结构变化。 main() 函数返回会最终导致调用 exit() 或类似的函数。 父进程在子进程调用 exit() 后恢复执行，但此时栈已因子进程的返回而损坏，导致程序不再可用。 因此，使用 exit() 是正确的方式，它不会修改父进程的栈层次，使父进程得以继续正常执行。而如果使用 exit() 函数，仍有潜在问题，因为它会刷新并关闭所有标准输入输出流，可能导致父进程的数据受损。 使用 _exit() 系统调用更推荐的选择是使用 _exit() 函数。与 exit() 不同，_exit() 直接结束进程，并且不会影响父进程的 IO 状态。因此，用于 vfork() 的子进程中，调用 _exit() 是一个更安全的做法。 fork 的优化为了提高效率，fork 的实现采用了写时复制（copy-on-write）技术。这意味着在调用 fork 时，并不会立即复制内存，而只有在需要修改时才会从父进程中复制数据到子进程中。这种技术显著降低了效能开销，使得 fork 适合在 exec 被调用之前的使用。 虽然 Linux 的手册页不鼓励使用 vfork()，因为它存在各种潜在的风险，建议开发者优先选择 fork()，特别是在现代操作系统的优化下。 总结虽然在某些情况下 vfork 的使用可能带来性能收益，但其引入的复杂性和潜在问题使得它不如现代的 fork 调用来得安全可靠。尤其是在多线程或复杂数据处理的场景下，fork 提供了更高的灵活性和稳定性。","categories":["2.语言","C语言","多线程"]},{"title":"进程和线程","path":"/2024/06/03/2-语言-C语言-多线程-进程和线程/","content":"进程概念进程是操作系统管理资源和调度执行的基本单位，其本质在于资源的分配。简单来说，当用户启动一个程序时，操作系统会为其创建一个进程，并为该进程分配所需的资源，包括文件描述符、内存空间、磁盘空间、输入输出设备等。这一过程确保进程能够有效地执行其任务。创建之后，进程进入就绪队列，等待操作系统的调度。 在具体实现中，进程多个关键元素紧密相连，形成执行的基础。例如，在应用程序中打开一个文本编辑器，系统就会为此分配一个进程，用户可以在此进程内进行各种操作，如输入文本、打开文件等。 在采用微内核结构的操作系统（如 MacOS 和 Windows NT）中，进程的角色发生了转变。在这些系统中，进程担当资源分配的角色，而线程则负责实际的调度执行。这意味着，在微内核设计中，执行并发任务的基本单位是线程。 线程概念线程是进程内执行的最小单元，类似于在流程管理中细分的步骤。如果把进程视为完成特定任务的”容器”，那么线程则是这些任务中具体执行的子任务。例如，当用户启用数据库应用以生成工资单时，该应用会被视为一个进程。在生成工资单的过程中，用户可能会同时请求数据库中的其他信息，这些请求被表示为该进程内的多个线程。 线程能够独立于其它线程在处理器上调度执行，从而在多处理器环境下，使得多个线程可以并行运行。例如，某个数据库程序可以在一个处理器上生成工资报告，同时，在另一个处理器上接受新的用户查询请求。这种灵活性和并发特性，就是操作系统引入线程的主要原因。 引入线程的好处 易于调度：线程的调度和管理比进程更加灵活，操作系统可以更高效地处理线程的创建、撤销和切换。 提高并发性：通过多线程，一个进程可以并发执行不同的任务，从而提升应用程序的响应速度和处理效率。 开销少：创建线程所需的资源和时间远低于创建进程，因而线程的使用极大减轻了系统负担。 充分利用多处理器：一个进程如果拥有多个线程，系统可以将这些线程分配到不同处理器上并行处理，从而实现更高的计算效率。 进程和线程的关系 一对多关系：一个线程仅能属于一个进程，但一个进程可以拥有多个线程，且必定至少有一个线程在运行。 资源共享：所有属于同一进程的线程都可以共享该进程的资源，如内存和文件句柄。 调度单位：CPU 调度的基本单元是线程，而非进程，这使得线程能更灵活地利用处理器资源。 同步与协作：在执行过程中，线程之间需要协作与同步。不同进程中的线程需通过消息传递的方式来实现协调。 程序与进程的区别程序本身与进程之间有所不同。程序是一个静态的指令集合，而进程则是在内存中执行程序所产生的动态活动。借助于多道程序设计，一个操作系统能够在单个 CPU 上同时有效地管理多个进程，这极大地提高了计算资源的利用率，使用户感觉似乎自己独占资源。 进程与线程为何并存？尽管进程具有多道程序设计的优点，使得资源得以更为高效地使用，但仍然存在一些不足之处，主要体现在以下两点： 处理单一事件：进程在同一时间只能执行一项任务。这意味着当一个进程阻塞（例如等待用户输入），整个进程将停滞不前，即便其内有其他工作不受影响。 阻塞效应：如果正在执行的进程因为等待某个输入而阻塞，那么所有与之相关的操作也会随之无法执行。比如在课堂上，老师在黑板上讲解，学生因等待老师完成，上述多个任务（听讲、记笔记、思考）都无法得以并行进行。 通过引入线程，这些问题得以解决。不同的线程可以独立运行，提升了并行处理的能力，从而显著提高工作效率。 线程的优点线程的加入使得进程的实现形式更加灵活。它允许在更低的级别实现并发，使得各过程间的执行步伐不再单一。具体来说，线程能够与多个核的处理器协同工作，以进一步提升应用的性能表现。例如，现代文字处理软件如 Word，通常会开启多个线程来同时进行不同的操作，一个处理用户输入，一个负责界面显示，另一个进行文件存盘。这种设计无疑提升了用户的使用体验，让人感觉操作流畅、反应迅速。 进程与线程的区别总结进程与线程的核心区别在于它们处理资源的方式。进程拥有独立的地址空间，因此在其崩溃时，不会影响其他进程。而线程则是在同一进程内执行的多条路径，虽各自拥有堆栈和局部变量，但都共享进程的地址空间。这意味着若一个线程失败，整个进程也会随之崩溃。 虽然多进程的方案更为稳健，但在资源切换时会产生较大的开销。而在需要共享变量的并发操作中，使用线程更能发挥优势，这就是为什么进程与线程的并存显得尤为重要。 进程的定义进程是操作系统中的一个核心概念。每当执行一个程序，操作系统便会相应地创建一个进程。在这个过程中，操作系统将负责管理相关资源的分配与释放，因此可以把进程看成是程序执行的一个动态过程。比如，打开一个文本编辑器，系统在后台创建了一个进程，该进程负责处理所有与文本编辑相关的操作，如输入、保存和格式化。 进程与程序的区别程序是静态的，它由存储在磁盘上的结构化指令组成，像一本还未翻开的书，没有具体的执行状态。相对应地，进程则是一个动态概念，涉及到程序的执行过程，包括创建、调度以及最终消亡。举个例子，将一个网页加载到浏览器中时，浏览器会为该网页创建一个进程，而该网页的代码就是程序。程序在硬盘上保持不变，而进程的状态则随着执行而变化。 Linux 进程的四大要素 执行的程序：这是供进程执行的具体代码，多个进程可以同时执行同一个程序，比如多个实例的网络浏览器可以同时在运行同一款浏览器软件。 独立的内核堆栈：每个进程都有它自己的内核堆栈，用于管理系统调用时的资源，这意味着不同进程之间不共享堆栈，避免了数据冲突。 进程控制块（PCB）：在 Linux 中，进程控制块被称为 task_struct。它是系统管理进程的基础数据结构，记录了进程的所有必要信息，如进程状态、程序计数器、内存限制等。这使得操作系统能够高效地调度和管理进程。 独立的存储空间：每个进程都有自己的用户空间，以避免内存冲突和安全问题。除了内核空间，进程所占用的用户空间保证了程序可以在独立的环境中运行，不会干扰其他进程。 对应于进程，线程只有前三个元素，没有独立的存储空间。另一方面， 内核线程：没有用户空间，完全由内核管理，适用于内核中的多任务处理。 用户线程：则是多个线程共享同一用户空间，适合轻量级的任务。 Linux 进程分类 交互式进程：这些进程通常由 Shell 启动，频繁与用户交互，因此需要迅速响应用户操作。延迟时间通常要求在 50 到 150 毫秒内。例如，终端命令行、文本编辑器及图形界面应用程序都是典型的交互式进程。 批处理进程：通常在后台运行，不需要用户直接交互，因此对反应速度的要求不那么严格。这类进程常常会被调度期限制。例如，编译程序、数据库搜索引擎以及科学计算应用程序都是经典的批处理进程案例。 实时进程：此类进程对调度有极其严格的要求，不能被低优先级的进程阻塞，需要在短时间内做出反应。音视频处理、机器人控制等应用都属于实时进程。实时进程的调度完全依赖于 Linux 的调度算法。 批处理进程可能涉及 IO 或 CPU，而实时进程则更加侧重于时间的敏感度。 Linux 进程优先级 静态优先级（priority）：静态优先级不随时间变动，内核不会主动修改。它是通过系统调用 nice 进行修改，指明该进程在与其他进程竞争 CPU 时所允许的最大时间片，一般默认为 20。每一个普通进程的静态优先级范围从 100（高优先级）到 139（低优先级）。例如，创建一个新进程时，通常会继承父进程的优先级，但用户可以通过 nice() 或者 setpriority() 系统调用改变这个优先级。 动态优先级（counter）：动态优先级是由系统为每个进程运行而分配的时间片。只要进程占用 CPU，动态优先级就会不断减小，直到达到 0 时，进程将重新调度。初始动态优先级为 20。调度器在进行调度时主要依据动态优先级，其值在 100 到 139 之间。动态优先级的计算公式为： Dynamic priority = max(100, min(static priority - bonus + 5, 139)) 其中，Bonus 的值在 0-10 之间，可以因为进程的平均睡眠时间而波动，影响动态优先级的提升或降低。 实时优先级（rt_priority）：实时优先级值为 1000，仅在实时进程中生效。Linux 将实时优先级与 counter 值相加，以生成实时进程的优先权值。绝对高的权值保证了实时进程的优先调度，即便在其他进程同时运行的情况下。 基础时间量子（Base time quantum）：由静态优先级决定。当一个进程耗尽当前的基础时间量子，内核将重新分配一个新的基础时间量子。静态优先级与基础时间量子的关系如下： 当静态优先级小于 120 时： Base time quantum (毫秒) = (140 - static priority) * 20 当静态优先级大于或等于 120 时： Base time quantum (毫秒) = (140 - static priority) * 5 Linux 进程创建过程在 Linux 系统中，进程是一个包含代码、数据及分配给它的各种资源的实体。创建进程的主要方式是使用 fork() 函数。这个系统调用能够生成一个几乎完全相同的新进程，称为子进程。主进程和子进程可以执行相同的操作，但由于初始参数或变量的不同，它们也可以执行不同的任务。调用 fork() 后，系统将为新的进程分配资源，包括存储代码和数据的内存空间。随后，原有进程的所有值都会被复制到新进程中，只有极少数的值在复制时会发生变化，这一过程类似于克隆。 复制进程控制块（Process Control Block，PCB），在 Linux 中对应的结构体是 task_struct。 为新进程分配一个新的内核堆栈。调用如下函数： ti = alloc_thread_info_node(tsk, node);tsk-stack = ti;setup_thread_stack(tsk, orig); 注意，这里只是复制 thread_info 结构，而并不是直接复制内核堆栈本身。 修改复制的进程数据，比如进程标识符（PID）和进程链表等，这些处理在 copy_process 函数内部完成。 例如，*childregs = *current_pt_regs(); 复制当前的内核堆栈内容。 childregs-ax = 0; 表示子进程的 fork() 调用返回 0。 p-thread.sp = (unsigned long) childregs; 设置调度到子进程时的内核堆栈顶。 p-thread.ip = (unsigned long) ret_from_fork; 设置调度到子进程时的第一条指令地址。 具体的系统调用，比如 sys_fork、sys_vfork 和 sys_clone，最终都是在 do_fork 函数中执行。这个函数中包含： copy_process dup_task_struct：复制 PCB。 alloc_thread_info_node：分配了一个内存页面，实际上就是为内核堆栈空间提供。 setup_thread_stack：将 thread_info 相关数据复制过来。 新进程的执行起始地址是 ret_from_fork。*childregs = *current_pt_regs(); 用于复制当前内核堆栈的状态（即 pt_regs），这是系统调用过程中栈中的部分。由于 childregs-ax = 0; 的设置，子进程在 fork() 返回时获得一个返回值 0。接下来，系统将进程调度到 ret_from_fork，这意味着新进程是从该地址开始执行。 Linux 系统中进程的表示在 Linux 系统中，每个进程都由一个称为 task_struct 的结构体进行描述。这一结构体记录了进程的所有信息，其中包括多个核心字段。以下是一些重要的字段： struct task_struct volatile long state; // 进程的运行状态 unsigned int flags; // 进程的状态标志 unsigned int rt_priority; // 进程的运行优先级 struct mm_struct *mm; // 进程的内存使用情况 pid_t pid; // 进程号，唯一标识 pid_t tgid; // 进程组号 struct task_struct *real_parent; // 该进程的真实父进程 struct task_struct *parent; // 当前进程的父进程 struct list_head children; // 子进程的链表 struct list_head sibling; // 兄弟进程的链表 struct task_struct *group_leader; // 主线程的进程描述符 struct list_head thread_group; // 该进程的所有线程的链表 cputime_t utime, stime; // 用户态和内核态执行时间 char comm[TASK_COMM_LEN]; // 进程名称 struct files_struct *files; // 打开的文件信息 struct signal_struct *signal; // 信号处理信息 struct sigband_struct *sighand; // 信号处理句柄; 其中，结构体字段的含义如下： **进程号 (pid)**：相当于每个进程的身份证，它是进程的唯一标识符，每个进程的 PID 都是独特的。 进程状态：标识进程当前处于运行、等待、停止或死亡： A. 运行态：正在运行或准备运行的状态。 B. 等待态：进程在等待某个事件或资源。 C. 停止态：进程已被终止。 D. 死亡态：已终止但仍占用 task_struct。 优先级与时间片：不同优先级的进程被调度执行的顺序会有所不同，一般较高优先级的进程会优先运行。时间片则指定了进程在处理器上被执行的时间。 虚拟内存：许多进程会有一些虚拟内存，而内核线程和守护进程通常没有。Linux 内核必须跟踪这些虚拟内存如何映射到物理内存。 处理器上下文：一个进程可以看作是系统状态的集合。在进程执行时，需要使用处理器的寄存器和堆栈等上下文信息。当进程暂停时，所有 CPU 相关的上下文信息都会被保存在该进程的 task_struct 中。重新调度进程时，这些上下文信息便会从该结构中恢复。 Linux 进程中的文件在 Linux 操作系统中，每个进程都有两个结构体用来描述与文件相关的信息。 第一个是 fs_struct，它包含了进程当前的工作目录、根目录以及 umask。umask 定义了新文件创建时的默认权限。通过系统调用可以修改 umask。 第二个是 files_struct，它记录了进程当前打开的所有文件的信息。f_mode 字段用于描述文件的打开模式（只读、读写或只写）。此外，f_pos 表示下一个读或写操作在文件中的位置。f_inode 描述了文件的 VFS （虚拟文件系统）索引节点，而 f_ops 则是一个指向操作例程的指针，每个操作例程对应文件的特定操作。 每当一个文件被打开时，files_struct 中的空闲文件指针之一便会被用于指向新的文件结构。Linux 进程在启动时会自动打开三个文件描述符，分别是标准输入 (stdin)、标准输出 (stdout) 和标准错误 (stderr)，这些描述符通常是从创建该进程的父进程继承而来的。所有对文件的访问都是通过传递或返回文件描述符来完成的，这些描述符索引了进程的文件描述符向量，因此标准输入、标准输出、标准错误对应的文件描述符分别为 0、1 和 2。 进程中的虚拟内存在 Linux 操作系统中，运行二进制可执行文件时，首先会创建一个新进程。如果将整个可执行文件的代码和数据全部加载到物理内存中，会造成不必要的资源浪费，因为它们不可能同时使用。随着系统中进程数量的增加，这种浪费会被放大，从而导致系统效率下降。为了解决这个问题，Linux 使用了一种称为 请求调页（demand-paging） 的技术。具体而言，系统只在进程需要使用其虚拟内存时，才会实际将相关数据加载到物理内存中。因此系统并不会直接将代码和数据加载，而是修改进程的页表，标识虚拟内存页的存在，但其实际的物理数据尚未加载到内存。 当进程访问某个代码或数据时，如果所需内存不在物理内存中，硬件会触发一个 页故障，控制权会转交给 Linux 内核来解决。Linux 必须知道进程地址空间中的每个虚拟内存区域的来源，以及如何加载这些区域的数据以解决故障。 进程分配虚拟内存时，Linux 并不会立即为之保留物理内存，它只是创建了一个新的 vm_area_struct 数据结构，以描述该虚拟内存区域，并将其链接到进程的虚拟内存列表。当进程尝试写入新分配的虚拟内存区域时，系统会张开页故障。由于当前页表中缺乏对应的条目，处理器会导致页故障异常，由 Linux 内核来处理此事件。 Linux 将检查被引用的虚拟地址是否处于当前进程的虚拟内存地址空间内。如果是有效的，Linux 会创建适当的页面表项（PTE），并为当前进程分配一页物理内存。此时，数据可能需要通过文件系统或交换硬盘读入物理内存。进程随后将从产生页故障的指令处继续执行，由于物理地址已存在，可顺利继续其运行流程。如果虚拟地址不是有效的，系统则会抛出常见的”段错误”异常。","categories":["2.语言","C语言","多线程"]},{"title":"NAS相关配置","path":"/2024/05/31/1-平台-NAS-NAS相关配置/","content":"控制面板-网络-设置，设置 DNS 为 223.5.5.5 或者 114.114.114.114 或者 119.29.29.29 配置时间服务器控制面板-高级模式-区域选项，与 NTP 服务器同步：打字填入 ntp1.aliyun.com 或者 time.apple.com 配置 SSH 服务 打开控制面板 选择终端机和 SNMP，启动 SSH 功能，设置端口号 打开 mobaxterm 连接 NAS 的 IP 加上设置的 SSH 端口号 进入终端后输入用户名和密码登录，之后输入 sudo -i 进入 root 用户但是默认 22 端口要改掉，最好在 9000 以上 配置 FRP 自启动编辑 rc.local 添加自启动脚本 #!/bin/shcd /home/ubuntu/frpServer/frp_0.52.3_linux_amd64#按照配置文件启动服务器端./frps -c ./frps.toml 在 NAS 中添加脚本到任务计划 进入控制面板，选择任务计划，选择新增 - 触发的任务 - 用户定义的脚本 编辑任务名称，选择账号为 root，事件为开机，勾选已启动 编辑任务设置，编辑运行命令中的内容为 bash /root/start.sh 确定保存后在该任务上右击，选择运行 猫盘配置 FRP，同步至云服务器 配置 SYNC，同步至夸克移动百度 frp 方案依赖服务器带宽，比较卡","categories":["1.平台","NAS"]},{"title":"Alist网盘搭建","path":"/2024/05/30/1-平台-服务器-工具-Alist网盘搭建/","content":"Alist 备份文件地址 Alist 搭建方案 方案一：云服务器直接搭建及存储 方案二：云服务搭建页面，NAS 需要搭建 webdav，同时需要提供 NAS 穿透方案 方案三：云服务器提供穿透方案 frpCloudflared，NAS 搭建页面和存储 本地搭建仓库地址 https://github.com/alist-org/alist Relaes 地址 https://github.com/alist-org/alist/releases 下载对应版本的 alist 使用，直接解压后按照下述方式运行即可 # 解压下载的文件，得到可执行文件：unzip alist-xxxx.zip# 运行程序.\\alist.exe server 之后访问本地 http://127.0.0.1:5244/ 即可打开 Alist 页面。 Docker 搭建version: 3.3services: alist: #离线下载选择xhofe/alist-aria2:latest image: xhofe/alist:latest container_name: alist volumes: - ./alist_data:/opt/alist/data ports: - 9083:5244 environment: - PUID=0 - PGID=0 - UMASK=022 restart: unless-stopped Alist 启动脚本 VBSDim ws_alistDim ws_frpSet ws_alist = Wscript.CreateObject(Wscript.Shell)ws_alist.run alist.exe server,vbhideSet ws_frp = Wscript.CreateObject(Wscript.Shell)ws_frp.run .\\frpc.exe -c .\\frpc.toml,vbhideWscript.quit 配置本地# 获得管理员信息 以下两个不同版本，新版本也有随机生成和手动设置# 低于v3.25.0版本.\\alist.exe admin# 高于v3.25.0版本# 随机生成一个密码.\\alist.exe admin random# 手动设置一个密码 `NEW_PASSWORD`是指需要设置的密码.\\alist.exe admin set NEW_PASSWORD dockerAlist 配置存储直接按照 Alist 官方文档配置即可，配置完成后，NAS 利用 CloudSync 套件，添加 WebDav 站点后即可访问。 # 随机生成一个密码docker exec -it alist ./alist admin random# 手动设置一个密码,`NEW_PASSWORD`是指需要设置的密码docker exec -it alist ./alist admin set NEW_PASSWORD WebDav 配置如果没有单独留路径选项那正常就是在 站点后面添加 /dav 选项，如下所示： 其他 搭建 NAS，192.168.2.100:5000 搭建 Alist，192.168.2.100:5244 Alist 添加夸克网盘移动云盘百度网盘 NAS 中安装 CloudSync，链接到 Alist 的 WebDav，双向同步方案 通过 FRP 透传 NAS 的端口和 WebDav 的端口到外网 如何让 Alist 网盘内不同的文件夹同步","categories":["1.平台","服务器","工具"]},{"title":"进程间通讯","path":"/2024/05/29/2-语言-C语言-多线程-进程间通讯/","content":"进程间通信的目的在深入探讨进程间通信之前，首先理解为什么程序之间需要交换数据至关重要。传统上，程序之间的交流常常依赖于文件操作。例如，一个进程可能会将数据写入文本文件，另一个进程随后从该文件中读取。这种方法虽然直观，但存在显著的缺陷。当一个进程频繁地进行读写操作时，硬盘的读写速度成为瓶颈，导致性能下降。因此，需要学习更加高效的进程间通信方式。 为什么需要进程通信进程之间通常需要合作以完成共同的任务。在许多情况下，进程需要传递数据。例如，当一个进程希望结束另一个进程时，它必须通知目标进程进行释放。在这样的场景下，进程通信变得不可或缺。 例如，在调试环境中，调试进程可能需要等待特定的调试事件，并根据这些事件来控制被调试进程的运行状态。调试进程还可能需要读取和修改被调试进程的内存空间，这一切都离不开高效的进程通信机制。 进程通信的特点最初，可能会误认为通过文件或数据库进行进程间通信是高效的。实际上，这些方法需要频繁访问磁盘，效率较低。而进程间通信旨在提供快速和实时的数据交换。 重要的是，要注意进程之间是相互独立的，每个进程都有自己的用户空间，不能随意访问其他进程的数据。但是，通过操作系统作为中介，进程可以安全而高效地进行信息交流，避免了对缓慢介质的依赖。 在 Linux 系统中，进程间通信（IPC）主要可以通过以下六种方式实现： 数据传输 发送事件 资源共享 进程控制 通信种类与特点浅析1. 管道（Pipe）管道是 UnixLinux 系统中常见的通信方式，分为有名管道和无名管道。管道在操作上实现单向通信，通常采用半双工方式。这意味着数据只能沿一个方向流动，适合父子进程之间的通信。有名管道允许无亲属关系的进程进行数据交换，使其灵活性大大增强。例如，一个进程可以通过有名管道向任意其他进程传送数据，而不需要直接的亲属关系。 2. 信号（Signal）信号机制相对复杂，主要用于向接收进程通知特定事件的发生。例如，当某个进程需要处理某个异常情况时，它可以发送信号引起相关进程的注意。信号是一种低层次的、异步的通信方式，能够有效地唤醒进程并促使其响应特定事件。 3. 消息队列（Message Queue）消息队列是一种存放在内核中的异步通信机制。这种方式允许进程将消息发送到队列中，其他进程随后可以从队列中读取这些消息。消息队列的优点在于它能有效地管理和传递一系列数据，降低了两边进程之间直接通信的复杂性。 // msgLucy.c#include sys/ipc.h#include sys/msg.h#include sys/stat.h#include sys/types.h#include stdio.h#include fcntl.h#include signal.h#include stdlib.h#include string.h#define PROJID 0XFF#define LUCY 1#define PETER 2#define SEED gint mqid;// 终止处理函数，用于清除消息队列void terminate_handler(int signo) msgctl(mqid, IPC_RMID, NULL); // 删除消息队列 exit(0);int main() key_t mqkey; struct msgbuf long mtype; // 消息类型 char mtext[256]; // 消息内容 int *m; // 指向整型数据的指针 msg; int ret; // 生成一个唯一的消息队列键 mqkey = ftok(., SEED); // 参数：路径和项目标识符 if (mqkey == -1) perror(ftok error:); // 如果生成消息队列键失败，输出错误信息。 exit(-1); // 创建消息队列，如果已经存在则打开 mqid = msgget(mqkey, IPC_CREAT | 0666); // 设置访问权限 if (mqid == -1) perror(msgget error:); // 如果获取消息队列失败，输出错误信息。 exit(-1); // 设置信号处理函数，处理终止信号 signal(SIGINT, terminate_handler); signal(SIGTERM, terminate_handler); while (1) printf(Lucy: ); // 提示输入 fgets(msg.mtext, 256, stdin); // 从标准输入读取消息 // 检查是否输入了quit以退出程序 if (strncmp(quit, msg.mtext, 4) == 0) msgctl(mqid, IPC_RMID, NULL); // 清理消息队列 exit(0); msg.mtext[strlen(msg.mtext) - 1] = \\0; // 去掉换行符 msg.mtype = LUCY; // 设置消息类型 // 发送消息到消息队列，使用阻塞方式 msgsnd(mqid, msg, strlen(msg.mtext) + 1, 0); // 接收来自彼得的消息 msgrcv(mqid, msg, sizeof(struct msgbuf), PETER, 0); printf(Peter: %s , msg.mtext); // 输出彼得的消息 printf(the point m: %p , msg.m); // 输出指针地址 // msgPeter.c#include sys/ipc.h#include sys/msg.h#include sys/stat.h#include sys/types.h#include stdio.h#include fcntl.h#include signal.h#include stdlib.h#include string.h#define PROJID 0XFF#define LUCY 1#define PETER 2#define SEED gvoid terminate_handler(int );int mqid;// 终止处理函数，实现消息队列的清理void terminate_handler(int signo) msgctl(mqid, IPC_RMID, NULL); // 删除消息队列 exit(0);int main() key_t mqkey; int n; struct msgbuf long mtype; // 消息类型 char mtext[256]; // 消息内容 int *m; // 指向整型数据的指针 msg; int ret; // 生成唯一的消息队列键 mqkey = ftok(., SEED); if (mqkey == -1) perror(ftok error:); // 错误处理 exit(-1); // 获取消息队列，如果不存在则创建 if ((mqid = msgget(mqkey, 0)) == -1) printf(come here!!!!!!!!!!!!!! ); // 在此处表示未创建任何消息队列 mqid = msgget(mqkey, IPC_CREAT | 0666); // 创建新的消息队列 if (mqid == -1) perror(msgget error:); // 如果获取消息队列失败，输出错误信息。 exit(-1); n = 4; // 整数值 msg.m = n; // 设置指针 // 输出指针地址和指向值 printf(the point m: %p , msg.m); printf(msg.ms value is %d , *(msg.m)); // 设置信号处理函数，处理终止信号 signal(SIGINT, terminate_handler); signal(SIGTERM, terminate_handler); while (1) // 接收来自露西的消息 msgrcv(mqid, msg, sizeof(struct msgbuf), LUCY, 0); printf(LUCY: %s , msg.mtext); // 输出露西的消息 printf(Peter: ); // 提示输入 fgets(msg.mtext, 256, stdin); // 从标准输入读取消息 // 检查是否输入了quit以退出程序 if (strncmp(quit, msg.mtext, 4) == 0) msgctl(mqid, IPC_RMID, NULL); // 清理消息队列 exit(0); msg.mtext[strlen(msg.mtext) - 1] = \\0; // 去掉换行符 msg.mtype = PETER; // 设置消息类型 // 发送消息到消息队列 msgsnd(mqid, msg, sizeof(struct msgbuf), 0); 4. 共享内存（Shared Memory）共享内存是进程间通信中速度最快的一种方式。通过直接操作内存，进程可以轻松地读写共享数据，而不需要额外的格式化操作。这种方式常与信号量结合使用，以确保进程在访问共享资源时的同步。 5. 信号量（Semaphore）信号量是用于实现进程间互斥和同步的重要工具。它们并不直接存储通信数据，而是控制多个进程对共享资源的访问，比如在多线程环境中的线程信号量。信号量的基本形式包括二元信号量和计数信号量，能够灵活处理不同的并发需求。 6. 套接字（Socket）套接字是一种网络协议的接口，允许不在同一机器上的进程进行通信。它作为一种通用的 IPC 方式，在各种操作系统中均有实现，因此被广泛使用。这种方式的灵活性在于它能实现远程过程调用，使得分布式系统中的进程能够顺畅地交换数据。 通过理解这些通信机制的特点和应用场景，就能在 Linux 环境下有效地实现进程间的数据传输与控制，无论是简单的任务协调还是复杂的系统调试。","categories":["2.语言","C语言","多线程"]},{"title":"指针","path":"/2024/05/28/2-语言-C语言-指针-指针/","content":"什么是指针在计算机编程中，指针是一种变量类型，用于存储内存地址。简单来说，指针指向内存中的某个位置。 每个内存单元都有一个唯一的地址，指针可以存储这个地址，并通过引用该地址来访问内存中存储的数据。通过使用指针，们可以直接访问和操作内存中的数据，而不需要将数据本身直接存储在变量中。 务必弄清楚存储单元的地址和存储单元的内容这两个概念的区别 指针可以指向任何数据类型，例如整数、字符、数组、结构体等。通过操作指针，们可以在程序中动态地分配和释放内存，以及在函数之间传递复杂的数据结构。 使用指针时，们可以使用一些操作符来进行不同的操作，包括： 取址操作符（）：用于获取变量的地址。 解引用操作符（*）：用于访问指针所指向的地址处存储的值。 指针在编程中非常有用，特别是在需要处理动态内存分配、传递大量数据或需要直接操作内存的情况下。然而，使用指针也需要谨慎，因为错误的使用指针可能导致内存泄漏、野指针访问等问题。 什么是指针变量指针变量是一种特殊类型的变量，它存储了一个内存地址，可以用于指向其他变量或数据的位置。换句话说，指针变量保存了一个指向内存中某个位置的值。 指针变量的声明需要指定所指向的数据类型。这是因为指针变量需要知道要解引用时应该如何解释所指向的内存。例如，如果一个指针变量指向整数类型的数据，则解引用该指针将给出该位置上的整数值。 通过指针变量，们可以通过间接引用来访问和修改所指向的变量的值。通过解引用操作符（*），们可以访问指针变量指向的内存地址中存储的实际数据。 以下是一个示例，展示了指针变量的声明、初始化和使用的过程： int main() int num = 10; // 定义一个整数变量 int* ptr; // 定义一个指向整数的指针变量 ptr = num; // 将指针指向变量num的地址 printf(num的值：%d , num); // 输出 num 的值 printf(ptr所指向的值：%d , *ptr); // 输出 ptr 所指向的值，即 num 的值 *ptr = 20; // 通过指针修改 num 的值 printf(修改后的num的值：%d , num); // 输出修改后的 num 的值 return 0; 在上述示例中，指针变量 ptr 被声明为指向整数类型的指针。通过使用操作符，将 ptr 指向了 num 变量的地址。然后，通过解引用 ptr，可以访问和修改 num 的值。 指针变量在许多编程语言中都存在，并且在内存管理、动态数据结构和函数参数传递等方面发挥着重要的作用。但是，正确使用指针是需要小心谨慎的，以避免出现内存错误和潜在的安全问题。 指针变量作为函数参数当将指针变量作为函数参数传递时，有几个方面需要注意，以确保正确使用指针并避免潜在的错误： 传递指针的副本：在函数调用时，指针变量作为参数传递给函数时，实际上是传递指针的副本，而不是原始指针本身。这意味着在函数内部对指针的修改不会影响函数外部的指针。 指针有效性检查：在函数内部使用指针之前，应该进行有效性检查，确保指针不为 NULL。空指针可能会导致访问无效的内存地址，导致程序崩溃或产生不可预测的结果。 指针的传递方式：指针可以通过值传递或引用传递来传递给函数。如果要在函数内部修改指针本身的值（例如使其指向不同的内存地址），则需要使用指针的引用传递，即将指针的地址作为参数传递给函数。 避免野指针：确保在函数内部正确初始化指针或分配内存，避免使用未初始化的指针。同时，注意在函数结束前释放动态分配的内存，以避免出现野指针（指向无效内存）。 下面是一个示例，展示了如何在函数中使用指针变量作为参数： #include stdio.hvoid modifyPointer(int* ptr) if (ptr != NULL) // 检查指针的有效性 *ptr = 42; // 修改指针所指向的值 ptr = NULL; // 修改指针本身的值（不会影响函数外部的指针） int main() int num = 0; int* ptr = num; printf(初始值：%d , *ptr); // 输出初始值 modifyPointer(ptr); // 将指针作为参数传递给函数 printf(修改后的值：%d , *ptr); // 输出修改后的值 return 0; 在上述示例中，定义了一个 modifyPointer 函数，该函数接受一个整型指针作为参数。在函数内部，首先进行指针的有效性检查，然后修改指针所指向的值为 42。然后，将指针本身的值设置为 NULL，但请注意这不会影响函数外部的指针。 在 main 函数中，声明了一个整型变量 num，并将其地址赋值给指针 ptr。然后，通过调用 modifyPointer 函数，并将指针 ptr 作为参数传递给函数，实现了在函数内部修改指针所指向的值。 在最后的输出中，可以观察到指针所指向的值在函数调用后发生了修改。 总结来说，当指针变量作为函数参数传递时，需要注意指针的有效性、传递方式和可能对指针本身的修改。遵循这些注意事项可以更安全地使用指针，并确保函数对指针的操作正确有效。 函数的调用可以（而且只可以）得到一个返回值（即函数值），而使用指针变量作参数，可以得到多个变化了的值。 通过指针引用数组通过指针引用数组，可以使用指针来操作数组元素。在 C 语言中，数组名本身就是指向数组第一个元素的指针。通过将数组名赋值给指针变量，可以通过指针来访问和修改数组元素。 #include stdio.hint main() int arr[5] = 1, 2, 3, 4, 5; // 定义一个整数数组 int* ptr; ptr = arr; // 将数组名赋值给指针变量 /* ptr2 = arr[0]; //是否可以？*/ printf(数组元素通过指针访问： ); for (int i = 0; i 5; i++) printf(arr[%d] = %d , i, *(ptr + i)); // 通过指针访问数组元素 return 0; 在上述示例中，arr 是一个整数数组。通过将 arr 赋值给指针变量 ptr，ptr 就指向了数组的第一个元素。然后，使用指针 ptr 通过偏移来访问数组中的其他元素，使用解引用操作符（*）来获取元素的值。 在循环中，通过递增指针 ptr 的值来访问数组的不同位置。通过*(ptr + i)，可以获得指针 ptr**偏移 i 个元素位置处(偏移大小取决于数组类型)**的值，即数组 arr 中索引为 i 的元素。 通过指针引用数组，可以实现对数组的灵活访问和操作。指针算术运算可以用于遍历数组、进行元素的读取和修改，甚至可以通过指针动态分配数组的内存空间。然而，需要小心确保指针不越界，并遵循指针的安全使用规则，以避免潜在的错误和内存访问问题。 *p++获取*p 的值要快于*p+i 的值的获取 用数组名作函数参数用数组名作函数参数时，因为实参数组名代表该数组首元素的地址，形参应该是一个指针变量 用指向数组的指针作函数参数一维数组名可以作为函数参数，多维数组名也可作函数参数。用指针变量作形参，以接受实参数组名传递来的地址。可以有两种方法：①用指向变量的指针变量②用指向一维数组的指针变量 通过指针引用多维数组指针变量可以指向一维数组中的元素，也可以指向多维数组中的元素。但在概念上和使用方法上，多维数组的指针比一维数组的指针要复杂一些。a[i]+j 代表谁的地址？代表 a[i][j]的地址*(a[i]+j)代表什么？代表元素 a[i][j]*(*(a+i)+j)代表什么？与*(a[i]+j)等价 通过指针引用字符串 字符串是存放在字符数组中的。引用一个字符串，可以用以下两种方法。(1) 用字符数组存放一个字符串，可以通过数组名和格式声明”%s”输出该字符串，也可以通过数组名和下标引用字符串中一个字符。(2) 用字符指针变量指向一个字符串常量，通过字符指针变量引用字符串常量。 在 C 语言中，字符串实际上是以 null 字符（’\\0’）结尾的字符数组。通过指针引用字符串，可以使用指针来操作字符串的字符元素。 #include stdio.hint main() char str[] = Hello, World!; // 定义一个字符串数组 char* ptr = str; // 将数组名赋值给指针变量 printf(字符串通过指针访问： ); while (*ptr != \\0) printf(%c, *ptr); // 通过指针访问字符串字符 ptr++; // 指针后移 printf( ); return 0; 在上述示例中，str 是一个字符数组，即字符串。通过将 str 赋值给指针变量 ptr，ptr 就指向了字符串的第一个字符。 使用指针 ptr，通过解引用操作符（*）来访问字符串的字符。在循环中，检查当前指针指向的字符是否为 null 字符（字符串结尾的标志），如果不是，则打印该字符并将指针后移一位。这样，通过循环迭代，可以逐个字符地访问和处理字符串。 需要注意的是，由于字符串以 null 字符结尾，因此在使用指针引用字符串时，需要通过判断 null 字符来确定字符串的结束位置。 通过指针引用字符串，可以进行各种字符串操作，例如查找、拷贝、连接等。指针算术运算也可以用于在字符串中移动和定位。然而，同样需要小心确保指针不越界，并遵循指针的安全使用规则，以避免潜在的错误和内存访问问题。 使用字符指针变量和字符数组的比较 字符数组由若干个元素组成，每个元素中放一个字符，而字符指针变量中存放的是地址（字符串第 1 个字符的地址），决不是将字符串放到字符指针变量中 可以对字符指针变量赋值，但不能对数组名赋值。 编译时为字符数组分配若干存储单元，以存放各元素的值，而对字符指针变量，只分配一个存储单元 指针变量的值是可以改变的，而数组名代表一个固定的值(数组首元素的地址)，不能改变。 字符数组中各元素的值是可以改变的，但字符指针变量指向的字符串常量中的内容是不可以被取代的。 用指针变量指向一个格式字符串，可以用它代替 printf 函数中的格式字符串 char *format;format=a=%d,b=%f ; printf(format,a,b);//相当于printf(a=%d,b=%f ,a,b); 指向函数的指针 如果在程序中定义了一个函数，在编译时，编译系统为函数代码分配一段存储空间，这段存储空间的起始地址，称为这个函数的指针。 在 C 语言中，可以定义和使用指向函数的指针来引用和调用函数。指向函数的指针可以存储函数的地址，并允许通过指针来调用该函数。 #include stdio.h// 示例函数，接受两个整数参数并返回它们的和int add(int a, int b) return a + b;int main() int (*ptr)(int, int); // 定义一个指向函数的指针 ptr = add; // 将函数名赋值给指针变量 int result = ptr(3, 4); // 通过指针调用函数 printf(函数调用的结果：%d , result); return 0; 在上述示例中，add 是一个示例函数，接受两个整数参数并返回它们的和。首先，需要使用指针语法定义一个指向函数的指针变量 ptr，通过指定函数的返回类型和参数类型。 然后，通过将函数名赋值给指针变量，将函数的地址存储在指针中。在示例中，ptr add;将函数 add 的地址赋值给指针变量 ptr。 最后，可以通过指针调用函数，使用指针后面跟上参数列表来传递参数。在示例中，ptr(3, 4)调用通过指针引用的函数，并传递参数 3 和 4。 通过指向函数的指针，可以实现一些高级的编程技巧，如回调函数、动态函数调用等。通过指针可以在运行时根据需要选择要调用的函数。然而，需要确保指针的类型与所引用的函数类型相匹配，以避免类型错误和未定义行为。 指向函数的指针作为函数参数 指向函数的指针变量的一个重要用途是把函数的地址作为参数传递到其他函数 指向函数的指针可以作为函数参数，把函数的入口地址传递给形参，这样就能在被调用的函数中使用实参函数 返回指针值的函数 一个函数可以返回一个整型值、字符值、实型值等，也可以返回指针型的数据，即地址。其概念与以前类似，只是返回的值的类型是指针类型而已 在 C 语言中，可以定义一个返回指针值的函数，该函数返回一个指针类型的值，指向某个数据或数据结构。通过返回指针值，可以在函数内部动态分配内存，并返回指向该内存的指针。 #include stdio.h#include stdlib.h// 返回动态分配内存的整数数组的指针int* createIntArray(int size) int* arr = (int*)malloc(size * sizeof(int)); // 使用malloc动态分配内存 // 假设分配内存成功，将数组元素初始化为0 for (int i = 0; i size; i++) arr[i] = 0; return arr; // 返回指向数组的指针int main() int* ptr = createIntArray(5); // 调用返回指针值的函数，接收返回的指针 printf(动态分配的数组：); for (int i = 0; i 5; i++) printf(%d , ptr[i]); // 通过指针访问和打印数组元素 printf( ); free(ptr); // 释放动态分配的内存 return 0; 在上述示例中，createIntArray 是一个返回指针值的函数。函数接受一个整数参数 size，表示要分配的数组大小。在函数内部，使用 malloc 动态分配了 size 个整数大小的内存空间，并将指向该内存的指针 arr 返回。 在 main 函数中，通过调用 createIntArray 函数，并将返回的指针赋值给指针变量 ptr。然后，使用指针 ptr 可以访问和操作动态分配的数组。 在示例中，遍历指针 ptr，并打印数组元素的值。 最后，使用 free 函数释放动态分配的内存，以避免内存泄漏。 通过定义返回指针值的函数，可以实现动态分配内存，并将该内存的地址返回给调用者。这在需要在函数外部访问和操作动态分配的数据时非常有用。然而，需要小心确保在使用返回的指针之前，进行合适的内存管理和错误处理。 指针数组和多重指针指针数组和多重指针是在 C 语言中用于处理指针的概念。它们提供了对多个指针的管理和操作，使得可以更灵活地处理和访问内存中的数据。 指针数组：指针数组是一个数组，其元素都是指针类型。每个元素可以指向不同类型的数据或数据结构。通过指针数组，可以有效地管理多个指针，每个指针可以指向不同的对象。 例如，可以定义一个指针数组来存储多个字符串的地址： char* strArray[3]; // 定义一个指针数组，每个元素指向一个字符串 指针数组可以用于实现诸如字符串数组、指向不同类型对象的数组、函数指针数组等。 多重指针：多重指针是指指向指针的指针。通过多重指针，可以实现对指针的间接引用和操作。多重指针在某些情况下非常有用，特别是在需要修改指针本身的值时。 例如，可以定义一个多重指针来引用一个整型指针的地址： int** ptrPtr; // 定义一个多重指针，指向一个整型指针 多重指针常用于动态内存分配、多级指针结构的数据结构、函数传递指针的指针等情况。 指针数组和多重指针的主要作用如下： 灵活存储和管理多个指针：指针数组允许存储和管理多个指针，每个指针可以指向不同的数据或对象。这对于需要处理多个相关指针的情况非常有用，例如字符串数组、函数指针数组等。 动态内存分配和释放：多重指针在动态内存分配和释放中非常有用。通过多重指针，可以通过引用指向指针的指针来修改指针的值，从而实现对动态分配内存的管理和释放。 传递指针的指针：多重指针可以用于函数参数，允许在函数内部修改指针的值，并使得修改在函数外部也可见。这对于需要在函数内部修改指针本身的值的情况非常有用。 总而言之，指针数组和多重指针提供了对指针的灵活管理和操作的能力。它们在 C 语言中常用于处理复杂的数据结构、动态内存分配、函数指针等情况下，提供了更高级的指针使用方式，使得程序可以更加灵活地操作和处理内存中的数据。 动态内存分配与指向它的指针变量 非静态的局部变量是分配在内存中的动态存储区的，这个存储区是一个称为栈的区域C 语言还允许建立内存动态分配区域，以存放一些临时用的数据，这些数据需要时随时开辟，不需要时随时释放。这些数据是临时存放在一个特别的自由存储区，称为堆区 动态内存分配是指在程序运行时，根据需要在堆（Heap）中动态地分配内存空间。与静态内存分配相对，静态内存分配是在编译时为变量或数据结构分配固定大小的内存空间。 在 C 语言中，动态内存分配使用了关键的函数：malloc，calloc，free，realloc。malloc 函数用于动态分配内存空间，而 free 函数用于释放之前分配的内存空间。 当使用 malloc 函数时，需要指定要分配的内存空间的大小，并返回一个指向该内存空间的指针。这样就可以通过指针来引用和操作这块动态分配的内存。 以下是一个示例代码，展示了动态内存分配和指向它的指针变量的使用： #include stdio.h#include stdlib.hint main() int* ptr; // 声明一个指针变量 ptr = (int*)malloc(sizeof(int)); // 动态分配一个整数大小的内存空间 if (ptr == NULL) printf(内存分配失败 ); return 1; *ptr = 42; // 使用指针访问和修改动态分配的内存 printf(动态分配的内存中的值：%d , *ptr); free(ptr); // 释放动态分配的内存 return 0; 在上述示例中，首先声明一个指针变量 ptr。然后，使用 malloc 函数动态分配一个整数大小的内存空间，并将返回的指针赋值给 ptr。通过将 sizeof(int)作为参数传递给 malloc，可以确保分配的内存空间足够存储一个整数。 接下来，可以使用指针 ptr 来访问和修改动态分配的内存，例如将整数值 42 存储到分配的内存中。 最后，在不再需要动态分配的内存时，使用 free 函数释放该内存空间。这是非常重要的，以防止内存泄漏和资源浪费。 动态内存分配与指向它的指针变量的使用允许在程序运行时根据需要分配和释放内存空间。这对于需要在运行时动态管理数据的大小和生命周期的情况非常有用，例如动态创建数组、构建动态数据结构等。然而，需要谨慎使用动态内存分配，确保适当地管理和释放动态分配的内存，以避免内存泄漏和潜在的错误。 有关指针的小结指针的基本概念：指针是一个变量，其值是内存地址。指针可以指向不同类型的数据或数据结构。通过指针可以访问和操作所指向的数据。指针的声明和初始化：指针的声明使用指针符号 ，例如 int ptr;表示 ptr 是一个指向整数的指针。可以通过将变量的地址赋值给指针来初始化指针，例如 ptr 将指向 num 变量的地址赋值给 ptr。指针的运算：可以使用运算符解引用指针，获取指针所指向的值，例如ptr 表示指针 ptr 所指向的值。可以使用运算符获取变量的地址，例如num 表示变量 num 的地址。可以使用指针进行算术运算，例如指针的加法、减法等。指针与数组：数组名可以看作是指向数组第一个元素的指针。可以使用指针对数组进行遍历、修改和传递等操作。通过指针可以实现动态分配数组和动态管理数组大小。指针与字符串：字符串在 C 语言中是以字符数组的形式存储的。可以使用指针引用和操作字符串。使用指针可以实现字符串的遍历、拷贝、连接等操作。指向函数的指针：可以定义指向函数的指针，存储函数的地址。通过指针可以调用函数，实现函数的动态调用和回调机制。动态内存分配与指针：使用 malloc 函数可以在程序运行时动态分配内存空间。通过指针引用和操作动态分配的内存。使用 free 函数释放动态分配的内存，防止内存泄漏。 指针是 C 语言中强大而灵活的概念，它允许直接访问内存和数据，并提供了动态分配内存、处理复杂数据结构、实现高级编程技巧等能力。指针的正确使用需要注意内存管理、空指针检查等细节，以确保程序的正确性和健壮性。理解和掌握指针的相关知识点和用法，有助于更好地理解和编写 C 语言程序。 总结 首先要准确地弄清楚指针的含义。指针就是地址，凡是出现”指针”的地方，都可以用”地址”代替，例如，变量的指针就是变量的地址，指针变量就是地址变量 要区别指针和指针变量。指针就是地址本身，而指针变量是用来存放地址的变量。 什么叫”指向”？地址就意味着指向，因为通过地址能找到具有该地址的对象。对于指针变量来说，把谁的地址存放在指针变量中，就说此指针变量指向谁。 注意：只有与指针变量的基类型相同的数据的地址才能存放在相应的指针变量中。 void * 指针是一种特殊的指针，不指向任何类型的数据，如果需要用此地址指向某类型的数据，应先对地址进行类型转换。可以在程序中进行显式的类型转换，也可以由编译系统自动进行隐式转换。无论用哪种转换，读者必须了解要进行类型转换 要深入掌握在对数组的操作中怎样正确地使用指针，搞清楚指针的指向。一维数组名代表数组首元素的地址 有关指针变量的定义形式的归纳比较 指针运算(1) 指针变量加（减）一个整数例如：p++,p–,p+i,p-i,p+i,ｐ-i 等均是指针变量加（减）一个整数。将该指针变量的原值(是一个地址)和它指向的变量所占用的存储单元的字节数相加（减）。(2) 指针变量赋值将一个变量地址赋给一个指针变量, 不应把一个整数赋给指针变量(3) 两个指针变量可以相减如果两个指针变量都指向同一个数组中的元素，则两个指针变量值之差是两个指针之间的元素个数(4) 两个指针变量比较若两个指针指向同一个数组的元素，则可以进行比较指向前面的元素的指针变量”小于”指向后面元素的指针变量如果 p1 和 p2 不指向同一数组则比较无意义(5) 指针变量可以有空值该指针变量不指向任何变量，可以这样表示：pNULL;","categories":["2.语言","C语言","指针"]},{"title":"指针基础","path":"/2024/05/27/2-语言-C语言-指针-指针基础/","content":"指针基础概念: 地址:变量在内存中的编号。 地址变量: 存放地址的变量。 地址 pointer (指针) int a = 5; a = 4;int *p = a, b; 指针定义: 存储类型 数据类型 *指针变量名；int *pa;char *pc; 赋值并初始化: int a = 5;int *p = a; //初始化,定义同时并赋值 赋值: int a = 5;int *p;p = a; //赋值*p = 6; 引用: * 与 互为逆运算,自右向左。 int a = 0x666;int *p = a; //假如a的地址为0x20008000, p的地址为0x30008000printf(%#x , a); //0x666printf(%#x , p); //0x20008000printf(%#x , *p); //0x666printf(%#x , a); //0x20008000printf(%#x , p); //0x30008000printf(%#x , *(p)); //0x20008000p == a == (*p)a == *p == *(a) 指针运算关注*p++与*++p 的区别。 野指针void 指针void 型指针可以赋值给其他任意类型，但其他类型不可以赋值给 void 类型指针. 赋值给其他类型时，建议加上强制类型转换. int *p = (int *)malloc(N); const 指针int a = 99;int const a = 99;const int a = 99; const 使 a 常量化。 int a = 99; int b = 999;int *p = a; *p=*p+1; //通过p修改a的值p = b; //p指向其他变量int *const pp = a; //pp是常量//pp = b; //pp是常量不可以改变p的值，即不可以改变p的指向。*pp = *pp+1; //不可改变指向,但可以改变指向的值.int const *qq = a; //(*qq)是常量const int *qq = a; //同上，两种效果相同。//*qq=*qq+1; //*qq是常量,不可以通过*qq去改变a的值。qq=b; //qq可以指向其他的变量。a=a+1;//*qq常量化，表示不能通过*qq去改变a的值，但a可以改变。int const * const ppp = a; //ppp和*ppp都被常量化。const int *const ppp = a; 练习1.指针的加减法： char a = 100;char *p = a; 若：a 的地址为 0x20008000,则 p+1=0x______;*p + 1 =0x_____;(int )p + 1 = 0x______;(int *)p + 1 = 0x______;(char *)p + 1 = 0x______;(char)p + 1 = 0x______; 2.以下程序的运行结果是 ______。 #include stdio.hmain()\tint m=1, n=2, *p=m, *q=n, *r;\tr=p; p=q; q=r;\tprintf(%d,%d,%d,%d ,m,n,*p,*q); 3、若有语句 int *point,a=4; 和 point=a; 下面均代表地址的一组选项是 _______. a)a, point, *ab)*a, a, *pointc)*point, *point, ad)a, *point , point","categories":["2.语言","C语言","指针"]},{"title":"博客部署前提笔记","path":"/2024/05/24/1-平台-服务器-博客-博客部署前提笔记/","content":"部署平台 Vercel GitHub Pages Cloudflare Pages 自建服务器部署 Netlify：Netlify 额外提供每个站点每月 1000 个已识别的活跃用户和站点分析。 Railway：支持项目内 Dockerfile 和 docker 镜像，但不支持 docker-compose Cloudflare 的定位为一家全球性的互联网基础设施提供商，提供了一系列的网络安全和性能优化服务，包括内容分发网络(CDN)、DDoS 防护、SSLTLS 加密、DNS 管理等。Cloudflare Workers（serverless 计算平台）和 Cloudflare Pages 可以用来部署 nextjs 应用。 Railway 提供免费容器服务。支持主流语言 python、nodejs 等直接运行，支持 Dockerfile 在线构建 docker 镜像。支持使用 CLI 部署。此外，还提供大量模板直接构建。例如 code server（vscode 网页版）等。按量付费，每个月 5 美元免费额度，跑个小程序够用。支持通过 Github repo 进行部署 Vercel 是一个云服务平台，支持静态网站和动态网站的应用部署、预览和上线。如果用过 GitHub Pages ，那么心里可能不会太陌生，也能通过 vercel 集成 GitHub 后，在 GitHub 项目进行代码推送，PR 合并自动部署的目的，且不需要考虑服务器和域名问题。 其他部署涉及到的各项关键配置文件有以下，各文件路径基于 HexoGithubObsidian 的仓库根目录 文件所属 文件名 文件路径 文件用途 GitHub Actions blogPublish.yml .github/workflows 用于仓库同步到 github 之后，自动将源码生成静态页面，同步到发布仓库进行发布 GitHub .gitignore ./ 用于忽略 Hexo 和 Obsidian 中不需要同步到 Git 的文件(有些文件体积过大，占用仓库体积) Hexo _config.yml ./ Hexo 站点配置文件 Hexo package.json ./ npm 安装包及命令文件，部署站点时所需的和 hexo 相关的依赖包都在此文件中 Hexo-Stellar _config.yml themes/stellar/_config.yml Hexo 主题配置文件 Hexo-Stellar widgets.yml themes/stellar/_data/widgets.yml Stellar 主题中的控件配置文件 更换主题 修改 .github/workflows/blogPublish.yml 该文件中指定了主题仓库和主题配置文件，修改主题仓库 修改 _config.theme.yml 该文件中默认为 stellar 的主题配置文件，需要修改为指定的主题配置文件 修改站点配置文件 _config.yml 需要在站点配置文件中修改指定的主题 Qexo本地部署 博客本地部署方案拉取仓库并本地部署脚本 rm -rf ./BlogDeploygit clone git@github.com:liuluhua/BlogDeploy.gitcd ./BlogDeploymkdir themescd themesgit clone git@github.com:xaoxuu/hexo-theme-stellar.gitgit clone git@github.com:next-theme/hexo-theme-next.gitcd ..cp ./_config.theme.stellar.widgets.yml ./themes/hexo-theme-stellar/_data/widgets.ymlcp ./_config.theme.stellar.yml ./themes/hexo-theme-stellar/_config.ymlnpm installhexo cleanhexo ghexo s -p 9050 云服务器用 pm2 部署 先确保安装了 nodejs 和 npm，并使用 pnpm 作为 nextjs 项目的依赖管理工具 npm install -g pnpm 安装 pm2 做进程管理 npm install -g pm2 在项目根目录下安装依赖，构建输出产物 pnpm installpnpm build 使用 pm2 启动服务 pm2 start pnpm --name sorafm -- start --port 8015 使用 nginx 做反向代理，先确保安装和启动了 nginx： sudo apt install nginxsudo systemctl start nginx 为 nextjs 项目创建 nginx 配置： sudo vi /etc/nginx/conf/sorafm.confserver listen 80; location / proxy_pass http://127.0.0.1:8015/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; error_log /var/log/nginx/sorafm.error; nginx 重载新的网站配置： sudo nginx -s reload DNS 解析域名到服务器的公网 ip 在 DNS 控制台添加一条 A 记录，指向服务器的公网 ip，等解析生效后，就可以访问 nextjs 项目了。 配置 https 访问，可以在 Ubuntu 安装 certbot 生成域名证书： sudo apt updatesudo apt install certbot python3-certbot-nginx 为新域名生成新的证书，并使用 https 访问 sudo certbot --nginx -d sorafm.trys.ai 配置完成后，就可以安全访问 nextjs 项目了。 云服务器用 Docker 部署同样是使用 Ubuntu 云服务器，使用 pm2 部署 nextjs 更简单直接，轻量级部署，服务资源占用少。使用 docker 部署，系统隔离性更好，更方便移植，适用于微服务架构。要使用 docker 部署 nextjs 应用，先确保在服务器安装好了 docker，再来改造 nextjs 项目 修改项目根目录下的 next.config.mjs，使用 standalone 模式输出编译产物 /** @type import(next).NextConfig */const nextConfig = output: standalone,;export default nextConfig; 在 deploy 文件夹下新建 Dockerfile 文件，写入 docker 镜像构建内容 FROM node:18-alpine AS base# Install dependencies only when neededFROM base AS depsRUN apk add --no-cache libc6-compat yarn global add pnpmWORKDIR /app# Install dependencies based on the preferred package managerCOPY package.json pnpm-lock.yaml* ./RUN pnpm i --frozen-lockfile# Rebuild the source code only when neededFROM deps AS builderWORKDIR /app# Install dependencies based on the preferred package managerCOPY . .RUN pnpm build# Production image, copy all the files and run nextFROM base AS runnerWORKDIR /appRUN addgroup --system --gid 1001 nodejs \\ adduser --system --uid 1001 nextjs \\ mkdir .next \\ chown nextjs:nodejs .nextCOPY --from=builder /app/public ./publicCOPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/staticUSER nextjsEXPOSE 8080ENV NODE_ENV productionENV PORT 8080ENV HOSTNAME 0.0.0.0# server.js is created by next build from the standalone outputCMD [node, server.js] 在项目根目录下新建 .dockerignore 文件，写入构建镜像时要忽略的内容 .next.vercel.vscodedatadebugnode_modules 开始构建 docker 镜像 sudo docker build -f deploy/Dockerfile -t sorafm:latest . 使用 docker 运行服务 sudo docker run -itd -p 127.0.0.1:8014:8080 --restart=always sorafm:latest 服务运行成功后，再通过 nginx 配置公网访问，DNS 解析公网域名，certbot 配置 https 证书，这三个步骤跟上面使用 pm2 部署 nextjs 的方案一致。 Cloudflare 部署上述两种方案：使用 pm2 和使用 docker 部署 nextjs 应用，需要先有一台服务器。如果不想买服务器，而是通过托管的方式部署 nextjs 项目，可以选择 Cloudflare Pages，几乎免费的云部署方案。按照 Cloudflare 的官方文档，使用 Cloudflare Pages 部署 nextjs 项目，主要的步骤： 安装部署依赖 pnpm add -D @cloudflare/next-on-pages 在项目根目录创建一个配置文件 wrangler.toml name = sorafmcompatibility_date = 2024-07-29compatibility_flags = [nodejs_compat]pages_build_output_dir = .vercel/output/static 更新 next.config.mjs 文件 import setupDevPlatform from @cloudflare/next-on-pages/next-dev;/** @type import(next).NextConfig */const nextConfig = ;if (process.env.NODE_ENV === development) await setupDevPlatform();export default nextConfig; 修改服务端路由运行时，对所有的 api 路由文件 route.ts 和所有的页面路由文件 page.tsx 都添加一行代码，指定使用 edge 运行时： export const runtime = edge; 修改 package.json 文件，添加编译指令 pages:build: npx @cloudflare/next-on-pages,preview: pnpmb pages:build wrangler pages dev,deploy: pnpm pages:build wrangler pages deploy 在项目根目录通过命令行部署项目到 Cloudflare Pages npm run deploy 在第一次运行 deploy 命令时，需要填写项目名称，跳转 Cloudflare 进行授权验证等。发布完成后，就可以在 Cloudflare-Workers and Pages 管理后台看到项目了。跟 Vercel 一样，Cloudflare 也为发布的项目生成一个子域名：xxx.pages.dev，部署成功可直接公网访问，方便项目快速上线验证。","categories":["1.平台","服务器","博客"]},{"title":"指针定义","path":"/2024/05/23/2-语言-C语言-指针-指针定义/","content":"void funArray(int *);void funArray(int []);void funArray2(int(*)[]);void funArray2(int [][]);void pointArray(int **);void pointArray(int *[]);void funPoint(int (*)(int, char **));int (*p[3])[3];int (*p)[3];void arrayPointArray(int (*[])[3]); typedef void (*fun)(int );typedef void (*)(int) fun;//此定义有误？fun function (fun);void (*function(void (*) (int)))(int);","categories":["2.语言","C语言","指针"]},{"title":"Docker下将已部署的wordpress备份及迁移","path":"/2024/05/22/1-平台-Docker-Docker下将已部署的wordpress备份及迁移/","content":"镜像# Docker 镜像备份 在已经部署好 wordpress 的机器上，使用 docker save 命令将 Docker 镜像保存到本地文件中。 使用以下命令将名为 wordpress 和 mysql 的 Docker 镜像分别保存到名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中： docker save wordpress wordpress_image.tar #保存wordpressdocker save mysql mysql_image.tar #保存mysql # Docker 镜像读取 将 wordpress_image.tar 和 mysql_image.tar 文件复制到目标机器上。在目标机器上，使用 docker load 命令将本地文件中的 Docker 镜像加载到 Docker 中。 使用以下命令将名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中的 Docker 镜像加载到 Docker 中： docker load wordpress_image.tardocker load mysql_image.tar 文件系统文件系统备份要将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方，可以使用 Docker 的导入和导出功能，具体步骤如下： 在运行 WordPress 应用程序的 Docker 容器上执行以下命令，将容器中的 WordPress 应用程序导出为 tar 文件： docker export container_id wordpress.tar 这将在当前目录下创建一个名为 wordpress.tar 的文件，其中包含 Docker 容器中的整个 WordPress 应用程序。 文件系统读取将 wordpress.tar 文件传输到要部署 WordPress 应用程序的目标服务器上。在目标服务器上执行以下命令，将 wordpress.tar 文件导入到 Docker 中： cat wordpress.tar | docker import - image_name:tag 其中，image_name 是为导入的 Docker 镜像指定的名称，tag 是为该镜像指定的标签。运行导入的 Docker 镜像，启动 WordPress 应用程序的容器： docker run -p host_port:container_port -d image_name:tag 其中，host_port 是要将容器的端口映射到主机上的端口号，container_port 是容器内运行 WordPress 应用程序的端口号。这样，就可以将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方。 启动 Docker 按照之前的 docker-compose 的方法启动 dokcer 使用 docker ps -a --no-trunc 需要修改并添加 command wordpress 是 docker-entrypoint.sh apache2-foreground mysql 是 docker-entrypoint.sh mysqld 使用 docker run 命令在目标机器上启动该 Docker 镜像。例如，使用以下命令在目标机器上启动名为 wordpress 的 Docker 镜像： #启动mysqldocker run -d \\--name mysql \\-v mysql_data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=liuluhua \\-e MYSQL_DATABASE=wordpress \\-e MYSQL_USER=liuluhua \\-e MYSQL_PASSWORD=liuluhua \\mysql:latest docker-entrypoint.sh mysqld #启动wordpressdocker run -d \\--name wordpress \\--link mysql \\-p 80:80 \\-e WORDPRESS_DB_HOST=mysql:3306 \\-e WORDPRESS_DB_USER=liuluhua \\-e WORDPRESS_DB_PASSWORD=liuluhua \\-e WORDPRESS_DB_NAME=wordpress \\-v ./wp-content:/var/www/html/wp-content \\-v ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini \\wordpress:latest docker-entrypoint.sh apache2-foreground 启动参数： **-d**：表示以”后台模式”运行容器，即使容器的主进程退出也不会停止容器。 **--name**：表示为容器指定一个名称，这样可以方便地对容器进行管理。 **-v**：表示将主机的目录或文件与容器内的目录或文件进行挂载，即数据卷。例，-v mysql_data:/var/lib/mysql 表示将主机的 mysql_data 目录挂载到容器内的 /var/lib/mysql 目录，这样容器内的 MySQL 数据就可以持久化存储在主机上。 **-e**：表示设置容器内的环境变量。例如，-e MYSQL_ROOT_PASSWORD=liuluhua 表示设置容器内的 MYSQL_ROOT_PASSWORD 环境变量为 liuluhua。 **--link**：表示将一个容器链接到另一个容器，使得容器之间可以进行通信。例如，--link mysql 表示将容器链接到名为 mysql 的容器。 **-p**：表示将容器的端口映射到主机的端口。例如，-p 80:80 表示将容器的 80 端口映射到主机的 80 端口，使得可以通过主机的 IP 地址访问容器内的服务。 **wordpress:latest 和 mysql:latest**：表示使用 wordpress 和 mysql 镜像的最新版本来创建容器。 **./wp-content:/var/www/html/wp-content 和 ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini**：表示将主机上的 wp-content 目录和 uploads.ini 文件挂载到容器内的 /var/www/html/wp-content 目录和 /usr/local/etc/php/conf.d/uploads.ini 文件，使得容器内的 WordPress 网站可以访问这些文件。","categories":["1.平台","Docker"]},{"title":"Docker命令","path":"/2024/05/20/1-平台-Docker-Docker命令/","content":"Docker 是一个开源的容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者和系统管理员在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括 VMs（虚拟机）、bare metal、OpenStack 集群、云端、数据中心和其他的基础应用平台。容器是完全使用沙箱机制，相互之间不会有任何接口。 架构Docker 的架构包括以下组件： Docker 守护进程：运行在主机上的后台进程，负责管理 Docker 对象，如镜像、容器、网络和数据卷。 Docker 客户端：通过 Docker API 与 Docker 守护进程通信。 Docker 镜像：包含应用程序和其依赖项的只读文件系统。 Docker 容器：Docker 镜像的可运行实例。 Docker 仓库：用于存储 Docker 镜像的地方。 主要需要注意的是镜像IMAGE和容器CONTAINER 可以将镜像视为虚拟机的一个快照，镜像是容器的基础，定义了容器的基本配置和内容 容器，即为镜像的实例化内容，当启动一个容器时，Docker 会从镜像创建一个只读的文件系统层，并在其上添加一个可写层，容器中的所有更改和数据都存储在这个可写层上。 基本命令Docker 提供了一系列命令行工具，用于管理 Docker 容器和镜像，以及执行与容器相关的操作 镜像 docker images：列出本地所有的镜像。 -a 列出所有的镜像（含中间映像层，默认，过滤掉中间映像层） --digests 显示镜像的摘要信息； -f 显示满足条件的镜像； --format 指定返回值的模板文件； --no-trunc 显示完整的镜像信息； -q 只显示镜像 ID。 docker rmi image：删除一个镜像。 docker pull image：从仓库中拉取一个镜像。 docker push image：将一个镜像推送到仓库中。 docker run image：根据指定的镜像创建并启动一个新的容器。 docker build -t image_name path_to_dockerfile：根据 Dockerfile 构建新的自定义镜像。 -f 指定要使用的 Dockerfile 路径 --label=[] 设置镜像使用的元数据； -m 设置内存最大值 --memory-swap 设置 Swap 的最大值为内存+swap，”-1”表示不限 swap --no-cache 创建镜像的过程不使用缓存 --pull 尝试去更新镜像的新版本 -q 安静模式，成功后只输出镜像 ID --rm 设置镜像成功后删除中间容器 --ulimit Ulimit 配置 docker tag 标记本地镜像 docker history 查看指定镜像的创建历史 -H 以可读的格式打印镜像大小和日期，默认为 true； --no-trunc 显示完整的提交记录； -q 仅列出提交记录 ID。 容器 docker ps：列出当前正在运行的容器。 -a 列出所有，包括运行中的和已经停止的 -f 根据条件过滤显示内容 -l 列出最近创建的容器 -n 列出最近创建的 N 个容器，N 为数字 -q 只显示容器 ID -s 显示总文件大小 docker create --name myserver nginx:latest:创建一个新的容器但不启动它 docker start container_id/container_name：启动已停止的容器。 docker stop container_id/container_name：停止运行中的容器。 docker restart container_id/container_name：重启容器。 docker kill -s kill myweb 参数 -s 向容器发送信号 docker rm container_id/container_name：删除指定容器。 -f 强制删除一个运行中的容器 -l 删除指定的链接 -v 删除与容器关联和卷 docker logs container_id/container_name：查看容器的日志输出。 -f 跟踪日志输出 -t 显示时间戳 --tail 只显示最新 n 条容器日志 --since 显示某个开始时间的所有日志 docker exec -it container_id/container_name command：在正在运行的容器中执行特定命令。 -d 在后台运行 -i 保持 STDIN 打开 -t 分配一个伪终端 docker exec -it container /bin/bash 进入 container 容器中的命令行 docker inspect container_id/container_name：查看容器的详细信息，包括 IP 地址、端口映射等。 -f 指定返回值格式或模板文件 -s 显示总文件大小 --type 为指定类型返回 JSON docker port container_id/container_name 显示指定容器的端口映射 运行docker run创建并启动一个新的容器常用参数如下：-d #后台运行容器，并返回容器ID-i #以交互式模式运行容器，常与-t参数同时使用-t #给容器重新分配一个伪终端，常与-i参数同时使用--name #给容器指定一个名称-m #指定容器使用内存的最大值--net #指定容器使用的网络类型--link #链接到另一个容器 其他 docker network ls：列出所有 Docker 网络。 docker volume ls：列出所有 Docker 卷。 docker cp /data/index.html bd96d72ed9c7:/web/ 将物理主机中的 /data/index.html 拷贝到容器 bd96d72ed9c7:/web/ 目录下 docker login 登陆到 Docker 镜像仓库，未指定镜像仓库地址，默认为官方仓库 -u 登陆的用户名 -p 登陆的密码 docker logout 登出 Docker 镜像仓库，未指定镜像仓库地址，默认为官方仓库 docker info 显示 Docker 系统信息，包括镜像和容器数 docker version 显示 Docker 版本信息 DockerfileDockerfile 是一种文本文件，负责定义如何构建 Docker 镜像。这个文件包含了一系列具体的指令和参数，用于指导 Docker 引擎在基础镜像上添加应用程序代码、运行时环境、依赖项和配置文件等，最终生成一个新的 Docker 镜像。以下是一些典型的 Dockerfile 指令及其详细说明： **FROM**：此指令标明基础镜像。每个 Docker 镜像都是基于某个基础镜像构建的，这个指令用于确定构建的起点。例如，使用 FROM ubuntu:latest 表示镜像将基于最新版本的 Ubuntu 操作系统。 **MAINTAINER**：这个指令用于设置镜像的作者信息，通常包括作者的姓名和电子邮件。例如，MAINTAINER Senthilkumar Palani info@ostechnix.com 说明了镜像的维护者及联系方式。 **RUN**：用于在镜像构建过程中执行特定命令。可以用于安装软件包、更新操作系统、配置环境等。例如，RUN apt-get install -y software-properties-common python 安装了 Python 及相关软件。 **CMD**：此指令设置容器启动时要执行的命令。如果在运行镜像时未指明其他命令，则会执行此默认命令。示例：CMD [/usr/bin/node, /var/www/app.js] 设置 Node.js 执行的初始脚本。 **ENTRYPOINT**：设定容器启动时的固定命令。虽然它与 CMD 类似，但 ENTRYPOINT 更加严格，允许传递参数以供指定命令使用。使用例：ENTRYPOINT [/usr/bin/node] 可与 CMD 的其他参数组合使用。 **COPY**：将本地文件复制到镜像中。例如，COPY index.html /usr/share/nginx/html/ 这条指令将本地的 index.html 文件复制到镜像内的指定路径。 **ADD**：与 COPY 类似，但支持复制网络资源和自动解压缩压缩文件。例如，ADD package.tar.gz /usr/src/app/ 会将压缩包解压到指定目录。 **WORKDIR**：设定容器的工作目录，后续的指令将在此目录下执行。例如，WORKDIR /var/www 会将工作目录切换到 varwww。 **EXPOSE**：声明容器运行时监听的端口号，但不会自动将端口映射到宿主机。例如，EXPOSE 8080 指定容器会监听 8080 端口。 **ENV**：设置环境变量，可以在容器内部被访问。示例：ENV APP_ENV production 设置了名为 APP_ENV 的环境变量，值为 production。 **ARG**：声明构建时参数，构建过程中可以通过 --build-arg 参数传递。例如，ARG VERSION=1.0 可以在构建时指定软件版本。 **VOLUME**：创建可从宿主机或其他容器挂载的挂载点。比如，VOLUME /data 会创建一个名为 data 的挂载点，方便数据共享。 **USER**：设置运行镜像的用户，比如 USER node 将切换到 node 用户身份运行容器中的命令。 **ONBUILD**：定义在子镜像构建时触发执行的特定操作。通过 ONBUILD RUN apt-get update 设定后续构建时自动更新软件包索引。 以下是一个简单的 Dockerfile 示例： FROM ubuntu:latestMAINTAINER Senthilkumar Palani info@ostechnix.comRUN apt-get install -y software-properties-common pythonRUN add-apt-repository ppa:chris-lea/node.jsRUN echo deb http://us.archive.ubuntu.com/ubuntu/ jammy universe /etc/apt/sources.listRUN apt-get updateRUN apt-get install -y nodejsRUN mkdir /var/wwwADD app.js /var/www/app.jsCMD [/usr/bin/node, /var/www/app.js] 要使用 Dockerfile 创建 Docker 镜像，运行以下命令： # docker build -t alpine . 注意命令末尾的点（.），指代当前上下文。 若 Dockerfile 存放于其他目录，可以用 -f 标志指定路径，例如： # docker build -f /path/to/a/Dockerfile . 创建镜像后，可以使用如下命令运行它： # docker run -it alpine 该命令将启动 Alpine 容器并连接到其中，使用户能够进行进一步的操作。 导入和导出 docker build 通过构建 Dockerfile 创建镜像。 docker commit 将运行中的容器保存为新镜像。 docker export 导出容器的文件系统为 tar 文件。 docker save 将镜像保存为 tar 文件，适用于镜像的备份和迁移。 docker build 目的：用于从 Dockerfile 创建镜像。 过程：开发者通过编写 Dockerfile，定义应用程序的环境、依赖和配置。执行 docker build 命令时，Docker 会逐步读取 Dockerfile 中的指令，构建出相应的镜像。 示例：如果有一个名为 Dockerfile 的文件，其中包含安装某个 Node.js 应用的所有指令，运行以下命令： docker build -t my-node-app . 这将创建一个名为 my-node-app 的新镜像。 docker commit 目的：用于将当前运行的容器的状态保存成新的镜像。 过程：当对一个已经启动的容器进行修改，如安装新软件或者修改配置文件后，可以使用 docker commit 命令，将这些更改保存为新的镜像。 示例：假设有一个名为 my-running-app 的正在运行的容器，通过以下命令可以把它的当前状态保存为新的镜像： docker commit my-running-app my-new-imagedocker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]## 参数说明-a : 提交的镜像作者；-c : 使用 Dockerfile 指令来创建镜像；-m : 提交时的说明文字；-p : 在 commit 时，将容器暂停 此命令将创建一个名为 my-new-image 的新镜像。 docker save 目的：用于将本地 Docker 镜像保存为一个 tar 文件。 过程：与 docker export 不同，docker save 会将镜像的信息和所有层一起打包，这样可方便地在另一个 Docker 实例中导入。 示例：若要保存名为 my-image 的镜像，可以使用： docker save -o my-image.tar my-image 这条命令将创建一个包含镜像 my-image 的 tar 文件，命名为 my-image.tar。 docker export 目的：用于将容器的文件系统打包成 tar 文件。 过程：docker export 只保留容器的文件系统，不包括元数据和历史记录。这个命令适合于备份容器的文件系统，或者将容器内容迁移到另一个环境。使用 docker export 命令导出的文件无法用作 Docker 镜像的源文件，只能用于将容器迁移到另一个 Docker 主机或将容器中的文件系统导出到本地。 示例：如果需要将容器 my-container 的文件系统导出，可以执行： docker export my-container my-container.tar 这样，会生成一个名为 my-container.tar 的文件，其中包含容器的所有文件。 docker load使用 docker load 命令来导入镜像。 docker load --input uu.tar(也可以使用docker load -i uu.tar或者 docker load uu.tar)docker load uu.tar","categories":["1.平台","Docker"]},{"title":"DRM+EGL 执行错误分析","path":"/2024/05/17/1-平台-Linux-Graphics-DRM-EGL-执行错误分析/","content":"mesa 运行 DRM+EGL 执行错误分析： src\\egl\\main\\egldefines.h 中定义了 EGL_VENDOR #define _EGL_VENDOR_STRING Mesa Project 输出结果为 Mesa Project，确认输出无误 https://askubuntu.com/questions/1027168/why-is-opengl-vendor-mesa-project 以上问题项中，该选项显卡为 Nvidia glxinfo tells you what the X11 server you’re running under is using for GL. It doesn’t tell you what an arbitrary program not using X11 might use. 故分析如下： 未正确启用显卡，EGL 采用的是 Mesa 软件渲染，故无法提供正确的 config 证明： 是否有 GLX 或 Wayland 等方案解决该问题","categories":["1.平台","Linux","Graphics"]},{"title":"LinuxGraphics 笔记","path":"/2024/05/14/1-平台-Linux-Graphics-LinuxGraphics-笔记/","content":"modetest 命令 利用 xrandr 在命令行指定输出 xrandr --output HDMI-1 --mode 1920x1080 | ./a.out Mesa 是一个开源的实现了 OpenGL 规范的图形库，它提供了一个 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU（OpenGL Utility Library）通常被视为 OpenGL 的一个独立组件，而不是 OpenGL 的核心部分。 GLU 提供了一些 OpenGL 的辅助功能，比如进行复杂几何运算和对象构造等。虽然 GLU 在许多 OpenGL 实现中都有支持，但它并不是 OpenGL 规范的一部分，因此在某些情况下，OpenGL 实现可能不包括 GLU 或将其作为一个可选组件。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，例如从系统的 OpenGL 安装中获取，或者从其他地方下载 GLU 的实现。然后将 GLU 的头文件包含到的项目中，并链接 GLU 库以使用 GLU 提供的功能。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 DRM利用 DRM+GBM+EGL 指定显卡运行代码分析 Mesa GBM（Generic Buffer Management）是一个开源图形缓冲区管理库，用于管理图形内存缓冲区。它是 Mesa 3D 图形库的一部分。GBM 主要用于 Linux 平台，为 Direct Rendering Manager (DRM) 内核子系统提供了一个用户空间 API。它提供了一种统一的接口，用于在 Linux 系统中管理图形缓冲区和设备之间的交互。 在 DRM（Direct Rendering Manager）中，CRTC（Cathode Ray Tube Controller）是一个显示管控制器，负责控制显示管的扫描、同步和刷新操作。它与 Encoder（编码器）和 Connector（连接器）之间存在着一定的联系。 CRTC（Cathode Ray Tube Controller）：CRTC 控制着实际显示设备的扫描和刷新操作。每个 CRTC 都与一个显示管（如液晶显示器或投影仪）相关联，负责生成该显示设备的图像信号。一个显卡可能有多个 CRTC，每个 CRTC 控制一个显示输出。 Encoder（编码器）：Encoder 是 CRTC 输出信号的编码器，将图像数据转换为特定格式的信号以便发送到显示设备。Encoder 通常与特定类型的连接器（如 HDMI、DVI、VGA 等）相关联，以便将图像数据转换为对应的视频信号格式。一个 CRTC 可能与多个 Encoder 相关联，这意味着它可以同时支持多种连接器类型。 Connector（连接器）：Connector 表示与显卡相连的物理显示端口，如 HDMI 接口、DVI 接口等。每个 Connector 对应一个实际的显示输出接口，比如连接显示器或投影仪的端口。每个 Connector 都与一个 Encoder 相关联，该 Encoder 负责将图像数据编码成连接器所需的信号格式。 在 DRM 中，通常的工作流程是： 用户空间（如图形驱动程序）通过 DRM 接口选择一个 Connector，然后创建一个 CRTC 并将其与所选 Connector 关联起来。 然后，用户空间会创建一个 Encoder，并将其与所选的 Connector 关联起来，以便将图像数据编码成正确的视频信号格式。 最后，用户空间会将帧缓冲区（Framebuffer）的内容提交给 CRTC 进行显示。CRTC 接收到帧缓冲区的内容后，会将其发送给相关联的 Encoder，最终显示到连接器所代表的显示设备上。 总之，CRTC 负责控制实际的显示设备，Encoder 负责将图像数据转换为视频信号格式，而 Connector 则表示实际的物理显示端口，它们之间相互关联，共同完成图像显示的任务。 EGL 是 Khronos 渲染 API（如 OpenGL、OpenGL ES 或 OpenVG）与底层本地平台 (窗口) 系统之间的接口。 EGL 主要功能：处理图形上下文管理、Buffer 管理和渲染同步 Display (EGLDisplay): 对实际显示设备窗口系统的抽象； Surface (EGLSurface): 存储图像的内存区域； Context (EGLContext): 存储渲染 API 的状态信息；一套标准的 EGL 绘制流程简介: 获取 EGL Display 对象：eglGetDisplay 初始化与 EGLDisplay 之间的连接：eglInitialize 获取 EGLConfig 对象：eglChooseConfig eglGetconfigs 创建 EGLContext 实例：eglCreateContext 创建 EGLSurface 实例：eglCreatewindowSurface eglCratePbufferSurface 连接 EGLContext 和 EGLSurface 上下文: eglMakeCurrent 使用 OpenGL ES API 绘制图形：gl_* 切换 front buffer 和 back buffer 显示：eglSwapBuffer 断开并释放与 EGLSurface 关联的 EGLContext 对象：eglRelease 删除 EGLSurface 对象 删除 EGLContext 对象 终止与 EGLDisplay 之间的连接 EGL Display 的获取EGLDisplay eglGetDisplay(NativeDisplayType native_display)EGLDisplay eglGetPlatformDisplay( EGLenum platform, void * native_display, const EGLAttrib * attrib_list);EGLDisplay eglGetPlatformDisplayEXT( EGLenum platform, void *native_display, const EGLint *attrib_list); eglGetDisplay 会根据现在的环境来决定默认的原生窗口系统，其他两个需要手动指定平台； compositor 运行相当于是裸机运行没有窗口环境，首先必须通过 GBM 或者 EGL_PLATFORM_DEVICE_EXT 扩展这两种方式来获取 EGLDisplay; GBM 概念: 基于 GEMTTM 的驱动对外是没有提供统一的内存管理接口的，至少 Buffer Object 创建销毁等操作是需要自行提供设备相关的即口进行实现的。 用户态没有统一的接口对缓冲区进行管理，这导致某些特定用户态程序的开发的困难，如 wayland compositor。 简单的说 GBM 就是为了实现 DRM(gbm_device) 作为 EGL 的本地平台，创建的句柄可以用来初始化 EGL 和创建渲染目标缓冲区 // get gdm_device// path = /dev/dri/renderD128 / dev/dri/card0egl_gbm.render_fd = open(path, O_RDWR|O_CLOEXEC);assert(-1 != egl_gbm.render_fd);egl_gbm.gbm_device = gbm_create_device(egl_gbm.render_fd);assert(NULL != egl_gbm.gbm_device);// get display1. egl_gbm.display = eglGetDisplay((EGLNativeDisplayType)egl_gbm.gbm_device);2. egl_gbm.display = eglGetPlatformDisplay(EGL_PLATFORM_GBM_KHR, egl_gbm.gbm_device, NULL);3. egl_gbm.display = eglGetPlatformDisplayEXT(EGL_PLATFORM_GBM_MESA, egl_gbm.gbm_device, NULL);// wlroots里面从严谨性来说，通过GBM获取EGL Display的时候，eglGetPlatformDisplayEXT后面的参数应该是EGL_PLATFORM_GBM_MESA而不是EGL_PLATFORM_GBM_KHR； Wayland：Wayland 是一种图形显示服务器协议，而 DRM 是 Linux 内核中的 Direct Rendering Manager 子系统，用于管理图形硬件驱动程序。在 Wayland 中，客户端应用程序通过 Wayland 协议与显示服务器通信，而 Wayland 服务器通过 DRM 接口与底层的图形硬件交互。 ** GBM**：直接的关系是 DRM 和 GBM，其中 DRM（Direct Rendering Manager）是 Linux 内核中的子系统，用于管理图形硬件的驱动程序，而 GBM（Generic Buffer Manager）是一个用户态库，提供了一个标准接口，用于分配、管理和操作图形内存，通常与 DRM 配合使用。GBM 通常与 DRM（Direct Rendering Manager）配合使用，用于与底层的图形硬件进行交互。应用程序可以使用 GBM 接口来分配和管理图形缓冲区，以便进行硬件加速的图形渲染。GBM 与 Wayland 无直接关联，但在一些特定的场景下，它们可能会一起使用。 GBM 控制 EGL：GBM 通常与 EGL 结合使用，以在硬件加速的图形渲染中创建和管理图形表面（buffers）。EGL（Embedded-System Graphics Library）是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。 EGL 操作 OpenGL API 进行操作：EGL 用于管理 OpenGL 或 OpenGL ES 的上下文和表面，以便应用程序可以使用 OpenGL API 进行图形操作。EGL 提供了一个标准的接口，用于在不同的图形系统中创建和管理 OpenGL 上下文和表面，以便实现跨平台的图形渲染。 确定显卡linux 内核检测到机器上的显卡时，会加载正确的设备驱动程序（位于内核树中的 ./drivers/gpu/drm/xy），并提供两个字符设备来控制显卡。 Udev （或使用的任何热插拔应用程序）将把它们创建为 /dev/dri/card0 /dev/dri/controlID64 只需要第一个。 可以像在这里做的那样，在应用程序中硬编码这个路径，但建议使用真正支持热插拔和多座的 libudev。不过，这超出了本文的讨论范围。 如果有多块显卡，可能还会有 /dev/dri/card1、/dev/dri/card2、…… modeset_open(out,node)： 辅助函数用于打开作为 @node 给定的 DRM 设备。 成功时，新的 fd 将存储在 @out 中。如果失败，则返回负错误代码。 打开文件后，还要检查 DRM_CAP_DUMB_BUFFER 功能。 如果驱动程序支持该功能，就可以创建简单的内存映射缓冲区，而无需任何依赖于驱动程序的代码。 由于希望避免使用任何 radeon、nvidia、intel 等驱动程序的特定代码，因此在此依赖于 DUMB_BUFFER。 确认显示设备需要找到可用的显示设备。 libdrm 提供了 drmModeRes 结构，其中包含所有需要的信息。 通过 drmModeGetResources(fd) 获取， 通过 drmModeFreeResources(res) 释放。 显卡上的物理连接器称为 “connector”。可以将显示器插入其中并控制显示内容。 肯定会对当前使用的 connector 感兴趣，因此，需遍历连接器列表，并尝试在每个可用的显示器上显示测试图片。 然而，这并不像听起来那么容易。首先，需要检查连接器是否被实际使用（显示器已插入并打开）。 然后，需要找到一个能控制该连接器的 CRTC，CRTC 稍后介绍。 然后，创建一个帧缓冲器对象 framebuffer object。 准备完成后就可以对帧缓冲区进行 mmap()，并在其中绘制测试图片。 然后，就可以告诉 DRM 设备在给定的 CRTC 上用选定的连接器显示帧缓冲。 由于要在帧缓存上绘制动态图像，因此必须记住所有这些设置。 因此，要为成功初始化的每对连接器 +crtc+ 帧缓冲器创建一个 “struct modeset_dev “ 对象，并将其推入全局设备列表。 因此，下一步需要实际准备好找到的所有连接器。 这段文字主要讲述了在 Linux 系统中确定显卡和显示设备的过程。以下是关键点的概括： 内核检测与驱动加载：Linux 内核会自动检测并加载适合的显卡驱动程序。 创建字符设备：显卡驱动程序会创建两个字符设备，用于控制显卡。 确认显示设备和 CRTC：通过遍历连接器列表，并尝试在每个可用显示器上显示测试图片，来确定合适的显示设备（CRTC）。 避免完整模式集的设置：在使用 CRTC 之前，需要确保其他设备没有占用该 CRTC。 创建并维护设备列表：为成功初始化的每一对连接器 +CRTC+ 帧缓冲器创建一个 struct modeset_dev 对象，并将其添加到全局设备列表中。modeset_prepare(fd)：该辅助函数将 DRM fd 作为参数，然后简单地从设备中获取资源信息。 如果初始化成功，只需将此对象作为新设备添加到全局模式集设备列表中。 资源结构包含所有连接器 ID 的列表。 使用辅助函数 drmModeGetConnector() 获取每个连接器的更多信息。 如果连接器当前未使用，也未插入监视器，的辅助函数 modeset_setup_dev() 将返回 -ENOENT。 因此，可以忽略该连接器。 modeset_find_crtc(fd, res, conn, dev)： 这个小助手试图为给定的连接器找到合适的 CRTC。 实际上，必须再引入一个 DRM 对象，以便更清楚地说明这一点：编码器（Encoders）。 编码器可以帮助 CRTC 将帧缓冲器中的数据转换成正确的格式，以便用于所选的连接器。 不需要了解更多的转换信息就能使用它。 不过，必须知道，每个连接器可以使用的编码器都是有限的。 而每个编码器只能与有限的 CRTC 配合使用。 因此，要做的就是尝试每一个可用的编码器，并寻找该编码器可以配合使用的 CRTC。 如果找到了第一个工作组合，就会很高兴，并将其写入 @dev 结构。 但在遍历所有可用编码器之前，首先要在一个连接器上尝试当前激活的编码器 +CRTC，以避免出现完整的模式集。 不过，在使用 CRTC 之前，必须确保之前设置的其他设备都没有使用该 CRTC。 请记住，每个 CRTC 只能驱动一个连接器！因此，只需遍历之前设置的设备的 “modeset_list”，并检查该 CRTC 之前是否未被使用。 否则，将继续使用下一个 CRTC编码器组合。","categories":["1.平台","Linux","Graphics"]},{"title":"Ubuntu更换国内源","path":"/2024/05/09/1-平台-Linux-Ubuntu-Ubuntu更换国内源/","content":"Ubuntu 更换国内源Ubuntu 本身的源使用的是国内的源，下载速度比较慢。在 Ubuntu 24.04 之前，Ubuntu 的软件源配置文件使用传统的 One-Line-Style，路径为 etcaptsources.list；从 Ubuntu 24.04 开始，Ubuntu 的软件源配置文件变更为 DEB822 格式，路径为 etcaptsources.list.dubuntu.sources。 清华源地址 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu-ports/ bionic 代表 ubuntu18 Ubntu24 之前版本备份etcaptsources.list 文件mv /etc/apt/sources.list /etc/apt/sourses.list.backup 新建etcaptsources.list 文件并添加以下内容#163源deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 更改完成之后执行一下 apt update 命令 其他的一些 apt 命令sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 其他几个国内的源：#中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse#阿里云源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse#清华源deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse Ubuntu24Ubuntu 24.04 使用中科大源的配置方法如下： 备份源配置文件在终端中输入以下命令： sudo cp /etc/apt/sources.list.d/ubuntu.sources /etc/apt/sources.list.d/ubuntu.sources.bak 编辑源配置文件输入以下命令打开源配置文件进行编辑： sudo vim /etc/apt/sources.list.d/ubuntu.sources 添加中科大源配置将以下内容添加到文件中： Types: debURIs: https://mirrors.ustc.edu.cn/ubuntuSuites: noble noble-updates noble-backportsComponents: main restricted universe multiverseSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpgTypes: debURIs: https://mirrors.ustc.edu.cn/ubuntuSuites: noble-securityComponents: main restricted universe multiverseSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg 更新软件源列表在终端中输入以下命令更新软件源列表： sudo apt-get update 如果需要升级系统软件包，可以继续输入以下命令： sudo apt-get upgrade","categories":["1.平台","Linux","Ubuntu"]},{"title":"加密方案","path":"/2024/05/08/1-平台-Linux-加密-加密方案/","content":"3568 应用程序及主板可执行文件加密在针对可执行文件的加壳加密和解密中，通常会使用以下步骤： 加壳加密： 选择壳程序： 选择一个用于加壳的程序，通常是一个小型的程序，它可以将原始的 ELF 文件嵌入到自身中，并添加解密逻辑。 嵌入并加密原始 ELF 文件： 将原始的 ELF 可执行文件嵌入到壳程序中，并对嵌入的原始 ELF 文件进行加密处理，使用加密算法对文件内容进行加密，确保只有正确的解密密钥可以解密文件。 生成加密后的文件： 将加密后的 ELF 文件保存为一个新的可执行文件，这个文件是经过加密处理的。 解密： 执行加密后的文件： 执行加密后的 ELF 文件，这个文件是壳程序，它包含了解密逻辑。 解密逻辑： 壳程序在运行时会对自身进行解密，并将嵌入的原始 ELF 文件解密出来。 还原原始 ELF 文件： 解密后的原始 ELF 文件会被还原到内存中，然后壳程序会将控制权转移到原始 ELF 文件，使得原始程序可以正常执行。 本文档实现的加密方式主要分为以下两个模块： 内核空间下，基于内核密钥保留服务的 ELF 文件解密并交付内核正常运行模块 用户空间下，基于非对称加密算法的 ELF 文件内容加密，主要针对 ELF Header 模块【可选加密 program header 和 section header】 1. 应用程序加壳1.1 ELF 文件格式介绍应用程序加壳模块对应用程序进行加密操作，主要针对以下模块进行加密操作 ELF header Program header table 【可选】 Section header table 【可选】 其中 ELF header 指明了 ELF 文件的整体信息，如 ELF 文件的 magic value、类型、版本、目标机器等。 #define EI_NIDENT (16)typedef struct unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version 文件版本,目前常见的ELF文件版本均为EV_CURRENT(1)*/ Elf_Addr e_entry; /* Entry point virtual address 入口虚拟地址。*/ Elf_Off e_phoff; /* Program header table file offset 段表文件偏移。*/ Elf_Off e_shoff; /* Section header table file offset 节表文件偏移。*/ Elf_Word e_flags; /* Processor-specific flags 处理器特定的标志，一般为0。*/ Elf_Half e_ehsize; /* ELF header size in bytes Elf_Header的大小（字节）*/ Elf_Half e_phentsize;\t/* Program header table entry size 段头的大小（字节）。*/ Elf_Half e_phnum; /* Program header table entry count 段的数量。*/ Elf_Half e_shentsize;\t/* Section header table entry size 节头的大小（字节）。*/ Elf_Half e_shnum; /* Section header table entry count 字的数量。*/ Elf_Half e_shstrndx; /* Section header string table index 节字符串表的节索引*/ Elf_Ehdr;[e_ident]包含了Maigc Number和其它信息，共16字节。\t0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。[e_type]ELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。[e_machine]处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 另外，ELF header 还指明了 program header table 与 section header table 两个表在文件中的偏移位置、条目个数、条目大小。 这两个表的位置和长度随着 sectionsegment 的个数而变化，而 ELF header 总是位于文件最开头，且长度固定。 如果想要访问 program header table 和 section header table 中的信息，必须通过 ELF header 来找到它们在文件中的确切位置。 Program header table 主要描述了将哪一个或哪几个 section 组织为一个 segment，以及各个 segment 的描述信息。 ELF 程序头是对二进制文件中段的描述，是程序装载必需的一部分。段（segment）是在内核装载时被解析的，描述了磁盘上可执行文件的内存布局以及如何映射到内存中。可以通过引用原始 ELF 头中名为 e_phoff（程序头表偏移量）的偏移量来得到程序头表， Section header table 描述了 ELF 文件中所有的 section，以及每个 section 的类型、长度等描述信息。 节，不是段。段是程序执行的必要组成部分，在每个段中，会有代码或者数据被划分为不同的节。节头表是对这些节的位置和大小的描述，主要用于链接和调试。节头对于程序的执行来说不是必需的，没有节头表，程序仍可以正常执行，因为节头表没有对程序的内存布局进行描述，对程序内存布局的描述是程序头表的任务。节头是对程序头的补充。readelf –l 命令可以显示一个段对应有哪些节，可以很直观地看到节和段之间的关系。 Section header table 中并不存储每个 section 的名称。所有 section 的名称全部存储在一个名为 section header string table 的 section 中，名称之间用 \\0 分隔。在 ELF header 中，记录了该 section 在 section header table 中的索引。 1.2 功能模块针对以上理解，加壳程序的功能有以下： 针对 ELF 文件，通过字段异或【RSA 加密(可选)】的方式进行覆写 ELF header【ProgramSection header table(可选)】 ELF 开头修改为 HMAVIC【加密方式字段】【加密内容字段】ELF 【可选】单独进行末尾追加签名，确认为 HMAVIC 程序 1.3 代码实现#define SIGN_OFFSET 9#define SIGN_CONTENT HMAVIC#define SIGN_LENGTH 6 调试 xxd -l 100 a.runreadelf -h a.run 2. 内核密钥保留服务2.1 密钥配置文件配置文件内容 #表示这个配置文件包含一系列的请求信息，用于生成证书请求[ req ]# 指定生成的 RSA 密钥长度为 2048 位default_bits = 2048# 指定用于请求的分辨名 (DN)，在 [ req_distinguished_name ] 部分中定义distinguished_name = req_distinguished_name# 禁用交互式提示，生成证书时不会要求用户输入prompt = no# 指定字符编码为 UTF-8string_mask = utf8only# 指定用于 X.509 扩展的配置，定义在 [ myexts ] 部分x509_extensions = myexts# 定义了请求的分辨名信息，包括组织 (O)、通用名 (CN) 和电子邮件地址 (emailAddress)[ req_distinguished_name ]# 指定组织名为hmavicO = hmavic# 指定通用名为 verification for hmavicCN = verification for hmavic# 指定电子邮件地址emailAddress = liuluhua7@gmail.com# 定义了 X.509 扩展信息，包括基本约束 (basicConstraints)、密钥用途 (keyUsage)、主题密钥标识符 (subjectKeyIdentifier) 和颁发者密钥标识符 (authorityKeyIdentifier)[ myexts ]# 指定证书不是 CA 证书，即不具有颁发其他证书的权限basicConstraints=critical,CA:FALSE# 指定密钥用途为数字签名keyUsage=digitalSignature# 指定使用 SHA-1 哈希算法生成主题密钥标识符subjectKeyIdentifier=hash# 指定使用密钥标识符生成颁发者密钥标识符authorityKeyIdentifier=keyid 生成密钥并导入证书 openssl req -new -nodes -utf8 -sha256 -days 36500 -batch -x509 -config x509.hm.genkey -outform PEM -out kernel_key.pem -keyout kernel_key.pem 使用 OpenSSL 工具生成一个配置信息由 x509.hm.genkey 指定的自签名的 X.509 格式证书。 以下是命令中每个选项的解释： openssl req：使用 OpenSSL 工具中的 req 子命令，用于处理证书请求和生成证书。-new：指定创建一个新的证书请求。-nodes：不加密生成的私钥，即不设置私钥密码。-utf8：指定使用 UTF-8 编码。-sha256：指定使用 SHA-256 哈希算法生成证书签名。-days 36500：指定证书的有效期为 36500 天-batch：在生成证书请求时不会提示用户输入任何信息，而是使用配置文件中指定的默认值。-x509：指定生成自签名的 X.509 格式证书，而不是生成证书请求。-config x509.genkey：指定使用配置文件 x509.genkey 中的配置信息来生成证书。-outform PEM：指定输出的证书格式为 PEM 格式。-out kernel_key.pem：指定输出的证书文件名为 kernel_key.pem。-keyout kernel_key.pem：指定输出的私钥文件名为 kernel_key.pem，因为在本例中私钥和证书是一对的。 2.2 编译内核修改 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 在文件最后增加以下内容： ## Certificates for signature checking#CONFIG_SYSTEM_TRUSTED_KEYRING=yCONFIG_SYSTEM_TRUSTED_KEYS=certs/kernel_key.pem 进入顶层目录执行 ./build.sh kernel 在编译过程中，应该可以看到如下信息： ...EXTRACT_CERTS PATH_TO_CERT/kernel_key.pemAS certs/system_certificates.oAR certs/built-in.o... 待内核编译完成，烧录内核至开发板，查看 proc 文件系统中的 /proc/keys。如果能够看到自行生成的密钥，那么说明该密钥已经被放置于内核的系统密钥环中。 3. 内核模块脱壳并运行3.1 功能模块针对加壳进行编写脱壳模块功能如下： 内核模块安装时进行 RSA 核验，核验通过则安装模块，否则卸载模块 注入到内核 ELF 运行之前，对 HMAVIC 开头的 ELF 进行拦截 根据加密方式和内容进行解密处理，解密完成后覆写内容交由 Linux 内核处理 【可选】针对未签名程序，拒绝执行 3.2 将解密模块嵌入内核中为 ELF 的签名与验证生成了一对 RSA 公私钥，将公私钥以符合 X.509 标准的方式导入到一个 PEM 编码的文件中。通过上述机制，可以将文件中的公钥证书编译到内核的系统密钥环上。这样，在 ELF 签名验证模块 中，可以通过使用系统密钥环中的公钥证书，对 ELF 文件中的签名信息进行验证。 首先，对 Linux 内核中已有的 内核模块签名 验证机制的代码进行了分析。在内核源代码目录 certs/system_keyring.c 中，定义了内核内置的受信密钥： certssystem_keyring.c 复制 static struct key *builtin_trusted_keys; 但由于这个变量没有被声明为 extern，因此无法在其它内核代码中直接引用这个变量。但是在这个源文件中，开放了 verify_pkcs7_signature() 函数，使得其它内核代码能够通过这个函数，间接使用内置密钥环的签名验证功能： certssystem_keyring.c 复制 /** * verify_pkcs7_signature - Verify a PKCS#7-based signature on system data. * @data: The data to be verified (NULL if expecting internal data). * @len: Size of @data. * @raw_pkcs7: The PKCS#7 message that is the signature. * @pkcs7_len: The size of @raw_pkcs7. * @trusted_keys: Trusted keys to use (NULL for builtin trusted keys only, * (void *)1UL for all trusted keys). * @usage: The use to which the key is being put. * @view_content: Callback to gain access to content. * @ctx: Context for callback. */int verify_pkcs7_signature(const void *data, size_t len, const void *raw_pkcs7, size_t pkcs7_len, struct key *trusted_keys, enum key_being_used_for usage, int (*view_content)(void *ctx, const void *data, size_t len, size_t asn1hdrlen), void *ctx)... 在内核代码中，通过 #include linux/verification.h 使用该函数时，输入 签名数据 与 被签名数据 的 缓冲区内存地址 和 缓冲区长度，就能够使用内置密钥完成签名认证。因此，ELF 签名验证模块 只要能够从 ELF 文件中正确提取 PKCS #7 格式的签名数据，以及签名保护的目标数据，就可以通过这个函数验证数字签名是否正确。 模块代码 ```编译 Makefile```makefileifneq ($(KERNELRELEASE),)obj-m := binfmt_elf_signature_verification.oelse# KDIR := ../#KDIR := /lib/modules/$(shell uname -r)/buildKDIR := /home/forlinx/Desktop/OK3568-linux-source/kernelall: $(MAKE) -C $(KDIR) M=$(PWD) modulesclean: $(RM) *.ko $(RM) *.o $(RM) *.mod* $(RM) *.symvers $(RM) *.order $(RM) .*.mk $(RM) .*.cmd $(RM) -r .tmp_versionsendif 执行 make ARCH=arm64 CROSS_COMPILE=/home/forlinx/Desktop/OK3568-linux-source/buildroot/output/OK3568/host/bin/aarch64-buildroot-linux-gnu- 参考Linux ELF 文件数据完整性保护系统 附录 A OpenSSL 进行密钥生成验证A1 私钥openssl genpkey -algorithm RSA -out private_key.pem -aes256 将生成一个 AES256 加密的 RSA 私钥，并将其保存到名为 private_key.pem 的文件中。 生成时需要密码，密码为 HmAvic@123 A2 公钥openssl rsa -in private_key.pem -pubout -out public_key.pem 将从私钥文件 private_key.pem 中提取公钥，并将其保存到名为 public_key.pem 的文件中。 A3 签名openssl dgst -sha256 -sign private_key.pem -out signature.bin your_elf_file 使用 SHA-256 算法对 your_elf_file 进行签名，并将签名结果保存到 signature.bin 文件中。 A4 签名认证openssl dgst -sha256 -verify public_key.pem -signature signature.bin your_elf_file 使用公钥 public_key.pem 验证 signature.bin 文件中的签名是否与 your_elf_file 匹配。 A5 签名和认证代码实现 #include stdio.h#include stdlib.h#include openssl/rsa.h#include openssl/pem.h#include openssl/sha.h#define BUF_SIZE 1024// 函数声明int sign_file(const char* file_path, const char* private_key_path, const char* signature_path);int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path);int main() const char* file_path = your_elf_file; const char* private_key_path = private_key.pem; const char* public_key_path = public_key.pem; const char* signature_path = signature.bin; // 签名文件 if (sign_file(file_path, private_key_path, signature_path) != 0) fprintf(stderr, Failed to sign file. ); return 1; printf(File signed successfully. ); // 验证签名 if (verify_signature(file_path, signature_path, public_key_path) != 0) fprintf(stderr, Signature verification failed. ); return 1; printf(Signature verified successfully. ); return 0;int sign_file(const char* file_path, const char* private_key_path, const char* signature_path) FILE* file = fopen(file_path, rb); if (!file) fprintf(stderr, Failed to open file. ); return 1; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) SHA256_Update(sha256, buffer, bytes_read); unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, sha256); fclose(file); // 加载私钥 FILE* private_key_file = fopen(private_key_path, rb); if (!private_key_file) fprintf(stderr, Failed to open private key file. ); return 1; RSA* rsa = PEM_read_RSAPrivateKey(private_key_file, NULL, NULL, NULL); fclose(private_key_file); if (!rsa) fprintf(stderr, Failed to load private key. ); return 1; // 对 ELF 文件哈希进行签名 unsigned char signature[BUF_SIZE]; unsigned int signature_length; if (!RSA_sign(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, signature_length, rsa)) fprintf(stderr, Failed to sign hash. ); RSA_free(rsa); return 1; // 将签名写入文件 FILE* signature_file = fopen(signature_path, wb); if (!signature_file) fprintf(stderr, Failed to create signature file. ); RSA_free(rsa); return 1; fwrite(signature, 1, signature_length, signature_file); fclose(signature_file); RSA_free(rsa); return 0;int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path) FILE* file = fopen(file_path, rb); if (!file) fprintf(stderr, Failed to open file. ); return 1; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) SHA256_Update(sha256, buffer, bytes_read); unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, sha256); fclose(file); // 加载公钥 FILE* public_key_file = fopen(public_key_path, rb); if (!public_key_file) fprintf(stderr, Failed to open public key file. ); return 1; RSA* rsa = PEM_read_RSA_PUBKEY(public_key_file, NULL, NULL, NULL); fclose(public_key_file); if (!rsa) fprintf(stderr, Failed to load public key. ); return 1; // 读取签名文件 FILE* signature_file = fopen(signature_path, rb); if (!signature_file) fprintf(stderr, Failed to open signature file. ); RSA_free(rsa); return 1; unsigned char signature[BUF_SIZE]; size_t signature_length = fread(signature, 1, BUF_SIZE, signature_file); fclose(signature_file); // 验证签名 if (RSA_verify(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, signature_length, rsa) != 1) fprintf(stderr, Signature verification failed. ); RSA_free(rsa); return 1; RSA_free(rsa); return 0; 附录 B 如何实现对程序的加解密公钥加密，私钥解密 方式一：不同设备内核烧录不同的私钥进行解密 方式二：不同设备内核烧录相同的私钥进行解密 B1 生成 RSA 密钥对首先，需要生成 RSA 密钥对，包括私钥和公钥。下面是一个示例命令来生成 RSA 密钥对： openssl genpkey -algorithm RSA -out private_key.pem -aes256openssl rsa -pubout -in private_key.pem -out public_key.pem 这个命令会生成一个 RSA 私钥文件 private_key.pem，并在生成的同时使用 AES256 算法对私钥进行加密保护。然后从私钥中提取公钥，并保存到 public_key.pem 文件中。 B2 使用 RSA 加密文件要使用 RSA 公钥加密文件，可以执行以下命令： openssl rsautl -encrypt -pubin -inkey public_key.pem -in plaintext.txt -out encrypted.txt 这个命令会使用公钥文件 public_key.pem 对明文文件 plaintext.txt 进行加密，并将加密后的结果输出到 encrypted.txt 文件中。 B3 使用 RSA 解密文件要使用 RSA 私钥解密文件，可以执行以下命令： openssl rsautl -decrypt -inkey private_key.pem -in encrypted.txt -out decrypted.txt 这个命令会使用私钥文件 private_key.pem 对加密文件 encrypted.txt 进行解密，并将解密后的结果输出到 decrypted.txt 文件中。 如何向内核中添加密钥 如何在程序中读取密钥","categories":["1.平台","Linux","加密"]},{"title":"ELF文件分析","path":"/2024/05/07/1-平台-Linux-程序-ELF文件分析/","content":"ELF 全称 “Executable and Linkable Format”，即可执行可链接文件格式，目前常见的 Linux、 Android 可执行文件、共享库（.so）、目标文件（ .o）以及 Core 文件（吐核）均为此格式。 文件布局常见的 ELF 文件大致结构如下： 常见的 ELF 格式如上图所示，左边为链接视图，右边为执行视图。从大局上看，ELF 文件主要分为 3 个部分: ELF Header Section Header Table Program Header Table 其中，ELF Header 是文件头，包含了固定长度的文件信息；Section Header Table 则包含了链接时所需要用到的信息；Program Header Table 中包含了运行时加载程序所需要的信息。 链接视图静态链接器（即编译后参与生成最终 ELF 过程的链接器，如 ld ）会以链接视图解析 ELF。编译时生成的 .o（目标文件）以及链接后的 .so （共享库）均可通过链接视图解析，链接视图可以没有段表（如目标文件不会有段表）。 执行视图动态链接器（即加载器，如 x86 架构 linux 下的 libld-linux.so.2 或者安卓系统下的 systemlinker 均为动态链接器）会以执行视图解析 ELF 并动态链接，执行视图可以没有节表。 文件头 ELF HeaderELF 的结构声明位于系统头文件 elf.h 中，ELF 格式分为 32 位与 64 位两种，除了重定位类型稍有区别，其它大致相同，为了简化描述，后续说明将省略 3264 字样。 ELF Header 的声明如下 : #define EI_NIDENT (16)typedef struct unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version */ Elf_Addr e_entry; /* Entry point virtual address */ Elf_Off e_phoff; /* Program header table file offset */ Elf_Off e_shoff; /* Section header table file offset */ Elf_Word e_flags; /* Processor-specific flags */ Elf_Half e_ehsize; /* ELF header size in bytes */ Elf_Half e_phentsize; /* Program header table entry size */ Elf_Half e_phnum; /* Program header table entry count */ Elf_Half e_shentsize; /* Section header table entry size */ Elf_Half e_shnum; /* Section header table entry count */ Elf_Half e_shstrndx; /* Section header string table index */ Elf_Ehdr; 注释都很清楚了，挑一些比较重要的来说。其中 e_type 表示 ELF 文件的类型，有以下几种: ET_NONE: 未知类型 ET_REL: 可重定向类型(relocatable)，通常是们编译的 *.o 文件 ET_EXEC: 可执行类型(executable)，静态编译的可执行文件 ET_DYN: 共享对象(shared object)，动态编译的可执行文件或者动态库 *.so ET_CORE: coredump 文件 e_entry 是程序的入口虚拟地址，注意不是 main 函数的地址，而是.text 段的首地址 _start。当然这也要求程序本身非 PIE(-no-pie)编译的且 ASLR 关闭的情况下，对于非 ET_EXEC 类型通常并不是实际的虚拟地址值。 其他的字段大多数是指定 Section Header(e_sh)和 Program Header(e_ph)的信息。SectionProgram Header Table 本身可以看做是数组结构，ELF 头中的信息指定对应 Table 数组的位置、长度、元素大小信息。最后一个 e_shstrndx 表示的是 section table 中的第 e_shstrndx 项元素，保存了所有 section table 名称的字符串信息。 e_ident包含了Maigc Number和其它信息，共16字节。0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。 e_typeELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。 e_machine处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 e_verison: 文件版本，目前常见的 ELF 文件版本均为 EV_CURRENT（1）。 e_entry: 入口虚拟地址。 e_phoff: 段表文件偏移。 e_shoff: 节表文件偏移。 e_flags: 处理器特定的标志，一般为 0。 e_ehsize: Elf_Header 的大小（字节） e_phentsize: 段头（Program Header）的大小（字节）。 e_phnum: 段的数量。 e_shentsize: 节头（Section Header）的大小（字节）。 e_shnum: 字的数量。 e_shstrndx: 节字符串表的节索引。 Section Headersection header table 是一个数组结构，这个数组的位置在 e_shoff 处，共有 e_shnum 个元素(即 section)，每个元素的大小为 e_shentsize 字节。每个元素的结构如下: typedef struct Elf32_Word\tsh_name; /* Section name (string tbl index) */ Elf32_Word\tsh_type; /* Section type */ Elf32_Word\tsh_flags; /* Section flags */ Elf32_Addr\tsh_addr; /* Section virtual addr at execution */ Elf32_Off\tsh_offset; /* Section file offset */ Elf32_Word\tsh_size; /* Section size in bytes */ Elf32_Word\tsh_link; /* Link to another section */ Elf32_Word\tsh_info; /* Additional section information */ Elf32_Word\tsh_addralign; /* Section alignment */ Elf32_Word\tsh_entsize; /* Entry size if section holds table */ Elf32_Shdr; 其中 sh_name 是该 section 的名称，用一个 word 表示其在字符表中的偏移，字符串表(.shstrtab)就是上面说到的第 e_shstrndx 个元素。ELF 文件中经常使用这种偏移表示方式，可以方便组织不同区段之间的引用。 sh_type 表示本 section 的类型，SPEC 中定义了几十个类型，列举其中一些如下: SHT_NULL: 表示该 section 无效，通常第 0 个 section 为该类型 SHT_PROGBITS: 表示该 section 包含由程序决定的内容，如.text、.data、.plt、.go SHT_SYMTABSHT_DYNSYM: 表示该 section 中包含符号表，如.symtab、.dynsym SHT_DYNAMIC: 表示该 section 中包含动态链接阶段所需要的信息 SHT_STRTAB: 表示该 section 中包含字符串信息，如.strtab、.shstrtab SHT_RELSHT_RELA: 包含重定向项信息 虽然每个 section header 的大小一样(e_shentsize 字节)，但不同类型的 section 有不同的内容，内容部分由这几个字段表示: sh_offset: 内容起始地址相对于文件开头的偏移 sh_size: 内容的大小 sh_entsize: 有的内容是也是一个数组，这个字段就表示数组的元素大小 与运行时信息相关的字段为: sh_addr: 如果该 section 需要在运行时加载到虚拟内存中，该字段就是对应 section 内容(第一个字节)的虚拟地址 sh_addralign: 内容地址的对齐，如果有的话需要满足 sh_addr % sh_addralign 0 sh_flags: 表示所映射内容的权限，可根据 SHF_WRITEALLOCEXECINSTR 进行组合 另外两个字段 sh_link 和 sh_info 的含义根据 section 类型的不同而不同，如下表所示: 至于不同类型的 section，有的是保存符号表，有的是保存字符串，这也是 ELF 表现出拓展性和复杂性的地方，因此需要在遇到具体问题的时候查看文档去进行具体分析。 Program Headerprogram header table 用来保存程序加载到内存中所需要的信息，使用段(segment)来表示。与 section header table 类似，同样是数组结构。数组的位置在偏移 e_phoff 处，每个元素(segment header)的大小为 e_phentsize，共有 e_phnum 个元素。单个 segment header 的结构如下: typedef struct Elf32_Word\tp_type; /* Segment type */ Elf32_Off\tp_offset; /* Segment file offset */ Elf32_Addr\tp_vaddr; /* Segment virtual address */ Elf32_Addr\tp_paddr; /* Segment physical address */ Elf32_Word\tp_filesz; /* Segment size in file */ Elf32_Word\tp_memsz; /* Segment size in memory */ Elf32_Word\tp_flags; /* Segment flags */ Elf32_Word\tp_align; /* Segment alignment */ Elf32_Phdr; 既然 program header 的作用是提供用于初始化程序进程的段信息，那么下面这些字段就是很直观的: p_offset: 该 segment 的数据在文件中的偏移地址(相对文件头) p_vaddr: segment 数据应该加载到进程的虚拟地址 p_paddr: segment 数据应该加载到进程的物理地址(如果对应系统使用的是物理地址) p_filesz: 该 segment 数据在文件中的大小 p_memsz: 该 segment 数据在进程内存中的大小。注意需要满足 p_memszp_filesz，多出的部分初始化为 0，通常作为.bss 段内容 p_flags: 进程中该 segment 的权限(RWX) p_align: 该 segment 数据的对齐，2 的整数次幂。即要求 p_offset % p_align p_vaddr。 剩下的 p_type 字段，表示该 program segment 的类型，主要有以下几种: PT_NULL: 表示该段未使用 PT_LOAD: Loadable Segment，将文件中的 segment 内容映射到进程内存中对应的地址上。值得一提的是 SPEC 中说在 program header 中的多个 PT_LOAD 地址是按照虚拟地址递增排序的。 PT_DYNAMIC: 动态链接中用到的段，通常是 RW 映射，因为需要由 interpreter(ld.so)修复对应的的入口 PT_INTERP: 包含 interpreter 的路径，见下文 PT_HDR: 表示 program header table 本身。如果有这个 segment 的话，必须要在所有可加载的 segment 之前，并且在文件中不能出现超过一次。 在不同的操作系统中还可能有一些拓展的类型，比如 PT_GNU_STACK、PT_GNU_RELRO 等，不一而足。 参考链接 Linux Foundation Referenced Specifications Executable and Linkable Format (ELF) Tool Interface Standard (TIS) Executable and Linking Format (ELF) Specification Version 1.2 elf(5) - format of Executable and Linking Format (ELF) files How programs get run: ELF binaries 深入了解GOT,PLT和动态链接","categories":["1.平台","Linux","程序"]},{"title":"内存分布","path":"/2024/05/06/1-平台-Linux-程序-内存分布/","content":"内存分布在 32 位操作系统中，地址空间的最大理论限制是 4GB，即 (2^{32}) 的结果。然而，这个地址空间并不能完全分配给用户应用程序，因为操作系统本身也需要占用部分内存。具体而言，在 32 位的操作系统中，可执行文件的内存分布如下： 用户空间 (app + C 库): 3GB 内核空间 (驱动): 1GB 内核空间内核空间占用了高位的 1GB 地址空间，范围是从 0xC0000000 到 0xFFFFFFFF。这部分内存由操作系统用来管理系统资源和与硬件设备的交互。用户态程序无法直接访问这些地址，因为这些内存区域被操作系统保留，以防止不受控制的错误访问可能引发的安全问题或系统崩溃。 例如，内核空间中的内存可能被用来存放进程控制块（PCB）、中断描述符表（IDT）以及设备驱动程序等。例如，当一个打印机被连接到系统时，相应的驱动程序会占用内核空间，以允许操作系统控制打印机打印命令。 用户空间剩下的 3GB 地址空间，从 0x00000000 到 0xBFFFFFFF，被分配给用户态应用程序。用户态应用程序的组成部分，包括代码段、数据段、堆与栈，以及动态链接库（DLL），均位于这一部分地址空间。 在这 3GB 的用户空间中，内存分布通常如下所示： 低地址+-----------------+| .text 段 | 代码段: 包含应用程序的可执行代码。通常从低地址开始分配，便于操作。+-----------------+| .data 段 | 数据段: 存放已初始化的全局变量和静态变量，确保在程序运行时可用。+-----------------+| .bss 段 | 包含未初始化的全局变量和静态变量，执行前自动清零。+-----------------+| 堆 (heap) | 堆: 用户自定义空间，用于动态内存分配（如 malloc、new），在使用后需手动释放。||(向高地址方向增长)| 堆一般从数据段之后的地址开始，向高地址方向增长。+-----------------+| || 空闲区域 | 在此区域中，共享库（DLLs）被映射到进程的地址空间，通常位于堆和栈之间的某个位置。| |+-----------------+| 栈 (stack) | 栈: 存储局部变量和函数调用相关信息，局部变量在函数返回时自动释放。| | 栈一般从高地址开始，向低地址方向增长。| (向低地址方向增长)|+-----------------+高地址 一个典型的 Linux C 程序内存空间通常分为几个关键部分： 代码段（.text）：此部分存放的是 CPU 要执行的指令。由于代码段是可共享的，因此相同的代码在内存中只会有一份拷贝。此外，该段通常是只读的，这样可以防止程序因意外而修改自己的指令。 初始化数据段（.data）：这个段包含程序中需要明确赋初始值的变量。比如，如果有声明为 int val = 100; 的全局变量，那么它的地址将指向这里。 未初始化数据段（.bss）：此区域中的数据在程序执行前被初始化为 0 或 null。例如，全局变量 int sum; 就会被放置在这里。 堆（Heap）：此段用于动态内存分配。通过调用如 malloc 或 new 函数，程序能够在运行时请求内存。 栈（Stack）：这个区域用于存储局部变量和函数调用过程中产生的临时变量。当函数完成执行时，栈空间会自动被释放。 #include stdio.h#include stdlib.h#include string.h/*C语言中数据的内存分配*/int a = 0; // 全局变量，位于.data段char *p1;int main() int b; // 局部变量b，位于栈中 char s[] = abc; // 数组s存放在栈中，字符串常量abc在常量区 char *p2; // 指针p2在栈中 char *p3 = 123456; // 字符串常量123456在常量区，p3指向栈中 static int c = 0; // 静态局部变量c，位于.data段 p1 = (char *)malloc(10); // 从堆中分配10个字节的空间 p2 = (char *)malloc(20); // 从堆中分配20个字节的空间 // 从常量区的Hello World复制字符串到堆中分配的内存 strcpy(p1, Hello World); free(p1); // 确保释放堆内存，避免内存泄漏 free(p2); // 同样释放p2所指向的堆内存 return 0; 在上述示例中，整个程序展示了内存分配的不同区域。局部变量如 b 和数组 s 存储于栈中，而全局变量和动态分配的内存则存放于数据段和堆中。这样的内存管理策略使得程序在运行时能有效利用内存资源，同时保持高效率和稳定性。","categories":["1.平台","Linux","程序"]},{"title":"Linux命令","path":"/2024/05/03/1-平台-Linux-系统参数-Linux命令/","content":"计算机硬件：运算器，控制器，存储器，输入输出设备等共同组成的 系统内核：让各种硬件设备各司其职且又能协同运行 嵌入式开发中常常需要确认开发板的系统版本，CPU，各种外部设备，内寸占用情况等数据。 终端一个基于文本的交互界面 快捷键 打开命令行终端 Ctrl+Alt+t 放大终端 Ctrl Shirft + 缩小终端 Ctrl - 终端提示符含义lemonade@ubuntu:~$ 对应用户名 (lemonade)@主机名 (ubuntu): 工作目录 (~) 提示符 ($) ~：家目录 $: 普通用户#: 超级用户 (root) 命令— 在终端中用于告诉计算机去执行一个动作 参数— 选项— 选项通常用一个连接号（-）或两个连接号（--）来划分 常用 ls: 列出当前目录内容 cd ~: 进入当前用户的家目录 ./ 当前目录 (可省略) ../ 上一层目录 ../../ 上一层的上一层 文件操作指令 mkdir 创建文件夹 mkdir mydir touch 创建空文件 touch myfile rmdir 删除一个空文件夹 rm 删除一个文件或文件夹,默认删除文件 rm -r 删除文件夹 打印定向指令 echo 打印一串字符 echo hello world 输出重定向指定输出的目标文件 向指定文件中追加内容 cat 读文件内容并打印 cat readme rootsudo sudo passwd 通过普通用户修改超级用户 (root) 的密码. su root 切换用户为 root 用户 (超级用户) su lemonade 切换为 lemonade 用户. sudo 用普通用户权限执行 root 的功能 普通用户权限执行 root 的功能需注意用户环境下的环境变量和 root 用户环境的下环境变量是否一致 移动拷贝指令 mv 移动命令 mv source dest``mv source dir cp 拷贝命令 man 用户帮助手册 man ls ls [options]... [file]... options 选项或参数 file 目标文件或文件夹 [] 可选标志 ... 多参机制 改变权值的命令 chmod 777 readme.sh 所有用户可读可写可执行 文件类型: - ：普通文件d : 文件夹目录l : 链接 (快捷方式)s : 网络套接字p: 管道b : 块设备, 磁盘 c : 字符设备, 键盘 关机 halt 关机 reboot 重启 sudo shutdown -h now 加上关机时间 sudo shutdown -h +1 See You la la 加上关机备注 shell 命令参数可以用长格式（完整的选项名称）man --help，也可以用短格式（单个字母的缩写）man -h，分别用 -- 与 - 作为前缀。 系统工作命令echo 命令用于在终端输出字符串或变量提取后的值，格式为”echo [字符串 | $变量]”。 date 命令用于显示及设置系统的时间或日期，格式为”date [选项] [+指定的格式]”。 poweroff wget 命令用于在终端中下载网络文件，格式为”wget [参数] 下载地址”。 ps 命令用于查看系统中的进程状态，格式为”ps [参数]”。 -b 后台下载模式 -P 下载到指定目录 -t 最大尝试次数 -c 断点续传 -p 下载页面内所有资源，包括图片、视频等 -r 递归下载 -a 显示所有进程（包括其他用户的进程） -u 用户以及其他详细信息 -x 显示没有控制终端的进程 |USER|PID |%CPU| %MEM|VSZ |RSS |TTY| STAT| START| TIME |COMMAND||进程的所有者|进程 ID 号|运算器占用率|内存占用率|虚拟内存使用量(单位是 KB)|占用的固定内存量(单位是 KB)|所在终端|进程状态|被启动的时间|实际使用 CPU 的时间|命令名称与参数| top 命令用于动态地监视进程活动与系统负载等信息，其格式为 top。 第 1 行：系统时间、运行时间、登录终端数、系统负载（三个数值分别为 1 分钟、5 分钟、15 分钟内的平均值，数值越小意味着负载越低）。 第 2 行：进程总数、运行中的进程数、睡眠中的进程数、停止的进程数、僵死的进程数。 第 3 行：用户占用资源百分比、系统内核占用资源百分比、改变过优先级的进程资源百分比、空闲的资源百分比等。其中数据均为 CPU 数据并以百分比格式显示，例如”97.1 id”意味着有 97.1%的 CPU 处理器资源处于空闲。 第 4 行：物理内存总量、内存使用量、内存空闲量、作为内核缓存的内存量。 第 5 行：虚拟内存总量、虚拟内存使用量、虚拟内存空闲量、已被提前加载的内存量。 pidof 命令用于查询某个指定服务进程的 PID 值，格式为”pidof [参数] [服务名称]”。 kill 命令用于终止某个指定 PID 的服务进程，格式为”kill [参数] [进程 PID]”。 killall 命令用于终止某个指定名称的服务所对应的全部进程，格式为：”killall [参数] [服务名称]”。 系统状态检测命令ifconfig 命令用于获取网卡配置与网络状态等信息，格式为”ifconfig [网络设备] [参数]”。 uname 命令用于查看系统内核与系统版本等信息，格式为”uname [-a]”。 uptime 用于查看系统的负载信息，格式为 uptime。 free 用于显示当前系统中内存的使用量信息，格式为”free [-h]”。 who 用于查看当前登入主机的用户终端信息，格式为”who [参数]”。 last 命令用于查看所有系统的登录记录，格式为”last [参数]”。 history 命令用于显示历史执行过的命令，格式为”history [-c]”。（用”!数字”的命令格式重复执行某一次的命令记录） sosreport 命令用于收集系统配置及架构信息并输出诊断文档，格式为 sosreport。 工作目录切换命令pwd 命令用于显示用户当前所处的工作目录，格式为”pwd [选项]”。 cd 命令用于切换工作路径，格式为”cd [目录名称]”。 ls 命令用于显示目录中的文件信息，格式为”ls [选项] [文件] “。 文本文件编辑命令cat 命令用于查看纯文本文件（内容较少的），格式为”cat [选项] [文件]”。（-n 显示行号） more 命令用于查看纯文本文件（内容较多的），格式为”more [选项]文件”。 head 命令用于查看纯文本文档的前 N 行，格式为”head [选项] [文件]”。 tail 命令用于查看纯文本文档的后 N 行或持续刷新内容，格式为”tail [选项] [文件]”。 tr 命令用于替换文本文件中的字符，格式为”tr [原始字符] [目标字符]”。（cat a.txt | tr [a-z] [A-Z]） wc 命令用于统计指定文本的行数、字数、字节数，格式为”wc [参数] 文本”。(-l 行数-w 单词数-c 字节数) stat 命令用于查看文件的具体存储信息和时间等信息，格式为”stat 文件名称”。 cut 命令用于按”列”提取文本字符，格式为”cut [参数] 文本”。 diff 命令用于比较多个文本文件的差异，格式为”diff [参数] 文件”。（–brief 确认两个文件是否不同，-c 比较差异之处） 文件目录管理命令touch 命令用于创建空白文件或设置文件的时间，格式为”touch [选项] [文件]”。 -a 仅修改”读取时间”（atime）-m 仅修改”修改时间”（mtime）-d 同时修改 atime 与 mtime mkdir 命令用于创建空白的目录，格式为”mkdir [选项] 目录”。 cp 命令用于复制文件或目录，格式为”cp [选项] 源文件 目标文件”。 mv 命令用于剪切文件或将文件重命名，格式为”mv [选项] 源文件 [目标路径|目标文件名]”。 rm 命令用于删除文件或目录，格式为”rm [选项] 文件”。 dd 命令用于按照指定大小和个数的数据块来复制文件或转换文件，格式为”dd [参数]”。 （dd if=/dev/zero of=560_file count=1 bs=560M）（dd if=/dev/cdrom of=RHEL-server-7.0-x86_64-LinuxProbe.Com.iso） if 输入的文件名称 of 输出的文件名称 bs 设置每个”块”的大小 count 设置要复制”块”的个数 file 命令用于查看文件的类型，格式为”file 文件名”。 打包压缩与搜索命令tar 命令用于对文件进行打包压缩或解压，格式为”tar [选项] [文件]” -c 创建压缩文件 -x 解开压缩文件 -t 查看压缩包内有哪些文件 -z 用 Gzip 压缩或解压 -j 用 bzip2 压缩或解压 -v 显示压缩或解压的过程 -f 目标文件名 -p 保留原始的权限与属性 -P 使用绝对路径来压缩 -C 指定解压到的目录 grep 命令用于在文本中执行关键词搜索，并显示匹配的结果，格式为”grep [选项] [文件]”。 -b 将可执行文件(binary)当作文本文件（text）来搜索 -c 仅显示找到的行数 -i 忽略大小写 -n 显示行号 -v 反向选择——仅列出没有”关键词”的行。 find 命令用于按照指定条件来查找文件，格式为”find [查找路径] 寻找条件 操作”。 -name 匹配名称 -perm 匹配权限（mode 为完全匹配，-mode 为包含即可） -user 匹配所有者 -group 匹配所有组 -mtime -n +n 匹配修改内容的时间（-n 指 n 天以内，+n 指 n 天以前） -atime -n +n 匹配访问文件的时间（-n 指 n 天以内，+n 指 n 天以前） -ctime -n +n 匹配修改文件权限的时间（-n 指 n 天以内，+n 指 n 天以前） -nouser 匹配无所有者的文件 -nogroup 匹配无所有组的文件 -newer f1 !f2 匹配比文件 f1 新但比 f2 旧的文件 -type bdcplf 匹配文件类型（后面的字幕字母依次表示块设备、目录、字符设备、管道、链接文件、文本文件） -size 匹配文件的大小（+50KB 为查找超过 50KB 的文件，而-50KB 为查找小于 50KB 的文件） -prune 忽略某个目录 -exec …… {}; 后面可跟用于进一步处理搜索结果的命令 进程状态： R（运行）：进程正在运行或在运行队列中等待。 S（中断）：进程处于休眠中，当某个条件形成后或者接收到信号时，则脱离该 状态。 D（不可中断）：进程不响应系统异步信号，即便用 kill 命令也不能将其中断。 Z（僵死）：进程已经终止，但进程描述符依然存在, 直到父进程调用 wait4()系统函数后将进程释放。 T（停止）：进程收到停止信号后停止运行。 管理员口令丢失解决办法 开机从 LILO 或 GRUB 中选择进入单用户模式（运行级别 1） 使用 passwd 命令修改 root 口令 重新切换为运行级别 3 或 5 sudo –s # 切换到 root 用户，但是不切换用户环境 操作系统uname -a #查看内核 head -n 1 /etc/issue #查看操作系统版本 cat /proc/cpuinfo #查看CPU信息 hostname #查看计算机名 lspci -tv #列出所有PCI设备 lsusb -tv #列出所有USB设备 lsmod #列出加载的内核模块 env #查看环境变量 资源free -m #查看内存使用量和交换区使用量 df -h #查看各分区使用情况 du -sh 目录名 #查看指定目录的大小 grep MemTotal /proc/meminfo #查看内存总量 grep MemFree /proc/meminfo #查看空闲内存量 uptime #查看系统运行时间、用户数、负载 cat /proc/loadavg #查看系统负载 磁盘和分区mount | column -t #查看挂接的分区状态 fdisk -l #查看所有分区 swapon -s #查看所有交换分区 hdparm -i /dev/hda #查看磁盘参数(仅适用于IDE设备) dmesg | grep IDE #查看启动时IDE设备检测状况 网络ifconfig #查看所有网络接口的属性 iptables -L #查看防火墙设置 route -n #查看路由表 netstat -nltp #查看所有监听端口 netstat -antp #查看所有已经建立的连接 netstat -s #查看网络统计信息 tcpdump 进程ps -aux # 显示瞬间行程 (process) 的动态 ps -ef #查看所有进程 top #实时显示进程状态 nice -n 1 ls # 将 ls 的优先序加 1 并执行 renice +1 987 -u daemon root -p 32 # 将行程 id 为 987 及 32 的行程与行程拥有者为 daemon 及 root 的优先序号码加 1 kill # 送出一个特定的信号 (signal) 给行程 id 为 pid 的行程根据该信号而做特定的动作, 若没有指定, 预设是送出终止 (TERM) 的信号 killall proc bg fg fg n pstree # 将所有行程 (process) 以树状图显示 skill # 送个讯号给正在执行的程序,预设的讯息为 TERM (中断) 用户w #查看活动用户 id 用户名 #查看指定用户信息 last #查看用户登录日志 cut -d: -f1 /etc/passwd #查看系统所有用户 cut -d: -f1 /etc/group #查看系统所有组 crontab -l #查看当前用户的计划任务 crontab 0 6-12/3 * 12 * /usr/bin/backup # 在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backup at 5pm + 3 days /bin/ls # 三天后的下午 5 点执行 /bin/ls: login passwd 服务chkconfig --list #列出所有系统服务 chkconfig --list | grep on #列出所有启动的系统服务 程序rpm -qa #查看所有安装的软件包 文件命令ls -alrtFR filename cut pwd mkdir/rmdir dir rm -rf dir cp -r dest source # 将目录下之档案亦皆依序拷贝至目的地 mv file1 file2 ln -s yy zz # 将档案 yy 产生一个 symbolic link:zz ,不加s为硬链接 touch filename #将档案的时候记录改为现在的时间。若档案不存在,系统会建立新的档案。 cat file more -s testfile # 逐页显示 testfile 之档案内容,如有连续两行以上空白行则以一行空白行显示。 more +20 testfile # 从第 20 行开始显示 testfile 之档案内容。 less filename # 浏览文字档案的内容 head file tail file tail -f file cat # 把档案串连接后传到基本输出（萤幕或加 fileName 到另一个档案） diff -u a.patch oldfile newfile # 可以完成比较功能，生成补丁文件 patch -i a.patch filname # 命令用于打补丁，补丁文件是使用diff产生的 split -b 1m filename filename.dump. # 将filename分割为1M大小，分割后的文件名为filename.dump.aa，filename.dump.ab... tr #指令从标准输入设备读取数据，经过字符串转译后，将结果输出到标准输出设备。 SSHssh user@host ssh -p port user@host ssh-copy-id user@host 压缩tar cf file.tar files tar xf file.tar tar czf file.tar.gz files tar xzf file.tar.gz tar cjf file.tar.bz2 tar xjf file.tar.bz2 gzip file gzip -d file.gz compress -f source.dat # 将 source.dat 压缩成 source.dat.Z，解压-d tar cjf - logs/ | split -b 1m - logs.tar.bz2 # 将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令 cat logs.tar.bz2.a* | tar xj # 分包解压 文件权限chmod a+x filename # 对文件增加权限 chown -R dirname # 对目前目录下的所有档案与子目录进行相同的拥有者变更 搜索grep pattern files grep -r pattern dir command | grep pattern find path -name filename* # 在 path 路径下查找所有以 filename 开头的文件 locate chdrv # 寻找所有叫 chdrv 的档案 expr #字串长度/从位置处抓取字串/出现次数 网络ping host whois domain dig domian dig -x host wget file wget -c file scp test.c root@192.168.7.1:/home/root\t# SCP 拷贝数据 系统信息date # 显示或设定系统的日期与时间 cal # 显示本月的月历 uptime # 显示开机时间等信息 who # 显示系统中有那些使用者正在上面 whoami finger user cat /proc/cpuinfo cat /proc/meminfo man command free file [filename]\t# 可查看可执行文件是 ARM 架构还是 X86 架构 uname -a\t# 显示电脑以及操作系统的相关信息 df\t# 查看磁盘 mount\t# 挂载 umount\t# 卸载 sync\t# 卸载之前同步数据 cat /sys/kernel/debug/usb/devices\t# 查看 USB 类型 time使用方式： time [options] COMMAND [arguments] 使用说明： time 指令的用途,在于等等。需要特别注意的是,部分资讯在 Linux 上显示不出来。这是因为在 Linux 上部分资源的分配函式与 time 指令所预设的方式并不相同,以致于 time 指令无法取得这些资料。 -o or –outputFILE 设定结果输出档。这个选项会将 time 的输出写入 所指定的档案中。如果档案已经存在,系统将覆写其内容。 -a or –append 配合 -o 使用,会将结果写到档案的末端,而不会覆盖掉原来的内容。 -f FORMAT or –formatFORMAT 以 FORMAT 字串设定显示方式。当这个选项没有被设定的时候,会用系统预设的格式。不过可以用环境变数 time 来设定这个格式,如此一来就不必每次登入系统都要设定一次。 一般设定上,可以用 \\t 表示跳栏,或者是用 表示换行。 每一项资料要用 % 做为前导。如果要在字串中使用百分比符号,就用.（学过 C 语言的人大概会觉得很熟悉） time 指令可以显示的资源有四大项,分别是： Time resources Memory resources IO resources Command info 详细的内容如下： Time Resources E 执行指令所花费的时间,格式是：[hour]:minute:second。请注意这个数字并不代表实际的 CPU 时间。 e 执行指令所花费的时间,单位是秒。请注意这个数字并不代表实际的 CPU 时间。 S 指令执行时在核心模式（kernel mode）所花费的时间,单位是秒。 U 指令执行时在使用者模式（user mode）所花费的时间,单位是秒。 P 执行指令时 CPU 的占用比例。其实这个数字就是核心模式加上使用者模式的 CPU 时间除以总时间。 Memory Resources M 执行时所占用的实体记忆体的最大值。单位是 KB t 执行时所占用的实体记忆体的平均值,单位是 KB K 执行程序所占用的记忆体总量（stack+data+text）的平均大小,单位是 KB D 执行程序的自有资料区（unshared data area）的平均大小,单位是 KB p 执行程序的自有堆叠（unshared stack）的平均大小,单位是 KB X 执行程序间共享内容（shared text）的平均值,单位是 KB Z 系统记忆体页的大小,单位是 byte。对同一个系统来说这是个常数 IO Resources F 此程序的主要记忆体页错误发生次数。所谓的主要记忆体页错误是指某一记忆体页已经置换到置换档（swap file)中,而且已经分配给其他程序。此时该页的内容必须从置换档里再读出来。 R 此程序的次要记忆体页错误发生次数。所谓的次要记忆体页错误是指某一记忆体页虽然已经置换到置换档中,但尚未分配给其他程序。此时该页的内容并未被破坏,不必从置换档里读出来 W 此程序被交换到置换档的次数 c 此程序被强迫中断（像是分配到的 CPU 时间耗尽）的次数 w 此程序自愿中断（像是在等待某一个 I/O 执行完毕,像是磁碟读取等等）的次数 I 此程序所输入的档案数 O 此程序所输出的档案数 r 此程序所收到的 Socket Message s 此程序所送出的 Socket Message k 此程序所收到的信号 ( Signal )数量 Command Info C 执行时的参数以及指令名称 x 指令的结束代码 ( Exit Status ) -p or –portability 这个选项会自动把显示格式设定成为： real %e user %U sys %S 这么做的目的是为了与 POSIX 规格相容。 -v or –verbose 这个选项会把所有程式中用到的资源通通列出来,不但如一般英文语句,还有说明。对不想花时间去熟习格式设定或是刚刚开始接触这个指令的人相当有用。 范例： 利用下面的指令 time -v ps -aux 们可以获得执行 ps -aux 的结果和所花费的系统资源。如下面所列的资料： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.4 1096 472 ? S Apr19 0:04 init root 2 0.0 0.0 0 0 ? SW Apr19 0:00 [kflushd] root 3 0.0 0.0 0 0 ? SW Apr19 0:00 [kpiod] ...... root 24269 0.0 1.0 2692 996 pts/3 R 12:16 0:00 ps -aux Command being timed: ps -aux User time (seconds): 0.05 System time (seconds): 0.06 Percent of CPU this job got: 68% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 0 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 238 Minor (reclaiming a frame) page faults: 46 Voluntary context switches: 0 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 mail使用方式： mail [-iInv] [-s subject] [-c cc-addr] [-b bcc-addr] user1 [user 2 ...] 使用说明： mail 不仅只是一个指令, mail 还是一个电子邮件程式,不过利用 mail 来读信的人应该很少吧！对于系统管理者来说 mail 就很有用,因为管理者可以用 mail 写成 script ,定期寄一些备忘录提醒系统的使用者。 i 忽略 tty 的中断讯号。 (interrupt) I 强迫设成互动模式。 (Interactive) v 列印出讯息,例如送信的地点,状态等等。 (verbose) n 不读入 mail.rc 设定档。 s 邮件标题。 c cc 邮件地址。 b bcc 邮件地址。 范例： 将信件送给一个或以上的电子邮件地址,由于没有加入其他的选项,使用者必须输入标题与信件的内容等。而 user2 没有主机位置,就会送给邮件伺服器的 user2 使用者。 mail user1@email.address mail user1@email.address user2 将 mail.txt 的内容寄给 user2 同时 cc 给 user1 。如果将这一行指令设成 cronjob 就可以定时将备忘录寄给系统使用者。 mail -s 标题 -c user1 user2 mail.txt 1\t显示目录信息 #\tls\tls -a\t列出当前目录下的所有文件，包括以.头的隐含文件 #\tls\tls -l或ll\t列出当前目录下文件的详细信息 #\tls\tls -a\t显示所有文件，包含隐藏。 #\tls\tls -al\t显示所有文件的详细信息。\t2\t查看路径 #\tpwd\tpwd\t查看当前所在目录的绝对路经\t3\t目录切换 #\tcd\tcd ..\t回当前目录的上一级目录 #\tcd\tcd -\t回上一次所在的目录 #\tcd\tcd -p aa/bb/cc\t直接创建多级子目录 #\tcd\tcd ~ 或 cd\t回当前用户的宿主目录 #\tcd\tcd ~用户名\t回指定用户的宿主目录\t4\t创建目录 #\tmkdir\tmkdir 目录名\t创建一个目录 #\tmkdir\tmkdir –p\t递归式去创建一些嵌套目录 #\trmdir\tRmdir 空目录名\t删除一个空目录\t5\t创建文件 #\ttouch\ttouch 1.txt\t创建文件1.txt\t6\t删除操作 #\trm\trm 文件名 文件名\t删除一个文件或多个文件 #\trm\trm -rf 非空目录名\t递归删除一个非空目录下的一切，加-f不提示\t7\t查看文件 #\tcat\tcat 文件名\t一屏查看文件内容 #\tcat\tcat 路径/文件名 |grep 字符串\t在文件中匹配字符串 #\tmore\tmore 文件名\t分页查看文件内容 #\tless\tless 文件名\t可控分页查看文件内容 #\tgrep\tgrep字符 文件名\t根据字符匹配来查看文件部分内容 #\tfind\tfind 路径 -name 字符串\t查找路径所在范围内满足字符串匹配的文件和目录 #\tfile\tfile 文件名\t查看文件类型 #\thead\thead -数字 文件名\t可以查看前n行，不加参数，默认为10. #\ttaill taill -数字 文件名\t可以查看后n行，不加参数，默认为10.\t8\t查看帮助 #\thelp cp\t查看内部命令cp #\tls --help |less 查看外部命令，分屏显示 #\tman cd\t查看cd帮助\t不分内部与外部命令 #\tinfo ls 查看 ls 信息 9\t复制文件 #\tcp\tcp /路经/文件 ./\t移动绝对路经下的文件到当前目录下 #\tcp /dev/cdrom linux4.iso 在字符界面上制作ISO镜像文件\t10\t移动文件 #\tmv\tmv 路经/文件 /经/文件\t移动相对路经下的文件到绝对路经下 #\tmv\tmv 文件名 新名称\t在当前目录下改名 #\tmv\tmv a.txt b.txt\t更改文件名 #\tmv\tmv 文件名 路径\t移动文件 #\tmv\tmv 路径/文件名 路径/文件名\t移动并更改文件名\t11\t系统管理 #\tdate\tdate 月日时分年\t更改计算机系统时间\t12\t文本编辑 #\tgedit\tgedit 文件名\t在图形界面下启动编辑器\t13\tvi模式间的切换 #\tvi\tvi tab切换命令与编辑模式\t打开vi编辑器 :q退出编辑环境 #\tvi\ta 从命令进入输入模式\t按ESC从输入模式进入命令模式。\t14\t文本编辑\t在命令模式下 读取文件 :e 新文件名\t一个文件完成后，打开新的文件。 :e! 新文件名\t强制关闭当前文件（不保存）并打开新文件 :f 文件名\t读取指定文件，并粘贴到光标所在行下 :w 保存已经命名的文件 :w 文件名\t保存未命名的文件 :w 文件名\t另存为文件名 :q 退出:q编辑器 :wq\t保存并退出 :q!\t不保存退出 h 光标左移 l\t光标右移 k\t光标上移 j\t光标下移\t15\t文本编辑\t在命令模式下 快速切换 快捷键ctrl+F\t前翻整页 快捷键ctrl+B\t后翻整页 快捷键ctrl+U\t前翻半页 快捷键ctrl+D\t后翻半页 :set nu\t在编辑器中显示行号 :200\t直接进入到第200行 :$\t进入最后一行\t16\t文本编辑\t在命令模式下 进入输入模式 i\t在当前光标处进入插入状态 a 在当前光标后进入插入状态 A\t将光标移动到当前行的行末，并进入插入状态 o\t在当前行的下面插入新行，并进入插入状态 O\t在当前行的上面插入新行，并进入插入状态\t17\t文本编辑\t在命令模式下 删除操作 cw\t删除当前光标所在单词尾部的字符，并进入插入状态 c$\t删除当前光标到行尾的字符，并进入插入状态 c^\t删除光标之前到行首的字符，并进入插入状态 3x\t删除当前光标处向右的3个字符 3dd\t删除当前行开始向下删除3行 3dw\t删除当前光标向右的3个单词 3de\t删除当前光标向右的3个单词，保留右面的空格 d$\t删除当前字符到行尾的所有字符 d^\t删除当前字符到行首的所有字符 J\t删除光标所在行尾的换行符 撤销操作 u\t取消最近的一次操作，并恢复操作结果 U\t取消当前行进行的所有操作 快捷键 Ctrl+R\t撤销命令u的取消操作\t18\t文本编辑\t命令模式 复制操作 4yy\t复制当前行及后续共4行的文本内容到vi缓冲区 7yw\t复制当前光标开始的7个单词到vi缓冲区 y$\t复制当前光标到行尾的内容到vi缓冲区 y^\t复制当前光标到行首的内容到vi缓冲区 :28,48y\t复制第28行到48行的内容到vi缓冲区 粘贴操作 p\t粘贴缓冲区内容到当前光标处，不覆盖文件已有内容\t19\t文本编辑 查找操作 /字符串\t从当前光标处开始向下查找指定字符串 n下 N上 ?字符串\t从当前光标处开始向上查找指定字符串 n下 N上\t20\t文本编辑\t命令模式 替换操作 :s/old/new\t在当前查找old替换成new.只替换当前行中第一个 :s/old/new/g\t替换行中所有old字符串为new :3,9s/old/new/g\t替换3-9行内所有old字符串为new :%s/old/new/g\t替换全文中所有old字符串为new 末尾加上参数c可强制每个替换都需要进行确认。 /new/c /gc (y、n、a、q)\t21\t文本编辑 #同时启动多个文件\tvi a.txt b.txt c.txt\t同时启动a.txt b.txt c.txt vi -o a.txt b.txt c.txt\t水平显示各个文件 vi -O a.txt b.txt c.txt\t垂直显示各个文件\t22\t文本编辑\t命令模式 文件之间切换操作 :args\t查看vi编辑器中多文件的状态（显示文件信息） :next\t多文件中向后切换 :prev\t多文件中前后切换 :first\t切换到多文件的首文件 :last\t切换到多文件的尾文件 快捷键ctrl+^\t切换到切换之前的文件\t23\t挂载光盘 #\tmount /dev/cdrom /media/cdrom 挂载光盘到/media/cdrom #\tumount /media/cdrom 卸载光盘，同umount -t iso9660 /media/cdrom\t24\t挂载U盘 #\tmount -t vfat /dev/sdb1 /media/cdrom 挂载U盘 #\tumount /media/cdrom 卸载U盘\t25\t创建用户及管理 #\tuseradd\tUseradd 用户名\t创建一个新的用户\t26 #\tchfn chfn 用户名\t输入用户信息\t27\t创建用户及管理 #\tuseradd\tuseradd -u 666 用户名\t创建一个ID号为666的新用户 #\tuseradd\tuseradd -e 12/22/2009 用户名\t创建一个2009/11/22日过期的用户 #\tuseradd\tuseradd -p 密码 用户名\t创建用户，并一同创建密码 #\tuseradd\tuseradd -g 组名 用户名\t创建用户并加入组（原组不存在，改加入新组） #\tuseradd\tuseradd -G 组名 用户名\t创建用户并加入组（原组存在，并加入新组）\t28\t用户相关修改 #\tusermod\tusermod -l 新名 旧名\t给用户改名 #\tusermod\tusermod -e 11/23/2009\t更改用户过期时间为2009/11/23 #\tusermod\tusermod -L 用户名\t禁用用户 #\tusermod\tusermod -U 用户名\t解锁用户 #\tuserdel\tuserdel 用户名\t删除用户，但不删除用户自家目录。 #\tuserdel\tuserdel -r 用户名\t删除用户，并删除用户自家目录。 #\tgroupadd\tGroupadd 组名\t创建一个新的组 #\tpasswd\tpasswd\t为root用户创建密码（修改） #\tpasswd\tPasswd 用户名\t为用户创建密码 #\tpasswd\tPasswd -d 用户名\t删除用户密码也能登陆 #\tpasswd\tPasswd -l 用户名\t锁定账号密码 #\tpasswd\tPasswd -u 用户名\t解锁账号密码 #\tpasswd\tPasswd -S 用户名\t查询账号密码\t29\t组相关修改 #\tGroups\tgroups 用户名\t查看用户所属组 #\tGroupadd\tgroupadd 用户名\t创建新用户 #\tGroupdel\tgroupdel组名 先应删它的用户\t删除组 #\tGroupmod groupmod –n新用户名 老用户名\t为组改名 #\tGroupmod groupmod –g 501 组名\t改变组GID #\tgpsswd\tgpasswd -d 用户名 组名\t把用户从组中删除 #\tgpsswd\tgpasswd -a 用户名 组名\t增加用户到组\t30\t用户管理 #\tId id 用户名\t查用户信息\t31\t用户管理 #\tll\tll 文件名\t查看文件权限\t32\t文件权限及所属的修改 #\tchmod\tchmod u+r\t增加用户读权限 #\tchmod\tchmod a+w\t增加所有人写权限 #\tchmod\tchmod g+x\t增加组执行权限 #\tchmod\tchmod 755 文件名\t更改文件权限为rwx-xr-x (r=4 w=2 x=1)值相加 #\tchown\tchown 用户名 文件名\t更改文件所属用户 #\tchown\tchown :组名 文件名\t更改文件所属组 #\tchown\tchown 用户名:组名 文件名\t同时更改用户名和组名 #\tchown\tchown -R 用户名:组名 目录名\t更改目录及其中所有文件所属组及用户\t33\t用户之间切换 用户切换 快捷键Alt+F2\t切换到用户F2 （F1 - F6） #\tsu\tsu - 用户名\t用于终端上用户的切换\t34 #\tcat\tcat /etc/shells\t显示系统支持的shell\t35\tshell #\techo\techo $SHELL\t查看当前系统所使用的shell #\techo\techo $变量\t应用变量 36\t定义命令别名 #\talias\talias\t查看定义好的命令别名 #\talias\talias la=ls -a\t临时定义命令别名\t37\t变量的设置 #\tchsh\tchsh 用户名 再输入/bin/csh\t更改默认sehll,且永久不变。 #\tset\tset |less\t查看系统变量 #\tPS1\tPS1=hello;\t更改[root@loadhost ~]为hello; #\t变量名=值\tMOVIE=life is beautiful\t自设变量 #\tunset\tunset 变量名\t删除变量 #\t/bin/bash\t进入子shell\texit 退出子shell #\texport export 变量名\t删除变量 #\treadonly\treadonly\t查看系统中只读变量 #\treadonly\treadonly 变量名\t设置变量为只读变量\t38 #\tsh\tsh 文件名\t执行无执行权限的脚本\t39\t历史命令 #\thistory\thistory |less\t显示命令历史记录 #\t！ ！39\t直接使用第39次命令 #\t！ ！c\t引用最后一次以c开头的命令。\t40\t重定向 # ls 文件名\t把ls得结果重定向到指定文件 # cat a.txt b.txt\t将a.txt中的文件复制到b.txt(覆盖） # cat c.txt b.txt\t将c.txt中的文件追加到b.txt中 # echo 字符串 a.txt\t将字符串追加到a.txt文件中 #\t2\t命令 2 文件名\t将错误重定向文件中\t41\tRPM包管理 #\trpm\trpm -qa\t显示系统所装所有的rmp软件包 #\trpm\trpm -ivh\t按照显示详细信息 #\trpm\trpm -ql rmp包名\t查询系统中指定软件包所包括的文件列表 #\trpm\trpm -qpl rmp包名\t查询未装包位置 #\trpm\trpm -qi rmp包名\t显示软件包的详细信息 #\trpm\trpm -qpi rmp包名\t信息列表 #\trpm\trpm -Uvh rmp包名\t升级包，可安装 #\trpm\trpm -e rmp包名\t卸载 #\trpm\trpm -e --nodeps rmp包名\t强制卸载 #\trpm\trpm -qf /bin/ls\t查询/bin/ls文件所在包\t42\t设置ip #\tnetconfig\tnetconfig 设置IP地址 #\tservice network restart 重启网络服务\t43\ttar包管理 #\tgzip\tgzip 文件名\t压缩文件，原文件消失 #\ttar\ttar cvf 包名 原文件名、原包名\t把文件和目录压缩成tar包 #\ttar\ttar tf 包名\t查看tar包中的文件 #\ttar\ttar xvf 包名\t释放tar包里的文件 参数-v为显示详细参数 #\ttar\ttar xvf 包名 -C 路径\t释放到指定目录 #\ttar\ttar jxvf 包名\t释放bz2格式压缩包 #\ttar\ttar zcvf 包名 文件名、原包名\t创建压缩tar包 #\ttar\ttar ztf 包名\t查看压缩tar包 #\ttar\ttar zxvf 包名 -C 路径\t释放tar包到指定路径\t44\t编译安装 #\t安装\t./configure 安装在程序目录下 # ./configure --prefix=/路径\t安装在指定目录 # make\t编译源代码 # make install\t将已编译的应用程序安装到目标路径 #\t卸载\t./unin stall\t卸载\t45\t字符下载 #\twget\twget 下载地址\t字符界面下的下载\t46\t安装程序的启动 #\tproz proz 下载路径\t安装在默认路径下的proz的启动 下载 #\t路径/proz\t路径/proz 下载路径\t安装在指定路径下的proz的启动 下载\t47\tgcc升级 #\tyum gcc\tyum gcc\t自动升级gcc\t48\t打补丁 #\tcat\tcat 路径 |patch -p1\t给程序打补丁\t49\t关机\t#\tshutdown\tshutdown -h\t关机 快捷键ctrl+alt+del 关机 #\tinit\tinit 0\t关机\t50\tinit的七种模式 #\tinit\tinit 1\t单用户模式 #\tinit\tinit 2\t无NFS,字符多用户 #\tinit\tinit 3\t多用户 #\tinit\tinit 4\t预留 #\tinit\tinit 5\t图形用户\t51\t重启 #\tinit\tinit 6\t重启 #\tshutdown\tshutdown -r\t重启 #\treboot\treboot\t重启\t52\t级别查询修改 #\trunlevel runlevel\t查询当前级别 #\tvi /etc/inittab 修改默认启动级别\t53\t启动级别 第十八行，id：4 把默认启动级别改为3 第32行，在ca::前加上# 32 #ca:: 把快捷键ctrl+alt+del关机 禁用 #\tchkconfig\tchkconfig --list\t查看安装包在各级的启动状态 #\tchkconfig\tchkconfig --level 24 httpd on\t启动httpd在 24级别。 #\tchkconfig --list rsyns 启动非独立的包，不写启动级别\t54\t系统进程 #\tpstree\tpatree |less\t显示进程树 #\tps\tps aux\t显示进程 #\tkill\tkill 进程号\t关闭进程 #\tkill kill -q 进程号\t强制结束 #\ttop\ttop\t动态查看进程 快捷键ctrl+z\t命令后加 放入后台运行 #\tjobs jobs\t查看后台运行项 #\tfg\tfg 2\t把后台运行的程序调入前台\t55\t任务计划的编辑 #\tat\tat 18:33\t为18：33分制作任务计划 #\tat at mkdir 目录名\t直接输入命令 快捷键ctrl+d 结束当前进程 #\tatq\tatq\t计划任务队列 #\tatrm\tat -d\t都为取消计划任务 #\tat -t 12011230 为12月1月12：30任务计划 #\trpm rpm -qa |grep vixie -cron\t查看计划任务工具包是否安装 #\tcrontab 打开编辑任务计划编辑器，格式：分钟 小时 天 月 星期 后加命令 #\tcrontab crontab -e\t修改任务计划 #\tmail\tmail\t接受系统邮件 #\tservice crond start 启动crond #\tcrontab\tcrontab -r\t删除全部计划任务\t56\t磁盘分区 #\tfdisk\tfdisk /dev/sdb\t打开磁盘分区工具 n 新建分区 w保存推出 d删除分区 q不保存推出 57\t磁盘格式化 mkfs.ext3\tmkfs.ext3 /dev/sdb1\t格式化成ext3格式 mkswap\tmkswap /dev/sdb2\t格式化成swap格式 mkfs.vfat mkfs.vfat /dev/sdb3\t格式化成fat格式 parted\tparted /dev/sdb\t查看分区sdb的类型\t58\t磁盘挂载 #\tvi vi /etc/fstab 挂载磁盘\t59\t磁盘配额 #\tquotacheck\tquotacheck -cug /media/sdb1\t启动磁盘配额 #\tquotaon\tquotaon /media/sdb #\teduota\teduota -u 用户名\t给用户做磁盘配额 #\tquota\tquota -u 用户名\t查看用户磁盘使用情况 #\tedquota\teduota -t 更改软限制时间 #\tedquota\teduota -g 组名\t更改组用户磁盘配额 #\tedquota\teduota -p 已陪用户名 用户名n\t为多个用户创建磁盘配额\t60\tIP信息编辑 #\troute\trout 查看默认网关 #\tcat /etc/sysconfig/network-scripta/ 查看ip信息文件 用vi可修改 #\tifconfig eth0 192.168.1.1 netmask 255.255.255.0 设置临时IP\t#\tnetconfig\tnetconfig 设置IP地址 需重启网卡服务 #\trouteadd\trouteadd default gw 网关\t设置临时网关 #\troutedel\troutedel default gw 网关\t删除临时网关 #\ttraceroute traceroute IP地址\t路由追踪 #\tifdown ifdown 网络接口名称\t禁用网卡 #\tifup\tifup 网络接口名称\t启用网卡\t61\t主机名更改 #\thostname\thostname 计算机名\t更改计算机名，重启无效 #\tvi /etc/sysconfig/network 更改计算机名 主机名设置后重启才能生效，一般和hostname一起使用。 62\t域名解析 #\tnslookup 网址或域名\t域名解析\t63\t安装NFS服务器 #\tvi\tvi /etc/hosts\t//添加IP地址与主机名(本地主机名称解析文件） #\tvi\tvi /etc/resolv.conf\tresolv.conf中的search用于设置主机的默认查找域名 #\trmp rmp -q nfs-utils portmap\t查询NFS服务器是否安装 #\trmp -ivh nfs-utils-1.0.6-46.i386.rmp portmp-4.0-63.i386.rmp 安装NFS 64\tshowmount的查询功能 #\tshowmount showmount NFS服务器主机地址\t显示当前主机中NFS服务器连接信息 #\tshowmount showmount -e IP地址\t显示指定主机中NFS服务器连接信息,并列表 #\tshowmount showmount -d NFS服务器地址\t显示指定主机中NFS服务器已被挂载的目录 #\tshowmount showmount -a NFS服务器地址\t显示挂载的共享列表和NFS客户机地址\t65\tNFS的共享输入与输出 #\texportfs export -rv\t使修改后的export -rv文件生效 #\texportfs export -auv\t临时停止NFS服务器的所有共享目录输出 #\texportfs export -av\t输出（启用）所有被-auv命令停止的NFS共享目录 #\tsystem-config-nfs 在图像界面下启动NFS服务器配置工具命令\t66\t配置NFS 服务器 必须安装的 软件包\trpm -qa |grep nfs-utils\t均在第二张光盘中 rpm -qa |grep portmap 配置exports 文件\tvi /etc/exports\t下面两行为格式 /opt/text *(sync,ro) 192.168.1.12(sync,rw) 共享源文件路径 所有主机（同步写磁盘，只读） 客户IP地址（同步写磁盘，读写） ping通NFS服务器与客户机 以上均在NFS服务器上完成 下面在客户机上完成 67\t配置NFS 客户端 showmount -e /192.168.1.1 查看NFS服务器共享目录 挂载共享目录\tmount 192.168.1.1:/opt/test /mnt 配置自动挂载\tvi /etc/fstab 以下两行为格式 192.168.1.1:/opt/text /mnt nfs defaults 0 0 服务器ip地址：共享源文件路径 挂载点路径 磁盘格式 默认挂载 存档 windows系统的 NFS 挂载\twindows中需安装liteall.exe软件 cat /etc/passwd |grep nfsnobody 查询UID GID 使用UID GID 挂载\t重启可解决兼容性问题\t68\t补充 #\twall\twall hello everyone\t在所有登陆用户桌面显示 #\twall\twall a.txt\t将a.txt中的内容显示到所有登陆用户的桌面 #\twc\twc\t统计从键盘输入的 行数 单词数 字符数 #\twc\twc /etc/passwd\t统计用户数（行） #\tls\tls a.txt b.txt\t将命令执行的输出和错误输出到指定的文件中","categories":["1.平台","Linux","系统参数"]},{"title":"时间编程","path":"/2024/05/02/1-平台-Linux-系统参数-时间编程/","content":"时间类型Coordinated Unicersal Time（UTC）：世界标准时间，也就是大家所熟知的格林威治标准时间（Greenwich Mean Time 吗 GMT） Calendar Time：日历时间，是用”从一个标准时间点（如：1970 年 1 月 1 日 0 点）到此时经过的秒数”来表示时间 时间获取获取日历时间，即从 1970 年 1 月 1 日 0 点到现在所经历的秒数 #include time.htime_t time(time_t*tloc); 将日历时间转化为格林威治标准时间，并保存至 TM 结构 struct tm *gmtime(const time_t*timep); 将日历时间转化为本地时间，并保存至 TM 结构 struct tm *localtime(const time_t*timep); struct tm int tm_sec; /* Seconds(0-60) */int tm_min; /* Minutes(0-59) */int tm_hour; /* Hours(0-23) */int tm_mday; /* Day of the month (1-31) */int tm_mon; /* Month (0-11) */int tm_year; /* Year - 1900 */int tm_wday; /* Day of the week (0-6, Sunday = 0) */int tm_yday; /* Dayin the year (0-365, 1 Jan = 0) */int tm_isdst; /* Daylightsaving time */; 将 tm 格式的时间转化为字符串，如：Sat Jul 30 08：43：03：2005 char*asctime(conststruct tm *tm); 将日历时间转化为本地时间的字符串形式 char*ctime(const time_t*timep); 获取从今日凌晨到现在的时间差，常用于计算事件耗时 #include sys/time.hint gettimeofday(struct timeval *tv,struct timezone *tz); struct timeval time_t tv_sec; /*seconds*/ 秒数suseconds_t tv_usec; /* microseconds*/ 微秒; 延时执行使程序睡眠 seconds #include unistd.hunsigned intsleep(unsigned intseconds); 使程序睡眠 usec 微秒 #include unistd.hint usleep(useconds_t usec);","categories":["1.平台","Linux","系统参数"]},{"title":"自启动","path":"/2024/05/01/1-平台-Linux-系统参数-自启动/","content":"设置脚本 - rc.local在 Ubuntu 系统中，rc.local 脚本承担着开机后自动执行特定命令的功能。该脚本的默认执行用户为 root，意味着其中的命令将以超级用户权限运行。这种设计对系统管理非常重要，因为某些操作，比如启动系统服务或进行系统级配置，需要足够的权限。 rc.local 脚本位于 /etc/ 目录下，这是一个系统目录，专门用于存放配置文件及需保证系统操作顺畅的其他文件。要修改此脚本，需具备 root 权限。执行以下命令以使用文本编辑器 vi 打开脚本： vi /etc/rc.local rc.local 脚本的基本结构如下，不同段落用注释进行解释，以便理解每个部分的功能： #!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will exit 0 on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.exit 0 **#!/bin/sh -e**：指定使用的解释器，当脚本中的某条命令返回非零状态时，脚本将立即退出。 注释部分：提供了脚本的操作指导，特别强调了成功执行时必须返回 0 的要求。 **exit 0**：标志脚本的结束，任何添加的命令必须位于此行之前。 为了确保要执行的指令有效地启动，可以在 exit 0 之前添加所需的命令。例如，可以选择启动 Nginx 服务。这可通过简单地将以下命令插入到 rc.local 中来实现： /usr/bin/nginx start 在编辑文件并添加完命令后，需要确保脚本具有可执行权限。可以通过以下命令进行权限修改： chmod +x /etc/rc.d/rc.local 需要注意的是，/etc/rc.d/rc.local 实际上是 /etc/rc.local 的软链接，因此对软链接的修改直接影响原始脚本。 在 Linux 系统中，控制随机启动的服务程序的主要目录是 /etc/init.d。此目录下包含了一系列脚本文件，这些脚本负责在系统启动时按顺序执行特定的程序。这种脚本文件的作用类似于 Windows 系统中的 autorun.dat 文件，它们能够指示系统在启动时需要执行哪些进程。 为了更好地理解这一过程，值得注意的是 /etc 目录下还包含了一组以 rc 开头的文件夹，如 rc1.d, rc2.d 直到 rc6.d。这些目录对应于 Linux 系统不同的运行级别（runlevels）。通常，用户会进入的 X Windows 多用户运行级别是第 5 级，这意味着涉及的服务程序存放在 rc5.d 文件夹中。在这个文件夹中，存在的脚本文件则指示在第 5 级运行时应启动的服务。 需要明确的是，这些 rc(1-6).d 目录中的文件其实是指向 /etc/init.d 目录下服务程序的软链接，类似于 Windows 系统中的快捷方式。这一设计的好处在于，所有服务程序都集中管理，便于维护和修改，而每个级别所需的服务则通过软链接分别指向主服务程序，这样能够有效地管理不同运行级别下的服务启动。 以启动 scim 程序为例，首先需要定位该程序在系统中的具体路径，使用 locate 命令可以轻松找到它。scim 的路径是 /usr/bin/scim，这里的 usr 代表用户程序的存放位置，而 bin 则表明该位置包含可以执行的程序。了解这一点后，可以编写一个脚本，将其放入 /etc/init.d 目录，并在 rc5.d 目录中创建一个相应的软链接。 以下是一个简单的脚本示例： #!/bin/bash/usr/bin/scim 第一行 #!/bin/bash 是一种声明，指明该脚本将使用 Bash 终端执行。 第二行 /usr/bin/scim 则是要执行的具体命令。 在创建链接时，需要特别注意在 rc5.d 目录下，每个链接的命名约定：以 S 开头的链接表示在系统启动时需要随机启动，而以 K 开头的链接则表示不随机启动。因此，如果想让某个服务在启动时随机启动，可以将链接名称中的 K 改为 S；反之，将 S 改为 K 则意味着该服务不再随机启动。这意味着，链接可以命名为 SXXX（其中 XXX 为自定义的标识符），这样系统就会在启动时随机加载它。 此外，在某些 Linux 发行版中，如 Red Hat（RH），rc.local 文件是所有脚本中最后执行的，所以还有另一种方法可以实现服务的随机启动，即在 rc.local 文件的末尾加入 /usr/bin/scim，这同样能达到开机启动的目的。此种方式灵活，适合于没有办法通过传统方式启动的服务。 关于放在 rc.local 中时不启动的问题1. 增加日志输出功能为了找出脚本在 rc.local 中不启动的具体原因，可以在脚本中增加日志输出功能。日志对排查问题至关重要，确保可以清晰地看到执行过程中的所有信息。下面是一个典型的 Memcached 启动脚本示例，包含日志记录功能： #!/bin/sh -e## rc.local## 此脚本在每个多用户运行级别的末尾执行。## 确保脚本在成功时返回 exit 0，在出错时返回其他值。## 要启用或禁用此脚本，只需更改执行权限。## 默认情况下，此脚本不执行任何操作。# 发送错误输出到日志文件logexec 2/tmp/rc.local.log # 将标准输出发送到同一个日志文件exec 1/tmp/rc.local.log 21 # 告诉 sh 在执行之前显示命令set -x # 启动 Memcached/usr/local/memcache/bin/memcached -p 11211 -m 64m -d -u root# 退出脚本exit 0 这样修改后，不仅能记录下错误信息，还能查看到所有执行的命令，方便排查。输出的信息可以在 /tmp/rc.local.log 文件中找到。 2. 修改 rc.local 文件头部在某些系统上，rc.local 文件的默认解释器可能不支持某些 Bash 特性。如果遇到兼容性问题，可以将文件头部的 /bin/sh 修改为 /bin/bash： #!/bin/bash 使用 Bash 解释器可以确保脚本中使用的所有功能都能够正常运作。 3. 提供执行权限如果需要执行的是一个独立的 Shell 脚本，比如 xxx.sh，则必须确保它具备执行权限。可以使用以下命令授予执行权限： sudo chmod +x xxx.sh 在启动时，建议使用以下命令格式确保脚本以正确的方式运行： sudo sh xxx.sh 这样做将确保无论是权限问题还是环境变量设置，都能顺利执行脚本。 使用 update-rc.d 增加开机启动服务给 Ubuntu 系统添加一个开机启动脚本的具体操作如下： 新建脚本文件 new_service.sh创建一个新的 shell 脚本文件，并写入需要执行的命令。脚本的基本结构如下： #!/bin/bash# command contentexit 0 在这里，# command content 应替换为在系统启动时需要执行的具体命令。例如，如果希望在开机时启动一个自定义的应用程序，则可以将其路径添加到该位置。exit 0 表示脚本成功完成，没有错误发生。 设置权限为了确保新建的脚本可以被系统执行，需要设置合适的权限。执行以下命令： sudo chmod 755 new_service.sh 或者，可以使用更简洁的命令： sudo chmod +x new_service.sh 这确保所有用户都能够执行该脚本，同时也支持读和写的权限。 把脚本放置到启动目录下将脚本移动到系统的初始化目录 /etc/init.d/。该目录专门存放在系统启动时需要运行的服务脚本。执行命令如下： sudo mv new_service.sh /etc/init.d/ 将脚本添加到启动脚本使用 update-rc.d 命令来注册脚本为开机启动。执行时，90 是优先级参数，值越高意味着该脚本的启动时间越晚。执行以下命令： cd /etc/init.d/sudo update-rc.d new_service.sh defaults 90 移除 Ubuntu 开机脚本若需要删除已经添加的开机启动脚本，可以使用以下命令： sudo update-rc.d -f new_service.sh remove 该命令会强制移除脚本，并清理所有链接到 /etc/init.d/ 的启动项，确保不会在开机时再次执行。 通过 sysv-rc-conf 管理启动服务的启动级别sysv-rc-conf 工具提供了直观的界面，可以更方便地管理开机启动项。可以通过以下命令打开配置界面： sudo sysv-rc-conf 在该界面中，可以直观地开启或关闭特定服务在不同运行级别下的启动状态。 update-rc.d 的详细参数使用 update-rc.d 命令时，可以根据需求指定脚本名称和参数。具体的命令格式如下（需在 root 权限下执行）： update-rc.d [-n] [-f] removeupdate-rc.d [-n] defaultsupdate-rc.d [-n] disable|enable [S|2|3|4|5]update-rc.d start|stop 参数说明： -n: 只做测试，不实际执行操作。 -f: 强制执行操作。 实例说明： (1) 添加新的启动脚本假设需要添加一个名为 sample_init_script 的新启动脚本，并指定它的默认启动顺序和运行级别。可以执行以下命令： update-rc.d sample_init_script defaults 这条命令实际上等同于下面的命令： update-rc.d sample_init_script start 20 2 3 4 5 . stop 20 0 1 6 其中的 20 表示在启动时的优先级，S、2、3、4、5 表示不同的运行级别。 (2) 指定启动顺序为 50 的脚本如果要安装 sample_init_script 并将其启动顺序设为 50，可以执行： update-rc.d sample_init_script defaults 50 (3) 管理多个脚本的启动顺序假设有两个脚本 A 和 B，A 应在 B 启动之前，且在 B 停止之后。可以使用以下命令设置它们的启动顺序： update-rc.d A 10 40update-rc.d B 20 30 (4) 删除启动脚本若要删除 sample_init_script 脚本（如果该脚本不存在则跳过），可以使用以下命令： update-rc.d -f sample_init_script remove 该命令会清理所有指向 /etc/init.d/sample_init_script 的链接，包括在 /etc/rcX.d 目录下的相关链接。 (5) 禁止 Apache 和 MySQL 组件开机自启如果需要取消 Apache 和 MySQL 组件的开机自启，可以使用以下命令： update-rc.d -f apache2 removeupdate-rc.d -f mysql remove 执行这些命令后，系统将在下次启动时不会自动加载 Apache 和 MySQL 服务，从而使其不再占用系统资源。 自启动服务在 /etc/systemd/system/my_startup.service 或 /usr/lib/systemd/system/startmyapp.service 编辑或创建一个服务文件 [Unit]Description=API Server for Klipper SV1Documentation=https://moonraker.readthedocs.io/Requires=network-online.targetAfter=network-online.target[Install]WantedBy=multi-user.target[Service]Type=simpleUser=forlinxSupplementaryGroups=moonraker-adminRemainAfterExit=yesWorkingDirectory=/home/forlinx/moonrakerEnvironmentFile=/home/forlinx/printer_data/systemd/moonraker.envExecStart=/home/forlinx/moonraker-env/bin/python $MOONRAKER_ARGSRestart=alwaysRestartSec=10 加载服务到自启动中 sudo systemctl daemon-reloadsudo systemctl enable my_startup 操作服务 # 设置开机自启动systemctl enable startmyapp.service# 停止开机自启动systemctl disable startmyapp.service# 启动服务systemctl start startmyapp.service# 关闭服务systemctl stop startmyapp.service# 重新启动服务systemctl restart startmyapp.service# 重新加载服务配置文件systemctl reload startmyapp.service# 查看服务当前状态systemctl status startmyapp.service# 查看所有已启动的服务systemctl list-units --type=services# 查询服务是否开机启动systemctl is-enabled startmyapp.service 查看全部服务列表可以通过执行以下命令来查看系统中所有的服务及其状态： sudo service --status-all 此命令会列出所有已注册服务，显示它们当前的运行状态。输出信息通常包括一个字符和服务的名称，其中 + 表示服务正在运行，- 表示服务已停止，? 则表示服务的状态不明确。 字段解释 disable|enable：这两个关键字指的是服务在 /etc/init.d 目录下的脚本是否存在，并且标识该服务是否设置为手动启动或自动启动。 例如：如果某个服务的脚本被标记为 enable，那么系统会在启动时自动加载该服务。 start|stop：这些命令指示服务的启动或停止。同样，这些脚本也位于 /etc/init.d 中，但更具体地说明了服务的当前状态。 例如：sudo service service_name start 会启动对应的服务，而 sudo service service_name stop 则会停止它。系统管理员可以随时根据需求调整服务的运行状态。 NN：这是一个由两位数字构成的值，用于指定服务的启动顺序。较大的数字会被优先处理，确保依赖较多的服务优先启动。 例如：如果有两个服务，分别标记为 90 和 80，这意味着设置为 80 的服务会在设置为 90 的服务之前启动或停止。这种机制确保了系统内各服务之间的依赖关系得到合理管理。 runlevel：这表示系统当前的运行级别，可以控制系统启动时各个服务的加载状态。在 UNIX 系统中，运行级别定义了系统允许的功能和服务状态。 例如：在经典的 Linux 系统中，运行级别 3 通常意味着系统处于多用户模式，而没有图形界面，而运行级别 5 则表示系统在多用户模式下并且有图形界面。通过设置不同的运行级别，可以灵活地管理系统的资源和访问权。 通过以上命令及其选项，可以有效地管理和监控系统中所有的服务状态，从而确保系统的正常运行和资源的合理利用。 查看服务状态journalctl 是 Systemd 日志收集服务 journal 的一个命令行界面。它允许用户查询和操作 systemd journal 中的日志条目。这对于诊断系统服务问题、追踪错误或者监控系统事件非常有用。下面是几个使用 journalctl 的基本命令示例： 查看所有日志，这个命令会显示系统中所有服务的日志。 journalctl 查看特定服务的日志，将服务名替换为想查看服务的日志名称，例如查看 nginx 服务日志： journalctl -u 服务名.servicejournalctl -u nginx.service 实时查看日志，这个命令会像 tail -f 一样实时显示新的日志条目。 journalctl -f 查看特定时间范围内的日志，这个例子会显示从 2023 年 4 月 1 日 0 点到 23 点 59 分 59 秒之间的日志。 journalctl --since 2023-04-01 00:00:00 --until 2023-04-01 23:59:59 查看包含特定关键词的日志，使用 grep 结合 journalctl 来过滤特定关键词，例如查找包含”error”的日志，或者直接使用 journalctl 的 grep 参数（-g 或–grep）： journalctl | grep errorjournalctl -u 服务名.service --grep 关键字 清空日志，这个命令会删除所有超过 1 天的日志条目。请注意，这将永久删除日志数据。 journalctl --vacuum-time=1d","categories":["1.平台","Linux","系统参数"]},{"title":"网络超时检测的三种方法","path":"/2024/04/30/1-平台-Linux-网络-网络超时检测的三种方法/","content":"网络超时检测的三种方法 网络通信中，很多操作会使得进程阻塞，这时们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 这里们总结一下网络超时检测的三种方法： 一、通过 setsockopt 设置套接字属性 SO_RCVTIMEO struct timeval t = 5, 0if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, t, sizeof(t)) == -1) perror(setsockopt); return -1;memset(peeraddr, 0, sizeof(peeraddr));len = sizeof(peeraddr);if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) printf(errno=%d: %s , errno, strerror(errno));\tif (errno == EAGAIN) printf(timeout ); return -1; 二、设定 select 函数的一个参数实现超时处理 struct timeval t= 3, 0;while (1) t.tv_sec = 3;\tt.tv_usec = 0;\tif ((ret = select(maxfd+1, rdfs, NULL, NULL, t)) == -1) perror(select); return -1; 三、设定一个定时器捕捉 SIGALRM 信号做超时控制 struct sigaction act;sigaction(SIGALRM, NULL, act); //获取SIGALRM信号的属性act.sa_handler = handler; // 设置SIGALRM信号的处理函数sigaction(SIGALRM, act, NULL); // 设置SIGALRM信号的属性alarm(3); // 定时器设置3秒钟while (1) if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) if (errno == EINTR) printf(timeout ); return -1; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["1.平台","Linux","网络"]},{"title":"网络配置","path":"/2024/04/29/1-平台-Linux-网络-网络配置/","content":"进入到 Ubuntu 系统中配置网络是确保计算机能够顺利连接互联网的关键步骤。主要需要配置以下几个方面的内容： 1. 修改文件 /etc/network/interfaces此文件用于配置 IP、网关、掩码等网络信息。 命令： sudo vi /etc/network/interfaces 或 sudo gedit /etc/network/interfaces 示例配置： # interfaces(5) file used by ifup(8) and ifdown(8)auto loiface lo inet loopbackauto eth0iface eth0 inet static address 192.168.1.151 netmask 255.255.255.0 gateway 192.168.1.2 注意：设置网关时，可以使用命令 sudo route add default gw 192.168.1.1。确保网关地址与 Virtual Network Editor 中的 “NAT Settings…” 一致，通常为 192.168.xx.2。 2. 修改文件 /etc/resolv.conf该文件保存 DNS 服务器的配置信息。 命令： sudo vi /etc/resolv.conf 或 sudo gedit /etc/resolv.conf 示例配置： nameserver 202.38.64.1 这里的 DNS 服务器地址可以根据实际环境调整，例如，可以使用校园网的 DNS，确保能够正常解析域名。 3. 解决 resolv.conf 被重写问题每当重启虚拟机或网络时，/etc/resolv.conf 文件可能会被重写，恢复为默认配置，导致先前保存的 DNS 设置丢失。这一问题需要解决，以避免每次都手动配置。 解决步骤： 理解 resolv.conf 被重写的原因。通常情况下，这个文件的开头会给出提示。 在 /etc/network/interfaces 中增加 dns-nameservers 参数。该参数的优先级高于 resolv.conf，网络会首先读取此设置。 示例配置： # interfaces(5) file used by ifup(8) and ifdown(8)auto loiface lo inet loopbackauto eth0iface eth0 inet static address 192.168.1.151 netmask 255.255.255.0 gateway 192.168.1.2 dns-nameservers 202.38.64.1 4. 重启虚拟机网络配置完成后，需要重启网络才能使设置生效。可以通过以下几种方法来实现： 重启网络服务： sudo service networking restart 或 sudo /etc/init.d/networking restart 重启特定网卡： sudo ifconfig eth0 downsudo ifconfig eth0 up 重启网卡不会影响其他网卡，因此更为推荐这种方法。 测试网络连接运行以下命令检查网络是否配置成功： ping www.baidu.com 如果成功响应，表明网络连接正常，可以顺利上网。 Linux 的网络接口设备在 Linux 操作系统中，网络接口是实现网络通信的重要组件，每个外围设备的网络接口都有相应的名称，这些名称遵循特定的命名规则，有助于用户和系统对网络设备进行管理和操作。 网络接口设备及其名称以下是 Linux 系统中常见的网络接口设备名称及其解释： lo：本地回送接口。该接口的主要功能是允许网络软件在本地进行测试和进程间通信。任何程序在使用回送地址（通常是 127.0.0.1）发送数据时，协议软件会立即将这些数据返回，而不会经过实际的网络传输。回送接口的一个典型应用是开发人员测试网络应用程序，比如在没有网络连接的情况下验证应用的基本功能。在 Linux 系统中，回送设备是预先配置好的，因此不需要额外的设置。 ethn：第 n 个以太网卡接口。其中，n 的值从 0 开始递增，表示系统中的第一个、第二个、第三个以太网卡等。以太网卡是大多数计算机的标准网络接口，其接口名中的 “eth” 部分识别了以太网类型，而 n 表示卡的顺序。例如，如果系统中有两块以太网卡，则它们分别被命名为 eth0 和 eth1。用户可以通过命令 ifconfig 或 ip link 来查看所有网络接口的状态和配置。 pppn：第 n 个 PPP（点对点协议）接口。PPP 接口通常用于通过串口和调制解调器建立互联网连接，尤其是在拨号上网的场景中比较常见。每个 PPP 接口按照其配置的顺序进行连接。例如，若系统中配置了两条通过 PPP 协议的线路，则可以称之为 ppp0 和 ppp1。对于需要通过拨号连接到互联网的场景，配置 PPP 接口是一种常见的解决方案。 网络配置命令 hostname 用于查看或配置计算机的主机名。例如，使用命令 hostname Linux 可以将主机名设置为“Linux”。主机名不仅在网络中识别设备，也为用户提供了便利，尤其是在管理多台服务器时。 ifconfig 该命令用于查看或配置网络接口。在执行 ifconfig 后，系统会显示所有网络接口的状态及其当前配置，如 IP 地址、网络掩码和传输状态等。通过该命令，用户可以快速诊断网络问题。 ifup 这个命令用于启用指定的网络接口。例如，运行 ifup eth0 将激活名为“eth0”的网络接口，允许数据包的发送和接收。 ifdown 与 ifup 相反，ifdown 用来禁用指定的网络接口。执行 ifdown eth0 将关闭该接口，数据传输将停止，用于进行维护或故障排查。 route 此命令用于查看或配置内核路由表的配置情况。通过运行 route -n，用户可查看路由表的详细信息，例如目的地、网关和网络接口等信息，从而确定数据包的传送路径。 配置以太网络－使用命令 配置 IP 地址 # ifconfig [interface] [ip-address] [netmask …] [broadcast …] [up] [down] 通过这条命令，用户可以为特定的网络接口（如 eth0）分配一个 IP 地址和网络掩码。例如，ifconfig eth0 192.168.1.10 netmask 255.255.255.0 up 将启动 eth0 接口，同时指定其 IP 地址和网络掩码。 配置默认网关 # route add default gw [IP 地址]# route add 0.0.0.0 netmask 0.0.0.0 eth0 这些命令允许用户设置默认网关，使数据包能够正确地发送到外部网络。比如，route add default gw 192.168.1.1 设置网关为 192.168.1.1，从而使得系统能通过这个网关访问外部网络。 配置 DNS 客户端 # vi /etc/resolv.conf 编辑 /etc/resolv.conf 文件可以配置 DNS 服务器，以便进行名称解析。例如，添加 nameserver 8.8.8.8 可使用 Google 的公共 DNS 服务进行域名解析。 TCPIP 配置文件 etcsysconfignetwork 这个文件包含了系统的基本网络信息，对系统的启动至关重要。例如，文件中可能指定网络是否启用等信息。 etcsysconfignetwork-scripts 存放网络配置脚本，负责系统启动时初始化网络信息。这里的每个配置脚本都是以“ifcfg-”开头，表示相应的网络接口配置。 etcxinetd.conf 定义由超级进程 xinetd 启动的网络服务，允许用户对服务的访问进行细致控制，包括限制 IP、端口和服务启动方式等。 etchosts 用于主机和 IP 的映射，允许用户通过主机名访问其他计算机。例如，添加条目 192.168.1.20 myserver 可以直接通过 myserver 来访问这台计算机。 etchost.conf 定义 DNS 客户端的搜索顺序，通常指定先进行 /etc/hosts 文件查找，然后再进行 DNS 查找。 etcresolv.conf 用于指定 DNS 服务器的地址，确保系统可以将域名解析为 IP 地址。 etcservices 该文件包含了服务名称和与之对应的网络端口和协议，帮助系统识别不同服务的访问。 etcsysconfignetwork-scriptsifcfg-eth0 用户可在此文件中编辑网络接口的配置，如 IP 地址、网关和站点等信息。 Linux 支持一块网卡绑定多个 IP 例如，通过编辑子接口配置文件 ifcfg-eth0:1，可以为同一网络接口设置多个 IP 地址，从而实现更灵活的网络配置。 Netconfig 调用菜单 通过该菜单，可以方便地进行网络设置，通过交互式界面引导用户完成配置。 配置 ADSL 网络接口 安装 pppoe rpm –qa | grep pppoe 此命令用于检查系统中是否已安装 pppoe（点对点协议以太网），确保系统具备建立 ADSL 连接的能力。 配置 pppoe adsl-setup/etc/sysconfig/network-scripts/ifcfg-ppp0adsl-status 使用 adsl-setup 命令引导用户配置 ADSL 网络，输入 ISP 提供的用户名和密码后，pppoe 会创建必要的配置文件，如 /etc/sysconfig/network-scripts/ifcfg-ppp0。后续可以运行 adsl-status 查看当前连接状态。 启用和挂断 ADSL 网络连接 adsl-start # 或 ifup ppp0adsl-stop # 或 ifdown ppp0 使用 adsl-start 可以启动 ADSL 连接，而 adsl-stop 则用来关闭连接。通过这些命令，用户能够方便地控制他们的网络连接，切换在线和离线状态。 检测网络状态 Ifconfig 此命令用于检测当前系统中所有网络接口的状态。通过执行 ifconfig，可以查看每个网络接口的 IP 地址、子网掩码和传输状态，例如，查看以太网接口时，输出将会包含该接口的 MAC 地址和活动状态。 Ping 通过发送回显请求到指定的 IP 地址或域名，以检测网络连通性。执行 ping www.example.com 将向该网站发送数据包，等待响应，可以显示网络延迟以及数据包丢失率，这有助于判断网络连接是否正常以及响应速度。 Netstat 用于查看网络状态，例如当前打开的连接和监听的端口。执行 netstat -tuln 可以显示当前的网络连接及其状态，有助于管理员了解哪些服务在运行并且监听哪些端口。 Traceroute 该命令用于跟踪数据包从源到目的地的路由路径，执行 traceroute www.example.com 将显示每个经过的路由器 IP 地址，从而帮助诊断网络性能问题。 Tcpdump 用于捕获和分析网络数据包，显示本机网络流量的状态。执行 tcpdump -i eth0 将实时展示通过指定网络接口的数据包信息，这对于网络故障排查与监控极为重要。 配置网卡信息IP、网关、掩码网卡配置通常在 /etc/network/interfaces 文件中进行，包含以下信息： auto eth0iface eth0 inet static address 192.168.10.10 netmask 255.255.255.0 gateway 192.168.10.1 DNSDNS 配置则在 /etc/resolv.conf 文件中设置，比如： nameserver 192.168.10.1 当完成更改后，重新启动网络服务生效。 sudo service networking restart 或在其他系统中使用： systemctl restart network 系统配置示例对于网络配置文件示例： # /etc/sysconfig/network-scripts/ifcfg-eno16777736TYPE=Ethernet # 设备类型BOOTPROTO=static # 地址分配模式NAME=eno16777736 # 网络接口名称ONBOOT=yes # 是否启动IPADDR=192.168.10.10 # IP 地址NETMASK=255.255.255.0 # 子网掩码 GATEWAY=192.168.10.1 # 默认网关DNS1=192.168.10.1 # DNS 服务器 桥方式 Bridge在桥接模式中，虚拟机与主机共享同一网络，通过自动获取或手动指定 IP 地址，使其与主机处于同一子网内。这要求虚拟机的 IP 地址、网关及 DNS 设置与主机一致，从而实现与外界的直接通信。例如，当虚拟机配置为获取 DHCP 时，它会向主机所在网络中的 DHCP 服务器请求 IP 地址。 NAT 方式在 NAT（网络地址转换）模式下，主机装备了一块名为隐藏网卡（B）的网络接口，这使得虚拟机能通过这块网卡与外部网络连接。虚拟机的网卡（A）默认情况下会自动接收 IP 地址，主机中的 DHCP 服务（由 vmware 等虚拟化软件提供）将负责 IP 的分配。比如，若主机网卡 B 的 IP 为 192.168.153.2，虚拟机网卡 A 的配置应如下： IP 地址：192.168.153.139 子网掩码：255.255.255.0 网关：192.168.153.2 DNS：192.168.153.2 Host-Only 方式在 Host-Only 模式下，网络结构与 NAT 相似，但主机充当唯一的网关。此模式仅允许虚拟机与主机之间交换数据，无法访问外部网络。这种设置适用于需要隔离虚拟机网络环境的场景。对于新创建虚拟机，默认使用桥接方式，建议手动指定 IP 地址。而在 NAT 模式下，IP 设置为自动通常更为实用。不过，通过精确配置手动 IP 也没有问题，确保它与主机网卡 B 在同一网段，且其他网络设置指向网卡 B 的地址。 设置 Linux 的 IP 地址在命令行中，可以使用以下指令来配置 IP 地址和默认网关： sudo ifconfig eth0 192.168.152.30 netmask 255.255.255.0sudo route add default gw 192.168.152.2 说明：如果以普通用户身份（如测试账户）执行这些命令，由于缺乏权限，需使用 sudo 提升权限，这样输入对应用户的密码就能临时获取管理员权限进行配置。 设置网卡的 DNS 服务器地址在网络环境中，DNS 服务器的角色至关重要，可以将例如 www.example.com 的域名解析为 IP 地址 172.18.0.5。每台能够联网的电脑都需要设置 DNS，以确保网站访问的顺畅。若希望配置 DNS 服务器地址，可编辑 /etc/resolv.conf 文件，使用命令： sudo gedit /etc/resolv.conf 在该文件内填写 DNS 服务器，例如： nameserver 8.8.8.8 # Googles Public DNS 通过这样的方式，可以有效设置每个网络接口的 DNS，以确保网络名称解析的正确性和快速性。","categories":["1.平台","Linux","网络"]},{"title":"Vmware共享文件夹","path":"/2024/04/26/1-平台-VMware-Vmware共享文件夹/","content":"查看共享的文件夹使用 vmware-hgfsclient 命令，可以查看当前系统中所有的共享文件夹。这个命令被广泛应用于 VMware 虚拟机环境中，以便于快速了解主机与虚拟机之间的共享资源。 输入以下命令： vmware-hgfsclient 运行后，系统会列出所有可用的共享文件夹名称，方便确认需要挂载的共享资源。 挂载共享文件夹要将共享文件夹挂载到虚拟机上，需要使用 vmhgfs-fuse 命令。这个命令会把主机的共享文件夹映射到虚拟机的一个目录中，使得两者之间可以无缝地共享文件。 执行以下命令，将主机下的 ShareDir 挂载到虚拟机的 /home/forlinx/ShareDir 文件夹中： vmhgfs-fuse .host:/ShareDir /home/forlinx/ShareDir -o subtype=vmhgfs-fuse,allow_other 如果在挂载后发现共享文件夹没有出现在指定位置，可以尝试执行以下命令： vmhgfs-fuse .host:/ /home/forlinx/ShareDir 如果没有其他错误信息显示，就可以认为挂载成功了。 注意：在进行挂载之前，请确认 /mnt 目录下的 hgfs 目录已经存在。如果没有，可以通过以下命令创建它： mkdir /mnt/hgfs 最后，运行 ls 命令来查看挂载内容，确保共享文件夹内的文件已经同步： ls /home/forlinx/ShareDir 如果能看到文件内容，就表示挂载成功。 自动挂载为了提高工作效率，如果想避免每次重启后都手动挂载共享文件夹，可以创建一个启动脚本，实现自动挂载。 脚本首先，创建一个名为 startShare.sh 的脚本文件，输入以下命令： vmhgfs-fuse .host:/ /home/forlinx/ShareDir 之后，为该脚本添加可执行权限： chmod a+x startShare.sh 接下来，将这个脚本添加到系统启动时的自启中，这样每次系统启动时都会自动执行这个挂载操作。 启动文件如果希望通过修改系统的启动文件来实现这一目标，首先，应该备份当前的 /etc/fstab 文件，以便在需要时能够恢复。例如，运行以下命令： cp /etc/fstab /etc/fstab_bak 然后，使用文本编辑器（如 vim）打开 fstab 文件： vim /etc/fstab 在文件的最后添加以下内容： # mount hgfs.host:/kali_share /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0 保存并退出编辑器后，系统将在每次启动时自动挂载指定的共享文件夹，这样就可以省去手动挂载的麻烦，确保文件始终可以访问。","categories":["1.平台","VMware"]},{"title":"虚拟机磁盘收缩","path":"/2024/04/25/1-平台-VMware-虚拟机磁盘收缩/","content":"1. 删除快照打开 VMware，选择工具栏的虚拟机，选择快照，选择快照管理器，删除不用的快照 2. 删除缓存文件打开虚拟机，删除虚拟机中的缓存文件目录： rm -rf /home/forlinx/.cache/vmware/drag_and_drop df -h 指令可查找到磁盘真实占据的磁盘空间 3. 压缩磁盘空间当虚拟机安装盘所剩余的空间大于.vmdk 文件的大小时，强烈推荐使用以下方式 在的终端输入 sudo /usr/bin/vmware-toolbox-cmd disk list 一般会有 / 目录 再输入 sudo /usr/bin/vmware-toolbox-cmd disk shrink / 即压缩根目录 / 4. 使用 DiskGenius 压缩存放在物理硬盘上的虚拟磁盘文件的大小并没有减小。虚拟机磁盘文件只会慢慢地变大，虚拟机软件不会在用户删除数据后对虚拟磁盘进行”压缩”。可以使用 DiskGenius 软件进行压缩。比如们使用的是 VMware 虚拟机，它的虚拟磁盘文件是 vmdk 格式。 1、在 DiskGenius 软件中，首先把要压缩的虚拟磁盘打开（菜单：”硬盘 – 打开虚拟硬盘文件”）。打开后就可以在左边的窗口中看到加载上的虚拟磁盘了。 2、然后们再新建一个容量不小于源虚拟硬盘的 vmdk 虚拟磁盘（菜单：”硬盘 – 新建虚拟硬盘文件 – 新建 VMware 虚拟硬盘文件”）。 3、开始进行压缩。选择（菜单：”工具 – 克隆硬盘”），弹出对话框后，在”选择源硬盘”时选择要压缩的 vmdk 虚拟磁盘，在”选择目标硬盘”时选择刚刚们新建的 vmdk 虚拟磁盘，然后点”开始”。 4、现在已经复制完毕了，们找到两个虚拟磁盘文件的所在路径，对比一下大小。可以看到，虚拟硬盘被压缩了。 这时，还需要做一些后续的清理工作。首先在 DiskGenius 软件中关闭刚才打开的两个虚拟硬盘，或者直接关闭 DiskGenius 软件。然后将源虚拟硬盘文件改名（备用，以防万一），再将新的虚拟硬盘文件改名为源虚拟硬盘的文件名（注意要完全相同）。最后打开虚拟机，启动一下虚拟系统，没有问题后就可以删除压缩前的源虚拟硬盘文件了。 5. 导出 OVF 重新建立新 vmdk有时候删除虚拟机快照出现错误，但快照图标已消失，导致无法再次删除，造成文件残留，就这样越堆越多，无法清理。 优点是可以释放大量空间，缺点是只能保留 VMware 虚拟机当前的状态和文件，丢失其他快照（可以按需先转到某个快照再导出 OVF，这样就可以保留快照时的状态了。同样，会丢失其他状态）。步骤如下： 点击要清理的虚拟机，然后左上角点击文件，导出为 OVF（只存了虚拟机当前的状态，大概有十几个 G），存到其他空闲的磁盘下。 将上述步骤导出的 ovf 再部署出来，看看虚拟机是否正常。 如果正常可用，就可以把虚拟机原来占用的磁盘清空了，快速释放大量空间。","categories":["1.平台","VMware"]},{"title":"USB设备连接到WSL","path":"/2024/04/24/1-平台-WSL-USB设备连接到WSL/","content":"在 WSL2（Windows Subsystem for Linux 2）中连接 3D 打印机的 USB 端口，首先需要将该设备从 Windows 系统挂载到 Linux 系统。这一过程需要在 Windows 环境中安装一个名为 usbipd 的工具。usbipd 允许 Windows 上的 USB 设备共享给 WSL2 的 Linux 系统使用。 安装 usbipd可以通过下面的链接访问 usbipd 的 GitHub 仓库，以获取更多信息和相关文档： usbipd GitHub 地址 在的 Windows 命令行中执行以下命令以安装 usbipd： # 在 Windows 命令行中执行winget install usbipd 确保执行成功。可以在命令行中输入 usbipd --version 来确认 usbipd 是否已正确安装，并查看其版本。 安装所需环境在完成 usbipd 的安装后，需要设置 WSL2 环境以支持 USB 设备的挂载。在的 WSL2 终端中执行以下命令： ## 在的 WSL 中执行sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 这段代码主要的作用是安装必要的 Linux 工具包，并设置 usbip 的可执行路径。 如果在这个过程中遇到错误提示，如 usbipd: error: WSL ‘usbip’ client not correctly installed，请检查上述步骤是否完全执行，必要时重新运行安装命令以确保所有组件都已正确配置。 列出并挂载 Windows 中的设备到 Linux 环境在完成了环境的设置后，接下来需要列出所有可用的 USB 设备并将其挂载到 WSL2 中。可以在 Windows 终端中执行以下命令： # 在 Windows 终端中执行usbipd wsl list 此命令会显示出当前连接的所有 USB 设备，列表中会包括它们的 busid，这在后面的步骤中是必需的。 一旦找到了想要挂载的设备的 busid，可以使用以下命令将该设备挂载到 Linux 环境中： usbipd wsl attach --busid=4-1 请根据想要连接的实际设备 ID 替换 4-1。执行后，应该能够在 WSL2 内访问到的 3D 打印机，接下来的步骤是配置和使用打印机。 通过以上步骤，可以顺利地在 WSL2 环境中使用 USB 设备，享受更灵活的开发和打印体验。","categories":["1.平台","WSL"]},{"title":"Obsidian笔记建设","path":"/2024/04/23/1-平台-服务器-Obsidian笔记建设/","content":"Obsidian 配置Ctrl+Shift+I 在控制台里可以查看详细日志，所有插件的日志都可以在这里看到 Hexo 忽略文件和文件夹由于 hexo 的文章只存在于 source 目录下，需要让 Obsidian 忽略其他文件的内容以优化性能以及减少不必要的搜索结果。具体的操作是在 设置-文件与链接-Exclude Files，将需要忽略的文件添加进去（尤其是 node_modules）。 Templater模板配置说明文档 https://silentvoid13.github.io/Templater/introduction.html 首先要创建模板，可以在 source 目录下创建 _obsidian 文件夹，并创建一篇 Post Template 的文章（md 文件），再创建新文章的时候，只需要点击侧边栏的『插入模板』按钮就可以快速生成 Front-matter 信息： ---title: % tp.file.title %date: % tp.file.creation_date(format=YYYY-MM-DD HH:mm:ss) %update: % tp.file.last_modified_date(YYYY-MM-DD HH:mm:ss) %comments: truetags:categories:dg-publish: true---定义脚本function generateTimestampUrl() var timestamp = Math.round(new Date() / 1000); var url = timestamp.toString(36) return url; module.exports = generateTimestampUrl; osidian-git快捷键 Ctrl + P 打开命令面板，输入 open source control view 启用可视化操作面板 obsidian-pangu已用 Linter 替代 中英文之间加空格 Hidden Folder目录隐藏插件 FileTree左侧菜单出现了一个 File Tree 的 Tab 页，点击后就可以看到文件以树形的结构呈现，展开 source 文件夹，并右键 _post 文件夹，选择 Focuse on Folder 后，左侧的文件列表中就只会显示 _post 文件夹中的内容了 Github Publisher已使用整个仓库进行同步发布，不采用这种单页面发布形式 将 Obsidian 中的文章和本地附件上传到 Github 仓库，上传前可以指定文件目录、自定义内容替换等操作。 能将 Obsidian 仓库里的任意笔记自动或者手动同步到 GitHub 代码仓库的任意位置。首先设置好 Github 相关信息，包括 Github repository，用户名，token 以及 Branch。当然也可以在单个笔记文件里，通过文档属性（frontmatter），单独设置接收笔记上传的 Github 仓库信息（可以选择同一用户下的不同仓库，同一仓库下的不同位置）。 上传设置 设定上传的笔记存储在 Github 仓库的位置。因为的 hexo 博客日志文件保存在 sourceposts 目录下，故选择 Fixed Folder，设定好默认上传到的目录。 文章发布 在文章文档属性添加一个 share 属性（可以根据需要在插件设置里改成其他任意名称），赋予值 true。文章写好后，share: true 右键发布。 ShellCommand可以解决 obsidian 无法打开 . 开头的默认文件的问题 再介绍个终极优化方案，之前执行命令是通过运行 bat 文件，而 Shell commands 可以在 Obsidian 中设置好命令，并通过 Obsidian 的命令面板或快捷键快速运行。 在插件设置面板中添加命令 运行博客： Shell commands 没有显示终端窗口的功能，所以需要启动 powershell 再传入命令 有了终端窗口才可以在窗口中按 Ctrl + C 关闭 Hexo 服务，否则它会一直占用端口 start powershell -NoExit -Command start http://localhost:4000 ; cd Blog ; hexo s 打开站点和主题配置文件： start Blog/_config.ymlstart Blog/themes/butterfly4.3.1/_config.yml 然后修改默认执行环境为 PowerShell 5，可以为每个命令设置下别名，就是在命令面板显示的名字 Emo 插件用 PicGo 支持更多自定义设置 用于自托管图片 image auto upload plugin也是用于自托管图片 Linter 插件用户在保存笔记时按照一定的格式，格式化笔记，这里用到的功能： 保存笔记时自动插入 front-matter 进入 Linter 的设置，选择 YAML 设置，找到其中的插入 YAML 设置（ Insert YAML attributes），打开开关后，输入要插入的 front-matter 自动更新文件修改时间戳 进入 Linter 的设置，选择 YAML 设置，找到其中的 YAML 时间戳（ yaml-timestamp），设置为 Hexo 识别的 date 和 update 格式化笔记 主要的是一个不同语言中间的空格自动添加，进入 Linter 的设置，选择空格，找到其中的 Space between Chinese Japanese or Korean and English or numbers，打开即可 其他插件 Image Converter 转化图片格式，统一转为 webp，并设置了图片分辨率大小。 Unique attachments 用于将附件的文件名统一为 “字母 + 数字”的格式,记着在配置里加入 webp 图片格式 Image Inserter 用于找图片，用于设置文章封面，即设置 cover.image 属性。 目前在用的插件","categories":["1.平台","服务器"]},{"title":"LNMP环境","path":"/2024/04/22/1-平台-服务器-博客-LNMP环境/","content":"前言在通过 Docker 部署 WordPress 的过程中，意识到许多需要修改的文件都必须通过 docker-compose 脚本映射到本地，这让改动变得不太方便。此外，由于 Docker 的特性，关闭并重启容器后，里面的数据往往会丢失。为了解决这个问题，只能依赖于持久化存储，而这可以通过 volume 或者称为”数据容器”的方案来实现。 容器一旦关闭，可以使用 -v 或者 --volumes-from 来重新利用以前的数据。此外，Docker 还支持挂载宿主机的磁盘目录，从而实现数据的永久存储。这种方式虽然可行，但在实际操作中，能够直观地查看和修改所有文件显得更为放心。因此，决定通过手动配置 LNMP 的基础运行环境来建立的 WordPress 网站。 目前配置 LNMP 环境可选的方式有以下几种： 通过宝塔面板进行可视化配置，适合不熟悉命令行的用户。 使用脚本实现一键配置，减少手动操作的复杂性。 各软件组件独立进行手动安装与配置，适合深入了解每个组件的用户。 在这次设置中，选择通过脚本配置，并将之前 Docker 中搭建的 WordPress 的所有数据导入新的环境中。 LNMP 介绍LNMP 是 WordPress 运行的基础环境，其全名相对应的是四个主要组件：Linux、Nginx、MySQLMariaDB 和 PHP。这些组件的角色功能如下： Linux：作为操作系统，它提供了基本的系统服务和资源管理，比如文件系统、用户管理和网络配置等。 Nginx：这是一个高性能的 Web 服务器，能有效处理客户端请求并将其转发给后端应用程序。Nginx 的异步处理能力使其能够轻松应对大量并发请求，特别适合用于动态站点。 MySQLMariaDB：这两者都是关系型数据库，负责存储和管理应用程序的数据。MySQL 和 MariaDB 提供强大的数据查询和存储功能，支持多种存储引擎。 PHP：作为服务器端的编程语言，PHP 允许开发人员编写复杂的程序逻辑，如处理用户请求、与数据库交互等。 LNMP 架构具有明显的优点： 高性能：如前所述，Nginx 能处理大量并发请求，适合流量密集型的网站。 稳定可靠：Linux 系统以其稳定性著称，广泛用于服务器环境，保证了良好的系统服务和资源管理。 易于扩展：选择 MySQL 或 MariaDB 可以轻松实现高可用和分布式架构，支持业务增长。 灵活可定制：PHP 支持丰富的框架和库，能够满足多样化的业务需求。 LNMP 架构在 Web 开发和运维领域得到了广泛的应用，尤其在面对高并发和大数据场景时，能够保持良好的性能表现与可扩展性。 此外，值得一提的是还有其他几种架构。例如，LAMP 是 Linux + Apache + MySQL + PHP 的组合，LNAMP 则是 Linux + Nginx + Apache + MySQL + PHP。Apache 是一种排名第一的 Web 服务器软件，以其跨平台特性和安全性被广泛采纳，是目前最流行的 Web 服务器之一。 一键安装 LNMP登录 VPS 或服务器使用 PuTTY 或其他类似的 SSH 工具登录到的 VPS 或服务器。成功登录后，运行以下命令以创建一个新的屏幕会话： screen -S lnmp 如果出现 screen: command not found 的提示，可以通过以下命令安装 screen： apt-get install screen 有关 screen 的详细用法，请参考其 官方教程。 下载并安装 LNMP 一键安装包可以选择下载两个版本的 LNMP 安装包： 下载版：推荐给美国及海外的 VPS 或空间较小的用户使用。 完整版：推荐给国内 VPS 用户，包含了一些预先放入的源码文件，方便快速安装。 安装 LNMP 稳定版如果希望进行无人值守安装，可以使用无人值守命令生成工具，或查看相关的无人值守说明教程。 使用以下命令下载并解压 LNMP 安装包： wget http://soft.vpser.net/lnmp/lnmp1.9.tar.gz -cO lnmp1.9.tar.gz tar zxf lnmp1.9.tar.gz cd lnmp1.9 ./install.sh lnmp 如果的目标是安装 LNMPA 或 LAMP，将命令中的 lnmp 替换为 lnmpa 或 lamp 即可。此外，还可以选择单独安装 Nginx 或数据库，运行以下命令： ./install.sh nginx 或 ./install.sh db 如果需要更改网站和数据库目录、自定义 Nginx 参数或 PHP 参数模块（如是否开启 lua），请在运行 ./install.sh 命令前修改安装包目录下的 lnmp.conf 文件。详细的参数说明可以在 lnmp.conf 文件中查看。 如遇到 wget: command not found 的提示，可以使用以下命令安装 wget： yum install wget 或 apt-get install wget 如果下载速度慢或遇到下载问题，请考虑更换其他下载节点，具体替换方法可以在 LNMP 的文档中找到。 执行 LNMP 安装命令运行 LNMP 安装命令后，可能会出现以下提示： 当前安装包中提供了多种 MySQL 和 MariaDB 的版本选项。如果选择安装 MySQL 5.6、5.7 或 MariaDB 10，确保的内存配置至少为 1G。如果仅需安装数据库，可以使用以下命令： ./install.sh db 在提示中，输入相应 MySQL 或 MariaDB 版本前的序号并回车，进入下一个步骤。 如果选择 MySQL 5.7 或 8.0 且系统架构为 x86 或 x86_64，系统会提示是否使用二进制包进行安装：”Using Generic Binaries [yn]:”。输入 y 表示使用二进制安装，输入 n 则使用源码编译。如果选择了二进制方式，建议离线安装或自行下载至安装包的 src 目录。 接下来，需要设置 MySQL 的 root 密码。出于安全考虑，可以直接回车，系统会自动生成一个密码（例如 lnmp.org#随机数字）。如果需要删除错误输入的密码，按住 Ctrl 并同时按 Backspace 或只按 Backspace 键（根据系统不同情况而定）。 接着，系统会询问是否启用 MySQL InnoDB，引擎默认开启，建议直接回车或输入 y。如果确定不需要，可以输入 n。请注意，MySQL 5.7 及以上版本无法关闭 InnoDB。 选择 PHP 版本时，请确认所选版本与的程序兼容。输入相应 PHP 版本的序号并回车，接下来会提示是否安装内存优化选项。可以选择不安装、Jemalloc 或 TCmalloc，直接回车则为默认不安装。 如果选择的是 LNMPA 或 LAMP，系统会进一步提示设置管理员邮箱，该邮箱在出现错误时会显示在错误页面上。接着，选择 Apache 版本，输入对应版本序号并回车。 在提示”Press any key to install… or Press Ctrl+c to cancel”后，按下回车键确认开始安装。LNMP 脚本将自动安装和编译 Nginx、MySQL、PHP、phpMyAdmin 等软件及相关组件。安装耗时从几十分钟到几个小时不等，具体时间依赖于机器配置及网络速度。 安装完成安装完成后，系统应显示： Nginx: OK, MySQL: OK, PHP: OK 同时，Nginx、MySQL、PHP 都应显示为运行状态，并确保 80 和 3306 端口存在，并提示安装时间及”Install lnmp V1.9 completed! enjoy it.”，说明安装成功。如果系统卡在”Install lnmp V1.9 completed! enjoy it.”不自动退出，可以按 Ctrl + c 强制退出。 完成安装后，可以按照添加虚拟主机的教程添加虚拟主机。随后，使用 SFTP 或 FTP 服务器上传网站代码，并将域名解析到 VPS 或服务器的 IP 地址。确保解析生效后，即可使用的网站。 安装失败如果出现某个部分没有成功安装的提示，意味着安装失败。需要使用 WinSCP 或其他相关工具，将 /root 目录下的 lnmp-install.log 文件下载到本地，并在 LNMP 支持论坛发帖，附上系统的发行版名称、版本号以及 32 位或 64 位等信息，并将 lnmp-install.log 压缩后上传，会通过日志分析错误并提供解决方案。 注意：默认情况下，LNMP 不会安装 FTP 服务器，若需要 FTP 服务器，请参考 此链接。 添加、删除虚拟主机及伪静态管理有关如何添加和删除虚拟主机的详细步骤，请访问 此链接。 扩展组件的安装如果需要安装扩展组件如 eAccelerator、xcache、memcached、imageMagick、ionCube、redis 或 opcache，请参考 此链接。 LNMP 相关软件的目录及文件位置关于 LNMP 相关软件的目录和文件位置的信息，可以访问 此链接。 LNMP 状态管理命令了解 LNMP 状态管理命令的详细内容，请查看 此链接。 仅安装数据库或 Nginx从 LNMP 1.5 版本开始，用户可以选择仅安装 MySQLMariaDB 数据库或 Nginx。要单独安装 Nginx，请在安装包目录下运行： ./install.sh nginx 要单独安装数据库，请运行： ./install.sh db LNMP 一键安装包的离线安装请注意，离线安装并不意味着不需要源，而是需要在本地建立一个源用于安装。 对于 CentOS 系统，离线安装的详细教程请参考 此链接。 对于 DebianUbuntu 发行版，需要在完全相同的临时环境下使用以下命令下载所有必需的软件包： apt-get install -d 软件包 然后通过 dpkg-scanpackages 命令将这些软件包打包至源目录。将该目录打包后上传至目标服务器并设置为源即可。 需要注意的是，如果选择在安装 MySQLMariaDB 时使用”Generic Binaries”（二进制包），必须提前下载好指定的二进制包并上传至 LNMP 安装包的 src 目录。 卸载 LNMP 一键安装包要卸载 LNMP 一键安装包，请在 LNMP 安装包目录下执行以下命令： ./uninstall.sh 按提示选择当前环境类型并回车确认，该操作会删除 LNMP 的相关程序组件，同时保留网站文件和备份数据库目录至 /root 目录下。如果还有其他需要保存的文件，请确保在卸载前进行备份。 独立安装安装 Nginx使用以下命令在的系统上安装 Nginx： sudo apt install nginx 此命令通过 APT 包管理器从默认软件源中下载并安装 Nginx。安装完成后，可以通过访问 http://localhost 来检查 Nginx 是否正常运行，默认情况下，Nginx 会在地址栏输入”localhost”时显示欢迎页面。 编辑 Nginx 配置首先，进入 Nginx 的配置目录： cd /etc/nginx/sites-enabled 删除默认配置文件，以防止它干扰自己的设置： sudo rm -f default 接下来，新建一个名为 test 的配置文件，使用以下命令： sudo vim test 在打开的编辑器中，输入以下内容，以配置 Nginx 服务： server listen 80; root /var/www/html; server_name localhost; location / index index.php index.html index.htm; error_page 500 502 503 504 /50x.html; location = /50x.html root /var/www/html; location ~ \\.php$ fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; 在此配置中，重要的部分是： listen 80; 表示 Nginx 将监听 HTTP 请求。 root /var/www/html; 指定网站文件的根目录。 location ~ \\.php$ 部分启用对 PHP 文件的处理。 完成输入后，按 Esc 退出插入模式，输入 :wq 保存并退出。 启动、设置开机启动 Nginx执行以下命令来启动 Nginx 服务： sudo systemctl start nginx 接着设置 Nginx 在系统启动时自动运行： sudo systemctl enable nginx 检查 Nginx 服务状态在本地浏览器中访问以下地址，确认 Nginx 服务正在正常运行： http://的云服务器实例的公网 IP 如果看到 Nginx 欢迎页面，就证明的配置成功了！ MySQL 数据库要配置 MySQL，首先需要通过命令行进入 MySQL 的命令行界面。请按以下步骤进行设置。使用下面的命令安装 MariaDB，它是 MySQL 的社区版本： sudo apt install mariadb-server mariadb-client 启动 MySQL在终端中运行以下命令以启动 MySQL： sudo mysql 设置 root 用户密码进入 MySQL 后，需要为 root 用户设置一个安全密码。可以使用以下命令： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY mynewpassword; 在这个示例中，将密码设置为 Mysql@1234，因此可以运行： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY Mysql@1234; 退出 MySQL在设置密码后，输入以下命令以退出 MySQL： exit; 安全配置 MySQL为了提升 MySQL 的安全性，接下来要运行安全配置命令。使用： sudo mysql_secure_installation 根据提示依次完成以下配置项： 输入 root 用户的密码： 这里要输入刚刚设置的密码，例如 Mysql@1234。 Securing the MySQL server deployment.Enter password for user root: 说明：在输入密码时，系统不会显示字符以确保安全。只需输入密码并按 Enter。 更改 root 用户密码： 系统会询问是否希望更改 root 用户的密码，可以输入 Y。 Change the password for root? (Press y|Y for Yes, any other key for No) : Y 然后再次输入新密码，并确认输入。 删除匿名用户： 输入 Y 来删除 MySQL 自带的匿名用户。默认情况下，MySQL 安装时会创建匿名用户，这会让任何人都能登录 MySQL，不需要创建用户账号，仅限于测试使用。 Remove anonymous users? (Press y|Y for Yes, any other key for No) : Y 禁止 root 用户远程登录： 输入 Y，以确保 root 只可以通过 localhost 进行连接，避免从网络上被猜测密码。 Disallow root login remotely? (Press y|Y for Yes, any other key for No) : Y 移除 test 数据库： 通过输入 Y，会移除 MySQL 默认的 test 数据库，避免其他用户随意访问。 Remove test database and access to it? (Press y|Y for Yes, any other key for No) : Y 重新加载授权表： 输入 Y 用以重载权限表，确保所有更改立即生效。 Reload privilege tables now? (Press y|Y for Yes, any other key for No) : Y 当命令行回显 All done! 时，表示安全配置已完成。 测试登录到 MySQL 数据库使用以下命令测试是否能够成功登录 MySQL 数据库： sudo mysql -uroot -p 此时命令行会提示输入密码： Enter password: 同样，输入密码时命令行不会显示字符。输入正确的密码后，将看到类似以下的信息，这表明已成功登录： Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 15Server version: 8.0.29-0ubuntu0.20.04.3 (Ubuntu)Copyright (c) 2000, 2022, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type help; or \\h for help. Type \\c to clear the current input statement.mysql 安装 PHP安装 PHP使用以下命令安装 PHP 及其常用模块： sudo apt install php7.4-cli php7.4-common php7.4-mysqlnd php7.4-fpm 启动 PHP-FPM 服务检查安装的版本是否为 7.4。如果确认是 7.4，接着启动 PHP-FPM 服务： systemctl start php7.4-fpm 然后将 PHP-FPM 服务设置为开机自启动： systemctl enable php7.4-fpm 修改 Nginx 配置以支持 PHP再次打开 Nginx 配置文件： sudo vim /etc/nginx/sites-enabled/test 按下 i 进入编辑模式，找到 fastcgi_pass 行，将其修改为： fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; 完成后，按 Esc，输入 :wq 保存并退出。 验证环境配置若 /var/www/html 文件夹下有其他文件，先用以下命令删除它们： sudo rm -rf /var/www/html/* 接着，创建一个测试文件： sudo vim /var/www/html/index.php 在编辑模式下输入： ?php phpinfo(); ? 保存并退出后，重启 Nginx 服务： sudo systemctl restart nginx 最后，在本地浏览器中访问以下地址，查看 PHP 环境配置是否成功： http://的云服务器实例的公网 IP 如果页面显示 PHP 信息，说明环境配置成功！","categories":["1.平台","服务器","博客"]},{"title":"Qexo本地部署","path":"/2024/04/19/1-平台-服务器-博客-Qexo本地部署/","content":"Qexo 是一个快速、强大、美观的在线 静态博客编辑器。使用 GPL3.0 开源协议。支持包括且不限于在 Vercel 等平台部署, 为的静态博客添加动态的元素 项目地址： https://github.com/Qexo/Qexo 本地部署安装 mysql sudo apt install mysql-server 查看并更新密码 sudo cat /etc/mysql/debian.cnf 进入 mysql，输入上面查询到的用户名和密码 mysql -u debian-sys-maint -p 创建 Qexo 要使用表 create database qexo; 克隆 qexo 项目到本地 git clone https://github.com/Qexo/Qexo.git 编辑配置，以使用 Mysql 为例, 确认好安装相关依赖后在 manage.py 的同级目录下创建并修改 configs.py import pymysql pymysql.install_as_MySQLdb() DOMAINS = [127.0.0.1, 124.222.246.202] DATABASES = default: ENGINE: django.db.backends.mysql, NAME: 数据库表, USER: 数据库用户名, PASSWORD: 数据库密码, HOST: 127.0.0.1, PORT: 3306, OPTIONS: init_command: SET sql_mode=STRICT_TRANS_TABLES 安装依赖 pip3 install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate 启动 Qexo 博客管理后端 后台运行，退出 shell 也在运行 nohup python3 manage.py runserver 0.0.0.0:9082 --noreload 访问公网 IP+ 端口即可打开 Qexo 管理页面","categories":["1.平台","服务器","博客"]},{"title":"博客Hexo部署","path":"/2024/04/18/1-平台-服务器-博客-博客Hexo部署/","content":"√ 博客框架采用 Hexo √ 部署到 GitHubPages（） √ 部署到 Vercel（GitHub Publish）- 已取消部署 × 通过 Netlify 部署和构建 √ 利用 Obsidian Digital GardenFlowershow 插件在 Vercel 上将笔记内容部署为 Obsidian 数字花园 - 已取消部署 部署流程 创建 GitHub 发布仓库 GitHub仓库部署 创建 GitHub 源码仓库，并在仓库中部署 Hexo 在源码仓库中创建工作流，工作流主要完成任务是在接收到同步后，完成以下几个动作 GitHub Actions 构建之前需要调用 hexo 插件自动生成 category 信息 构建静态页面生成 public 文件夹 将 public 文件夹拷贝至发布仓库 Hexo 仓库部署Hexo 仓库部署分为两种形式，一种是部署在 Github 上，利用 GitHub Actions 生成页面，一种是部署在本地，本地生成页面后将 public 同步到 github pages。 如果部署在 GitHub，则需要两个仓库，一个用于部署 Hexo 源码，一个用于部署 GitHubPages，之后需要通过 github actions 进行发布管理。优点是本地不需要 Hexo 环境，直接提交后自动构建页面 源码仓库闭源，同步笔记到源码仓库后，源码仓库通过 actions 时触发同步到发布仓库，更新发布仓库页面 如果部署在本地，需要在本地生成静态网页，之后将静态网页通过 publisher 发布 public 文件夹到 github 仓库，但是需要本地具有 Hexo 环境，且需要在本地生成静态网页 Github 部署可以实现两个仓库都在 GitHub，并通过 GitHub Actions 在源码仓库进行编译，编译完成后自动将源码仓库的静态页面内容复制到发布仓库，实现自动化的发布管理。 将 Hexo 的源码仓库设置在 GitHub 上，可以在这个仓库中编辑和管理 Hexo 的源代码、主题和文章。 创建另一个 GitHub 仓库作为发布仓库，用于存放生成的静态网页。可以将 Hexo 生成的 public 文件夹的内容推送到这个仓库中。该仓库利用 GitHub Pages，直接通过 username.github.io 进行访问 在 Hexo 源码仓库中设置一个 GitHub Actions workflow，以便在每次提交或推送时自动将更新的内容复制到发布仓库。 需要配置 GitHub 的 ssh，可以有权限访问两个仓库 需要配置发布仓库的 deploy key，可以有权限写入发布仓库 域名获取 GitHub 二级域名 GitHubPages liuluhua.github.io 二级域名 https://freedomain.one/ linglu.work.gd cloudflare 托管 https://dash.cloudflare.com/ 解析包括添加三条解析记录 192.30.252.153 是 GitHub 的地址，也可以 ping 的 http:的用户名.github.io 的 ip 地址，填入进去。 第三个记录类型是 CNAME，CNAME 的记录值是：http:的用户名.github.io 这里千万别弄错了。 绑定 Github 域名，登录 GitHub，进入之前创建的仓库，点击 settings，设置 Custom domain，输入的域名 PicGo 和 Github 图床配置PicGo 是一个开源的图片上传工具，主要用于将本地图片上传到各种图片托管服务，并生成图片链接。它提供了图形界面和命令行两种方式来使用。 用途图片托管：将本地图片上传到图片托管服务，如 GitHub 等。图片压缩：在上传图片之前，可以选择对图片进行压缩以减小图片文件大小，节省存储空间和加快图片加载速度。图片管理：通过 PicGo 上传的图片可以在相应的托管服务上进行管理，包括查看、删除等操作。图片链接生成：上传成功后，PicGo 会生成图片链接，方便在博客、论坛等地方直接使用图片。 GitHub 图床配置 创建一个 public 仓库 进入 Settings-Developer Settings-Personal access tokens (classic) 生成 token 设置自定义域名为 https://raw.staticdn.net/liuluhua/liuluhua.github.io/ImageBed 配置 Github 图床图床设计选择 GitHub，输入在 GitHub 的仓库名，分支名和 token 即可 设置 GitHub 为默认图床 设置图床参数 设定存储路径 插件 super-prefix安装 super prefix 插件，将图片存储时按照时间分类存储（Nodejs 环境） 配置文件路径插件 需要在 PicGo 设置中关闭时间戳重命名 /img/2019/11/18/20191118005858.jpeg 参数 建议值 说明 prefixFormat YYYY/MM/DD/ 文件名个性前缀格式 (以结尾) fileFormat YYYYMMDDHHmmss 文件名个性格式 Emo 插件如果不想要在配置 picGo 软件，直接用 Obsidian 中的 Emo 插件即可，相比起来缺少了自定义域名等功能 GitHubGithub Pages 部署GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让可以在 GitHub 仓库里托管和发布自己的静态网站页面。 创建 GitHub 账号，并创建一个基于用户名.github.io 的仓库 使用 GitHub Pages 进行部署，所建仓库必须取名为”GitHub 用户名.github.io” 勾选”Add a README file”，不然后面会看不到 GitHub Pages 域名和部署分支 仓库需要创建为公有仓库，即 public 仓库大小限制为 创建完成后 GitHub Pages 给提供了一个格式为 https://GitHub用户名.github.io 的免费域名，并且相应的网站是从该仓库的 mainmaster 分支构建得到的 自定义域名，在 GitHub 仓库 Settings-Pages-Custom domain 添加自己的域名 Git HookGit hook 是一种机制，允许在特定的 Git 事件发生时触发自定义的脚本或命令。这些事件可以包括提交 (commit)、推送 (push)、合并 (merge) 等。使用 Git hook，可以在这些事件发生时执行自定义的操作，比如运行测试、格式化代码、触发构建等。Git 提供了一系列的预定义钩子，可以将自己的脚本绑定到这些钩子上，或者创建自定义的钩子。 GitHub ActionsGitHub Actions 是 GitHub 提供的一项持续集成（CI）和持续部署（CD）服务，允许开发者自动化软件开发工作流程。通过 GitHub Actions，可以在 GitHub 上运行自定义的代码（称为动作），以响应存储库中的事件，例如推送代码、创建拉取请求等。 一个 GitHub Actions 的核心概念是 workflow（工作流），它是一系列由动作组成的自定义任务，这些任务可以在特定的事件触发时自动执行。每个 workflow 都定义了一系列步骤，每个步骤又包含一个或多个动作。workflow 可以用 YAML 格式定义，并存储在存储库的 .github/workflows 目录中。 通过 GitHub Actions，实现将代码同步 GitHub 之后，由 GitHub Actions 执行页面的发布。 执行 GitHub Actions，在需要执行的储存库中前往 Settings Pages Source，并将 Source 改为 GitHub Actions。 在储存库中建立 .github/workflows/blogPublish.yml 并写入内容 环境变量配置在 Settings – Secrets and Variables – Actions 里面,配置后，可以在 actions 里面通过 $ secrets.dingtalk_secret 调用到对应的数据 文章更新时间问题使用 Github Actions 造成的文章更新时间问题参考原文： https://mrseawave.github.io/blogs/articles/2021/01/07/ci-hexo-update-time/ 当使用 Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。对于 Github Actions 可以使用命令在构建之前进行处理 jobs: deploy_gh_pages: steps: - name: Restore file modification time run: | git ls-files -z | while read -d path; do touch -d $(git log -1 --format=@%ct $path) $path; done 如果 git 命令不好用， 也可以使用 find 命令 find source/_posts -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果 github actions 中使用 actionscheckout@v2，请设定它的参数 fetch-depth: 0，因为 0 表示获取所有分支和标签的所有历史记录。默认值为 1 gitignore在 Git 仓库的根目录下编辑有.gitignore 文件，该文件中定义了一些不需要上传至 GitHub 的内容，列在该文件中的文件或文件夹将会被忽略，不在上传 Hexo 忽略文件.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_multiconfig.yml Obsidian 忽略文件.obsidian/workspace .obsidian 文件本身是可以同步的，当前存储库的插件以及相关的配置都会下载在这个文件夹中，因此将其同步到 git 记录中也是非常有用的，假如切换设备就不需要重新为当前的存储库重新配置 Obsidian 了。 GitHub 仓库部署源码仓库部署 创建一个私有仓库，此处创建一个 BlogDeploy 仓库，仓库拉取到本地后，在仓库中部署 Hexo使用 创建 gitignore 文件，排除 Hexo 不用上传的文件 同步仓库到远端 发布仓库部署 创建一个 GitHub 仓库，仓库必须取名为”GitHub 用户名.github.io” 仓库需要创建为公有仓库，即 public 创建一个分支，分支名为 ImageBed，用于做图床上传 获取 Token，选择用户 Settings-Developer settings-Personal access tokens，token 的权限获取，勾上 workflow 即可 图床分支创建用于存储图片，图床分支的相关信息部署完成后，需要在 PicGo 中进行配置 git checkout -b my-test //在当前分支下创建my-test的本地分支分支git push origin my-test //将my-test分支推送到远程git branch --set-upstream-to=origin/my-test //将本地分支my-test关联到远程分支my-test上 git branch -a //查看远程分支 Hexo 部署Hexo 是一个基于 Node.js 的静态网站生成器，主要用于快速、简单地搭建个人博客或静态网站。它采用 Markdown 格式来撰写内容，并提供了丰富的主题和插件生态系统，可以轻松扩展和定制网站功能和外观。 适用于个人博客、项目文档、个人简历等各种静态网站的搭建和管理。 目录架构_config.yml #网站的配置信息package.json #应用程序的信息scaffolds #模版文件夹source #存放用户资源，Markdown 文档\t_drafts\t_poststhemes #主题文件夹public #网站文件 Hexo 使用使用流程 安装 hexosudo npm install -g hexo-cli 查看版本，确认安装成功 hexo -v 创建一个新文件夹 Hexo，并初始化该文件夹 hexo init Hexo 清除缓存 hexo clean 生成静态文件 hexo g 开启本地服务器并修改端口为 80hexo s -p 9050 常用命令 npm install -g hexo-cli #安装Hexo npm update hexo -g #升级 hexo init #初始化博客 命令简写 hexo n 的博客hexo new 的博客 #新建文章 hexo ghexo generate #生成 hexo shexo server #启动服务预览 hexo dhexo deploy #部署 hexo server #Hexo会监视文件变动并自动更新，无须重启服务器 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令端口修改 node_modules\\hexo-server\\index.js 临时启动 hexo s -p 9050 hexo generate 将 Hexo 源码目录中已有的源码编译生成为静态网页文件，生成以下： db.json 文件：编译过程中产生的中间文件，不用关心； public 文件夹：新生成的静态网页文件就存放在这个目录下。 hexo deploy 将静态网页文件推送到 GitHub Pages Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容 快捷编辑配置文件站点配置文件和主题配置文件是 DIY 博客经常要编辑的两个文件，在 Obsidian 中没法编辑 yml 文件，可以通过 URL 来打开 yml 文件，会自动调用默认的编辑器打开。创建一个专门用于编辑配置的文件，写入两个配置文件所在的相对路径： [打开站点配置文件](Blog/_config.yml)[打开主题配置文件](Blog/themes/stellar/_config.yml)# 或者通过osidian插件shellcommands打开.开头的隐藏文件[Github 同步忽略文件配置](obsidian://shell-commands/?vault=BlogDeployexecute=f4b02rlcvr) 站点配置文件在 blog 根目录里的 _config.yml 文件称为站点配置文件 主题修改:theme 网站标题:title 副标题:subtitle 网站描述:description 作者:author 网站头像外部链接:avatar 网站语言:language:zh-Hans 时区:timezone:AsiaShanghai 自定义域名：url: 忽略文件： skip_render: # 排除一些obsidian编辑器的文件和一些脚本/模板文件 - _posts/.obsidian/* - _posts/Scripts/* - _posts/Templates/* 主题配置文件使用的主题：stellar 或者 Next，二选其一 进入根目录 themes 文件夹，里面有个 _config.yml 文件，为主题配置文件 社交外链的设置，即在侧栏展示的个人社交网站信息。(插件 jiathis) 插入网易云，进入网页版的网易云音乐，选择喜欢的音乐，点击生成外链播放器，在侧栏插入这首歌的音乐播放器，修改 blog/themes/next/layout/_macro 的 sidebar.swig 文件，添加刚刚复制的外链代码 设置背景，在 blog/themes/next/source/css/_custom 文件的 custom.styl 首部添加 body background:url(./background.jpg); background-attachment: fixed; ，fixed 固定背景图片 增加侧栏菜单条目，默认的侧栏菜单条目有：首页、归档、标签、关于、搜索等。如果想要增加其他的菜单条目，修改主题配置文件 _config.yml 里的 Menu Settings 中的 menu 和 menu_icons 两个地方 域名配置文件进入 blog/source 目录下，创建一个文件，文件名 CNAME，写入的自定义域名 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 扩展：abbrlink文章永久链接 category并列分类，了解一下： categories: - [Linux] - [Tools]并列+子分类，再了解一下： categories: - [Linux, Hexo] - [Tools, PHP] 自定义文章标签生成标签页面 hexo new page tags，修改 blogsourcetagsindex.md，添加 type: “tags” title: tagsdate: 2023-01-08 11:27:57type: tags 以后就可以在文章文件头添加标签了，如下 title: Hexo + GitHub 搭建个人博客date: 2023-01-07 13:15:00tags:- Hexo- Next- 博客 手动生成和添加是十分繁琐的，后续利用插件形式按照目录格式为文章自动生成标签。 部署插件 hexo-deployer-git 编辑 Hexo 顶层目录下的 _config.yml 文件，文件最后可以看到 deployment 相关内容 deploy： type: git repo: git@github.com:liuluhua/liuluhua.github.io.git branch: main repo 填写仓库 ssh 地址 branch 的填写需要和 GitHub Pages部分指定的Branch保持一致 搜索插件 hexo-generator-searchdbstellar 自带了搜索插件，故未配置该插件 安装 hexo-generator-searchdbnpm install hexo-generator-searchdb 修改主题配置文件 local_search:\tenable: true 自动标签插件 hexo-auto-category该插件在 Hexo 进行 build 的时候会去自动根据文章目录情况来自动修改文章的 categories 信息 安装插件 npm install hexo-auto-category --save 修改站点配置文件 _config.yml，使文章链接清晰 # Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the max_depth of directory-tree you want to generate, should 0# multiple: multiple category hierarchiesauto_category: enable: true multiple: true depth: 5# 修改 permalink 让的文章链接更加友好，并且有益于 SEO permalink: :year/:month/:hash.html# 规定的新文章在 _post 目录下是以 cateory new_post_name: :category/:title| 该插件需要每次手动构建执行 hexo g 时才会更新 categories 信息。 仓库部署在本地，上传时使用 git hook，在每次执行 commit 前都自动运行 npx hexo generate 触发自动生成 categories 的行为，并将生成后的变更自动添加到本次提交中，然后一同 push 到 github 上去。这里可以使用 husky 来很方便的设置这样一个 git hook 1. 安装 huksy：npm install husky --save-dev 2. 执行 huksy 初始化指令：npx husky install *3. 在 package.json 中的 scripts 中写入：prepare: husky install 4. 在生成的 .husky 目录创建 pre-commit 文件（chmod a+x pre-commit），并写入以下内容，之后提交代码时，检查有无 categories 的生成信息。 #!/usr/bin/env sh . $(dirname -- $0)/_/husky.sh npx hexo generate git add . 仓库部署在 GitHub 时直接利用 GitHub Actions 自动生成 站点地图 hexo-generator-sitemap修改主题配置文件 menu: sitemap: /sitemap.xml || fa fa-sitemap 执行 hexo cl hexo g 生成 sitemap.xml 此时可以在 blog/public 文件夹下看到 sitemap.xml 验证，进入 Google Search Console ，选择网址前缀，输入网址时记得加上 https:，选择 HTML 标记，会得到元标记 meta name=google-site-verification content=xxxxxxxx /，将 content 后的内容加入到主题配置文件中 google_site_verification: xxxxxxxx，执行 hexo cl hexo g hexo d 点击前往资源页面，添加站点地图，成功提交 静态资源压缩 hexo-neat主题配置文件添加配置 neat_enable: trueneat_html: enable: true exclude:neat_css: enable: true exclude: - **/*.min.cssneat_js: enable: true mangle: true output: compress: exclude: - **/*.min.js 字数统计 hexo-word-counter评论系统 utterancUtterances 是一个基于 Github Issues 的轻量级评论系统，主页地址 http://utteranc.es Hexo Stellar 主题的配置文件如下： ######## Comments ########comments: service: utterances # beaudar, utterances, giscus, twikoo, waline, artalk comment_title: 快来参与讨论吧~ # utterances # https://utteranc.es/ utterances: repo: liuluhua/liuluhua.github.io issue-term: title issue-number: theme: preferred-color-scheme label: 💬 其他使用情况下，在网页需要插入 Utterances 评论的位置，粘贴以下代码（username，reponame 分别修改为 GitHub 用户名，仓库名）。 script src=https://utteranc.es/client.js repo=username/reponame issue-term=pathname theme=github-light crossorigin=anonymous async/script 设置字体霞鹜文楷字库 GitHub 地址： https://github.com/lxgw/LxgwWenKai 更改站点配置文件，增加如下字段 inject: head: link rel=stylesheet href=https://cdn.jsdelivr.net/gh/satouriko/LxgwWenKai_Webfonts@v1.101/dist/LXGWWenKaiMono-Bold.css / 更改主题配置文件，找到 style 字段在 font-family 中增加字体名称： style: font-family: logo: LXGWWenKaiMono body: LXGWWenKaiMono code: LXGWWenKaiMono codeblock: LXGWWenKaiMono Canvas nest 背景动画 在 blog/source/_data 文件夹下新建 footer.njk 并编辑 script color=0,255,255 opacity=1 zIndex=-1 count=70 src=https://cdn.staticfile.org/canvas-nest.js/1.0.1/canvas-nest.js/script 修改主题配置文件 custom_file_path: footer: source/_data/footer.njk stellar 主题中直接添加在主题配置文件 _config.yml footer 的 content 中 设置背景音乐在 stellar 主题的 _data/widgets.yml 文件中找到 welcome 字段，在其中的 content 部分添加： welcome: layout: markdown title: 哈喽~ 旅人： content: |iframe frameborder=no border=0 marginwidth=0 marginheight=0 width=224 height=86 src=//music.163.com/outchain/player?type=2id=512983678auto=1height=66/iframe 百度数据分析进入 https://tongji.baidu.com/ 申请账号后，输入网址获取统计代码，之后在 stellar 主题的配置文件 _config.yml 的扩展插件部分插入以下代码： baiduanalytics: enable: true # 使能百度分析接口 inject: | ...扩展插件代码 MathJax 安装 hexo-filter-mathjax 修改主题配置文件 math: mathjax: enable: true 此后可在文章文件开头添加参数 mathjax: true 以使用 MathJax CDN 修改主题配置文件 vendors: plugins: custom custom_cdn_url: https://cdn.staticfile.org/$cdnjs_name/$version/$cdnjs_file 运行时间next 主题在 /blog/themes/next/layout/_partials/footer.njk 中添加 stellar 主题在主题配置文件 _config.yml 中找到 footer: 中的 content: |，在其后添加 div span id=timeDate载入天数.../span span id=times载入时分秒.../span/divscript var now = new Date(); function createtime() var grt= new Date(05/20/2024 05:20:00);//此处修改的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )hnum = 0 + hnum; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )mnum = 0 + mnum; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )snum = 0 + snum; document.getElementById(timeDate).innerHTML = 本站已安全运行 +dnum+ 天 ; document.getElementById(times).innerHTML = hnum + 小时 + mnum + 分 + snum + 秒; setInterval(createtime(),250);/script 文章页眉显示标签用于 next 主题 在 blog/source/_data 文件夹下新建 post-meta.njk 并编辑 span class=post-meta-item %- if post.tags and post.tags.length % %- set tag_indicate = i class=fa fa-tag/i if theme.tag_icon else # % span class=post-tags %- for tag in post.tags.toArray() % a href= url_for(tag.path) rel=tag tag_indicate tag.name /a %- endfor % /span %- endif %/span 修改主题配置文件 custom_file_path: postMeta: source/_data/post-meta.njk 评论系统 Waline Waline评论系统的配置 前往 Waline 官网 根据指引到 Vercel 进行 Waline 服务端部署 安装 @walinehexo-nextnpm install @waline/hexo-next 为了不使用魔法也能正常评论，需要有自己的域名解析到 Waline 服务端，可以在域名控制台给自己的博客域名添加二级域名，添加 CNAME 解析到 cname-china.vercel-dns.com 或添加 A 解析到 76.223.126.88（也可以前往 Vercel All IP 自行挑选合适的节点），接着进入 Vercel 的 Waline 应用的控制台，在 Settings-Domains 里添加上文提到的二级域名，这样在主题配置文件添加配置后就可以正常评论了 主题配置文件添加配置 配置完评论后及时到 Waline 服务端登录，以便管理评论 可选择开启评论邮件提醒功能， Waline 官网 有详细的说明 阅读量统计用于 next 主题 Leancloud（https://console.leancloud.cn/） 创建应用，进入该应用的 设置-应用凭证，找到 AppID 和 AppKey，记录下来后面配置要用 配置 _config.yml 启用网页访问统计，配置 leancloud 的 app_id 和 app_key，打开计数功能，统计来源改为 leancloud #网页访问统计#Analysis of website visitorsweb analytics:\tenable:trueleancloud:\tapp id: app key: # 浏览量计数# Number of visitsviews:\tenable:true\t#统计数据来源\t#Data Source\t#Options:busuanzi | leancloud\tsource:leancloud\tformat:次 PV、UV 统计数用于 next 主题显示页面的访问量和访客数量 # 展示网站的 pv、w 统计数# Display website pv and uv statisticsstatistics:\tenable:true\t#统计数据来源，使用leancloud 需要设置web analytics:leancloud中的参数;busuanzi 显示统计数据很大属于正常现象，部署后会正常\t# Data source.If use leancloud,you need to set the parameter inweb analytics:leancloud\t# Options:busuanzian | leancloud\tsource:leancloud\t#页面显示的文本，是数字的占位符(必须包含)，下同\t# Displayed text, is a placeholder for numbers (must be included), the same below\tpv format:总访问量 次\tuv format:总访客数 人 词句 APIp id=hitokotoa href=# id=hitokoto_text:D 获取中.../a/pscriptfetch(https://v1.hitokoto.cn).then(response = response.json()).then(data = const hitokoto = document.querySelector(#hitokoto_text)hitokoto.href = `https://hitokoto.cn/?uuid=$data.uuid`hitokoto.innerText = data.hitokoto).catch(console.error)/script","categories":["1.平台","服务器","博客"]},{"title":"Python返回前端请求IP地址","path":"/2024/04/17/1-平台-服务器-微信-Python返回前端请求IP地址/","content":"前端 js 代码script\tfetch(/get_ip, method: GET,headers: Content-Type: application/json,) .then(response = response.text()) .then(data = document.getElementById(ip_addr).innerHTML=data)/script","categories":["1.平台","服务器","微信"]},{"title":"微信公众号后端配置","path":"/2024/04/16/1-平台-服务器-微信-微信公众号后端配置/","content":"后端服务代码from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonapp = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[http://124.222.246.202,http://127.0.0.1])#CORS(app)HOME_PATH = /home/ubuntu/lemonadeWebSite/html/#@app.route(/, methods=[GET])#def home_index():# index_html = open(/home/ubuntu/liuluhua.github.io/index.html, r)# print (文件名: , index_html.name)# print (是否已关闭 : , index_html.closed)# print (访问模式 : , index_html.mode)# return index_html.read()@app.route(/get_ip, methods=[GET])def ip_addr(): ip_addr = request.remote_addr api_url = fhttps://ipinfo.io/ip_addr/json response = requests.get(api_url) data = response.json() ret_data = 来自+data.get(country)+ +data.get(region)+的+data.get(ip)+朋友; return ret_data@app.route(/get_picture, methods=[GET])def picture_show(): pic_dir = 0.res/Picture/ name = request.args.get(id) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = for file_name in os.listdir(act_addr): fileNameList += fimg src=pic_dirname/file_name alt=file_name print(file_name) print (fileNameList) return (fileNameList)@app.route(/getFileContent, methods=[POST])def getFileContent(): filePath = request.get_json().get(filePos) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(/getFileList, methods=[POST])def getFileList(): return json.dumps(request.get_json()) + getDirList(HOME_PATH+Python);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(fdivdir:depth name:) ret_list.append(entry.name+/div) getDirList(entry.path, ret_list, depth+1) else: file_pos = dir_path.replace(/home/ubuntu/html,) ret_list.append(fpa onclick=openFile(\\file_pos/entry.name\\)file:depth name: + entry.name+/a/p) return .join(ret_list)@app.route(/signin, methods=[POST])def signin(): print(post signin) username = request.form.get(username) password = request.form.get(password) button_clicked = request.form.get(signin) # 或者使用 signup #jsonify(response: test) # 确定哪个按钮被点击了 if button_clicked == signin: # 处理登录操作 return fLogin: Username=username, Password=password elif button_clicked == signup: # 处理注册操作 return fSignup: Username=username, Password=password else: # 没有按钮被点击或者未知按钮名称 return Unknown button pressed@app.route(/wechat, methods=[GET])def wechat_signature(): data = request.args echostr = data.get(echostr) signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) if not signature or not timestamp or not nonce: return False tmp_str = .join(sorted([liuluhua, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(UTF-8)).hexdigest() if tmp_str == signature: return echostr else: print(Failed) return Failed@app.route(/wechat, methods=[POST])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是不是文本 if text == req.get(MsgType): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = ToUserName:req.get(FromUserName), FromUserName:req.get(ToUserName), CreateTime:int(time.time()), MsgType:text, Content:req.get(Content) # 把构造的字典转换成xml格式 xml = xmltodict.unparse(xml:resp) # print(req.get(Content)) # 返回数据 return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml:resp) return xmlif __name__ == __main__: app.run(host=127.0.0.1, port=9080) Nginx 配置# Default server configuration#server listen 80 default_server; listen [::]:80 default_server; # SSL configuration # # listen 443 ssl default_server; # listen [::]:443 ssl default_server; # # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 # # Read up on ssl_ciphers to ensure a secure configuration. # See: https://bugs.debian.org/765782 # # Self signed certs generated by the ssl-cert package # Dont use them in a production server! # # include snippets/snakeoil.conf; root ~/lemonadeWebSite/html; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; #server_name _; location / # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; #proxy_pass http://localhost:9999; # proxy_http_version 1.1; # proxy_set_header Upgrade $http_upgrade; # proxy_set_header Connection upgrade; # proxy_set_header Host $host; # proxy_cache_bypass $http_upgrade; location ~ ^/(wechat|get_*|signin) proxy_pass http://localhost:9999; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ # include snippets/fastcgi-php.conf; # # # With php7.0-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php7.0-fpm: # fastcgi_pass unix:/run/php/php7.0-fpm.sock; # # deny access to .htaccess files, if Apaches document root # concurs with nginxs one # #location ~ /\\.ht # deny all; ## Virtual Host configuration for example.com## You can move that to a different file under sites-available/ and symlink that# to sites-enabled/ to enable it.##server # listen 80;# listen [::]:80;## server_name example.com;## root /var/www/example.com;# index index.html;## location / # try_files $uri $uri/ =404;# #","categories":["1.平台","服务器","微信"]},{"title":"大小端字节序和位序","path":"/2024/04/15/2-语言-C语言-位运算-大小端字节序和位序/","content":"大小端的数据反向例：一个 32 位 unsigned long 数据类型的反向 unsigned long wrd;wrd = ((wrd0xFF000000)24)|((wrd0x00FF0000)8)|((wrd0x0000FF00)8)|((wrd0x000000FF)24); 对 wrd 变量中的 32 位整数进行字节反转，即将字节顺序从大端格式（big-endian）转换为小端格式（little-endian），或反之。具体来说，这段代码将 wrd 中的 4 个字节的位置互换。 ((wrd0xFF000000)24) 提取 wrd 的最高字节（第 1 个字节），并右移 24 位，将其移到最低字节位置。 ((wrd0x00FF0000)8) 提取 wrd 的第 2 个字节，并右移 8 位，将其移到倒数第 2 个字节位置。 ((wrd0x0000FF00)8) 提取 wrd 的第 3 个字节，并左移 8 位，将其移到第 2 个字节位置。 ((wrd0x000000FF)24) 提取 wrd 的最低字节（第 4 个字节），并左移 24 位，将其移到最高字节位置。 最后，通过按位或运算 (|) 将这些位组合成新的 32 位整数，从而实现字节顺序的完全反转。例如，将 0x12345678 变为 0x78563412。 按位逆序unsigned long wrd;wrd = (((wrd0xaaaaaaaa)1)|((wrd0x55555555)1));wrd = (((wrd0xcccccccc)2)|((wrd0x33333333)2));wrd = (((wrd0xf0f0f0f0)4)|((wrd0x0f0f0f0f)4));wrd = (((wrd0xff00ff00)8)|((wrd0x00ff00ff)8));return ((wrd16) | (wrd16)); 将 wrd 变量中的 32 位整数按位进行反转（即将二进制的最高位与最低位交换，次高位与次低位交换，以此类推），实现32 位整数的比特翻转。 代码的实现分多个步骤，逐步实现位的反转： wrd = (((wrd0xaaaaaaaa)1)|((wrd0x55555555)1)); 将 wrd 的相邻两位互换（奇数位与偶数位互换）。 wrd = (((wrd0xcccccccc)2)|((wrd0x33333333)2)); 将 wrd 的每 2 位组内的位互换。 wrd = (((wrd0xf0f0f0f0)4)|((wrd0x0f0f0f0f)4)); 将 wrd 的每 4 位组内的位互换。 wrd = (((wrd0xff00ff00)8)|((wrd0x00ff00ff)8)); 将 wrd 的每 8 位组内的位互换。 return ((wrd16) | (wrd16)); 将 wrd 的高 16 位和低 16 位交换。 最终结果是 wrd 中的 32 位被完全按位反转，如将 0x12345678 变为 0x1E6A2C48。 大小端字节序大端字节序（Big-Endian）和小端字节序（Little-Endian）是两种不同的字节存储顺序方式，用于在多字节数据类型（如整数、浮点数）在内存中的表示。不管是 Motorla 模式还是 Intel 模式，只有数据存在跨字节存储的时候，才会有所区别，单个字节数据两者无差异。大端模式（motolora）下，数据的处理方式和平常手写的顺序相同。 信号的起始位就是信号的最低位。 LSB：least significant byte(某个信号的最低字节) MSB：most significant byte(某个信号的最⾼字节) lsb：least significant bit(某个信号中某个字节的最低有效位) msb：most significant bit(某个信号中某个字节的最⾼有效位) 大端字节序 大端模式也称 Motorla 模式，存储数据的格式为高字节（最高有效字节）保存在低的存储地址，而低字节（最低有效字节）保存在高的存储地址。 数据的高位字节存储在低地址位置，低位字节存储在高地址位置。例如，整数值 0x12345678 在大端字节序中的存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 小端字节序小端模式也称 Intel 模式，存储数据的格式为低字节保存在较低的存储地址，而高字节保存在高的存储地址。 数据的低位字节存储在低地址位置，高位字节存储在高地址位置。使用同样的示例值 0x12345678，小端字节序的存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 扩展数据在存储器中的存放顺序位序 z 字节中位序 - 升序：lsb 在一个 Byte 的最右边，msb 在一个 Byte 的最左边： Byte：b7-b6-b5-b4-b3-b2-b1-b0 字节中位序 - 降序：lsb 在一个 Byte 的最左边，msb 在一个 Byte 的最右边： Byte：b0-b1-b2-b3-b4-b5-b6-b7 字节序 小端存储： 对于大于一个字节的数据类型的数据，在存储器中，低字节存储在低地址，高字节存储在高地址； 大端存储： 对于大于一个字节的数据类型的数据，在存储器中，高字节存储在低地址，低字节存储在高地址； 变量如果直接在程序中使用一个 Uint16 的变量，不使用指针时，使用方式如下： 获取该变量的低字节：Uint8 Temp = (Uint8)(gusVar 0xFF) 获取该变量的高字节：Uint8 Temp = (Uint8)((gusVar 8) 0xFF) 将该变量赋给其他变量：Uint16 Temp = gusVar; 如果使用指针来获取存储在 0 和 1 地址的值”0x5A5”，分为以下情况： 存储方式是大端，0 地址放 0x05，1 地址放 0xA5: 存储方式是小端，0 地址放 0xA5，1 地址放 0x05; 存放顺序数据在报文中的存放顺序依赖于字节序和字节中的位序排序方式，一般情况下： 字节序：Byte0、Byte1、Byte2、Byte3、Byte4、Byte5、Byte6、Byte7 位序：bit7、bit6、bit5、bit4、bit3、bit2、bit1、bit0 Motorola_LSB 和 Motorola_MSB 的区别是某个信号起始位置确定的情况下，在报文中的映射空间不一样，映射顺序一样(低字节放在高字节，高字节放在低地址，位序都是从右到左是 b0 到 b7)。 Intel(小端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte1 = (gstrMsg.Byte1 0x0F) | ((Uint8)(gusVal 0x0F) 4); gstrMsg.Byte2 = (gstrMsg.Byte2 0xF0) | ((Uint8)(gusVal 0xF0) 4); gstrMsg.Byte2 = (gstrMsg.Byte2 0x0F) | ((Uint8)((gusVal 8) 0x0F)); Motorola_LSB(大端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte0 = (Uint8)((gusVal 4) 0xFF);gstrMsg.Byte1 = (gstrMsg.Byte1 0x0F) | ((Uint8)(gusVal 4)); Motorola_MSB(大端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte1 = (gstrMsg.Byte1 0xE0) | ((Uint8)((gusVal 7) 0x1F));gstrMsg.Byte2 = (gstrMsg.Byte2 0xFE) | ((Uint8)(gusVal 0x7F)); 传输顺序 字节顺序：先传 Byte0，最后传 Byte7； 字节内位序：先传 bit7，最后传 bit0； 64 位和 32 位的不同64 位和 32 位的大小端情况是类似的，但存在一些细微差异。在 64 位系统中，数据被划分为 8 字节（64 位），而在 32 位系统中，数据被划分为 4 字节（32 位）。因此，字节的顺序和对齐方式在这两种情况下可能会有所不同。 例如，考虑一个 64 位整数值 0x1122334455667788。在大端字节序中，存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 而在小端字节序中，存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x88 0x77 0x66 0x55 0x44 0x33 0x22 0x11 比较整数值 0x12345678 在 64 位和 32 位系统上，以大端字节序和小端字节序存储的示例： 64 位系统大端字节序： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x12 0x34 0x56 0x78 0x00 0x00 0x00 0x00 64 位系统小端字节序： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x00 0x00 0x00 0x00 0x78 0x56 0x34 0x12 32 位系统大端字节序： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 32 位系统小端字节序： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 影响字节序的选择对于不同的计算机体系结构和通信协议至关重要。它主要影响以下方面： 数据传输：在网络通信和数据交换中，如果通信双方使用不同的字节序，就需要进行字节序的转换，以确保正确解释和传输数据。 文件格式：某些文件格式（如图像、音频、视频）可能使用特定的字节序来存储数据，因此读取和解析这些文件时需要考虑字节序。 处理器架构：不同的处理器架构可能采用不同的字节序。例如，x86 架构使用小端字节序，而 PowerPC 架构使用大端字节序。在开发软件时，需要根据目标处理器架构的字节序选择适当的数据处理方式。 正确地处理字节序是确保跨平台兼容性和数据一致性的重要方面，特别是在网络通信和数据交换的情况下。 校验方法int main() unsigned int num = 0x01020304; unsigned char *ptr = (unsigned char*)num; if (*ptr == 0x01) printf(大端字节序 ); else printf(小端字节序 ); return 0;//联合体int checkCPU()\tunion w int a; char b;\tc;\tc.a = 1;\treturn(c.b==1)","categories":["2.语言","C语言","位运算"]},{"title":"Matlab静态代码转换为动态加载","path":"/2024/04/12/2-语言-Matlab-Matlab静态代码转换为动态加载/","content":"1. 将 MATLAB 转换为 CC++ 代码在将 MATLAB 代码转换为 C 或 C++ 代码时，通常使用 MATLAB 的 MATLAB Coder 工具。这个工具可以将 MATLAB 函数、脚本、甚至整个项目转换为相应的 C 或 C++ 代码。具体步骤如下： 打开 MATLAB 环境并加载要转换的脚本或函数。 在命令窗口中输入 codegen 命令，后面跟上想要转换的函数名。例如：codegen myFunction -args 0，其中 myFunction 是的 MATLAB 函数名，-args 后面的参数是函数的输入类型。 MATLAB 将生成一个以 CC++ 语言编写的代码副本，输出到当前工作目录下。 2. 在文件中执行 Makefile執行 Makefile 的过程就是通过该文件控制编译流程。以下是用来交叉编译代码的 Makefile 示例： CC:= arm-none-linux-gnueabi-gccOBJS:=$(patsubst %.c, %.o, $(wildcard *.c))PRO_NAME:= libmatlab.so$(PRO_NAME):$(OBJS)\t$(CC) -shared -o $(PRO_NAME) $(OBJS)%.o:%.c\t$(CC) -c -Wall -I. -o $@ $\tclean:\trm -rf *.o $(PRO_NAME) CC 变量指定了交叉编译器（在这个例子中是 arm-none-linux-gnueabi-gcc），该编译器用于编译适用于 ARM 架构的代码。 OBJS 自动生成当前目录下所有 C 源文件的目标文件列表，省去了手动维护对象文件列表的烦恼。 PRO_NAME 是所生成的共享库的名称 libmatlab.so。 此 Makefile 定义了生成共享库的规则：在 $(PRO_NAME) 依赖的目标文件构建成功后，链接成最终的共享库。 3. 执行 make，生成动态库文件在命令行中执行 make 命令，这将触发 Makefile 的默认目标。在的终端中输入： make 如果一切顺利，系统将按照 Makefile 中定义的规则进行编译并生成 libmatlab.so 文件。这一步骤会将所有的 C 源文件编译成对象文件，并链接成一个共享库。 4. 将动态库文件添加到开发板上的 /opt 目录下将生成的 libmatlab.so 库文件复制到开发板的 /opt 目录下，可以通过以下命令实现： scp libmatlab.so user@your_board_ip:/opt 请确保替换 user 和 your_board_ip 为实际的用户名和开发板的 IP 地址。复制完成后，的开发板将在 /opt 目录中找到这个动态库。 在软件项目的 .pro 文件中的 LIBS 选项中，添加以下内容，以便编译器能够找到并链接到 libmatlab.so： -L./extlibrary/matlab -lmatlab -Wl,-rpath,/opt 其中： -L 指定库文件的路径。 -l 表示要链接的库名（去掉前面的 lib 和后面的 .so）。 -Wl,-rpath 指定运行时的库搜索路径。 5. 复制头文件和库文件最后，确保将 Matlab 编译生成的全部 CC++ 头文件，以及通过 Makefile 生成的库文件复制到项目的工程目录下。这可以通过简单的 cp 命令来完成，例如： cp /path/to/matlab/headers/*.h /path/to/your/project/include/cp /opt/libmatlab.so /path/to/your/project/lib/ 这一步确保在编译的项目时，编译器能够找到所有需要的头文件和库文件，使得编译过程顺利进行。","categories":["2.语言","Matlab"]},{"title":"从Matlab生成独立C语言代码","path":"/2024/04/11/2-语言-Matlab-从Matlab生成独立C语言代码/","content":"MATLAB CoderMATLAB Coder 是一个强大的工具，它可以从 MATLAB 代码生成独立的、可阅读且可移植的 CC++ 代码。这使得用户能够在各种不同的开发环境中使用其 MATLAB 开发的算法和功能，而无需完全依赖 MATLAB 环境。 MATLAB 算法转化为嵌入式 C 代码的实现要求 数据类型管理在将 MATLAB 算法转换为 C 代码之前，必须明确每个变量的数据类型。举例来说，在图像处理领域，像素值通常使用 8 位无符号整数 (uint8) 表示。这种表示方式确保了每个像素的值范围在 0 到 255 之间，使其非常适合于灰度图像的表征。类似地，在音频处理中，采样值通常使用 16 位有符号整数 (int16) 进行表示，以便覆盖 -32768 到 32767 的音频信号幅度。因此，在 C 代码中应显式定义这些数据类型，以优化内存使用。例如，相关变量的定义如下所示： uint8_t pixel_value; // 用于存储图像的像素值int16_t sample_value; // 用于存储音频的采样值 内存静态分配MATLAB 允许动态变化变量的大小，而这一特性在嵌入式系统中并不可行。为了确保代码在嵌入式设备上高效运行，应在编译时完成内存分配。例如，在处理一幅固定尺寸的图像时，可以事先定义一个数组以存储像素值，从而避免在运行时进行动态内存分配。这种做法提高了系统的稳定性和响应速度，提高了代码的可预测性，代码示例如下： uint8_t image[HEIGHT][WIDTH]; // 预定义图像的高度和宽度 降低计算复杂性和内存占用嵌入式软件设计者在将高层算法映射到有限资源的硬件时，必须降低算法的复杂性。这一过程通常包括优化算法逻辑，以减少其对 CPU 和内存的需求。一个常见的做法是采用固定点数学运算而非浮点运算，因为浮点运算通常需要显著更多的计算资源和内存空间。例如，在 C 代码中，可以使用整数来进行定点运算，以便提供更高的效率： #define FIXED_POINT_SHIFT 8int32_t fixed_point_value = (int32_t)(input_value * (1 FIXED_POINT_SHIFT)); // 定点表示 支持定点运算在嵌入式系统中，整个算法必须严格地定义为定点数据类型。这意味着任何浮点数运算都需转化为定点数运算。在 C 代码中，程序的数学运算必须通过左右移位操作来实现定点数的乘法和除法，示例如下： int32_t multiply_fixed_point(int32_t a, int32_t b) return (int32_t)((a * b) FIXED_POINT_SHIFT); // 定点乘法 适配嵌入式 MATLAB 功能 编写适用于嵌入式 MATLAB 的函数是实现高效算法的重要步骤。然而，在这过程中，必须注意并非所有的 MATLAB 工具箱函数都能在嵌入式 MATLAB 的子集环境中使用。工具箱函数可以被视作模板或示例，帮助用户在资源受限的计算和存储环境中实现类似的功能。例如，在某些实时系统中，复杂的图形界面工具箱函数可能不可用，用户可以借助简单的数学计算函数，确保核心算法得以顺利运行。考虑到资源限制，采用基础的数学函数，不仅能保持功能的实现，还能提高性能。 在嵌入式 MATLAB 编程的过程中，EMLMEX 工具的使用至关重要。它能够有效检测可能出现的所有语法错误。在每次编译时，EMLMEX 都会自动生成一份编译报告，报告中详细描述了发现的问题，并提供了涉及出错代码行在程序中的准确链接。例如，如果某行代码因拼写错误而未能通过编译，EMLMEX 将清楚地指出具体的行号和错误类型，使开发人员能够迅速进行调整。这样的高效机制显著提升了开发流程的便利性。 生成 CC++ 代码的步骤使用 MATLAB Coder 生成 CC++ 代码的过程分为以下三步： 准备 MATLAB 算法: 确保所要生成代码的 MATLAB 文件编写无误。函数需要以适合代码生成的格式书写，例如不使用不兼容的函数或特性。 检查 MATLAB 代码的兼容性: 有些 MATLAB 代码的语句并不能直接转换成 CC++ 代码。因此，进行兼容性检查是必要的，这样可以避免在后续步骤中出现错误。 生成源代码或 MEX 文件: 最终步骤是通过 MATLAB Coder 工具选择合适的输出类型生成 CC++ 代码或者 MEX 文件。 界面编写 MATLAB 文件: 创建一个名为 foo.m 的 MATLAB 文件，文件中包含了两个数相乘的功能，实现代码如下： function c = foo(a, b) %#codegen% 该函数用于计算参数 a 和 b 的乘积c = a * b; % 执行乘法操作 在此代码中，%#codegen 注解不仅是一个指示，它还用于告知编译器在进行代码生成时不要生成关于不兼容语法的警告。这样的设计使得在与 C 或 C++ 等语言交互时，可以确保保持良好的兼容性。 选择编译器: 打开 MATLAB 的命令窗口，输入并执行 mex -setup，接着将出现一系列已安装编译器的选项。在此步骤中，选择一个合适的编译器，比如 Microsoft Visual C++，以确保接下来的步骤能够顺利进行。 启动 MATLAB Coder: 在命令窗口中输入 coder 并按下回车键，此操作会弹出 MATLAB Coder Project 对话框，这为接下来的项目设置提供了一个友好的用户界面。 创建新项目: 在 “New” 选项卡的 Name 中填入项目名称 foo.prj，然后单击 OK 进入 MEX Function 对话框，开始设置项目的具体参数。 添加文件: 点击 Overview 选项卡中的 Add files，选择并打开先前创建的 foo.m 文件。这一操作确保了项目中有处理乘法所需的代码。 定义输入变量: 选中变量 a，然后选择 Define by Example…。在弹出的 MATLAB Expression 输入框中输入值 5，然后点击 OK。这一过程同样适用于变量 b，其输入值为 6。通过这种方式，定义输入变量能有效地帮助 MATLAB Coder 理解函数的运行环境。 设置输出类型: 在 Build 选项卡中，将 Output type 设置为 cc++ Static Library，并请确保勾选 Generate code only。这样设置意味着生成的代码将会编译成一个静态库形式，而不是一个可执行文件，有助于后续在其他语言中的调用。 更多设置: 点击 More settings，选择 General - Language 设置为 C++，在 Interface 选项中去掉所有选项，以确保生成的代码兼容性和简洁性，完成设置后点击 Close。 生成代码: 点击 Build 进行代码编译。在编译完成后的界面中，可以点击 View report 来查看生成的报告，其中详细列出变量 a、b 和 c 的信息。这一步骤对于检查代码的正确性和性能至关重要。 编写测试代码: 创建一个名为 test.cpp 的文件，在此文件中写入以下代码，以便于测试生成的功能： #include stdafx.h#include foo.h#include iostreamusing namespace std;int _tmain(int argc, _TCHAR* argv[]) double a = 0.0, b = 0.0, c = 0.0; cout Enter two numbers: ; cin a b; // 从标准输入读取用户输入的两个数 c = foo(a, b); // 调用生成的 foo 函数执行乘法运算 cout c = c endl; // 输出乘法结果 return 0; 命令行直接应用 EMLC 工具，用户可以将适用于嵌入式 MATLAB 的程序转换为 C 源代码。举例而言，用户可以通过如下命令将 adaptive-stats-roi.m 程序生成 C 代码： emlc adaptive-stats-roi.m -egIn-c -report 此处，-report 选项允许用户生成一份包含 C 源文件超链接的 HTML 报告，同时自动生成 MATLAB 函数所需的头文件。这种整合的方式使用户能够方便地将现有的 C 代码融入嵌入式 MATLAB 流程中。 对于已经开发的 C 函数库，开发者通常希望在程序中重复利用它们。嵌入式 MATLAB 提供了 C 程序接口程序 em1_ceval，允许用户在嵌入式 MATLAB 中调用外部 C 函数。举个例子，在 roi_stats.m 程序中，用户可以把调用 MATLAB 函数 mysort 替换为已存在的 C 函数 c_sort： Bool c_sort(float U[], int n, int m) // C function implementation for sorting 这种替换涉及到了 em1_ceval 函数的使用，它能够将输入和输出参数的数值或变量传递给 C 函数，从而实现功能的复用和效率的提升。示例代码如下： % Sort the sub-matrix onlysorted = em1_ceval(C_sort, em1_rref(V(1)), em1_wref(V(1)), count, int(numel(V)));","categories":["2.语言","Matlab"]},{"title":"Flask模块","path":"/2024/04/10/2-语言-Python-Flask模块/","content":"什么是 Flask？Flask 是一个用 Python 编写的轻量级 Web 框架。它以简单、灵活和可扩展著称，特别适合快速开发和原型设计。Flask 遵循 WSGI(Web Server Gateway Interface)标准，并使用 Jinja2 模板引擎。它的核心设计是最小化默认功能，同时允许通过插件和扩展轻松添加所需的功能。 Flask 的特点 轻量级：只提供基础的 Web 开发功能，没有强制性的项目结构。 模块化和可扩展性：通过扩展支持数据库 ORM（如 SQLAlchemy）、表单处理（如 WTForms）等功能。 简洁清晰：非常适合初学者，代码简单易读。 社区活跃：拥有大量文档、教程和第三方扩展支持。 学习 Flask 的关键路线1. 基础知识 Python 基础：掌握 Python 语法、函数、模块和包的使用。 HTTP 协议：了解 HTTP 的请求方法（GET、POST 等）、状态码、URL、请求头和响应头。 HTMLCSSJS：掌握基本的前端技术，用于构建用户界面。 2. Flask 核心概念 安装与快速开始： 使用 pip install flask 安装 Flask。 学习构建一个简单的 “Hello, World” 应用。 路由与视图函数： 学习使用 @app.route() 定义路由。 理解动态路由和 URL 变量。 模板引擎： 学习使用 Jinja2 模板引擎。 理解模板继承和动态渲染 HTML。 请求与响应： 使用 request 解析表单数据、查询参数和文件上传。 使用 Response 对象构建自定义响应。 静态文件： 学习如何提供 CSS、JS 和图片等静态文件。 表单处理： 学习如何处理 HTML 表单，初步了解 CSRF 保护。 3. 高级功能 **蓝图 (Blueprints)**： 理解模块化应用的构建方式。 通过蓝图拆分大项目，提高代码组织性。 数据库： 学习 Flask-SQLAlchemy 集成。 掌握基本的 CRUD 操作。 认证与授权： 使用 Flask-Login 实现用户登录和会话管理。 学习基于角色的权限控制。 错误处理： 自定义错误页面（如 404 和 500）。 中间件： 理解请求钩子（before_request、after_request）的作用。 API 开发： 使用 Flask 构建 RESTful API。 学习如何使用 Flask-RESTful 或 Flask-RESTX。 4. 部署与优化 部署： 使用 Gunicorn、uWSGI 等部署 Flask 应用。 使用 Docker 打包和部署 Flask 项目。 日志和调试： 配置日志记录。 学习调试工具（如 Flask-DebugToolbar）。 性能优化： 学习缓存机制（如 Flask-Caching）。 使用 CDN 提升静态资源加载速度。 5. 综合项目 构建一个完整的 Web 应用： 用户认证系统（注册、登录、注销）。 数据库操作（例如博客或留言板）。 前后端分离（如使用前端框架 Vue.js 或 React）。 6. 扩展阅读 Flask 官方文档：https://flask.palletsprojects.com/ 学习 Flask 扩展，如： Flask-Mail（邮件发送） Flask-Migrate（数据库迁移） Flask-SocketIO（实时通信） 通过以上学习路线，逐步掌握 Flask 的核心功能和常见扩展，可以高效开发自己的 Web 应用。","categories":["2.语言","Python"]},{"title":"OpenCV 图片相似度","path":"/2024/04/09/2-语言-Python-OpenCV-图片相似度/","content":"值哈希算法、差值哈希算法和感知哈希算法是用于图像相似性比较的重要工具。这三种算法的返回值都在 0 到 64 之间，数值越小，表明图像之间的相似度越高。其中，64 位的哈希值可以通过汉明距离进行比较，汉明距离表示两个二进制字符串之间不同的位数。具体来说，汉明距离为 0 代表两张图片完全相同，而值为 64 则表示它们之间差异最大。同时，三直方图和单通道直方图的返回值范围则是 0 到 1，值越大，同样代表着更高的相似度。 下面是相关算法的源代码，展示了如何通过 Python 和 OpenCV 进行图片哈希处理及相似度计算： import osimport cv2import numpy as npfrom PIL import Imageimport requestsfrom io import BytesIOimport matplotlibimport shutilimport concurrent.futuresimport itertoolsimport psutilimport timefrom queue import Queuematplotlib.use(TkAgg)import matplotlib.pyplot as pltdef aHash(img): # 均值哈希算法 # 缩放为8*8 img = cv2.resize(img, (8, 8)) # 转换为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # s为像素和初值为0，hash_str为hash值初值为 s = 0 hash_str = # 遍历累加求像素和 for i in range(8): for j in range(8): s = s + gray[i, j] # 求平均灰度 avg = s / 64 # 灰度大于平均值为1相反为0生成图片的hash值 for i in range(8): for j in range(8): if gray[i, j] avg: hash_str = hash_str + 1 else: hash_str = hash_str + 0 return hash_strdef dHash(img): # 差值哈希算法 # 缩放8*8 img = cv2.resize(img, (9, 8)) # 转换灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) hash_str = # 每行前一个像素大于后一个像素为1，相反为0，生成哈希 for i in range(8): for j in range(8): if gray[i, j] gray[i, j + 1]: hash_str = hash_str + 1 else: hash_str = hash_str + 0 return hash_strdef pHash(img): # 感知哈希算法 # 缩放32*32 img = cv2.resize(img, (32, 32)) # , interpolation=cv2.INTER_CUBIC # 转换为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 将灰度图转为浮点型，再进行dct变换 dct = cv2.dct(np.float32(gray)) # opencv实现的掩码操作 dct_roi = dct[0:8, 0:8] hash = [] avreage = np.mean(dct_roi) for i in range(dct_roi.shape[0]): for j in range(dct_roi.shape[1]): if dct_roi[i, j] avreage: hash.append(1) else: hash.append(0) return hashdef calculate(image1, image2): # 灰度直方图算法 # 计算单通道的直方图的相似值 hist1 = cv2.calcHist([image1], [0], None, [256], [0.0, 255.0]) hist2 = cv2.calcHist([image2], [0], None, [256], [0.0, 255.0]) # 计算直方图的重合度 degree = 0 for i in range(len(hist1)): if hist1[i] != hist2[i]: degree = degree + \\ (1 - abs(hist1[i] - hist2[i]) / max(hist1[i], hist2[i])) else: degree = degree + 1 degree = degree / len(hist1) return degreedef classify_hist_with_split(image1, image2, size=(256, 256)): # RGB每个通道的直方图相似度 # 将图像resize后，分离为RGB三个通道，再计算每个通道的相似值 image1 = cv2.resize(image1, size) image2 = cv2.resize(image2, size) sub_image1 = cv2.split(image1) sub_image2 = cv2.split(image2) sub_data = 0 for im1, im2 in zip(sub_image1, sub_image2): sub_data += calculate(im1, im2) sub_data = sub_data / 3 return sub_datadef cmpHash(hash1, hash2): # Hash值对比 # 算法中1和0顺序组合起来的即是图片的指纹hash。顺序不固定，但是比较的时候必须是相同的顺序。 # 对比两幅图的指纹，计算汉明距离，即两个64位的hash值有多少是不一样的，不同的位数越小，图片越相似 # 汉明距离：一组二进制数据变成另一组数据所需要的步骤，可以衡量两图的差异，汉明距离越小，则相似度越高。汉明距离为0，即两张图片完全一样 n = 0 # hash长度不同则返回-1代表传参出错 if len(hash1) != len(hash2): return -1 # 遍历判断 for i in range(len(hash1)): # 不相等则n计数+1，n最终为相似度 if hash1[i] != hash2[i]: n = n + 1 return ndef getImageByUrl(url): # 根据图片url 获取图片对象 html = requests.get(url, verify=False) image = Image.open(BytesIO(html.content)) return imagedef PILImageToCV(): # PIL Image转换成OpenCV格式 path = /Users/waldenz/Documents/Work/doc/TestImages/t3.png img = Image.open(path) plt.subplot(121) plt.imshow(img) print(isinstance(img, np.ndarray)) img = cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR) print(isinstance(img, np.ndarray)) plt.subplot(122) plt.imshow(img) plt.show()def CVImageToPIL(): # OpenCV图片转换为PIL image path = /Users/waldenz/Documents/Work/doc/TestImages/t3.png img = cv2.imread(path) # cv2.imshow(OpenCV,img) plt.subplot(121) plt.imshow(img) img2 = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) plt.subplot(122) plt.imshow(img2) plt.show()def bytes_to_cvimage(filebytes): # 图片字节流转换为cv image image = Image.open(filebytes) img = cv2.cvtColor(np.asarray(image), cv2.COLOR_RGB2BGR) return imgdef runAllImageSimilaryFun(para1, para2): # 均值、差值、感知哈希算法三种算法值越小，则越相似,相同图片值为0 # 三直方图算法和单通道的直方图 0-1之间，值越大，越相似。 相同图片为1 # t1,t2 14;19;10; 0.70;0.75 # t1,t3 39 33 18 0.58 0.49 # s1,s2 7 23 11 0.83 0.86 挺相似的图片 # c1,c2 11 29 17 0.30 0.31 # if para1.startswith(http): # # 根据链接下载图片，并转换为opencv格式 # img1 = getImageByUrl(para1) # img1 = cv2.cvtColor(np.asarray(img1), cv2.COLOR_RGB2BGR) # # img2 = getImageByUrl(para2) # img2 = cv2.cvtColor(np.asarray(img2), cv2.COLOR_RGB2BGR) # else: # 通过imread方法直接读取物理路径 img1 = cv2.imread(para1) img2 = cv2.imread(para2) # # 检查是否成功读取图像 # if img1 is None: # print(fError: Unable to read image para1.) # if img2 is None: # print(fError: Unable to read image para2.) hash1 = aHash(img1) hash2 = aHash(img2) n1 = cmpHash(hash1, hash2) # print(均值哈希算法相似度aHash：, n1) hash1 = dHash(img1) hash2 = dHash(img2) n2 = cmpHash(hash1, hash2) # print(差值哈希算法相似度dHash：, n2) hash1 = pHash(img1) hash2 = pHash(img2) n3 = cmpHash(hash1, hash2) # print(感知哈希算法相似度pHash：, n3) n4 = classify_hist_with_split(img1, img2) # print(三直方图算法相似度：, n4) n5 = calculate(img1, img2) # print(单通道的直方图, n5) # print(%d %d %d %.2f %.2f % (n1, n2, n3, round(n4[0], 2), n5[0])) # print(%.2f %.2f %.2f %.2f %.2f % (1 - float(n1 / 64), 1 - # float(n2 / 64), 1 - float(n3 / 64), round(n4[0], 2), n5[0])) if n1==0 or n2==0 or n3==0 or n4==1 or n5==1: # 构建目标文件路径 dest1 = os.path.join(destination_dir, os.path.basename(para1)) dest2 = os.path.join(destination_dir, os.path.basename(para2)) # 移动文件 shutil.move(para1, dest1) shutil.move(para2, dest2) print(均值哈希算法相似度aHash：, n1) print(差值哈希算法相似度dHash：, n2) print(感知哈希算法相似度pHash：, n3) print(三直方图算法相似度：, n4) print(单通道的直方图, n5) # plt.subplot(121) # plt.imshow(Image.fromarray(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))) # plt.subplot(122) # plt.imshow(Image.fromarray(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))) # plt.show()def monitor_memory_and_submit_tasks(queue, executor, destination_dir): while not queue.empty(): if psutil.virtual_memory().percent 90: p1, p2 = queue.get() executor.submit(runAllImageSimilaryFun, p1, p2) else: print(Memory usage above 90%, waiting...) time.sleep(1) # 等待1秒后再次检查内存使用情况if __name__ == __main__: source_dir = E:/00.Arch/Compare/WeiXin/ destination_dir = E:/00.Arch/Compare/ouput/ # 获取目录下所有图片文件路径 # image_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.endswith(.png)] image_files=[] for root, _, files in os.walk(source_dir): for file in files: if file.lower().endswith((.jpg)): image_files.append(os.path.join(root, file)) # 使用组合生成所有成对图片 image_combinations = list(itertools.combinations(image_files, 2)) # 使用队列存储任务 task_queue = Queue() for p1, p2 in image_combinations: task_queue.put((p1, p2)) # 使用线程池处理图像比对 with concurrent.futures.ThreadPoolExecutor() as executor: monitor_memory_and_submit_tasks(task_queue, executor, destination_dir) # p1 = E:/00.Arch/Compare/WeiXin/IMG_20230809_214702.jpg # p2 = E:/00.Arch/Compare/WeiXin/IMG_20230809_214714.jpg # destination_dir = E:/00.Arch/Compare/ouput/ # # 确保目标目录存在 # os.makedirs(destination_dir, exist_ok=True) # # # 检查文件是否存在 # if not os.path.exists(p1): # print(fError: File p1 does not exist.) # if not os.path.exists(p2): # print(fError: File p2 does not exist.) # runAllImageSimilaryFun(p1, p2) 测试时，多个图像被用来验证不同算法的准确度。其中五个值分别代表均值哈希算法、差值哈希算法、感知哈希算法、三直方图算法和单通道直方图的相似度。值得注意的是，具体的相似度结果将习惯性地在控制台输出，便于直观分析。","categories":["2.语言","Python"]},{"title":"pip下载网络问题","path":"/2024/04/08/2-语言-Python-pip下载网络问题/","content":"在使用 Python 安装包工具 pip 时经常会出现下载很慢的情况，这其中有很大一部分原因和 pip 的源有关，在安装 python 后，通常 python 解释器自带 pip 这个工具，但是这里 pip 是设置的默认源，也就是官方源：https://pypi.org/simple，这个源在国内的下载速度是很慢的，所以为了提高包的下载速度可以通过换源来实现。 临时使用参数可以在使用 pip 的时候加参数 -i https://pypi.tuna.tsinghua.edu.cn/simple pip install -i https://pypi.tuna.tsinghua.edu.cn/simple markdown 这样就会从清华这边的镜像去安装 markdown。 # 清华源pip install markdown -i https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip install markdown -i https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip install markdown -i http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip install markdown -i http://pypi.douban.com/simple/# 中国科学技术大学pip install markdown -i http://pypi.mirrors.ustc.edu.cn/simple/ 报错未添加信任源pip install beautifulsoup4 --trusted-host mirrors.aliyun.com 永久修改命令行# 清华源pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip config set global.index-url http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip config set global.index-url http://pypi.douban.com/simple/# 换回默认源pip config unset global.index-url 配置文件 Linux 下 ~/.pip/pip.conf Windows 下 %HOMEPATH%\\pip\\pip.ini内容如下： [global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 报错未添加信任源[install]trusted-host=pypi.douban.com","categories":["2.语言","Python"]},{"title":"Web部署","path":"/2024/04/05/2-语言-Python-Web部署/","content":"搭建开发环境首先，确认系统安装的 Python 版本是 3.7.x： $ python3 --versionPython 3.7.0 然后，用 pip 安装开发 Web App 需要的第三方库： 异步框架 aiohttp： $pip3 install aiohttp 前端模板引擎 jinja2： $ pip3 install jinja2 MySQL 5.x 数据库，从 官方网站 下载并安装，安装完毕后，请务必牢记 root 口令。为避免遗忘口令，建议直接把 root 口令设置为 password； MySQL 的 Python 异步驱动程序 aiomysql： $ pip3 install aiomysql 项目结构选择一个工作目录，然后，建立如下的目录结构： awesome-python3-webapp/ -- 根目录|+- backup/ -- 备份目录|+- conf/ -- 配置文件|+- dist/ -- 打包目录|+- www/ -- Web目录，存放.py文件| || +- static/ -- 存放静态文件| || +- templates/ -- 存放模板文件|+- ios/ -- 存放iOS App工程|+- LICENSE -- 代码LICENSE 创建好项目的目录结构后，建议同时建立 git 仓库并同步至 GitHub，保证代码修改的安全。 Web 骨架由于的 Web App 建立在 asyncio 的基础上，因此用 aiohttp 写一个基本的 app.py： import logging; logging.basicConfig(level=logging.INFO)import asyncio, os, json, timefrom datetime import datetimefrom aiohttp import webdef index(request): return web.Response(body=bh1Awesome/h1)@asyncio.coroutinedef init(loop): app = web.Application(loop=loop) app.router.add_route(GET, /, index) srv = yield from loop.create_server(app.make_handler(), 127.0.0.1, 9000) logging.info(server started at http://127.0.0.1:9000...) return srvloop = asyncio.get_event_loop()loop.run_until_complete(init(loop))loop.run_forever() 运行 python app.py，Web App 将在 9000 端口监听 HTTP 请求，并且对首页 / 进行响应： $ python3 app.pyINFO:root:server started at http://127.0.0.1:9000... 这里简单地返回一个 Awesome 字符串，在浏览器中可以看到效果 这说明的 Web App 骨架已经搭好了，可以进一步往里面添加更多的东西。 ORMORM 全称是：Object Relational Mapping(对象关系映射)，其主要作用是在编程中，把面向对象的概念跟数据库中表的概念对应起来。举例来说就是，定义一个对象，那就对应着一张表，这个对象的实例，就对应着表中的一条记录。 在一个 Web App 中，所有数据，包括用户信息、发布的日志、评论等，都存储在数据库中。在 awesome-python3-webapp 中，选择 MySQL 作为数据库。 Web App 里面有很多地方都要访问数据库。访问数据库需要创建数据库连接、游标对象，然后执行 SQL 语句，最后处理异常，清理资源。这些访问数据库的代码如果分散到各个函数中，势必无法维护，也不利于代码复用。 所以，要首先把常用的 SELECT、INSERT、UPDATE 和 DELETE 操作用函数封装起来。 由于 Web 框架使用了基于 asyncio 的 aiohttp，这是基于协程的异步模型。在协程中，不能调用普通的同步 IO 操作，因为所有用户都是由一个线程服务的，协程的执行速度必须非常快，才能处理大量用户的请求。而耗时的 IO 操作不能在协程中以同步的方式调用，否则，等待一个 IO 操作时，系统无法响应任何其他用户。 这就是异步编程的一个原则：一旦决定使用异步，则系统每一层都必须是异步，”开弓没有回头箭”。 幸运的是 aiomysql 为 MySQL 数据库提供了异步 IO 的驱动。 创建连接池需要创建一个全局的连接池，每个 HTTP 请求都可以从连接池中直接获取数据库连接。使用连接池的好处是不必频繁地打开和关闭数据库连接，而是能复用就尽量复用。 连接池由全局变量 __pool 存储，缺省情况下将编码设置为 utf8，自动提交事务： @asyncio.coroutinedef create_pool(loop, **kw): logging.info(create database connection pool...) global __pool __pool = yield from aiomysql.create_pool( host=kw.get(host, localhost), port=kw.get(port, 3306), user=kw[user], password=kw[password], db=kw[db], charset=kw.get(charset, utf8), autocommit=kw.get(autocommit, True), maxsize=kw.get(maxsize, 10), minsize=kw.get(minsize, 1), loop=loop ) Select要执行 SELECT 语句，用 select 函数执行，需要传入 SQL 语句和 SQL 参数： @asyncio.coroutinedef select(sql, args, size=None): log(sql, args) global __pool with (yield from __pool) as conn: cur = yield from conn.cursor(aiomysql.DictCursor) yield from cur.execute(sql.replace(?, %s), args or ()) if size: rs = yield from cur.fetchmany(size) else: rs = yield from cur.fetchall() yield from cur.close() logging.info(rows returned: %s % len(rs)) return rs SQL 语句的占位符是 ?，而 MySQL 的占位符是 %s，select() 函数在内部自动替换。注意要始终坚持使用带参数的 SQL，而不是自己拼接 SQL 字符串，这样可以防止 SQL 注入攻击。 注意到 yield from 将调用一个子协程（也就是在一个协程中调用另一个协程）并直接获得子协程的返回结果。 如果传入 size 参数，就通过 fetchmany() 获取最多指定数量的记录，否则，通过 fetchall() 获取所有记录。 Insert, Update, Delete要执行 INSERT、UPDATE、DELETE 语句，可以定义一个通用的 execute() 函数，因为这 3 种 SQL 的执行都需要相同的参数，以及返回一个整数表示影响的行数： @asyncio.coroutinedef execute(sql, args): log(sql) with (yield from __pool) as conn: try: cur = yield from conn.cursor() yield from cur.execute(sql.replace(?, %s), args) affected = cur.rowcount yield from cur.close() except BaseException as e: raise return affected execute() 函数和 select() 函数所不同的是，cursor 对象不返回结果集，而是通过 rowcount 返回结果数。 ORM有了基本的 select() 和 execute() 函数，就可以开始编写一个简单的 ORM 了。 设计 ORM 需要从上层调用者角度来设计。 先考虑如何定义一个 User 对象，然后把数据库表 users 和它关联起来。 from orm import Model, StringField, IntegerFieldclass User(Model): __table__ = users id = IntegerField(primary_key=True) name = StringField() 注意到定义在 User 类中的 __table__、id 和 name 是类的属性，不是实例的属性。所以，在类级别上定义的属性用来描述 User 对象和表的映射关系，而实例属性必须通过 __init__() 方法去初始化，所以两者互不干扰： # 创建实例:user = User(id=123, name=Michael)# 存入数据库:user.insert()# 查询所有User对象:users = User.findAll() 定义 Model首先要定义的是所有 ORM 映射的基类 Model： class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(rModel object has no attribute %s % key) def __setattr__(self, key, value): self[key] = value def getValue(self, key): return getattr(self, key, None) def getValueOrDefault(self, key): value = getattr(self, key, None) if value is None: field = self.__mappings__[key] if field.default is not None: value = field.default() if callable(field.default) else field.default logging.debug(using default value for %s: %s % (key, str(value))) setattr(self, key, value) return value Model 从 dict 继承，所以具备所有 dict 的功能，同时又实现了特殊方法 __getattr__() 和 __setattr__()，因此又可以像引用普通字段那样写： user[id]123 user.id123 以及 Field 和各种 Field 子类： class Field(object): def __init__(self, name, column_type, primary_key, default): self.name = name self.column_type = column_type self.primary_key = primary_key self.default = default def __str__(self): return %s, %s:%s % (self.__class__.__name__, self.column_type, self.name) 映射 varchar 的 StringField： class StringField(Field): def __init__(self, name=None, primary_key=False, default=None, ddl=varchar(100)): super().__init__(name, ddl, primary_key, default) 注意到 Model 只是一个基类，如何将具体的子类如 User 的映射信息读取出来呢？答案就是通过 metaclass：ModelMetaclass： class ModelMetaclass(type): def __new__(cls, name, bases, attrs): # 排除Model类本身: if name==Model: return type.__new__(cls, name, bases, attrs) # 获取table名称: tableName = attrs.get(__table__, None) or name logging.info(found model: %s (table: %s) % (name, tableName)) # 获取所有的Field和主键名: mappings = dict() fields = [] primaryKey = None for k, v in attrs.items(): if isinstance(v, Field): logging.info( found mapping: %s == %s % (k, v)) mappings[k] = v if v.primary_key: # 找到主键: if primaryKey: raise RuntimeError(Duplicate primary key for field: %s % k) primaryKey = k else: fields.append(k) if not primaryKey: raise RuntimeError(Primary key not found.) for k in mappings.keys(): attrs.pop(k) escaped_fields = list(map(lambda f: `%s` % f, fields)) attrs[__mappings__] = mappings # 保存属性和列的映射关系 attrs[__table__] = tableName attrs[__primary_key__] = primaryKey # 主键属性名 attrs[__fields__] = fields # 除主键外的属性名 # 构造默认的SELECT, INSERT, UPDATE和DELETE语句: attrs[__select__] = select `%s`, %s from `%s` % (primaryKey, , .join(escaped_fields), tableName) attrs[__insert__] = insert into `%s` (%s, `%s`) values (%s) % (tableName, , .join(escaped_fields), primaryKey, create_args_string(len(escaped_fields) + 1)) attrs[__update__] = update `%s` set %s where `%s`=? % (tableName, , .join(map(lambda f: `%s`=? % (mappings.get(f).name or f), fields)), primaryKey) attrs[__delete__] = delete from `%s` where `%s`=? % (tableName, primaryKey) return type.__new__(cls, name, bases, attrs) 这样，任何继承自 Model 的类（比如 User），会自动通过 ModelMetaclass 扫描映射关系，并存储到自身的类属性如 __table__、__mappings__ 中。 然后，往 Model 类添加 class 方法，就可以让所有子类调用 class 方法： class Model(dict): ... @classmethod @asyncio.coroutine def find(cls, pk): find object by primary key. rs = yield from select(%s where `%s`=? % (cls.__select__, cls.__primary_key__), [pk], 1) if len(rs) == 0: return None return cls(**rs[0]) User 类现在就可以通过类方法实现主键查找： user = yield from User.find(123) 往 Model 类添加实例方法，就可以让所有子类调用实例方法： class Model(dict): ... @asyncio.coroutine def save(self): args = list(map(self.getValueOrDefault, self.__fields__)) args.append(self.getValueOrDefault(self.__primary_key__)) rows = yield from execute(self.__insert__, args) if rows != 1: logging.warn(failed to insert record: affected rows: %s % rows) 这样，就可以把一个 User 实例存入数据库： user = User(id=123, name=Michael)yield from user.save() 最后一步是完善 ORM，对于查找，可以实现以下方法： findAll() - 根据 WHERE 条件查找； findNumber() - 根据 WHERE 条件查找，但返回的是整数，适用于 select count(*) 类型的 SQL。以及 update() 和 remove() 方法。所有这些方法都必须用 @asyncio.coroutine 装饰，变成一个协程。调用时需要特别注意： user.save() 没有任何效果，因为调用 save() 仅仅是创建了一个协程，并没有执行它。一定要用： yield from user.save() 才真正执行了 INSERT 操作。 编写 Model有了 ORM，就可以把 Web App 需要的 3 个表用 Model 表示出来： import time, uuidfrom orm import Model, StringField, BooleanField, FloatField, TextFielddef next_id(): return %015d%s000 % (int(time.time() * 1000), uuid.uuid4().hex)class User(Model): __table__ = users id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) email = StringField(ddl=varchar(50)) passwd = StringField(ddl=varchar(50)) admin = BooleanField() name = StringField(ddl=varchar(50)) image = StringField(ddl=varchar(500)) created_at = FloatField(default=time.time)class Blog(Model): __table__ = blogs id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) user_id = StringField(ddl=varchar(50)) user_name = StringField(ddl=varchar(50)) user_image = StringField(ddl=varchar(500)) name = StringField(ddl=varchar(50)) summary = StringField(ddl=varchar(200)) content = TextField() created_at = FloatField(default=time.time)class Comment(Model): __table__ = comments id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) blog_id = StringField(ddl=varchar(50)) user_id = StringField(ddl=varchar(50)) user_name = StringField(ddl=varchar(50)) user_image = StringField(ddl=varchar(500)) content = TextField() created_at = FloatField(default=time.time) 在编写 ORM 时，给一个 Field 增加一个 default 参数可以让 ORM 自己填入缺省值，非常方便。并且，缺省值可以作为函数对象传入，在调用 save() 时自动计算。 例如，主键 id 的缺省值是函数 next_id，创建时间 created_at 的缺省值是函数 time.time，可以自动设置当前日期和时间。 日期和时间用 float 类型存储在数据库中，而不是 datetime 类型，这么做的好处是不必关心数据库的时区以及时区转换问题，排序非常简单，显示的时候，只需要做一个 float 到 str 的转换，也非常容易。 初始化数据库表如果表的数量很少，可以手写创建表的 SQL 脚本： -- schema.sqldrop database if exists awesome;create database awesome;use awesome;grant select, insert, update, delete on awesome.* to www-data@localhost identified by www-data;create table users ( `id` varchar(50) not null, `email` varchar(50) not null, `passwd` varchar(50) not null, `admin` bool not null, `name` varchar(50) not null, `image` varchar(500) not null, `created_at` real not null, unique key `idx_email` (`email`), key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table blogs ( `id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `name` varchar(50) not null, `summary` varchar(200) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table comments ( `id` varchar(50) not null, `blog_id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8; 如果表的数量很多，可以从 Model 对象直接通过脚本自动生成 SQL 脚本，使用更简单。 把 SQL 脚本放到 MySQL 命令行里执行： $ mysql -u root -p schema.sql 就完成了数据库表的初始化。 编写数据访问代码接下来，就可以真正开始编写代码操作对象了。比如，对于 User 对象，就可以做如下操作： import ormfrom models import User, Blog, Commentdef test(): yield from orm.create_pool(user=www-data, password=www-data, database=awesome) u = User(name=Test, email=test@example.com, passwd=1234567890, image=about:blank) yield from u.save()for x in test(): pass 可以在 MySQL 客户端命令行查询，看看数据是不是正常存储到 MySQL 里面了。 Web 框架在正式开始 Web 开发前，需要编写一个 Web 框架。 aiohttp 已经是一个 Web 框架了，为什么还需要自己封装一个？ 原因是从使用者的角度来说，aiohttp 相对比较底层，编写一个 URL 的处理函数需要这么几步： 第一步，编写一个用 @asyncio.coroutine 装饰的函数： @asyncio.coroutinedef handle_url_xxx(request): pass 第二步，传入的参数需要自己从 request 中获取： url_param = request.match_info[key]query_params = parse_qs(request.query_string) 最后，需要自己构造 Response 对象： text = render(template, data)return web.Response(text.encode(utf-8)) 这些重复的工作可以由框架完成。例如，处理带参数的 URL/blog/id 可以这么写： @get(/blog/id)def get_blog(id): pass 处理 query_string 参数可以通过关键字参数 **kw 或者命名关键字参数接收： @get(/api/comments)def api_comments(*, page=1): pass 对于函数的返回值，不一定是 web.Response 对象，可以是 str、bytes 或 dict。 如果希望渲染模板，可以这么返回一个 dict： return __template__: index.html, data: ... 因此，Web 框架的设计是完全从使用者出发，目的是让使用者编写尽可能少的代码。 编写简单的函数而非引入 request 和 web.Response 还有一个额外的好处，就是可以单独测试，否则，需要模拟一个 request 才能测试。 @get 和@post要把一个函数映射为一个 URL 处理函数，先定义 @get()： def get(path): Define decorator @get(/path) def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): return func(*args, **kw) wrapper.__method__ = GET wrapper.__route__ = path return wrapper return decorator 这样，一个函数通过 @get() 的装饰就附带了 URL 信息。 @post 与 @get 定义类似。 定义 RequestHandlerURL 处理函数不一定是一个 coroutine，因此用 RequestHandler() 来封装一个 URL 处理函数。 RequestHandler 是一个类，由于定义了 __call__() 方法，因此可以将其实例视为函数。 RequestHandler 目的就是从 URL 函数中分析其需要接收的参数，从 request 中获取必要的参数，调用 URL 函数，然后把结果转换为 web.Response 对象，这样，就完全符合 aiohttp 框架的要求： class RequestHandler(object): def __init__(self, app, fn): self._app = app self._func = fn ... @asyncio.coroutine def __call__(self, request): kw = ... 获取参数 r = yield from self._func(**kw) return r 再编写一个 add_route 函数，用来注册一个 URL 处理函数： def add_route(app, fn): method = getattr(fn, __method__, None) path = getattr(fn, __route__, None) if path is None or method is None: raise ValueError(@get or @post not defined in %s. % str(fn)) if not asyncio.iscoroutinefunction(fn) and not inspect.isgeneratorfunction(fn): fn = asyncio.coroutine(fn) logging.info(add route %s %s = %s(%s) % (method, path, fn.__name__, , .join(inspect.signature(fn).parameters.keys()))) app.router.add_route(method, path, RequestHandler(app, fn)) 最后一步，把很多次 add_route() 注册的调用： add_route(app, handles.index)add_route(app, handles.blog)add_route(app, handles.create_comment)... 变成自动扫描： # 自动把handler模块的所有符合条件的函数注册了:add_routes(app, handlers) add_routes() 定义如下： def add_routes(app, module_name): n = module_name.rfind(.) if n == (-1): mod = __import__(module_name, globals(), locals()) else: name = module_name[n+1:] mod = getattr(__import__(module_name[:n], globals(), locals(), [name]), name) for attr in dir(mod): if attr.startswith(_): continue fn = getattr(mod, attr) if callable(fn): method = getattr(fn, __method__, None) path = getattr(fn, __route__, None) if method and path: add_route(app, fn) 最后，在 app.py 中加入 middleware、jinja2 模板和自注册的支持： app = web.Application(loop=loop, middlewares=[ logger_factory, response_factory])init_jinja2(app, filters=dict(datetime=datetime_filter))add_routes(app, handlers)add_static(app) middlewaremiddleware 是一种拦截器，一个 URL 在被某个函数处理前，可以经过一系列的 middleware 的处理。 一个 middleware 可以改变 URL 的输入、输出，甚至可以决定不继续处理而直接返回。middleware 的用处就在于把通用的功能从每个 URL 处理函数中拿出来，集中放到一个地方。例如，一个记录 URL 日志的 logger 可以简单定义如下： @asyncio.coroutinedef logger_factory(app, handler): @asyncio.coroutine def logger(request): # 记录日志: logging.info(Request: %s %s % (request.method, request.path)) # 继续处理请求: return (yield from handler(request)) return logger 而 response 这个 middleware 把返回值转换为 web.Response 对象再返回，以保证满足 aiohttp 的要求： @asyncio.coroutinedef response_factory(app, handler): @asyncio.coroutine def response(request): # 结果: r = yield from handler(request) if isinstance(r, web.StreamResponse): return r if isinstance(r, bytes): resp = web.Response(body=r) resp.content_type = application/octet-stream return resp if isinstance(r, str): resp = web.Response(body=r.encode(utf-8)) resp.content_type = text/html;charset=utf-8 return resp if isinstance(r, dict): ... 有了这些基础设施，就可以专注地往 handlers 模块不断添加 URL 处理函数了，可以极大地提高开发效率。 配置文件有了 Web 框架和 ORM 框架，就可以开始装配 App 了。 通常，一个 Web App 在运行时都需要读取配置文件，比如数据库的用户名、口令等，在不同的环境中运行时，Web App 可以通过读取不同的配置文件来获得正确的配置。 由于 Python 本身语法简单，完全可以直接用 Python 源代码来实现配置，而不需要再解析一个单独的 .properties 或者 .yaml 等配置文件。 默认的配置文件应该完全符合本地开发环境，这样，无需任何设置，就可以立刻启动服务器。 把默认的配置文件命名为 config_default.py： # config_default.pyconfigs = db: host: 127.0.0.1, port: 3306, user: www-data, password: www-data, database: awesome , session: secret: AwEsOmE 上述配置文件简单明了。但是，如果要部署到服务器时，通常需要修改数据库的 host 等信息，直接修改 config_default.py 不是一个好办法，更好的方法是编写一个 config_override.py，用来覆盖某些默认设置： # config_override.pyconfigs = db: host: 192.168.0.100 把 config_default.py 作为开发环境的标准配置，把 config_override.py 作为生产环境的标准配置，就可以既方便地在本地开发，又可以随时把应用部署到服务器上。 应用程序读取配置文件需要优先从 config_override.py 读取。为了简化读取配置文件，可以把所有配置读取到统一的 config.py 中： # config.pyconfigs = config_default.configstry: import config_override configs = merge(configs, config_override.configs)except ImportError: pass 这样，就完成了 App 的配置。 MVC现在，ORM 框架、Web 框架和配置都已就绪，可以开始编写一个最简单的 MVC，把它们全部启动起来。 通过 Web 框架的 @get 和 ORM 框架的 Model 支持，可以很容易地编写一个处理首页 URL 的函数： @get(/)def index(request): users = yield from User.findAll() return __template__: test.html, users: users __template__ 指定的模板文件是 test.html，其他参数是传递给模板的数据，所以在模板的根目录 templates 下创建 test.html： !DOCTYPE htmlhtmlhead meta charset=utf-8 / titleTest users - Awesome Python Webapp/title/headbody h1All users/h1 % for u in users % p u.name / u.email /p % endfor %/body/html 接下来，如果一切顺利，可以用命令行启动 Web 服务器： $ python3 app.py 然后，在浏览器中访问 http://localhost:9000/。 如果数据库的 users 表什么内容也没有，就无法在浏览器中看到循环输出的内容。可以自己在 MySQL 的命令行里给 users 表添加几条记录，然后再访问 构建前端对于复杂的 HTML 前端页面来说，需要一套基础的 CSS 框架来完成页面布局和基本样式。另外，jQuery 作为操作 DOM 的 JavaScript 库也必不可少。 从零开始写 CSS 不如直接从一个已有的功能完善的 CSS 框架开始。有很多 CSS 框架可供选择。这次选择 uikit 这个强大的 CSS 框架。它具备完善的响应式布局，漂亮的 UI，以及丰富的 HTML 组件，让能轻松设计出美观而简洁的页面。 可以从 uikit首页 下载打包的资源文件。 所有的静态资源文件统一放到 www/static 目录下，并按照类别归类： static/+- css/| +- addons/| | +- uikit.addons.min.css| | +- uikit.almost-flat.addons.min.css| | +- uikit.gradient.addons.min.css| +- awesome.css| +- uikit.almost-flat.addons.min.css| +- uikit.gradient.addons.min.css| +- uikit.min.css+- fonts/| +- fontawesome-webfont.eot| +- fontawesome-webfont.ttf| +- fontawesome-webfont.woff| +- FontAwesome.otf+- js/ +- awesome.js +- html5.js +- jquery.min.js +- uikit.min.js 由于前端页面肯定不止首页一个页面，每个页面都有相同的页眉和页脚。如果每个页面都是独立的 HTML 模板，那么在修改页眉和页脚的时候，就需要把每个模板都改一遍，这显然是没有效率的。 常见的模板引擎已经考虑到了页面上重复的 HTML 部分的复用问题。有的模板通过 include 把页面拆成三部分： html % include file=inc_header.html % % include file=index_body.html % % include file=inc_footer.html %/html 这样，相同的部分 inc_header.html 和 inc_footer.html 就可以共享。 但是 include 方法不利于页面整体结构的维护。jinjia2 的模板还有另一种”继承”方式，实现模板的复用更简单。 “继承”模板的方式是通过编写一个”父模板”，在父模板中定义一些可替换的 block（块）。然后，编写多个”子模板”，每个子模板都可以只替换父模板定义的 block。比如，定义一个最简单的父模板： !-- base.html --html head title% block title% 这里定义了一个名为title的block % endblock %/title /head body % block content % 这里定义了一个名为content的block % endblock % /body/html 对于子模板 a.html，只需要把父模板的 title 和 content 替换掉： % extends base.html %% block title % A % endblock %% block content % h1Chapter A/h1 pblablabla.../p% endblock % 对于子模板 b.html，如法炮制： % extends base.html %% block title % B % endblock %% block content % h1Chapter B/h1 ul lilist 1/li lilist 2/li /ul% endblock % 这样，一旦定义好父模板的整体布局和 CSS 样式，编写子模板就会非常容易。 让通过 uikit 这个 CSS 框架来完成父模板 __base__.html 的编写： !DOCTYPE htmlhtmlhead meta charset=utf-8 / % block meta %!-- block meta --% endblock % title% block title % ? % endblock % - Awesome Python Webapp/title link rel=stylesheet href=/static/css/uikit.min.css link rel=stylesheet href=/static/css/uikit.gradient.min.css link rel=stylesheet href=/static/css/awesome.css / script src=/static/js/jquery.min.js/script script src=/static/js/md5.js/script script src=/static/js/uikit.min.js/script script src=/static/js/awesome.js/script % block beforehead %!-- before head --% endblock %/headbody nav class=uk-navbar uk-navbar-attached uk-margin-bottom div class=uk-container uk-container-center a href=/ class=uk-navbar-brandAwesome/a ul class=uk-navbar-nav li data-url=blogsa href=/i class=uk-icon-home/i 日志/a/li lia target=_blank href=#i class=uk-icon-book/i 教程/a/li lia target=_blank href=#i class=uk-icon-code/i 源码/a/li /ul div class=uk-navbar-flip ul class=uk-navbar-nav % if user % li class=uk-parent data-uk-dropdown a href=#0i class=uk-icon-user/i user.name /a div class=uk-dropdown uk-dropdown-navbar ul class=uk-nav uk-nav-navbar lia href=/signouti class=uk-icon-sign-out/i 登出/a/li /ul /div /li % else % lia href=/signini class=uk-icon-sign-in/i 登陆/a/li lia href=/registeri class=uk-icon-edit/i 注册/a/li % endif % /ul /div /div /nav div class=uk-container uk-container-center div class=uk-grid !-- content -- % block content % % endblock % !-- // content -- /div /div div class=uk-margin-large-top style=background-color:#eee; border-top:1px solid #ccc; div class=uk-container uk-container-center uk-text-center div class=uk-panel uk-margin-top uk-margin-bottom p a target=_blank href=# class=uk-icon-button uk-icon-weibo/a a target=_blank href=# class=uk-icon-button uk-icon-github/a a target=_blank href=# class=uk-icon-button uk-icon-linkedin-square/a a target=_blank href=# class=uk-icon-button uk-icon-twitter/a /p pPowered by a href=#Awesome Python Webapp/a. Copyright copy; 2014. [a href=/manage/ target=_blankManage/a]/p pa href=http://www.liaoxuefeng.com/ target=_blankwww.liaoxuefeng.com/a. All rights reserved./p a target=_blank href=#i class=uk-icon-html5 style=font-size:64px; color: #444;/i/a /div /div /div/body/html __base__.html 定义的几个 block 作用如下： 用于子页面定义一些 meta，例如 rss feed： % block meta % ... % endblock % 覆盖页面的标题： % block title % ... % endblock % 子页面可以在 head 标签关闭前插入 JavaScript 代码： % block beforehead % ... % endblock % 子页面的 content 布局和内容： % block content % ...% endblock % 把首页改造一下，从 __base__.html 继承一个 blogs.html： % extends __base__.html %% block title %日志% endblock %% block content % div class=uk-width-medium-3-4 % for blog in blogs % article class=uk-article h2a href=/blog/ blog.id blog.name /a/h2 p class=uk-article-meta发表于 blog.created_at/p p blog.summary /p pa href=/blog/ blog.id 继续阅读 i class=uk-icon-angle-double-right/i/a/p /article hr class=uk-article-divider % endfor % /div div class=uk-width-medium-1-4 div class=uk-panel uk-panel-header h3 class=uk-panel-title友情链接/h3 ul class=uk-list uk-list-line lii class=uk-icon-thumbs-o-up/i a target=_blank href=#编程/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#读书/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#Python教程/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#Git教程/a/li /ul /div /div% endblock % 相应地，首页 URL 的处理函数更新如下： @get(/)def index(request): summary = Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. blogs = [ Blog(id=1, name=Test Blog, summary=summary, created_at=time.time()-120), Blog(id=2, name=Something New, summary=summary, created_at=time.time()-3600), Blog(id=3, name=Learn Swift, summary=summary, created_at=time.time()-7200) ] return __template__: blogs.html, blogs: blogs Blog 的创建日期显示的是一个浮点数，因为它是由这段模板渲染出来的： p class=uk-article-meta发表于 blog.created_at /p 解决方法是通过 jinja2 的 filter（过滤器），把一个浮点数转换成日期字符串。来编写一个 datetime 的 filter，在模板里用法如下： p class=uk-article-meta发表于 blog.created_at|datetime /p filter 需要在初始化 jinja2 时设置。相关代码如下： def datetime_filter(t): delta = int(time.time() - t) if delta 60: return 1分钟前 if delta 3600: return %s分钟前 % (delta // 60) if delta 86400: return %s小时前 % (delta // 3600) if delta 604800: return %s天前 % (delta // 86400) dt = datetime.fromtimestamp(t) return %s年%s月%s日 % (dt.year, dt.month, dt.day)...init_jinja2(app, filters=dict(datetime=datetime_filter))... 现在，完善的首页显示如下 编写 API什么是 Web API 呢？ 如果想要获取一篇 Blog，输入 http://localhost:9000/blog/123，就可以看到 id 为 123 的 Blog 页面，但这个结果是 HTML 页面，它同时混合包含了 Blog 的数据和 Blog 的展示两个部分。对于用户来说，阅读起来没有问题，但是，如果机器读取，就很难从 HTML 中解析出 Blog 的数据。 如果一个 URL 返回的不是 HTML，而是机器能直接解析的数据，这个 URL 就可以看成是一个 Web API。比如，读取 http://localhost:9000/api/blogs/123，如果能直接返回 Blog 的数据，那么机器就可以直接读取。 REST 就是一种设计 API 的模式。最常用的数据格式是 JSON。由于 JSON 能直接被 JavaScript 读取，所以，以 JSON 格式编写的 REST 风格的 API 具有简单、易读、易用的特点。 编写 API 有什么好处呢？由于 API 就是把 Web App 的功能全部封装了，所以，通过 API 操作数据，可以极大地把前端和后端的代码隔离，使得后端代码易于测试，前端代码编写更简单。 一个 API 也是一个 URL 的处理函数，希望能直接通过一个 @api 来把函数变成 JSON 格式的 REST API，这样，获取注册用户可以用一个 API 实现如下： @get(/api/users)def api_get_users(*, page=1): page_index = get_page_index(page) num = yield from User.findNumber(count(id)) p = Page(num, page_index) if num == 0: return dict(page=p, users=()) users = yield from User.findAll(orderBy=created_at desc, limit=(p.offset, p.limit)) for u in users: u.passwd = ****** return dict(page=p, users=users) 只要返回一个 dict，后续的 response 这个 middleware 就可以把结果序列化为 JSON 并返回。 需要对 Error 进行处理，因此定义一个 APIError，这种 Error 是指 API 调用时发生了逻辑错误（比如用户不存在），其他的 Error 视为 Bug，返回的错误代码为 internalerror。 客户端调用 API 时，必须通过错误代码来区分 API 调用是否成功。错误代码是用来告诉调用者出错的原因。很多 API 用一个整数表示错误码，这种方式很难维护错误码，客户端拿到错误码还需要查表得知错误信息。更好的方式是用字符串表示错误代码，不需要看文档也能猜到错误原因。 可以在浏览器直接测试 API，例如，输入 http://localhost:9000/api/users，就可以看到返回的 JSON： 功能注册和登录用户管理是绝大部分 Web 网站都需要解决的问题。用户管理涉及到用户注册和登录。 用户注册相对简单，可以先通过 API 把用户注册这个功能实现了： _RE_EMAIL = re.compile(r^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)1,4$)_RE_SHA1 = re.compile(r^[0-9a-f]40$)@post(/api/users)def api_register_user(*, email, name, passwd): if not name or not name.strip(): raise APIValueError(name) if not email or not _RE_EMAIL.match(email): raise APIValueError(email) if not passwd or not _RE_SHA1.match(passwd): raise APIValueError(passwd) users = yield from User.findAll(email=?, [email]) if len(users) 0: raise APIError(register:failed, email, Email is already in use.) uid = next_id() sha1_passwd = %s:%s % (uid, passwd) user = User(id=uid, name=name.strip(), email=email, passwd=hashlib.sha1(sha1_passwd.encode(utf-8)).hexdigest(), image=http://www.gravatar.com/avatar/%s?d=mms=120 % hashlib.md5(email.encode(utf-8)).hexdigest()) yield from user.save() # make session cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = ****** r.content_type = application/json r.body = json.dumps(user, ensure_ascii=False).encode(utf-8) return r 注意用户口令是客户端传递的经过 SHA1 计算后的 40 位 Hash 字符串，所以服务器端并不知道用户的原始口令。 接下来可以创建一个注册页面，让用户填写注册表单，然后，提交数据到注册用户的 API： % extends __base__.html %% block title %注册% endblock %% block beforehead %scriptfunction validateEmail(email) var re = /^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)1,4$/; return re.test(email.toLowerCase());$(function () var vm = new Vue( el: #vm, data: name: , email: , password1: , password2: , methods: submit: function (event) event.preventDefault(); var $form = $(#vm); if (! this.name.trim()) return $form.showFormError(请输入名字); if (! validateEmail(this.email.trim().toLowerCase())) return $form.showFormError(请输入正确的Email地址); if (this.password1.length 6) return $form.showFormError(口令长度至少为6个字符); if (this.password1 !== this.password2) return $form.showFormError(两次输入的口令不一致); var email = this.email.trim().toLowerCase(); $form.postJSON(/api/users, name: this.name.trim(), email: email, passwd: CryptoJS.SHA1(email + : + this.password1).toString() , function (err, r) if (err) return $form.showFormError(err); return location.assign(/); ); ); $(#vm).show(););/script% endblock %% block content % div class=uk-width-2-3 h1欢迎注册！/h1 form id=vm v-on=submit: submit class=uk-form uk-form-stacked div class=uk-alert uk-alert-danger uk-hidden/div div class=uk-form-row label class=uk-form-label名字:/label div class=uk-form-controls input v-model=name type=text maxlength=50 placeholder=名字 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label电子邮件:/label div class=uk-form-controls input v-model=email type=text maxlength=50 placeholder=your-name@example.com class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label输入口令:/label div class=uk-form-controls input v-model=password1 type=password maxlength=50 placeholder=输入口令 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label重复口令:/label div class=uk-form-controls input v-model=password2 type=password maxlength=50 placeholder=重复口令 class=uk-width-1-1 /div /div div class=uk-form-row button type=submit class=uk-button uk-button-primaryi class=uk-icon-user/i 注册/button /div /form /div% endblock % 这样就把用户注册的功能完成了 用户登录比用户注册复杂。由于 HTTP 协议是一种无状态协议，而服务器要跟踪用户状态，就只能通过 cookie 实现。大多数 Web 框架提供了 Session 功能来封装保存用户状态的 cookie。 Session 的优点是简单易用，可以直接从 Session 中取出用户登录信息。 Session 的缺点是服务器需要在内存中维护一个映射表来存储用户登录信息，如果有两台以上服务器，就需要对 Session 做集群，因此，使用 Session 的 Web App 很难扩展。 采用直接读取 cookie 的方式来验证用户登录，每次用户访问任意 URL，都会对 cookie 进行验证，这种方式的好处是保证服务器处理任意的 URL 都是无状态的，可以扩展到多台服务器。 由于登录成功后是由服务器生成一个 cookie 发送给浏览器，所以，要保证这个 cookie 不会被客户端伪造出来。 实现防伪造 cookie 的关键是通过一个单向算法（例如 SHA1），举例如下： 当用户输入了正确的口令登录成功后，服务器可以从数据库取到用户的 id，并按照如下方式计算出一个字符串： 用户id + 过期时间 + SHA1(用户id + 用户口令 + 过期时间 + SecretKey) 当浏览器发送 cookie 到服务器端后，服务器可以拿到的信息包括： 用户 id 过期时间 SHA1 值如果未到过期时间，服务器就根据用户 id 查找用户口令，并计算： SHA1(用户id + 用户口令 + 过期时间 + SecretKey) 并与浏览器 cookie 中的哈希进行比较，如果相等，则说明用户已登录，否则，cookie 就是伪造的。 这个算法的关键在于 SHA1 是一种单向算法，即可以通过原始字符串计算出 SHA1 结果，但无法通过 SHA1 结果反推出原始字符串。 所以登录 API 可以实现如下： @post(/api/authenticate)def authenticate(*, email, passwd): if not email: raise APIValueError(email, Invalid email.) if not passwd: raise APIValueError(passwd, Invalid password.) users = yield from User.findAll(email=?, [email]) if len(users) == 0: raise APIValueError(email, Email not exist.) user = users[0] # check passwd: sha1 = hashlib.sha1() sha1.update(user.id.encode(utf-8)) sha1.update(b:) sha1.update(passwd.encode(utf-8)) if user.passwd != sha1.hexdigest(): raise APIValueError(passwd, Invalid password.) # authenticate ok, set cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = ****** r.content_type = application/json r.body = json.dumps(user, ensure_ascii=False).encode(utf-8) return r # 计算加密cookie:def user2cookie(user, max_age): # build cookie string by: id-expires-sha1 expires = str(int(time.time() + max_age)) s = %s-%s-%s-%s % (user.id, user.passwd, expires, _COOKIE_KEY) L = [user.id, expires, hashlib.sha1(s.encode(utf-8)).hexdigest()] return -.join(L) 对于每个 URL 处理函数，如果都去写解析 cookie 的代码，那会导致代码重复很多次。 利用 middle 在处理 URL 之前，把 cookie 解析出来，并将登录用户绑定到 request 对象上，这样，后续的 URL 处理函数就可以直接拿到登录用户： @asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(check user: %s %s % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(set current user: %s % user.email) request.__user__ = user return (yield from handler(request)) return auth # 解密cookie:@asyncio.coroutinedef cookie2user(cookie_str): Parse cookie and load user if cookie is valid. if not cookie_str: return None try: L = cookie_str.split(-) if len(L) != 3: return None uid, expires, sha1 = L if int(expires) time.time(): return None user = yield from User.find(uid) if user is None: return None s = %s-%s-%s-%s % (uid, user.passwd, expires, _COOKIE_KEY) if sha1 != hashlib.sha1(s.encode(utf-8)).hexdigest(): logging.info(invalid sha1) return None user.passwd = ****** return user except Exception as e: logging.exception(e) return None 这样，就完成了用户注册和登录的功能。 编写日志创建页在 Web 开发中，后端代码写起来其实是相当容易的。 例如，编写一个 REST API，用于创建一个 Blog： @post(/api/blogs)def api_create_blog(request, *, name, summary, content): check_admin(request) if not name or not name.strip(): raise APIValueError(name, name cannot be empty.) if not summary or not summary.strip(): raise APIValueError(summary, summary cannot be empty.) if not content or not content.strip(): raise APIValueError(content, content cannot be empty.) blog = Blog(user_id=request.__user__.id, user_name=request.__user__.name, user_image=request.__user__.image, name=name.strip(), summary=summary.strip(), content=content.strip()) yield from blog.save() return blog 编写后端 Python 代码不但很简单，而且非常容易测试，上面的 API：api_create_blog() 本身只是一个普通函数。 Web 开发真正困难的地方在于编写前端页面。前端页面需要混合 HTML、CSS 和 JavaScript，如果对这三者没有深入地掌握，编写的前端页面将很快难以维护。 更大的问题在于，前端页面通常是动态页面，也就是说，前端页面往往是由后端代码生成的。 生成前端页面最早的方式是拼接字符串： s = htmlheadtitle + title + /title/headbody + body + /body/html 显然这种方式完全不具备可维护性。所以有第二种模板方式： htmlhead title title /title/headbody body /body/html ASP、JSP、PHP 等都是用这种模板方式生成前端页面。 如果在页面上大量使用 JavaScript（事实上大部分页面都会），模板方式仍然会导致 JavaScript 代码与后端代码绑得非常紧密，以至于难以维护。其根本原因在于负责显示的 HTML DOM 模型与负责数据和交互的 JavaScript 代码没有分割清楚。 要编写可维护的前端代码绝非易事。和后端结合的 MVC 模式已经无法满足复杂页面逻辑的需要了，所以，新的 MVVM：Model View ViewModel 模式应运而生。 MVVM 最早由微软提出来，它借鉴了桌面应用程序的 MVC 思想，在前端页面中，把 Model 用纯 JavaScript 对象表示： script var blog = name: hello, summary: this is summary, content: this is content... ;/script View 是纯 HTML： form action=/api/blogs method=post input name=name input name=summary textarea name=content/textarea button type=submitOK/button/form 由于 Model 表示数据，View 负责显示，两者做到了最大限度的分离。 把 Model 和 View 关联起来的就是 ViewModel。ViewModel 负责把 Model 的数据同步到 View 显示出来，还负责把 View 的修改同步回 Model。 ViewModel 如何编写？需要用 JavaScript 编写一个通用的 ViewModel，这样，就可以复用整个 MVVM 模型了。 好消息是已有许多成熟的 MVVM 框架，例如 AngularJS，KnockoutJS 等。选择 Vue 这个简单易用的 MVVM 框架来实现创建 Blog 的页面 templates/manage_blog_edit.html： % extends __base__.html %% block title %编辑日志% endblock %% block beforehead %scriptvar ID = id , action = action ;function initVM(blog) var vm = new Vue( el: #vm, data: blog, methods: submit: function (event) event.preventDefault(); var $form = $(#vm).find(form); $form.postJSON(action, this.$data, function (err, r) if (err) $form.showFormError(err); else return location.assign(/api/blogs/ + r.id); ); ); $(#vm).show();$(function () if (ID) getJSON(/api/blogs/ + ID, function (err, blog) if (err) return fatal(err); $(#loading).hide(); initVM(blog); ); else $(#loading).hide(); initVM( name: , summary: , content: ); );/script% endblock %% block content % div class=uk-width-1-1 uk-margin-bottom div class=uk-panel uk-panel-box ul class=uk-breadcrumb lia href=/manage/comments评论/a/li lia href=/manage/blogs日志/a/li lia href=/manage/users用户/a/li /ul /div /div div id=error class=uk-width-1-1 /div div id=loading class=uk-width-1-1 uk-text-center spani class=uk-icon-spinner uk-icon-medium uk-icon-spin/i 正在加载.../span /div div id=vm class=uk-width-2-3 form v-on=submit: submit class=uk-form uk-form-stacked div class=uk-alert uk-alert-danger uk-hidden/div div class=uk-form-row label class=uk-form-label标题:/label div class=uk-form-controls input v-model=name name=name type=text placeholder=标题 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label摘要:/label div class=uk-form-controls textarea v-model=summary rows=4 name=summary placeholder=摘要 class=uk-width-1-1 style=resize:none;/textarea /div /div div class=uk-form-row label class=uk-form-label内容:/label div class=uk-form-controls textarea v-model=content rows=16 name=content placeholder=内容 class=uk-width-1-1 style=resize:none;/textarea /div /div div class=uk-form-row button type=submit class=uk-button uk-button-primaryi class=uk-icon-save/i 保存/button a href=/manage/blogs class=uk-buttoni class=uk-icon-times/i 取消/a /div /form /div% endblock % 初始化 Vue 时，指定 3 个参数： el：根据选择器查找绑定的 View，这里是 #vm，就是 id 为 vm 的 DOM，对应的是一个 div 标签； data：JavaScript 对象表示的 Model，初始化为 name: , summary: , content: ； methods：View 可以触发的 JavaScript 函数，submit 就是提交表单时触发的函数。 接下来，在 form 标签中，用几个简单的 v-model，就可以让 Vue 把 Model 和 View 关联起来： !-- input的value和Model的name关联起来了 --input v-model=name class=uk-width-1-1 Form 表单通过 form v-on=submit: submit 把提交表单的事件关联到 submit 方法。 需要特别注意的是，在 MVVM 中，Model 和 View 是双向绑定的。如果在 Form 中修改了文本框的值，可以在 Model 中立刻拿到新的值。试试在表单中输入文本，然后在 Chrome 浏览器中打开 JavaScript 控制台，可以通过 vm.name 访问单个属性，或者通过 vm.$data 访问整个 Model 如果在 JavaScript 逻辑中修改了 Model，这个修改会立刻反映到 View 上。试试在 JavaScript 控制台输入 vm.name = MVVM简介，可以看到文本框的内容自动被同步了 双向绑定是 MVVM 框架最大的作用。借助于 MVVM，把复杂的显示逻辑交给框架完成。由于后端编写了独立的 REST API，所以，前端用 AJAX 提交表单非常容易，前后端分离得非常彻底。 日志列表页MVVM 模式不但可用于 Form 表单，在复杂的管理页面中也能大显身手。例如，分页显示 Blog 的功能，先把后端代码写出来： 在 apis.py 中定义一个 Page 类用于存储分页信息： class Page(object): def __init__(self, item_count, page_index=1, page_size=10): self.item_count = item_count self.page_size = page_size self.page_count = item_count // page_size + (1 if item_count % page_size 0 else 0) if (item_count == 0) or (page_index self.page_count): self.offset = 0 self.limit = 0 self.page_index = 1 else: self.page_index = page_index self.offset = self.page_size * (page_index - 1) self.limit = self.page_size self.has_next = self.page_index self.page_count self.has_previous = self.page_index 1 def __str__(self): return item_count: %s, page_count: %s, page_index: %s, page_size: %s, offset: %s, limit: %s % (self.item_count, self.page_count, self.page_index, self.page_size, self.offset, self.limit) __repr__ = __str__ 在 handlers.py 中实现 API： @get(/api/blogs)def api_blogs(*, page=1): page_index = get_page_index(page) num = yield from Blog.findNumber(count(id)) p = Page(num, page_index) if num == 0: return dict(page=p, blogs=()) blogs = yield from Blog.findAll(orderBy=created_at desc, limit=(p.offset, p.limit)) return dict(page=p, blogs=blogs) 管理页面： @get(/manage/blogs)def manage_blogs(*, page=1): return __template__: manage_blogs.html, page_index: get_page_index(page) 模板页面首先通过 API：GET /api/blogs?page=? 拿到 Model： page: has_next: true, page_index: 1, page_count: 2, has_previous: false, item_count: 12 , blogs: [...] 然后，通过 Vue 初始化 MVVM： scriptfunction initVM(data) var vm = new Vue( el: #vm, data: blogs: data.blogs, page: data.page , methods: edit_blog: function (blog) location.assign(/manage/blogs/edit?id= + blog.id); , delete_blog: function (blog) if (confirm(确认要删除 + blog.name + ？删除后不可恢复！)) postJSON(/api/blogs/ + blog.id + /delete, function (err, r) if (err) return alert(err.message || err.error || err); refresh(); ); ); $(#vm).show();$(function() getJSON(/api/blogs, page: page_index , function (err, results) if (err) return fatal(err); $(#loading).hide(); initVM(results); ););/script View 的容器是 #vm，包含一个 table，用 v-repeat 可以把 Model 的数组 blogs 直接变成多行的 tr： div id=vm class=uk-width-1-1 a href=/manage/blogs/create class=uk-button uk-button-primaryi class=uk-icon-plus/i 新日志/a table class=uk-table uk-table-hover thead tr th class=uk-width-5-10标题 / 摘要/th th class=uk-width-2-10作者/th th class=uk-width-2-10创建时间/th th class=uk-width-1-10操作/th /tr /thead tbody tr v-repeat=blog: blogs td a target=_blank v-attr=href: /blog/+blog.id v-text=blog.name/a /td td a target=_blank v-attr=href: /user/+blog.user_id v-text=blog.user_name/a /td td span v-text=blog.created_at.toDateTime()/span /td td a href=#0 v-on=click: edit_blog(blog)i class=uk-icon-edit/i a href=#0 v-on=click: delete_blog(blog)i class=uk-icon-trash-o/i /td /tr /tbody /table div v-component=pagination v-with=page/div/div 往 Model 的 blogs 数组中增加一个 Blog 元素，table 就神奇地增加了一行；把 blogs 数组的某个元素删除，table 就神奇地减少了一行。所有复杂的 Model-View 的映射逻辑全部由 MVVM 框架完成，只需要在 HTML 中写上 v-repeat 指令，就什么都不用管了。 可以把 v-repeat=blog: blogs 看成循环代码，所以，可以在一个 tr 内部引用循环变量 blog。v-text 和 v-attr 指令分别用于生成文本和 DOM 节点属性。 效率现在，已经把一个 Web App 的框架完全搭建好了，从后端的 API 到前端的 MVVM，流程已经跑通了。 在继续工作前，注意到每次修改 Python 代码，都必须在命令行先 Ctrl-C 停止服务器，再重启，改动才能生效。 在开发阶段，每天都要修改、保存几十次代码，每次保存都手动来这么一下非常麻烦，严重地降低了的开发效率。有没有办法让服务器检测到代码修改后自动重新加载呢？ Django 的开发环境在 Debug 模式下就可以做到自动重新加载，如果编写的服务器也能实现这个功能，就能大大提升开发效率。 可惜的是，Django 没把这个功能独立出来，不用 Django 就享受不到，怎么办？ 其实 Python 本身提供了重新载入模块的功能，但不是所有模块都能被重新载入。另一种思路是检测 www 目录下的代码改动，一旦有改动，就自动重启服务器。 按照这个思路，可以编写一个辅助程序 pymonitor.py，让它启动 wsgiapp.py，并时刻监控 www 目录下的代码改动，有改动时，先把当前 wsgiapp.py 进程杀掉，再重启，就完成了服务器进程的自动重启。 要监控目录文件的变化，也无需自己手动定时扫描，Python 的第三方库 watchdog 可以利用操作系统的 API 来监控目录文件的变化，并发送通知。先用 pip 安装： $ pip3 install watchdog 利用 watchdog 接收文件变化的通知，如果是 .py 文件，就自动重启 wsgiapp.py 进程。 利用 Python 自带的 subprocess 实现进程的启动和终止，并把输入输出重定向到当前进程的输入输出中： #!/usr/bin/env python3# -*- coding: utf-8 -*-__author__ = Michael Liaoimport os, sys, time, subprocessfrom watchdog.observers import Observerfrom watchdog.events import FileSystemEventHandlerdef log(s): print([Monitor] %s % s)class MyFileSystemEventHander(FileSystemEventHandler): def __init__(self, fn): super(MyFileSystemEventHander, self).__init__() self.restart = fn def on_any_event(self, event): if event.src_path.endswith(.py): log(Python source file changed: %s % event.src_path) self.restart()command = [echo, ok]process = Nonedef kill_process(): global process if process: log(Kill process [%s]... % process.pid) process.kill() process.wait() log(Process ended with code %s. % process.returncode) process = Nonedef start_process(): global process, command log(Start process %s... % .join(command)) process = subprocess.Popen(command, stdin=sys.stdin, stdout=sys.stdout, stderr=sys.stderr)def restart_process(): kill_process() start_process()def start_watch(path, callback): observer = Observer() observer.schedule(MyFileSystemEventHander(restart_process), path, recursive=True) observer.start() log(Watching directory %s... % path) start_process() try: while True: time.sleep(0.5) except KeyboardInterrupt: observer.stop() observer.join()if __name__ == __main__: argv = sys.argv[1:] if not argv: print(Usage: ./pymonitor your-script.py) exit(0) if argv[0] != python3: argv.insert(0, python3) command = argv path = os.path.abspath(.) start_watch(path, None) 一共 70 行左右的代码，就实现了 Debug 模式的自动重新加载。用下面的命令启动服务器： $ python3 pymonitor.py wsgiapp.py 或者给 pymonitor.py 加上可执行权限，启动服务器： $ ./pymonitor.py app.py 在编辑器中打开一个 .py 文件，修改后保存，看看命令行输出，是不是自动重启了服务器： $ ./pymonitor.py app.py [Monitor] Watching directory /Users/michael/Github/awesome-python3-webapp/www...[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000...[Monitor] Python source file changed: /Users/michael/Github/awesome-python-webapp/www/handlers.py[Monitor] Kill process [2747]...[Monitor] Process ended with code -9.[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000... 现在，只要一保存代码，就可以刷新浏览器看到效果，大大提升了开发效率。 完善在 Web App 框架和基本流程跑通后，剩下的工作全部是体力活了：在 Debug 开发模式下完成后端所有 API、前端所有页面。需要做的事情包括： 把当前用户绑定到 request 上，并对 URL/manage/ 进行拦截，检查当前用户是否是管理员身份： @asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(check user: %s %s % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(set current user: %s % user.email) request.__user__ = user if request.path.startswith(/manage/) and (request.__user__ is None or not request.__user__.admin): return web.HTTPFound(/signin) return (yield from handler(request)) return auth 后端 API 包括： 获取日志：GET apiblogs 创建日志：POST apiblogs 修改日志：POST apiblogs:blog_id 删除日志：POST apiblogs:blog_iddelete 获取评论：GET apicomments 创建评论：POST apiblogs:blog_idcomments 删除评论：POST apicomments:comment_iddelete 创建新用户：POST apiusers 获取用户：GET apiusers管理页面包括： 评论列表页：GET managecomments 日志列表页：GET manageblogs 创建日志页：GET manageblogscreate 修改日志页：GET manageblogs 用户列表页：GET manageusers用户浏览页面包括： 注册页：GET register 登录页：GET signin 注销页：GET signout 首页：GET 日志详情页：GET blog:blog_id把所有的功能实现，第一个 Web App 就宣告完成！ 部署很多做开发的同学把部署这件事情看成是运维同学的工作，这种看法是完全错误的。首先，最近流行 DevOps 理念，就是说，开发和运维要变成一个整体。其次，运维的难度，其实跟开发质量有很大的关系。代码写得垃圾，运维再好也架不住天天挂掉。最后，DevOps 理念需要把运维、监控等功能融入到开发中。想服务器升级时不中断用户服务？那就得在开发时考虑到这一点。 下面，就来把 awesome-python3-webapp 部署到 Linux 服务器。 搭建 Linux 服务器要部署到 Linux，首先得有一台 Linux 服务器。要在公网上体验的同学，可以在 Amazon 的 AWS 申请一台 EC2 虚拟机（免费使用 1 年），或者使用国内的一些云服务器，一般都提供 Ubuntu Server 的镜像。想在本地部署的同学，请安装虚拟机，推荐使用 VirtualBox。 选择的 Linux 服务器版本是 Ubuntu Server 14.04 LTS，原因是 apt 太简单了。如果准备使用其他 Linux 版本，也没有问题。 Linux 安装完成后，请确保 ssh 服务正在运行，否则，需要通过 apt 安装： $ sudo apt-get install openssh-server 有了 ssh 服务，就可以从本地连接到服务器上。建议把公钥复制到服务器端用户的 .ssh/authorized_keys 中，这样，就可以通过证书实现无密码连接。 部署方式利用 Python 自带的 asyncio，已经编写了一个异步高性能服务器。但是，还需要一个高性能的 Web 服务器，这里选择 Nginx，它可以处理静态资源，同时作为反向代理把动态请求交给 Python 代码处理。这个模型如下 Nginx 负责分发请求 在服务器端，需要定义好部署的目录结构： /+- srv/ +- awesome/ -- Web App根目录 +- www/ -- 存放Python源码 | +- static/ -- 存放静态资源文件 +- log/ -- 存放log 在服务器上部署，要考虑到新版本如果运行不正常，需要回退到旧版本时怎么办。每次用新的代码覆盖掉旧的文件是不行的，需要一个类似版本控制的机制。由于 Linux 系统提供了软链接功能，所以，把 www 作为一个软链接，它指向哪个目录，哪个目录就是当前运行的版本 而 Nginx 和 python 代码的配置文件只需要指向 www 目录即可。 Nginx 可以作为服务进程直接启动，但 app.py 还不行，所以，Supervisor 登场！Supervisor 是一个管理进程的工具，可以随系统启动而启动服务，它还时刻监控服务进程，如果服务进程意外退出，Supervisor 可以自动重启服务。 总结一下需要用到的服务有： Nginx：高性能 Web 服务器 + 负责反向代理； Supervisor：监控服务进程的工具； MySQL：数据库服务。在 Linux 服务器上用 apt 可以直接安装上述服务： $ sudo apt-get install nginx supervisor python3 mysql-server 然后，再把自己的 Web App 用到的 Python 库安装了： $ sudo pip3 install jinja2 aiomysql aiohttp 在服务器上创建目录 /srv/awesome/ 以及相应的子目录。 在服务器上初始化 MySQL 数据库，把数据库初始化脚本 schema.sql 复制到服务器上执行： $ mysql -u root -p schema.sql 服务器端准备就绪。 部署用 FTP 还是 SCP 还是 rsync 复制文件？如果需要手动复制，用一次两次还行，一天如果部署 50 次不但慢、效率低，而且容易出错。 正确的部署方式是使用工具配合脚本完成自动化部署。Fabric 就是一个自动化部署工具。由于 Fabric 是用 Python 2.x 开发的，所以，部署脚本要用 Python 2.7 来编写，本机还必须安装 Python 2.7 版本。 要用 Fabric 部署，需要在本机（是开发机器，不是 Linux 服务器）安装 Fabric： $ easy_install fabric Linux 服务器上不需要安装 Fabric，Fabric 使用 SSH 直接登录服务器并执行部署命令。 下一步是编写部署脚本。Fabric 的部署脚本叫 fabfile.py，把它放到 awesome-python-webapp 的目录下，与 www 目录平级： awesome-python-webapp/+- fabfile.py+- www/+- ... Fabric 的脚本编写很简单，首先导入 Fabric 的 API，设置部署时的变量： # fabfile.pyimport os, refrom datetime import datetime# 导入Fabric API:from fabric.api import *# 服务器登录用户名:env.user = michael# sudo用户为root:env.sudo_user = root# 服务器地址，可以有多个，依次部署:env.hosts = [192.168.0.3]# 服务器MySQL用户名和口令:db_user = www-datadb_password = www-data 然后，每个 Python 函数都是一个任务。先编写一个打包的任务： _TAR_FILE = dist-awesome.tar.gzdef build(): includes = [static, templates, transwarp, favicon.ico, *.py] excludes = [test, .*, *.pyc, *.pyo] local(rm -f dist/%s % _TAR_FILE) with lcd(os.path.join(os.path.abspath(.), www)): cmd = [tar, --dereference, -czvf, ../dist/%s % _TAR_FILE] cmd.extend([--exclude=\\%s\\ % ex for ex in excludes]) cmd.extend(includes) local( .join(cmd)) Fabric 提供 local(...) 来运行本地命令，with lcd(path) 可以把当前命令的目录设定为 lcd() 指定的目录，注意 Fabric 只能运行命令行命令，Windows 下可能需要 Cgywin 环境。 在 awesome-python-webapp 目录下运行： $ fab build 看看是否在 dist 目录下创建了 dist-awesome.tar.gz 的文件。 打包后，就可以继续编写 deploy 任务，把打包文件上传至服务器，解压，重置 www 软链接，重启相关服务： _REMOTE_TMP_TAR = /tmp/%s % _TAR_FILE_REMOTE_BASE_DIR = /srv/awesomedef deploy(): newdir = www-%s % datetime.now().strftime(%y-%m-%d_%H.%M.%S) # 删除已有的tar文件: run(rm -f %s % _REMOTE_TMP_TAR) # 上传新的tar文件: put(dist/%s % _TAR_FILE, _REMOTE_TMP_TAR) # 创建新目录: with cd(_REMOTE_BASE_DIR): sudo(mkdir %s % newdir) # 解压到新目录: with cd(%s/%s % (_REMOTE_BASE_DIR, newdir)): sudo(tar -xzvf %s % _REMOTE_TMP_TAR) # 重置软链接: with cd(_REMOTE_BASE_DIR): sudo(rm -f www) sudo(ln -s %s www % newdir) sudo(chown www-data:www-data www) sudo(chown -R www-data:www-data %s % newdir) # 重启Python服务和nginx服务器: with settings(warn_only=True): sudo(supervisorctl stop awesome) sudo(supervisorctl start awesome) sudo(/etc/init.d/nginx reload) 注意 run() 函数执行的命令是在服务器上运行，with cd(path) 和 with lcd(path) 类似，把当前目录在服务器端设置为 cd() 指定的目录。如果一个命令需要 sudo 权限，就不能用 run()，而是用 sudo() 来执行。 配置 Supervisor上面让 Supervisor 重启 awesome 的命令会失败，因为还没有配置 Supervisor 呢。 编写一个 Supervisor 的配置文件 awesome.conf，存放到 /etc/supervisor/conf.d/ 目录下： [program:awesome]command = /srv/awesome/www/app.pydirectory = /srv/awesome/wwwuser = www-datastartsecs = 3redirect_stderr = truestdout_logfile_maxbytes = 50MBstdout_logfile_backups = 10stdout_logfile = /srv/awesome/log/app.log 配置文件通过 [program:awesome] 指定服务名为 awesome，command 指定启动 app.py。 然后重启 Supervisor 后，就可以随时启动和停止 Supervisor 管理的服务了： $ sudo supervisorctl reload$ sudo supervisorctl start awesome$ sudo supervisorctl statusawesome RUNNING pid 1401, uptime 5:01:34 配置 NginxSupervisor 只负责运行 app.py，还需要配置 Nginx。把配置文件 awesome 放到 /etc/nginx/sites-available/ 目录下： server listen 80; # 监听80端口 root /srv/awesome/www; access_log /srv/awesome/log/access_log; error_log /srv/awesome/log/error_log; # server_name awesome.liaoxuefeng.com; # 配置域名 # 处理静态文件/favicon.ico: location /favicon.ico root /srv/awesome/www; # 处理静态资源: location ~ ^\\/static\\/.*$ root /srv/awesome/www; # 动态请求转发到9000端口: location / proxy_pass http://127.0.0.1:9000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 然后在 /etc/nginx/sites-enabled/ 目录下创建软链接： $ pwd/etc/nginx/sites-enabled$ sudo ln -s /etc/nginx/sites-available/awesome . 让 Nginx 重新加载配置文件，不出意外，的 awesome-python3-webapp 应该正常运行： $ sudo /etc/init.d/nginx reload 如果有任何错误，都可以在 /srv/awesome/log 下查找 Nginx 和 App 本身的 log。如果 Supervisor 启动时报错，可以在 /var/log/supervisor 下查看 Supervisor 的 log。 如果一切顺利，可以在浏览器中访问 Linux 服务器上的 awesome-python3-webapp 了 如果在开发环境更新了代码，只需要在命令行执行： $ fab build$ fab deploy 自动部署完成！刷新浏览器就可以看到服务器代码更新后的效果。","categories":["2.语言","Python"]},{"title":"利用chardet识别文件编码","path":"/2024/04/04/2-语言-Python-利用chardet识别文件编码/","content":"常见编码格式 ASCII, UTF-8, UTF-16 (2 variants), UTF-32 (4 variants)Big5, GB2312, EUC-TW, HZ-GB-2312, ISO-2022-CN (Traditional and Simplified Chinese)EUC-JP, SHIFT_JIS, CP932, ISO-2022-JP (Japanese)EUC-KR, ISO-2022-KR (Korean)KOI8-R, MacCyrillic, IBM855, IBM866, ISO-8859-5, windows-1251 (Cyrillic)ISO-8859-5, windows-1251 (Bulgarian)ISO-8859-1, windows-1252 (Western European languages)ISO-8859-7, windows-1253 (Greek)ISO-8859-8, windows-1255 (Visual and Logical Hebrew)TIS-620 (Thai) 测试代码 import chardetopen_file = open(file=miui.cpp,mode=rb) # 以二进制模式读取文件data = open_file.read() # 获取文件内容print(data) open_file.close() # 关闭文件result = chardet.detect(data) # 检测文件内容print(result) #encoding: utf-8, confidence: 0.99, language: 输出结果 encoding: utf-8 表示检测到文件的编码格式为utf-8confidence: 0.99 表示可信度为百分之九十九language: 表示文件内容的语言","categories":["2.语言","Python"]},{"title":"学习路线","path":"/2024/04/03/2-语言-Python-学习路线/","content":"Python 自学计划Python 的主体内容大致可以分为以下几个部分： 1. 面向过程面向过程编程是 Python 的基础组成部分，这一部分涵盖了基本的表达式、条件语句（如 if 语句）、循环结构（如 for 和 while 循环）以及函数的定义与使用。如果有任何编程语言的基础，特别是像 C 语言这样的语言，这一部分内容就会显得比较直观。例如，循环结构可以用来处理重复任务，而函数则帮助组织代码，避免重复。例如，一个简单的函数可以轻松地计算两个数字的和： def add(a, b): return a + b 如果没有编程的基础，建议从一本基础性参考书开始学习，例如《Python Programming》。这本书的内容通俗易懂，面向计算机导论，读者不需要有编程经验也能顺利入门。 2. 面向对象在 Python 中，面向对象编程是另一个重要的概念，涉及到基本的面向对象概念，比如类、对象、方法、属性和继承等。Python 是一种面向对象的语言，强调”一切皆对象”。与 Java 和 C++ 不同，Python 的面向对象机制相对松散，意味着学习者可以更灵活地进行创造和修改。 例如，定义一个类可能是这样的： class Animal: def __init__(self, name): self.name = name def speak(self): return fself.name says hello. 松散的结构使得学习和维护代码变得简单，但也会带来一定的灵活性，容易让初学者犯错。因此，在使用面向对象编程时，需要注意如何管理和维护自己的代码。 3. 应用功能Python 的应用功能包括输入输出（IO）、数据容器如列表（list）和字典（dictionary）、内置函数、模块和格式化字符串等。这些概念在其他编程语言中也同样存在，具有很强的实用性和可移植性。例如，字典是一种灵活的数据结构，可以使用键值对的方式存储数据，这样可以通过键快速访问到对应的值： person = name: Alice, age: 30print(person[name]) # 输出: Alice 这些应用功能使得 Python 成为一个高效和易于使用的编程语言，适合开发各种类型的应用。 4. 高级语法Python 还提供了一些高级语法，如上下文管理器、列表推导、函数式编程、装饰器和特殊方法等。这些高级功能虽然不是学习 Python 的必需，但它们使编程更加简洁和优雅。例如，列表推导能够在一行中实现复杂的列表创建，相较于传统的循环使用，能够减少代码量，提高可读性： squares = [x**2 for x in range(10)] 这里，仅用一行代码就生成了从 0 到 9 的平方列表，这在用传统的 for 循环时需要更多的行数。 Web 开发方向 阅读资料: 完成《简明 Python 教程》。这本书以清晰易懂的语言为初学者介绍 Python 的基本概念和语法结构，适合初次接触编程的读者。 适应开发环境: 安装 Python 最新版本，并设置好开发环境（推荐使用 Anaconda 或直接安装 Python）。熟悉基本的命令行操作（例如创建虚拟环境、安装包等），为后续项目打下基础。 项目目标: 编写一个简单的网络爬虫。 必学模块: re: 学习正则表达式，用于提取网页内容（例如获取网页中的特定信息）。 urllib2: 处理 URL 请求与 HTTP 响应，从而获取网页数据。 sqlite3: 了解如何使用 SQLite 数据库存储抓取的数据。 threading 和 Queue: 实现多线程爬取，提高抓取效率和速度。 实施细节: 学习如何使用正则表达式分析抓取到的数据，举例来说，可以从文章中提取出标题、作者及发布时间。 实现程序自动重启功能，当获取数据的请求失败时可以自动继续，确保爬虫的持续抓取的稳定性和有效性。 选择框架: 学习 Flask 或 webpy 等轻量级 Web 开发框架。这些框架易于上手，并且具有丰富的文档支持，适合初学者进行实践。 数据库接口: 掌握如何连接和操作 SQLite 数据库，以便在的 Web 应用中存储和检索数据。 项目实例: 开发一个简单的 Web 应用，如博客，至少实现以下功能： 用户可以注册和登录。 用户可以发表新文章。 用户可以查看已有文章的列表，并点击进入查看详细内容。 项目功能实施: 基于前面的学习，给的 Web 应用增加一个小功能，比如评论功能，用户能在文章下方留下评论。 测试与上线: 测试包括单元测试、集成测试等，确保应用程序的稳定性和正确性。 理解基本的部署流程（如使用 Heroku 或 VPS 来上线的应用），让的项目从开发环境转变为生产环境。 算法与数据结构在 Python 中，常用的数据结构包括 list、tuple、set、frozenset 和 dict，以及 collections 模块中的 OrderedDict、defaultdict、deque、namedtuple 和 Counter 等。特别是对这些数据结构的特性和使用场景进行深入理解，可以帮助在不同的编程任务中选择合适的工具，从而提高代码的效率。 例如，了解当需要一个可变的、有序的数据集合时，可以使用 OrderedDict，而在需要一个无重复元素的集合时，应选择 set。此外，掌握基本的算法思想，如递归、二分查找等，可以帮助编写出高效且易用的代码。如果想通过实践来加深理解，推荐在 ACM 竞赛平台或 LeetCode 等网站上进行刷题训练。 Python 与数据库在网站业务的后端，主流的数据库类型有三种：关系型数据库（如 MySQL）、文档型数据库（如 MongoDB）以及内存型数据库（如 Redis）。这些数据库各自具有不同的优势和适用场景。作为后端程序员，了解如何灵活使用这些数据库以及它们各自的特点至关重要，尤其是 MySQL 和 Redis。 SQLiteSQLite 是一个轻量级的数据库，引入了简便的文件存储方式，适合快速开发和小型应用。可以参考 SQLite Python Tutorial 来掌握基础知识。《The Definitive Guide to SQLite》是一本深入解析 SQLite 的书籍，适合需要更高效使用该数据库的开发者。 在使用 SQLite 3 时，了解一些基本的命令和操作是至关重要的。可以通过阅读 SQLite Documentation 来获取相关信息。 MySQLMySQL 是一种流行的关系数据库，对于需要进行大数据量存储和操作的应用尤为合适。想要接触 MySQL 的开发者可查阅 Python MySQL Database Access 的教程。 MongoDBMongoDB 作为 NoSQL 的一员，因其灵活的数据模型而受到广泛欢迎。对于熟悉 SQL 的开发者，学习 MongoDB 的门槛相对较低。推荐阅读 MongoDB官方文档 进行入门。两个常用的 Python 驱动是： PyMongo - 提供了类似 Mongo Shell 的接口，便于实现 MongoDB 的各种操作。 MongoEngine - 作为 MongoDB 的 ORM 框架，它把数据模型转化为 Python 对象，通用性和易用性较高。 RedisRedis 是一个基于内存的高性能键值存储数据库。虽然 Redis 需要一定的学习成本，但它能带来显著的性能提升，尤其在实时应用中。入门推荐阅读 The Little Redis Book。常用的 Python 客户端驱动包括： redis-py - 官方支持的 Redis Python 客户端。 更多客户端选择可以参考 Redis Clients。 Python 的 Web 框架Python 拥有众多 Web 框架供开发者选择，适合不同类型的项目。可以在 Python Web Frameworks 中一览这些框架优势。如果找不到合适的框架，也可以考虑基于自己的需求开发一个。这些框架之所以如此繁多，反映了 Python 社区的活跃和多样化。 web.pyweb.py是一个简约而强大的 Python Web 框架。它被公开归属，意味着可以将其用于任何目的，而不受限制。 项目链接: 在线 demo 创始人: Aaron Swartz 的博客【在 GitHub 上有分享】。 FlaskFlask是一个轻量级的 Web 应用框架，基于 Werkzeug WSGI 工具包和 Jinja2 模板引擎。它采用 BSD 许可，因此允许自由使用和修改。Flask 被称为微框架，因为它核心部分简单但可扩展。 实战教程: Flask Mega-Tutorial TornadoTornado是一个异步框架，最初在 FriendFeed 开发，之后在 Facebook 收购后开源。Tornado 是一个 Python web 框架和异步网络库，非常适合构建高性能的非阻塞实时 Web 应用。如果希望的 Web 应用具有高并发的能力，Tornado 将是一个不错的选择。 项目链接: Tornado on GitHub DjangoDjango是一个高级 Python Web 框架，旨在鼓励快速开发以及干净、务实的设计。作为一个全栈式框架，Django 拥有许多内置组件，确保快速构建可靠的 web 应用。 资料链接: Django 资料","categories":["2.语言","Python"]},{"title":"安装","path":"/2024/04/02/2-语言-Python-安装/","content":"源码安装打开终端，使用以下命令更新软件包列表： sudo apt update 安装编译 Python 3.10 所需的依赖项： sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码并进入解压后的目录： tar -xf Python-3.10.0.tgzcd Python-3.10.0 配置 Python 3.10 的编译选项： ./configure --enable-optimizations 编译并安装 Python 3.10： make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。 安装时网络问题见 pip下载网络问题","categories":["2.语言","Python"]},{"title":"爬虫","path":"/2024/04/01/2-语言-Python-爬虫/","content":"ScrapyScrapy 是一个开源的爬虫框架，特别适合用于提取网络数据。它通过异步网络请求提高了爬取效率，常用于网络抓取、数据挖掘等任务。Scrapy 的强大之处在于其模块化设计，便于扩展和定制。比如，可以快速定制爬取规则，存储抓取的数据，或是构建复杂的爬虫项目。 BeautifulSoupBeautifulSoup 是一个用于解析 HTML 和 XML 文档的库，对于处理网页抓取中常见的文件结构非常有效。它提供很方便的 API 来搜索和操作解析结果，比如通过 tags 和 CSS Selectors 直接找到网页中的特定元素。例如，可以使用如下方式提取一个 p 标签中的文本内容： from bs4 import BeautifulSouphtml_doc = htmlbodypHello, World!/p/body/htmlsoup = BeautifulSoup(html_doc, lxml)print(soup.p.text) # 输出: Hello, World! MechanizeMechanize 是一个用于自动化 Web 表单的 Python 库，支持模拟用户行为，如填写表单、点击链接等。它允许脚本自动处理各种状态和返回的数据。比如，可以使用 Mechanize 登陆一个需要身份验证的网站，输入用户名和密码，提交表单并访问受保护的页面。 SeleniumSelenium 是一个流行的 Web 测试自动化框架，能够控制浏览器进行各种测试和自动化任务。它特别适用于处理 JavaScript 渲染的网页，因为它仿佛是真正的用户在操作浏览器。通过 Selenium，可以模拟点击、滚动等操作，甚至可以等待特定的元素出现在页面上。以下是一个简单的例子，用于打开网页并等待某个元素： from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECdriver = webdriver.Chrome()driver.get(http://example.com)try: element = WebDriverWait(driver, 10).until( EC.presence_of_element_located((By.TAG_NAME, h1)) ) print(element.text)finally: driver.quit() 变量在 Python 中，变量可以存储不同类型的数据，包括数字、字符串、列表、元组和字典： 数字：可以是整数或浮点数（如 age = 30）。 字符串：文本数据（如 name = Alice）。 列表：有序集合（如 fruits = [apple, banana, cherry]）。 元组：不可变的有序集合（如 coordinates = (10.0, 20.0)）。 字典：键值对集合（如 person = name: Alice, age: 30）。 函数在 Python 中，函数是一段封装的代码，用于执行特定的任务，如计算和数据处理。可以自定义函数来实现复杂的功能并提高代码的复用性。 循环体循环体允许重复执行一段代码。Python 提供了 for 循环和 while 循环。例如，使用 for 循环迭代一个列表： fruits = [apple, banana, cherry]for fruit in fruits: print(fruit) 网页的构成网页一般由 HTML、CSS 和 JavaScript 构成： HTML：提供网页的基本结构，包含如 p, div, ul, img, h1, a href= 等标签。 CSS：用于样式设计，控制颜色、字型和布局。 JavaScript：提供交互功能。 网页的整体结构通常可分为三个部分： header：通常包含网站的标题和导航菜单。 content：网页的主要内容区域，存放文本、图片等。 footer：页面底部的额外信息，如版权声明和链接。 在 HTML 中，head 标签包含诸如元数据和链接到 CSS 文件等信息，通常用户看不见。而 body 标签则包含网页的可见内容。 解析网页中的元素信息网页数据的解析可以借助各种工具和库来实现。 BeautifulSoup 用于解析网页，其底层可以使用 lxml 或 html.parser。 选择器： CSS Selector: 例如，body div:nth-child(1) img 可以精确选择第一个 div 标签中的图片。 XPath: 例如，/html/body/div[1]/img 提供另一种选择路径语法。 Request进行 HTTP 请求时，主要有以下几种方法： GET：用于请求数据，常用于获取页面。 POST：用于提交数据，如登录操作。 PUT 和 DELETE：用于更新和删除数据，通常在 RESTful API 中使用较少。 使用 requests 库可以轻松发送这些请求： import requestsresponse = requests.get(http://example.com) 第三方库Python 拥有丰富的第三方库，便于用户进行网络请求及数据处理，比如： requests：用于发起网络请求。 BeautifulSoup：用于解析 HTML 和 XML。 Selenium：用于自动化浏览器操作。 在进行网络爬虫时，伪装成浏览器进行访问非常重要，通常会设置 User-Agent 以避免阻止请求。 黑客攻击模块Python 的优势之一是它拥有许多库支持网络安全研究与黑客攻击。比如： pydbg：用于调试和操控进程。 scapy：用于网络包分析和生成。 sqlmap：用于检测和利用 SQL 注入漏洞。 httplib：用于 HTTP 请求的处理。 这些库被广泛应用于信息安全领域，帮助研究人员和开发者探测潜在的网络漏洞。 能够访问各种 APIPython 的 ctypes 库允许黑客访问 Windows、OS X、Linux 和其他操作系统提供的动态链接库和共享库。这种能力使得开发者可以创建跨平台的攻击脚本，利用各种系统提供的 API 进行深层次的交互。 黑客攻击工具与 Python许多常用的黑客攻击工具都提供了 Python API，以便于高级用户进行自定义扩展。最具代表性的包括： sqlmap：自动化 SQL 注入和数据库接管。 Nmap：用于网络探测和安全审计。 Metasploit：渗透测试框架，包含大量的攻击模块。 通过 Python，这些工具可以被整合，并根据具体需要进行强大的自定义，极大提升了攻击的灵活性和效率。","categories":["2.语言","Python"]},{"title":"笔记","path":"/2024/03/29/2-语言-Python-笔记/","content":"Python 是一种面向对象的解释型计算机程序设计语言，可以处理系统运维、图形处理、数学处理、文本处理、数据库编程、网络编程、web 编程、多媒体应用、pymo 引擎、黑客编程、爬虫编写、机器学习、人工智能等等。 基础入门Python 基础Python 简介Python 安装语法格式与编码规范Python 包管理及其版本管理工具的使用模块导入在 Python 中，可以导入各种模块来扩展功能，以下是导入模块的几种方式： 导入整个模块: import module1, module2 从模块中仅导入特定的函数、类或变量: from modname import name1 需要注意，导入的模块必须位于可执行程序的同一目录下，或者该模块应在 Python 的系统路径中。 类型与运算（包括容器以及容器的访问使用）Python 的字符串List，set，Dict，tuple 等类型（包括访问、添加、删除等超作）切片列表推倒生成器迭代器和解析语句与语法以及文件操作常用关键字运算符和基本运算（位运算）赋值、表达式以及输入输出输入处理与错误检查在 Python 中，当通过 input() 函数读取输入时，得到的数据类型为字符串（str）。例如，执行以下代码： birth = input(birth: )if birth 2000: print(00前)else: print(00后) 假设用户输入 1982，程序将引发如下错误： Traceback (most recent call last): File stdin, line 1, in moduleTypeError: unorderable types: str() int() 这个错误的原因在于字符串类型无法直接与整数进行比较。为了避免这个问题，需要将输入的字符串转换为整型，使用 int() 函数。修改后的代码如下： s = input(birth: )birth = int(s)if birth 2000: print(00前)else: print(00后) 重新运行这段代码后，如果输入 1982，程序会正确输出 00前。但如果输入一个非数字的字符串，例如 abc，将会遇到另一个类型的错误： Traceback (most recent call last): File stdin, line 1, in moduleValueError: invalid literal for int() with base 10: abc 这表示 int() 函数无法将字符串 abc 转换为一个整数，程序因此崩溃。要解决这个问题，可以实现错误检查机制。 异常处理Python 允许使用 try 语块来测试可能发生异常的代码，而在发生异常时，代码会跳转到 except 块处理相应的错误，格式如下： try: # 测试语句except [ExceptionType]: # 处理异常的代码 语句条件判断Python 的条件判断依赖于缩进的规则。如果 if 语句的条件为 True，紧接着的缩进语句将会被执行；如果条件为 False，则执行 else 语句块中的内容。示例代码如下： if birth 2000: print(00前)else: print(00后) 务必记得在条件后添加冒号（:）。除此之外，当需要进行更复杂的条件判断时，可以使用 elif 语句，表示”否则如果”。完整形式如： if condition1: action1elif condition2: action2elif condition3: action3else: action4 if 语句从上到下进行判断。一旦找到一个为 True 的条件，相应的动作被执行后，其余条件将被忽略。 if x: print(True) 在此示例中，只要 x 是非零值、非空字符串或非空列表，判断结果即为 True；否则为 False。 循环循环使计算机能够高效地执行重复性任务，Python 支持两种基本循环：for...in 循环和 while 循环。 1. for...in 循环 这种循环结构用于遍历列表或元组中的每个元素。例如： names = [Michael, Bob, Tracy]for name in names: print(name) 在此代码中，for 循环会将 names 列表中的每个名字依次赋值给变量 name，并执行缩进代码块。 如果想计算 1 到 10 的整数之和，可以使用如下代码： sum = 0for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]: sum = sum + xprint(sum) 要计算从 1 到 100 的整数之和，可以借助 range() 函数，该函数生成一个整数序列，并用 list() 函数转换为列表： list(range(5)) # 输出 [0, 1, 2, 3, 4] 要计算 1 到 100 的整数之和，可以使用： total = sum(range(101)) # 输出 5050 2. while 循环 while 循环会在条件为真时持续执行，条件为假时退出。例如，想计算 100 以内所有奇数之和，可以写： sum = 0n = 99while n 0: sum = sum + n n = n - 2print(sum) 此处，变量 n 每次循环后都会减少 2，直到其不再满足 while 条件为止。 提前退出和跳过1. break 语句 break 可用于提前结束循环。例如： n = 1while n = 100: if n 10: break print(n) n = n + 1print(END) 执行上述代码时，将打印出 1 至 10 后，紧接着显示 END，显示 break 的效果是立即退出循环。 2. continue 语句 continue 使程序跳过当前循环，直接进行下一次循环。例如，若只想打印 1 到 10 之间的奇数，可以这样处理： n = 0while n 10: n = n + 1 if n % 2 == 0: continue print(n) 运行后，输出为 1, 3, 5, 7, 9，表明 continue 跳过了所有的偶数输出。 函数以及函数式编程入门函数基础作用域参数与返回值（多返回值、默认参数等）高阶函数一个函数可以接收另一个函数作为参数，这样的函数被称为高阶函数。高阶函数在函数式编程中占据着重要的地位，它使得函数的使用更加灵活多变。 函数 map()map() 函数是一个常用的高阶函数，它接受两个参数：一个是函数，另一个是可迭代对象（Iterable）。map() 将指定的函数应用于序列中的每一个元素，并返回一个迭代器。 需要注意的是，map() 返回的是一个生成器（Iterator），因此要提取结果，必须使用 for 循环、next() 函数，或者通过将其转换为列表（list）来实现。 示例： def f(x): return x * x # 定义一个函数 f(x)，返回 x 的平方r = map(f, [1, 2, 3, 4, 5, 6]) # 使用 map 函数将 f(x) 应用于 [1, 2, 3, 4, 5, 6] 列表的每个元素print(print(r), r) # 直接打印 r，得到的是 r 变量指向的地址# 输出示例：print(r) map object at 0x02658A30print(list(r) = , list(r)) # 将 r 转换为列表并打印# 输出示例：list(r) = [1, 4, 9, 16, 25, 36]# 使用 for 循环逐个输出for n in r: print(n)# 输出：# 1# 4# 9# 16# 25# 36 示例提取方式 使用 for 循环输出每个元素：先将生成器用于 for 循环，逐个打印出平方的结果。值得注意的是，一旦生成器被遍历后，它就无法再次使用。 使用 next() 函数逐个提取： while True: try: print(next(r)) except StopIteration as e: print(e.value) break# 输出：# 1# 4# 9# 16# 25# 36# None 函数 reduce()reduce() 函数用于将一个二元函数作用于一个序列，并通过逐步迭代计算出最终结果。它需要传入两个参数：一个是具有两个参数的函数，另一个是可迭代对象。reduce() 的工作机制是将计算结果不断地应用于累积值和序列的下一个元素。 公式为： reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 示例 1： from functools import reduce # 需要引入 functools 库def f(x, y): return x * y # 定义一个函数，返回两个数的乘积# 将函数 f 作为参数传入 reduce 函数print(reduce(f, [1, 2, 3, 4])) # 输出结果# 输出示例：24 解析： 第一步：计算 f(1, 2)，输出结果为 1 * 2 = 2。 第二步：将第一步的输出值 2 当作第一个参数，执行 f(2, 3)，输出结果为 2 * 3 = 6。 第三步：在前一步的基础上，计算 f(6, 4)，得到结果 6 * 4 = 24。 示例 2： def MySum(x, y): return x + y # 定义一个函数，返回两个数的和print(reduce(MySum, [1, 2, 3, 4, 5])) # 输出结果为 1 + 2 + 3 + 4 + 5# 输出示例：15 在这个示例中，reduce(MySum, [1, 2, 3, 4, 5]) 的计算过程相当于： 1 + 2 3 3 + 3 6 6 + 4 10 10 + 5 15 递归匿名函数：lambda函数式编程工具：filter 和 reduce文件操作文本文件、二进制文件读写文件和目录操作序列化与反序列化模块与面向对象模块代码编写基础类代码编写基础多线程、Re 正则表达式的使用多线程Python 的多线程技术在 IO 密集型任务中表现优越，但在计算密集型任务中却受限于全局解释器锁的影响。因此，针对不同的任务类型，开发者需要在多线程和其他并行处理技术（如 multiprocessing 模块或异步编程）之间做出明智的选择。这会确保应用程序能够平衡性能和资源使用，达到最佳效果。 执行控制执行 Python 代码的过程是由 Python 虚拟机（Python Virtual Machine, PVM）负责的。在这个环境中，尽管可以同时创建多个线程，但实际上在任意时刻只有一个控制线程在运行。这种行为源于 Python 的设计使得每个线程都需要通过全局解释器锁（Global Interpreter Lock, GIL）来访问解释器，确保每个时刻只有一个线程在执行 Python 字节码。 GIL 的作用全局解释器锁（GIL）是一个机制，用于确保在同一时间只有一个线程可以执行 Python 字节码。这个锁防止了线程之间的竞争条件，但也带来了性能上的限制。具体的执行流程如下： 设置 GIL：当一个线程准备执行代码时，首先会获取 GIL，确保其它线程无法执行字节码。 切换进线程：一旦获得 GIL，该线程可以开始运行。 执行以下操作之一： 运行一个指定数量的字节码指令，这意味着它会执行具体的代码行。 线程主动让出控制权，如果线程进入休眠或等待状态。 切换出线程：若线程请求 IO 操作或出现阻塞，这个线程会放弃 GIL，进入休眠状态，让其他等待的线程有机会运行。 解锁 GIL：完成执行后，会释放 GIL，属于当前线程的运行控制权结束。 返回步骤 1：再次进入获取 GIL 的循环，等待下一个线程的执行。 IO 密集型与计算密集型在 IO 密集型操作中，如网络请求、文件读取等，线程在等待 IO 操作完成时会主动释放 GIL。这样，其他线程便可以利用这段时间执行他们的操作，提高了应用程序的整体效率。例如，当一个线程正在等待从服务器接收数据时，其他线程可以进行文件写入或读取，从而最大限度地提高了资源使用率。 相对而言，计算密集型操作，比如大量的数学计算或数据处理，由于线程在执行时会持续占有 GIL，因此即便有多个线程，它们并不能有效地并行处理任务。这通常会导致多线程效果不佳，反而增加了上下文切换的开销。 例如，假设在进行图像处理任务，每个线程都在进行复杂的像素计算。由于 GIL 的存在，这些线程不能充分利用多核 CPU 的并行计算能力，最终的执行速度比单线程情况下还要慢。 线程模块threading 模块的类与函数 类对象 Thread：执行线程 Timer：在指定时间后执行线程 Lock：原始锁（互斥锁） RLock：重入锁 Condition：条件变量 Event：事件变量 Semaphore：控制同时执行的线程数量 BoundedSemaphore：带边界的信号量 Barrier：所有线程在达到一定数量后才继续执行 函数 activeCount()：返回当前活动线程数量 currentThread()：返回当前线程对象 enumerate()：返回当前活动线程的列表 settrace(func)：为所有线程设置跟踪函数 setprofile(func)：为所有线程设置配置文件函数 stack_size(size=None)：获取或设置线程栈的大小 Thread 类的属性与方法在 threading 模块中的 Thread 类主要提供了一些常用的属性和方法： 属性 name：线程名称 ident：线程标识符 daemon：是否为守护线程 方法 __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None)：初始化线程 start()：开始执行线程 join(timeout=None)：阻塞，等待线程终止或超时 is_alive()：检查线程是否存活 isDaemon()：检查线程是否为守护线程 setDaemon(daemonic)：设置线程为守护线程 使用 Threading 模块创建线程Python 常用的多线程模块主要有 threading 和 Queue。在这里，将重点讨论 threading 模块的使用。 threading 模块中的 Thread 类是执行线程的主要对象。使用 Thread 类，可以通过几种方法创建线程。以下是最常用的三种方式： 创建 Thread 的实例，并传递给它一个可调用对象（函数或类的实例方法）。 通过派生 Thread 的子类，并创建子类的实例。 使用 callable 结合 args 参数传递额外的参数。 可调用对象（函数，类的实例方法）使用多线程首先，介绍如何创建一个 Thread 实例，并将函数传递给它作为可调用对象。下面是具体的实现步骤： 示例：创建 Thread 实例并传递给它一个函数 from threading import Threadfrom time import sleep, ctimedef func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime())# 创建 Thread 实例t1 = Thread(target=func, args=(第一个线程, 1))t2 = Thread(target=func, args=(第二个线程, 2))# 启动线程运行t1.start()t2.start()# 等待所有线程执行完毕t1.join() # join() 等待线程终止，如果不调用会导致主线程挂起t2.join() 在运行上述代码时，输出结果可能是： ---开始--- 第一个线程 时间 Fri Nov 29 11:34:31 2019---开始--- 第二个线程 时间 Fri Nov 29 11:34:31 2019***结束*** 第一个线程 时间 Fri Nov 29 11:34:32 2019***结束*** 第二个线程 时间 Fri Nov 29 11:34:33 2019 通过该示例可以看到，两个线程几乎同时开始，尽管线程一需要的时间短一些，但他们的开始时间非常接近。这表明多线程的确可以并行执行，节约了时间，总共运行约两秒，而如果按顺序运行会长达三秒，节省了约一秒。 在创建 Thread 实例时，需要接收 target 和 args（也可以是 kwargs）两个参数。target 用于接收需要使用多线程调用的对象，args 用于接收调用对象所需的参数，注意 args 接受的是元组，kwargs 接受的是字典。 注意： start() 方法启动线程的执行，而 join() 方法则会阻塞主线程，直到新线程完成执行。调用 join() 是可选的，只有在需要等待线程完成后再进行其他操作时才需要使用。 派生 Thread 的子类，并创建子类的实例除了创建线程的实例外，还可以通过继承 Thread 类来创建自定义线程。这样可以更好地封装线程逻辑，便利后续扩展。 示例：派生 Thread 的子类 from threading import Threadfrom time import sleep, ctime# 创建 Thread 的子类class MyThread(Thread): def __init__(self, func, args): :param func: 可调用的对象 :param args: 可调用对象的参数 Thread.__init__(self) # 别忘记调用 Thread 的初始化方法 self.func = func self.args = args def run(self): self.func(*self.args)def func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime())def main(): # 创建 Thread 实例 t1 = MyThread(func, (1, 1)) t2 = MyThread(func, (2, 2)) # 启动线程运行 t1.start() t2.start() # 等待所有线程执行完毕 t1.join() t2.join()if __name__ == __main__: main() 在此示例中，创建了一个 MyThread 类，它继承自 Thread。通过重载 run() 方法，将传递的可调用对象执行。在使用自定义子类后，线程的逻辑更加清晰和易于管理。 拓展：获取可调用对象的返回值在多线程的环境中，直接从子线程中获取返回值是不可行的。此时，可以通过在子类中添加属性来保存运行结果，并提供一个获取结果的方法。 示例：获取多线程中程序运行的结果 from threading import Threadfrom time import sleep, ctime# 创建 Thread 的子类class MyThread(Thread): def __init__(self, func, args): :param func: 可调用的对象 :param args: 可调用对象的参数 Thread.__init__(self) self.func = func self.args = args self.result = None def run(self): self.result = self.func(*self.args) def getResult(self): return self.resultdef func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime()) return secdef main(): # 创建 Thread 实例 t1 = MyThread(func, (1, 1)) t2 = MyThread(func, (2, 2)) # 启动线程运行 t1.start() t2.start() # 等待所有线程执行完毕 t1.join() t2.join() # 获取线程中程序的运行结果 print(t1.getResult()) print(t2.getResult())if __name__ == __main__: main() 在这个示例中，为 MyThread 类添加了一个 result 属性来存储运行结果，并提供了 getResult() 方法以供获取。这样可以轻松地获取每个线程的执行结果，也为以后的扩展留出了空间。 线程同步线程优先级队列（ Queue）网络编程什么是 Socket?requests 网络库的简介和使用Python 实践网络爬虫网络爬虫技术价值、简单的网络爬虫架构URI 管理器及其实现方法网页下载及其 urllib2、requests 的使用网页解析器和 BeautifulSoup 模块数据分析与机器学习库以及相关算法介绍数据分析库：NumpyScipyPandas机器学习库：Scikit-Learn数据可视化库：Matplotlib文本分析库：NLTK网络分析库：igraph","categories":["2.语言","Python"]},{"title":"网易云评论获取","path":"/2024/03/28/2-语言-Python-网易云评论获取/","content":"在使用 Ajax 技术加载数据的网站中，JavaScript 发起的 HTTP 请求通常需要带上参数，而且这些参数的值经过加密处理。如果们想使用网站的 REST API 来爬取数据，就必须首先了解其加密方式。整个过程需要通过抓包工具，仔细阅读和分析网站的 js 代码，这样可能会耗费一天甚至更长的时间。虽然这个过程繁琐，但们可以采用一些更为高效的方法来提取数据。一个可行的方法是使用 Selenium 库，这能够模拟浏览器行为，直接抓取所需的网页数据，提升们的工作效率。 实现目标本文将展示如何利用 Selenium 爬取网易云音乐中歌曲《Five Hundred Miles》的所有评论，然后将这些评论存储到 MongoDB 数据库中。 工具为了实现这个目标，们需要一些特定的工具。以下是所需的工具清单： Selenium: 这是一个 Web 应用程序自动化测试工具，能够模拟用户在浏览器中的操作，如打开页面、点击按钮等。它能够有效解决 JavaScript 渲染问题，使得们能获取动态加载的数据。 安装方法： pip install selenium Chrome 浏览器: 们将使用 Chrome 浏览器来进行抓取操作。 WebDriver: 这是 Selenium 控制浏览器的必要组件。因为使用的是 Chrome 浏览器，所以需要下载对应的 ChromeDriver。下载后需解压，并将其放到 Python 的 Scripts 文件夹中。 MongoDB: 网易云音乐的评论数量庞大，常常超过十万条，为了有效管理这些数据，们需要数据库进行存储。在此们选择使用 MongoDB。 pymongo: 这是 Python 访问 MongoDB 的库，安装同样采用 pip： pip install pymongo 爬取思路接下来的步骤将详细描述们的爬取逻辑： 启动 Selenium: 使用 Selenium 驱动 Chrome 浏览器，打开要爬取的页面。 计算评论分页数: 获取页面中”最新评论”标签后的评论总数，以此计算出总共的评论分页数。这可以通过将评论总数除以每页显示的评论数量（20 条）并向上取整来实现。 爬取数据: 首先爬取第一页的评论，然后将数据存储到 MongoDB。 分页处理: 利用 Selenium 模拟点击”下一页”按钮，继续抓取后续页面的评论数据，并存储。 循环迭代: 重复步骤 4，直到所有评论数据都被爬取完毕。 代码实现首先，们需要确定要爬取的歌曲《Five Hundred Miles》的 URL 地址，并调用爬取函数。 if __name__ == __main__: url = http://music.163.com/#/song?id=27759600 # Five Hundred Miles start_spider(url) 接下来，使用 Selenium 启动 Chrome 浏览器并访问指定页面： from selenium import webdriverimport timefrom math import ceilfrom selenium.webdriver.common.by import Bydef start_spider(url): 启动 Chrome 浏览器访问页面 brower = webdriver.Chrome() brower.get(url) # 等待5秒，确保评论数据加载完成 time.sleep(5) # 页面嵌套在一个 iframe 中，必须先切换到 iframe 才能定位其中的元素 iframe = brower.find_element(By.CLASS_NAME, g-iframe) brower.switch_to.frame(iframe) # 获取【最新评论】总数 new_comments = brower.find_elements(By.XPATH, //h3[@class=u-hd4])[1] max_page = get_max_page(new_comments.text) 然后定义一个函数，用于计算出总分页数： def get_max_page(new_comments): 根据评论总数, 计算出总分页数 print(=== + new_comments + ===) max_page = int(new_comments.split(()[1].split())[0]) # 每页显示20条最新评论 max_page = ceil(max_page / 20) print(一共有, max_page, 个分页) return max_page 接下来，可以开始循环爬取评论数据，初始时从第一页开始： current = 1is_first = Truewhile current = max_page: print(正在爬取第, current, 页的数据) if current == 1: is_first = True else: is_first = False data_list = get_comments(is_first, brower)def get_comments(is_first, brower): 获取评论数据 items = brower.find_elements(By.XPATH, //div[@class=cmmts jflag]/div[@class=itm]) # 首页包含15条精彩评论与20条最新评论，只需保留最新评论 if is_first: items = items[15:] data_list = [] for each in items: data = # 获取用户昵称、评论内容等信息 userId = each.find_element(By.XPATH, ./div[@class=head]/a).get_attribute(href).split(=)[1] nickname = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[1]/div[1]/a).text content = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[1]/div[1]).text.split(：)[1] like = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[@class=rp]/a[1]).text like = like.strip().split(()[1].split())[0] if like else 0 avatar = each.find_element(By.XPATH, ./div[@class=head]/a/img).get_attribute(src) data.update( userId: userId, nickname: nickname, content: content, like: like, avatar: avatar ) print(data) data_list.append(data) return data_list 最后，将爬取到的评论数据存储到 MongoDB 中，并模拟点击”下一页”按钮： save_data_to_mongo(data_list)def save_data_to_mongo(data_list): 一次性插入20条评论，以提高插入效率，降低数据丢失风险 collection = db_manager[MONGO_COLLECTION] try: if collection.insert_many(data_list): print(成功插入, len(data_list), 条数据) except Exception: print(插入数据出现异常)# 模拟点击下一页按钮time.sleep(1)go_nextpage(brower)def go_nextpage(brower): 模拟人为操作, 点击【下一页】 next_buttons = brower.find_elements(By.XPATH, //div[@class=mcmmt]/div[3]/div[1]/a) if next_buttons and next_buttons[-1].text == 下一页: next_buttons[-1].click() 扩展访问普通网站的整个过程： 们访问使用 Ajax 加载数据的网站的整个过程：","categories":["2.语言","Python"]},{"title":"设置flask后端CORS跨域访问","path":"/2024/03/27/2-语言-Python-设置flask后端CORS跨域访问/","content":"设置前后端分离 环境搭建flask 项目地址 https://tutorial.helloflask.com/ 安装 flask 和 flask-cors cors 用于允许服务器进行跨域访问 pip install flaskpip install flask-cors 浏览器 js 前端代码function SendUrlToServer(url, method)\tlet requestUrl = http://124.222.246.202:8081/fetch-sub-url?url=+url;\t/*let requestUrl = ?url=http://127.0.0.1:8081/fetch-sub-url*/\tfetch(requestUrl, method: method,\theaders: Content-Type: application/json\t,\t/*body: JSON.stringify( url: url )*/\t).then(response = response.text()).then(data = console.log(Response from server:);).catch(error = console.error(Error sending data:, error););function RSS() SendUrlToServer(https://rsshub.app/bilibili/ranking/0/3/1, GET); 服务器端 python 代码from flask import Flask, request, jsonifyfrom flask_cors import CORSimport requestsimport feedparser##get python pathimport ospython_path = os.environ.get(PYTHONPATH)print(PYTHONPATH:, python_path)##get endapp = Flask(__name__)#CORS(app, resources=r/*: origins: http://127.0.0.1:80) # 允许指定的来源访问CORS(app)@app.route(/fetch-sub-url, methods=[GET,POST])def fetch_sub_url(): #data = request.get_json() #url = data.get(url) #url = https://www.baidu.com url = request.args.get(url) print (current url is ===+url) try: response = requests.get(url) response_text = response.text return response_text except requests.exceptions.RequestException as e: return jsonify(error: str(e)) # 解析RSS feed #feed = feedparser.parse(url) # 打印feed的标题 #print(Feed Title:, feed.feed.title) # 打印feed中的条目 #for entry in feed.entries: # print( Title:, entry.title) # print(Link:, entry.link) # print(description:, entry.description) #return feedif __name__ == __main__: app.run(host=0.0.0.0, port=8081) 后端服务开机自启 systemdetcsystemdsystem 启动 [Unit]Description=Start Python BackEnd With HtmlAfter=multi-user.target[Service]WorkingDirectory=/home/ubuntuType=idle#ExecStart=/home/ubuntu/html/BackEnd/start_backend.shExecStart=/usr/bin/python3 /home/ubuntu/html/BackEnd/main.pyUser=ubuntuGroup=ubuntuEnvironment=PYTHONPATH=/home/ubuntu/.local/lib/python3.10/site-packages[Install]WantedBy=multi-user.target 将服务单元文件复制到 systemd 目录： 将的服务单元文件复制到etcsystemdsystem目录下。可以使用 sudo 命令进行拷贝，确保文件的权限设置正确。 sudo cp your-service-name.service /etc/systemd/system/ 重新加载 systemd 配置： 需要重新加载 systemd 配置以使更改生效。 sudo systemctl daemon-reload 启用服务： 要启用服务，使其在系统启动时自动启动，可以运行以下命令： sudo systemctl enable your-service-name.service 这将会在适当的运行级别下创建符号链接，以便服务在系统启动时自动启动。 启动服务： 如果想立即启动服务，可以运行以下命令启动服务 sudo systemctl start your-service-name.service 完整后端处理代码： from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonimport socketimport asynciofrom aiohttp import web# root_dir = /home/ubuntu/html/# pic_dir = 0.res/Picture/# name = 1#request.args.get(id)# act_addr = os.path.join(root_dir,pic_dir,name);# fileNameList = # for file_name in os.listdir(act_addr):# fileNameList += pic_dir+name+/+file_name# print(fileNameList)app = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[http://124.222.246.202,http://127.0.0.1])HOME_PATH = /home/ubuntu/BlogData/#@app.route(/, methods=[GET])#def home_index():# index_html = open(/home/ubuntu/liuluhua.github.io/index.html, r)# print (文件名: , index_html.name)# print (是否已关闭 : , index_html.closed)# print (访问模式 : , index_html.mode)# return index_html.read()@app.route(/get_ip, methods=[GET])def ip_addr(): ip_addr = request.remote_addr api_url = fhttps://ipinfo.io/ip_addr/json response = requests.get(api_url) data = response.json() ret_data = 来自+data.get(country)+ +data.get(region)+的+data.get(ip)+朋友; return ret_data@app.route(/get_picture, methods=[GET])def picture_show(): pic_dir = 0.res/Picture/ name = request.args.get(id) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = for file_name in os.listdir(act_addr): fileNameList += fimg src=pic_dirname/file_name alt=file_name print(file_name) print (fileNameList) return (fileNameList)@app.route(/getFileContent, methods=[POST])def getFileContent(): filePath = request.get_json().get(filePos) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(/getFileList, methods=[POST])def getFileList(): #return json.dumps(request.get_json()) + getDirList(HOME_PATH+Python); return getDirList(HOME_PATH+Python);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(detailssummaryspan class=tree-item) ret_list.append(entry.name+/span/summary) getDirList(entry.path, ret_list, depth+1) ret_list.append(/details) else: file_pos = dir_path.replace(/home/ubuntu/html,) ret_list.append(fdetailssummary \\ span class=tree-item onclick=openFile(\\file_pos/entry.name\\) + entry.name+/summary/details) return .join(ret_list)@app.route(/signin, methods=[POST])def signin(): print(post signin) username = request.form.get(username) password = request.form.get(password) button_clicked = request.form.get(signin) # 或者使用 signup #jsonify(response: test) # 确定哪个按钮被点击了 if button_clicked == signin: # 处理登录操作 return fLogin: Username=username, Password=password elif button_clicked == signup: # 处理注册操作 return fSignup: Username=username, Password=password else: # 没有按钮被点击或者未知按钮名称 return Unknown button pressed@app.route(/wechat, methods=[GET])def wechat_signature(): data = request.args echostr = data.get(echostr) signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) if not signature or not timestamp or not nonce: return False tmp_str = .join(sorted([******, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(UTF-8)).hexdigest() if tmp_str == signature: return echostr else: print(Failed) return Failed@app.route(/wechat, methods=[POST])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是不是文本 if text == req.get(MsgType): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = ToUserName:req.get(FromUserName), FromUserName:req.get(ToUserName), CreateTime:int(time.time()), MsgType:text, Content:req.get(Content) # 把构造的字典转换成xml格式 xml = xmltodict.unparse(xml:resp) # print(req.get(Content)) # 返回数据 return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml:resp) return xmlif __name__ == __main__: app.run(host=127.0.0.1, port=9080)","categories":["2.语言","Python"]},{"title":"资料","path":"/2024/03/26/2-语言-Python-资料/","content":"0. GitHubGitHub 拥有丰富的开源项目，用户可以找到大量的 Python 库和工具，例如 Pipenv，它能有效地管理 Python 项目的依赖和虚拟环境。 1. Python Code ExamplesPython Code Examples 是一个极好的在线资源，提供多种 Python 代码示例。在这个网站上，学习者可以通过搜索具体的功能实现，找到相关的代码范例进行参考。在面对特定问题时，查找相关示例并进行模仿可以加速学习过程。例如，若想实现字符串的排序，只需要输入”string sort”，就能找到众多相关的代码片段，从中学习和理解其用法。 2. Python 中文学习大本营Python中文学习大本营 是一个为中文用户提供 Python 学习资料的平台。在这里，能找到丰富的 Flask 资源，包括书籍、视频教程和代码示例，几乎涵盖了学习 Flask 所需的所有内容。无论是想快速上手构建 Web 应用，还是深入理解 Flask 的底层机制，都能在这个网站上找到合适的指南。 3. Python Module of the Week Python 3 Module of the Week Python Module of the Week 这个系列的文章致力于介绍 Python 的标准库，每一篇文章详细讲解一个模块的功能和使用方法。例如，collections 模块提供了多种特殊的容器数据类型，适合不同的数据存储需求，学习这些模块能帮助更高效地使用 Python。 4. Welcome to Python for you and meWelcome to Python for you and me 是一个专为初学者设计的网站。它以简单易懂的方式介绍 Python 的基本语法、数据结构和项目经验。通过实例和练习，初学者可以逐步掌握 Python 的精髓，提升编程技能。 5. CheckiO is a code game codersCheckiO 是一个独特的学习平台，将编程与游戏结合在一起。用户在这个网站上可以通过解决一系列编程挑战来提升自己的技能。每个关卡都要求编写代码来完成特定任务，这种互动学习方式不仅有趣，还能有效提高的逻辑思维与编程能力。 6. Python 基础教程Python基础教程 是一个广为人知的学习平台，提供 Python 的基础知识。如果完全没有编程经验，建议从这个网站开始。它涵盖了 Python 的基本语法、数据类型、控制结构等内容，并配有简单的例子和练习，帮助打下坚实的基础。 学习资源 A Byte of Python: 该书提供 Python 的基本知识，边学习边实践的方式加深理解。 Google’s Python Lessons: Google 发布的 Python 教程，内容清晰，非常适合自学者。 Python Documentation: 官方在线文档，适合深入了解 Python 各个模块及其使用。 CS61A: SICP with Python: MIT 课程，结合 Python 深入探讨计算机科学的基本原理。 Python Guide：由 requests 的作者编写，尤其偏向软件工程方面的实践。 Use Python：提供一些更为实际的 Python 使用技巧和案例。 Python 核心编程：全面介绍 Python 语言的各个方面。 Dive Into Python：一本开源的优质书籍。 Fluent Python：深入探讨 Python 的高级主题。 Python3 Cookbook：收集了众多 Python 编程技巧。 Python 核心编程 Python 网络数据采集 利用 Python 进行数据分析","categories":["2.语言","Python"]},{"title":"QAudioRecorder音频采集","path":"/2024/03/25/2-语言-Qt-QAudioRecorder音频采集/","content":"在此项目中，使用了 QFile 将音频保存为 .raw 格式，虽然可以用 MATLAB 进行处理与播放，且音质表现良好，但这个格式是自己定义的，许多常规播放器无法识别。因此，转向了 QAudioRecorder，它允许保存为业界主流的音频格式。这改变显著提升了可用性，但在多线程采集音频时仍遇到了一些奇怪的问题。 以下是整个过程的主要步骤： 1. 初始化mpProbe = new QAudioProbe; // 创建音频探针，用于监听声音数据mpAudioRecorder = new QAudioRecorder(); 在初始化阶段，创建了 QAudioProbe 对象，这是用于捕获音频数据的探针。之后，将探针的信号与一个槽函数 audioSample::processBuffer 绑定，这样探针能够在获取到音频缓冲区数据时触发相应的处理。 connect(mpProbe, QAudioProbe::audioBufferProbed, this, audioSample::processBuffer); 接着，将音频探针与音频录制器关联，指定声源并进行编码设置。所需参数如下： mpProbe-setSource(mpAudioRecorder);settings.setCodec(audio/PCM); // 设置音频编解码器为 PCMsettings.setBitRate(96000);settings.setChannelCount(1);settings.setQuality(QMultimedia::EncodingQuality::HighQuality);settings.setEncodingMode(QMultimedia::ConstantQualityEncoding);mpAudioRecorder-setContainerFormat(audio/wav); // 设置容器格式为 WAV 需要注意的是，根据 QT5.9 版本的更新： 在 QT5.9 版本之前，使用 settings.setCodec(audio/PCM); 进行编码配置，从 5.9 开始，需要使用 mpAudioRecorder-setContainerFormat(audio/x-wav); 进行设置。 2. 开启设备settings.setSampleRate(mSampleRate); // 在开启设备时确定采样率mpAudioRecorder-setAudioInput(audioDeviceInfo.deviceName()); // 打开指定的音频输入设备 确定了设备的采样率，并通过 QAudioDeviceInfo 类打开了特定的音频输入设备。为了使音频探针接收到数据，随便指定了一个输出位置，这个时候还没有开始录音： mpAudioRecorder-setOutputLocation(QUrl::fromLocalFile(./---test.avi)); 经过实验证明，输出路径需为绝对路径，而非相对路径，否则数据无法保存。 mpAudioRecorder-setEncodingSettings(settings);mpAudioRecorder-record(); // 开始录音，触发 audioSample::processBuffer 槽函数 3. 开始录音在正式录音开始之前，如果需要中止之前的录音，需检测当前状态： if (mpAudioRecorder-state() == QMediaRecorder::RecordingState) mpAudioRecorder-stop(); 然后设置新的输出位置并重新开始录音： mpAudioRecorder-setOutputLocation(QUrl::fromLocalFile(path));mpAudioRecorder-record(); 4. 结束录音结束录音的检查与开始录音的流程相似： if (mpAudioRecorder-state() == QMediaRecorder::RecordingState) mpAudioRecorder-stop(); 问题与解决方案虽然整体流程看似简洁，但面临了一个关键问题：连续调用 mpAudioRecorder-stop(); 和 mpAudioRecorder-record(); 会导致第二段录音无法打开。通过实验发现，增加约 10ms 的延时可以解决这个问题。理想情况下，等待过程应在主线程中进行，并通过信号与槽机制调用 mpAudioRecorder-record()。 另一个实验是尝试更换探针源： mpProbe-setSource(mpAudioRecorder_copy); // 更换仍然不可行 系统提示子线程不能开辟新线程。通过调试发现，这是因为每个探针都是独立线程，因此这样做并不适用。 为了解决同时监听与录音的需求，决定创建两个不同的录音对象：一个用于数据显示，另一个用于实际录音。探针的录音对象可以配置为较低的质量和采样率，这样就不会影响主录音的质量。 额外注意事项需要特别强调的是， QAudioRecorder 和 QAudioInput 类不能同时使用，否则会导致后者无法找到设备，显示设备被占用。 经过这些步骤，在台式机上成功使用 QAudioRecorder 和 QAudioInput 类实现了连续音频采集。对于树莓派而言，虽然这两种方式均可实现连续采集，但前者在压缩率方面不尽如人意，而后者则通过 ffmpeg 库实现不错的压缩效果，然而无法实时获取音频数据。因此，最终选择了结合 QAudioRecorder 和 QAudioProbe 的方案，获得了更理想的结果。","categories":["2.语言","Qt"]},{"title":"QProcess类来执行系统命令并获取输出","path":"/2024/03/22/2-语言-Qt-QProcess类来执行系统命令并获取输出/","content":"使用 QProcess 的 start 方法启动命令。通过 waitForStarted 等待命令启动完成，使用 connect 连接 readyReadStandardOutput 信号到一个槽函数，当有新的标准输出时，会触发该槽函数读取并输出结果。最后使用 waitForFinished(-1)等待命令执行完毕，-1 表示无限等待，直到命令完成。 #include QCoreApplication#include QProcessint main(int argc, char *argv[]) QCoreApplication a(argc, argv); QProcess process; // 以异步方式启动命令，这里以执行dir命令为例（Windows 系统） process.start(cmd, QStringList() /c dir); // 等待命令启动完成 if (!process.waitForStarted()) qDebug() Command failed to start!; return 1; // 连接信号与槽，以便在有新的标准输出时进行处理 QObject::connect(process, QProcess::readyReadStandardOutput, []() QString output = process.readAllStandardOutput(); qDebug() output; ); // 等待命令执行完成 if (!process.waitForFinished(-1)) qDebug() Command execution timed out!; return 1; return a.exec(); 上述代码是在 Windows 系统下执行 dir 命令的示例。如果在 Linux 系统下，需要将启动命令修改为相应的终端命令，例如 process.start(“bash”, QStringList() “-c” “ls”); 来执行 ls 命令列出目录内容。 QProcess 中 start 和 write 中写的命令，末尾要加上 （Linux 直接加 ，Windows 加 \\r ），否则命令可能无法执行。并且，write 方法不可与 waitForFinished 一起使用，否则会阻塞 30 秒，waitForFinished 只能用 start 一起使用。 如果要执行带有管道”|”等特殊字符的命令，可能需要一些额外的处理。例如，在 Linux 系统下执行 ps -ef | grep’mem’这样的命令，需要按照如下方式启动进程： QString cmd = ps -ef | grepmem;process.start(bash, QStringList() -c cmd); 这样就可以通过 QProcess 获取执行系统命令的输出结果了。Qt 无法直接识别管道”|”和重定向””命令，需要在启动程序或终端时作为参数传入这些命令，而不是启动后再输入。","categories":["2.语言","Qt"]},{"title":"Qt学习概览","path":"/2024/03/21/2-语言-Qt-Qt学习概览/","content":"Qt 基础部分Qt 入门环境搭建在开始 Qt 开发之前，首先需要安装 Qt 和 Qt Creator。以下是不同操作系统上的详细安装步骤： Windows 系统： 访问 Qt 官方网站 下载最新版本的 Qt 在线安装器。 运行安装器，选择需要安装的 Qt 版本（如 Qt 6.3 LTS）和模块（如 Qt Desktop）。 配置安装路径，并选择安装 Qt Creator。 等待安装完成后，打开 Qt Creator 并配置开发环境。 macOS 系统： 下载并安装 Qt Online Installer for macOS。 按照安装向导选择需要的 Qt 组件。 安装完成后，打开 Qt Creator 并设置开发环境。 Linux 系统： 使用包管理器安装 Qt 和 Qt Creator： sudo apt-get install qt5-default qtcreator 也可以通过 Qt 官方网站下载离线安装包并手动安装。 第一个 Qt 应用创建一个简单的 “Hello World” 应用，学习基本的项目结构和运行流程： 打开 Qt Creator，选择 “文件” - “新建项目”。 选择 “应用程序” - “Qt Widgets 应用程序”。 填写项目名称（如 “HelloWorld”）和项目路径。 在 mainwindow.h 中添加一个 QLabel 显示 “Hello World”。 编译并运行项目，查看结果。 Qt 对话框标准对话框Qt 提供了一系列标准对话框，常用的有： QMessageBox：用于显示消息框。 QMessageBox::information(this, 提示, 这是一个信息对话框); QFileDialog：用于文件选择。 QString fileName = QFileDialog::getOpenFileName(this, 打开文件, , 文本文件 (*.txt)); QColorDialog：用于选择颜色。 QColor color = QColorDialog::getColor(Qt::red, this); 自定义对话框创建自定义对话框的步骤如下： 继承 QDialog 类，设计 UI 界面。 添加必要的控件（如按钮、输入框）。 实现按钮的点击事件，处理用户输入。 在主窗口中显示对话框： MyDialog dialog(this);dialog.exec(); Qt 窗口窗口类型 主窗口（MainWindow）：应用程序的主界面。 对话框（Dialog）：用于临时交互的窗口。 MDI（多文档界面）：允许多个子窗口在主窗口中打开。 窗口属性设置窗口的基本属性： 标题： setWindowTitle(我的应用程序); 大小： resize(800, 600); 图标： setWindowIcon(QIcon(icon.png)); 自定义窗口部件自定义控件通过继承 QWidget 创建自定义控件： 创建一个新的类，继承 QWidget。 在 paintEvent 方法中实现绘制逻辑。 在 event 方法中处理事件。 绘制与事件处理 绘制： void MyWidget::paintEvent(QPaintEvent *) QPainter painter(this); painter.drawText(10, 20, Hello, World!); 事件处理： void MyWidget::mousePressEvent(QMouseEvent *event) // 处理鼠标按下事件 event-accept(); Qt 中级布局管理布局类型 垂直布局（QVBoxLayout）： QVBoxLayout *layout = new QVBoxLayout;layout-addWidget(button1);layout-addWidget(button2); 水平布局（QHBoxLayout）： QHBoxLayout *layout = new QHBoxLayout;layout-addWidget(label);layout-addWidget(lineEdit); 网格布局（QGridLayout）： QGridLayout *layout = new QGridLayout;layout-addWidget(button1, 0, 0);layout-addWidget(button2, 0, 1); 嵌套布局通过嵌套布局实现复杂界面： QVBoxLayout *mainLayout = new QVBoxLayout;QHBoxLayout *topLayout = new QHBoxLayout;topLayout-addWidget(label);topLayout-addWidget(lineEdit);mainLayout-addLayout(topLayout);mainLayout-addWidget(textEdit); 事件处理事件模型Qt 的事件模型包括事件的生成、传递和处理。常见的事件有鼠标事件、键盘事件和绘制事件。 自定义事件 定义自定义事件类： class MyEvent : public QEvent public: MyEvent(int type) : QEvent(type) ; 发送事件： QCoreApplication::postEvent(receiver, new MyEvent(MyEvent::Type)); 处理事件： bool MyWidget::event(QEvent *event) if (event-type() == MyEvent::Type) // 处理自定义事件 return true; return QWidget::event(event); 二维绘图QPainter 使用使用 QPainter 绘制基本形状和文本： void MyWidget::paintEvent(QPaintEvent *) QPainter painter(this); painter.setBrush(Qt::blue); painter.drawRect(10, 10, 100, 100); painter.setPen(Qt::red); painter.drawText(20, 20, Hello, World!); 图形视图框架使用 QGraphicsView 和 QGraphicsScene 进行复杂图形绘制： QGraphicsScene scene;scene.addRect(10, 10, 100, 100);QGraphicsView view(scene);view.show(); 容器标准容器类 QList： QListQString list;list Apple Banana; QMap： QMapQString, int map;map[Apple] = 5; QSet： QSetint set;set 1 2 3; 模型视图架构将数据与 UI 分离： QStringListModel model;model.setStringList(list);QListView view;view.setModel(model); 数据库Qt SQL 模块使用 QSqlDatabase 和 QSqlQuery 进行数据库操作： QSqlDatabase db = QSqlDatabase::addDatabase(QSQLITE);db.setDatabaseName(example.db);QSqlQuery query;query.exec(SELECT * FROM table); 数据模型与视图绑定将数据库数据与 UI 组件绑定： QSqlTableModel model;model.setTable(table);QTableView view;view.setModel(model); 多线程Qt 线程类使用 QThread 创建和管理线程： class MyThread : public QThread void run() override // 线程执行的代码 ;MyThread thread;thread.start(); 线程间通信使用信号与槽进行数据传递： class MyThread : public QThread Q_OBJECTpublic: void run() override emit send_data(Hello from thread); signals: void send_data(const QString data);; 网络网络编程基础使用 QNetworkAccessManager 进行 HTTP 请求： QNetworkAccessManager *manager = new QNetworkAccessManager(this);connect(manager, QNetworkAccessManager::finished, this, MyClass::replyFinished);manager-get(QNetworkRequest(QUrl(http://example.com))); TCPIP 通信实现基本的 TCP 客户端和服务器： // 客户端QTcpSocket socket;socket.connectToHost(localhost, 8080);socket.write(Hello, Server); // 服务器QTcpServer server;server.listen(QHostAddress::Any, 8080);connect(server, QTcpServer::newConnection, this, MyClass::handleConnection); Qt 高级国际化 翻译工具：Qt 提供了 Qt Linguist 工具来处理翻译文件，支持 .ts（翻译源文件）和 .qm（编译后的翻译文件）格式。开发者可以通过 Qt Linguist 添加、编辑翻译内容，并导出为 .qm 文件供应用加载。例如，开发者可以将界面中的文本字符串提取到 .ts 文件中，由翻译人员进行翻译，然后编译成 .qm 文件，最后在应用中加载相应的翻译文件以实现多语言支持。 语言切换机制：在 Qt 应用中，可以通过 QLocale 类设置应用的语言环境，并使用 QTranslator 类加载不同的翻译文件来实现动态语言切换。例如，开发者可以在应用初始化时检测系统语言，或者提供一个语言选择界面，让用户选择语言，然后通过加载对应的 .qm 文件来切换界面语言。以下是一个简单的示例： #include QApplication#include QTranslator#include QLocaleint main(int argc, char *argv[]) QApplication app(argc, argv); QTranslator translator; // 根据系统语言加载翻译文件 translator.load(app_ + QLocale::system().name()); app.installTranslator(translator); // 显示主窗口 MainWindow window; window.show(); return app.exec(); 自定义样式 样式表（QSS）：Qt 样式表（QSS，Qt Style Sheets）是一种类似 CSS 的语言，用于自定义控件的外观。通过在应用中加载 QSS 文件，开发者可以统一设置控件的字体、颜色、边距等样式。例如，可以通过以下 QSS 代码自定义按钮的样式： QPushButton background-color: #4CAF50; color: white; padding: 10px; border: none; border-radius: 5px;QPushButton:hover background-color: #45a049; 将上述代码保存为 styles.qss 文件，并在应用中加载： app.setStyleSheet(QPushButton background-color: #4CAF50; color: white; padding: 10px; border: none; border-radius: 5px; ); 创建自定义样式：除了使用 QSS，开发者还可以通过继承 QStyle 类来创建完全自定义的控件样式。例如，可以自定义按钮的外观和行为： #include QApplication#include QStyle#include QPainterclass CustomStyle : public QStyle public: CustomStyle() : QStyle() void drawControl(ControlElement element, const QStyleOption option, QPainter *painter, const QWidget *widget) const override if (element == CE_PushButton) // 自定义按钮的绘制逻辑 painter-save(); painter-setRenderHint(QPainter::Antialiasing); painter-setPen(Qt::NoPen); painter-setBrush(Qt::green); painter-drawRoundedRect(option.rect, 5, 5); painter-restore(); else QStyle::drawControl(element, option, painter, widget); ;int main(int argc, char *argv[]) QApplication app(argc, argv); app.setStyle(new CustomStyle()); QPushButton button(Custom Button); button.show(); return app.exec(); 三维绘图 Qt 3D 模块：Qt 3D 是一个用于创建和渲染三维场景的模块，提供了实时渲染、动画、粒子效果等功能。开发者可以通过 Qt 3D 创建复杂的三维场景，并与 Qt GUI 无缝集成。例如，以下代码创建了一个简单的三维场景： #include Qt3DCore/QEntity#include Qt3DRender/QCamera#include Qt3DRender/QLight#include Qt3DExtras/QOrbitCameraController#include Qt3DCore/QTransform#include Qt3DRender/QMaterial#include Qt3DRender/QGeometry#include Qt3DRender/QBuffer#include Qt3DRender/QAttributeint main() // 创建主实体 Qt3DCore::QEntity *scene = new Qt3DCore::QEntity; // 创建相机 Qt3DRender::QCamera *camera = scene-addComponent(new Qt3DRender::QCamera); camera-setPosition(QVector3D(0.0f, 0.0f, 5.0f)); camera-setUpVector(QVector3D(0.0f, 1.0f, 0.0f)); camera-setViewCenter(QVector3D(0.0f, 0.0f, 0.0f)); // 创建灯光 Qt3DCore::QEntity *lightEntity = new Qt3DCore::QEntity(scene); Qt3DRender::QLight *light = new Qt3DRender::QLight(lightEntity); light-setColor(Qt::white); light-setPosition(QVector3D(5.0f, 5.0f, 5.0f)); // 创建立方体 Qt3DCore::QEntity *cubeEntity = new Qt3DCore::QEntity(scene); Qt3DRender::QGeometry *geometry = new Qt3DRender::QGeometry(cubeEntity); Qt3DRender::QBuffer *vertexBuffer = new Qt3DRender::QBuffer(geometry); QByteArray vertexData = attribute vec3 aPosition; void main() gl_Position = aPosition; ; vertexBuffer-setData(vertexData); Qt3DRender::QAttribute *positionAttribute = new Qt3DRender::QAttribute(geometry); positionAttribute-setName(Qt3DRender::QAttribute::defaultPositionAttributeName()); positionAttribute-setBuffer(vertexBuffer); positionAttribute-setVertexBaseType(Qt3DRender::QAttribute::Float); positionAttribute-setVertexSize(3); geometry-addAttribute(positionAttribute); Qt3DRender::QMaterial *material = new Qt3DRender::QMaterial(cubeEntity); material-setEffect(new Qt3DRender::QEffect); cubeEntity-addComponent(geometry); cubeEntity-addComponent(material); // 创建渲染窗口 Qt3DExtras::QOrbitCameraController *cameraController = new Qt3DExtras::QOrbitCameraController(); cameraController-setCamera(camera); cameraController-setLinearSpeed(5.0f); cameraController-setLookSpeed(100.0f); Qt3DExtras::Qt3DWindow view; view.setRootEntity(scene); view.setCamera(camera); view.show(); return app.exec(); 物理引擎集成：Qt 3D 支持与物理引擎（如 PhysX）集成，以实现真实的物理模拟效果。例如，可以在三维场景中添加刚体、碰撞体和约束，以模拟物体的物理行为。以下代码展示了如何在 Qt 3D 中添加一个物理体： #include Qt3DCore/QEntity#include Qt3DPhysics/Qt3DPhysicsint main() // 创建主实体 Qt3DCore::QEntity *scene = new Qt3DCore::QEntity; // 初始化物理引擎 Qt3DPhysics::QPhysicsManager *physicsManager = new Qt3DPhysics::QPhysicsManager(scene); physicsManager-setGravity(QVector3D(0.0f, -9.8f, 0.0f)); // 创建一个物理体 Qt3DCore::QEntity *physicsEntity = new Qt3DCore::QEntity(scene); Qt3DPhysics::QPhysicsBody *physicsBody = new Qt3DPhysics::QPhysicsBody(physicsEntity); physicsBody-setMass(1.0f); physicsBody-setLinearDamping(0.5f); physicsBody-setAngularDamping(0.5f); // 添加碰撞体 Qt3DPhysics::QCollisionShape *collisionShape = new Qt3DPhysics::QCollisionShape(physicsEntity); collisionShape-setShape(new Qt3DPhysics::QSphereShape(1.0f)); physicsEntity-addComponent(physicsBody); physicsEntity-addComponent(collisionShape); // 将物理体添加到场景中 scene-addComponent(physicsManager); // 显示场景 Qt3DExtras::Qt3DWindow view; view.setRootEntity(scene); view.show(); return app.exec(); 创建插件 插件架构概述：Qt 提供了一个强大的插件机制，允许开发者将应用程序功能模块化。插件可以在运行时动态加载和卸载，从而无需重新编译主应用程序即可扩展功能。Qt 插件通常包含一个接口类和实现类，通过 Q_PLUGIN_METADATA 宏进行注册。例如，以下代码定义了一个简单的插件接口： #ifndef MYPLUGIN_INTERFACE_H#define MYPLUGIN_INTERFACE_H#include QObjectclass MyPluginInterface : public QObject Q_OBJECTpublic: virtual ~MyPluginInterface() virtual void doSomething() = 0;;#define MyPluginInterface_iid org.qt-project.MyPluginInterfaceQ_DECLARE_INTERFACE(MyPluginInterface, MyPluginInterface_iid)#endif // MYPLUGIN_INTERFACE_H 开发与加载插件：开发者可以通过继承插件接口并实现具体功能来创建插件。插件需要在 .pro 文件中使用 TEMPLATE = lib 和 CONFIG += plugin 进行配置。以下是一个简单的插件实现示例： #include myplugininterface.h#include QObjectclass MyPlugin : public MyPluginInterface Q_OBJECT Q_PLUGIN_METADATA(IID MyPluginInterface_iid FILE myplugin.json)public: MyPlugin(QObject *parent = nullptr) : QObject(parent) ~MyPlugin() void doSomething() override qDebug() Plugin: Doing something...; ; 在主应用程序中，可以通过 QPluginLoader 加载插件并调用其功能： #include QApplication#include QPluginLoader#include myplugininterface.hint main(int argc, char *argv[]) QApplication app(argc, argv); QPluginLoader loader(path/to/myplugin.so); QObject *plugin = loader.instance(); MyPluginInterface *interface = qobject_castMyPluginInterface*(plugin); if (interface) interface-doSomething(); return app.exec(); 嵌入式编程 嵌入式平台支持：Qt 提供了对多种嵌入式平台的支持，如 Raspberry Pi、BeagleBone 等。开发者可以使用 Qt 创建高性能的嵌入式 GUI 应用程序，并通过 Qt Creator 的跨平台编译工具链进行交叉编译。例如，在 Raspberry Pi 上运行 Qt 应用程序，需要在 .pro 文件中配置交叉编译工具链： # 配置交叉编译器CC = /path/to/gccCXX = /path/to/g++# 配置目标机器的环境TARGET = myappTEMPLATE = appQT += core gui 优化与调试技巧：在嵌入式环境中，优化和调试是非常重要的。开发者可以通过以下方法优化性能： 硬件加速：利用 GPU 加速渲染，通过在 .pro 文件中启用 QT += quick。 优化编译选项：在 .pro 文件中添加 CONFIG += release 以启用发布模式，禁用调试信息。 减少资源使用：优化图像和音频资源，减少内存占用。 调试技巧： 使用 gdb 进行远程调试。 通过串口或 SSH 连接到目标设备进行日志输出和调试。 使用 Qt Creator 的内置调试工具进行符号级调试。 通过以上方法，开发者可以高效地开发和调试嵌入式 Qt 应用程序。","categories":["2.语言","Qt"]},{"title":"Qt的条件编译","path":"/2024/03/20/2-语言-Qt-编译-Qt的条件编译/","content":"qmake 是一个强大的工具，专门用于为不同平台和编译器生成 Makefile。手动编写 Makefile 既困难又容易出错，尤其是在需要为多个平台和编译器组合编写多个 Makefile 的情况下。使用 qmake，开发人员只需创建一个简单的 .pro 文件，然后运行 qmake，就能自动生成合适的 Makefile。 对于一些简单的项目，例如一个基本的 hello 程序，开发人员可以在项目的顶层目录下直接运行 qmake -project 来自动生成 .pro 文件。然而，对于一些复杂的 Qt 项目，自动生成的 .pro 文件可能无法满足特定需求，这时程序员需要手动修改 .pro 文件。接下来，我们将简单介绍 .pro 文件的相关内容。 .pro 文件模板.pro 文件主要有三种模板： app（应用程序模板） lib（库模板） subdirs（递归编译模板） 在 .pro 文件中，可以通过以下代码指定所使用的模板： TEMPLATE = app 如果不指定 TEMPLATE，.pro 文件默认为 app 模式。实际上，项目中使用最多的也是 app 模式。app 模式的 .pro 文件主要用于构建适用于应用程序的 Makefile。 .pro 文件示例下面通过一个例子简单介绍 app 模式下的 .pro 文件（关于 lib 和 subdirs 模式的 .pro 文件，用户可以查阅 qmake 的相关文档）。这个 .pro 文件的内容将完全手动编写。在实际项目中，程序员可以使用 qmake -project 生成 .pro 文件，然后在此基础上进行相应修改。 假设项目中有如下源代码文件： hello.cpp hello.h main.cpp 首先，需要在 .pro 文件中指定源代码文件（.cpp 文件），可以通过 SOURCES 变量来指定，代码如下： SOURCES += hello.cpp 对于每一个 .cpp 文件，都需要如此指定。代码如下： SOURCES += hello.cppSOURCES += main.cpp 也可以通过反斜线形式指定： SOURCES = hello.cpp \\ main.cpp 接下来，需要指定所需的头文件（.h 文件），通过 HEADERS 变量来指定。.pro 文件中的代码如下： HEADERS += hello.hSOURCES += hello.cppSOURCES += main.cpp 项目生成的可执行程序文件名会自动设置，程序文件名与 .pro 文件名一致，但在不同平台下，其扩展名是不同的。例如，如果 .pro 文件名为 hello.pro，在 Windows 平台下会生成 hello.exe，而在 Linux 平台下则会生成 hello。可以使用 TARGET 变量来指定可执行程序的基本文件名，代码如下： TARGET = helloworld 最后一步是设置 CONFIG 变量。由于此项目是一个 Qt 项目，因此需要将 qt 添加到 CONFIG 变量中，以告知 qmake 将 Qt 相关的库与头文件信息添加到 Makefile 文件中。现在完整的 .pro 文件内容如下所示： CONFIG += qtHEADERS += hello.hSOURCES += hello.cppSOURCES += main.cppTARGET = helloworld 现在可以利用此 .pro 文件生成 Makefile，命令如下： $ qmake -o Makefile hello.pro 如果当前目录下只有一个 .pro 文件，可以直接使用命令： $ qmake 在生成 Makefile 文件后，即可使用 make 命令进行编译。 .pro 文件常见配置对于 app 模式的 .pro 文件，常用的变量包括： HEADERS：指定项目的头文件（*.h） SOURCES：指定项目的 C++ 源文件（*.cpp） FORMS：指定需要 uic 处理的由 Qt Designer 生成的 *.ui 文件 RESOURCES：指定需要 rcc 处理的 *.qrc 文件 DEFINES：指定预定义的 C++ 预处理器符号 INCLUDEPATH：指定 C++ 编译器搜索全局头文件的路径 LIBS：指定工程要链接的库 CONFIG：指定各种用于工程配置和编译的参数 QT：指定工程所要使用的 Qt 模块（默认是 core 和 gui，对应于 QtCore 和 QtGui） TARGET：指定可执行文件的基本文件名 DESTDIR：指定可执行文件放置的目录 CONFIG 变量用于控制编译过程中的各个方面。常用参数如下： debug：编译出具有调试信息的可执行程序。 release：编译不带调试信息的可执行程序，与 debug 同时存在时，release 失效。 qt：指应用程序使用 Qt，此选项是默认包括的。 dll：动态编译库文件。 staticlib：静态编译库文件。 通过合理配置 .pro 文件，开发人员可以有效管理项目的构建过程，确保在不同平台上都能顺利编译和运行。 通过 DEFINES 定义宏可以在 pro 文件中使用 DEFINES += 宏名来定义宏。然后在 pro 文件或源码中使用 contains(DEFINES,宏名) 来判断该宏是否被定义,从而实现条件编译。 DEFINES += MY_MACRO # 定义宏 MY_MACROcontains(DEFINES, MY_MACRO) message(MY_MACRO defined)\t# 做一些操作 else message(MY_MACRO not defined) # 做其他操作contains(QMAKE_HOST.os, Unix) # 针对unix平台做一些操作 在源码中也可以使用 #ifdef MY_MACRO...#endif 来根据宏定义进行条件编译。 通过 CONFIG 配置CONFIG 变量用于指定工程配置和编译器选项,每个选项值都可用于条件判断。 CONFIG += MY_CONFIGMY_CONFIG LIBS += -lmydll # 链接某库 else LIBS += -lxxxdll # 链接其他库 通过平台判断QMake 提供了一些内置变量来判断当前平台,如 win32、macx、android 等,可以根据这些变量进行条件编译。 win32 LIBS += -lwindowslibmacx LIBS += -lmaclib !macx:!win32 # 针对unix平台做一些操作","categories":["2.语言","Qt","编译"]},{"title":"Qt的线程池","path":"/2024/03/19/2-语言-Qt-Qt的线程池/","content":"线程池线程池是一种常见的并发编程模型，用于管理和复用多个线程来执行任务。它的基本思想是在应用程序启动时创建一组线程，这些线程可以重复使用，以执行一系列的任务，而不需要为每个任务都创建和销毁线程。 线程池通常由线程池管理器、工作队列和一组工作线程组成。 线程池管理器：负责管理线程池的创建、销毁和线程数量的控制。 工作队列：用于存储待执行的任务。当任务提交至线程池时，会被添加到工作队列中，等待线程池中的线程来执行。 工作线程：线程池中的线程会从工作队列中取出任务，并执行任务的操作。 线程池的优点包括： 提高性能：通过重用线程，避免了频繁创建和销毁线程的开销，可以减少系统资源的占用和提高任务的响应速度。 控制并发度：通过限制线程池中的线程数量，可以有效控制并发任务的数量，避免资源过度消耗和系统负载过重。 提供任务队列：线程池可以维护一个任务队列，任务的提交和执行是解耦的，可以灵活地调整任务的处理顺序和优先级。 简化线程管理：由线程池管理器负责线程的创建、销毁和管理，开发者无需手动管理线程的生命周期。 Qt 的线程池QThreadPool 管理并回收单个 QThread 对象，以帮助降低使用线程的程序中的线程创建成本。每个 Qt 应用程序都有一个全局的 QThreadPool 对象，可以通过调用 globalInstance() 来访问。 要使用 QThreadPool 中的一个线程，子类化 QRunnable 并实现 run() 虚函数。然后创建该类的一个对象，并将其传递给 QThreadPool::start()。QThreadPool 默认会自动删除 QRunnable。使用 QRunnable::setAutoDelete() 来更改自动删除标志。 QThreadPool 支持通过在 QRunnable::run() 内部调用 tryStart(this) 多次执行同一个 QRunnable。如果启用了自动删除，当最后一个线程退出 run 函数时，QRunnable 将被删除。在启用自动删除时，使用相同的 QRunnable 多次调用 start() 会造成竞争条件，不建议这样做。 一段时间未使用的线程将会过期。默认的过期超时时间是 30000 毫秒（30 秒）。可以使用 setExpiryTimeout() 更改此设置。设置负的过期超时时间将禁用过期机制。 调用 maxThreadCount() 来查询要使用的最大线程数。如果需要，可以使用 setMaxThreadCount() 更改限制。默认的 maxThreadCount() 是 QThread::idealThreadCount()。activeThreadCount() 函数返回当前正在工作的线程数量。 reserveThread() 函数为外部使用保留一个线程。使用完线程后使用 releaseThread()，以便它可以被重新使用。本质上，这些函数暂时增加或减少活动线程数，在实现对 QThreadPool 不可见的耗时操作时非常有用。 QThreadPool 是用于管理线程的低级类，有关更高级的替代方案，请参阅 Qt Concurrent 模块。 函数说明// 获取和设置线程中的最大线程个数int maxThreadCount() const;void setMaxThreadCount(int maxThreadCount);// 给线程池添加任务, 任务是一个 QRunnable 类型的对象// 如果线程池中没有空闲的线程了, 任务会放到任务队列中, 等待线程处理void QThreadPool::start(QRunnable * runnable, int priority = 0);// 如果线程池中没有空闲的线程了, 直接返回值, 任务添加失败, 任务不会添加到任务队列中bool QThreadPool::tryStart(QRunnable * runnable);// 线程池中被激活的线程的个数(正在工作的线程个数)int QThreadPool::activeThreadCount() const;// 尝试性的将某一个任务从线程池的任务队列中删除, 如果任务已经开始执行就无法删除了bool QThreadPool::tryTake(QRunnable *runnable);// 将线程池中的任务队列里边没有开始处理的所有任务删除, 如果已经开始处理了就无法通过该函数删除了void QThreadPool::clear();// 在每个Qt应用程序中都有一个全局的线程池对象, 通过这个函数直接访问这个对象static QThreadPool * QThreadPool::globalInstance(); 一个扫描 IP 地址的线程池实例#include QApplication#include QThreadPoolclass ScanIpThread : public QRunnablepublic: QString ipAddr; ScanIpThread(QString ip_addr) ipAddr = ip_addr; void run() override qDebug() Hello world from thread QThread::currentThread(); QStringList parameters;#if defined(WIN32) parameters -n 5;#else parameters -c 5;#endif parameters ipAddr; int exitCode = QProcess::execute(ping, parameters); if (exitCode==0) qDebug()ipAddr its alive; else qDebug()ipAddr its dead; ;int main(int argc, char *argv[]) QApplication a(argc, argv); QThreadPool *threadPool = new QThreadPool; threadPool-setMaxThreadCount(64); for(int i=0; i255; i++) ScanIpThread *scanNode = new ScanIpThread(QString(192.168.0.%1).arg(i)); // QThreadPool takes ownership and deletes node automatically threadPool-start(scanNode); return a.exec();","categories":["2.语言","Qt"]},{"title":"Qt线程管理QThread","path":"/2024/03/18/2-语言-Qt-Qt线程管理QThread/","content":"QThread 会通知触发了一个信号当线程 started()和 finished()时，或者使用 isFinished()和 isRunning()来查询线程的状态。 可以通过调用 exit()或 quit()来停止线程。在极端情况下，可能要强行 terminate()一个执行线程。但是，这样做是危险的。请阅读文档查看 terminate()和 setTerminationEnabled()的详细信息。 可以通过连接 finished()信号到 QObject::deleteLater()释放运行刚刚结束的线程对象。 使用 wait()来阻塞调用的线程，直到其他线程执行完毕（或者直到指定的时间过去）。 QThread 中还提供了静态的、平台独立的休眠功能：sleep()、msleep()、usleep()允许秒，毫秒和微秒来区分。 注意：一般情况下，wait()和 sleep()函数应该不需要，因为 Qt 是一个事件驱动型框架。而不是 wait()，关心监听信号 finished()。取代 sleep()，可以考虑使用 QTimer。 静态函数 currentThreadId()和 currentThread()返回标识当前正在执行的线程。前者返回该线程的平台特定的 ID，后者返回一个线程指针。 要设置线程的名称，可以在启动线程之前调用 setObjectName()。如果不调用 setObjectName()，线程的名称将是线程对象的运行时类型（上例中”WorkerThread”，因为这是 QThread 子类的类名）。 和界面有关的函数不能通过 QThread 的方式执行 movetothreadWorker 槽中的代码将在一个单独的线程中执行，然而，可以将（来自任何对象、在任何线程中）任何信号与该槽自由地连接，在不同的线程里连接信号和槽也是安全的，这要归功于一个叫排队的连接机制（queued connections）。 class Worker : public QObject\tQ_OBJECT\tpublic slots: void doWork(const QString parameter) // ... emit resultReady(result); signals: void resultReady(const QString result);;class Controller : public QObject\tQ_OBJECT\tQThread workerThread;\tpublic: Controller() Worker *worker = new Worker; worker-moveToThread(workerThread); connect(workerThread, QThread::finished, worker, QObject::deleteLater); connect(this, Controller::operate, worker, Worker::doWork); connect(worker, Worker::resultReady, this, Controller::handleResults); workerThread.start(); ~Controller() workerThread.quit(); workerThread.wait(); public slots: void handleResults(const QString );\tsignals: void operate(const QString );; 实例化 QThread是子类化 QThread 中并重新实现 run 函数，在 run()返回后线程就会退出，在线程中将不会有任何的事件循环运行除非调用 exec()。 当子类化 QThread 时，构造函数在旧线程中执行，然而 run()在新线程中执行。 一个线程实例位于实例化它的旧线程中，而非调用 run()的新线程中，这意味着所有线程的排队槽将在旧线程中执行。因此，开发人员希望在新线程调用槽必须 通过 movetothread 实现，新槽不应直接在子类化 QThread 中来实现。 class WorkerThread : public QThread\tQ_OBJECT\tvoid run() Q_DECL_OVERRIDE QString result; emit resultReady(result); signals: void resultReady(const QString s);;void MyObject::startWorkInAThread()\tWorkerThread *workerThread = new WorkerThread(this);\tconnect(workerThread, WorkerThread::resultReady, this, MyObject::handleResults);\tconnect(workerThread, WorkerThread::finished, workerThread, QObject::deleteLater);\tworkerThread-start(); 线程异步通知~~QT 中的信号槽（signalslot）事件机制是基于主程序线程的。这意味着在辅助线程中无法使用信号机制，原因稍后会详细说明。因此，所有事件都是阻塞型的。换句话说，除非你处理完某个槽（slot）事件，否则下一个事件不会被触发。 ~~不过，有一个例外，那就是 QTimer。timerEvent(QTimerEvent* e) 事件会在设定的时间到达时重复触发，无论上一次的 timerEvent 是否结束。遗憾的是，我没有深入研究 QTimer 的实现，因此不清楚它是如何做到这一点的。 ~~接下来，关于 QT 中用于网络通信的类 QSocket，如果想要使用 QSocket 接收数据，必须连接其 readyRead() 事件。然而，正如前面所提到的，所有信号槽的触发都是基于主线程的。因此，你实现的 slotReadyRead() 方法将在主线程中被调用。如果你的程序需要接收大量数据，或者对数据进行验证（正如我当前所做的），将这些耗时的操作放在主线程中是不可行的。 ~~一个直观的解决方案是将 QSocket 放入一个线程中，但实际上这样并不可行。首先，QThread 不是从 QObject 继承而来的，因此无法使用任何信号槽机制。网上有一些人尝试通过多重继承的方法同时从 QThread 和 QObject 继承出新的类，但实践证明这种方法也不可行。其次，如果在 QThread 中再加入一个从 QObject 继承的类来负责连接 QSocket 的 readyRead() 事件，由于 QT 的信号槽机制完全依赖于主线程，最终的 slotReadyRead() 方法仍然会在主线程中执行，导致 QThread 成为摆设。 ~~要实现异步的数据采集功能，应该结合 QThread 和 QSocketDevice 两个类。与 QSocket 不同，QSocketDevice 不会在任何数据到达时自动触发事件。相反，你必须主动调用它的函数来查询是否有数据到达，或者调用 wait 函数，阻塞程序，直到有数据到达。对于主线程来说，阻塞是不可行的，但对于线程来说，这种效果正是所需。 ~~一旦数据正常接收完毕，数据采集线程必须主动通知主线程中的数据处理类。查阅 QT 文档后，我发现要让 QThread 向主线程发送信息，必须使用 QApplication::postEvent() 函数，只有这个函数是线程安全的。然而，使用 QApplication::postEvent() 函数时，我发现了另一个严重的问题：该函数是阻塞型的，调用它的线程会等待主线程中的处理函数返回后才能继续执行。这意味着，如果数据采集的速度超过了主线程的处理速度，我需要在线程中提供缓存功能，以防止数据采集停止。因此，我需要一种异步的通知方法。 ~~在这种情况下，我首先想到的是使用 QTimer，因为它是非阻塞型的。然而，在时间要求比较敏感的场合，我并不希望使用 QTimer。经过在论坛上寻找无果（可能是因为我的英文水平有限），我最终决定自己实现一个解决方案：再创建一个线程（称为事件通知线程），并在其中使用 QWaitCondition。该线程将始终处于等待状态，一旦数据采集线程收到数据，它就会唤醒事件通知线程中的 QWaitCondition。此时，事件通知线程会使用 QApplication::postEvent() 向主线程发送事件。 ~~假设在某个时刻，主线程正在处理数据，而事件发送线程的 postEvent() 过程尚未返回。如果此时数据采集线程又有新数据到达，它并不会知道事件发送线程的状态，而是简单地再次唤醒 QWaitCondition。值得注意的是，对 QWaitCondition 的多次唤醒不会产生影响，事件发送线程将继续阻塞在 postEvent() 中。经过一段时间后，事件发送线程中的 postEvent() 返回，此时它会设置自己的 QWaitCondition 再次进入等待状态，直到数据采集线程再次唤醒它。 ~~总结一下，在事件发送线程中，如果当前正在处理 postEvent()，它将自动忽略数据采集线程发来的任何更新命令。而在主线程中的处理程序在被通知时，会自动查找数据缓存中的所有数据进行处理，从而清空所有缓存中积压的数据。这样一来，数据采集和处理的效率得到了有效提升。 ~~ QTcpSocket 或 QSerialPort 的实例化过程应置于 QThread 的 Run 函数中实现。","categories":["2.语言","Qt"]},{"title":"使用 CMake 构建 Qt5 项目","path":"/2024/03/15/2-语言-Qt-编译-使用-CMake-构建-Qt5-项目/","content":"使用 CMake 构建 Qt5 项目的详细步骤Qt5 支持利用 CMake 构建项目，而 Visual Studio Code（VS Code）也能兼容 CMake 构建系统，因此在这些工具的帮助下，构建和运行 Qt5 项目是完全可行的。 测试环境 Qt 版本：5.15.0 CMake 版本：3.17.5 Visual Studio 版本：2019 16.7.5（支持 C++桌面开发） Visual Studio Code 版本：1.49.3 步骤1. 将 Qt 的 bin 目录添加到环境变量假设 Qt 安装路径为 C:\\Qt，则需将以下路径添加至系统环境变量中，以便系统能够找到 Qt 的可执行文件： C:\\Qt\\5.15.0\\msvc2019_64\\bin 这一步骤确保了 Qt 命令行工具能够在命令提示符和其他环境中被顺利调用。 2. 安装 VS Code 扩展打开 VS Code 的扩展商店，在搜索框中输入 C++，然后安装 CC++扩展，这个扩展为 C++开发提供了必要的支持，包括代码高亮和智能感知等功能。 接着，同样在扩展商店中搜索 CMake，并安装两个扩展：一个是 CMake，另一个是 CMake Tools。这些扩展将帮助 VS Code 更好地处理 CMake 文件和项目构建。 3. 使用 Qt Creator 创建 CMake 项目使用 Qt Creator 工具创建一个新的 CMake 项目，例如命名为”Test”。在这个过程中，Qt Creator 将自动生成 CMakeLists.txt 文件以及基础的源代码文件。 4. 在 VS Code 中打开项目在 VS Code 中选择打开项目，定位到刚创建的项目目录，特别是 CMakeLists.txt 文件所在的文件夹。VS Code 会自动识别 CMake 项目。 在操作中，需要选择一个 CMake Kit，推荐使用 Visual Studio 2019 工具包。也可以选择 MinGW，具体配置请参考 CMake 扩展的官方文档。系统会询问是否要配置智能感知功能，建议选择”是”。 5. 构建并运行项目在 VS Code 中，通过按 F7 键进行项目构建。构建完成后，可按 Shift + F5 键来运行项目。这个流程用于在开发环境中测试项目的功能。 6. 调试项目若需要调试项目，可以通过添加断点来跟踪代码执行流程，然后按下 Ctrl + F5 进行调试。这种调试能力使开发人员可以仔细观察程序的行为并快速解决潜在问题。 一些小问题完成上述步骤后，项目应能正常编码和运行。然而，在智能感知方面可能出现一些小问题，比如 Qt 生成的 .ui 文件尚未被包含在智能感知的 include 目录中。 通过查询 CMake 文档发现，ui 文件所在的目录应该被自动添加至目标属性的 include 目录属性中。然而实际验证过程显示，这一过程并不总是可靠。因此，需手动添加相应的 include 路径。 假设生成的目标名称为 Test，需要在 CMakeLists.txt 文件的结尾添加以下行： target_include_directories(Test PRIVATE $CMAKE_BINARY_DIR/Test_autogen/include_Debug) 最终的 CMakeLists.txt 文件内容最终的 CMakeLists.txt 文件内容应如下所示： cmake_minimum_required(VERSION 3.5)project(Test LANGUAGES CXX)set(CMAKE_INCLUDE_CURRENT_DIR ON)set(CMAKE_AUTOUIC ON)set(CMAKE_AUTOMOC ON)set(CMAKE_AUTORCC ON)set(CMAKE_CXX_STANDARD 11)set(CMAKE_CXX_STANDARD_REQUIRED ON)# 以下代码是关于Android的设置，可根据需求选择性使用# if(ANDROID)# set(ANDROID_PACKAGE_SOURCE_DIR $CMAKE_CURRENT_SOURCE_DIR/android)# if (ANDROID_ABI STREQUAL armeabi-v7a)# set(ANDROID_EXTRA_LIBS# $CMAKE_CURRENT_SOURCE_DIR/path/to/libcrypto.so# $CMAKE_CURRENT_SOURCE_DIR/path/to/libssl.so)# endif()# endif()find_package(QT NAMES Qt6 Qt5 COMPONENTS Widgets REQUIRED)find_package(Qt$QT_VERSION_MAJOR COMPONENTS Widgets REQUIRED)if(ANDROID) add_library(Test SHARED main.cpp mainwindow.cpp mainwindow.h mainwindow.ui )else() add_executable(Test main.cpp mainwindow.cpp mainwindow.h mainwindow.ui )endif()target_link_libraries(Test PRIVATE Qt$QT_VERSION_MAJOR::Widgets)target_include_directories(Test PRIVATE $CMAKE_BINARY_DIR/Test_autogen/include_Debug) 此时，智能感知功能正常工作，可以提升编码的体验和效率。","categories":["2.语言","Qt","编译"]},{"title":"信号与槽详解","path":"/2024/03/14/2-语言-Qt-信号槽-信号与槽详解/","content":"1、概述信号槽是 Qt 框架引以为豪的机制之一。所谓信号槽，实际就是 观察者模式。当某个事件发生之后，比如，按钮检测到自己被点击了一下，它就会发出一个信号（signal）。这种发出是没有目的的，类似广播。如果有对象对这个信号感兴趣，它就会使用连接（connect）函数，意思是，将想要处理的信号和自己的一个函数（称为槽（slot））绑定来处理这个信号。也就是说，当信号发出时，被连接的槽函数会自动被回调。这就类似观察者模式：当发生了感兴趣的事件，某一个操作就会被自动触发。（这里提一句，Qt 的信号槽使用了额外的处理来实现，并不是 GoF 经典的观察者模式的实现方式。） 信号和槽是 Qt 特有的信息传输机制，是 Qt 设计程序的重要基础，它可以让互不干扰的对象建立一种联系。 槽的本质是类的成员函数，其参数可以是任意类型的。和普通 C++成员函数几乎没有区别，它可以是 虚函数；也可以被重载；可以是公有的、保护的、私有的、也可以被其他 C++成员函数调用。唯一区别的是：槽可以与信号连接在一起，每当和槽连接的信号被发射的时候，就会调用这个槽。 1.1 对象树(子对象动态分配空间不需要释放)参考连接：https://blog.csdn.net/fzu\\_dianzi/article/details/6949081 Qt 提供了一种机制，能够自动、有效的组织和管理继承自 QObject 的 Qt 对象，这种机制就是对象树。 Qt 对象树在 用户界面 编程上是非常有用的。它能够帮助程序员减轻内存泄露的压力。 比如说当应用程序创建了一个具有父窗口部件的对象时，该对象将被加入父窗口部件的孩子列表。当应用程序销毁父窗口部件时，其下的孩子列表中的对象将被一一删除。这让们在编程时，能够将主要精力放在系统的业务上，提高编程效率，同时也保证了系统的稳健性。 下面笔者将简单分析对象树。 代码验证： int main(int argc, char *argv[]) QApplication app(argc, argv); QDialog *dlg = new QDialog(0); QPushButton *btn = new QPushButton(dlg); qDebug() dlg = dlg; qDebug() btn = btn; dlg-exec(); delete btn; qDebug() dlg = dlg; return 0;dlg = QDialog(0x3ea1a0) btn = QPushButton(0x3ea228) 关闭窗口后，dlg QDialog(0x3ea1a0)这说明关闭窗口，不会销毁该窗口部件，而是将其隐藏起来。们在 qDebug() “dlg “ dlg;之后加上qDebug() “btn “ btn;明显的，们之前已经 delete btn，btn 指针没有被赋值为 0，这是编译器决定的。执行程序后，必然出现段错误。 2、将程序稍微修改下。 int main(int argc, char *argv[]) QApplication app(argc, argv); QDialog *dlg = new QDialog(0); QPushButton *btn = new QPushButton(dlg); qDebug() dlg = dlg; qDebug() btn = btn; dlg-exec(); delete dlg; qDebug() btn = btn; return 0; 2、信号和槽为了体验一下信号槽的使用，们以一段简单的代码说明：Qt5 的书写方式：（推荐的使用）★★★★★ #include QApplication#include QPushButtonint main(int argc, char *argv[]) QApplication app(argc, argv); QPushButton button(Quit);\tQObject::connect(button, QPushButton::clicked,\tapp, QApplication::quit); button.show(); return app.exec(); 们按照前面文章中介绍的在 Qt Creator 中创建工程的方法创建好工程，然后将 main()函数修改为上面的代码。点击运行，们会看到一个按钮，上面有”Quit”字样。点击按钮，程序退出。 connect()函数最常用的一般形式： connect(sender, signal, receiver, slot); 参数： sender：发出信号的对象 signal：发送对象发出的信号 receiver：接收信号的对象 slot：接收对象在接收到信号之后所需要调用的函数 信号槽要求信号和槽的参数一致，所谓一致，是参数类型一致。如果不一致，允许的情况是，槽函数的参数可以比信号的少，即便如此，槽函数存在的那些参数的顺序也必须和信号的前面几个一致起来。这是因为，可以在槽函数中选择忽略信号传来的数据（也就是槽函数的参数比信号的少），但是不能说信号根本没有这个数据，就要在槽函数中使用（就是槽函数的参数比信号的多，这是不允许的）。 如果信号槽不符合，或者根本找不到这个信号或者槽函数，比如们改成： connect(button, QPushButton::clicked, QApplication::quit2); 由于 QApplication 没有 quit2 这样的函数，因此在编译时会有编译错误： quit2 is not a member of QApplication 这样，使用成员函数指针们就不会担心在编写信号槽的时候出现函数错误。 Qt4 的书写方式： int main(int argc, char *argv[]) QApplication a(argc, argv); QPushButton *button = new QPushButton(Quit); connect(button, SIGNAL(clicked()), a, SLOT(quit())); button-show(); return a.exec(); 这里使用了SIGNAL和SLOT这两个宏，将两个函数名转换成了字符串。注意到 connect()函数的 signal 和 slot 都是接受字符串，一旦出现连接不成功的情况，Qt4 是没有编译错误的（因为一切都是字符串，编译期是不检查字符串是否匹配），而是在运行时给出错误。这无疑会增加程序的不稳定性。 Qt5 在语法上完全兼容 Qt4 小总结： 1. 格式: connect(信号发出者对象(指针), className::clicked, 信号接收者对象(指针), classB::slot); 2. 标准信号槽的使用: connect(sender, Send::signal, receiver, Receiver::slot) 3、自定义信号槽使用 connect()可以让们连接系统提供的信号和槽。但是，Qt 的信号槽机制并不仅仅是使用系统提供的那部分，还会允许们自己设计自己的信号和槽。 下面们看看使用 Qt 的信号槽，实现一个报纸和订阅者的例子： 有一个报纸类 Newspaper，有一个订阅者类 Subscriber。Subscriber 可以订阅 Newspaper。这样，当 Newspaper 有了新的内容的时候，Subscriber 可以立即得到通知。 #include QObject // newspaper.h // class Newspaper : public QObject Q_OBJECTpublic: Newspaper(const QString name) : m_name(name) void send() emit newPaper(m_name); signals: void newPaper(const QString name); private: QString m_name;; // reader.h //#include QObject#include QDebug class Reader : public QObject Q_OBJECTpublic: Reader() void receiveNewspaper(const QString name) qDebug() Receives Newspaper: name; ; // main.cpp //#include QCoreApplication #include newspaper.h#include reader.h int main(int argc, char *argv[]) QCoreApplication app(argc, argv); Newspaper newspaper(Newspaper A); Reader reader; QObject::connect(newspaper, Newspaper::newPaper, reader, Reader::receiveNewspaper); newspaper.send(); return app.exec(); ●首先看 Newspaper 这个类。这个类继承了 QObject 类。只有继承了 QObject 类的类，才具有信号槽的能力。 所以，为了使用信号槽，必须继承 QObject。凡是 QObject 类（不管是直接子类还是间接子类），都应该在第一行代码写上 Q_OBJECT。不管是不是使用信号槽，都应该添加这个宏。这个宏的展开将为们的类提供信号槽机制、国际化机制以及 Qt 提供的不基于 C++ RTTI 的反射能力。 ● Newspaper 类的 public 和 private 代码块都比较简单，只不过它新加了一个 signals。signals 块所列出的，就是该类的信号。信号就是一个个的函数名，返回值是 void（因为无法获得信号的返回值，所以也就无需返回任何值），参数是该类需要让外界知道的数据。信号作为函数名，不需要在 cpp 函数中添加任何实现。 ●Newspaper 类的 send()函数比较简单，只有一个语句 emit newPaper(m_name);。emit 是 Qt 对 C++ 的扩展，是一个关键字（其实也是一个宏）。emit 的含义是发出，也就是发出 newPaper()信号。感兴趣的接收者会关注这个信号，可能还需要知道是哪份报纸发出的信号？所以，们将实际的报纸名字 m_name 当做参数传给这个信号。当接收者连接这个信号时，就可以通过槽函数获得实际值。这样就完成了数据从发出者到接收者的一个转移。 ● Reader 类更简单。因为这个类需要接受信号，所以们将其继承了 QObject，并且添加了 Q_OBJECT 宏。后面则是默认构造函数和一个普通的成员函数。Qt 5 中，任何成员函数、static 函数、全局函数和 Lambda 表达式都可以作为槽函数。与信号函数不同，槽函数必须自己完成实现代码。槽函数就是普通的成员函数，因此作为成员函数，也会受到 public、private 等访问控制符的影响。（如果信号是 private 的，这个信号就不能在类的外面连接，也就没有任何意义。） 3.1 自定义信号槽需要注意的事项●发送者和接收者都需要是 QObject 的子类（当然，槽函数是全局函数、Lambda 表达式等无需接收者的时候除外）； ●使用 signals 标记信号函数，信号是一个函数声明，返回 void，不需要实现函数代码； ●槽函数是普通的成员函数，作为成员函数，会受到 public、private、protected 的影响； ●使用 emit 在恰当的位置发送信号； ●使用 QObject::connect()函数连接信号和槽。 ●任何成员函数、static 函数、全局函数和 Lambda 表达式都可以作为槽函数 3.2 信号槽的更多用法● 一个信号可以和多个槽相连　如果是这种情况，这些槽会一个接一个的被调用，但是它们的调用顺序是不确定的。 ●多个信号可以连接到一个槽只要任意一个信号发出，这个槽就会被调用。 ●一个信号可以连接到另外的一个信号当第一个信号发出时，第二个信号被发出。除此之外，这种信号-信号的形式和信号-槽的形式没有什么区别。 ●槽可以被取消链接这种情况并不经常出现，因为当一个对象 delete 之后，Qt 自动取消所有连接到这个对象上面的槽。 ●使用 Lambda 表达式在使用 Qt 5 的时候，能够支持 Qt 5 的编译器都是支持 Lambda 表达式的。 们的代码可以写成下面这样： QObject::connect(newspaper, static_castvoid (Newspaper:: *)(const QString )(Newspaper::newPaper),[=](const QString name) /* Your code here. */ ); 在连接信号和槽的时候，槽函数可以使用 Lambda 表达式的方式进行处理。 4、Lambda 表达式C++11 中的 Lambda 表达式用于定义并创建匿名的函数对象，以简化编程工作。首先看一下 Lambda 表达式的基本构成：[函数对象参数](操作符重载函数参数)mutable或exception -返回值函数体 ①函数对象参数； []，标识一个 Lambda 的开始，这部分必须存在，不能省略。函数对象参数是传递给编译器自动生成的函数对象类的构造函数的。函数对象参数只能使用那些到定义 Lambda 为止时 Lambda 所在作用范围内可见的局部变量（包括 Lambda 所在类的 this）。函数对象参数有以下形式： ▲空。没有使用任何函数对象参数。 ▲。函数体内可以使用 Lambda 所在作用范围内所有可见的局部变量（包括 Lambda 所在类的 this），并且是值传递方式（相当于编译器自动为们按值传递了所有局部变量）。 ▲。函数体内可以使用 Lambda 所在作用范围内所有可见的局部变量（包括 Lambda 所在类的 this），并且是引用传递方式（相当于编译器自动为们按引用传递了所有局部变量）。 ▲ this。函数体内可以使用 Lambda 所在类中的成员变量。 ▲ a。将 a 按值进行传递。按值进行传递时，函数体内不能修改传递进来的 a 的拷贝，因为默认情况下函数是 const 的。要修改传递进来的 a 的拷贝，可以添加 mutable 修饰符。 ▲ a。将 a 按引用进行传递。 ▲ a, b。将 a 按值进行传递，b 按引用进行传递。 ▲ ，a, b。除 a 和 b 按引用进行传递外，其他参数都按值进行传递。 ▲ , a, b。除 a 和 b 按值进行传递外，其他参数都按引用进行传递。 int m = 0, n = 0;[=] (int a) mutable m = ++n + a; (4); [] (int a) m = ++n + a; (4); [=,m] (int a) mutable m = ++n + a; (4); [,m] (int a) mutable m = ++n + a; (4); [m,n] (int a) mutable m = ++n + a; (4); [m,n] (int a) m = ++n + a; (4); ② 操作符重载函数参数； 标识重载的()操作符的参数，没有参数时，这部分可以省略。参数可以通过按值（如：(a,b)）和按引用（如：(a,b)）两种方式进行传递。 ③ 可修改标示符； mutable 声明，这部分可以省略。按值传递函数对象参数时，加上 mutable 修饰符后，可以修改按值传递进来的拷贝（注意是能修改拷贝，而不是值本身）。 ④ 错误抛出标示符； exception 声明，这部分也可以省略。exception 声明用于指定函数抛出的异常，如抛出整数类型的异常，可以使用 throw(int) ⑤ 函数返回值； -返回值类型，标识函数返回值的类型，当返回值为 void，或者函数体中只有一处 return 的地方（此时编译器可以自动推断出返回值类型）时，这部分可以省略。 ⑥ 是函数体； {}，标识函数的实现，这部分不能省略，但函数体可以为空。 总结： 案例代码： mainwidget.h #ifndef MAINWIDGET_H#define MAINWIDGET_H#include QWidget#include QPushButton#include subwidget.h //子窗口头文件class MainWidget : public QWidget Q_OBJECTpublic: MainWidget(QWidget *parent = 0); ~MainWidget();public slots: void mySlot(); void changeWin(); void dealSub(); void dealSlot(int, QString);private: QPushButton b1; QPushButton *b2; QPushButton b3; SubWidget subWin;;#endif // MAINWIDGET_H subwidget.h #ifndef SUBWIDGET_H#define SUBWIDGET_H#include QWidget#include QPushButtonclass SubWidget : public QWidget Q_OBJECTpublic: explicit SubWidget(QWidget *parent = 0); void sendSlot();signals: /* 信号必须有signals关键字来声明 * 信号没有返回值，但可以有参数 * 信号就是函数的声明，只需声明，无需定义 * 使用：emit mySignal(); * 信号可以重载 */ void mySignal(); void mySignal(int, QString);public slots:private: QPushButton b;;#endif // SUBWIDGET_H main.cpp #include mainwidget.h#include QApplicationint main(int argc, char *argv[]) QApplication a(argc, argv); MainWidget w;//执行MainWidget的构造函数 w.show(); return a.exec(); mainwidget.cpp #include mainwidget.h#include QPushButton#include QDebug //打印MainWidget::MainWidget(QWidget *parent) : QWidget(parent) b1.setParent(this); b1.setText(close); b1.move(100, 100); b2 = new QPushButton(this); b2-setText(abc); connect(b1, QPushButton::pressed, this, MainWidget::close); /* b1: 信号发出者，指针类型 * QPushButton::pressed：处理的信号， 发送者的类名::信号名字 * this: 信号接收者 * MainWidget::close： 槽函数，信号处理函数 接收的类名::槽函数名字 * 发送-处理-接收-处理 */ /* 自定义槽，普通函数的用法 * Qt5：任意的成员函数，普通全局函数，静态函数 * 槽函数需要和信号一致（参数，返回值） * 由于信号都是没有返回值，所以，槽函数一定没有返回值 */ connect(b2, QPushButton::released, this, MainWidget::mySlot); connect(b2, QPushButton::released, b1, QPushButton::hide); /* 信号：短信 * 槽函数：接收短信的手机 */ setWindowTitle(老大); //this-setWindowTitle(老大);//等价同上 b3.setParent(this); b3.setText(切换到子窗口); b3.move(50, 50); //显示子窗口 //subWin.show(); connect(b3, QPushButton::released, this, MainWidget::changeWin); //处理子窗口的信号// void (SubWidget::*funSignal)() = SubWidget::mySignal;// connect(subWin, funSignal, this, MainWidget::dealSub);// void (SubWidget::*testSignal)(int, QString) = SubWidget::mySignal;// connect(subWin, testSignal, this, MainWidget::dealSlot); //Qt4信号连接 //Qt4槽函数必须有slots关键字来修饰 connect(subWin, SIGNAL(mySignal()), this, SLOT(dealSub()) ); connect(subWin, SIGNAL(mySignal(int,QString)), this, SLOT(dealSlot(int,QString)) ); //缺点： SIGNAL SLOT 将函数名字 - 字符串 不进行错误检查 //Lambda表达式, 匿名函数对象 //C++11增加的新特性， 项目文件： CONFIG += C++11 //Qt配合信号一起使用，非常方便 QPushButton *b4 = new QPushButton(this); b4-setText(Lambda表达式); b4-move(150, 150); int a = 10, b = 100; connect(b4, QPushButton::clicked, // = :把外部所有局部变量、类中所有成员以值传递方式 // this: 类中所有成员以值传递方式 // : 把外部所有局部变量， 引用符号 [=](bool isCheck) qDebug() isCheck; ); resize(400, 300);void MainWidget::dealSlot(int a, QString str) // str.toUtf8() - 字节数组QByteArray // ……data() - QByteArray - char * qDebug() a str.toUtf8().data();void MainWidget::mySlot() b2-setText(123);void MainWidget::changeWin() //子窗口显示 subWin.show(); //本窗口隐藏 this-hide();void MainWidget::dealSub() //子窗口隐藏 subWin.hide(); //本窗口显示 show();MainWidget::~MainWidget() subwidget.cpp #include subwidget.hSubWidget::SubWidget(QWidget *parent) : QWidget(parent) this-setWindowTitle(小弟); b.setParent(this); b.setText(切换到主窗口); connect(b, QPushButton::clicked, this, SubWidget::sendSlot); resize(400, 300);void SubWidget::sendSlot() emit mySignal(); emit mySignal(250, 是子窗口);SingnalAndSlot.proQT += core guigreaterThan(QT_MAJOR_VERSION, 4): QT += widgetsTARGET = 03_SignalAndSlotTEMPLATE = appSOURCES += main.cpp\\ mainwidget.cpp \\ subwidget.cppHEADERS += mainwidget.h \\ subwidget.hCONFIG += C++11","tags":["clippings"],"categories":["2.语言","Qt","信号槽"]},{"title":"信号与槽连接的优化","path":"/2024/03/13/2-语言-Qt-信号槽-信号与槽连接的优化/","content":"包括在内，许多初学者在连接信号与槽的时候，常常使用一个信号对应一个槽函数，这种方式虽然在简单的小练习中能正常工作，但一旦项目规模稍微扩大，所需要编写的槽函数数量迅速增加，似乎变得有些难以管理。例如，当用户在界面上进行各种操作时，每个操作都可能触发相应的事件来发出信号，而这些信号如果要一一对应到槽函数，将会导致代码量的显著增加。 m_firstButton = new QPushButton(first, this);m_secondButton = new QPushButton(second, this);connect(m_firstButton, SIGNAL(clicked()), this, SLOT(firstButtonSlot()));connect(m_secondButton, SIGNAL(clicked()), this, SLOT(secondButtonSlot())); 显然，上述方式适用于简单的场景，但在复杂的项目中们需要寻找更高效的方法来减少槽函数的数量，达到简化代码的目的。这里，QObject 类中的 sender() 方法将大大简化们的工作。通过这个方法，们可以确定哪个对象发出了信号，从而在一个通用的槽函数中处理不同的按钮事件。 m_firstButton = new QPushButton(first, this);m_secondButton = new QPushButton(second, this);QHBoxLayout *layout = new QHBoxLayout(this);layout-addWidget(m_firstButton);layout-addWidget(m_secondButton);connect(m_firstButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));connect(m_secondButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));void c::buttonClickedSlot() // 获取发出信号的对象 auto button = qobject_castQPushButton*(this-sender()); // 对对象进行判断 if (button == m_firstButton) qDebug() firstButtonClicked; else if (button == m_secondButton) qDebug() secondButtonClicked; 通过这种方式，们可以清楚地识别是哪个按钮触发了点击事件，从而在一个集中处理的地方管理按钮的响应。这样，们不仅减少了槽函数的数量，代码的逻辑也更加清晰。 除了这种连接信号与槽的方式，Qt 还允许使用信号连接信号。但是，如果们这样做，会存在一个问题：无法判断到底是哪个对象发出的信号。例如，当们连接两个按钮的点击信号到同一个槽时，最终只会收到一个按钮信号，导致无法区分。 // 用信号连接一个信号connect(m_firstButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));connect(m_secondButton, SIGNAL(clicked()), m_firstButton, SIGNAL(clicked()));void c::buttonClickedSlot() auto button = qobject_castQPushButton*(this-sender()); if (button == m_firstButton) qDebug() firstButtonClicked; else if (button == m_secondButton) qDebug() secondButtonClicked; 在这种情况下，即使们点击第二个按钮，发出的信号仍然是与第一个按钮关联的，因此不能达到们想要的结果。 此外，在实际开发中，常常需要通过代码模拟用户的操作，尤其是在自动化测试或特定功能实现时。以 QPushButton 为例，它内置了一些方法，可以通过代码模拟按钮的点击事件。 // 模拟用户点击按钮m_firstButton-click();m_firstButton-toggle(); 此外，QPushButton 中提供了一系列与信号相对应的槽函数，如： public Q_SLOTS: void setIconSize(const QSize size); void animateClick(int msec = 100); // 模拟点击 void click(); // 通常用于模拟按钮点击 void toggle(); // 切换按钮的选中状态 void setChecked(bool); // 设置按钮是否选中 这些方法为开发者提供了更加灵活的方式，以便在代码中实现复杂的用户交互逻辑，从而提升程序的可维护性和可读性。","tags":["clippings"],"categories":["2.语言","Qt","信号槽"]},{"title":"信号槽","path":"/2024/03/12/2-语言-Qt-信号槽-信号槽/","content":"1. Qt4 信号槽方式信号发送者、信号、信号接收者、处理函数 connect(pushBtn, SIGNAL(clicked(bool)), this, SLOT(slot_Qt4())); 这种方式是 Qt4 以及之前版本中连接信号和槽的传统方法。SIGNAL 和 SLOT 是宏，会在编译时展开，生成相应的代码。在运行时，Qt 的元对象系统会根据字符串进行信号和槽的连接。这种方式虽然灵活，但存在一些问题： 类型安全性：由于使用字符串来表示信号和槽的名称，编译器无法在编译时检查信号和槽的参数是否匹配。只有在运行时才会发现错误。 效率：由于信号和槽的连接是基于字符串的，会导致运行时解析开销较大。 2. Qt5 信号槽方式Qt5 引入了新的信号槽连接方式，使用指向成员函数的指针，提供了更高的类型安全性和效率。 connect(pushBtn, QPushButton::clicked, this, Widget::slot_Qt5); 这种方式的优势在于： 编译时检查：编译器会检查信号和槽的参数类型是否匹配，避免了运行时错误。 效率：由于直接使用函数指针，避免了运行时解析字符串的开销，连接速度更快。 3. Qt5 Lambda 表达式Qt5 还支持使用 C++11 的 Lambda 表达式来连接信号和槽。 connect(pushBtn, QPushButton::clicked, [=]() qDebug() lambda 表达式;); 这种方式在 Qt5 中非常常用，具有以下特点： 匿名函数：Lambda 表达式可以定义在连接语句中，避免了定义槽函数的麻烦。 捕获变量：[=] 是 Lambda 表达式的捕获列表，表示以值传递的方式捕获 Lambda 表达式所在作用域中的所有自动变量，包括 this 指针。捕获的变量在 Lambda 表达式内部可以访问，但不能修改（除非使用 mutable 关键字）。 类型安全性：编译器会检查 Lambda 表达式的参数类型是否与信号的参数类型匹配。 4. 配置 C++11 支持为了使用 Lambda 表达式，需要在项目文件（.pro 文件）中添加以下配置： CONFIG += C++11 这告诉 Qt 编译器支持 C++11 的特性，包括 Lambda 表达式。 5. 总结 Qt4 方式：灵活但缺乏类型安全性，运行时解析开销大。 Qt5 方式：类型安全，效率高，推荐使用。 Lambda 表达式：简洁方便，适合需要快速定义处理逻辑的场景。 通过以上几种方式，可以根据具体需求选择合适的信号槽连接方式。","categories":["2.语言","Qt","信号槽"]},{"title":"信号槽传递大量数据的效率","path":"/2024/03/11/2-语言-Qt-信号槽-信号槽传递大量数据的效率/","content":"1. 隐式共享在开发过程中，开发者经常面临着数据传递时的效率问题。特别是在 Qt 框架下，当需要通过信号槽传递大量数据时候，复制和拷贝的开销可能会给性能带来影响。为了优化这一过程，很多开发者选择使用指针传递数据，以避免不必要的数据复制。然而，Qt 中的隐式共享机制有效地解决了这个问题，使得开发者无需为此担忧。 隐式共享是一种资源管理策略，通过共享相同的数据副本来减少内存使用和提高效率。需要指出的是，隐式共享有其特定的条件和适用规则，并不是所有数据结构都支持。例如， QByteArray 和 QString 就支持隐式共享，但一些其他结构可能不具备这一特性。 #include QCoreApplication#include QDebugint main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建一个包含hello world的字节数组 QByteArray b2 = b1; // 这里发生了浅拷贝，b1和b2指向相同的数据 qDebug() 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); qDebug() 0x + QString::number(reinterpret_castqintptr(b2.constData()), 16); b2 = 好，世界; // 修改b2的内容，此时会触发深拷贝 qDebug() Qt::endl; qDebug() 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); // 仍然为b1的地址 qDebug() 0x + QString::number(reinterpret_castqintptr(b2.constData()), 16); // b2的新地址 return a.exec(); 输出结果为： 0x1b65580x1b65580x1b65580x1b7d68 在这个示例中，b1 和 b2 初始时指向同一个内存地址。对 b2 的修改会触发深拷贝，这意味着 b2 现在有了自己的内存副本，而 b1 的数据依然是原来的内容。这种机制不仅提高了效率，也减轻了不必要的内存占用。 2.信号槽中的隐式共享信号槽机制是 Qt 的一个核心特性，它允许对象之间以松耦合的方式进行通信。这种通信方式也能受益于隐式共享，进一步提升数据传输的效率。 #include QCoreApplication#include QDebugclass Test : public QObject Q_OBJECTpublic: void received(QByteArray byte) qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); byte = x; // 此时会触发深拷贝 qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); signals: void sigByte(QByteArray byte); // 定义信号;int main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建字节数组 qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); Test t; // 创建Test类的实例 QObject::connect(t, Test::sigByte, t, Test::received); //连接信号和槽 emit t.sigByte(b1); // 发送信号 return a.exec();#include main.moc 输出结果为： int main(int, char**) 0xf66558void Test::received(QByteArray) 0xf66558void Test::received(QByteArray) 0xf67df8 这个例子展示了在信号槽中如何使用隐式共享。当信号 sigByte 发送时，received 槽接收的 byte 最初与 b1 指向同一内存位置。修改 byte 的内容，将触发深拷贝，确保 b1 的数据不会被改变。这意味着在添加信号槽时间劣化的风险可以被降到最低，优化了程序整体性能。 3.多线程中信号槽的隐式共享在现代应用开发中，多线程编程可以显著提升程序的响应能力和处理性能。Qt 的信号槽机制在多线程环境中同样有效，并且隐式共享在这里依然能大放异彩。 #include QCoreApplication#include QDebug#include QThreadclass Test : public QObject Q_OBJECTpublic: void received(QByteArray byte) qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); byte = x; // 触发深拷贝 qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); signals: void sigByte(QByteArray byte); // 定义信号;int main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建字节数组 qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); Test t; QObject::connect(t, Test::sigByte, t, Test::received); // 连接信号和槽 QThread th; // 创建新的线程 t.moveToThread(th); // 将测试对象移入新线程 th.start(); emit t.sigByte(b1); // 发送信号，通过新线程处理 return a.exec();#include main.moc 输出结果为： QThread(0xdd5ff0) int main(int, char**) 0xdd6558QThread(0x69fd60) void Test::received(QByteArray) 0xdd6558QThread(0x69fd60) void Test::received(QByteArray) 0x2593a48 此示例中，信号 sigByte 发送的数据在新的线程 th 中被处理。标准的隐式共享机制依然适用，从上面的输出可以看到，received 槽输出的内存地址最初与 b1 相同，之后的深拷贝确保了 b1 的数据不被修改。这样不仅保持了数据安全性，也提供了多线程的灵活性。 4.结论通过以上示例，无论是在单线程还是多线程环境中，Qt 的信号槽机制都有效支持隐式共享。这种机制减少了数据传输中的拷贝开销，使得即使在传递大数据量时也不会显著影响性能。 尽管在测试中主要围绕 QByteArray 展示了隐式共享的性质，但其他数据结构是否支持隐式共享仍需查阅 Qt 官方文档或进行功能测试。在某些情况下，为了进一步优化性能，建议在信号槽连接时使用常引用 const QByteArray 来传递数据，这样既能避免临时变量的构造开销，也能确保在信号传输过程中不会造成数据的复制和不必要的内存使用。在多线程环境中，使用常引用同样是一个有效且高效的选择。","tags":["clippings"],"categories":["2.语言","Qt","信号槽"]},{"title":"信号槽分析","path":"/2024/03/08/2-语言-Qt-信号槽-信号槽分析/","content":"moc 元对象编译器, 全称是 Meta-Object Compiler，也就是”元对象编译器”。是 QT 翻译扩展语法到 C++语言的工具，目前见扩展了信号与槽机制。 信号槽方式编程上更方便（不容易出错） 回调需要自行处理麻烦的回调管理，稍微不注意就出错。 而且信号槽方式更利于 mvc 分离实现。 信号和槽机制的优点: 类型安全, 关联的信号和槽的参数必须是等同。 降低 Qt 对象间的耦合度,只需要 emit,对象无需知道哪个对象来接收该信号, 信号槽的效率和回调函数相比,变低 10 倍, 原因如下: 1）需要定位接收信号的对象。 2）遍历所有的关联（如一信号对多槽） 3）传递的参数 4）多线程的时候。信号可能需要排队等待。 **1.**信号和槽实现 1.Q_OBJECT Q_OBJECT 展开后,会有一个 QMetaObject 元对象静态类、还有一些元对象操作函数： signals****和 slots: 们以这为例: 预处理之前会调用 moc 程序，对文件预处理之后生成一个 moc_xxx.cpp 文件. 如下图所示: moc 会将 signals 和 slots 下的函数名转换为字符数组.并生成一个名称 idx 索引号. 然后生成一个 qt_meta_data_Widget(由于类名是 Widget,所以后缀是 Widget)数组: 其中 4, 14,表示有 4 个方法,然后 14 表示 unit 偏移位置,即 qt_meta_data_Widget[14]就是第一个方法. 然后并创建一个 qt_static_metacall 回调函数,实现调用目标类指针的槽函数: 当调用 emit 信号时,其实就是调用 moc 实现的一个信号函数, 信号函数内部调用了 QMetaObject::activate()函数: 而 activate 函数就会去 QObjectConnectionListVector 连接链表容器里面查找信号对应的索引号所在的值,里面存放了每个接受对象指针和槽函数 id 的链表: 然后遍历该信号关联的链表里的所有目标对象指针和槽函数,并调用 qt_static_metacall 回调函数,实现调用槽函数. connect: connect 会将信号和槽函数字符串化, 然后执行 connect 的时候会判断信号槽参数是否一致.并遍历”信号槽”字符串的索引号.如果索引号都定义了,则在发送方的连接链表容器的信号索引处,添加一个目标对象指针和槽函数索引号的类到链表中.","tags":["clippings"],"categories":["2.语言","Qt","信号槽"]},{"title":"操作MySQL","path":"/2024/03/07/2-语言-Qt-数据库-操作MySQL/","content":"项目文件 proQT += sql 头文件#include QSqlDatabase#include QSqlQuery#include QSqlError 查询数据库驱动qDebug() QSqlDatabase::drivers(); 此行代码打印出可用的数据库驱动列表，开发者可以通过此信息确认所需驱动是否安装成功，确保数据库交互操作正常。 连接数据库QSqlDatabase db = QSqlDatabase::addDatabase(QMYSQL); 这里的代码创建了一个名为 db 的 QSqlDatabase 对象，并指定使用的数据库驱动为 QMYSQL，即 MySQL 数据库。 db.setHostName(127.0.0.1); // 本地服务器 IPdb.setPort(3306); // 端口号db.setDatabaseName(test); // 数据库名称db.setUserName(root); // 用户名db.setPassword(); // 密码 这些设置分别定义了数据库连接所需的主机名、端口号、数据库名、用户名和密码。在这个例子中，连接的是本地数据库，用户名为 root，没有密码。 if (!db.open()) // 打开数据库 qDebug() db.lastError(); // 输出错误信息 如果数据库打开失败，lastError() 方法会返回错误信息，方便调试连接问题。 db.close(); // 关闭数据库 在完成数据库操作后，关闭数据库连接是一种良好的实践。 创建数据表QSqlQuery query;bool ok = query.exec(create table student(id int primary key auto_increment, name varchar(255), age int, score int) ENGINE=INNODB;); 此代码执行了一个 SQL 查询，以创建一个名为 student 的表，表中包含 id（自增主键）、name（学生姓名）、age（年龄）和 score（分数）等字段。如果表创建失败，接下来的代码块将捕获并输出错误信息。 if (!ok) qDebug() query.lastError(); // 输出创建表的错误信息 数据插入QSqlQuery query;bool ok = query.exec(insert into student(id, name, age, score) values(1, 张三, 18, 80)); 这行代码向 student 表中插入了一条记录，包含学生 ID、姓名、年龄和分数。如果插入操作失败，错误信息将被打印出来以便于查错。 if (!ok) qDebug() query.lastError(); // 输出插入数据的错误信息 数据修改QSqlQuery query;bool ok = query.exec(update student set score=100 where name=张三); 此代码更新 student 表中名为 张三 的学生的分数。如果更新操作失败，系统会输出相关错误信息。 if (!ok) qDebug() query.lastError(); // 输出修改数据的错误信息 数据查询QSqlQuery query;bool ok = query.exec(select id from student where name=张三); 该语句从 student 表中查询姓名为 张三 的学生的 ID。若查询失败，错误信息将被打印。 if (!ok) qDebug() query.lastError(); // 输出查询的错误信息else query.next(); qDebug() query.value(0).toInt(); // 输出查询结果 在成功执行查询后，使用 next() 方法移动到结果集的下一条记录，然后获取结果并打印出来。 遍历整个表ok = query.exec(select * from student); 这一行代码用于查询 student 表中的所有记录。 if (!ok) qDebug() query.lastError(); // 输出遍历表的错误信息else while (query.next()) // 遍历完为 false // 方式1：以下标 qDebug() query.value(0).toInt() query.value(1).toString() query.value(2).toInt() query.value(3).toInt(); // 方式2：以字段 // qDebug() query.value(id).toInt() query.value(name).toString() query.value(age).toInt() query.value(score).toInt(); 在本段代码中，使用 next() 方法遍历整个结果集。两种打印方式中，第一种是通过字段索引获取记录，第二种对字段名进行访问，二者都能有效获取数据。 数据删除QSqlQuery query;bool ok = query.exec(delete from student where name=张三); 此语句通过姓名删除 student 表中对应的记录。如果操作失败，相关错误信息将被输出。 if (!ok) qDebug() query.lastError(); // 输出删除数据的错误信息 删除整个表QSqlQuery query;bool ok = query.exec(drop table student); 该行代码用来删除整个 student 表，从而清除所有相关数据。删除操作的错误信息同样会被捕获并输出。 if (!ok) qDebug() query.lastError(); // 输出删除整个表的错误信息 最后，关闭数据库连接以释放资源。 db.close(); // 关闭数据库 示例// 在.pro文件中增加对Qt SQL模块的支持QT += sql// 头文件部分，定义MainWindow类，继承自QMainWindowQT_END_NAMESPACEclass MainWindow : public QMainWindow Q_OBJECTpublic: // 构造函数，接受一个父级窗口指针，默认为nullptr MainWindow(QWidget *parent = nullptr); // 析构函数，负责资源释放 ~MainWindow();private slots: // 定义多个槽函数，响应按钮点击事件 void on_pushButton_5_clicked(); // 连接数据库 void on_pushButton_6_clicked(); // 查询操作 void on_pushButton_clicked(); // 添加数据 void on_pushButton_2_clicked(); // 通过主键删除数据 void on_pushButton_3_clicked(); // 更新数据private: Ui::MainWindow *ui; // 界面对象指针 QSqlDatabase db; // 数据库对象;// 以防止重复包含头文件#endif // MAINWINDOW_H// 实例化SQL数据库对象db = QSqlDatabase::addDatabase(QMYSQL); // 选择使用MySQL驱动db.setHostName(localhost); // 设置主机名db.setDatabaseName(test); // 指定数据库名称db.setUserName(root); // 设置用户名db.setPassword(password); // 设置密码db.setPort(3306); // 设置端口号（默认为3306）// 连接数据库的槽函数实现void MainWindow::on_pushButton_5_clicked() if (db.open()) // 尝试打开数据库连接 // 连接成功，向文本编辑器添加信息 ui-textEdit-append(connect success!); QMessageBox::information(this, connection info, connect success!); else // 连接失败 QString errInfo = db.lastError().text(); // 获取错误信息 QMessageBox::information(this, connection info, connect failed! + errInfo); // 执行查找操作的槽函数实现void MainWindow::on_pushButton_6_clicked() QString sql = select * from fam; // SQL查询语句 QSqlQuery query; // 创建查询对象 query.exec(sql); // 执行查询 ui-textEdit-clear(); // 清空文本编辑器内容 while (query.next()) // 遍历查询结果 ui-textEdit-insertPlainText(QString::number(query.value(0).toInt()) + ); // 插入ID ui-textEdit-insertPlainText(QString(query.value(1).toString()) + ); // 插入姓名 ui-textEdit-insertPlainText(QString(query.value(2).toString()) + ); // 插入地址 ui-textEdit-insertPlainText(QString::number(query.value(3).toInt()) + ); // 插入年龄 ui-textEdit-insertPlainText(QString(query.value(4).toString() + )); // 插入性别 // 添加数据的槽函数实现void MainWindow::on_pushButton_clicked() db.transaction(); // 开始事务处理 QSqlQuery query; // 创建查询对象 int index = ui-lineEdit-text().toInt(); // 从输入框获取ID QString name = ui-lineEdit_2-text(); // 从输入框获取姓名 QString addres = ui-lineEdit_3-text(); // 从输入框获取地址 int age = ui-lineEdit_4-text().toInt(); // 从输入框获取年龄 QString gender = ui-lineEdit_5-text(); // 从输入框获取性别 // 组装插入SQL语句 QString sql = QString(insert into fam (id, name, address, age, gender) values (%1, %2, %3, %4, %5)) .arg(index).arg(name).arg(addres).arg(age).arg(gender); // 执行插入，如果所有条件满足 if (query.exec(sql) !addres.isEmpty() !gender.isEmpty()) db.commit(); // 提交事务 // 清空输入框供下次使用 ui-lineEdit-clear(); ui-lineEdit_2-clear(); ui-lineEdit_3-clear(); ui-lineEdit_4-clear(); ui-lineEdit_5-clear(); // 输出添加的数据到文本编辑器 ui-textEdit-insertPlainText(QString::number(index) + ); // 输出ID ui-textEdit-insertPlainText(name + ); // 输出姓名 ui-textEdit-insertPlainText(addres + ); // 输出地址 ui-textEdit-insertPlainText(QString::number(age) + ); // 输出年龄 ui-textEdit-insertPlainText(gender + ); // 输出性别 else // 处理插入失败的情况 db.rollback(); // 回滚事务 QMessageBox::information(this, connection info, add failed!); // 提示添加失败 // 通过主键删除数据的槽函数实现void MainWindow::on_pushButton_2_clicked() db.transaction(); // 开始事务处理 QSqlQuery query; // 创建查询对象 int index = ui-lineEdit-text().toInt(); // 从输入框获取ID if (!ui-lineEdit-text().isEmpty()) // 检查输入框是否为空 // 拼装删除SQL语句 QString sql = QString(delete from fam where id=%1).arg(index); if (query.exec(sql)) // 执行删除操作 db.commit(); // 提交事务 else // 删除失败 QMessageBox::information(this, connection info, delete failed!); // 提示删除失败 db.rollback(); // 回滚事务 ui-textEdit-clear(); // 清空文本编辑器 QString sql = select * from fam; // 查询所有数据 query.exec(sql); // 执行查询 ui-textEdit-clear(); // 清空文本编辑器 while (query.next()) // 遍历查询结果 ui-textEdit-insertPlainText(QString::number(query.value(0).toInt()) + ); // 插入ID ui-textEdit-insertPlainText(QString(query.value(1).toString()) + ); // 插入姓名 ui-textEdit-insertPlainText(QString(query.value(2).toString()) + ); // 插入地址 ui-textEdit-insertPlainText(QString::number(query.value(3).toInt()) + ); // 插入年龄 ui-textEdit-insertPlainText(QString(query.value(4).toString() + )); // 插入性别 // 数据更新的槽函数实现void MainWindow::on_pushButton_3_clicked() db.transaction(); // 开始事务处理 QSqlQuery query; // 创建查询对象 int index = ui-lineEdit-text().toInt(); // 从输入框获取ID QString name = ui-lineEdit_2-text(); // 从输入框获取姓名 QString addres = ui-lineEdit_3-text(); // 从输入框获取地址 int age = ui-lineEdit_4-text().toInt(); // 从输入框获取年龄 QString gender = ui-lineEdit_5-text(); // 从输入框获取性别 // 更新SQL语句 QString sql = QString(update fam set name=%1, address=%2, age=%3, gender=%4 where id=%5) .arg(name).arg(addres).arg(age).arg(gender).arg(index); // 执行更新操作 if (query.exec(sql) !addres.isEmpty() !gender.isEmpty()) db.commit(); // 提交事务 // 清空输入框 ui-lineEdit-clear(); ui-lineEdit_2-clear(); ui-lineEdit_3-clear(); ui-lineEdit_4-clear(); ui-lineEdit_5-clear(); // 输出更新后的数据到文本编辑器 ui-textEdit-insertPlainText(QString::number(index) + ); // 输出ID ui-textEdit-insertPlainText(name + ); // 输出姓名 ui-textEdit-insertPlainText(addres + ); // 输出地址 ui-textEdit-insertPlainText(QString::number(age) + ); // 输出年龄 ui-textEdit-insertPlainText(gender + ); // 输出性别 else // 处理更新失败情况 db.rollback(); // 回滚事务 QMessageBox::information(this, connection info, update failed!); // 提示更新失败","categories":["2.语言","Qt","数据库"]},{"title":"数据库Sqlite3的使用","path":"/2024/03/06/2-语言-Qt-数据库-数据库Sqlite3的使用/","content":"创建数据库void SqlDriver::CreatDb() if(QSqlDatabase::contains(qt_sql_default_connection)) db = QSqlDatabase::database(qt_sql_default_connection); else db = QSqlDatabase::addDatabase(QSQLITE); db.setDatabaseName(test.db); db.setUserName(test); db.setPassword(test); 打开及关闭数据库bool SqlDriver::OpenDb() if(!db.open()) qDebug() Error: Failed to connect database. db.lastError(); return false; return true;void SqlDriver::CloseDb() db.close(); 查找数据表bool SqlDriver::searchTable(QString table) if (query-exec(SELECT name FROM sqlite_master)) while (query-next()) if (query-value(0).toString() == table) qDebug()find tablesquery-value(0).toString(); return true; // 找到指定表名，返回 true else qDebug() Error executing SHOW TABLES: query-lastError().text(); return false; 创建数据表void SqliteOperator::CreateTable() if(!searchTable(SubInfo)) query-exec(create table SubInfo (code varchar(8) primary key, name varchar(30), lastTime varchar(30), lastValue varchar(30), lastPercent varchar(30))); 插入更新数据void SqlDriver::setNetValue(MSG_CONTENT set_msg) //确认主表中是否包含该数据 query-exec(select * from SubInfo); bool hasAdded = false; while(query-next()) if(set_msg.code == query-value(0).toString()) hasAdded = true; //如果已经添加到主表中去，则更新新数据到主表中去 if(hasAdded) query-exec(QString(UPDATE SubInfo SET name = %1, lastTime = %2, lastValue = %3, lastPercent = %4 WHERE code = %5) .arg(set_msg.name) .arg(set_msg.lastTime) .arg(set_msg.lastNetValue) .arg(set_msg.lastPercent) .arg(set_msg.code)); //如果主表中没有该数据，则插入新的数据 else if(!query-exec(QString(insert into SubInfo values (%1, %2, %3, %4, %5)) .arg(set_msg.code) .arg(set_msg.name) .arg(set_msg.lastTime) .arg(set_msg.lastNetValue) .arg(set_msg.lastPercent))) qDebug()query-lastError().text(); void SqlDriver::setHistory(MSG_CONTENT set_msg) //检测是否有该数据的历史记录 if(searchTable(set_msg.code)) //query-exec(QString(drop table %1).arg(set_msg.code)); query-exec(QString(select * from %1).arg(set_msg.code)); MSG_CONTENT set_msg_tmp; while(query-next()) set_msg_tmp.hisDate.append(query-value(0).toString()); set_msg_tmp.hisNetValue.append(query-value(1).toString()); set_msg_tmp.hisPercent.append(query-value(2).toString()); int oldSize = set_msg_tmp.hisDate.size(); int newSize = set_msg.hisDate.size(); if( oldSize newSize) //插入历史数据 for(int i=oldSize; inewSize; i++) query-exec(QString(insert into %1 values (%2, %3, %4)) .arg(set_msg.code) .arg(set_msg.hisDate.at(i)) .arg(set_msg.hisNetValue.at(i)) .arg(set_msg.hisPercent.at(i))); else //创建该数据的历史记录表 if(!query-exec(QString(create table %1 (time varchar(16) primary key, netValue varchar(30), percent varchar(30))).arg(set_msg.code))) qDebug()create table failedset_msg.codequery-lastError().text(); //插入历史数据 for(int i=0; iset_msg.hisDate.size(); i++) query-exec(QString(insert into %1 values (%2, %3, %4)) .arg(set_msg.code) .arg(set_msg.hisDate.at(i)) .arg(set_msg.hisNetValue.at(i)) .arg(set_msg.hisPercent.at(i))); 查询数据void SqlDriver::getNetValue(QListMSG_CONTENT *msg_content) query-exec(select * from SubInfo); while(query-next()) qDebug()find codesquery-value(0).toString(); MSG_CONTENT msg_tmp; msg_tmp.code = query-value(0).toString(); msg_tmp.name = query-value(1).toString(); msg_tmp.lastTime = query-value(2).toString(); msg_tmp.lastNetValue = query-value(3).toString(); msg_tmp.lastPercent = query-value(4).toString(); msg_content-append(msg_tmp); void SqlDriver::getHistory(MSG_CONTENT* subNode) if(searchTable(subNode-code))//在表格中包含历史记录 query-exec(QString(select * from %1).arg(subNode-code)); while(query-next()) subNode-hisDate.append(query-value(0).toString()); subNode-hisNetValue.append(query-value(1).toString()); subNode-hisPercent.append(query-value(2).toString()); 条件查询void SqliteOperator::QueryData() QString select_sql = QString(select * from SubInfo where name = %1 and (age = %2 or age = %3)) .arg(Wang) .arg(30) .arg(25); QSqlQuery sql_query; if(!sql_query.exec(select_sql)) qDebug()sql_query.lastError(); else while(sql_query.next()) int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); qDebug()QString(id:%1 name:%2).arg(id).arg(name); 删除数据和表void SqlDriver::delNetValue(QString code) if (!query-exec(QString(delete from SubInfo where code = %1).arg(code))) qDebug()delete subinfo failedcodequery-lastError().text(); if (!query-exec(QString(drop table %1).arg(code))) qDebug()drop table failedcodequery-lastError().text(); 示例database.h#ifndef DATABASE_H#define DATABASE_H#include QTextCodec#include QSqlDatabase#include QSqlQuery#include QTime#include QSqlError#include QtDebug#include QSqlDriver#include QSqlRecordclass DataBasepublic: bool createConnection();//创建一个连接 bool createTable(); //创建数据库表 bool insert(); //出入数据 bool queryAll(); //查询所有信息 bool updateById(intid);//更新 bool deleteById(int id);//删除 bool sortById(); //排序;#endif// DATABASE_H database.cpp#include database.h//建立一个数据库连接bool DataBase::createConnection() //以后就可以用sqlite1与数据库进行连接了 QDatabase db = QDatabase::database(QSQLITE); db.setDatabaseName(.//qtDb.db); if(!db.open()) qDebug()无法建立数据库连接; return false; return true;//创建数据库表bool DataBase::createTable() QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); bool success = query.exec(create table automobil(id int primary key,attribute varchar, type varchar,kind varchar,nation int,carnumber int,elevator int, distance int,oil int,temperature int)); if(success) qDebug()QObject::tr(数据库表创建成功! ); return true; else qDebug()QObject::tr(数据库表创建失败! ); return false; //向数据库中插入记录bool DataBase::insert() QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); query.prepare(insert into automobil values(?,?,?,?,?,?,?,?,?,?)); long records = 10; for(int i = 0; i records; i++) query.bindValue(0, i); query.bindValue(1,四轮); query.bindValue(2,轿车); query.bindValue(3,富康); query.bindValue(4,rand()%100); query.bindValue(5,rand()%10000); query.bindValue(6,rand()%300); query.bindValue(7,rand()%200000); query.bindValue(8,rand()%52); query.bindValue(9,rand()%100); bool success = query.exec(); if(!success) QSqlError lastError = query.lastError(); qDebug()lastError.driverText()QString(QObject::tr(插入失败)); return false; return true;//查询所有信息bool DataBase::queryAll() QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); query.exec(select * from automobil); QSqlRecord rec = query.record(); qDebug()QObject::tr(automobil表字段数:)rec.count(); while(query.next()) for(int index = 0; index 10;index++) qDebug()query.value(index) ; qDebug() ; //根据ID删除记录bool DataBase::deleteById(int id) QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); query.prepare(QString(delete from automobil where id = %1).arg(id)); if(!query.exec()) qDebug()删除记录失败!; return false; return true;//根据ID更新记录bool DataBase::updateById(int id) QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); query.prepare(QString(update automobil set attribute =?,type =?,kind =?,nation =?, carnumber =?,elevator =?,distance =?,oil =?, temperature =? where id = %1).arg(id)); query.bindValue(0,四轮); query.bindValue(1,轿车); query.bindValue(2,富康); query.bindValue(3,rand()%100); query.bindValue(4,rand()%10000); query.bindValue(5,rand()%300); query.bindValue(6,rand()%200000); query.bindValue(7,rand()%52); query.bindValue(8,rand()%100); bool success = query.exec(); if(!success) QSqlError lastError = query.lastError(); qDebug()lastError.driverText()QString(QObject::tr(更新失败)); return true;//排序bool DataBase::sortById() QSqlDatabase db = QSqlDatabase::database(sqlite1);//建立数据库连接 QSqlQuery query(db); bool success = query.exec(select * from automobil order by id desc); if(success) qDebug()QObject::tr(排序成功); return true; else qDebug()QObject::tr(排序失败!); return false; main.cpp#include QCoreApplication#include database.hint main(int argc, char *argv[]) QCoreApplication a(argc,argv); QTextCodec::setCodecForLocale(QTextCodec::codecForLocale()); DataBase d; d.createConnection();//创建连接 //d.createTable(); //d.insert(); d.queryAll(); //已经完成过createTable(),insert(),现在进行查询 return 0; 运行结果automobil表字段数: 10QVariant(qlonglong,0)QVariant(QString,四轮)QVariant (Qstring,轿车)QVariant(QString,富康) QVariant (qlonglong,41) QVariant(qlonglong,8467)QVariant (qlonglong,34) QVariant(qlonglong,26500 QVariant (qlonglong,33)QVariant (qlonglong,24)QVariant (qlonglong,1) QVariant(QString,四轮) QVariant (Qstring,轿车)QVariant(QString,富康) QVariant (qlonglong,78)","categories":["2.语言","Qt","数据库"]},{"title":"Qwt曲线绘制","path":"/2024/03/05/2-语言-Qt-绘图-Qwt曲线绘制/","content":"Qwt 编译安装及配置（动态） 下载与解压首先，下载 qwt-6.1.2.zip 文件并解压到本地。确保你能找到解压后的 qwt-6.1.2 文件夹。 进入文件夹并执行 qmake打开命令提示符（cmd），使用 cd 命令进入到 qwt-6.1.2 文件夹内。执行以下命令： qmake qwt.pro 注意：红色框中所示的路径是 QT 源码静态编译的目录。为了避免添加环境变量的麻烦，建议使用绝对路径。如果不使用绝对路径，则需要在系统环境变量中添加 QT 的路径，以便直接执行 qmake qwt.pro。 编译过程执行以下命令开始编译： mingw32-make 这个过程可能需要一些时间，请耐心等待。 安装 Qwt编译完成后，执行以下命令进行安装： mingw32-make install 这个过程通常需要十多分钟。 配置文件拷贝 将 qwt-6.1.2/lib 目录下的 qwt.dll 和 qwtd.dll 文件拷贝到 Qt 安装目录下的 Qt\\..\\mingw49_32\\bin 文件夹。 将 qwt-6.1.2/lib 目录下的 libqwt.a 和 qwtd.a 文件拷贝到 Qt 安装目录下的 Qt\\..\\mingw49_32\\lib 文件夹。 将 qwt-6.1.2/plugins/designer 目录下的 qwt_designer_plugin.dll 文件拷贝到 Qt 安装目录下的 Qt\\..\\mingw49_32\\plugins\\designer 文件夹。 在 E:\\software\\Qt\\Qt5.5.1\\5.5\\mingw492_32\\include 文件夹下新建一个名为 Qwt 的文件夹，并将 C:\\Qwt-6.1.2\\include 文件夹下的所有内容拷贝到新建的 Qwt 文件夹内。 注意事项在 .pro 文件内的链接路径需要根据实际情况进行调整。 Qwt 编译安装及配置（静态） 下载与解压同样，下载并解压 qwt-6.1.3.zip 文件。 修改编译设置进入 E:\\Qt\\qwt-6.1.3\\ 文件夹，进行以下修改： 将编译设置改为静态编译。 在相关文件中添加 -static 参数。 注意：红色框中所示的路径是静态编译后生成的 Qwt 的路径，可以根据自己的需求进行更改。 注释处理确保将不必要的行注释掉，以免影响编译。 编译过程通过命令提示符进入到 qwt-6.1.2 文件夹，执行以下命令： qmake qwt.pro 同样，红色框中所示的路径是 QT 源码静态编译的目录，建议使用绝对路径。 编译与安装执行以下命令开始编译： mingw32-make 这个过程可能需要一些时间，请耐心等待。完成后，执行： mingw32-make install 这个过程通常需要十多分钟。 配置文件拷贝 将 E:\\Qt\\qwt-6.1.3\\lib 下的 libqwt.a 拷贝到 QT 静态编译的环境目录 E:\\Qt\\5.4.0_MinGW_static\\lib 下。 将 E:\\Qt\\qwt-6.1.3\\designer\\plugins\\designer 下的 libqwt_designer_plugin.a 拷贝到 QT 静态编译的环境目录 E:\\Qt\\5.4.0_MinGW_static\\plugins\\designer 下。 新建文件夹新建一个名为 QtQwt 的文件夹，将 qwt 静态编译路径 C:\\Qwt-6.1.3-static\\include 中的所有头文件拷贝进去。然后将 QtQwt 文件夹复制到 QT 静态编译路径 E:\\Qt\\5.4.0_MinGW_static\\include 下。 链接路径设置在 .pro 文件内部添加链接路径： LIBS += -LE:\\Qt\\5.5.1_MinGW_static\\lib -lqwt 注意：蓝色部分为路径，根据自己的实际路径进行调整。 头文件引用如果工程文件需要使用特定的头文件，例如 qwt_plot_layout.h，请将其引用路径修改为 QtQwt\\qwt_plot_layout.h。 绘图坐标转换为时间为了将绘图坐标转换为时间，可以定义一个新的类 TimeScaleDraw，继承自 QwtScaleDraw。以下是实现的代码示例： class TimeScaleDraw: public QwtScaleDraw // 定义一个新类去继承 QwtScaleDrawpublic: TimeScaleDraw(const QTime base): baseTime(base) // 初始化成员变量 baseTime virtual QwtText label(double v) const // 重写 label 方法 QTime upTime = baseTime.addSecs((int)v); // 将坐标值转换为时间 return upTime.toString(hh:mm); // 返回格式化的时间字符串 private: QTime baseTime; // 存储基准时间; 这个类通过重写 label 方法，将绘图坐标转换为可读的时间格式，使得图表中的时间轴更加直观。","categories":["2.语言","Qt","绘图"]},{"title":"编译MySQL数据库驱动","path":"/2024/03/04/2-语言-Qt-数据库-编译MySQL数据库驱动/","content":"环境配置与依赖安装运行环境： Qt5.6（开源版） Ubuntu 14.04 LTS（x86_64） MySQL 5.7.11 下载与安装 MySQL： 从 mysql.comdownloadsmysql 下载 MySQL 5.7.11。 在 Ubuntu 14.04 上安装 Qt5.6 和 MySQL 5.7.11。 依赖问题与解决： 在安装过程中，若第七步提示找不到 libaio2，可通过以下命令安装相应包： sudo apt-get install libaio2 若提示缺少 libmecab2： mysql-community-server 依赖于 libmecab2 (= 0.996-1.1)；然而未安装软件包 libmecab2。 补充安装步骤： 若安装未完全，需按顺序安装以下几个包： mysql-server_5.7.11-ubuntu14.04_amd64.deb mysql-community-test_5.7.11-1ubuntu14.04_amd64.deb mysql-testsuite_5.7.11-1ubuntu14.04_amd64.deb 登录数据库： 登录 MySQL 数据库时，命令应使用小写： mysql -u root -p 编译 QMYSQL 插件下载 Qt 源码： 从 Qt5.6 官方下载地址 下载 qtbase-opensource-src。 安装依赖包： 如果出现依赖包未安装的情况，先执行以下命令安装： sudo apt-get install libmecab2 编译步骤： 进入 MySQL 驱动源码存放目录。 检查 qmake 版本： qmake -v 若版本过低，会提示错误，解决方法是使用 Qt5.6 本版本的 qmake。 查看 MySQL 相关的头文件目录和库文件目录。 在执行 qmake 命令前，需要安装三个依赖包： libmysqlclient-dev libqt5sql5-dev build-essential 运行 qmake 命令生成新的 Makefile： qmake 如果没有反应，说明成功生成 Makefile。 执行 sudo make 命令： sudo make 若出现如下错误： /usr/bin/ld: cannot find -lmysqlclient_r 解决方案： 在 /usr/lib/x86_64-linux-gnu 目录下查找库函数： ls -l libmysql* 找到相关的软链接文件，例如： libmysqlclient.so - libmysqlclient.so.20.3.1 若需要的 libmysqlclient_r.so 的软链接不存在，执行以下命令创建： sudo ln -s libmysqlclient.so.20.3.1 libmysqlclient_r.so 之后再次执行 sudo make，如无错误，编译成功。 如果出现错误消息： recipe for target .obj/qsql_mysql.o failed 检查和修复相关文件以确保编译正确。 将生成的 libqsqlmysql.so 拷贝到 Qt5.6 的安装目录下，并检查该驱动： sudo apt-get install qtbase5-private-dev 拷贝路径示例： cp libqsqlmysql.so /path/to/Qt5.6/lib/ 测试 MySQL 连接 在 Qt5.6 中进行 MySQL 的连接测试，确保安装和设置成功。","categories":["2.语言","Qt","数据库"]},{"title":"Qt多项目管理","path":"/2024/03/01/2-语言-Qt-编译-Qt多项目管理/","content":"Qt 项目模块化编译指南在 Qt 项目开发过程中，当项目规模变大时，为了提高编译效率和代码复用性，通常会将项目拆分为多个子模块，分别编译成静态库或动态库再进行加载。以下是详细的模块化配置指南： 1. 条件编译配置在 Qt 项目文件中，可以通过条件编译指令根据不同的平台、架构或其他条件来调整编译选项。 # 根据平台选择配置unix # Unix/Linux 平台特定配置 message(Building on Unix/Linux platform.) DEFINES += UNIX else:win32 # Windows 平台特定配置 message(Building on Windows platform.) DEFINES += WINDOWS# 根据架构选择配置contains(QT_ARCH, arm64) # ARM64 架构特定配置 message(Building for ARM64 architecture.) DEFINES += ARM64# 根据 Qt 版本选择配置contains(QT_VERSION, 5.) # Qt 5 特定配置 message(Building with Qt 5.) QT += widgets else:contains(QT_VERSION, 6.) # Qt 6 特定配置 message(Building with Qt 6.) QT += widgets 示例： 在不同平台下包含不同的头文件： #ifdef UNIX#include unistd.h#elif defined(WINDOWS)#include windows.h#endif 2. 子项目：静态库 (Static Library)静态库编译后会将代码直接链接到调用库的目标文件中，通常用于不需要动态加载的功能模块。 # 静态库配置示例：printHello.proQT -= guiTARGET = printHelloCONFIG += staticlibTEMPLATE = libDEFINES += printHello_LIBRARYCONFIG -= debug_and_release# 源文件和头文件SOURCES += printHello.cppHEADERS += printHello.h# 添加自定义编译选项QMAKE_CXXFLAGS += -std=c++11 功能说明： QT -= gui：移除 GUI 组件，因为静态库可能不需要 GUI 支持。 TEMPLATE = lib：指定项目为库类型。 CONFIG += staticlib：生成静态库。 DEFINES += printHello_LIBRARY：定义预处理宏，防止多次包含。 3. 子项目：动态库 (Dynamic Link Library)动态库允许在运行时加载，适用于需要动态扩展的功能模块。 # 动态库配置示例：printNice.proQT -= guiTARGET = printNiceTEMPLATE = libDEFINES += printNice_LIBRARYCONFIG -= debug_and_release# 源文件和头文件SOURCES += printNice.cppHEADERS += printNice.h# 添加导出符DEFINES += PRINTNICE_EXPORT=declspec(dllexport) 功能说明： TEMPLATE = lib：指定项目为库类型。 DEFINES += PRINTNICE_EXPORT：在 Windows 平台上导出符号。 4. 可执行程序项目 (Executable Program)主程序项目负责调用和加载各个库文件。 # 主程序配置示例：print.proQT += core gui widgetsTARGET = printTEMPLATE = app# 源文件和头文件SOURCES += main.cpp printwindow.cppHEADERS += printwindow.h# 界面文件FORMS += printwindow.ui# 链接静态库LIBS += -L../printHello -lprintHello# 链接动态库LIBS += -L../printNice -lprintNice# 添加自定义编译选项QMAKE_CXXFLAGS += -std=c++11 功能说明： QT += widgets：添加 GUI 支持。 TEMPLATE = app：指定为可执行程序。 LIBS：指定库文件路径和名称，注意路径要与实际编译输出一致。 5. 管理项目结构使用子目录模式管理多个子项目，确保编译顺序正确。 # 总体项目配置：main.proTEMPLATE = subdirsSUBDIRS += \\ printHello/printHello.pro \\ printNice/printNice.pro \\ print.pro# 确保子项目按顺序编译CONFIG += ordered# 定义编译输出路径DESTDIR = ../bin 功能说明： TEMPLATE = subdirs：指定为子目录项目。 SUBDIRS：列出所有子项目，按依赖关系排序。 CONFIG += ordered：确保按顺序编译子项目。 DESTDIR：指定编译输出目录，方便管理。 6. 编译和使用编译步骤： 打开终端或命令提示符，进入项目根目录。 执行 qmake 生成 Makefile。 执行 make 或 nmake 开始编译。 编译完成后，主程序和库文件会输出到指定目录。 使用示例：在主程序中调用动态库函数： #include printHello.hint main(int argc, char *argv[]) QApplication a(argc, argv); PrintHello hello; hello.print(); return a.exec(); 7. 常见问题解答 库文件路径问题：确保 LIBS 中的路径正确，或者使用绝对路径。 导出符号问题：在 Windows 平台，确保动态库函数使用 declspec(dllexport) 导出。 编译顺序问题：在 SUBDIRS 中按依赖顺序排列，先编译库，再编译主程序。 通过以上配置和步骤，可以将大型 Qt 项目高效地拆分为多个模块，实现模块化管理和编译。","categories":["2.语言","Qt","编译"]},{"title":"QComboBox样式表","path":"/2024/02/29/2-语言-Qt-样式表-QComboBox样式表/","content":"字体样式QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗，bold 为加粗， normal 为不加粗 color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 对于字体样式，可以把 family size style weight 统一设置在 font 属性中： font: bold italic 18px Microsoft YaHei; 这里出现的顺序要求是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family 文字位置padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; padding-left 为设置按钮(包括选择框和文字)距离左边边界的距离 padding-top 为设置按钮(包括选择框和文字)距离顶边边界的距离 padding-right 为设置按钮(包括选择框和文字)距离右边边界的距离 padding-bottom 为设置按钮(包括选择框和文字)距离底边边界的距离 在 qss 中，属性 text-align 对 QComboBox 是不起作用的，一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以精确地调节文字的显示位置 下面调节字体左间距为 30px QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; 可以看到设置的 padding-left 只对按钮框文字起作用，对下拉列表不起作用，后面会单独讨论下拉框样式 边框样式border-style: solid;border-width: 2px;border-color: aqua; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 2px; border-style: solid; border-color: aqua; 也可以把 border 的 width style color 一起设置在 border 属性中： border: 2px solid aqua; 但必须注意的是，值的顺序必须是按照 width style color 来写，不然不会生效！如果不想显示边框可以直接设置 border 属性值为 none 也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 QComboBox 下面来设置左上角和左下角半径 QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 2px; border-style: solid; border-color: aqua; border-top-left-radius: 13px; border-bottom-left-radius: 13px; 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 比如给 QComboBox 左边添加一个背景图片 QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #BDC8E2; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 1px; border-style: solid; border-color: aqua; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 对于 background，可以把 color image repeat position 一起设置在 background 属性中： background: url(./image.png) no-repeat left center #2E3648; color image repeat position 这些属性值出现的顺序可以任意 动态样式可以设置鼠标悬浮时的样式 QComboBox:hover color: green; background-color: black; 当下拉列表显示出来时的样式 QComboBox:on color: red; background-color: black; 当下拉框按钮可编辑输入文字时的样式 QComboBox:editable color: white; background-color: #2E3648; 想要可编辑样式生效需要设置下拉框按钮为可编辑，比如调用 setEditable() 方法，值得注意的是，一旦可编辑样式生效，其它类似于 hover、on 所设置的样式都会被覆盖掉，除非再次设置为不可编辑 下拉图标下拉图标属于下拉框按钮的一个子控件 drop-down，而 drop-down 中又包含 down-arrow 子控件，用样式表把这两个控件显示出来： QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: normal; font-weight: bold;QComboBox::drop-down border: 1px solid red;QComboBox::down-arrow border: 1px solid green; 在样式表中，设置 drop-down 边框颜色为红色，down-arrow 边框为绿色。也可以自定义 drop-down 控件的大小和位置： QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: normal; font-weight: bold; padding-left: 6px;QComboBox::drop-down width:28px; height:22px; border: 1px solid red; subcontrol-position: center top; subcontrol-origin: padding;QComboBox::down-arrow border: 1px solid green; width 和 height 设置 drop-down 的宽高 subcontrol-position 设置 drop-down 的位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 subcontrol-origin 设置 drop-down 的对齐方式，一般设置为 padding 如果想要自定义的 width、height、subcontrol-position 生效，必须在 QComboBox 按钮中设置 padding 的值，哪怕设置值为 0，否则无法生效！ 当然，也可以设置 drop-down 的圆角半径 border-radius，属性值和其它控件样式的设置方式一样： border-top-left-radius: 6px;border-top-right-radius: 6px;border-bottom-left-radius: 6px;border-bottom-right-radius: 6px;border-radius: 6px; 同时，还可以往 drop-down 添加图片，方式有两种： image: url(./arrow_down.png);background-image: url(./arrow_down.png); image 设置唯一的自动适应不重复的图片，而 background-image 则需要手动调节它的 repeat, position 属性值。这里，不推荐在 drop-down 中设置图片，因为它有一个更好放图片的控件 down-arrow","categories":["2.语言","Qt","样式表"]},{"title":"QLabel样式表","path":"/2024/02/28/2-语言-Qt-样式表-QLabel样式表/","content":"QLabel font-family: Microsoft YaHei; font-size: 14px; color: #BDC8E2; background-color: #2E3648; 字体样式font-family: Microsoft YaHei;font-size: 14px;font-style: italic;font-weight: bold;color: #BDC8E2;font: bold italic 18px Microsoft YaHei; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体样式，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗样式，bold 为加粗， normal 为不加粗 font 为同时设置字体 style weight size family 的样式，但是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 文字位置padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; padding-left 为设置文字距离左边边界的距离 padding-top 为设置文字距离顶边边界的距离 padding-right 为设置文字距离右边边界的距离 padding-bottom 为设置文字距离底边边界的距离 在 qss 中，属性 text-align 对 Label 是不起作用的，只能通过设置 padding 来实现文字的显示位置；一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以在任意位置显示了（默认情况下文字是上下左右都居中显示的） 边框样式border-style: solid;border-width: 2px;border-color: red;border: 2px solid red; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent border 为同时设置 border 的 width style color 属性，但值的顺序必须是按照 width style color 来写，不然不会生效！也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 Label 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 background 为设置背景的所有属性，color image repeat position 这些属性值出现的顺序可以任意 示例QLabel font-family: Microsoft YaHei; font-size: 18px; color: #BDC8E2; font-style: normal; font-weight: normal; border-style: solid; border-width: 2px; border-color: aqua; border-radius: 20px; padding-left: 20px; padding-top: 0px; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 动态样式鼠标悬浮时的样式 QLabel:hovercolor: red;border-color: green; background-color: aqua; 标签禁止时的样式 QLabel:disabledcolor: blue;border-color: brown; background-color: aqua; 不过，遗憾的是，标签并没有点击 pressed 这种样式的","categories":["2.语言","Qt","样式表"]},{"title":"QPushButton样式表","path":"/2024/02/27/2-语言-Qt-样式表-QPushButton样式表/","content":"QPushButton font-family: Microsoft YaHei; font-size: 16px; color: #BDC8E2; background-color: #2E3648; 字体样式font-family: Microsoft YaHei;font-size: 14px;font-style: italic;font-weight: bold;color: #BDC8E2;font: bold italic 18px Microsoft YaHei; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗，bold 为加粗， normal 为不加粗 font 为同时设置字体 style weight size family 的样式，但是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 文字位置text-align: left center;padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; text-align 为设置文字位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 padding-left 为设置文字距离左边边界的距离 padding-top 为设置文字距离顶边边界的距离 padding-right 为设置文字距离右边边界的距离 padding-bottom 为设置文字距离底边边界的距离 特殊的位置可以使用 text-align 来设置，如果要精确设置位置只能通过 padding 来设置，一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以显示任意位置显示了（默认情况下文字是上下左右都居中显示的） 边框样式border-style: solid;border-width: 2px;border-color: red;border: 2px solid red; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent border 为同时设置 border 的 width style color 属性，但值的顺序必须是按照 width style color 来写，不然不会生效！ 也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red;border-right-style: solid;border-right-width: 3px;border-right-color: green;border-right: 3px solid green;border-bottom-style: solid;border-bottom-width: 2px;border-bottom-color: blue;border-bottom: 2px solid blue;border-left-style: solid;border-left-width: 3px;border-left-color: aqua;border-left: 3px solid aqua; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 PushButton 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 background 为设置背景的所有属性，color image repeat position 这些属性值出现的顺序可以任意 示例QPushButton font-family: Microsoft YaHei; font-size: 16px; color: #BDC8E2; font-style: italic; font-weight: bold; text-align: left center; padding-left: 25px; padding-top: 0px; border-style: solid; border-width: 2px; border-color: aqua; border-radius: 20px; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 动态样式设置鼠标悬浮时的样式 QPushButton:hover\tcolor: red;\tborder-color: green; background-color: aqua; 鼠标点击时的样式 QPushButton:pressed\tcolor: green;\tborder-color: blueviolet; background-color: black; 按钮禁止时的样式 QPushButton:disabled\tcolor: blue;\tborder-color: brown; background-color: aqua; 下拉菜单对于 QPushButton，可以给它设置添加一个下拉菜单，这需要调用 QPushButton 的 setMenu() 方法，当菜单设置成功后，QPushButton 就会默认添加一个 menu-indicator 下拉菜单指示器图标，可以对这个菜单图标进行样式修改 QPushButton::menu-indicator image: url(./image.png); subcontrol-position: right center; subcontrol-origin: padding; right: 10px; top: 15px; image 为设置菜单指示器图标 subcontrol-position 设置菜单指示器图标的位置，如果不设置的话会默认放在右下角 subcontrol-origin 为设置菜单指示器图标与按钮之间的停靠位置，默认为 padding right top left bottom 为设置菜单指示器图标距离按钮四个位置的距离 当然下拉菜单指示器图标也有动态样式 QPushButton::menu-indicator:hover image: url(./image1.png)QPushButton::menu-indicator:pressed image: url(./image2.png)QPushButton::menu-indicator:open image: url(./image2.png) 对于 menu-indicator 来说 pressed 和 open 原理相同","categories":["2.语言","Qt","样式表"]},{"title":"Linux下C程序插入shell脚本","path":"/2024/02/26/2-语言-Shell-Linux下C程序插入shell脚本/","content":"linux 下 C 程序插入执行 shell 脚本最近在看深入理解计算机系统，看到一个函数叫做 execve()，这个函数很有意思，可以在一个进程插入另外一个进程执行，但是又不像 fork()一样产生一个子进程，execve()插入的进程和原进程共享进程号，就好像执行这进程就像执行过程调用一般随意。 函数原型如下： int execve(const char *filename, char *const argv[], char *const envp[]); EXAMPLE The following program is designed to be execed by the second program below. It just echoes its command-line one per line. * myecho.c * #include stdio.h#include stdlib.hintmain(int argc, char *argv[])\tint j;\tfor (j = 0; j argc; j++)\tprintf(argv[%d]: %s , j, argv[j]);\texit(EXIT_SUCCESS); This program can be used to exec the program named in its command-line argument: * execve.c * #include stdio.h#include stdlib.h#include unistd.hintmain(int argc, char *argv[])\tchar *newargv[] = NULL, hello, world, NULL ;\tchar *newenviron[] = NULL ;\tif (argc != 2) fprintf(stderr, Usage: %s file-to-exec , argv[0]); exit(EXIT_FAILURE); newargv[0] = argv[1];\texecve(argv[1], newargv, newenviron);\tperror(execve); /* execve() only returns on error */\texit(EXIT_FAILURE); We can use the second program to exec the first as follows: $ cc myecho.c -o myecho$ cc execve.c -o execve$ ./execve ./myechoargv[0]: ./myechoargv[1]: helloargv[2]: world 插入一个 shell 脚本执行：#include stdio.h#include stdlib.h#include unistd.hintmain(int argc, char *argv[])\tchar *newargv[] = /etc ;\tchar *newenviron[] = NULL ;\tif (argc != 2) fprintf(stderr, Usage: %s file-to-exec , argv[0]); exit(EXIT_FAILURE); newargv[0] = argv[1];\texecve(argv[1], newargv, newenviron);\tperror(execve); /* execve() only returns on error */\texit(EXIT_FAILURE); script.sh 如下： #!/bin/bashls 执行： ./execve ./script.sh 会在当前终端下输出所有的文件 yca@ubuntu:~/桌面/hello$ ./execve ./script.sh1 execve hello1 hello3 hello5 hello_lex1.txt execve.c hello1.c hello3.cpp hello5.c k_maxBubble hello hello1.o hello3.o hello5.o k_max.cBubble.c hello.c hello2.c hello3.s hello5.s lex.yy.cQuickSort.c hello.lex hello2.o hello4 hello5.s1 script.shQuicksort1.c hello.sh hello2.s hello4.c hello51.s","categories":["2.语言","Shell"]},{"title":"shell介绍","path":"/2024/02/23/2-语言-Shell-shell介绍/","content":"shellshell 是一个编程语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支；也是一个命令行解释器，交互式地解释和执行用户输入的命令；还是内核的保护工具，它调用了系统核心的大部分功能来执行程序、建立文件并以并行的方式协调各个程序的运行。 Shell 有两种执行命令的方式： 交互式（Interactive）：解释执行用户的命令，用户输入一条命令，Shell 就解释执行一条。 批处理（Batch）：用户事先写一个 Shell 脚本 (Script)，shell 脚本是 shell 命令的有限序列，将各类命令预先放入其中，方便一次性执行的一个程序文件，主要用于方便管理员进行设置或者管理，而不必一条一条地敲命令。 Shell 脚本是解释执行的，不需要编译，Shell 程序从脚本中一行一行读取并执行这些命令，相当于一个用户把脚本中的命令一行一行敲到 Shell 提示符下执行 Linux 的 Shell 种类众多，常见的有：Bourne Shell（usrbinsh 或binsh）、Bourne Again Shell（binbash）、C Shell（usrbincsh）、K Shell（usrbinksh）、Shell for Root（sbinsh）等等。 不同的 Shell 语言的语法有所不同，所以不能交换使用。关注的重点是 Bash，Bash 也是大多数 Linux 系统默认的 Shell。在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，在下面的文字中，可以看到#!binsh，它同样也可以改为#!binbash。 编写 Shell 脚本的格式是固定的，一个简单的 shell 脚本如下： #!/bin/sh#print hello world in the console windowa = hello worldecho $a 首行中的符号 #! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。 如果首行没有这句话，在执行脚本文件的时候，将会出现错误。 后续的部分就是主程序，Shell 脚本像高级语言一样，也有变量赋值，也有控制语句。 除第一行外，以#开头的行就是注释行，直到此行的结束。 如果一行未完成，可以在行尾加上 “，这个符号表明下一行与此行会合并为同一行。 编辑完毕，将脚本存盘为 filename.sh，文件名后缀 sh 表明这是一个 Bash 脚本文件。执行方式： 1.加可执行权限 chmod u+x filename.sh ./filename.sh2.执行通过bash运行 /bin/bash filename.sh3.将路径添加到环境变量 chmod u+x filename.sh PATH+=:/home/fs/Temp filename.sh //任意目录运行4.添加到bin文件夹 chmod u+x filename.sh sudo mv filename.sh /bin/ 注意，一定要写成.filename.sh，而不是 filename.sh。运行其它二进制的程序也一样，直接写 filename.sh，linux 系统会去 PATH 里寻找有没有叫 filename.sh 的，而只有bin, sbin, usrbin，usrsbin 等在 PATH 里，的当前目录通常不在 PATH 里，所以写成 filename.sh 是会找不到命令的，要用.filename.sh 告诉系统说，就在当前目录找。 速查表 命令 含义 %!xxd 将二进制文件转换为 16 进制和 ASCII 表形式查看 * 代表通配符，可代表任意长度的任意字符； ？ 可代表单个长度的任意字符 [] 通配括号中的元素 [^……] 除去括号中的元素，其他通配 file 将输出重定向到 file 中去（新建） file 将输出重定向到 file 中去（追加模式） file 将 file 作为标准输入 2 或 –标准错误 pipe 管道,将第一个命令的输出作为第二个命令的输入 shell 命令使用 tab 补齐：命令 文件名 路径 history ：查看命令历史 通配符 *：匹配任意长度任意字符串 管道 |：第一个指令的输出作为第二个指令的输入：ls /usr/bin | wc -l 重定向 : 命令置换：反撇号 ls `pwd` 常用命令 用户管理命令 进程管理命令 通配符*?[...][-][^...][a-z, ABC] // 表示匹配a到z和A,B,C中任意一个字符ls file[3-4][5-9].c /*表示名匹配文件名含[3-4]中的一个字符和[5-9]中的一个字符，两个字符的共两个字符的文件名都符合规则。*/ 管道| 将第一个命令的正确输出内容 通过管道输出给 第二个命令作为输入.要求第一个命令有输出，第二个命令有输入功能。 重定向echo hello world test 将内容输出到文件 test 中。 echo hello Eric test 将字符串内容追加到 test 中,在 test 原有的内容上添加 2 2 将报错信息重定向或追加到指定文件. 将正确信息和错误信息一起重定向或追加到指定文件。 0 标准输入 stdin 1 标准输出 stdout ‘ ’ main() return ; fflush(stdout); 2 标准出错 stderr /dev/null 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 cat /dev/null ~/.bash_history // 利用/dev/null清空指定文件。/dev/zero command file 将输出重定向到 file。 command file 将输入重定向到 file。 command file 将输出以追加的方式重定向到 file。 n file 将文件描述符为 n 的文件重定向到 file。 n file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n m 将输出文件 m 和 n 合并。 n m 将输入文件 m 和 n 合并。 tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 管道和重定向的比较command1 | command2 左输出 | 右输入 command file 左输出 右文件 command file 左输入 右文件 管道的命令同时执行,command2 等待 command1 的输出 (阻塞) 重定向是有优先级的,由进程优先级决定. 常用命令less/more alias 定义别名 alias md=mkdirmd dir1 dir2 //md就是mkdir了,这里创建了两个目录(文件夹)dir1和dir2. head/tail sort 排序命令 cat /etc/passwd | sort -t: -k 4 -n //-t指定分隔符 -k 4 指定分隔后的段, -n 完整比较。manman 1 可执行程序或Shell命令man 2 ?man 3 ? 用户管理命令adduserdeluser --remove-home //删除用户的同时，删除其工作目录chownchown xiaomeng jielun //将文件jielun的所有者改为xiaomeng.su 切换用户passwd 修改密码sudo //用超级用户权限执行一次命令；sudo passwd //普通用户修改root用户密码;usermodusermod -l Ez xiaoming //更改用户名xiaoming为Ez,要保证用户不在登陆状态; 相关文件: /etc/passwd/etc/shadow/etc/skel//etc/group/etc/gshadowchmod 改变文件读写执行权限rw- r-- r--110 100 1006 4 4| | |其他用户| |组用户权限|所属者的权限Xm 进程管理信息进程的概念:程是指正在执行的程序的实例。每个运行的程序都在系统中作为一个进程存在。进程是操作系统进行任务调度和资源管理的基本单位，它拥有自己的内存空间、执行代码、数据和资源。进程之间相互独立，彼此隔离，这样可以确保一个进程的异常不会影响其他进程的正常运行。进程与程序的区别:程序是一组静态的指令和数据的集合，它们存储在磁盘上；而进程是程序的实例，是程序在内存中的执行过程。程序只是静态的代码和数据的集合，而进程是具有动态特性、在系统中运行的实体。 进程 程序 定义 进程是正在运行的程序的实例。在操作系统中，进程代表了一个独立的执行单元，拥有自己的内存空间、程序代码、数据和资源。每个运行的程序都以进程的形式存在。 程序是一组指令和数据的集合，它是静态的、存储在磁盘上的文件，描述了如何执行特定任务。程序本身并不占用系统资源，只有在被加载到内存并运行时，才成为一个进程。 特性 进程是一个动态的实体，具有生命周期，可以处于运行、就绪、阻塞、挂起等不同状态，而且进程之间相互独立，彼此隔离。 程序是一个静态的实体，只是存储在磁盘上的文件，并不具有自己的执行状态和资源。 生命周期 进程从创建、运行到终止，进程有一个明确的生命周期。当进程终止时，它占用的资源会被操作系统回收。 程序本身没有生命周期，只有在被加载到内存并执行为进程后，才会有生命周期。 进程和程序之间是一种从程序到进程的实例化关系。当运行一个程序时，操作系统会为该程序创建一个对应的进程，使得程序在内存中得以执行。 进程的查看: ps -auxps -elf 进程的几种状态: 运行（Running）：表示进程正在运行或正在执行。 就绪（Ready）：表示进程已经准备好运行，但由于系统资源限制或其他进程的运行，它暂时还没有得到处理器的分配。 阻塞（Blocked）：也称为等待（Waiting），表示进程由于等待某个事件的发生（如 IO 操作完成、信号等）而暂停执行，直到事件发生才能继续运行。 挂起（Suspended）：表示进程被暂时挂起，不占用 CPU 资源，并且可能被放置在磁盘上。这种状态通常用于系统中的一些特殊情况，如进程被调试或由于内存不足而被置换出来。 shell 命令行下查找在当前目录下所有文件中查找内容包含 string 的文件并列出字符所在的文件,所在行及所在行的内容: find ./ -name * -exec grep -n string ./ \\; 使用 find 查找时希望忽略某个目录 (-prune): 如果希望在app 目录下查找文件，但不希望在appbin 目录下查找: find /app -name /app/bin -prune -o -print 使用 type 选项: 如果要在etc 目录下查找所有的目录: find /etc -type d -print 如果要在etc 目录下查找.svn 的目录: find /etc -name .svn -type d -print 为了在当前目录下查找除目录以外的所有类型的文件: find . ! -type d -print 为了在当前目录下查找所有的符号链接文件，可以用: find . -type | -print 为了用 ls -l 命令列出所匹配到的文件，可以把 ls -l 命令放在 find 命令的 -exec 选项中: find . -type f -exec ls -l \\; 注：f 表示普通文件 shell 脚本各种执行方式source ./*.sh . ./*.sh ./*.sh 的区别 ./*.sh 的执行方式等价于 sh ./*.sh 或者 bash ./*.sh， 此三种执行脚本的方式都是重新启动一个子 shell,在子 shell 中执行此脚本。 .source ./*.sh 和 . ./*.sh 的执行方式是等价的，即两种执行方式都是在当前 shell 进程中执行此脚本，而不是重新启动一个 shell 而在子 shell 进程中执行此脚本。验证依据：没有被 export 导出的变量（即非环境变量）是不能被子 shell 继承的验证结果： [root@localhost ~]#name=dangxu //定义一般变量[root@localhost ~]# echo $namedangxu[root@localhost ~]# cat test.sh //验证脚本，实例化标题中的./*.sh#!/bin/shecho $name[root@localhost ~]# ls -l test.sh //验证脚本可执行-rwxr-xr-x 1 root root 23 Feb 611:09 test.sh[root@localhost ~]# ./test.sh //以下三个命令证明了结论一[root@localhost ~]# sh ./test.sh[root@localhost ~]# bash ./test.sh[root@localhost ~]# . ./test.sh //以下两个命令证明了结论二dangxu[root@localhost ~]# source ./test.shdangxu[root@localhost ~]#","categories":["2.语言","Shell"]},{"title":"Shell任务","path":"/2024/02/22/2-语言-Shell-Shell任务/","content":"计划任务服务程序一次性计划任务“at 时间”是一个命令行工具，用于在指定的时间执行一次性任务。 通过使用该命令，可以安排计划在将来的某个时间运行的命令或脚本。 时间参数可以采用多种格式，如 HH:MM，HH:MM AMPM 或者明天的日期。 例如，以下命令将在下午 2 点运行一个脚本： at 2pm 脚本路径 查看计划任务“at -l”命令用于列出当前计划的 at 任务列表，显示已经被安排的任务及其相关信息，如任务序号、执行时间等。 例如，以下命令将列出当前计划的 at 任务列表： at -l 取消计划任务“atrm 任务序号”命令用于取消一个已经计划的 at 任务，其中任务序号是通过”at -l”命令列出的任务的序号。 例如，以下命令将取消任务序号为 1 的 at 任务： atrm 1 长期性计划任务crontab -e 创建、编辑计划任务 crontab -l 查看当前计划任务 crontab -r 删除某条计划任务 crontab -u 编辑他人的计划任务 demo: crontab -e crontab -l25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar /home/wwwroot whereis rm 时间周期设置：25 3 * * 1,3,5 依次对应 分钟，小时，日期，月份，星期 任务内容:要运行的命令 /usr/bin/tar -czvf backup.tar /home/wwwroot","categories":["2.语言","Shell"]},{"title":"Shell和终端和控制台的区别","path":"/2024/02/21/2-语言-Shell-Shell和终端和控制台的区别/","content":"shell、控制台、终端的区别终端(terminal，或者叫物理终端）：是一种设备，不是一个程序，一般说的就是能提供命令行用户界面的设备，典型的是屏幕和键盘，或其他的一些物理终端。 虚拟终端：屏幕和键盘只是一个终端，可能不够用，又不想增加设备投入，就产生了虚拟终端。 gnome-terminal,urxvt，mlterm，xterm 等等是一个程序，职责是模拟终端设备，和虚拟终端的区别表面上在于它以 GUI 形式的窗口出现，内部则是程序结构和系统控制结构有所不同，但本质上差不多。 控制台（console):显示系统消息的终端就叫控制台，Linux 默认所有虚拟终端都是控制台，都能显示系统消息。 但有时专指 CLI 下的模拟终端设备的一个程序，和 gnome-terminal,urxvt，mlterm，xterm 等相同，只是 CLI 和 GUI 界面的区别。 一般 console 有 6 个，tty1-6，CTRL+ALT+f1~6 切换。 shell：shell 是一个抽象概念，shell 的一切操作都在计算机内部，负责处理人机交互，执行脚本等，是操作系统能正常运行的重要组成部分,bash，ash，zsh，tcsh 等是 shell 这个抽象概念的一种具体的实现，都是一个程序，都能生成一个进程对象 如果想换 shell 的程序，可以修改etcpasswd，把里面的binbash 换成想要的 shell，或者用 chsh 命令来切换 终端和 Shellshell 与终端的关系：shell 把一些信息适当的输送到终端设备，同时还接收来自终端设备的输入。一般每个 shell 进程都会有一个终端关联，也可以没有。 字符程序 — 虚拟终端 — 图像显示 shell — xterm — X11 终端和控制台终端，英文叫做 terminal ,通常简称为 term ，比如在 X 下的 xterm. 控制台，英文叫做 console。 要明白这两者的关系，还得从以前的多人使用的计算机开始。 大家都知道，最初的计算机由于价格昂贵，因此，一台计算机一般是由多个人同时使用的。 在这种情况下一台计算机需要连接上许多套键盘和显示器来供多个人 使用。 在以前专门有这种可以连上一台电脑的设备，只有显示器和键盘，还有简单的处理电路，本身不具有处理计算机信息的能力，他是负责连接到一台正常的计算 机上（通常是通过串口） ，然后登陆计算机，并对该计算机进行操作。 当然，那时候的计算机操作系统都是多任务多用户的操作系统。 这样一台只有显示器和键盘能够通过串口连接到计算机 的设备就叫做终端。 而控制台又是什么回事呢？ 学机电的人应该知道，一台机床，或者数控设备的控制箱，通常会被称为控制台，顾名思义，控制台就是一个直接控制设备的台面（一个面板，上面有很多控制按 钮）。 在计算机里，把那套直接连接在电脑上的键盘和显示器就叫做控制台。 请注意它和终端的区别，终端是通过串口连接上的，不是计算机本身就有的设备，而控制台是 计算机本身就有的设备，一个计算机只有一个控制台。 计算机启动的时候，所有的信息都会显示到控制台上，而不会显示到终端上。 也就是说，控制台是计算机的基 本设备，而终端是附加设备。 当然，由于控制台也有终端一样的功能，控制台有时候也被模糊的统称为终端。 计算机操作系统中，与终端不相关的信息，比如内核消息，后台服务消息，都可以显示到控制台上，但不会显示到终端上。 以上是控制台和终端的历史遗留区别。 现在由于计算机硬件越来越便宜，通常都是一个人独占一台计算机超做，不再连接以前那种真正意义上的”终端设备了”，因此，终端和控制台的概念也慢慢演化了。 终端和控制台由硬件的概念，演化成了软件的概念。 现在说的终端，比如 linux 中的虚拟终端，都是软件的概念，他用计算机的软件来模拟以前硬件的方式。 比如在 linux 中，用 alt+f1 ~ f6 可以切换六个虚拟终端，就好比是以前多人公用的计算机中的六个终端设备，这就是为什么这个叫”虚拟终端”的原因。 当然，现在的 linux 也可以通过串口 线，连接一个真正的终端，现在这种终端设备已经非常罕见了，但是还存在，只是一般人很难见到。 也有人利用以前的老电脑（386，486）装上一个串口通信 软件，连上一台计算机，来模拟一个终端来用。这样可以达到一台电脑多人使用的目的。 简单的说，能直接显示系统消息的那个终端称为控制台，其他的则称为终端。 但是在 linux 系统中，这个概念也已经模糊化了。 比如下面这条命令： echo hello,world /dev/console 这条命令的目的是将”hello,world”显示到控制台上devconsole 是控制台设备的设备名。 在 linux 中，在字符模式下，无论在哪个虚拟终端下执行这条命令，字符 hello,world 都会显示在当前的虚拟终端下。 也就是说，linux 把当前的终端当作控制台来看待。 可见，linux 中已经完全淡化了控制台和终端的区别。 但是在其他的 UNIX 类系统中，却很明显的有虚拟终端和控制台的区别。比如 freeBSD 系统。 在 freebsd 中，只有第一个”终端”才是真正的控制台。 （就是说按 alt+f1 得到的那个虚拟终端），无论在哪个虚拟终端上执行上面的那条命令（哪怕是通过网络连接的伪终端上执行这条命令）。 hello,world 字符总会显示到第一个”终端”也就是 真正的控制台上。 另外，其他的一些系统内部信息，比如哪个用户在哪个终端登陆，系统有何严重错误警告等信息，全都显示在这个真正的控制台上。 在这里，就明 显的区分了终端和控制台的概念。其他 UNIX 中也是这样的。 比如 Tru64 unix 在 X 下有一个控制台模拟软件，无论在哪里输入 echo “hello,world” devconsole 命令，hello,world 总会显示在这个控制台模拟器中。 在 X 界面下用的那些输入命令的软件，比如 xterm ,rxvt, gnome-terminal 等等，都应该被称为终端模拟软件。 请注意它和控制台模拟软件的区别。 linux 中好象没有控制台模拟软件。 在 X 中的终端模拟 软件中输入的 echo “hello,world”devconsole 命令的输出信息，都会输出到启动该 X 服务器的虚拟终端上。 比如，用字符方式登陆系统。 进入第一个虚拟终端，然后 startx 启动 X 服务器。 再打开 xterm 来输入 echo “hello,world”devconsole 命令，那么字符串 hello,world 就显示在第一个虚拟终端上。 按 ctrl+alt+f1，回到那个启动 X 服务器的终端，就可以看到 hello, world 字符串。 现在该明白终端和控制台的区别了吧。 再简单的说，控制台是直接和计算机相连接的原生设备，终端是通过电缆、网络等等和主机连接的设备。 在以前的硬件终端设备中，由于生产厂家不同，所遵循的标准不同，因此有不同的型号标准。 比如 vt100 等。这里的 vt100 就是一个标准，那么现在 们所说的终端，往往不是真正的硬件终端了，而是终端模拟软件了，因此不同的终端模拟软件可能符合不同的标准，还有一些终端模拟软件符合很多种不同终端的标 准。 比如 gnome 的终端模拟软件 gnome-terminal，他提供好几中标准可供用户选择。 用户只要设置一下就可以了。 现在，由于原先的这些设备在的视线中渐渐淡出，控制台和终端的概念也慢慢谈化。 普通用户可以简单的把终端和控制台理解为：可以输入命令行并显示程序运行过程中的信息以及程序运行结果的窗口。 不必要严格区分这两者的差别。","categories":["2.语言","Shell"]},{"title":"Shell基础","path":"/2024/02/20/2-语言-Shell-Shell基础/","content":"变量定义Shell 支持自定义变量，不区分数据类型,全部识别为字符串 定义变量时，命名符合标识符规定，变量名不加 $ 符号 varName=value 注意变量名和等号之间不能有空格，同时变量名的命令遵循以下规则 首个字符必须为字母 中间不能有空格，支持下划线 不能使用标点符号，不能使用 bash 里的关键字 使用使用一个定义过的变量，只要在变量名前面加 $ 符号即可 echo $varNameecho $varName //帮助进行边界识别 变量名外的花括号时可选的，可以用于帮助解释器识别变量，比如下面这种情况 for skill in Adado\techo i am good at $skillScriptdone 如果不给 skill 变量加{}，解释器会把 $skillScript 当成一个变量 重新定义已定义的变量可以被重新定义 myUrl=http://see.xidian.edu.cn/cpp/linux/echo $myUrlmyUrl=http://see.xidian.edu.cn/cpp/shell/echo $myUrl 第二次赋值的时候不能写 $myUrl=http://see.xidian.edu.cn/cpp/shell/，只有使用变量时才加 $ 符号 只读变量使用 readonly 可以将变量定义为只读变变量，只读变量的值不能被改变 #!/bin/bashmyUrl=http://see.xidian.edu.cn/cpp/shell/readonly myUrlmyUrl=http://see.xidian.edu.cn/cpp/danpianji/ 运行脚本，会报如下错误： /bin/sh: NAME: This variable is read only. 删除变量使用 unset 可以删除变量，unset 不能删除只读变量 unset 变量名set 显示本地的所有变量 变量类型位置变量接收用户参数 $0 表示当前脚本名称 $1 表示接收的第一个命令行参数 $2 表示第二个命令行参数，以此类推 $# 参数的个数$? 命令执行结果,函数返回结果,$$ 进程id$1,$2..$9,$10, $11$@ $* $* 当做整体处理 环境变量 (全局可以访问的变量)脚本中定义的变量只在本脚本有效 envexport 变量名 //将局部变量变为全局变量 特殊变量 $0 当前脚本的文件名 $n 传递给脚本或函数的参数，$1,$2 $# 传递给脚本或函数的参数个数 $* 传递给脚本或函数的所有参数 $@ $? 上个命令的退出状态或函数的返回值 $$ 当前 shell 进程 ID $* 和 $@ 的区别 #!/bin/bashecho \\$*= $*echo \\\\$*\\=$*echo \\$@= $@echo \\\\$@\\=$@echo print each param from \\$*for var in $*do\techo $vardoneecho print each param from \\$@for var in $@do\techo $vardoneecho print each param from \\\\$*\\for var in $*do\techo $vardoneecho print each param from \\\\$@\\for var in $@do\techo $vardone 运行 .test.sh “a” “b” “c” “d”，看到下面的结果： $*= a b c d$*= a b c d$@= a b c d$@= a b c dprint each param from $*abcdprint each param from $@abcdprint each param from $*a b c dprint each param from $@abcd 替换，运算符，字符串，数组替换如果表达式中包含特殊字符，Shell 将会进行替换。例如，在双引号中使用变量就是一种替换，转义字符也是一种替换。 #!/bin/basha=10echo -e Value of a is $a 这里 -e 表示对转义字符进行替换。如果不使用 -e 选项，将会原样输出 Value of a is 10 命令替换命令替换是将一个命令的输出作为另一个命令的参数。命令格式如下所示。 command1 `command2` 其中，命令 command2 的输出将作为命令 command1 的参数。 ls `pwd` //这里是反引号,和~是同一个按键 pwd 命令用于显示当前目录的绝对路径。在上面的命令行中，使用命令置换符，将 pwd 的运行结果作为 ls 命令的参数。最终，命令执行结果是显示当前目录的文件内容。 需要注意命令置换和管道 pipe 的区别 变量替换变量替换可以根据变量的状态（是否为空、是否定义等）来改变它的值可以使用的变量替换形式 形式 说明 ${var} 变量本来的值 ${var:-word} 如果变量 var 为空或已被删除 (unset)，那么返回 word，但不改变 var 的值。 ${var:word} 如果变量 var 为空或已被删除(unset)，那么返回word，并将 var 的值设置为 word。 ${var:?message} 如果变量 var 为空或已被删除 (unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值。若此替换出现在 Shell 脚本中，那么脚本将停止运行。 ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值。 运算符Bash 支持很多运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符算数运算符awk 和 expr，expr #!/bin/bashval=`expr 2 + 2`echo value : $valval=`expr 2 \\* 2`echo value : $val 输出 value : 4 value : 4 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边 乘号 * 前边必须加反斜杠 \\ 才能实现乘法运算 `+``-``*``/``%`取余`=`赋值`==`相等`!=`不等 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字-eq 相等-ne 不等-gt 左侧大于右侧，返回 true-lt 小于-ge 大于等于-le 小于等于布尔运算符! 非-a 与-o 或字符串运算符 [ -z $String ] echo $? `=` 检测两个字符串是否相等，相等返回 true。`!=` 不等`-z` 检测字符串长度是否为0，为0返回 true`-n` 检测字符串长度是否为0，不为0返回 true`str` 检测字符串是否为空，不为空返回 true。 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性 [ -d /etc/fstab ] echo $? 操作符 作用 -b file 检测文件是否是块设备文件 -c file 检测文件是否是字符设备文件 -d file 检测文件是否是目录 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件） -g file 检测文件是否设置了 SGID 位 -k file 检测文件是否设置了粘着位 (Sticky Bit) -p file 检测文件是否是具名管道 -u file 检测文件是否设置了 SUID 位 -r file 检测文件是否可读 -w file 检测文件是否可写 -x file 检测文件是否可执行 -s file 检测文件是否为空（文件大小是否大于 0） -e file 检测文件（包括目录）是否存在 字符串字符串可以用单引号，也可以用双引号，也可以不用引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号里可以有变量 双引号里可以出现转义字符 数组bash 支持一维数组（不支持多维数组），并且没有限定数组的大小。类似与 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组 在 Shell 中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为： array_name=(value1 ... valuen) 还可以单独定义数组的各个分量： array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组读取数组元素值的一般格式是： $array_name[index] 使用 @ 或 * 可以获取数组中的所有元素 $array_name[*]$array_name[@] 获取数组长度或取数组长度的方法与获取字符串长度的方法相同，例如： # 取得数组元素的个数length=$#array_name[@]# 或者length=$#array_name[*]# 取得数组单个元素的长度lengthn=$#array_name[n] 逻辑语句功能语句read 是用来读取用户输入信息的命令，能够把接收到的用户输入信息赋值给后面的指定变量，-p 参数用于向用户显示一定的提示信息。 操作符 作用 -p “ 提示内容 “ -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 read -n 5 AA BB CCread AA BB CChello xiaoming, mingtian you kongread -p Enter your score（0-100）： GRADE 判断语句判断语句格式： [ 条件表达式 ] 对应两边应均有一个空格 逻辑测试语句： 与 (当前面的命令执行成功后才会执行它后面的命令) 或（当前面的命令执行失败后才会执行它后面的命令） ！ 非（把条件测试中的判断结果取相反值） 得到当前内存剩余量： FreeMem=`free -m | grep Mem: | awk print $4`[ $FreeMem -lt 1024 ] echo Insufficient Memory break 语句break 命令允许跳出所有循环（终止执行后面的所有循环）。在嵌套循环中，break 命令后面还可以跟一个整数，表示跳出第几层循环。例如： break n //表示跳出第 n 层循环。 continue 语句continue 命令与 break 命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。同样，continue 后面也可以跟一个数字，表示跳出第几层循环。 结构语句case casecase var in1)...;;2|3|4)...;;esac case 工作方式如上所示。取值后面必须为关键字 in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。;; 与其他语言中的 break 类似，意思是跳到整个 case 语句的最后。 demo: #!/bin/bashread -p 请输入一个字符，并按Enter键确认： KEYcase $KEY in[a-z]|[A-Z]) echo 输入的是 字母。 ;;[0-9]) echo 输入的是 数字。 ;;*) echo 输入的是 空格、功能键或其他控制字符。esac 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 if if [ ] thenelsefiif [ ] thenelif [ ] thenelsefi demo: #!/bin/bashread -p Enter The Users Password : PASSWDfor UNAME in `cat users.txt`doid $UNAME /dev/null （就是和2这两个的结合体）if [ $? -eq 0 ] then echo Already existselse useradd $UNAME /dev/null echo $PASSWD | passwd --stdin $UNAME /dev/null if [ $? -eq 0 ] then echo $UNAME , Create success else echo $UNAME , Create failure fifidone 循环语句for for 变量 in 列表do..donefor ((i=0; iN; i++))dodonefor var in `ls`for var in $(ls)for var #列表的内容是位置参数变量时，可以省略in ... 列表是一组值（数字、字符串等）组成的序列，每个值通过空格分隔。每循环一次，就将列表中的下一个值赋给变量。 demo: HLIST=`echo www.baidu.com`for IP in $HLISTdo ping -c 3 -i 0.2 -W 3 $IP /dev/nullif [ $? -eq 0 ] then echo baidu is onlineelse echo baidu is offlinefidone while while 表达式do..donewhile (($i $loop))do...done while 循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。 demo: PRICE=$(expr $RANDOM % 1000)TIMES=0echo 商品实际价格为0-999之间，猜猜看是多少？while truedo read -p 请输入猜测的价格数目： INT let TIMES++ if [ $INT -eq $PRICE ] ; then echo 恭喜答对了，实际价格是 $PRICE echo 总共猜测了 $TIMES 次 exit 0 elif [ $INT -gt $PRICE] ; then echo 太高了！ else echo 太低了！ fidone untilluntil 循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。一般 while 循环优于 until 循环。 a=0until [ ! $a -lt 10 ]doecho $aa=`expr $a + 1`done 函数函数定义 function_name () list of commands [ return value ]function function_name () list of commands [ return value ] 如果希望直接从终端调用函数，可以将函数定义在主目录下的 .profile 文件，这样每次登录后，在命令提示符后面输入函数名字就可以立即调用。返回值函数返回值，可以显式增加 return 语句；如果不加，会将最后一条命令运行结果作为返回值。接收函数返回值用 $?。Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0 表示成功，其他值表示失败。（返回值范围 0-255）如果 return 其他数据，比如一个字符串，往往会得到错误提示：”numeric argument required”。如果一定要让函数返回字符串，那么可以先定义一个变量，用来接收函数的计算结果，脚本在需要的时候访问这个变量来获得函数返回值。调用调用函数只需要给出函数名，不需要加括号。 Hello() echo hello, worldHelloHello2() echo hello2, worldreturn 1Hello2ret=$? 输出给了变量 var=$(Hello2) 删除像删除变量一样，删除函数也可以使用 unset 命令，不过要加上 .f 选项，如下所示： unset .f function_name 参数在 Shell 中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1 表示第一个参数，$2 表示第二个参数 获取第十个参数需要 $10。当 n10 时，需要使用 $n 来获取参数。 $# 传递给函数的参数个数。 $* 显示所有传递给函数的参数。 $@ 与 $* 相同，但是略有区别 $? 函数的返回值。 传参: function add_fun () add_fun str1 str2 str3 文件包含Shell 也可以包含外部脚本，将外部脚本的内容合并到当前脚本。 . filenamesource filename 两种方式的效果相同，简单起见，一般使用点号 (.)，但是注意点号 (.) 和文件名中间有一空格 被包含脚本不需要有执行权限","categories":["2.语言","Shell"]},{"title":"Shell环境变量","path":"/2024/02/19/2-语言-Shell-Shell环境变量/","content":"环境变量在操作系统中扮演着极为重要的角色，它们指定了系统的运行环境，包括一些基本的参数，如临时文件夹位置和系统文件夹位置等。下面将更详细地探讨 Linux 的环境变量，涵盖变量的种类、设置方法及常用环境变量的示例。 一、Linux 的变量种类根据变量的生存周期，Linux 变量可以大致分为两类： 永久变量：这些变量需要在系统的配置文件中进行修改。一旦更改，它们会对未来的所有会话有效。 临时变量：这些变量使用 export 命令声明后，仅在当前的 shell 会话中有效。一旦关闭 shell，此变量便失效。 二、设置变量的三种方法 在 /etc/profile 文件中添加变量【对所有用户生效（永久的）】使用文本编辑器（如 VI）编辑 /etc/profile 文件，可以将变量添加到所有用户的环境中。例如，想要添加一个新的路径到 PATH 变量中，可以这样做： # vi /etc/profile 在文件中添加以下行： export PATH=/home/fs:$PATH 注：修改完文件后，记得执行 source /etc/profile 命令，使更改立即生效，否则将在下次重新登录时才会生效。 在用户目录下的 .bash_profile 文件中增加变量【对单一用户生效（永久的）】每个用户都有自己的配置文件，通常名为 .bash_profile。修改这一文件也可以实现变量的持久化。例如，对用户 guok 的 .bash_profile 文件进行修改： # vi /home/guok/.bash_profile 添加如下内容以设置 CLASSPATH： export CLASSPATH=./JAVA_HOME/lib:$JAVA_HOME/jre/lib 注：同样地，修改后需要运行 source /home/guok/.bash_profile 以快速应用更改。 直接运行 export 命令定义变量【只对当前 shell（BASH）有效（临时的）】如果在命令行运行 export 命令，可以设置一个仅在当前会话内有效的变量，例如： export TEMP_VAR=Temporary Value 这个变量在当前的 shell 被关闭后将失效。如果重新打开一个 shell，需要再次设定该变量。 三、PATH 声明PATH 环境变量是系统查找可执行文件时的重要参数。它的格式为：PATH=$PATH:your_custom_path，其中可以添加自己的路径，并用冒号 : 进行隔开。为了使路径更改立即生效，可以执行： source ~/.bash_profile 需要特别注意的是，将当前路径 ./ 添加到 PATH 中可能会引起安全问题，容易受到意想不到的攻击。完成设置后，可以使用以下命令查看当前的 PATH： echo $PATH 这样可以确保能够迅速访问位于 PATH 中目录的程序，避免每次都输入完整路径。 四、常用的环境变量 变量名 内容 PATH 指定 shell 查找命令或程序的目录 HOME 当前用户的主目录 HISTSIZE 记录的历史命令数 LOGNAME 当前用户的登录名 HOSTNAME 主机的名称 SHELL 当前用户使用的 shell 类型 LANGUAGE 语言相关的环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符（root 用户为 #，普通用户为 $） 五、常用的环境变量相关命令 显示环境变量 HOME fs@ubuntu:~$ echo $HOME/home/fs 设置一个新的环境变量 HELLO fs@ubuntu:~$ export HELLO=Hellofs@ubuntu:~$ echo $HELLOHello 使用 env 命令显示所有环境变量 fs@ubuntu:~$ envSSH_AGENT_PID=2427GPG_AGENT_INFO=/tmp/keyring-Sqfg93/gpg:0:1...HELLO=Hello... 使用 set 命令显示所有本地定义的 shell 变量 fs@ubuntu:~$ setBASH=/bin/bashBASH_VERSION=2.05b.0(1)-release... 使用 unset 命令来清除环境变量 fs@ubuntu:~$ export TEST=Test # 增加一个环境变量 TESTfs@ubuntu:~$ env | grep TEST # 验证环境变量 TEST 是否存在TEST=Testfs@ubuntu:~$ unset TEST # 删除环境变量 TESTfs@ubuntu:~$ env | grep TEST # 确认变量已被删除 使用 readonly 命令设置只读变量 fs@ubuntu:~$ export TEST=Test # 增加环境变量 TESTfs@ubuntu:~$ readonly TEST # 将 TEST 设为只读fs@ubuntu:~$ unset TEST # 尝试删除只读变量# 输出将显示不可删除的错误信息 通过这些操作，用户可以清晰地管理和设置环境变量，从而定制 Linux 系统的行为和性能，以适应不同的需求和工作环境。","categories":["2.语言","Shell"]},{"title":"Shell脚本","path":"/2024/02/16/2-语言-Shell-Shell脚本/","content":"Shell 脚本的本质Shell 脚本实际上是一系列有序的 shell 命令集合，通过这些命令，可以自动化执行操作，极大地提高工作效率。以下是一个简单的示例脚本： #!/bin/bash devnull 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 执行脚本 改变脚本权限使用 chmod 命令赋予脚本执行权限，test.sh 变为可执行文件： chmod u+x test.sh./test.sh # 执行脚本# 输出的文件路径为 /home/fs/Temp/test.sh 直接调用 Bash 执行脚本通过指定 Bash 解释器来运行脚本： /bin/bash test.sh 设置 PATH 变量修改 PATH 环境变量，可以在任意目录下执行 test.sh： chmod u+x test.shPATH+=:/home/fs/Temp # 将脚本所在路径追加到 PATHtest.sh # 在任何位置可以直接执行 将脚本移动到可执行目录使用 sudo 命令将脚本移动到 /bin/ 目录，以便全局可用： chmod u+x test.shsudo mv test.sh /bin/ Shell 变量自定义变量 数据类型Shell 不区分变量的数据类型，所有变量都视为字符串。即便将数字赋值给变量，它仍会被视为字符串。例如： number=123echo $number # 输出 123 命名规则变量名需遵循标识符规定，如以字母或下划线开头，可以包含字母、数字及下划线。 引用变量使用 $ 直接引用变量，也可以用 $ 进行边界识别，防止与后续字符混淆： Var=Helloecho $Var # Helloecho $Varworld # Helloworld 只读变量定义后不可更改： readonly varname 删除变量可以使用 unset 命令删除某个变量： unset varname 显示变量使用 set 命令可查看当前脚本中的所有变量。 位置变量 位置参数变量提供了脚本运行时的传入参数： $#: 参数个数 $?: 上一条命令的返回结果 $$: 当前进程 ID $1, $2, ...: 代表第 1 个、第 2 个参数，$10, $11 支持到 11 个后面的参数 $@: 所有参数（以空格分隔） $*: 所有参数作为一个整体 环境变量 (全局变量) 使用 env 命令可以显示当前环境变量。 export 命令可以将局部变量提升为全局变量，以便在子进程中访问： export variable_name 在脚本内部定义的变量只在当前脚本中有效，不会影响全局环境。 功能语句readread 命令用于从标准输入读取数据，可以设定提示信息或输入限制。 read -p 请输入内容: user_input -t: 指定等待用户输入的时间（秒） -n: 限制读取的字符数 -s: 隐藏用户输入的信息（例如输入密码） 示例： read -n 5 user_variable # 只读取 5 个字符 exprexpr 命令用于进行算术运算，示例如下： sum=$(expr $AA + $BB) # 用 expr 计算 AA 和 BB 的和# 等价于sum=$(($AA + $BB)) # 使用内置的算术扩展 testtest 命令用于条件判断，支持多种类型的比较： 字符串比较： =: 判断两个字符串是否相等 !=: 判断两个字符串是否不相等 整数比较： -eq: 相等 -ne: 不相等 -gt: 大于 -ge: 大于或等于 -lt: 小于 -le: 小于或等于 文件属性检查： -d: 判断是否为目录 -f: 判断是否为文件 -r: 判断文件是否可读 -w: 判断文件是否可写 判断语句判断语句的基本格式为 \\[ 条件表达式 \\]，条件表达式用于评估文件或目录的特性、逻辑条件或数值比较等。两边需留有一个空格，以确保正确识别。 文件测试语句例如，下面的语句用于判断 /etc/fstab 是否为一个目录，返回的 $? 表示该命令的执行状态，0 表示成功，其他值表示失败： [ -d /etc/fstab ] echo $? 操作符 作用 -d 测试文件是否为目录类型 -e 测试文件是否存在 -f 判断文件是否为常规文件 -r 测试当前用户是否有权限读取该文件 -w 测试当前用户是否有权限写入该文件 -x 测试当前用户是否有权限执行该文件 逻辑测试语句逻辑测试语句允许通过组合多个条件来表达逻辑关系。举个例子，如果想在某个文件存在且具有读取权限时执行某个命令，可以使用以下方式： 与（表示前面的命令执行成功后，才会执行后面的命令） ! 非（表示反转条件测试的结果，例如，如果条件为真则反转为假） 整数值比较语句整数值比较语句用于对数值进行比较。比如，可以使用以下命令来判断两个数值是否相等： [ 10 -eq 10 ] echo $? 如果比较内存情况，下面的脚本可以获取当前剩余内存并判断是否充足： FreeMem=`free -m | grep Mem: | awk print $4`[ $FreeMem -lt 1024 ] echo Insufficient Memory 操作符 作用 -eq 判断是否等于 -ne 判断是否不等于 -gt 判断是否大于 -lt 判断是否小于 -le 判断是否小于或等于 -ge 判断是否大于或等于 字符串比较语句字符串比较语句用于评估字符串间的关系。比如，用于检查某个字符串是否为空的语句如下： [ -z $String ] echo $? 操作符 作用 比较字符串内容是否相同 ! 比较字符串内容是否不同 -z 判断字符串内容是否为空 通过这些基本的测试语句和比较操作符，用户可以灵活地进行条件判断，这在脚本编写中至关重要。理解这些基础可以帮助用户更有效地进行编程与自动化处理。 结构语句条件语句条件语句用于根据特定条件的真假来执行不同的代码块。以下是基本的结构示例： if [ condition ]; then # 如果条件为真，执行的代码fi 在这个结构中，如果方括号中的条件为真，接下来的代码块就会被执行。例如，如果想检查某个文件是否存在，可以用如下代码： if [ -f example.txt ]; then echo 文件存在fi 第二种形式的条件语句提供了一个”否则”的选项： if [ condition ]; then # 如果条件为真，执行的代码else # 如果条件不为真，执行的代码fi 例如，检查一个文件的存在性，并在其不存在时提供反馈： if [ -f example.txt ]; then echo 文件存在else echo 文件不存在fi casecase 语句是一种多分支选择结构，可以让根据变量的值执行不同的代码块。其基本结构如下： case var in pattern1) # 与 pattern1 匹配时执行的代码 ;; pattern2|pattern3) # 与 pattern2或 pattern3 匹配时执行的代码 ;;esac 例如，假设要根据用户输入的颜色来输出相应的消息： case $color in red) echo 选择的是红色 ;; green) echo 选择的是绿色 ;; blue) echo 选择的是蓝色 ;; *) echo 未知颜色 ;;esac 循环语句循环语句用于重复执行代码块，直到满足某个条件为止。 for 循环用于在一个预定义的列表中遍历每个元素，其基本结构如下： for var in list; do # 循环中的代码done 例如，列出数字 1 到 5 的示例： for num in 1 2 3 4 5; do echo 当前数字是 $numdone while 循环在条件成立时继续执行代码，如下所示： while [ condition ]; do # 循环中的代码done 例如，使用 while 循环打印小于 5 的数字： count=1while [ $count -le 5 ]; do echo 当前计数是 $count count=$((count + 1))done until 循环则是当条件不成立时继续执行，基本形式如下： until [ condition ]; do # 循环中的代码done 例如，使用 until 循环打印数字，直到计数达到 5： count=1until [ $count -gt 5 ]; do echo 当前计数是 $count count=$((count + 1))done 函数定义和使用函数的过程相对直观。函数的返回值可以通过特殊变量 $? 来获取，这个变量会存储函数执行后返回的结果。值得注意的是，返回值的范围是 0 到 255，其中 0 通常表示成功，其他值则用于指示不同的错误或异常状态。这种设定为错误处理和调试提供了便利。 函数定义示例function_name() # 在这里编写代码 在上述示例中，function_name 是用户自定义的函数名，函数体内可以包含任何有效的 Bash 代码。一旦定义了函数，就可以在脚本的其他部分进行调用。 传递参数示例可以通过命令行将参数传递给函数，例如： function_name arg1 arg2 在这里，arg1 和 arg2 是传递给 function_name 函数的参数。这些参数可以在函数内部通过 $1、$2 的方式访问，其中 $1 表示第一个参数，$2 表示第二个参数。举个例子： greet() echo Hello, $1! Welcome to the world of Bash scripting.greet Alice 在这个例子中，当调用 greet Alice 时，函数将输出 Hello, Alice! Welcome to the world of Bash scripting.。这样，函数不仅封装了代码，还可以根据传入不同的参数表现出不同的行为。 获取返回值示例假设有一个计算两个数和的函数： sum() return $(($1 + $2))sum 5 10echo The return value is $? 在这个例子中，sum 函数计算 5 和 10 的和，并将结果作为返回值。然后，通过 echo The return value is $? 可以看到函数返回的结果是 0，因为 Bash 只会返回 0-255 的数值。如果希望在函数中直接输出结果而不是返回它，可以使用 echo，但要知道这和返回值是两个不同的概念。 小结函数是 Bash 脚本中非常重要的组成部分，它们允许重用代码并组织逻辑。通过函数，可以处理复杂的任务，只需一次定义，便可多次调用，并且可以灵活地传递参数，从而提高脚本的效率和可读性。掌握函数的使用，能够使的脚本更具模块化和可维护性。 Shell 脚本各种执行方式在使用 Shell 脚本时，了解不同执行方式的区别非常重要。关注的是三种执行脚本的方式：./*.sh、. ./*.sh 和 source ./*.sh。 执行方式的比较1. ./*.sh、sh ./*.sh 和 bash ./*.sh这三种方式本质上是相同的。它们都启动了一个新的子 Shell 进程，在这个子进程中执行脚本。执行后，所有在这个脚本内定义的变量和更改的状态都不会影响到父 Shell。可以理解为，子 Shell 就像一个临时的工作环境，操作结束后，它便会消失，带走的只会是自己所做的记录。 示例name=dangxu # 定义一般变量echo $name # 输出：dangxu 接下来，假设在 test.sh 文件内有如下内容： #!/bin/shecho $name # 输出变量内容 执行如下命令： ./test.sh # 输出为空，因为在子 Shell 中没有继承到变量sh ./test.sh # 输出为空bash ./test.sh # 输出为空 可以看到，在这三个命令中，name 变量没有被传递给子 Shell，所以脚本内部输出为空。 2. . ./*.sh 和 source ./*.sh这两种方式是等价的，都是在当前 Shell 进程中执行脚本。与前面的方法不同，当前 Shell 的上下文被保留，变量的定义和状态的改变会在当前环境中生效。 示例继续使用之前的 test.sh 内容，在当前 Shell 中运行： . ./test.sh # 这里将输出变量内容：dangxusource ./test.sh # 同样将输出变量内容：dangxu 在这两种执行方式中，因为是在当前 Shell 中运行脚本，所以变量 name 的值可以被正确地输出。 验证依据Shell 的机制决定了非环境变量（未使用 export 关键字导出的变量）不会被子 Shell 继承。这一特性是判断脚本执行上下文的关键依据。 验证结果通过下面的命令，可以在终端下观察到变量的行为： [root@localhost ~]# name=dangxu # 定义变量[root@localhost ~]# echo $name # 输出：dangxu[root@localhost ~]# cat test.sh # 验证脚本#!/bin/shecho $name # 将输出变量内容 接下来验证文件权限，确保脚本可执行： [root@localhost ~]# ls -l test.sh-rwxr-xr-x 1 root root 23 Feb 6 11:09 test.sh 然后分别执行不同的命令来验证的结论： 使用子 Shell 执行： ./test.sh # 输出为空sh ./test.sh # 输出为空bash ./test.sh # 输出为空 在当前 Shell 中执行： . ./test.sh # 输出：dangxusource ./test.sh # 输出：dangxu 最终，通过这些实例和验证得出结论，清晰地了解了各种 Shell 脚本执行方式的行为及其区别。这对于日常的 Shell 编程和调试都是至关重要的。","categories":["2.语言","Shell"]},{"title":"使用服务启动程序日志乱码解决","path":"/2024/02/15/2-语言-Shell-使用服务启动程序日志乱码解决/","content":"使用 service 启动 Qt 程序时，输出的日志是中文乱码 直接启动程序，输出的日志却是正常的，这种问题解决方案如下 方案一编辑 service 文件 vim /sbin/service 在 env -i 后面加上 LANG=$LANG 系统本身需支持中文语言包 方案二在启动脚本中引入环境变量","categories":["2.语言","Shell"]},{"title":"JavaScript","path":"/2024/02/14/2-语言-工具语言-JavaScript/","content":"示例分析//在当前页面重新载入页面function reloadPageContent(reloadPage) window.location.replace(reloadPage);//按钮点击展开或隐藏function updateClick() $(document).ready((function() //ready函数来确保文档加载完毕后再执行代码(jquery库代码)\t$(a).click((function() //为文档中的所有a标签绑定点击事件 $(this).next(.menu).toggle()//找到当前被点击的a标签的下一个.menu类的元素，切换它的可见性\t)) ))//获取并更新innerHTML中的内容function getInnerHTML(filePos) var xhr = new XMLHttpRequest(); xhr.open(GET, filePos, true); xhr.onreadystatechange = function() if (xhr.readyState === 4 xhr.status === 200) var htmlContent = xhr.responseText; document.getElementById(mainmenu).innerHTML = htmlContent; updateClick(); ; xhr.send();function showPicture() fetch(http://124.222.246.202/get_picture?id=1, method: GET,headers: Content-Type: application/json,) .then(response = response.text()) .then(data = document.getElementById(mainmenu).innerHTML=data)function openFile(filePos) var xhr = new XMLHttpRequest(); xhr.open(POST, http://124.222.246.202/getFileContent, true); xhr.setRequestHeader(Content-Type, application/json;charset=UTF-8); var message = filePos ; var jsonMessage = JSON.stringify(message); xhr.onreadystatechange = function () if (xhr.readyState === 4 xhr.status === 200) var responseContainer = document.getElementById(mainmenu); responseContainer.innerHTML = meta name=viewport content=width=device-width, initial-scale=1link rel=stylesheet href=2.css/github-markdown-css/github-markdown.cssstyle.markdown-body box-sizing: border-box;min-width: 200px;max-width: 980px;margin: 0 auto;padding: 45px;@media (max-width: 767px) .markdown-body padding: 15px;/stylearticle class=markdown-body+marked.parse(xhr.responseText)+/article; ; xhr.send(jsonMessage);function blogList() // 创建XMLHttpRequest对象 var xhr = new XMLHttpRequest(); // 配置请求，将消息发送到后端Python服务器 xhr.open(POST, http://124.222.246.202/getFileList, true); // 设置请求头，告诉服务器发送的是JSON数据 xhr.setRequestHeader(Content-Type, application/json;charset=UTF-8); // 创建要发送的消息对象 var message = message: Hello, backend! ; // 将消息对象转换为JSON格式 var jsonMessage = JSON.stringify(message); // 处理响应 xhr.onreadystatechange = function () if (xhr.readyState === 4 xhr.status === 200) // 在页面上显示后端返回的消息 var responseContainer = document.getElementById(mainmenu); responseContainer.innerHTML = 后端返回的消息: + xhr.responseText; ; // 发送请求 xhr.send(jsonMessage);","categories":["2.语言","工具语言"]},{"title":"JavaScript学习笔记","path":"/2024/02/13/2-语言-工具语言-JavaScript学习笔记/","content":"JavaScript 用法HTML 中的 Javascript 脚本代码必须位于 script 与 /script 标签之间。 通常，需要在某个事件发生时执行代码，比如当用户点击按钮时。 如果把 JavaScript 代码放入函数中，就可以在事件发生时调用该函数。 Javascript 脚本代码可被放置在 HTML 页面的 body 和 head 部分中。 通常的做法是把函数放入 head 部分中，或者放在页面底部。这样就可以把它们安置到同一处位置，不会干扰页面的内容。 外部的 JavaScript也可以把脚本保存到外部文件中。外部文件通常包含被多个网页使用的代码。 外部 JavaScript 文件的文件扩展名是 .js。 如需使用外部文件，请在 script 标签的 “src” 属性中设置该 .js 文件： button type=button onclick=myFunction()点击这里/buttonpb注释：/bmyFunction 保存在名为 myScript.js 的外部文件中。/pscript src=myScript.js/script\t/body js 代码如下： function myFunction() document.getElementById(demo).innerHTML=的第一个 JavaScript 函数; 外部脚本不能包含 script 标签。在标签中填写 onclick 事件调用函数时，不是 onclick函数名， 而是 onclick函数名 +() JavaScript JSONJSON 英文全称 JavaScript Object Notation JSON 是用于存储和传输数据的格式。 JSON 通常用于服务端向网页传递数据 。 数据为 键值 对。 数据由逗号分隔。 大括号保存对象 方括号保存数组 JSON 是 JS 对象的字符串表示法。它使用文本表示一个 JS 对象的信息，（JSON）本质是一个字符串。 JSON 字符串转换为 JavaScript 对象 var text = sites : [ + name:Runoob , url:www.runoob.com , + name:Google , url:www.google.com , + name:Taobao , url:www.taobao.com ]; obj = JSON.parse(text);document.getElementById(demo).innerHTML = obj.sites[1].name + + obj.sites[1].url; JSON.parse()\t用于将一个 JSON 字符串转换为 JavaScript 对象。 JSON.stringify()\t用于将 JavaScript 值转换为 JSON 字符串。 运行与调试在 Chrome 浏览器中可以通过按下 F12 按钮或者右击页面，选择 “ 检查 “ 来开启开发者工具 或者在右上角菜单栏选择 “ 更多工具 “》” 开发者工具 “ 来开启 Console 窗口调试 JavaScript 代码在 符号后输入要执行的代码 console.log(“runoob”)，按回车后执行 清空 Console 窗口到内容 Chrome snippets 小脚本也可以在 Chrome 浏览器中创建一个脚本来执行，在开发者工具中点击 Sources 面板，选择 Snippets 选项卡，在导航器中右击鼠标，然后选择 Create new snippet 来新建一个脚本文件 点击 Create new snippet 后，会自动创建一个文件，只需在右侧窗口输入以下代码，然后按 Ctrl+S 保存更改即可。 保存后，右击文件名，选择 “Run” 执行代码 设置断点debugger 关键字 JavaScript 输出 使用 window.alert() 弹出警告框。 使用 document.write() 方法将内容写到 HTML 文档中。 使用 innerHTML 写入到 HTML 元素。 使用 console.log() 写入到浏览器的控制台。 数据类型JavaScript 字面量 数字（Number）字面量 可以是整数或者是小数，或者是科学计数 (e)。 字符串（String）字面量 可以使用单引号或双引号: 表达式字面量 用于计算： 5 + 6 数组（Array）字面量 定义一个数组：[40, 100, 1, 5, 25, 10] 对象（Object）字面量 定义一个对象：{firstName:”John”, lastName:”Doe”, age:50, eyeColor:”blue”} 函数（Function）字面量 定义一个函数：function myFunction(a, b) { return a * b;} 变量 var 关键词来声明变量 当声明新变量时，可以使用关键词 “new” 来声明其类型： var carname=new String;var x= new Number;var y= new Boolean;var cars= new Array;var person= new Object; 变量的数据类型可以使用 typeof 操作符来查看： 值类型 (基本类型)： 字符串（String） var x “John”; 数字 (Number) var x 5; 布尔 (Boolean) var xtrue; 空（Null） 未定义（Undefined）\tvar x; Symbol。 引用数据类型（对象类型）： 对象 (Object) var person = firstName: John, lastName : Doe, id : 5566, fullName : function() return this.firstName + + this.lastName; ; 对象属性有两种寻址方式：nameperson.lastname;nameperson[“lastname”]; 数组 (Array) var cars=[Saab,Volvo,BMW]; var carsnew Array();cars[0]”Saab”;cars[1]”Volvo”;cars[2]”BMW”;或者 (condensed array):var carsnew Array(“Saab”,”Volvo”,”BMW”);或者 (literal array):var cars[“Saab”,”Volvo”,”BMW”]; 函数 (Function) button onclick=myFunction(Harry Potter,Wizard)点击这里/buttonbutton onclick=myFunction(Bob,Builder)点击这里/buttonscriptfunction myFunction(name,job)\talert(Welcome + name + , the + job);/script 带有返回值的函数 function myFunction() var x=5; return x;var myVar=myFunction(); 函数表达式 var x = function (a, b) return a * b; 还有两个特殊的对象： 正则（RegExp） 正则表达式主体修饰符 (可选) var patt = /runoob/i //字符串 var n = str.search(/Runoob/i); var patt = /e/; //正则patt.test(The best things in life are free!); runoobi 是一个正则表达式。runoob 是一个正则表达式主体 (用于检索)。i 是一个修饰符 (搜索不区分大小写)。 在 JavaScript 中，正则表达式通常用于两个字符串方法 : search() 和 replace()。 search() 方法用于检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串，并返回子串的起始位置。 replace() 方法用于在字符串中用一些字符串替换另一些字符串，或替换一个与正则表达式匹配的子串。 test() 方法用于检测一个字符串是否匹配某个模式，如果字符串中含有匹配的文本，则返回 true，否则返回 false。 exec() 方法用于检索字符串中的正则表达式的匹配。 日期（Date） 生存周期 局部变量 在 JavaScript 函数内部声明的变量（使用 var）是局部变量，所以只能在函数内部访问它。（该变量的作用域是局部的）。 全局变量函数外声明的变量是全局变量，网页上的所有脚本和函数都能访问它。 事件HTML 事件可以是浏览器行为，也可以是用户行为。 HTML 页面完成加载 HTML input 字段改变时 HTML 按钮被点击 |事件 |描述 | |:–: |:–: | |onchange |HTML 元素改变 | |onclick |用户点击 HTML 元素 | |onmouseover\t|鼠标指针移动到指定的元素上时发生 | |onmouseout |用户从一个 HTML 元素上移开鼠标时发生\t| |onkeydown |用户按下键盘按键 | |onload |浏览器已完成页面的加载 | 语句条件语句if-else if (condition1) 当条件 1 为 true 时执行的代码else if (condition2) 当条件 2 为 true 时执行的代码else 当条件 1 和 条件 2 都不为 true 时执行的代码 switch switch(n) case 1: 执行代码块 1 break; case 2: 执行代码块 2 break; default: 与 case 1 和 case 2 不同时执行的代码 循环语句for for (var i=0,len=cars.length; ilen; i++) document.write(cars[i] + br); var person=fname:Bill,lname:Gates,age:56; for (x in person) // x 为属性名 txt=txt + person[x]; while while (条件) 需要执行的代码 do 需要执行的代码while (条件); 其他breakcontinuetypeof检测变量的数据类型nullnull 是一个只有一个值的特殊类型。表示一个空对象引用。undefinedundefined 是一个没有设置值的变量 null 和 undefined 的值相等，但类型不等 错误处理 try 语句测试代码块的错误。 catch 语句处理错误。 throw 语句创建自定义错误。 finally 语句在 try 和 catch 语句之后，无论是否有触发异常，该语句都会执行。 异步编程回调函数这段程序中的 setTimeout 就是一个消耗时间较长（3 秒）的过程，它的第一个参数是个回调函数，第二个参数是毫秒数，这个函数执行之后会产生一个子线程，子线程会等待 3 秒，然后执行回调函数 “print”，在命令行输出 “RUNOOB!”。 function print() document.getElementById(demo).innerHTML=RUNOOB!;setTimeout(print, 3000); setTimeout(function () document.getElementById(demo).innerHTML=RUNOOB!;, 3000); JavaScript Promise类JavaScript HTML DOMHTML DOM (文档对象模型)（Document Object Model） 通过 id 找到 HTML 元素 var x=document.getElementById(intro); 通过标签名找到 HTML 元素 var x=document.getElementById(main);var y=x.getElementsByTagName(p); 通过类名找到 HTML 元素 var x=document.getElementsByClassName(intro); JavaScript HTML DOM - 改变 HTML内容 htmlbodyp id=p1Hello World!/pscriptdocument.getElementById(p1).innerHTML=新文本!;/script/body/html 属性 !DOCTYPE htmlhtmlbodyimg id=image src=smiley.gifscriptdocument.getElementById(image).src=landscape.jpg;/script/body/html JavaScript HTML DOM - 改变 CSS!DOCTYPE htmlhtmlheadmeta charset=utf-8title菜鸟教程(runoob.com)/title/headbody p id=p1Hello World!/pp id=p2Hello World!/pscriptdocument.getElementById(p2).style.color=blue;document.getElementById(p2).style.fontFamily=Arial;document.getElementById(p2).style.fontSize=larger;/scriptp以上段落通过脚本修改。/p /body/html JavaScript HTML DOM 事件scriptdocument.getElementById(myBtn).onclick=function()displayDate();/script onload 和 onunload 事件会在用户进入或离开页面时被触发。 onchange 事件常结合对输入字段的验证来使用。 onmouseover 和 onmouseout 事件可用于在用户的鼠标移至 HTML 元素上方或移出元素时触发函数。 onmousedown, onmouseup 以及 onclick 构成了鼠标点击事件的所有部分。首先当点击鼠标按钮时，会触发 onmousedown 事件，当释放鼠标按钮时，会触发 onmouseup 事件，最后，当完成鼠标点击时，会触发 onclick 事件。 总结JavaScript：直接写入 HTML 输出流document.write(h1这是一个标题/h1);document.write(p这是一个段落。/p); 只能在 HTML 输出流中使用 document.write。 如果在文档已加载后使用它（比如在函数中），会覆盖整个文档。 JavaScript：对事件的反应button type=button onclick=alert(欢迎!)点!/button JavaScript：改变 HTML 内容x=document.getElementById(demo); //查找元素x.innerHTML=Hello JavaScript; //改变内容 DOM (Document Object Model)（文档对象模型）是用于访问 HTML 元素的正式 W3C 标准。 JavaScript：改变 HTML 图像scriptfunction changeImage() element=document.getElementById(myimage) if (element.src.match(bulbon)) element.src=/images/pic_bulboff.gif; else element.src=/images/pic_bulbon.gif; /scriptimg decoding=async loading=lazy id=myimage onclick=changeImage() src=/images/pic_bulboff.gif width=100 height=180 JavaScript：改变 HTML 样式x=document.getElementById(demo) //找到元素 x.style.color=#ff0000; //改变样式 JavaScript：验证输入input id=demo type=textscriptfunction myFunction()\tvar x=document.getElementById(demo).value;\tif(isNaN(x)||x.replace(/(^\\s*)|(\\s*$)/g,)==) alert(不是数字);\t/scriptbutton type=button onclick=myFunction()点击这里/button","categories":["2.语言","工具语言"]},{"title":"Markdown笔记","path":"/2024/02/12/2-语言-工具语言-Markdown笔记/","content":"Markdown 笔记语法表格 文本样式 样式 语法 示例 加粗 前后 ** 或 __ 加粗 1 加粗 2 斜体 前后 * 或 _ 斜体 1 斜体 2 删除线 前后 ~~ 删除线 内联代码 前后 code 下划线 前u 后 /u 下划线 高亮 前后== 高亮文本 引用 此内容为引用内容 链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接 Blog网址 图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中 图片可拖动为文件到任意窗口使用 无序列表 项目 项目 1 项目 A 项目 B 项目 2 有序列表 项目 1 项目 A 项目 B 项目 2 任务列表 A 计划 A1 计划 A2 计划 B 计划 代码块代码块支持 168 种编程语言 // javascript 冒泡排序function bubbleSort(array) let swapped = true; do swapped = false; for (let j = 0; j array.length; j++) if (array[j] array[j + 1]) let temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; swapped = true; while (swapped); return array; KaTeX 数学公式内联公式质能方程 $Emc^2$ 公式块$$\\displaystyle \\left( \\sum_{k1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k1}^n a_k^2 \\right) \\left( \\sum_{k1}^n b_k^2 \\right)$$","categories":["2.语言","工具语言"]},{"title":"Markdown语法","path":"/2024/02/09/2-语言-工具语言-Markdown语法/","content":"Markdown 基础介绍Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 Markdown 能被使用来撰写电子书，如：Gitbook。 标题Markdown 标题有两种格式。 使用 和 - 标记一级和二级标题 一级标题=================二级标题----------------- 使用 # 号可表示 1-6 级标题，一级标题对应一个 # 号。 # 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 段落Markdown 段落的换行有两种格式。 使用两个以上空格加上回车 在段落后面使用一个空行 字体*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ 分割线可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： **** * ******- - ----------- 删除线如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线 ~~ 即可 ~~这是要删除的文本~~ 下划线利用 html 的 u 标签 u带下划线文本/u 脚注脚注是对文本的补充说明。 Markdown 脚注的格式如下: [^要注明的文本] 列表Markdown 支持有序列表和无序列表。 无序列表使用星号 (*)、加号 (+) 或是减号 (-) 作为列表标记，这些标记后面要添加一个空格，然后再填写内容 * 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项 有序列表使用数字并加上 . 号来表示 1. 第一项2. 第二项3. 第三项 列表嵌套只需在子列表中的选项前面添加两个或四个空格即可 1. 第一项：- 第一项嵌套的第一个元素- 第一项嵌套的第二个元素2. 第二项：- 第二项嵌套的第一个元素- 第二项嵌套的第二个元素 区块 Markdown 区块引用是在段落开头使用 符号 ，然后后面紧跟一个空格符号 区块是可以嵌套的，一个 符号是最外层，两个 符号是第一层嵌套 区块中也可以使用列表 列表中也可以使用区块，需要在 前添加四个空格的缩进 区块 区块嵌套 区块嵌套 1. 区块列表1 2. 区块列表2 + 区块列表1 + 区块列表2* 列表1 列表区块1 列表区块2* 列表2 代码段落上的一个函数或片段的代码可以用反引号把它包起来（） `printf()` 代码块 四个空格 tab 制表符 用 `` 包裹一段代码，并指定一种语言 链接[链接名称](baidu.com)baidu.com 高级链接 这个链接用 1 作为网址变量 [Google][1]然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ 图片![alt 属性文本](图片地址)![alt 属性文本](图片地址 可选标题) 也可以按照高级链接的方式，将图片地址放在文档结尾图片大小如果要修改图片大小，采用 html 的 img 标签 表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行 | 表头 | 表头 || ---- | ---- || 单元格 | 单元格 || 单元格 | 单元格 | 对齐 -: 设置内容和标题栏居右对齐。 :- 设置内容和标题栏居左对齐。 :-: 设置内容和标题栏居中对齐。 Markdown 技巧 不同的 markdown 编辑器支持的语法略有不同，下方介绍的相关技巧不一定支持 Github Flavored Markdown (GFM) 的工作清单语法 显示效果 KaTeX 数学公式排版语法语法 显示效果 SVG 向量流程图语法 显示效果 向量 UML 顺序图表语法 显示效果","categories":["2.语言","工具语言"]},{"title":"RSS","path":"/2024/02/08/2-语言-工具语言-RSS/","content":"Rsshub 的 docker 部署 下载 docker-compose.yml wget https://raw.githubusercontent.com/DIYgod/RSSHub/master/docker-compose.yml 检查是否有需要修改的配置 vi docker-compose.yml # or your favorite editor 创建 redis 卷 Create a docker volume to persist Redis caches docker volume create redis-data 启动 docker-compose up -d Channelchannel 参考手册 元素 描述category 可选的。为 feed 定义所属的一个或多个种类。cloud 可选的。注册进程，以获得 feed 更新的立即通知。copyright 可选。告知版权资料。description 必需的。描述频道。docs 可选的。规定指向当前 RSS 文件所用格式说明的 URL。generator 可选的。规定用于生成 feed 的程序。image 可选的。在聚合器呈现某个 feed 时，显示一个图像。language 可选的。规定编写 feed 所用的语言。lastBuildDate 可选的。定义 feed 内容的最后修改日期。link 必需的。定义指向频道的超链接。managingEditor 可选的。定义 feed 内容编辑的电子邮件地址。pubDate 可选的。为 feed 的内容定义最后发布日期。rating 可选的。feed 的 PICS 级别。skipDays 可选的。规定忽略 feed 更新的天。skipHours 可选的。规定忽略 feed 更新的小时。textInput 可选的。规定应当与 feed 一同显示的文本输入域。 Itemitem 参考手册 元素 描述author 可选的。规定项目作者的电子邮件地址。category 可选的。定义项目所属的一个或多个类别。comments 可选的。允许项目连接到有关此项目的注释（文件）。description 必需的。描述此项目。enclosure 可选的。允许将一个媒体文件导入一个项中。guid 可选的。为项目定义一个唯一的标识符。link 必需的。定义指向此项目的超链接。pubDate 可选的。定义此项目的最后发布日期。source 可选的。为此项目指定一个第三方来源。 验证可以在 http://www.feedvalidator.org 找到很好的验证器。 RSS 阅读器功能文字 字体 字号 背景 翻页 图片 缩放 移动 下载 视频 播放暂停 快进 进度条 音量 下载 设置 订阅 自动手动同步 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["2.语言","工具语言"]},{"title":"正则表达式_介绍","path":"/2024/02/07/2-语言-工具语言-正则表达式-介绍/","content":"参考链接：正则表达式30分钟入门教程 什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。 很可能使用过 Windows 下用于文件查找的通配符(wildcard)，也就是和?。如果想查找某个目录下的所有的 Word 文档的话，会搜索.doc。在这里，* 会被解释成任意的字符串。和通配符类似，正则表达式也是用来进行文本匹配的工具。 元字符正则表达式中的元字符是指具有特殊意义的字符，它们用于定义模式或规则，以便在文本中匹配特定的模式。以下是一些常见的元字符 — — . 匹配任意单个字符（除了换行符）。 * 匹配前面的字符零次或多次。 + 匹配前面的字符一次或多次。 ? 匹配前面的字符零次或一次。(懒惰模式) ^ 匹配字符串的开头。 $ 匹配字符串的结尾。 [] 匹配方括号中的任意一个字符。 () 标记一个子表达式的开始和结束位置。 | 用于在两个或多个模式之间进行选择。 字符转义如果需要匹配这些特殊字符本身，就需要使用字符转义。 字符转义是指用反斜杠 \\ 将特殊字符转义成普通字符的过程。例如，如果要匹配句子中的句号，就需要使用 . 来表示句号本身，而不是任意单个字符。同样的，如果要匹配星号本身，就需要使用 * 来表示星号本身，而不是匹配前面的字符零次或多次。 在正则表达式中，还有一些常用的转义字符，如 \\d 表示匹配任意一个数字字符，\\w 表示匹配任意一个字母、数字或下划线字符，\\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等），\\b 表示匹配单词的边界等。这些转义字符可以方便地匹配一些常见的字符类型，避免了手动输入所有可能的字符的麻烦。 重复{n}重复 n 次 {n,}重复 n 次或更多次 {n,m}重复 n 到 m 次 字符字符匹配直接在方括号里列出： [aeiou]就匹配任何一个英文元音字母； [.?!]匹配标点符号(.或?或!)。 也可以指定一个字符范围： [0-9]代表的含意与\\d 就是完全一致的：一位数字； [a-z0-9A-Z_]也完全等同于\\w。 **表达式解析：(?0\\d{2}[) -]?\\d{8}**这个表达式可以匹配几种格式的电话号码，像(010)88886666，或 022-22334455，或 02912345678 等。首先是一个转义字符(,它能出现 0 次或 1 次(?),然后是一个 0，后面跟着 2 个数字(\\d{2})，然后是)或-或空格中的一个，它出现 1 次或不出现(?)，最后是 8 个数字(\\d{8})。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。 IP 地址表达式((2[0-4]\\d|25[0-5]|[01]?\\d\\d?).){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?) 转义字符与反义字符在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法(?#comment)来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，们更需要懒惰匹配，也就是匹配尽可能少的字符。前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样.?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。现在看看懒惰版的例子吧： a.?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 后向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。 后向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b可以用来匹配重复的单词，像 go go, 或者 kitty kitty。","categories":["2.语言","工具语言"]},{"title":"正则表达式笔记","path":"/2024/02/06/2-语言-工具语言-正则表达式笔记/","content":"正则表达式什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。 正则表达式就是记录文本规则的代码，用于模式匹配和搜索文本的工具。 正则表达式的模式 字面值字符：普通字符按照字面意义进行匹配,例如字母、数字、空格等，可以直接匹配它们自身。 特殊字符：例如点号 .、星号 *、加号 +、问号 ? 等，它们具有特殊的含义和功能。 字符类：用方括号 [ ] 包围的字符集合，用于匹配方括号内的任意一个字符。[^ ] 匹配除了括号内的字符以外的任意一个字符 元字符：例如 \\d、\\w、\\s 等，用于匹配特定类型的字符，如数字、字母、空白字符等。 量词：例如 n、n,、n,m 等，用于指定匹配的次数或范围。 边界符号：例如 ^、$、\\b、\\B 等，用于匹配字符串的开头、结尾或单词边界与非边界位置。 分组和捕获：( )：用于分组和捕获子表达式。(?: )：用于分组但不捕获子表达式。 字符字符匹配直接在方括号里列出： [aeiou] 就匹配任何一个英文元音字母 [.?!] 匹配标点符号 (.或?或!) 也可以指定一个字符范围： [0-9] 代表的含意与\\d 就是完全一致的：一位数字 [a-z0-9A-Z_] 也完全等同于\\w。 普通字符 字符 含义 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（ 、\\r）之外的任何单个字符，相等于 [^ \\r]。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] 非打印字符 字符 含义 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 特殊字符 字符 含义 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则$ 也匹配 ‘ ’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。 * 匹配前面的子表达式零次或多次。要匹配 * 字符，请使用*。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。 . 匹配除换行符 之外的任何单字符。要匹配 . ，请使用 . 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 [。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’ ’ 匹配换行符。序列 ‘ 匹配 “，而 ‘(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用^。 { 标记限定符表达式的开始。要匹配 {，请使用 {。 | 指明两项之间的一个选择。要匹配|，请使用 |。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。例如 IP 地址表达式:((2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?).)3(2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?) 限定符 字符 含义 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于 {0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 “do” 、 “does”、 “doxy” 中的 “do” 和 “does”。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 含义 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 或 \\r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 或 \\r 之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 不能将限定符与定位符一起使用。由于在紧靠换行或者单词边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式 转义字符与反义字符 在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。 反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法 (?#comment) 来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。 如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，们更需要懒惰匹配，也就是匹配尽可能少的字符。 前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样 .*? 就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 现在看看懒惰版的例子吧： a.*?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，” 或 “ 操作,字符具有高于替换运算符的优先级，使得m 反向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本 (也就是此分组捕获的内容) 可以在表达式或其它程序中作进一步的处理。 反向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b 可以用来匹配重复的单词，像 go go, 或者 kitty kitty。 总结 确定需要匹配的基本字符或字符类别集合等 确定匹配的字符或字符集合的数量 特殊字符和转义字符的处理 边界和位置的匹配 使用捕获组 () 进行多组匹配 使用反向引用 使用逻辑操作符进行判定 正则表达式字符含义表 字符 含义 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 “n”。\\ 匹配一个换行符。序列 \\\\ 匹配 “\\ 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \\ 或 \\\\r 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 \\ 或 \\\\r 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o2 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o2, 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o1, 等价于 o+。o0, 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。o0,1 等价于 o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，o+? 将匹配单个 “o”，而 o+ 将匹配所有 o。 . 匹配除换行符（ 、\\r）之外的任何单个字符。要匹配包括 \\ 在内的任何字符，请使用像 (. ) 的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在 VBScript 中使用 SubMatches 集合，在 JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ( 或 )。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “ 或 “ 字符 ( ) 来组合一个模式的各个部分是很有用。例如， industr(?:y (?pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，Windows(?95 98 (?!pattern) 正向否定预查 (negative assert)，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如 Windows(?!95 98 (?pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，(?95 98 (? 反向否定预查，与正向否定预查类似，只是方向相反。例如 “(?” 能匹配 “3.1Windows” 中的 “Windows”，但不能匹配 “2000Windows” 中的 “Windows”。 x y 匹配 x 或 y。例如，z [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 “plain” 中的 a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，[^abc] 可以匹配 “plain” 中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\\\\b 可以匹配”never” 中的 er，但不能匹配 “verb” 中的 er。 \\B 匹配非单词边界。er\\\\B 能匹配 “verb” 中的 er，但不能匹配 “never” 中的 er。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的c 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\\\x41 匹配 “A”。\\\\x041 则等价于 \\\\x04 “1”。正则表达式中可以使用 ASCII 编码。 um 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)\\\\1 匹配两个连续的相同字符。 标识一个八进制转义值或一个向后引用。如果 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 m 标识一个八进制转义值或一个向后引用。如果 m 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 m 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 m 将匹配八进制转义值 nm。 ml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。","categories":["2.语言","工具语言"]},{"title":"Kalman Filter 通俗讲解-CSDN博客","path":"/2024/02/05/2-语言-结构算法-Kalman-Filter-通俗讲解-CSDN博客/","content":"引言Kalman Filter，很多人刚听到这个名词时，总是会下意识认为这就是个 滤波器。我这里想要重点声明的是，Kalman Filter 不是滤波，它是一种信息融合的过程。那么 Kalman Filter 到底是什么？它在那些方面有着应用，它的基本原理又是什么。如果你参考国内的论坛或者教材上，你一定会发现，大部分都是一些复杂公式与枯燥抽象的说明。这里我们将通过尽量通俗易懂的讲解来给大家解释下什么叫 Kalman Fiter。 先睹为快正如我前面提到的，从定义及复杂公式去理解卡尔曼滤波，对咱们凡人来说基本是不可能的。我们将公式简化，先从下面的公式来开始讲解： 其中下标 k k k 是指状态，这里我们可以把它看成间隔，比如 k 1 k1 k=1 指 1ms， k 2 k2 k=2 指 2ms。我们的目的就是要找到在状态 k k k 时 X X X 的估计。在公式中 Z k Z_k Zk​就是真实测量值。我们要牢记，这些测量值并不可靠。（如果这些测量值是可靠的，那么我们就没必要学 kalman filter 了：））。 K k K_k Kk​指卡尔曼增益（这是整个公式中的核心点）。 X k − 1 ^ \\hat{X_{k-1}} Xk−1​^​就是上一状态时的估计。在上述公式中，我们唯一未知的量就是卡尔曼增益 K k K_k Kk​。像测量值及上一状态估计，我们都已经知道了。当然了，求出卡尔曼增益并不简单，但是我们有方法来解决它。我们从另一角度来思考，让我们假设卡尔曼增益为 0.5，我们会得到什么呢？它就是个简单的平均！换句话说，我们应该找到对应于每个状态的更加智能化的卡尔曼增益系数。归根结底就是： 卡尔曼滤波器为每个结果状态找到最优的平均因子。 不知怎的，还记得一些关于过去的状态。 如何，Kalman Filter 神奇吧！ 分步指南下面是分布指南，可以快速开始卡尔曼滤波。 Step1 构建模型这是最重要的步骤。首先，你必须确保卡尔曼滤波的条件符合你的问题。我们还记得卡尔曼滤波的两个典型方程（wiki）：x k A x k − 1 + B u k + W k − 1 x_k Ax_{k-1}+Bu_k+W_{k-1} xk​=Axk−1​+Buk​+Wk−1​z k H x k + v k z_k Hx_k+v_k zk​=Hxk​+vk​ 第一个公式意味着每个 x k x_k xk​可以通过一个线性随机方程来表示。任何一个 x k x_k xk​都是它前一状态的的只加上控制信号 u k u_k uk​及处理噪声 W k − 1 W_{k-1} Wk−1​的线性组合。大多数的情况下，并不需要控制信号 u k u_k uk​。 第二个公式告诉我们，任何测量值（这里我们并不确定它是否准确）是当前状态信号值及测量噪声的线性组合，我们默认该值服从高斯分布。 这两个公式中的处理噪声及测量噪声，我们都认为是统计独立的。 方程式中的系数 A , B A,B A,B 及 H H H 是一般形式的矩阵。但是在大多数的信号处理问题中，我们使用的模型中，这些系数都仅仅是数值。而且当这些值在状态间发生变化时，大多数的情况下，我们可以假设它们就是常数。 如果我们确定我们的系统符合这个模型（大多数的系统都是符合的），那么接下来，就只剩下估计噪声函数 W k − 1 W_{k-1} Wk−1​及 v k v_k vk​的均值和标准差。我们知道在现实生活中，没有哪个信号是纯高斯分布的，但是我们可以通过近似来进行假设。 这不是一个大问题，因为我们将看到卡尔曼滤波算法试图收敛到正确的估计，即使高斯噪声参数估计很差。 这里我们要始终牢记于心的是：“你估计噪声参数越准确，你就能获得更好的估计” Step2 开始处理如果你成功的将你的模型拟合到卡尔曼滤波器中，那么接下来的步骤就是决定必要的参数及你的初始值。 我们有两个不同的方程集合：时间更新（预测）及测量更新（校准）。两个方程集合都是应用在第 k k k 个状态 我们在步骤一中建立模型，因此我们知道矩阵 A,B 和 H。很可能，他们都是数值常量。并且他们极可能都是数值 1. 我建议你们重新写下这些公式，并看看如何去简化这些公式。.上述公式中最痛苦的事儿就是确定 R 和 Q 了。R 还相对比较容易找出，因为，通常来讲，我们对环境中的噪声还是比较确定的。但是寻找 Q 就并不明显了。在这个阶段，我们并不能给你一个指定的方法。 为了开始这个处理，我么需要知道 x 0 x_0 x0​和 P 0 P_0 P0​的估计 Step3 迭代在我们收集了我们需要的所有信息后，我们开始处理流程，现在我们可迭代估计。我们要牢记上一状态的估计将成为当前状态的估计的输入。这里，先验估计指测量更新校准前的粗略估计。这里我们使用在测量更新公式中的先验值 在测量更新公式中，我们找到了在状态 k 时 x 的估计。并且找到了为了状态 k+1 估计所需要的值。 我们计算的卡尔曼增益，在下一个迭代步骤中并不需要。 这是一组方程中隐藏的，神秘的，最重要的部分。 我们在测量更新阶段评估的值也称为后验值。这也是说得通的。 一个简单的例子如果小伙伴们在看到这里还有点稀里糊涂的，那么接下来我们找个例子来加深下理解。 现在，让我们努力去估计一个标量随机常数，例如来自某个信号源的“电压读数”。假设它有一个恒定的 a V 电压，但是我们读数会不准确，可能会读高了，也有可能读低了。我们假设测量噪声的的标准差为 0.1 V。 现在我们来构建我们的模型： 就像我之前说的，我们可以把方程简化成非常简单的形式。 首先，我们有一个一维的信号的问题，因此我们模型中的每个系数都是数值，而不是矩阵。 我们并没有控制信号 u k u_k uk​ 因为信号是一个常数，那么常数 A 就是 1，因为我们已经知道下一个值等于先前的值。我们很幸运，在这个例子中我们有一个恒定的值，但是即使它具有其他任何线性性质，我们都可以将它假设成 1. 值 H1,因为我们知道测量值是由状态值和一些噪声组成的。你很少会遇到现实生活中，H 与 1 不相同的情况 最后，我们假设我们得到了下面的测量值 TIME (ms) 1 2 3 4 5 6 7 8 9 10 VALUE (V) 0.39 0.50 0.48 0.29 0.25 0.32 0.34 0.48 0.41 0.45 我们应该从某处开始，比如说 k0。我们应该找到或者假设某个初始状态。这里我们给出了一些初始值。我们假设 $X_00$ 并且 $P_01$，那么为什么我们不选择 $P_00$ 呢？这很简单。如果我们这样选择，那么就意味着环境中不存在噪声，而这个假设将导致在 k 状态下 X 的所有结果估计值为 0（保留初始状态），所以我们一般不取 $P_00$ 我们来写时间更新和测量更新方程 ![这里写图片描述](https://img-blog.csdn.net/20180603164207725?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA2NjUyMTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 每一轮计算的步骤：","tags":["clippings"],"categories":["2.语言","结构算法"]},{"title":"PID算法","path":"/2024/02/02/2-语言-结构算法-PID算法/","content":"简介无人机可以在空中进行智能自动飞行，直升机能够悬停在空中，而地铁则可以在每个站点精准地停下。这其中，火车按照预定速度行驶，平衡车也能做到保持直立平衡，所有这些现代技术的实现背后，离不开自动控制技术。这种技术使得机器在各自的领域变得更加智能与高效。 自动控制技术是 20 世纪发展最快、影响最大的技术之一，它已经成为 21 世纪最重要的高技术之一。在科技、生产、军事、管理乃至的日常生活中，自动控制技术都扮演着不可或缺的角色。简单来说，自动控制技术是控制论的技术实现，是通过具备特定控制功能的自动控制系统来完成特定的控制任务，确保某个过程按照预设要求运行，从而实现预定目标。 自动控制原理根据控制方式的不同，自动控制系统一般分为闭环控制和开环控制两种类型。 闭环控制闭环控制，又称负反馈控制，其工作原理与人类或动物的目标导向行为类似。闭环控制系统由多个部分构成：传感器、控制装置和执行机构。传感器如同生物的感官，负责检测被控对象的状态信息（输出量），并将其转换为物理或电信号传输给控制装置。控制装置相当于人体的神经系统，它会比较被控对象的实际状态和设定目标，以便生成一个控制信号，通过执行机构来驱动被控对象，调整其到达理想状态。 在实际应用中，闭环控制的方法多种多样，涵盖了最优控制、自适应控制、专家控制、模糊控制、容错控制和智能控制等，广泛应用于现代工业及科技领域。 开环控制开环控制，也被称为程序控制，是依据事先设定的程序依次发出信号以控制对象。根据信号产生的方式，开环控制可以分为时限控制、次序控制和条件控制。从 20 世纪 80 年代以来，应用微电子技术生产的可编程序控制器已在各类工业控制中得到广泛应用，例如电梯控制、数控机床和自来水厂的运行管理，表现出极大的灵活性和效率。 然而，在实际情况中，大多数系统都倾向于使用闭环控制，因为闭环控制具备反馈调节功能，可以实时监测系统状态，并基于偏差进行动态调整，确保状态最终趋近于预设目标。 PID 控制器原理PID 控制算法是闭环控制中一种基础而重要的控制算法，已有近 70 年的使用历史，它以简单的结构、良好的稳定性和可靠的工作性能，广泛应用于工业控制领域。尤其在对系统动态特性不完全了解或者无法有效测量系统参数时，PID 控制技术尤为适用。 在一个单回路控制系统中，受到外界扰动的影响时，被控变量的值会偏离设定值，产生误差。自动控制系统会将来自传感器的测量值与设定值进行比较，产生的误差值随后通过比例、积分和微分运算生成一个标准控制信号，进而调整执行机构的动作。PID 控制器的核心便是基于误差，通过比例（P）、积分（I）与微分（D）三者的计算，得到所需的控制量。很重要的一点是：PID 控制算法的核心要素就是比例（P）、积分（I）、微分（D）。 ① 比例（P）控制比例控制是最基本的控制方式。其理念是系统一旦发现偏差，比例调节就会立即做出反应，努力减少这种偏差。比例控制能快速调整，减小误差，但如果比例参数设置过大，系统将可能崩溃，甚至变得不稳定。尽管比例控制带来快速的响应，往往在稳态条件下仍会存在误差。 ② 积分（I）控制积分控制的输出与误差信号在时间上的积累量成正比。随着时间的推移，即使误差非常小，积分项也会逐渐增加，推动控制器的输出以使稳态误差趋近于零。然而，由于积分的累积特性，调节速度可能变慢，过快的增益将导致系统不稳定。因此，积分项通常与比例项结合使用，形成 PI 调节器，以减少稳态误差。 ③ 微分（D）控制微分控制则是将控制器的输出与误差信号的变化率（即误差的变化速度）相联系。自动控制系统在调整的过程中常常会产生振荡，尤其是在存在较大延迟的情形下，这种现象更为明显。微分控制可以提前预测误差变化，进而避免过大的超调。因此，当控制对象具有显著惯性或滞后特性时，比例+微分（PD）控制器可以改善系统在调节过程中的动态特性。 在自动调节系统中，干扰刚出现时微分控制立刻起效，同时比例控制会随着误差的加大而增加作用，帮助系统迅速稳定。之后，积分控制会渐渐增强直至消除余差，实现设定值上的精确控制。 在实际应用中，PID 控制算法有两种计算方法：位置式算法和增量算法。增量算法相较于标准算法，根据相邻两次运算的差异计算。 标准的位置式计算法公式：[P_{out}(t) K_p \\cdot e(t) + K_i \\cdot \\sum e(t) + K_d \\cdot (e(t) - e(t-1))] 增量法计算公式：[\\Delta P P_{out}(t) - P_{out}(t-1) K_p \\cdot (e(t) - e(t-1)) + K_i \\cdot e(t) + K_d \\cdot (e(t) - 2e(t-1) + e(t-2))] PID 控制器的参数整定PID 控制器的参数整定是控制系统设计的核心内容，常见方法可以大致分为理论计算整定法和工程整定法。前者依赖于所设计系统的数学模型，经过理论计算确定控制器的参数。后者更加依赖经验，通常在实际工程中进行试验调整。常用的参数整定方法包括临界比例法、反应曲线法和衰减法。 在的经验中，PID 参数的确定步骤如下： 确定比例系数 Kp先将积分项和微分项去掉，使其成为纯比例调节。设定输入为系统最大输出的 60% 至 70%，从 0 开始逐渐提升 Kp 直至观察到系统开始振荡。随后逐步减小 Kp，直至系统恢复稳定。记录此时的 Kp，并将最终比例系数设定为其 70% 至 80%。 确定积分时间常数 TiKp 确定后，设定一个较大的积分时间常数 T，然后逐渐减小到系统形成振荡，再逐步增大 T 直至消失。最终记录 T，并将 PID 控制器的 Ti 值设定为当前的 150% 至 180%。 确定微分时间常数 Td微分时间常数 Td 一般设为 0，使 PID 调节转变为 PI 调节。如果非要设定，取不振荡时的值的 30% 即可。 系统空载、带载联调最后进行 PID 参数的微调，确保其满足特定性能要求。 通过以上步骤，读者可以更深入地理解 PID 控制的工作原理。接下来，将以电机转速控制系统为例，形象地展示 PID 为什么能使系统达到设定值。 在电机转速控制系统中，输入量是目标设定值（设定转速），测量装置实时测量当前转速。控制器（PID 控制器）根据偏差计算控制值，最终输出给执行机构。初始状态下电机转速为零，设定值为 100 RPM，则控制过程是： 当前速度偏差计算为 (U_e(k) U_r(k) - U_d(k)) PID 控制器计算比例、积分和微分控制值，合并得出当前控制值。 该过程不断重复，最终电机在加负载时仍然能够稳定在设定值。 最后，咱们借用单摆现象进一步说明 PID 控制的原则。抬高单摆的小球后放手，小球会因重力自然摆动最终静止。这个现象反映了比例部分，重力相当于系统的”恢复力”，其始终指向平衡位置。同样，空气阻力的存在使得小球最终回到静止状态，类似于 PID 中微分部分的作用。积分在此的角色则相似于抵消外界扰动的额外力量，确保系统准确平衡。 通过这样的对比，读者能够更形象易懂地把握 PID 控制的本质与机制。PID 的三个部分相互补充，确保控制系统稳定、可靠。 代码#includestdio.h#includestdlib.h//#includeMacianPID.h/**PID 控制其实是对偏差的控制过程。 *如果偏差为0,则比例环节不起作用，只有存在偏差时，比例环节才起作用。 *积分环节主要是用来消除静差，所谓静差，就是系统稳定后输出值和设定值之间的差值，积分环节实际上就是偏差累计的过程，把累计的误差加到原有系统上以抵消系统造成的静差。 *微分信号则反应了偏差信号的变化规律，或者说是变化趋势，根据偏差信号的变化趋势来进行超前调节，从而增加了系统的快速性。 1.比例系数 Kp 的作用是加快系统的响应速度，提高系统的调节精度。Kp 越大，系统的响应速度越快，系统的调节精度越高，但是容易产生超调，甚至会使系统不稳定。Kp 取值过小，则会降低调节精度，使响应速度缓慢，从而延长调节时间，是系统静态、动态特性变差；2.积分作用系数 Ki 的作用是消除系统的稳态误差。Ki 越大，系统的静态误差消除的越快，但是 Ki 过大，在响应过程的初期会产生积分饱和的现象，从而引起响应过程的较大超调。若 Ki 过小，将使系统静态误差难以消除，影响系统的调节精度；3.微分系数 Kd 的作用是改善系统的动态特性，其作用主要是在响应过程中抑制偏差向任何方向的变化，对偏差变化进行提前预报。但是 kd 过大，会使响应过程提前制动，从而延长调节时间，而且会降低系统的抗干扰性。 12/16 去除变积分PID控制方式 变积分 PID 的基本思想是设法改变积分项的累加速度，使其与偏差大小相对应：偏差越大，积分越慢; 偏差越小，积分越快*/struct _pid\tfloat SetParam; //定义设定值 float ActualParam;\t//定义实际值 float err; //定义偏差值\tfloat err_next; //定义上一个偏差值 float err_last; //定义最上前的偏差值 float Kp,Ki,Kd; //定义比例、积分、微分 float voltage; //控制执行器的变量 float integral; //定义积分值 //积分分离\t当被控量与设定值偏差较大时，取消积分作用。当被控量接近设定值时，引入积分控制，已消除静差，提高精度 float err_max; //积分分离 被控量与设定偏差最大值 //抗积分饱和 控制器输出继续增大 执行器开度不可能开大 此时输出控制量超出正常运行范围而进入饱和区 float umax; // 抗积分饱和 控制量极限范围 float umin; // 抗积分饱和 控制量极限范围 pid; void PID_init()\tpid.SetParam = 0.0;\tpid.ActualParam = 0.0;\tpid.err = 0.0;\tpid.err_next = 0.0; pid.err_last = 0.0;\tpid.integral = 0.0;\tpid.Kp = 0.200000;\tpid.Ki = 0.015000;\tpid.Kd = 0.200000;\tpid.err_max = 200;\tpid.umax = 400;\tpid.umin= -200; float PID_realize(float param)//\tfloat incrementParam ;\tint index; pid.SetParam = param;\tpid.err = pid.SetParam - pid.ActualParam; if( pid.ActualParam pid.umax ) //抗积分饱和 if(\tabs(pid.err) pid.err_max ) //积分分离过程 index = 0; else index = 1; if( pid.err 0 ) pid.integral+=pid.err; else if( pid.ActualParam pid.umin ) if(\tabs(pid.err) pid.err_max ) index = 0; else index = 1; if(pid.err 0 ) pid.integral+=pid.err; else if(abs(pid.err) pid.err_max) //积分分离过程 index=0; else index=1; pid.integral+=pid.err; //pid.integral/2 梯形积分； 消除余差 提高积分项运算精度 矩形积分改为梯形积分 pid.voltage = pid.Kp*pid.err + index*pid.Ki*pid.integral/2 + pid.Kd*(pid.err-pid.err_last);\tpid.err_last = pid.err;\tpid.ActualParam = pid.voltage*1.0; //增量式PID 结果与最近三次的偏差有关 提高系统的稳定性 //incrementParam = pid.Kp*(pid.err-pid.err_next) + pid.Ki*pid.err + pid.Kd*(pid.err-2*pid.err_next+pid.err_last); //pid.ActualParam += incrementParam;\t//pid.err_last = pid.err_next;\t//pid.err_next = pid.err; return pid.ActualParam;int main()\tPID_init();\tint count=0; while(count1000) float speed=PID_realize(200.0); printf(%f ,speed); count++; if(count%6 ==0) printf( ); return 0;","categories":["2.语言","结构算法"]},{"title":"基础算法","path":"/2024/02/01/2-语言-结构算法-基础算法/","content":"10 大基础实用算法及其讲解算法一：快速排序算法快速排序是一种高效的排序算法，由计算机科学家东尼·霍尔发展而成。其核心理念是利用分治法将待排序的数组分成多个子数组，通过递归不断排序。快速排序在平均情况下，排序 n 个项目的比较次数为 Ο(n log n)，而在最坏情况下则需要 Ο(n²) 次比较。但其实，最坏情况并不常见，快速排序的性能通常优于其他平均时间复杂度为 Ο(n log n) 的算法。这主要归因于其内部循环在许多计算机架构上可以被有效地实现。 算法步骤： 选择基准：从数列中挑出一个元素作为基准（pivot）。 分区操作：重新排序数列，确保所有比基准小的元素在基准前面，而所有比基准大的元素在基准后面。 递归排序：对基准前后两个子数组递归应用上述步骤，直到每个子数组的大小为零或一。 例如，给定数组 [3, 6, 8, 10, 1, 2, 1]，选择 3 作为基准，分区后可能得到 [1, 2, 1, 3, 6, 8, 10]，然后递归排序 [1, 2, 1] 和 [6, 8, 10]。 算法二：堆排序算法堆排序利用堆这一数据结构进行排序。堆是近似完全二叉树并且遵循堆的性质，即每个父节点的键值总是大于或小于其子节点的键值。堆排序的时间复杂度为 Ο(n log n)，适合在大规模数据处理时使用。 算法步骤： 创建堆：构建一个最大堆（或者最小堆）。 交换元素：将堆的最大元素（根节点）与堆的最后一个元素交换。 调整堆：减小堆的大小并对根节点进行下沉操作，维护堆的性质。 重复：持续执行步骤 2 和步骤 3，直到堆的大小为 1。 通过这种方式，可以确保所有元素按顺序排列。举个例子，初始堆 [10, 9, 8, 7, 6] 被调整为 [9, 7, 8, 10, 6]，并继续逐步形成有序数组。 算法三：归并排序归并排序是一种有效的排序算法，属于分治法的典型应用，能高效处理大数据集。 算法步骤： 申请空间：为合并后序列申请一个大小为两个已排序序列之和的空间。 指针初始化：设定两个指针，分别指向两个已排序序列的开始位置。 合并操作：比较两个指针所指向的元素，选择较小的元素放入合并空间，并移动相应指针。 重复比较：继续直到其中一个指针到达序列尾部。 复制剩余元素：将剩下的序列全部复制到合并序列的尾部。 例如，将 [1, 3, 5] 和 [2, 4, 6] 合并到同一空间，最终形成排序后的序列 [1, 2, 3, 4, 5, 6]。 算法四：二分查找算法二分查找算法是一种高效的搜索算法，只适用于有序数组。其每一步都将搜索范围缩小一半，具有 Ο(log n) 的时间复杂度。 算法步骤： 确定中间元素：从数组中选取中间元素，如果该元素是目标，则搜索结束。 范围缩小：如果目标值与中间元素不符，则根据目标值与中间元素的大小关系，选择新的搜索范围。 重复查找：该过程持续进行，直到找到目标值或范围为空。 例如，在列表 [1, 2, 3, 4, 5] 中查找 3，第一个中间元素是 3，直接找到目标。 算法五：BFPRT(线性查找算法)BFPRT 算法，也称为”中位数的中位数”，用于选择第 k 大或第 k 小的元素，保证在最坏情况下时间复杂度为 Ο(n)。 算法步骤： 分组：将元素分为 n5 组，每组包含 5 个元素。 计算中位数：对每组排序并提取中位数。 递归查找：递归调用选择算法找到中位数的中位数，以此作为基准进行分割。 分割数组：根据中位数，将数组分为小于和大于该中位数的部分。 递归搜索：根据 k 的值判断在左边还是右边继续搜索，直到确定 k-th 元素。 比如，在数组 [1, 5, 2, 6, 3] 中选择第 k 大的元素时，通过多次分割和选择中位数来缩小范围。 算法六：DFS（深度优先搜索）深度优先搜索（DFS）是一种有效的树和图遍历方法，其核心思想是尽可能深地探索分支，直到访问到所有节点。 算法步骤： 访问节点：访问起始节点 v。 递归遍历：从未访问过的邻接点出发，进行深度优先遍历。 回溯处理：一旦整个分支被遍历完，回溯并检查其他未访问的节点。 例如，从节点 A 开始，DFS 可能访问顺序为 A - B - D - C，直到所有节点被访问。基于这一概念，还可生成拓扑排序用于解决最大路径等问题。 算法七：BFS（广度优先搜索）广度优先搜索（BFS）从根节点开始，沿着图的宽度逐层遍历所有节点。主要用于寻找最短路径。 算法步骤： 入队根节点：将根节点放入队列。 探查节点：取出队头节点，判断是否为目标。如果是，则结束搜索。 队列处理：将尚未访问的子节点加入队列。 重复步骤：直至队列为空，或者目标被找到。 在一棵树中，从 Node A 开始，BFS 可能会按层访问每一行的节点，保证找到最短的路径。 算法八：Dijkstra 算法Dijkstra 算法是求解单源最短路径的经典算法，适用于非负权重的有向图。 算法步骤： 初始化：设定源节点 S 的距离为零，其他节点的距离为无穷大。 选择顶点：从未访问的节点中选择距离最小的节点，标记为已访问。 更新距离：对所有邻接的节点，若通过当前节点的距离更小，则更新它们的距离值。 重复：持续进行上述步骤直到所有节点均已访问。 例如，在有向图中，Dijkstra 算法能够从源节点出发找到其余所有节点的最短路径，帮助解决如路由问题等多项应用。 算法九：动态规划算法动态规划是一种通过将原问题分解为简单的子问题，从而高效解决复杂问题的方法。常用于优化问题中。 算法步骤： 最优子结构：确定问题的最优解是否包含子问题的最优解。 重叠子问题：识别出相同的子问题，保证每个子问题只计算一次并存储结果以提高效率。 构建递归关系：通过递归或迭代构建算法以解决实际问题。 例如，背包问题需要在给定物品中选择组合以最大化价值，利用动态规划可以显著提高计算效率。 算法十：朴素贝叶斯分类算法朴素贝叶斯分类算法基于贝叶斯定理，通过特征之间独立性的假设来处理分类问题。 算法步骤： 特征独立：假设特征之间相互独立，对每个特征的条件概率进行估计。 计算概率：基于训练数据计算每个类别的概率。 分类决策：通过计算后验概率，选择具有最高概率的分类结果。 朴素贝叶斯算法在许多实际应用中（如文本分类和垃圾邮件过滤）表现良好，虽假设较为简单，但其效率和准确性往往令人惊讶。","categories":["2.语言","结构算法"]},{"title":"敏捷开发","path":"/2024/01/31/2-语言-结构算法-敏捷开发/","content":"敏捷开发模式是一种软件开发方法论，旨在通过迭代和增量的方式交付高质量的软件产品。它强调灵活性、快速响应变化、团队协作以及持续交付。敏捷开发模式的核心思想是通过短周期的开发迭代（通常称为”迭代”或”冲刺”）来逐步构建和完善产品，从而快速适应需求变化并持续向客户交付价值。 敏捷开发的主要特点 迭代与增量开发：项目分为多个迭代，每个迭代持续 1 到 4 周。在每个迭代结束时，团队交付一个可工作的产品增量，逐步完善产品。 持续反馈与改进：通过频繁的反馈循环，团队能够在每个迭代后反思并改进开发过程，确保项目朝着正确的方向发展。 拥抱变化：敏捷开发鼓励团队适应需求的变化，而不是严格按照最初的计划执行。需求的变化被视为客户对市场的反应，而非对项目的干扰。 跨职能团队：敏捷团队通常是小型的、跨职能的，包含开发人员、测试人员、设计师和其他相关角色。这种结构有助于团队快速做出决策并高效协作。 客户参与：客户（或其代表）是敏捷团队的重要成员，持续提供反馈，确保开发出的产品符合期望。 用户故事和任务管理：需求通常被分解为用户故事（User Stories），每个故事描述了用户的某种需求或功能。团队根据用户故事制定任务并进行开发。 看板和任务板：敏捷团队常使用看板（Kanban）或任务板（Task Board）来跟踪工作进度，确保所有任务按时完成。 常见的敏捷开发框架 Scrum：一种广泛使用的敏捷框架，强调固定长度的冲刺、每日站会、冲刺评审和回顾，以及产品负责人（Product Owner）和 Scrum Master 的角色。 看板（Kanban）：一种强调持续交付和流程优化的敏捷方法，通过可视化工作流程和限制在制品（WIP）来提高团队效率。 极限编程（XP, Extreme Programming）：一种强调工程实践的敏捷方法，重点包括测试驱动开发（TDD）、结对编程、持续集成等。 敏捷开发的优点 快速交付：通过短周期的迭代，敏捷开发能够更快地交付可用的软件产品。 更高的灵活性：敏捷开发能够快速响应需求变化，适应市场和客户的动态需求。 提高客户满意度：通过持续交付和客户参与，敏捷开发能够更好地满足客户需求。 持续改进：团队通过定期反思和回顾，不断优化开发流程和产品质量。 敏捷开发的挑战 文化转变：组织需要适应从传统瀑布式开发向敏捷开发的文化转变，这可能需要时间和努力。 需求管理：在敏捷开发中，需求管理可能变得复杂，特别是在面对频繁变化的情况下。 团队协作：敏捷开发依赖于团队的高效协作，任何沟通不畅或角色不明确都会影响项目进度。","categories":["2.语言","结构算法"]},{"title":"最小二乘法","path":"/2024/01/30/2-语言-结构算法-最小二乘法/","content":"最小二乘法（又称最小平方法）是一种广泛应用于数据分析和统计推断的技术。它的核心思想是通过最小化数据点与拟合函数之间的误差的平方和，来寻找数据的最佳匹配。换句话说，最小二乘法能够有效地帮助们找到一个函数，使得该函数与给定数据点的距离尽可能小。这种方法不仅适用于简单的线性回归，也能够扩展应用于多种形式的曲线拟合。 假设已知有 N 个点，设这条直线方程为： y a·x + b 其中，a 和 b 的计算公式如下： 利用最小二乘法，们可以迅速估计出未知的数据值，并确保这些估计值与实际观测值之间的误差的平方和达到最小。例如，考虑们拥有一组观测点，这些点可能代表某种物理现象或实验结果。通过应用最小二乘法，们可以得到符合这些点趋势的一条直线，这条线能有效总结和描述这些观测数据。 假设们有 N 个数据点，这些数据点可能代表多种情况，比如一组学生的考试成绩和学习时间。们的目标是拟合一条直线，这条直线可以帮助们理解学习时间与考试成绩之间的关系。该直线可以用以下数学表达式表示： [ y a \\cdot x + b ] 这里的 ( y ) 表示考试成绩，( x ) 表示学习时间， ( a ) 是斜率，反映了学习时间每增加一个单位，考试成绩的变化量；而 ( b ) 则是截距，表示当学习时间为零时，预计的考试成绩。 为了计算这两个参数 ( a ) 和 ( b )，们需要使用以下公式： 斜率 ( a ) 的计算公式斜率 ( a ) 的计算公式为： [ a \\frac{N \\cdot \\Sigma (x_i \\cdot y_i) - \\Sigma x_i \\cdot \\Sigma y_i}{N \\cdot \\Sigma (x_i^2) - (\\Sigma x_i)^2} ] 在这个公式中： ( \\Sigma (x_i \\cdot y_i) ) 是所有数据点的 ( x ) 和 ( y ) 值乘积的总和。 ( \\Sigma x_i ) 是所有 ( x ) 值的总和。 ( \\Sigma y_i ) 是所有 ( y ) 值的总和。 ( \\Sigma (x_i^2) ) 是所有 ( x ) 值的平方的总和。 例如，假设们有以下学习时间（小时）和相应考试成绩（分数）的数据点： 学习时间 (x) 考试成绩 (y) 1 60 2 70 3 75 4 80 5 90 在这个例子中，通过计算相关的求和，可以代入公式计算出斜率 ( a )。 截距 ( b ) 的计算公式截距 ( b ) 的计算公式为： [ b \\frac{\\Sigma (x_i^2) \\cdot \\Sigma y_i - \\Sigma x_i \\cdot \\Sigma (x_i \\cdot y_i)}{N \\cdot \\Sigma (x_i^2) - (\\Sigma x_i)^2} ] 这一公式同样依赖于之前提到的求和项，目的是找出当学习时间为零时，考生的期望成绩。通过同样的例子，们可以通过插入数据计算出截距 ( b )。 这些公式提供了一种有效的方法来量化变量之间的线性关系。对于公式推导的详细过程，这里不再赘述，网上有许多资源，如统计和机器学习教材，提供了相关解释和示例代码，方便读者进一步查阅。通过实践和示例，将能够更好地理解线性回归的基本概念及其应用。 算法代码以下是实现最小二乘法进行直线拟合的核心代码： //-------------------------------------------------------------//功能 : 最小二乘法直线拟合 y = a·x + b， 计算系数a 和 b//参数 : x -- 辐照度的数组// y -- 功率的数组// num -- 数组包含的元素个数，x[]和y[]的元素个数必须相等//返回 : 拟合计算成功返回true, 拟合计算失败返回false//-------------------------------------------------------------bool leastSquareLinearFit(float x[], float y[], const int num, float a, float b) float sum_x2 = 0.0; float sum_y = 0.0; float sum_x = 0.0; float sum_xy = 0.0; try for (int i = 0; i num; ++i) sum_x2 += x[i] * x[i]; sum_y += y[i]; sum_x += x[i]; sum_xy += x[i] * y[i]; catch (...) return false; a = (num * sum_xy - sum_x * sum_y) / (num * sum_x2 - sum_x * sum_x); b = (sum_x2 * sum_y - sum_x * sum_xy) / (num * sum_x2 - sum_x * sum_x); return true; 数据样本在进行拟合计算时，们可以使用以下示例数据： x: 表示辐照度的浮点数数组 float x[96] = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.46667,11.4667, 31.6, 52.7333, 80.3333, 116.333, 156.6, 199.4, 242.2, 283.4, 329.2, 379.333, 431.333,482.6, 541, 594.4, 643.533, 692.133, 736.267, 772.667, 810.133, 841.867, 868.2, 892.4, 917.667,939.8, 954.667, 969, 976.8, 983.4, 987.467, 994.933, 1023.67, 875.2, 873.933, 758.8, 678.2,515.867, 782.533, 908.8, 779.2, 831.4, 645.533, 734.067, 679.533, 610.267, 565.067, 512.467,462, 405.2, 354.133, 302, 247.8, 191.533, 140, 94.2667, 57.5333, 25.9333, 4, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0; y: 表示功率的浮点数数组 float y[96] = 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595,0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595,0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 1.785, 2.57833, 3.927, 5.79233, 7.379, 9.48133,11.1473, 12.4167, 13.6627, 16.193701, 18.248699, 19.042, 19.042, 19.105301, 16.6383,17.240999, 14.631, 11.8217, 11.663, 12.155, 15.488, 21.859301, 19.32, 19.042, 19.6133, 21.105,22.9937, 20.827299, 23.858299, 23.0333, 19.2883, 15.6937, 21.5893, 23.802999, 20.518299,21.5893, 17.907301, 17.971001, 17.574301, 16.781, 15.5513, 12.3773, 10.2747, 8.60867,6.86333, 5.39567, 3.88767, 2.856, 2.142, 2.142, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952,0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952; 计算结果在这个过程中，通过调用 leastSquareLinearFit 函数，们可以计算出最终结果： 斜率 ( a ) 计算结果为 0.0215136 截距 ( b ) 计算结果为 0.608488 这些结果显示了辐照度变化与功率之间的关系，为后续数据分析奠定了基础。","categories":["2.语言","结构算法"]},{"title":"栈和队列","path":"/2024/01/29/2-语言-结构算法-栈和队列/","content":"栈（stack）栈是限定仅在表的一端进行插入或删除操作的线性表。们把允许插入和删除操作的一端称为栈顶（top），另一端称为栈底（bottom）。不含任何数据元素的栈称为空栈。栈又称为”后进先出（Last In First Out，简称 LIFO）的线性表”，简称为 LIFO 结构。 栈的插入操作，称为进栈入栈压栈。栈的删除操作，称为出栈弹栈。 栈的顺序存储结构及实现 定义 typedef int data_t; //定义栈中数据元素的数据类型typedef struct\tdate_t *data; //用指针指向栈的存储空间\tint maxlen; //当前栈的最大元素个数\tint top; //指向栈顶位置（数组下标）的变量seqstack_t; //顺序栈类型定义 创建栈 seqstack_t *CreateEmptyStack(int max_len)\tseqstack_t *stack;\tstack = (seqstack_t *)malloc(sizeof(seqstack_t));\tstack-data = (data_t *)malloc(sizeof(data_t)*max_len);\tstack-top = -1;\tstack-max_len = max_len;\treturn stack; 摧毁一个栈 void DestroyStack(seqstack_t *stack)\tif(stack != NULL) if(stack-data != NULL) free(stack-data); free(stack); 清空一个栈 void ClearStack(seqstack_t *stack)\tif(stack != NULL) stack-top = -1; 判断栈是否为空 int EmptyStack(seqstack_t *stack)\tif(stack == NULL) return -1;\treturn(stack-top == -1 ? 1 : 0); 5、判断栈是否为满 int FullStack(seqstack_t *stack)\tif(stack == NULL) return -1;\treturn(stack-top == (stack-max_len - 1) ? 1 : 0); d 6、进栈 int PushStack(seqstack_t *stack ,data_t x)\tif(FullStack(stack)) return -1;\telse stack-top++; stack-data[stack-top] = x; return 0; 7、出栈 int PopStack(seqstack_t *stack,data_t *x)\tif(EmptySqstack(stack)) return -1;\telse *x = stack-data[stack-top]; stack-top--; return 0; 8、取栈顶元素 int GetTop(seqstack_t *stack,data_t *x)\tif(EmptyStack(stack)) return -1;\telse *x = stack-data[stack-top];\treturn 0; 栈的链式存储结构及实现若是栈中元素的数目变化范围较大或不清楚栈元素的数目，就应该考虑使用链式存储结构。人们将用链式存储结构表示的栈称作”链栈”。链栈通常用一个无头结点的单链表表示。插入操作和删除操作均在链表头部进行，链表尾部就是栈底，栈顶指针就是头指针。 定义 typedef int data_t;typedef struct node_t\tdata_t data; //数据域\tstruct node_t *next; //链接指针域linkstack_t; //链栈类型定义 创建空栈： linkstack_t *CreateLinkstack()\tlinkstack_t *top;\ttop = (linkstack_t *)malloc(sizeof(linkstack_t));\ttop-next = NULL;\treturn top; 判断是否为空栈： int EmptyStack(linkstack_t *top)\treturn (top-next == NULL ? 1 : 0); 入栈 void PushStack(linkstack_t *top,data_t x)\tlinkstack_t *p;\tp = (linkstack_t *)malloc(sizeof(linkstack_t));\tp-data = x;\tp-next = top-next;\ttop-next = p;\treturn; 出栈 int PopStack(linkstack_t stack,data_t *x)\tif(stack-next == NULL || stack == NULL) return -1;\tlinkstack_t p;\tp = stack-next;\tstack-next = p-next;\tif(x != NULL) *x = p-data;\tfree(p);\treturn 0; linkstack#include stdio.h#include stdlib.h#include linkstack.hlinkstack_t *CreateEmptyLinkstack()\tlinkstack_t *s;\ts = (linkstack_t *)malloc(sizeof(linkstack_t));\ts-next = NULL;\treturn s;void DestroyLinkstack(linkstack_t *stack)\tif (stack) /* clear the stack linked list */ ClearLinkstack(stack); /* free the stack header */ free(stack);\tint EmptyLinkstack(linkstack_t *stack)\tif (stack) return ((NULL == stack-next) ? 1 : 0); else return -1;\tvoid ClearLinkstack(linkstack_t *stack)\tlinkstack_t *node; /* node to be removed */\tif (!stack) return;\twhile ( NULL != stack-next ) /* disconnect the one to be removed */ node = stack-next; stack-next = node-next; free(node); return;int PushStack(linkstack_t *stack, data_t x)\tlinkstack_t *node; /* node to be inserted */\tif (!stack) return -1;\tnode = (linkstack_t *)malloc(sizeof(linkstack_t));\tif (NULL == node) return -1; node-data = x;\t/* insert from the head of the link list * its cheaper to push from the head of the single-linked * list. */\tnode-next = stack-next;\tstack-next = node;\treturn 0;int PopStack(linkstack_t *stack, data_t *data)\tlinkstack_t *node; /* node to be removed */ if (!stack) return -1;\tif (!(stack-next)) return -1; /* stack is empty */\t/* pop from the head of the list */\tnode = stack-next;\tstack-next = node-next;\tif (data) *data = node-data; /* now we can free the node safely */\tfree(node); return 0;int GetTop(linkstack_t *stack, data_t *data)\tif (!stack) return -1;\tif (!(stack-next)) return -1; /* stack is empty */ if (data) *data = stack-next-data; return 0;void\tVisitStack(linkstack_t *stack)\tlinkstack_t *node; /* node to be iterated */ if (!stack) return;\t/* print from the base to the top */\tprintf(stack = );\tif (stack-next) /* list is not empty */ node = stack-next; while (NULL != node) printf(%d,, node-data); node = node-next; printf(\\b ); else printf( ); 栈的应用递归递归：函数在自身的函数体内直接或间接地调用自身。 示例：递归法求斐波那契数列 int Fbi(int i) if(i2) return i==0?0:1;\treturn Fbi(i-1)+Fbi(i-2);int main() int i;\tfor(i=0;i40;i++) printf(%d\\t,Fbi(i));\tprintf( );\treturn 0; 要实现递归，必要的两个条件是递归出口和递归逻辑。在示例程序中，if(i2)就是递归出口，而 Fbi(i-1)+Fbi(i-2)就是递归逻辑。对比递归代码和非递归（迭代）代码，们可以看出递归和迭代的区别：迭代使用循环结构，而递归使用分支结构 在某些程序中，递归能使得程序结构简洁清晰，容易理解。但是大量的调用递归函数会建立许多该函数的副本，需要大量的内存存储空间。而迭代法则无需大量的存储空间。 要想实现递归，们需要明白递归的过程本质上是函数返回顺序是其调用顺序的逆序，即：先行调用的函数会在后面获得返回值。这种先行存储数据，并在之后逆序恢复得到数据的过程，显然很符合栈这种数据结构。因此，编译器使用栈来实现函数的递归。 在调用阶段，对于每层递归，函数的局部变量、参数、返回地址都被压入栈中，再去调用下次递归。在返回阶段，依次弹出位于栈顶的函数，获得计算结果。这也是为什么需要”递归出口”的原因，递归出口可以看做是从压栈到弹栈的状态转变因素。 后缀（逆波兰）表示法中缀表达式，即运算符（此处特指算数运算符）在操作数中间。9+(3-1)*3+10/2 后缀表示法，也称为逆波兰表示法，即运算符在两个操作数之后出现 9 3 1 - 3 * + 10 2 / + 后缀表达式的算法规则：从左到右遍历表达式，若遇到数字则进栈，遇到运算符则弹出栈顶两个元素进行运算，计算结果再次压栈，最后计算得到的结果就是最终结果。 们以 9 3 1 - 3 * + 10 2 / + 进行讲解（操作数入栈） 初始化一个空栈，此栈用于对要计算的操作数的进出及存储。 9、3、1 都是数字，因此依次入栈 接下来是-，是符号，弹出栈顶两个元素作为操作数，注意先弹出的元素在符号右侧，后弹出的元素在符号左侧，即 3 - 1，得到计算结果 2，将 2 压栈。 数字 3 进栈 后面是 *，栈顶两个元素弹栈进行运算 2 * 3，得到结果 6，再压入栈 后面是+，栈顶两个元素弹栈进行运算 9 + 6，得到结果 15，再压入栈 数字 10 和 2 进栈 后面是，栈顶两个元素弹栈进行运算 10 2，得到结果 5，再压入栈 最后一个符号是+，栈顶两个元素弹栈进行运算 15 + 5，得到结果 20 最终结果是 20，栈变为空，结束运算。 中缀表达式转化为后缀表达式的规则：从左到右遍历中缀表达式的每个数字和符号，若是数字就输出，即成为后缀表达式的一部分；若是符号则判断其与栈顶符号的优先级，是右括号或优先级低于或等于栈顶符号的则栈顶元素依次出栈并输出，直至遇到一个比其优先级低的运算符为止，并将当前符号进栈，一直到最终输出后缀表达式为止。 们以 9+(3-1)*3+10/2------9 3 1 - 3 * + 10 2 / + 进行讲解（运算符入栈） 初始化一个空栈，用于对符号进出栈使用。 第一个数字是 9，输出 9。后面的符号+入栈。 第三个字符是（，依然是符号，因其是左括号还未配对，故进栈。 第四个字符是数字 3，输出，此时表达式为 9 3，接着符号-进栈。 接下来是数字 1，输出，此时表达式为 9 3 1，后面是符号），此时们需要把（之前的所有元素都出栈，直至输出（为止。此时总的表达式是 9 3 1 -。 紧接着是符号 *，因为此时的栈顶符号是+，优先级低于 *，因此不输出，* 进栈。紧接着是数字 3，输出，总表达式为 9 3 1 – 3. 之后是符号+，此时栈顶元素是 *，比+优先级高，因此栈中元素出栈并输出（因为没有比+更低优先级的符号，所以全部出栈），总输出表达式为 9 3 1 – 3 * +。然后将这个符号+进栈。 紧接着输出数字 10，总表达式为 9 3 1 – 3 * + 10。之后是符号 /，所以 / 进栈。 最后一个数字为 2，此时总表达式为 9 3 1 – 3 * + 10 2。 因已到最后，所以将栈中符号全部出栈。最终获得的后缀表达式为 9 3 1 – 3 * + 10 2 / +。 队列队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。队列是一种先进先出（First In First Out）的线性表，简称 FIFO。允许插入操作的一端称为队尾，允许删除操作的一端称为队头。 队列作为特殊的线性表，有顺序队列和链式队列两种形式。 队列的顺序存储结构及实现如果们要建立元素个数为 n 的队列，则需要建立一个数组长度不小于 n 的数组，数组下标为 0 的为队头，当最大下标的为队尾。若有元素要入队，则只需将其存储在第 n+1 个位置即可。而若想出队，则删除了下标为 0 的元素后，所有在其后的元素都需要向前移动一格，即保持下标为 0 的元素为队头。但这样做显然浪费了大量时间。 解决该问题的方法就是不再限制下标为 0 的元素为队头，每次出队后，队头自动变成当前数组下标最小的元素即可。这样就无需所有元素向前移动。但是，若如此做，则会造成大量的已出队的元素的存储空间浪费。而且，若此时入队元素已经大于 n，则们需要更大的存储空间才行，但队头位置有大量空间未利用，空间浪费严重。 解决以上问题的方法就是如果后面满了，则们就从头开始，也就是将队列做成头尾相接的循环。们把这种头尾相接的顺序存储结构的队列称为循环队列。 在循环队列中，当队列为空时，有 front=rear，而当所有队列空间全占满时，也有 front=rear。为了区别这两种情况，规定循环队列最多只能有 MaxSize-1 个队列元素，当循环队列中只剩下一个空存储单元时，队列就已经满了。因此，队列判空的条件时 front=rear，而队列判满的条件时 front=（rear+1）%MaxSize。 队头指针 front，指向队头元素的位置的前一个位置。即指向预留的位置； 队尾指针 rear，指向队尾元素的位置； 入队： rear = (rear + 1) % N (maxsize)，然后元素放入队尾 rear 所指向的位置； 出队： front = (front + 1) % N，然后取出队头指针 front 所指向的元素； 队空： front == rear; 队满： (rear + 1) % N == front, N 为数组的元素个数； 为了区别空队和满队，满队元素个数比数组元素个数少一个。 这样，们就需要两个指示其队头（front）和队尾（rear）的下标变量。 #define N 64 //队列中数据元素的数据类型typedef int data_t;typedef struct\tdata_t data[N]; //用数组作为队列的储存空间\tint front,rear; //指示队头位置和队尾位置的指针sequeue_t; 当 (rear+1)%QueueSize==front 时，此时队尾的下个位置就是队头，则该队列为满队列。注意 rear 的位置不是队尾元素的位置，而是队尾元素的下一个位置，即当队列满时，队列中还有一个空闲存储空间，但们规定该状态下就是满队列。 那么，定义好队列的的队头和队尾位置，们来考虑怎样计算队列长度。 当 rearfront 时，表示队尾在队头右边，此时队列长度为 rear-front； 当 rearfront 时，表示队尾在队友左边，此时计算队列长度应分成两部分，即 rear 一部分，QueueSize-front 一部分，总体长度为 rear-front+QueueSize。 通用计算队列长度的公式是 length=(rear-front+QueueSize)%QueueSize 创建空队列 sequeue_t *CreateEmptySequeue()\tsequeue_t *queue;\tqueue = (sequeue_t *)malloc(sizeof(sequeue_t));\tif (NULL == queue) return NULL;\tqueue-front = queue-rear = 0;\treturn queue; 摧毁一个队列 voidDestroySequeue(sequeue_t *queue)\tif (NULL != queue) free(queue); 判断一个队列是否为空 intEmptySequeue(sequeue_t *queue)\tif (NULL == queue) return-1;\treturn (queue-front == queue-rear ? 1 : 0); 判断一个队列是否为满 intFullSequeue(sequeue_t *queue)\tif (NULL == queue) return-1;\treturn ((queue-rear + 1) % N == queue-front ? 1 : 0); 清空一个队列 voidClearSequeue(sequeue_t *queue)\tif (NULL == queue) return;\tqueue-front = queue-rear = 0;\treturn; 入队 intEnQueue(sequeue_t *queue, data_t x)\tif (NULL == queue) return - 1;\tif (1 == FullSequeue(queue)) return-1; /* full */\tqueue-rear = (queue-rear + 1) % N;\tqueue-data[queue-rear] = x;\treturn 0; 出队 intDeQueue(sequeue_t *queue, data_t *x)\tif (NULL == queue) return-1;\tif (1 == EmptySequeue(queue)) return-1; /* empty */\tqueue-front = (queue-front + 1) % N;\tif (NULL != x) *x = queue-data[queue-front]; return 0; 队列的链式存储结构及实现队列的链式存储结构本质上是从单链表演化而来的。将单链表改造成链式队列，如果将头结点做为队头，最后一个节点做为队尾，则该队列的出队操作方便，而入队操作较慢；反之，如果将头结点做为队尾，最后一个节点做为队头，则该队列的入队操作方便，而出队操作较慢。那么，能否将单链表稍加改进，使得该链式队列的入队操作和出队操作一样方便呢？ 答案是可以的，只需要改进头结点。将”头结点存储一个 next 指针”改为”头结点存储两个指针 front 和 rear”，front 指针指向队头，rear 指针指向队尾。这样们进行出队入队操作时，只需要访问这两个指针就能快速地找到队头队尾。 队列的链式存储结构定义，将单链表的头结点稍加改造 typedef int data_t;typedef struct node_t//定义单链表\tdata_t data;\tstruct node_t *next;linknode_t, *linklist_t;typedef struct//定义链式队列 linklist_t front, rear;linkqueue_t; 创建空队列 linkqueue_t *CreateEmptyLinkqueue()\tlinkqueue_t *lp = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif(lp == NULL) return;\tlp-front = lp-rear = (linknode_t *)malloc(sizeof(linknode_t));\tif(lp-front == NULL) return;\tlp-front-next = NULL;\treturn lp; 摧毁一个链队列 void DestroyLinkqueue(linkqueue_t *queue)\tif(queue != NULL) ClearLinkqueue(queue); free(queue); 清空一个链队列 void ClearLinkqueue(linkqueue_t *queue)\tlinknode_t *qnode;\twhile(q-front) qnode = queue-front; queue-front= qnode-next; free(qnode); queue-rear = NULL; 判定链式队列是否为空 由于单链表的属性，链式队列几乎不会出现”队列已满”的情况，因此不考虑判定链式队列是否已满的操作。判定链式队列是否为空，只需要判定队列的 front 指针是否为空即可。 int EmptyLinkqueue(linkqueue_t *queue)\tif(queue == NULL) return-1;\treturn(queue-front == queue-rear ? 1 : 0); 队列的链式存储结构——入队操作 入队操作其实就是在链表尾部插入节点。（需要判定插入时链表是否为空，如果链表为空，则 front 和 rear 两个指针都需要操作）新来的数据节点附在当前 rear 节点之后，并将 rear 节点指向该节点即可。 int EnQueue(linkqueue_t *queue,data_t x)\tlinknode_t *node_new;\tif(queue == NULL) return-1;\tnode_new = (linknode_t *)malloc(sizeof(linknode_t));\tif(node_new == NULL) return-1;\tnode_new-data = x;\tnode_new-next = NULL;\tif(queue-front-next == NULL) queue-front-next = queue-rear = node_new; else queue-rear-next = node_new; queue-rear = node_new; return 0; 队列的链式存储结构——出队操作 出队操作就是将链表的头结点的后继节点出队，并将其之后的节点设置为头结点的后继节点。若链表除头结点外仅剩一个元素，则需将 rear 指向头结点。 int DeQueue(linkqueue_t *queue,data_t *x)\tlinknode_t *node_remove;\tif(queue == NULL || queue-front-next == NULL) return-1;\tnode_remove = queue-front-next;\tqueue-front-next = node_remove-next;\tif(x != NULL) *x = node_remove-data;\tfree(node_remove);\treturn 0; 链式队列代码typedef int data_t;typedef struct node_t\tdata_t data;\tstruct node_t *next; linknode_t, *linklist_t;typedef struct\tlinklist_t front, rear; linkqueue_t;linkqueue_t *CreateEmptyLinkqueue()//创建空队列\tlinkqueue_t *queue;\tqueue = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif (NULL == queue) perror(Create Empty LinkQueue Error); return NULL; queue-rear = queue-front = NULL;\treturn queue;int ClearLinkqueue(linkqueue_t *queue)//清空队列\tlinknode_t *node_remove;\tnode_remove = queue-front;\twhile (NULL != node_remove) queue-front = queue-front-next; free (node_remove); node_remove = queue-front; queue-rear = NULL;\treturn OK;int DestroyLinkqueue(linkqueue_t *queue)//销毁队列\tif (queue) ClearLinkqueue(queue); free(queue); return OK; else printf(DestroyLinkqueue Error ); return ERROR;\tint EmptyLinkqueue(linkqueue_t *queue)//判定队列是否为空\tif (!queue) printf(EmptyLinkqueue Error ); return -1; return queue-front == NULL ? OK : ERROR;int EnQueue(linkqueue_t *queue, data_t x)//入队\tlinknode_t *node_new;\tif (!queue) printf(EnQueue Error ); return ERROR; node_new = (linknode_t *)malloc(sizeof(linknode_t));\tnode_new-data = x;\tnode_new-next = NULL;\tif(EmptyLinkqueue(queue)==OK) queue-front = queue-rear = node_new; else queue-rear-next = node_new; queue-rear = node_new; return OK;int DeQueue(linkqueue_t *queue, data_t *x)//出队\tlinknode_t *node_remove;\tif(!queue) printf(DeQueue Error ); return ERROR; if(EmptyLinkqueue(queue)==OK) printf(queue is Empty ); return ERROR; node_remove = queue-front;\tqueue-front = node_remove-next;\tif (NULL == queue-front) queue-rear = NULL;\tif(x) *x = node_remove-data; free(node_remove);\treturn OK;int VisitQueue(linkqueue_t *queue)//遍历队列\tlinknode_t *node;\tprintf(aueue = );\tnode = queue-front;\tif (NULL == node) printf( ); return OK; while (NULL != node) printf(%d,, node-data); node = node-next; printf(\\b );\treturn OK; 球钟问题球钟是一个利用球的移动来记录时间的简单装置。它有三个可以容纳若干个球的指示器：分钟指示器，五分钟指示器，小时指示器。若分钟指示器中有 2 个球，五分钟指示器中有 6 个球，小时指示器中有 5 个球，则时间为 5:32。每过一分钟，球钟就会从球队列的队首取出一个球放入分钟指示器，分钟指示器最多可容纳 4 个球。当放入第五个球时，在分钟指示器的 4 个球就会按照他们被放入时的相反顺序加入球队列的队尾。而第五个球就会进入五分钟指示器。按此类推，五分钟指示器最多可放 11 个球，小时指示器最多可放 11 个球。 当小时指示器放入第 12 个球时，原来的 11 个球按照他们被放入时的相反顺序加入球队列的队尾，然后第 12 个球也回到队尾。这时，三个指示器均为空，回到初始状态，从而形成一个循环。因此，该球钟表示时间的范围是从 0：00 到 11：59。 思考：球钟需要多少个球，才能实现计时范围为 0：00 到 11：59？ 提示：使用 3 个栈来分别表示 1min 指示器、5min 指示器和 1h 指示器，使用一个队列来存储小球 #include stdio.h#include stdlib.h#define MAXSIZE_1 5#define MAXSIZE_2 12#define MAXSIZE_ball 28#define OK 1#define ERROR 0typedef int data_t;typedef struct //一分钟的顺序栈\tdata_t data[MAXSIZE_1];\tint top;one_min_t;typedef struct //五分钟与一小时的顺序栈\tdata_t data[MAXSIZE_2];\tint top;five_min_t;typedef struct //所有小球的存放队列\tdata_t data[MAXSIZE_ball];\tint front;\tint rear;SqQueue;int main() int i; data_t *the_ball; one_min_t *one_min; five_min_t *five_min,*one_hour; SqQueue *ball; one_min = CreateEmptyStack(); five_min = CreateEmptyStack(); one_hour = CreateEmptyStack(); ball = CreateEmptyQueue(); for(i = 0; i MAXSIZE_ball; i++) EnQueue(ball,i+1); DeQueue(ball,the_ball); if(0==PushStack(one_min,the_ball)) for(i=0; i4; i++) PopStack(one_min,the_ball); EnQueue(ball,the_ball); return 0;int PushStack(SqStack *s,data_t e)//压栈\tif(s-top==MAXSIZE-1) printf(Stack is Full ); return ERROR; s-top++;\ts-data[s-top]=e;\treturn OK;int PopStack(SqStack *s,data_t *e)//弹栈\tif(s-top==-1) printf(Stack is Empty ); return ERROR; *e=s-data[s-top];\ts-top--;\treturn OK;SqStack* CreateEmptyStack()//创建栈 SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) printf(CreateEmptyStack Error ); exit(0); stack-top=-1; return stack;int EmptyStack(SqStack *s)//判断栈是否是空栈 return -1==s-top?OK:ERROR;int FullStack(SqStack *s)//判断栈是否是满栈 return MAXSIZE-1==s-top?OK:ERROR;int ClearStack(SqStack *s)//清空栈内元素 s-top=-1; return OK;SqQueue *CreateEmptyQueue()//创建队列\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL) printf(CreateEmptyQueue Error ); return NULL; sq-front=0;\tsq-rear=0;\treturn sq;int EmptyQueue(SqQueue *Q)//判断队是否为空\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if(Q-rear==Q-front) return OK;\telse return ERROR;int FullQueue(SqQueue *Q)//判断队是否已满\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if((Q-rear+1)%MAXSIZE==Q-front) return OK;\telse return ERROR;int EnQueue(SqQueue *Q,data_t e)//元素e入队\tif(FullQueue(Q)==OK) printf(Queue is Full ); return ERROR; Q-data[Q-rear]=e;\tQ-rear=(Q-rear+1)%MAXSIZE;\treturn OK;int DeQueue(SqQueue *Q,data_t *e)//元素出队，出队元素存储在e中\tif(EmptyQueue(Q)==OK) printf(Queue is Empty ); return ERROR; *e=Q-data[Q-front];\tQ-front=(Q-front+1)%MAXSIZE;\treturn OK; #includestdio.h#includestdlib.h#define ONEMIN 5#define FIVEMIN 12#define ONEHOUR 12#define BALLQUE 28#define OK 1#define ERROR 0typedef int data_t;typedef struct\tdata_t *data;\tint top;//栈顶\tint maxlen;SqStack;typedef struct\tdata_t *data;\tint front;//队头位置\tint rear;//队尾位置\tint maxlen;SqQueue;/**************************队列部分**************************/SqQueue *CreateEmptyQueue(int length)//创建队列\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL) printf(CreateEmptyQueue Error ); return NULL; sq-data = (data_t*)malloc(sizeof(data_t)*length);\tsq-maxlen=length;\tsq-front=0;\tsq-rear=0;\treturn sq;int EmptyQueue(SqQueue *Q)//判断队是否为空\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if(Q-rear==Q-front) return OK;\telse return ERROR;int FullQueue(SqQueue *Q)//判断队是否已满\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if((Q-rear+1)%Q-maxlen==Q-front) return OK;\telse return ERROR;int EnQueue(SqQueue *Q,data_t e)\tif(FullQueue(Q)==OK) printf(Queue is Full ); return ERROR; Q-data[Q-rear]=e;\tQ-rear=(Q-rear+1)%Q-maxlen;\treturn OK;int DeQueue(SqQueue *Q,data_t *e)\tif(EmptyQueue(Q)==OK) printf(Queue is Empty ); return ERROR; *e=Q-data[Q-front];\tQ-front=(Q-front+1)%Q-maxlen;\treturn OK;/**************************栈部分**************************/int PushStack(SqStack *s,data_t e)//压栈\tif(s-top==s-maxlen-1) printf(Stack is Full ); return ERROR; s-top++;\ts-data[s-top]=e;\treturn OK;data_t PopStack(SqStack *s)//弹栈\tif(s-top==-1) printf(Stack is Empty ); return ERROR; data_t e=s-data[s-top];\ts-top--;\treturn e;SqStack* CreateEmptyStack(int length)//创建栈 SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) printf(CreateEmptyStack Error ); exit(0); stack-data = (data_t*)malloc(sizeof(data_t)*length);\tstack-maxlen=length; stack-top=-1; return stack;int EmptyStack(SqStack *s)//判断栈是否是空栈 return -1==s-top?OK:ERROR;int FullStack(SqStack *s)//判断栈是否是满栈 return s-maxlen-1==s-top?OK:ERROR;void ShowTime(SqStack *one_min,SqStack *five_min,SqStack *one_hour)//计算球钟内3个栈的小球所代表的时间并打印\tint hour,minute;\tminute=(one_min-top+1)+(five_min-top+1)*5;\thour=one_hour-top+1;\tprintf(time: %d:%d ,hour,minute);int main()\tSqStack *one_min = CreateEmptyStack(ONEMIN);//1分钟栈\tSqStack *five_min = CreateEmptyStack(FIVEMIN);//5分钟栈\tSqStack *one_hour = CreateEmptyStack(ONEHOUR);//1小时栈\tSqQueue *ballque = CreateEmptyQueue(BALLQUE);//球队列\tint i;\tdata_t data;\tfor(i=1;i=ballque-maxlen-1;i++) EnQueue(ballque,i); while(1) DeQueue(ballque,data);//出队一个球 PushStack(one_min,data);//压入1分钟栈中 if(FullStack(one_min)==OK)//如果1分钟栈已满 for(i=0;ione_min-maxlen-1;i++)//弹出4个元素到队列中 EnQueue(ballque,PopStack(one_min)); PushStack(five_min,PopStack(one_min));//第5个压入5分钟栈 if(FullStack(five_min)==OK)//如果5分钟栈已满 for(i=0;ifive_min-maxlen-1;i++)//弹出11个元素到队列中 EnQueue(ballque,PopStack(five_min)); PushStack(one_hour,PopStack(five_min));//第12个元素压入1小时栈 if(FullStack(one_hour)==OK)//如果1小时栈已满 for(i=0;ione_hour-maxlen;i++)//弹出12个元素到队列中 EnQueue(ballque,PopStack(one_hour)); ShowTime(one_min,five_min,one_hour);//打印时间 sleep(1);//延时1秒 return 0; 两个栈实现队列队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead，分别完成在队列尾部插入元素和在队列头部删除节点的功能。 template typename Tclass CQueuepublic: CQueue(void); ~CQueue(void); void appendTail(const T element); T deleteHead();private: stackT stack1; stackT stack2;; 思路：栈是先进后出，而队列是先进先出的，而要用栈实现队列的话，两步操作如下： 进队列：第一个栈 stack1 专门用来压入数据； 出队列：要把队列头部元素输出，而这个头部会在 stack1 中的底部，因此们需要利用辅助栈 stack2 ，把 stack1 元素依次压入 stack2，这样原来 stack1 中的底部元素变成 stack2 的栈顶，而这就是队列的 head，将之输出即可。 上面分析是针对 stack2 空的情况，若 stack2 非空，则要继续把 stack2 中元素依次 pop 出来。 //进队列template typename T void CQueueT::appendTail(const T element) stack1.push(element);//出队列template typename T T CQueueT::deleteHead() if (stack2.empty()) //若stack2是空的，则把stack1的元素copy过来 while (!stack1.empty()) T data = stack1.top(); stack1.pop(); stack2.push(data); if (stack2.empty()) throw new exception(queue is empty); //取stack2栈顶元素，即队列的head T head = stack2.top(); stack2.pop(); return head; 数组实现队列 //数组实现队列template typename Tclass CArrayQueuepublic: CArrayQueue(void); ~CArrayQueue(void); void appendTail(const T element); T deleteHead();private: const static int nSize; T Array[10]; int nHead; int nTail;;template typename T const int CArrayQueueT:: nSize = 10;template typename T CArrayQueueT::CArrayQueue(void) this-nHead = 0; this-nTail = -1;template typename T CArrayQueueT::~CArrayQueue(void) this-nHead = 0; this-nTail = -1;//进队列template typename T void CArrayQueueT::appendTail(const T element) if (nTail - nHead = nSize) throw new exception(Queue is full!); Array[(++nTail) % nSize] = element; if (nHead / nSize 0 ) nTail -= nSize; nHead -= nSize; //出队列template typename T T CArrayQueueT::deleteHead() T Head = Array[nHead++]; return Head;","categories":["2.语言","结构算法"]},{"title":"滤波算法","path":"/2024/01/26/2-语言-结构算法-滤波算法/","content":"在进行数据收集的过程中，难免会遭遇到随机误差。这种误差源于随机干扰，其特征是在相同条件下测量同一物理量时，误差的大小和符号表现出无规律的变化，难以预测。例如，在监测温度时，某次测量记录 为 22.5°C，下一次则可能 是 22.7°C，后又回 到 22.4°C，这种波动看似偶然，但在多次测量后，可以发现其结果却能够符合某种统计规律。为了减少随机干扰导致的这些误差，硬件层面可以采用滤波技术，软件层面则可以利用特定的软件算法实现数字滤波。 数字滤波算法是系统测控算法中非常关键的一部分，其具有极强的实时性。利用数字滤波器克服随机干扰带来的误差，具体有以下几个显著优点： 成本效益高：数字滤波不需要额外的硬件设备，仅依赖一个计算过程，因此具有很高的可靠性，同时避免了阻抗匹配问题。例如，传统的模拟滤波器可能因频率不匹配而无法有效处理某些信号，但数字滤波器能够稳定地处理那些频率极低的信号，这是模拟设备所无法做到的。 共用性强：数字滤波使用软件实现，一台系统中多条输入通道可以共享同一个滤波程序，这无疑降低了整体的系统开支。例如，在一套气象监测系统中，对于风速、气温和湿度等多个传感器数据，可以仅用一个软件算法对所有信号进行滤波，避免了为每个信号配备独立硬件的高昂成本。 灵活性：通过简单地调整滤波器的程序或运算，可以方便地改变滤波特性。对于去除低频干扰和随机信号，这种灵活性尤为重要。例如，当察觉某一测量系统受到低频噪声影响时，只需更新程序设置，就能立刻优化信号处理，确保最终结果的准确性。 常用算法多样：在实际应用中，常用的数字滤波算法包括有限幅滤波法、中值滤波法、算术平均滤波法、加权平均滤波法和滑动平均滤波法等。这些算法各有特点，例如，中值滤波法在处理含有脉冲噪声的信号时表现尤为出色，而滑动平均滤波法则适合于平滑整体趋势。 然而，也需注意个别算法在获取有效采样值时可能需要对数据进行多次采样，这在采样速度较慢的情况下，可能会影响系统的实时性。在高速实时监测的场合，这种延迟可能导致数据失真或错过重要信息。因此，选择适合的滤波算法和设计合理的采样策略是提升数据收集准确性和及时性的关键因素。 递推平均滤波（滑动平均滤波法） 递推平均滤波，也称滑动平均滤波法，是一种通过平滑数据来抑制噪声和波动的技术。它将连续的 N 个采样值视作一个固定长度的队列，其中每采样到一个新数据，就会将其放入队尾，而队首的一个旧数据悄然被丢弃。这种先进先出的处理方式确保了每次计算平均值时，队列中总是最新的 N 个数据点。 滤波的过程如下：从队列中的 N 个数据进行算术平均运算，就能得到一个新的滤波结果。通常情况下，N 值设定为 12，这代表将过去的 12 个数据值结合在一起，为当前值提供更稳定的表现。 滤波算法对周期性干扰如电磁干扰和振动噪声具有良好的抑制作用，因其可以有效地平滑系统输出，尤其适用于高频振荡系统。例如，在测量温度时，如果传感器受到风速变化的影响，使用滑动平均法就能平滑温度值，使其波动减少，便于观察真实温度趋势。 然而，这种滤波方法的灵敏度相对较低，对偶然出现的脉冲性干扰，比如瞬间的电压尖峰或机械敲击等，滤波效果不佳。这意味着如果采样数据中出现突发性干扰，滤波结果可能不会得到有效的修正，因此在面临严重脉冲干扰的环境中，滑动平均法可能并不适用。 需要注意的是，滑动平均法可能会消耗一定的 RAM，因为它需要为 N 个数据分配存储空间。此外，使用环型队列的结构可以有效地管理缓冲区，使得在不断获得新数据的同时，保持存储效率。 C 语言代码如下： #define N 12char value_buf[N];char i = 0;char filter() char count; int sum = 0; value_buf[i++] = get_ad(); // 将新的采样值存入缓冲区 if (i == N) i = 0; // 循环缓冲区 for (count = 0; count N; count++) sum += value_buf[count]; // 计算当前缓冲区的和 return (char)(sum / N); // 返回平均值 这段代码定义了一个名为 filter 的函数，实现了递推平均滤波（滑动平均滤波法）。它使用一个长度为 N（定义为 12）的缓冲区 value_buf 来存储采样值。每当调用 filter 函数时，它会获得一个新的采样值，首先将其存入缓冲区，然后计算并返回该缓冲区内所有采样值的平均值，实现数据的平滑处理。如果 i 达到 N，代码会将 i 重设为 0，从而实现一个循环缓冲区的行为。 滑动平均滤波的方式设计了一次采样的处理策略，将当前采样值与过去的若干个采样值一起进行平均，这有效地过滤了原始数据中的极端变化。因此，在实际应用中，会预先为 N 个数据分配内存空间以供存储。每次新数据的加入会伴随最旧的数据被删除，从而始终保持最新的 N 个有效数据。这种设计确保了对数据的连续更新和高效管理，非常适合处理动态变化的信号。 程序代码的简单存取结构展示了如何不断更新和计算滑动平均值，示例如下： char value_buff[N];char i=0;char filter() char count; int sum=0; value_buff[i++] = get_data(); // 读取新数据 if(i == N) i = 0; // 实现环形队列 for(count = 0; count N; count++) sum += value_buff[count]; // 累加所有数据 return (char)(sum / N); // 返回平均值 整体来看，滑动平均滤波法是有效且简单的一种数据处理方法，尤其适合需要平滑输出结果的应用场景。 中位值平均滤波法中位值平均滤波法，也被称为防脉冲干扰平均滤波法，是一种有效的信号处理技术。它旨在从一组数据中去除异常值和脉冲干扰，提取更为稳定的平均值。 原理 操作流程： 采集 N 个数据。首先，去掉这一组数据中的最大值和最小值。接着，对剩余的 N-2 个数据进行平均计算。这种方法结合了中位值滤波法的优点与算术平均滤波法的优点，降低了偶然脉冲干扰对结果的影响。 例如，如果采集到的一组数据为 [5, 4, 3, 2, 1, 4, 5, 8, 3, 7, 2, 3, 6, 7]，当 N 设为 5 时，首先去掉最大值 8 和最小值 1，剩余数据为 [5, 4, 3, 4, 3]，最后得出它们的平均值。 优点： 脉冲干扰的消除：中位值平均滤波法能够有效消除偶然出现的脉冲干扰。例如，当某个传感器受到瞬时电击或噪声影响，导致一个数据点异常高或低时，中位值的方法可以避免这一异常值对平均的影响。 抑制周期性干扰：对于周期性干扰（如电源频率干扰），中位值算法展现出良好的抑制能力，因为它只关注中心位置的数据，而忽略掉那些波动较大的极端值。 高平滑度：在高频振荡的系统中，该算法提供了较好的平滑效果，适用于信号需要稳定的应用场景，如温湿度监测。 缺点： 计算速度：与算术平均滤波法一样，中位值平均滤波的计算速度较慢。这是因为它需要对数据进行排序，而排序通常是一个计算量较大的操作，尤其是在数据量较大的情况下。 内存消耗：该方法在处理数据时可能会占用较多的 RAM。在保存和处理大量数据时，应考虑优化内存使用。 示例代码下面是应用中位值平均滤波法的 C++ 示例代码。在这些代码中，首先获取一组数据，然后进行排序，去掉最大和最小值，并计算平均值。 #define FILTER_N 5 // 定义采样数量int Filter() int i; int filter_sum = 0; int filter_max, filter_min; int filter_buf[FILTER_N]; // 进行数据采集 for(i = 0; i FILTER_N; i++) filter_buf[i] = Get_AD(); // 获取数据 delay(1); // 延时确保数据稳定 filter_max = filter_buf[0]; filter_min = filter_buf[0]; filter_sum = filter_buf[0]; // 寻找最大值和最小值 for(i = 1; i FILTER_N; i++) if(filter_buf[i] filter_max) filter_max = filter_buf[i]; if(filter_buf[i] filter_min) filter_min = filter_buf[i]; filter_sum += filter_buf[i]; // 去掉最大值和最小值后计算平均 filter_sum = filter_sum - filter_max - filter_min; return filter_sum / (FILTER_N - 2); 详细过程说明 数据采集：通过 Get_AD() 函数从传感器获取输入数据，循环执行相应的延时确保数据准确。 数据分析：首先初始化最大值和最小值为第一项数据，随后遍历所有采集的数据，以确定真正的最大和最小值。 处理结果：计算所有数据的和，然后减去最大值和最小值，最后将结果除以 N-2（有效数据点的数量）得到最终的平均值。 总结使用中位值平均滤波法可以有效地消除数据中的脉冲干扰和极端异常值，尤其适合于数据波动较大的场景。尽管计算速度较慢且可能占用较多内存，但在需要稳定输出的应用场合，使用此方法往往能够获得更为可靠的结果。 限幅滤波算法在这个算法的运作过程中，它首先计算两次相邻采样的数据差异，也就是两次数据的增量。然后，将这个增量的绝对值与预先设定的允许最大差值 ( A ) 进行比较。这样的比较决定了新数据的有效性。 具体步骤 计算增量：将最新采样值与前一次采样值相减，得到的数据称为增量。假设有两次测量温度的数据，第一次测量的温度为 20°C，第二次为 21.5°C，增量为 ( 21.5 - 20 1.5 )°C。 比较绝对值：接着，取增量的绝对值 1.5°C，判断是否超过最大允许差值 ( A )。假设设定 ( A 2 )°C，则 ( 1.5 )°C ≤ ( 2 )°C，此时可以认为本次采样有效。 选择数据：如果增量小于或等于 ( A )，新采样值被视为有效数据，被接受并作为最新的数据。如果增量大于 ( A )，那么本次数据被认为异常，系统将使用上一次的有效数据作为本次数据，以确保输出的稳定性和准确性。例如，若本次增量计算为 2.5°C，而 ( A 2 )°C，系统会选择上一次的有效数据，而非新的异常数据。 算法的程序代码如下： #define A // 允许的最大差值char data; // 上一次的数据char filter() char data_new; // 新数据变量 data_new = get_data(); // 获得新数据变量 if ((data_new - data) A || (data - data_new A)) return data; // 如果增量超出限制，返回上一次数据 else return data_new; // 否则返回新数据 应用场景限幅滤波算法特别适用于处理变化缓慢的信号，比如温度监测、物体位置追踪等场景。例如，在监控房间温度时，如果探测器读取到的温度突变，可能是由于外部环境瞬间变化引起的。通过限幅滤波，可以有效忽略这些突发的异常数据，确保系统输出的温度值反映的是环境的真实状态。 对于选取合适的最大允许差值 ( A ) 来说，这通常是非常关键的一步。它的大小因被测对象的不同而异，可能需要依赖经验数据或进行实验来确定。在实际应用中，合理设定 ( A ) 将提高算法的鲁棒性，保证数据的有效性和准确性。例如，某些环境中的温度变化通常很缓和，选取 ( A 1 )°C 可能就足够了；而在气温变化较大的地区，则可能需要设置 ( A 3° )C 或更高，以避免误判。 算术平均滤波算法算术平均滤波算法是一种简单有效的信号处理技术，其核心原理在于对连续的 N 次采样值进行计算，求得其平均值，从而减少随机干扰对信号的影响。这种方法特别适用于存在随机噪声的信号，如温度传感器的输出、电压信号或其他传感器数据。在这些情况下，信号可能会受到环境因素的波动影响而产生干扰，导致读数不稳定。 算法实现以下是该算法的基本程序代码示例，用于计算 N 次采样值的算术平均： char filter() int sum = 0; // 初始化总和变量 for (int count = 0; count N; count++) // 循环 N 次进行采样 sum += get_data(); // 累加每次采样值 delay(); // 读取下一个数据前的延迟，确保数据稳定 return (char)(sum / N); // 返回 N 次采样值的平均值 算法详解此算法中，get_data() 函数是用来获取当前采样值的。在循环中，sum 变量逐步累加这些值，而 delay() 函数则用于在每次采样之间引入必要的延时，确保信号读取的稳定性。例如，假设在测量温度，当环境温度因风速或阳光照射等因素变化时，连续采样以捕捉稳定读数尤为重要。 平滑程度与灵敏度的关系算术平均滤波算法在实际应用中，其表现与选择的 N 值有直接关系： 大 N 值：例如，当 N 取值为 32，算法会对更多的样本进行平均处理。这会导致结果变得平滑，减少短时间内的波动，但也会使系统对瞬时变化的不敏感。例如，在温度变化剧烈的环境下，大 N 值可能会导致测量响应迟缓，从而丧失对突发温度变化的及时感知。 小 N 值：相对而言，当 N 取值为 4，系统可以更快反应，灵敏度提高，能够快速捕捉到信号的变化。然而，这样会增加输出信号的波动性，可能使得测量过程中的噪声更为明显。 N 值的选择为了简化计算和提高处理速度，N 通常会选择为 2 的整数幂（例如 4、8、16、32），这样可以利用位移操作代替除法，从而提高运算效率。比如，对于 N16，可以通过右移 4 位代替除以 16 的操作，这在嵌入式系统和实时处理场景中尤其重要，因为运算速度直接影响了系统的响应能力。 通过合理设置 N 值，算术平均滤波算法能在灵敏度和平滑度之间找到一个平衡点，以适应不同的信号处理需求。 加权平均滤波算法加权平均滤波算法是为了解决算术平均滤波算法在平滑度和灵敏度之间存在的冲突而提出的一种方法。算术平均滤波在平滑数据时可能会丢失一些重要的细节，而加权平均滤波则通过赋予不同采样值不同的重要性来改善这一问题。具体来说，它的原理是对于连续 N 次采样值，分别乘以不同的加权系数，然后求出这些加权值的加和。加权系数的特点是一般采用从小到大的分配方式，以增强对后续采样值的关注，从而更有效地捕捉到数据变化的趋势。 加权系数通常是小于 1 的实数，并且它们的总和必须等于 1。这一设置确保了加权运算后的结果仍然是一个有效的采样值。例如，假设有 5 个采样值，其对应的加权系数是 0.1、0.2、0.3、0.4、0.0，那么这些系数的总和为 1.0，能够有效提升最近几次的采样在最终结果中的影响力。 加权平均数字滤波的数学模型可以表示为： [ D \\sum_{i0}^{N-1} C_i X_{N-i} ] 其中： ( D ) 为 N 个采样值的加权平均值； ( X_{N-i} ) 为第 ( N-i ) 次采样值； ( N ) 为采样次数； ( C_i ) 为加权系数。 在公式中，加权系数 ( C_i ) 显示了各个采样值在最终平均值中所占的比例。通常情况下，越靠后的采样值，其对应的加权值会越大，这种策略有助于增加新近数据在最终结果中的重要性，从而更敏感地反映采样值的变化。 加权平均滤波方法的核心在于它能够从众多信号中突出一个特定信号，同时压制其他部分的信号，从而提高对参数变化的感知能力和信号处理的效率。 以下是一个实现加权平均滤波的样例程序代码： char jq[N] = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12; // 加权系数表，存放于程序存储区char sum_jq = 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12; // 计算加权系数的总和char filter() char count; char value_buff[N]; // 存储获取到的采样值 int sum = 0; // 用于存储加权和 // 获取 N 次采样值 for (count = 0; count N; count++) value_buff[count] = get_data(); // 从外部获取数据 delay(); // 等待一定时间以稳定数据 // 计算加权和 for (count = 0; count N; count++) sum += value_buff[count] * jq[count]; // 每个采样值乘以其对应的权重 return (char)(sum / sum_jq); // 返回加权平均值 在这段代码中，jq 数组包含了加权系数，而 get_data() 函数负责获取实际的采样值。这种实现方式确保了程序能够灵活处理数据并有效提取出重要信号，进而获得期望的滤波效果。 低通滤波低通滤波是信号处理中的一种重要技术，其作用在于去除高频噪声，同时保留低频信号。为了实现这一功能，普通的硬件 RC 低通滤波器可通过微分方程表示。然而，通过使用差分方程，可以使用软件算法模拟硬件滤波的效果。经过推导，最终得到低通滤波的算法如下： Yn = a * Xn + (1 - a) * Yn-1 在上述公式中： Xn 表示本次的采样值。 Yn-1 是上次的滤波输出值。 a 是滤波系数，通常其值远小于 1，决定了当前采样对输出的影响程度。 Yn 是本次滤波的输出值。 从公式中，可以看出，本次的滤波输出值主要依赖于上次的输出值，而不是直接基于上次的采样值。这一特性使得该算法与加权平均滤波有了本质的区别：加权平均滤波会直接结合所有过去的采样值给予权重，而此算法强调了过去输出的持续影响。这使得低通滤波器在信号处理时能够有效地减少因快速变化引起的波动，从而实现平滑效果。 同样重要的是，低通滤波的截止频率可以通过以下公式计算： fL = a / (2 * π * t) （其中 π 约等于 3.14） 在这个公式中： a 是滤波系数。 t 是采样间隔时间。 例如，假设采样间隔时间 t 为 0.5 秒（即每秒采样 2 次），且设定 a 为 132，则可以这样计算截止频率： fL = (1/32) / (2 * 3.14 * 0.5) = 0.01 Hz 当目标参数是变化很慢的物理量时，该滤波算法显得特别有效，它能够有效地将高频噪声过滤掉，提高信号的稳定性。然而，值得注意的是，该算法无法滤除高于 12 采样频率的干扰信号。在本例中，由于采样频率为 2Hz，因此对于 1Hz 以上的干扰信号，需要采用其他更强的滤波方法加以处理。 虽然低通滤波算法与加权平均滤波存在相似之处，但加权系数仅有两个：a 和 1-a。为简化计算，可以将 a 取为一个整数，而将 1-a 用 256-a 来替代，从而避免复杂的浮点运算。为了确保计算的准确性，过滤输出值使用双字节表示，其中一个字节存储整数部分，另一个字节存储小数部分。这种设计避免了因每次计算时舍去尾数而引起的输出不变问题，确保了滤波的有效性。 通过上述方法，可以在软件中有效实现低通滤波器的功能，高效地处理和优化信号，满足各种数据处理需求。 卡尔曼滤波卡尔曼滤波器是一个 “optimalrecursivedataprocessingalgorithm（最优化自回归数据处理算法）”。对于解决很大部分的问题，他是最优，效率最高甚至是最有用的。 假设要研究的对象是一个房间的温度。根据的经验判断，这个房间的温度是恒定的，也就是下一分钟的温度等于现在这一分钟的温度（假设用一分钟来做时间单位）（这里的假设相当于状态方程的系数 A 为 1）。假设对的经验不是 100%的相信，可能会有上下偏差几度。把这些偏差看成是高斯白噪声（White GaussianNoise）（这里就是 W(k)），也就是这些偏差跟前后时间是没有关系的而且符合高斯分配（Gaussian Distribution）。另外在房间里放一个温度计，但是这个温度计也不准确的，测量值会比实际值偏差。也把这些偏差看成是高斯白噪声。（温度计的测量值就是 Z(k),而由于温度测到的温度就是温度，不用再换算，所以系数 H 就是 1，偏差就是 V(k)）好了，现在对于某一分钟有两个有关于该房间的温度值：根据经验的预测值（系统的预测值 X(k|k-1)）和温度计的值（测量值 Z(k)）。下面要用这两个值结合他们各自的噪声来估算出房间的实际温度值。 假如要估算 k 时刻的是实际温度值。首先要根据 k-1 时刻的温度值，来预测 k 时刻的温度。因为相信温度是恒定的，所以会得到 k 时刻的温度预测值是跟 k-1 时刻一样的，假设是 23 度，同时该值的高斯噪声的偏差是 5 度（5 是这样得到的：如果 k-1 时刻估算出的最优温度值的偏差（p(k-1|k-1)就是上一时刻的 p(k|k)）是 3，对自己预测的不确定度是 4 度，他们平方相加再开方，就是 5（算出来的就是 P(k|k-1)））。然后，从温度计那里得到了 k 时刻的温度值（测量值 Z(k)），假设是 25 度，同时该值的偏差是 4 度。由于用于估算 k 时刻的实际温度有两个温度值，分别是 23 度和 25 度。究竟实际温度是多少呢？相信自己还是相信温度计呢？究竟相信谁多一点，可以用他们的 covariance（协方差）来判断。因为 `Kg^2=5^2/(5^2+4^2)`，所以 ` Kg=0.78`，可以估算出 k 时刻的实际温度值是：`23+0.78*(25-23)=24.56` 度。可以看出，因为温度计的 covariance 比较小（比较相信温度计），所以估算出的最优温度值偏向温度计的值。 现在已经得到 k 时刻的最优温度值了，下一步就是要进入 k+1 时刻，进行新的最优估算。到现在为止，好像还没看到什么自回归的东西出现。对了，在进入 k+1 时刻之前，还要算出 k 时刻那个最优值（24.56 度）的偏差。算法如下：((1-Kg)*5^2)^0.5=2.35。这里的 5 就是上面的 k 时刻预测的那个 23 度温度值的偏差，得出的 2.35 就是进入 k+1 时刻以后 k 时刻估算出的最优温度值的偏差（对应于上面的 3）。 就是这样，卡尔曼滤波器就不断的把 covariance 递归，从而估算出最优的温度值。他运行的很快，而且它只保留了上一时刻的 covariance。上面的 Kg，就是卡尔曼增益（Kalman Gain）。 kalman 滤波器算法首先，先要引入一个离散控制过程的系统。该系统可用一个线性随机微分方程（Linear Stochastic Difference equation）来描述： x(k)是 k 时刻的系统状态，u(k)是 k 时刻对系统的控制量。A 和 B 是系统参数，对于多模型系统，他们为矩阵。y(k)是 k 时刻的测量值，H 是测量系统的参数，对于多测量系统，H 为矩阵。q(k)和 r(k)分别表示过程和测量的噪声。他们被假设成高斯白噪声(White Gaussian Noise)，他们的 covariance 分别是 Q，R（这里假设他们不随系统状态变化而变化）。 对于满足上面的条件(线性随机微分系统，过程和测量都是高斯白噪声)，卡尔曼滤波器是最优的信息处理器。下图给出 KF 算法的流程和五个核心更新方程如下： 下面来结合 covariances 来估算系统的最优化输出（类似上一节那个温度的例子）。首先要利用系统的过程模型，来预测下一状态的系统。假设现在的系统状态是 k，根据系统的模型，可以基于系统的上一状态而预测出现在状态： X(k|k-1)=A X(k-1|k-1)+B U(k) ……….. (1) 式(1)中，X(k|k-1)是利用上一状态预测的结果，X(k-1|k-1)是上一状态最优的结果，U(k)为现在状态的控制量，如果没有控制量，它可以为 0。 到现在为止，的系统结果已经更新了，可是，对应于 X(k|k-1)的 covariance 还没更新。用 P 表示 covariance： P(k|k-1)=A P(k-1|k-1) A’+Q ……… (2) 式(2)中，P(k|k-1)是 X(k|k-1)对应的 covariance，P(k-1|k-1)是 X(k-1|k-1)对应的 covariance，A’表示 A 的转置矩阵，Q 是系统过程的 covariance。式子 1，2 就是卡尔曼滤波器 5 个公式当中的前两个，也就是对系统的预测。 现在有了现在状态的预测结果，然后再收集现在状态的测量值。结合预测值和测量值，可以得到现在状态(k)的最优化估算值 X(k|k)： X(k|k)= X(k|k-1)+Kg(k) (Z(k)-H X(k|k-1)) ……… (3) 其中 Kg 为卡尔曼增益(Kalman Gain)： Kg(k)= P(k|k-1) H’ / (H P(k|k-1) H’ + R) ……… (4) 到现在为止，已经得到了 k 状态下最优的估算值 X(k|k)。但是为了要另卡尔曼滤波器不断的运行下去直到系统过程结束，还要更新 k 状态下 X(k|k)的 covariance： P(k|k)=（I-Kg(k) H）P(k|k-1) ……… (5) 其中 I 为 1 的矩阵，对于单模型单测量，I1。当系统进入 k+1 状态时，P(k|k)就是式子(2)的 P(k-1|k1)。这样，算法就可以自回归的运算下去。 卡尔曼滤波器的原理基本描述了，式子 1，2，3，4 和 5 就是他的 5 个基本公式。根据这 5 个公式，可以很容易的实现计算机的程序。 kalman 实现把房间看成一个系统，然后对这个系统建模。当然，见的模型不需要非常地精确。所知道的这个房间的温度是跟前一时刻的温度相同的，所以 A1。没有控制量，所以 U(k)0。因此得出： X(k|k-1)=X(k-1|k-1) ……….. (6) 式子（2）可以改成： P(k|k-1)=P(k-1|k-1) +Q ……… (7) 因为测量的值是温度计的，跟温度直接对应，所以 H1。式子 3，4，5 可以改成以下： X(k|k)= X(k|k-1)+Kg(k) (Z(k)-X(k|k-1)) ……… (8)Kg(k)= P(k|k-1) / (P(k|k-1) + R) ……… (9)P(k|k)=（1-Kg(k)）P(k|k-1) ……… (10) 现在模拟一组测量值作为输入。假设房间的真实温度为 25 度，模拟了 200 个测量值，这些测量值的平均值为 25 度，但是加入了标准偏差为几度的高斯白噪声（在图中为蓝线）。 为了令卡尔曼滤波器开始工作，需要告诉卡尔曼两个零时刻的初始值，是 X(0|0)和 P(0|0)。他们的值不用太在意，随便给一个就可以了，因为随着卡尔曼的工作，X 会逐渐的收敛。但是对于 P，一般不要取 0，因为这样可能会令卡尔曼完全相信给定的 X(0|0)是系统最优的，从而使算法不能收敛。选了 X(0|0)1 度，P(0|0)10。 该系统的真实温度为 25 度，图中用黑线表示。图中红线是卡尔曼滤波器输出的最优化结果（该结果在算法中设置了 Q1e-6，R1e-1）。 matlab 下面的 kalman 滤波程序： clearN=200;w(1)=0;w=randn(1,N)x(1)=0;a=1;for k=2:N;x(k)=a*x(k-1)+w(k-1);endV=randn(1,N);q1=std(V);Rvv=q1.^2;q2=std(x);Rxx=q2.^2;q3=std(w);Rww=q3.^2;c=0.2;Y=c*x+V;p(1)=0;s(1)=0;for t=2:N;p1(t)=a.^2*p(t-1)+Rww;b(t)=c*p1(t)/(c.^2*p1(t)+Rvv);s(t)=a*s(t-1)+b(t)*(Y(t)-a*c*s(t-1));p(t)=p1(t)-c*b(t)*p1(t);endt=1:N;plot(t,s,r,t,Y,g,t,x,b); Kalman 过程详解： 预测：做出先验估计 x[n|n-1]=A*x[n-1|n-1] 【对于一维的情况，A 可以看成一个常数使用，经常取 1，同时对于 B 经常取零(—可能有人会有疑问：取 0 没事吗，可以放心的告诉，问题不大。反过来想想，这只是一个估计，可以在估计噪声方差得到修正)】 向前推算协方差：做出预测后的新的概率分布的方差（预测上次的最优估计为当前时刻的先验估计这个过程可以当成一个符合预测过程噪声分布的和另一个(上一次的最优估计可以看做高斯分布的)也符合高斯分布的相加。预测结果也是符合高斯噪声分布的，方差是两个相互独立的方差之和）。 【对于一维的情况,P[n|n-1]=P[n-1|n-1]+Q。 Q 为预测方差，代表对预测的不信任程度，工程上根据实际调节以改善滤波器的性能:动态效果和去噪效果】 计算卡尔曼增益： 【对于一维的情况，K[n]=H*P[n|n-1]/H^2*P[n|n-1]+R。其中 H 是对观测的响应倍数，通常取 1，R 为测量的方差，工程上一般都可以直接获得】 更估计值：做出后验估计，修正后的估计值，更接近真实值。 【对于一维的情况，最优估计由下式给出：x[n|n]=x[n|n-1]+K[n]*z[n]-x[n|n-1]。其中 z[n]为观测值】 更新误差协方差：得到最优估计的概率分布的方差。 【对于一维的情况，新的误差协方差由下给出：P[n|n]=(1-K[n]*H)*P[n|n-1]】 代码实现// 一维滤波器信息结构体typedef struct double filterValue; // k-1时刻的滤波值，指的是在上一个时刻的估计值 double kalmanGain; // Kalman增益，控制当前估计值与新测量值的融合程度 double A; // 状态转移模型，x(n)=A*x(n-1)+u(n)，u(n)服从正态分布N(0,Q) double H; // 观测模型，z(n)=H*x(n)+w(n)，w(n)服从正态分布N(0,R) double Q; // 过程噪声方差，量化预测过程中的不确定性 double R; // 测量噪声方差，通过实验获取，此值决定了测量的可靠性 double P; // 估计误差协方差，反映了当前估计的准确程度 KalmanInfo;/** * @brief Init_KalmanInfo 初始化滤波器的初始参数 * @param info 滤波器指针，指向KalmanInfo结构体 * @param Q 预测噪声方差，由系统外部确定 * @param R 测量噪声方差，由系统外部确定 */void Init_KalmanInfo(KalmanInfo* info, double Q, double R) info-A = 1; // 状态转移矩阵设置为1，表示当前状态等于上一个状态 info-H = 1; // 观测矩阵设置为1，表示直接测量状态 info-P = 10; // 后验状态估计值的误差初始值，设置为10以减少初期不确定性的影响 info-Q = Q; // 过程噪声方差，影响滤波收敛速度，需根据实际情况设定 info-R = R; // 测量噪声方差，建议通过实验统计获得，对测量准确性很重要 info-filterValue = 0; // 初始滤波值设为0，表示开始的状态double KalmanFilter(KalmanInfo* kalmanInfo, double lastMeasurement) // 预测下一时刻的值 double predictValue = kalmanInfo-A * kalmanInfo-filterValue; // 基于上一个滤波值进行预测，此处适合多种应用场景 // 更新协方差 kalmanInfo-P = kalmanInfo-A * kalmanInfo-A * kalmanInfo-P + kalmanInfo-Q; // 计算先验均方差，反映当前预测的不确定性 double preValue = kalmanInfo-filterValue; // 记录上次实际的滤波值，为后续可能的计算做准备 // 计算Kalman增益 kalmanInfo-kalmanGain = kalmanInfo-P * kalmanInfo-H / (kalmanInfo-P * kalmanInfo-H * kalmanInfo-H + kalmanInfo-R); // Kalman增益在0到1之间，较大时表示对测量值的信任度提高 // 修正结果，结合预测值与新测量值 kalmanInfo-filterValue = predictValue + (lastMeasurement - predictValue) * kalmanInfo-kalmanGain; // 通过残余（测量值与预测值之差）来调整估计，输出当前时刻的滤波值 // 更新后验估计协方差 kalmanInfo-P = (1 - kalmanInfo-kalmanGain * kalmanInfo-H) * kalmanInfo-P; // 更新后的协方差反映了更准确的状态估计结果 return kalmanInfo-filterValue; // 返回当前时刻的滤波值 此代码实现了一个简单的一维 Kalman 滤波器，主要用于信号预测和噪声抑制。滤波器的有效性在于调整参数 Q 和 R，这些参数直接影响滤波器对不同来源噪声的敏感度，使得它可以在动态环境下提供平滑且准确的估计。通过合理设置这些初始值和更新步骤，Kalman 滤波器将能够逐渐学习并优化对环境状态的预测。","categories":["2.语言","结构算法"]},{"title":"设计模式","path":"/2024/01/25/2-语言-结构算法-设计模式/","content":"单一职责原则单一职责原则（Single Responsibility Principle，SRP）强调一个类应该仅有一个职责或原因去改变。换句话说，每个模块或类应该专注于其特定的功能，避免承担过多的责任。这样可以使代码更易于理解、测试和维护。 例如，在一个电子商务系统中，一个“订单处理”类如果同时负责处理订单的创建、支付以及订单状态的更新，就会变得复杂且难以管理。将这些职责进行拆分，每个模块专注于一个特定的任务，比如“创建订单类”、“支付处理类”和“订单状态更新类”，这样就能在代码的维护和扩展上带来更大的灵活性。 开放-封闭原则开放-封闭原则（Open-Closed Principle，OCP）指出软件实体（类、模块、函数等）应该对扩展开放，对修改封闭。这意味着在不改变现有代码的前提下，可以通过添加新代码来扩展系统的功能。 以一个图形绘制程序为例，最开始系统只支持绘制圆形和矩形。如果未来需要添加绘制三角形的功能，遵循开放-封闭原则的设计允许通过新增一个“三角形”类，而不需要修改原有的圆形和矩形类。这种设计不仅提高了系统的可扩展性，也降低了引入新功能时可能带来的错误风险。 依赖倒转原则依赖倒转原则（Dependency Inversion Principle，DIP）要求高层模块不应该依赖低层模块，而是应该依赖于抽象。换句话说，程序应通过接口或抽象类而非具体实现来进行交互。 以数据访问层和业务逻辑层为例。业务逻辑层应该依赖于一个数据访问接口，比如“IDatabaseAccess”，而不是对具体的数据访问类“SqlDatabaseAccess”进行依赖。这样，如果未来需要更换数据库，例如从 SQL Server 迁移到 MongoDB，只需实现一个新的“MongoDatabaseAccess”类，而业务逻辑层的代码无需更改。这种方法提高了系统的灵活性和可维护性。 迪米特法则迪米特法则（Law of Demeter）也称为“最少知识原则”，提倡一个对象不应该主动去了解其他对象的内部细节，尤其是其非直接依赖的对象。这一原则旨在降低对象之间的耦合度，提高系统的模块化。 一个公司项目管理系统为例，在一个“项目”对象中，可能包含对“团队”对象的引用。根据迪米特法则，“项目”对象不应直接访问“团队”成员的具体信息。例如，不应通过“项目”对象直接获取团队成员的邮箱，而应提供一个方法如“getTeamMemberEmails()”，这样“项目”只需要与“团队”进行互动，而不需要关注“团队”内部的实现细节。这种设计使得对象之间的交互变得简单和清晰，减少了系统的复杂性。 创建型模式创建型模式的主要目标是通过各种方式来创建对象，从而提高软件设计的灵活性和重用性。这些模式提供了解决实例创建过程的标准方法，使得代码更易于维护和扩展。 简单工厂模式简单工厂模式是一种不属于 GoF 设计模式的模式，它通过一个工厂类来创建对象。工厂类根据输入的参数来决定实例化哪一个具体类。比如，在一个汽车生产系统中，简单工厂可以根据车型参数（如“轿车”或“SUV”）来生成不同类型的汽车对象。这种模式的优点在于 Clients 不需要直接依赖具体类，只需依赖工厂接口。 class CarFactory public static Car createCar(String type) if (type.equals(Sedan)) return new Sedan(); else if (type.equals(SUV)) return new SUV(); return null; 抽象工厂抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族，而无须明确指定具体类。抽象工厂的目的是为了一次性创建一系列相关对象，在用户对系统进行扩展时，不会引入太多的变化。典型应用场景如跨平台的 UI 组件库，允许用户在不同操作系统下创建符合各自风格的界面元素。 interface GUIFactory Button createButton(); Checkbox createCheckbox();class WindowsFactory implements GUIFactory public Button createButton() return new WindowsButton(); public Checkbox createCheckbox() return new WindowsCheckbox(); 建造者模式建造者模式允许逐步构建一个复杂的对象。在创建对象时，将其构建过程与表示分离，使同样的构建过程可以创建不同的表示。常见于复杂对象的创建，尤其是当对象的构造复杂，或者构造参数不容易归类时。 class Car private String engine; private int wheels; public void setEngine(String engine) this.engine = engine; public void setWheels(int wheels) this.wheels = wheels; class CarBuilder private Car car; public CarBuilder() car = new Car(); public CarBuilder buildEngine(String engine) car.setEngine(engine); return this; public CarBuilder buildWheels(int wheels) car.setWheels(wheels); return this; public Car build() return car; 工厂方法工厂方法模式允许创建对象的实例，但将实例化的过程延迟到子类中。定义了一个创建对象的接口，但将实例化的工作放在一个子类中实现。通过这种方式，代码的扩展性增强，可以避开在类的多个位置进行修改。 abstract class Creator public abstract Product factoryMethod();class ConcreteCreatorA extends Creator public Product factoryMethod() return new ConcreteProductA(); 原型模式原型模式通过拷贝现有对象的方式来创建新对象，而不是通过构造函数进行创建。在某些情况下，创建对象的开销较大，使用现有对象拷贝的方式可以提升效率。它适用于对象的创建成本较高时，例如大量配置和初始化数据的情境。 class Prototype implements Cloneable private String data; public Prototype(String data) this.data = data; public Prototype clone() throws CloneNotSupportedException return (Prototype) super.clone(); 单例模式单例模式确保一个类只有一个实例，并提供一个全局访问点。在需要控制实例数量的情况下，单例模式非常有用。典型场景包括日志记录器、配置管理器等，在这些情况下，多个实例可能会引起资源浪费或不一致性问题。 class Singleton private static Singleton instance; private Singleton() public static synchronized Singleton getInstance() if (instance == null) instance = new Singleton(); return instance; 结构型模式结构型模式关注于如何将类或对象组合成更大的结构，以便实现灵活的代码组织和提高系统的可复用性。以下是几种常见的结构型模式，每种模式都有其独特的特点和应用场景。 适配器模式适配器模式通过将一个接口转换成另一个接口，使得本来因为接口不兼容而无法一同工作的类能协调起来。例如，在现代城市中，电源插座的标准因地区而异。欧洲标准的插头通常是两头带有圆孔的插头，而美国的插头则为扁平双脚设计。假设有一台只能接受美国标准插头的设备，但接入的是欧洲标准插头。此时，一个适配器的引入可以将欧洲插头转换为适合美国插座的类型，从而使设备正常工作。这个模式在软件开发中尤为关键，特别是在集成第三方库或者老旧代码时，可以平滑地与当前使用的系统兼容。这样，开发者能够继续利用现有的资源，而不必重写整个系统。 代码示例：// 目标接口public interface Target void request();// 适配者类public class Adaptee public void specificRequest() System.out.println(Called specificRequest); // 适配器类public class Adapter implements Target private Adaptee adaptee; public Adapter(Adaptee adaptee) this.adaptee = adaptee; @Override public void request() adaptee.specificRequest(); 桥接模式桥接模式通过将抽象部分与它的具体实现部分分隔开来，使得二者可以独立变化。核心在于引入一个桥接接口，创建一个抽象层，这样具体实现与抽象定义不再强关联。考虑一个图形绘制程序，其中存在不同形状（如圆形、矩形）和色彩（如红色、蓝色）。使用桥接模式，可以将形状定义与色彩定义分开，从而使在新增一个形状或颜色时，不会影响其他部分的实现。例如，若添加一个绿色的三角形，仅需要实现三角形的相关接口以及与绿色相关的颜色实现，而不需要更改现有的代码结构。 代码示例：// 形状接口public interface Shape void draw();// 颜色接口public interface Color void fill();// 实现形状的类public class Circle implements Shape private Color color; public Circle(Color color) this.color = color; @Override public void draw() System.out.print(Drawing Circle in ); color.fill(); // 实现颜色的类public class Red implements Color @Override public void fill() System.out.println(Red Color); 组合模式组合模式允许将对象组合成树形结构，以表示部分与整体的层次关系。它通过提供一致的接口，使得客户端对单个对象和组合对象的操作保持一致性。以文件系统为例，用户可以将文件和目录视为树形结构的节点。一个目录中可以包含多个文件或子目录，而每个文件和目录又可被视作一个独立的节点。通过组合模式，操作文件和目录时，可以仅使用统一的接口，从而简化了文件系统的操作。例如，可以用相同的方法来打开一个文件或目录，无需考虑它们的具体类型。 代码示例：// 组件接口public interface File void display();// 叶子节点类public class ImageFile implements File private String name; public ImageFile(String name) this.name = name; @Override public void display() System.out.println(Displaying image: + name); // 容器类public class Directory implements File private ListFile files = new ArrayList(); private String name; public Directory(String name) this.name = name; public void add(File file) files.add(file); @Override public void display() System.out.println(Directory: + name); for (File file : files) file.display(); 装饰模式装饰模式允许在不改变对象原有结构的情况下，动态地为其增加新的功能和责任。这种模式比子类化方案更具灵活性，因为它可以在运行时为对象增加多种功能。以咖啡为例，一杯基本咖啡可以通过添加牛奶、糖或香料等配料来改变其风味。每种添加物就像是一个装饰者，可以独立地添加到咖啡中，形成多种不同的组合。这样，无需修改咖啡的原始配方，就可以在多个咖啡实例中共享这些功能，当需要添加新功能时，只需简单地创建一个新的装饰者。 例如，如果原有的咖啡对象是一个 SimpleCoffee 类，可以通过实现 CoffeeDecorator 类来构建不同种类的咖啡装饰品，比如 MilkDecorator、SugarDecorator 和 SpiceDecorator。 interface Coffee String getDescription(); double cost();class SimpleCoffee implements Coffee public String getDescription() return Simple Coffee; public double cost() return 1.00; abstract class CoffeeDecorator implements Coffee protected Coffee coffee; public CoffeeDecorator(Coffee coffee) this.coffee = coffee; public String getDescription() return coffee.getDescription(); public double cost() return coffee.cost(); class MilkDecorator extends CoffeeDecorator public MilkDecorator(Coffee coffee) super(coffee); public String getDescription() return coffee.getDescription() + , Milk; public double cost() return coffee.cost() + 0.50; 外观模式外观模式意在通过提供一个统一的接口，来简化复杂系统的使用方法，并隐藏内部复杂性。这种模式对用户而言，使得各个子系统间的交互变得直观且易于使用。例如，在一个多媒体播放软件中，用户需要同时控制音频、视频和字幕这三个子系统。没有外观模式的情况下，可能需要分别调用不同的操作，这很容易导致混淆。 引入外观模式后，可以设计一个统一的接口，比如 MediaFacade，用户只需调用简单的方法来同时控制音视频的播放和停止，而无需了解每个子系统的底层实现。这样，维护和使用变得更为方便。 class AudioSystem public void play() System.out.println(Audio Playing); public void stop() System.out.println(Audio Stopped); class VideoSystem public void play() System.out.println(Video Playing); public void stop() System.out.println(Video Stopped); class SubtitleSystem public void show() System.out.println(Subtitle Showing); public void hide() System.out.println(Subtitle Hidden); class MediaFacade private AudioSystem audio; private VideoSystem video; private SubtitleSystem subtitle; public MediaFacade() audio = new AudioSystem(); video = new VideoSystem(); subtitle = new SubtitleSystem(); public void play() audio.play(); video.play(); subtitle.show(); public void stop() audio.stop(); video.stop(); subtitle.hide(); 享元模式享元模式通过共享对象来有效管理大量细粒度对象，从而减少内存占用。该模式在处理大量相似对象时显示出巨大的效益。举例来说，在一个文本编辑器中，每个字符都可以视为一个对象。当文档中存在大量相同字符时，例如字母“a”，使用传统方法会在内存中创建多个“a”字符对象，这显然是低效的。 通过享元模式，可以创建一个字符工厂，这个工厂负责管理和共享字符对象。当需要使用某个字符时，工厂首先检查是否已有相应的字符对象。如果已有，则直接返回该对象；如果没有，则创建一个新的字符对象。这种方法极大节省了内存，同时提升了性能。 class CharacterFlyweight private char character; public CharacterFlyweight(char character) this.character = character; public char getCharacter() return character; class CharacterFactory private MapCharacter, CharacterFlyweight characterMap = new HashMap(); public CharacterFlyweight getCharacter(char c) if (!characterMap.containsKey(c)) characterMap.put(c, new CharacterFlyweight(c)); return characterMap.get(c); 代理模式代理模式用于为其他对象提供代理，从而控制对该对象的访问。通过这种模式，可以在不改动目标对象的前提下，进行各种操作。一个常见的应用场景是网络服务中的代理服务器，用户在请求数据时，可以通过代理服务器实现对目标服务器的请求处理。 代理不仅可以用于请求转发，还可以用于权限控制、数据缓存等功能。例如，在访问一个需要认证的服务时，代理可以在转发请求前先进行用户身份验证。这样一来，系统的灵活性和安全性得以增强，同时还可以保持与原始对象的一致性。 interface Image void display();class RealImage implements Image private String filename; public RealImage(String filename) this.filename = filename; loadImageFromDisk(); private void loadImageFromDisk() System.out.println(Loading + filename); public void display() System.out.println(Displaying + filename); class ProxyImage implements Image private RealImage realImage; private String filename; public ProxyImage(String filename) this.filename = filename; public void display() if (realImage == null) realImage = new RealImage(filename); realImage.display(); 行为型模式行为型模式专注于对象之间的责任分配和通信，帮助建立清晰的合作方式。以下是几种常见的行为型模式的介绍及其特点。 观察者模式观察者模式定义了一种一对多的依赖关系，使得当一个对象的状态发生改变时，所有依赖于它的对象都能收到通知并自动更新。这种模式在许多实际应用场景中十分常见。例如，在气象站内，当温度、湿度或气压等气象数据变化时，多个显示设备（如电子显示屏、手机应用程序等）将即时更新其显示信息，确保用户获得最新的数据。此外，新闻网站的订阅功能也是经典的应用，用户可以选择订阅自己感兴趣的新闻专题，当相关内容更新时，系统会通过电子邮件或推送通知的方式直接将信息送达用户。这种及时的信息传递机制增强了用户的获取体验，提高了系统的互动性。 代码示例： // 伪代码示例class Subject private ListObserver observers = new ArrayList(); public void addObserver(Observer observer) observers.add(observer); public void notifyObservers() for (Observer observer : observers) observer.update(); class ConcreteObserver implements Observer public void update() // 实现更新逻辑 模板方法模式模板方法模式通过定义一个算法的框架并将某些步骤的实现留给子类，从而提供了灵活性和可扩展性。以下是一个生活中的例子：烘焙的过程包括预热烤箱、准备食材、混合材料、烘焙等步骤。模板方法模式确保这一系列步骤的执行顺序和基本流程始终不变，而子类可以根据特定的需求实现不同的步骤，如制作巧克力蛋糕或香草蛋糕时所需的具体材料和配方可能不同。这样，无论使用何种口味的蛋糕，基本的烘焙流程始终保持一致。代码示例： abstract class AbstractBaker public final void bake() preheatOven(); prepareIngredients(); mixIngredients(); bakeCake(); protected abstract void prepareIngredients(); protected abstract void mixIngredients(); private void preheatOven() // 固定步骤 private void bakeCake() // 固定步骤 class ChocolateCakeBaker extends AbstractBaker protected void prepareIngredients() // 特定的材料准备 protected void mixIngredients() // 特定的混合方法 命令模式命令模式将请求封装为对象，从而支持对请求的参数化、请求的排队和请求日志功能。这一模式在图形用户界面中应用广泛，用户的操作（如点击按钮、选择菜单项等）可以表示为命令。例如，文本编辑器支持的“剪切”、“复制”和“粘贴”等操作，可以实现为独立的命令对象。这种封装方法的好处在于，这些命令可以被轻松管理、撤销或重做，提升了用户交互的灵活性与体验。代码示例： interface Command void execute(); void undo();class CutCommand implements Command public void execute() // 执行剪切操作 public void undo() // 撤销剪切操作 class CopyCommand implements Command public void execute() // 执行复制操作 public void undo() // 撤销复制操作 状态模式状态模式允许一个对象根据其内部状态的变化改变其行为。这一模式特别适用于那些具有多种状态并能在状态间转换的复杂系统。例如，在某款游戏中，角色的状态可以是“待机”、“行走”、“攻击”等。每种状态都有独特的行为和响应，而状态模式使状态的管理和转换变得更为清晰和简化。通过集中管理不同状态下的逻辑，程序可以在状态改变时迅速做出反应，提高了执行效率。代码示例： interface State void handle();class IdleState implements State public void handle() // 处理待机状态的逻辑 class WalkingState implements State public void handle() // 处理行走状态的逻辑 class Character private State currentState; public void setState(State state) currentState = state; public void action() currentState.handle(); 职责链模式职责链模式通过将请求的发送者与接收者解耦，使得多个对象有机会处理请求。这种模式中，处理请求的对象按顺序连接成一条链，可以逐级传递请求。以客户服务中心为例，用户的问题可能会经历多个处理阶段，从初级支持到技术支持，甚至渗透到更高级的处理层级。每个阶段都有专员负责特定类型的问题，问题会在这些阶段间流转，直到得到解决或者放弃。这种结构化的请求处理方法提升了响应效率和客户满意度。代码示例： abstract class Handler protected Handler next; public void setNext(Handler next) this.next = next; public abstract void handleRequest(Request request);class LevelOneHandler extends Handler public void handleRequest(Request request) if (request.isSimple()) // 处理简单请求 else if (next != null) next.handleRequest(request); class LevelTwoHandler extends Handler public void handleRequest(Request request) if (request.isTechnical()) // 处理技术请求 else if (next != null) next.handleRequest(request); 解释器模式解释器模式为特定语言定义语法，并提供解析和执行方式。此模式在需要动态解读和执行逻辑的情况下非常有用。例如，计算器程序可以使用表达式来表示数学运算，通过解释器模式，程序能够解析用户输入的表达式，如“3 + 5 * 2”，并计算出正确的结果。这种灵活的解析能力使得程序可以处理用户自主定义的表达式，拓宽了软件的适用范围。 代码示例： interface Expression int interpret();class Number implements Expression private int number; public Number(int number) this.number = number; public int interpret() return number; class Addition implements Expression private Expression left; private Expression right; public Addition(Expression left, Expression right) this.left = left; this.right = right; public int interpret() return left.interpret() + right.interpret(); 中介者模式中介者模式通过引入一个中介类，显著简化了对象之间的通信，使得对象间的耦合度降低。这种方式减少了组件之间的直接依赖，使得系统更加灵活。在一个聊天应用的场景中，所有用户并不直接互相交流，而是通过一个中央服务器进行消息的传递和管理。例如，当用户 A 发送消息给用户 B 时，消息首先到达中介服务器，由中介服务器再转发给用户 B。如此一来，服务器不仅可以统一管理消息，还可以处理消息的存储、转发以及用户的在线状态等功能，有效提升了管理的效率和扩展性。代码示例： class Mediator private ListUser users = new ArrayList(); public void registerUser(User user) users.add(user); public void sendMessage(String message, User sender) for (User user : users) // 发送消息给除了发件人以外的所有用户 if (user != sender) user.receive(message); 访问者模式访问者模式的核心在于可以在不改变元素类的基础上，动态地为被访问的元素添加新操作。这一设计尤其适用于那些结构相对稳定但操作需求频繁变化的系统。举个例子，在一个复杂的数据结构（如图形库）中，可以定义多个不同的访问者，每个访问者负责为不同类型的图形（如圆形、方形或三角形）实施独特的渲染策略。这样，开发人员可以通过实现新的访问者类来扩展功能，而不必修改任何图形类。代码示例： interface Visitor void visit(Circle circle); void visit(Square square);class Circle void accept(Visitor visitor) visitor.visit(this); class Square void accept(Visitor visitor) visitor.visit(this); 策略模式策略模式通过定义一系列可互换的算法，让客户端可以在运行时选择具体的策略。这种模式特别适合于那些需要根据特定条件快速切换行为的场景。例如，在一个在线零售商的购物平台中，不同的促销活动需要不同的折扣策略，如满减、百分比折扣等。每一种折扣策略都可以独立地实现，从而简化了系统的维护和扩展过程。用户在结账时，系统会根据其购物情况自动选择最优的折扣策略。代码示例： interface DiscountStrategy double applyDiscount(double price);class FullReductionStrategy implements DiscountStrategy public double applyDiscount(double price) return price - 50; // 满减50 class PercentageDiscountStrategy implements DiscountStrategy public double applyDiscount(double price) return price * 0.9; // 90% 的价格 备忘录模式备忘录模式允许对象在不暴露内部状态的情况下，保存和恢复其状态。这一模式特别适合于需要实现撤销或恢复功能的应用场合。例如，在一款文本处理器中，为了提供用户撤回最近编辑操作的能力，应用程序可以采用备忘录模式来保存文本的多个编辑状态。每当用户做出改变时，应用程序便会创建一个状态快照，用户随时可以选择恢复到之前某个特定的状态。代码示例： class Memento private String state; public Memento(String state) this.state = state; public String getState() return state; class TextEditor private String content; public Memento save() return new Memento(content); public void restore(Memento memento) this.content = memento.getState(); 迭代器模式迭代器模式提供了一种顺序访问集合对象中元素的方式，同时又不暴露集合的内部结构。这种模式通常被应用于各种集合类，如列表、树或其他复杂的数据结构。举例来说，在一个电商平台的购物车中，用户能够逐一查看购物车中的商品。通过迭代器的实现，用户可以便捷地访问每一件商品，而无需了解背后复杂的实现细节。代码示例： interface Iterator boolean hasNext(); Object next();class ShoppingCart private ListItem items = new ArrayList(); public void addItem(Item item) items.add(item); public Iterator iterator() return new ShoppingCartIterator(); private class ShoppingCartIterator implements Iterator private int index = 0; public boolean hasNext() return index items.size(); public Object next() return items.get(index++);","categories":["2.语言","结构算法"]},{"title":"算法","path":"/2024/01/24/2-语言-结构算法-算法/","content":"提到算法时，就不能忽视数据结构之间的紧密联系。们经常会见到这样一个著名的公式： 数据结构 + 算法 程序为了更好地理解这个公式，们不妨先看一张示意图，来具体展示算法与数据结构的关系。 算法的定义算法可以被视为一系列有穷的规则、语句和指令的集合。这些指令指明了如何通过特定的步骤解决某个具体的问题。举个例子，制作一杯咖啡的过程可以看作是一种算法，它包含了步骤，比如：1）烧水，2）冲泡咖啡粉，3）加入牛奶等。每一步都必须清晰地定义，才能确保最终得到一杯美味的咖啡。 一、算法的特性在讨论算法时，有几个关键特性是必须了解的： 有穷性算法的执行步骤是有限的，意味着在某个特定的时间内，算法一定能够完成。 确定性每个步骤应当清晰明确，没有歧义。这一点很重要，因为一个模糊的步骤可能导致错误的结果。 可行性算法的每一计算步骤都要在合理的时间限制内完成，确保算法在实际应用中的可用性。 输入一个算法可以接收一个或多个外部输入。例如，计算两个数字的和需要用户提供这两个数字作为输入。 输出一个算法必须会生成一个或多个输出结果，这实际上是算法执行的目的所在。 二、如何评价一个算法的好坏评估一个算法的好坏，需要从多个角度进行考量： 时间消耗算法执行过程中的时间消耗是一个重要指标。例如，在排序算法中，时间复杂度可以决定其在处理大数据集时的表现。 存储空间消耗一些算法在运行期间可能需要大量内存，这会影响到程序的性能和可用性，因此要考虑存储空间的消耗。 易于理解和实现算法的设计应当应易于理解与实现，这不仅有助于编程，还方便后期的调试与维护。例如，快速排序的算法相对通俗易懂，因而被广泛使用。 三、时间复杂度时间复杂度是用来描述算法随输入规模增长而增长的时间消耗情况。们先介绍几个基本概念： 问题的规模输入数据的大小通常用 n 来表示。更大的 n 意味着更复杂的计算。 时间复杂度算法的时间复杂度是消耗时间与问题规模 n 之间的函数关系，通常记为 T(n)。 1. 语句的频度语句的频度是指在一个算法中可执行的语句被反复执行的次数。假设某个可执行语句的执行时间为 t，并且执行次数为 f，那么该语句所耗费的时间可以计算为：t*f 例如，如果有一个算法需要执行的循环体中存在五个可执行语句，每个语句执行的时间为 1 毫秒，那么总耗时为 5 毫秒。以下面程序为例，求两个 N 阶方阵乘积： void MATRIXM(A, B, C) float A[n][n], B[n][n], C[n][n]; int i, j, k; // 语句频度 for (i = 0; i n; i++) // n+1 for (j = 0; j n; j++) // n(n+1) C[i][j] = 0; // n*n for (k = 0; k n; k++) // n*n(n+1) C[i][j] = C[i][j] + A[i][k] * B[k][j]; // n*n*n 2. 算法的时间复杂度算法的时间复杂度是所有可执行语句的频度之和，记为 T(n)。T(n) 是算法所需时间的一种估计，其中 n 为问题的规模（或大小、体积）。如上面的例子中，问题的规模 n 为矩阵的阶，该算法的时间复杂度为： T(n) = (n+1) + n(n+1) + n^2 + n^2(n+1) + n^3 = 2n^3 + 3n^2 + 2n + 1 当问题规模 n 趋近于无穷大时，lim(T(n)/(n³) =2，故 T(n) 与 n³ 为同阶无穷大，或者说 T(n) 与 n³ 成正比、T(n) 的量级为 n³，记为 T(n) = O(n³); 问题规模 n 的某个函数 f(n), T(n) O (f(n))。随着问题规模 n 的增大，算法执行时间的增长率和 f(n)的增长率相同","categories":["2.语言","结构算法"]},{"title":"g++参数介绍","path":"/2024/01/23/2-语言-编译链接-g-参数介绍/","content":"介绍gcc and g++分别是 gnu 的 c c++编译器，gccg++在执行编译工作的时候，总共需要 4 步 预处理,生成.i 的文件 将预处理后的文件不转换成汇编语言,生成文件.s 有汇编变为目标代码(机器代码)生成.o 的文件 连接目标代码,生成可执行程序 总体选项 -E 只激活预处理,这个不生成文件,需要把它重定向到一个输出文件里面. gcc -E hello.c pianoapan.txtgcc -E hello.c | more 慢慢看吧,一个 hello word 也要与处理成 800 行的代码 -S 只激活预处理和编译，就是指把文件编译成为汇编代码。 gcc -S hello.c 他将生成.s 的汇编代码，可以用文本编辑器察看 -c 只激活预处理,编译,和汇编,也就是他只把程序做成 obj 文件 gcc -c hello.c 他将生成.o 的 obj 文件 目录选项-Idir 在是用#include”file”的时候,gccg++会先在当前目录查找所制定的头文件,如果没有找到,他回到缺省的头文件目录找,如果使用-I 制定了目录,他回先在所制定的目录查找,然后再按常规的顺序去找.对于#include,gccg++会到-I 制定的目录查找,查找不到,然后将到系统的缺省的头文件目录查找-include file -i 相当于”#include”包含某个代码,简单来说,就是便以某个文件,需要另一个文件的时候,就可以用它设定,功能就相当于在代码中使用#include gcc hello.c -include /root/pianopan.h -I-就是取消前一个参数的功能,所以一般在-Idir 之后使用-idirafter dir 在-I 的目录里面查找失败,讲到这个目录里面查找. -iprefix prefix -iwithprefix dir 一般一起使用,当-I 的目录查找失败,会到 prefix+dir 下查找 -Ldir 制定编译的时候，搜索库的路径。比如自己的库，可以用它制定目录，不然编译器将只在标准库的目录找。这个 dir 就是目录的名称。 -llibrary 制定编译的时候使用的库 gcc -lcurses hello.c 使用 ncurses 库编译程序 调试选项 -g 只是编译器，在编译的时候，产生调试信息。 -gstabs 此选项以 stabs 格式声称调试信息,但是不包括 gdb 调试信息. -gstabs+ 此选项以 stabs 格式声称调试信息,并且包含仅供 gdb 使用的额外调试信息. -ggdb 此选项将尽可能的生成 gdb 的可以使用的调试信息. -glevel 请求生成调试信息，同时用 level 指出需要多少信息，默认的 level 值是 2 链接方式选项：-static 此选项将禁止使用动态库。 优点：程序运行不依赖于其他库 缺点：文件比较大 -shared (-G) 此选项将尽量使用动态库，为默认选项 优点：生成文件比较小 缺点：运行时需要系统提供动态库 -symbolic 建立共享目标文件的时候,把引用绑定到全局符号上. 对所有无法解析的引用作出警告(除非用连接编辑选项 -Xlinker -z -Xlinker defs’取代)。 注：只有部分系统支持该选项. 错误与告警选项 -Wall 一般使用该选项，允许发出 GCC 能够提供的所有有用的警告。也可以用-W{warning}来标记指定的警告。 -pedantic 允许发出 ANSIISO C 标准所列出的所有警告 -pedantic-errors 允许发出 ANSIISO C 标准所列出的错误 -werror 把所有警告转换为错误，以在警告发生时中止编译过程 -w 关闭所有警告,建议不要使用此项 预处理选项 -Dmacro 相当于 C 语言中的#define macro -Dmacrodefn 相当于 C 语言中的#define macrodefn -Umacro 相当于 C 语言中的#undef macro -undef 取消对任何非标准宏的定义 其他选项-o 制定目标名称,缺省的时候,gcc 编译出来的文件是 a.out gcc -o hello.exe hello.c (哦,windows用习惯了)gcc -o hello.asm -S hello.c -O0 -O1 -O2 -O3 编译器的优化选项的 4 个级别，-O0 表示没有优化,-O1 为缺省值，-O3 优化级别最高 -fpic 编译器就生成位置无关目标码.适用于共享库(shared library). -fPIC 编译器就输出位置无关目标码.适用于动态连接(dynamic linking),即使分支需要大范围转移. -v 显示详细的编译、汇编、连接命令 -pipe 使用管道代替编译中临时文件,在使用非 gnu 汇编工具的时候,可能有些问题 gcc -pipe -o hello.exe hello.c -ansi 关闭 gnu c 中与 ansi c 不兼容的特性,激活 ansi c 的专有特性(包括禁止一些 asm inline typeof 关键字,以及 UNIX,vax 等预处理宏, -fno-asm 此选项实现 ansi 选项的功能的一部分，它禁止将 asm,inline 和 typeof 用作关键字。 -fno-strict-prototype 只对 g++起作用,使用这个选项,g++将对不带参数的函数,都认为是没有显式的对参数的个数和类型说明,而不是没有参数.而 gcc 无论是否使用这个参数,都将对没有带参数的函数,认为城没有显式说明的类型 -fthis-is-varialble 就是向传统 c++看齐,可以使用 this 当一般变量使用. -fcond-mismatch 允许条件表达式的第二和第三参数类型不匹配,表达式的值将为 void 类型 -funsigned-char -fno-signed-char -fsigned-char -fno-unsigned-char 这四个参数是对 char 类型进行设置,决定将 char 类型设置成 unsigned char(前 两个参数)或者 signed char(后两个参数) -imacros file 将 file 文件的宏,扩展到 gccg++的输入文件,宏定义本身并不出现在输入文件中 -nostdinc 使编译器不再系统缺省的头文件目录里面找头文件,一般和-I 联合使用,明确限定头文件的位置 -nostdin C++ 规定不在 g++指定的标准路经中搜索,但仍在其他路径中搜索,.此选项在创建 libg++库使用 -C 在预处理的时候,不删除注释信息,一般和-E 使用,有时候分析程序，用这个很方便的 -M 生成文件关联的信息。包含目标文件所依赖的所有源代码可以用 gcc -M hello.c 来测试一下，很简单。 -MM 和上面的那个一样，但是它将忽略由#include 造成的依赖关系。 -MD 和-M 相同，但是输出将导入到.d 的文件里面 -MMD 和-MM 相同，但是输出将导入到.d 的文件里面 -Wa,option 此选项传递 option 给汇编程序;如果 option 中间有逗号,就将 option 分成多个选项,然后传递给会汇编程序 -Wl.option 此选项传递 option 给连接程序;如果 option 中间有逗号,就将 option 分成多个选项,然后传递给会连接程序. -x language filename 设定文件所使用的语言,使后缀名无效,对以后的多个有效.也就是根据约定 C 语言的后缀名称是.c 的，而 C++的后缀名是.C 或者.cpp可以使用的参数有下面的这些 `c’, `objective-c’, `c-header’, `c++’, `cpp-output’, `assembler’, and `assembler-with-cpp’. gcc -x c hello.pig -x none filename 关掉上一个选项，也就是让 gcc 根据文件名后缀，自动识别文件类型 gcc -x c hello.pig -x none hello2.c","categories":["2.语言","编译链接"]},{"title":"GCC编译流程","path":"/2024/01/22/2-语言-编译链接-GCC编译流程/","content":"GCC 编译流程GCC（GNU Compiler Collection）是一款强大的编译器，主要用于将 C、C++ 等语言的源代码编译成机器可执行文件。整个编译过程可以分为四个主要步骤，每个步骤都有其特定的功能和重要性。 Step 1: 预处理在预处理阶段，GCC 会处理一些特殊的指令和文件： 头文件加载：源代码中通常会使用 #include 指令来引用外部库或其他文件。例如，#include stdio.h 允许们使用标准输入输出函数。 宏定义替换：通过 #define 指令定义的宏会被直接替换成其对应的值，简化代码的编写。例如，#define PI 3.14 会将源代码中的 PI 替换成 3.14。 条件编译：使用 #ifdef 和 #ifndef 等指令，可以根据不同的条件启用或禁用代码块。这在处理不同平台或功能模块时尤其有用。 去除注释：所有的注释（如 // 和 /* */）都会在此步骤被移除，因为它们对编译过程没有意义。 通过这个步骤，GCC 生成一个名为 name.i 的预处理文件，这是一个纯文本文件，包含了所有的加载内容和替换结果。这一过程的命令为： gcc -E name.c -o name.i 或简写为： gcc -o name.i -E name.c Step 2: 编译在编译阶段，GCC 对 name.i 文件进行以下操作： 语法检查：编译器会检查代码是否符合 C 语言的语法规范。如果发现任何错误如缺少分号、括号不匹配等，GCC 会立即报错并终止编译过程。比如，如果代码中有错误，输出可能会提示出错的行和具体错误信息，帮助开发者快速定位问题。 生成汇编代码：如果没有语法错误，编译器接着生成汇编语言代码，文件名为 name.s。 这个步骤的命令如下： gcc -S name.i -o name.s 或简写为： gcc -o name.s -S name.i Step 3: 汇编在汇编阶段，GCC 将汇编代码转换为机器代码，即目标文件（.o 文件）。这一步骤可以视为将高级语言翻译成计算机能够直接理解的指令集。 机器码生成：汇编代码中每一条指令都会被转化为相应的机器指令，形成一个目标文件 name.o。此文件包含了编译后的代码，但尚未链接成完整的可执行文件。 执行汇编的命令为： gcc -c name.s -o name.o 或简写为： gcc -o name.o -c name.s Step 4: 链接最后一个步骤是链接。链接的主要工作是将一个或多个目标文件（name.o 和可能的其他.o 文件）结合起来，生成一个最终的可执行文件。 生成可执行文件：在这个阶段，GCC 将处理目标文件之间的符号引用，将它们合并，并生成可执行文件（如可称为 name 的文件）。如果程序依赖于外部库，链接器会在这里找到并包含所需的库文件。 执行链接的命令为： gcc name.o -o name 或简写为： gcc -o name name.o 经过这四个步骤后，编译完成，生成的可执行文件可以在操作系统中运行。整个过程确保代码从人类可读的高级语言转化为机器能够理解和执行的二进制文件。","categories":["2.语言","编译链接"]},{"title":"Make和Makefile","path":"/2024/01/19/2-语言-编译链接-Make和Makefile/","content":"在开发一个系统时，一般会将系统划分为多个模块。这种模块化的方式改善了系统的可维护性，便于更改和调试。然而，不同模块之间的关联不可避免，模块的修改可能需要对其他模块进行更新。对于小型系统而言，手动编译和连接非常高效且简单，但当面对大型系统，包括多个模块时，手动编译的方式就显得繁琐且容易出错。 因此，Linux 系统引入了 make 命令来自动管理目标文件的更新。与手动编译相比，make 命令的主要优点是只更新那些被修改过的文件。在 Linux 中，文件有一个最后修改时间，make 通过这一时间戳来判断是否需要重新编译该文件。这样，未修改的文件不会被重复处理，避免了不必要的浪费，同时确保不会遗漏需要更新的文件。 模块与模块之间可能存在依赖关系，make 命令正是根据这些依赖关系进行自动维护的。因此，理解依赖关系是理解 make 命令的关键。需要注意的是，make 并不自动知道这些依赖关系，程序员需要在一个叫做 Makefile 的文件中显式地定义它们。 Makemake 是一个常用的构建工具，使用它可以自动化编译和构建程序。这对大型项目尤其重要，可以大大简化复杂项目的构建过程。 make 通过读取名为 Makefile 的文本文件，根据其中定义的规则和依赖关系，识别出哪些文件需要重新编译，然后执行相应的编译命令。 在英语中，Make 这个词的意思是”制作”。在命令行中，使用 make 命令时，如果需要生成文件 a.txt，可以通过以下命令实现： $ make a.txt 但是，如果直接执行此命令，make 并不知道如何生成 a.txt。它需要依赖于 Makefile 中定义的规则。这条命令的代表性规则可能如下所示： 假设 a.txt 依赖于 b.txt 和 c.txt，两者合并生成 a.txt。为此，make 需要明白以下规则： a.txt: b.txt c.txt cat b.txt c.txt a.txt 这样的规则需要写入 Makefile 中。值得一提的是，Makefile 的名称并不是唯一的，可以写为 makefile，也可以通过命令行参数指定其他文件名，例如： $ make -f rules.txt $ make --file=rules.txt 这样，make 命令会根据 rules.txt 文件中的规则执行相应操作。 Make 命令make 命令可以带有四种参数：标志、宏定义、文件名和目标文件名，其标准形式为： make [flags] [macro definitions] [targets] 在 Unix 系统中，常用的标志选项及其含义如下表所示： 标志位 含义 -f file 指定文件 file 作为描述文件；如果 file 为 -，则描述文件指向标准输入。系统默认查找当前目录下的 makefile 或 Makefile 文件。 -i 忽略命令执行返回的错误信息。 -s 沉默模式，执行前不输出命令行信息。 -r 禁止使用内置规则。 -n 非执行模式，打印所有执行命令，但不实际执行。 -t 更新目标文件。 -q make 根据目标文件是否已更新返回状态信息”0”或非”0”。 -p 输出所有宏定义和目标文件描述。 -d 调试模式，输出有关文件及检测时间的详细信息。 在 Linux 下，某些标志选项与 Unix 系统略有不同，以下是不同之处： 标志位 含义 -c dir 在读取 Makefile 之前切换到指定目录 dir。 -I dir 指定搜索目录以包含其他 Makefile 文件。 -h 帮助文档，显示所有的 make 选项。 -w 在处理 Makefile 前后显示工作目录。 在命令行参数中，可以通过指定目标 target 来告诉 make 需要编译的目标。如果命令行中未指定目标，则 make 会默认执行描述文件中定义的第一个目标。 通常，Makefile 中还定义有 clean 目标，用于清除编译过程产生的中间文件，例如： clean: rm -f *.o 当运行 make clean 时，会执行 rm -f *.o 命令，删除所有中间文件。 隐含规则 make 工具包括内置的隐含规则，这些规则定义了从不同的依赖文件生成特定类型目标的方法。Unix 系统支持基于文件扩展名的隐含规则，例如，将 .c 文件编译为 .o 文件： .c: .o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $ 系统中常见的文件扩展名及其含义如下表所示： 扩展名 含义 .o 目标文件 .c C 源文件 .f FORTRAN 源文件 .s 汇编源文件 .y Yacc-C 源语法 .l Lex 源语法 在早期 Unix 系统中也支持 Yacc-C 和 Lex 源语法。编译过程中，系统会首先在 Makefile 中查找与目标文件相关的 .C 文件。如果存在依赖的 .y 和 .l 文件，则会先将其转换为 .c 文件后再编译生成对应的 .o 文件；如果只有 .y 文件，系统则会直接编译该文件。 GNU make 不仅支持后缀规则，还支持另一类隐含规则，称为模式规则。这类规则更为通用，可以定义复杂的依赖规则。模式规则的语法类似于正则表达式，但目标名称前多了一个 % 符号。 例如，下面的模式规则定义了如何将任意 file.c 文件转换为 file.o： %.c: %.o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $ MakefileMakefile 是一个包含构建规则的文本文件，定义了项目中各个源文件之间的依赖关系及如何生成目标文件。make 依据 Makefile 中的规则来判断哪些文件需要重新编译，并执行相应命令生成目标文件。 规则Makefile 包含了一系列规则，每个规则定义了一个或多个目标文件及其所需的依赖文件和编译命令。规则的形式如下： target: prerequisites commands target 是规则的目标，prerequisites 是前置条件，可以是一个或多个文件。命令行中必须以 tab 键开头，以执行相关命令。 目标是必需的，而前置条件和命令是可选的，但至少需要有一个。每条规则表明两件事：构建目标的前置条件是什么，以及如何构建。 目标一个目标定义了一条规则。目标通常是文件名，表示 make 将要构建的对象，比如 a.txt。 目标可以是单个文件名，也可以是多个文件名，用空格分隔；除了文件名，目标还可以是某个操作的名称，这被称为伪目标（phony target）： clean: rm *.o 在上面的例子中，目标是 clean，这是一个伪目标，表示执行删除对象文件的操作。当运行 $ make clean 时，make 会去执行相应的命令。 需要注意的是，如果当前目录含有名为 clean 的文件，make 可能不会执行该命令，因为它认为目标已经存在，就不需要再构建。为了避免这种情况，可以通过以下方式声明 clean 为”伪目标”： .PHONY: cleanclean: rm *.o 一旦声明为伪目标，make 就不会检查是否存在名为 clean 的文件，而是在每次运行时都执行对应的命令。 .PHONY 还有其他很多内置目标名，可以查看手册。如果运行 make 命令时没有指定目标，默认执行 Makefile 中的第一个目标。例如： $ make 会执行 Makefile 第一个目标。 示例：执行多个目标.PHONY: cleanclean: rm *.o temp.PHONY: cleanall cleanobj cleandiffcleanall: cleanobj cleandiff rm programcleanobj: rm *.ocleandiff: rm *.diff 上述示例定义了多个目标的执行结构，clean 会删除中间文件，cleanall 则在执行 cleanobj 和 cleandiff 后删除最终程序文件。","categories":["2.语言","编译链接"]},{"title":"构建工具Make","path":"/2024/01/18/2-语言-编译链接-构建工具Make/","content":"Make 的基本概念与使用代码转化为可执行文件的过程称为编译（compile）。在编译的过程中，如何安排各个文件的编译顺序则称为构建（build）。在各种构建工具中，Make 是最常用的选择之一。自 1977 年问世以来，Make 主要被应用于 C 语言项目。然而，实际上，只要某个文件发生变化，任何项目都可以使用 Make 进行重新构建。 本文将逐步介绍 Make 命令的使用方法，适合没有基础的读者，只需掌握命令行操作即可轻松理解。参考资料主要包括 Isaac Schlueter 的《Makefile 文件教程》和《GNU Make 手册》。 一、Make 的概念“Make”在英语中的含义是“制作”。Make 命令正是基于这个含义，其目的在于生成指定的文件。例如，若要生成名为 a.txt 的文件，可以执行如下命令： $ make a.txt 然而，直接输入这条命令并不会产生任何效果，因为 Make 命令并不自知如何生成 a.txt，这就需要事先定义规则，告知 Make 如何调用其他命令以完成这项任务。 假设 a.txt 依赖于 b.txt 和 c.txt，它是通过将后两个文件合并的结果。那么，Make 需要了解如下规则： a.txt: b.txt c.txt cat b.txt c.txt a.txt 这段规则的意思是，首先确认 b.txt 和 c.txt 这两个源文件必须存在。接下来，执行 cat 命令将这两个文件的内容合并，并输出到新文件 a.txt 中。这意味着，执行 make a.txt 实际上包括两个步骤。 所有这类规则都记录在一个名为 Makefile 的文件中，Make 命令依赖这个文件进行构建。Makefile 文件也可以命名为 makefile，或通过命令行参数指定其他名称。 例如，可以通过以下命令指定使用名为 rules.txt 的文件： $ make -f rules.txt 或者： $ make --file=rules.txt 这条命令说明 Make 将依据 rules.txt 文件中的规则进行构建。 总之，Make 实际上是一个根据预定义的 Shell 命令进行构建的工具。它的规则简洁明了：用户设定需要构建的目标文件、文件所依赖的源文件，以及当源文件发生变化时如何重新构建目标文件。通过这些清晰的指示，Make 能够有效地支持自动化的构建过程，提升开发效率。 二、Makefile 文件的格式构建规则都写在 Makefile 文件里面，要学会如何使用 Make 命令，就必须掌握如何编写 Makefile 文件。 2.1 概述Makefile 文件由一系列规则（rules）构成。每条规则的形式如下： target : prerequisites[tab] commands 在这个格式中，第一行的冒号前面的部分称为”目标”（target），冒号后面的部分称为”前置条件”（prerequisites）。第二行必须由一个 tab 键起首，后面跟着”命令”（commands）。 目标是必需的，不可省略； 前置条件和命令都是可选的，但是两者之中至少必须存在一个。 每条规则明确了构建目标所需的前置条件，以及如何构建这个目标。以下将详细讲解每条规则的三个组成部分。 2.2 目标（target）一个目标（target）构成一条规则。目标通常表示文件名，指明 Make 命令所要构建的对象。例如，目标可以是 a.txt。目标可以是单个文件名，也可以是多个文件名，用空格分隔。 除了文件名，目标还可以是某个操作的名字，这种情况称为”伪目标”（phony target）： clean:\trm *.o 在上面的代码中，目标是 clean，它不是一个文件名，而是一个操作的名字，作用是删除对象文件。可以通过运行 $ make clean 来执行这个命令。 但是，如果当前目录中存在一个文件名为 clean，该命令将不会执行。因为 Make 会发现 clean 已存在，认为没有必要重新构建，就不会执行指定的 rm 命令。 为避免这种情况，可以明确声明 clean 为”伪目标”，写法如下： .PHONY: cleanclean:\trm *.o temp 通过声明 clean 为”伪目标”，Make 将不会检查 clean 文件是否存在，而是每次运行都执行对应命令。像 .PHONY 这样的内置目标名还有不少，详细信息可查阅官方手册。 如果在运行 Make 命令时没有指定目标，默认执行 Makefile 文件中的第一个目标： $ make 上面代码将执行 Makefile 文件的第一个目标。 2.3 前置条件（prerequisites）前置条件通常是一组文件名，多个文件名之间用空格分隔。它指定了”目标”是否需要重新构建的判断标准：只要有一个前置文件不存在，或者有更新（前置文件的最后修改时间戳比目标的时间戳新），”目标”就需要进行重新构建。 例如： result.txt: source.txt\tcp source.txt result.txt 在这段代码中，构建 result.txt 的前置条件是 source.txt。如果当前目录中存在 source.txt，make result.txt 命令将可以正常运行；否则，必须再写一条规则，来生成 source.txt。 source.txt:\techo this is the source source.txt 在上面的代码中，source.txt 后面没有前置条件，表示它与其他文件无关。只要此文件不存在，每次调用 make source.txt 都将生成这个文件。 $ make result.txt$ make result.txt 执行这两条命令时，第一次运行将首先生成 source.txt，然后生成 result.txt。第二次执行时，Make 会发现 source.txt 未发生变动（时间戳晚于 result.txt），因此不会执行任何操作，result.txt 同样不会被重新生成。 如果需要生成多个文件，常用下面的写法： source: file1 file2 file3 在上面的代码中，source 为一个伪目标，具有三个前置文件，并且没有对应的命令。执行 $ make source 命令后，将一次性生成 file1、file2 和 file3。这种方式相比于逐一生成各个目标，更加高效和便捷。 $ make file1$ make file2$ make file3 2.4 命令（commands）命令（commands）表示如何更新目标文件，由一行或多行的 Shell 命令组成。这些命令是构建”目标”的具体指令，其运行结果通常是生成目标文件。 每行命令之前必须有一个 tab 键。如果希望使用其他键，可以使用内置变量 .RECIPEPREFIX 进行声明。 .RECIPEPREFIX = all: echo Hello, world 在上面的代码中，通过 .RECIPEPREFIX 将大于号（）替代了 tab 键。因此，每行命令都以大于号作为前缀，而不是 tab 键。 需要注意的是：每行命令在单独的 Shell 中执行。这些 Shell 之间没有继承关系。例如： var-lost:\texport foo=bar\techo foo=[$$foo] 如果执行 make var-lost，将无法获取到 foo 的值，因为两行命令在不同的进程中执行。解决此问题的一个方法是将两行命令合并为一行，并用分号分隔： var-kept:\texport foo=bar; echo foo=[$$foo] 另一个解决办法是在换行符前加上反斜杠进行转义： var-kept:\texport foo=bar; \\\techo foo=[$$foo] 最后，可以使用 .ONESHELL: 命令来确保所有命令在同一 Shell 中执行： .ONESHELL: var-kept:\texport foo=bar;\techo foo=[$$foo] 三、Makefile 文件的语法3.1 注释在 Makefile 中，注释以井号（#）开始。任何在井号之后的内容都会被忽略，通常用于解释代码的意图或提供额外的信息。例如： # 这是注释result.txt: source.txt# 这也是注释cp source.txt result.txt # 这也是注释 上面的例子中，注释清楚地解释了各行命令的含义，帮助后续维护人员理解代码结构。 3.2 回声（echoing）在默认情况下，make 命令在执行每条命令时会先打印出这条命令的内容，这个过程称为“回声”（echoing）。例如，在下面的规则中： test:# 这是测试 执行命令 make test 时，将看到类似如下的输出： $ make test # 这是测试 如果希望抑制该回声，只需在命令前加上 @ 符号。例如： test:@# 这是测试 然后再次运行 make test，将不会有任何输出。通常情况下，保留命令的输出信息是有帮助的，但在处理注释或只需要显示的 echo 命令时使用 @ 符号是一个不错的选择，例如： test:@echo TODO 3.3 通配符通配符（wildcard）允许在 Makefile 中指定一组符合条件的文件名，类似于 Bash 中的写法。主要的通配符包括星号（*）、问号（?）和方括号（[...]）。例如，使用 *.o 可以表示当前目录下所有扩展名为 .o 的文件。 clean:\trm -f *.o 这条规则会删除当前目录中所有以 .o 作为后缀的文件，简化了清理工作的步骤。 3.4 模式匹配Make 命令支持对文件名进行类似正则表达式的模式匹配。主要符号为 %。假设当前目录下有 f1.c 和 f2.c 两个源码文件，如果希望将它们编译成各自的对象文件，可以使用如下模式匹配的规则： %.o: %.c 这条规则相当于手动列出所有文件的关系： f1.o: f1.cf2.o: f2.c 使用匹配符 %，可以大幅度减少冗余的规则定义，方便管理和更新。 3.5 变量和赋值符Makefile 支持自定义变量，使用等号（=）进行赋值操作。例如： txt = Hello Worldtest:\t@echo $(txt) 在这个例子中，变量 txt 被赋值为 Hello World，并通过 @echo 命令进行输出。变量的调用需使用 $( ) 包裹。若要调用 Shell 环境变量，则需要在美元符号前再加一个美元符号，以防止 Make 命令对其进行转义： test:\t@echo $$HOME 此外，变量的值可以指向其他变量，例如： v1 = $(v2) 这里面临一个问题：v1 的值是在定义时扩展（静态扩展）还是运行时扩展（动态扩展）？如果 v2 的值是动态的，则两种扩展方式的结果可能会出现差异。为了解决此类问题，Makefile 提供了四种赋值运算符（=, :=, ?=, +=），具体区别可参考相关资料，例如 StackOverflow。 VARIABLE = value：在执行时扩展，允许递归扩展。 VARIABLE := value：在定义时扩展。 VARIABLE ?= value：只有在该变量为空时才设置值。 VARIABLE += value：将值追加到变量的尾部。 3.6 内置变量（Implicit Variables）Make 命令支持一系列内置变量，例如 $(CC) 代表当前使用的编译器，$(MAKE) 代表当前使用的 Make 工具。这些变量旨在增强跨平台的兼容性。内置变量的详细清单可在手册中找到。以下是一个示例： output:\t$(CC) -o output input.c 在执行该目标时，$(CC) 会被替换为所选编译器的命令。 3.7 自动变量（Automatic Variables）Make 命令提供了一些自动变量，这些变量的值与当前规则密切相关，主要包括以下几种： $@：指代当前目标，即 Make 命令正在构建的那个目标。 例如，在如下规则中： a.txt b.txt:\ttouch $@ 这里的 $@ 分别在执行时指向 a.txt 和 b.txt。 $：指代第一个前置条件。 示例： a.txt: b.txt c.txt\tcp $ $@ 这里，$ 会替换为 b.txt，即复制 b.txt 到 a.txt。 $?：指代比目标更新的所有前置条件。 $^：指代所有前置条件。 $*：表示与模式符 % 匹配的部分。 $(@D) 与 $(@F)：分别指向$@的目录名和文件名。 例如： dest/%.txt: src/%.txt\t@[ -d dest ] || mkdir dest\tcp $ $@ 在这个例子中，src/ 目录下的文本文件将被复制到 dest/ 目录中，前提是先检查 dest/ 目录是否存在。 3.8 判断和循环Makefile 也可以使用类似 Bash 的语法进行条件判断和循环。例如： ifeq ($(CC), gcc)libs = $(libs_for_gcc)elselibs = $(normal_libs)endif 此代码用于判断当前的编译器是不是 gcc，然后根据判断结果选择不同的库文件。此外，循环的写法如下： LIST = onetwo threeall:\tfor i in $(LIST); do \\ echo $$i; \\\tdone 这个循环会依次输出 onetwo 和 three。 3.9 函数Makefile 中也可以定义和调用函数。函数的调用格式为 $(function arguments)。Makefile 提供了多种内置函数供使用，以下是几个常用的示例： shell 函数：执行 Shell 命令。 srcfiles := $(shell echo src/00..99.txt) wildcard 函数：在 Makefile 中替代 Bash 的通配符。 srcfiles := $(wildcard src/*.txt) subst 函数：用于文本替换。 $(subst from, to, text) 例如，将字符串 feet on the street 中的 ee 替换为 EE。 $(subst ee, EE, feet on the street) patsubst 函数：用于模式替换。 $(patsubst pattern, replacement, text) 例如，将文件名 x.c c bar.c 替换为 x.c.o bar.o。 替换后缀名函数：格式为 变量名 + 冒号 + 后缀名替换规则，是 patsubst 函数的一种简写形式。 min: $(OUTPUT:.js=.min.js) 这表示将变量 OUTPUT 中的后缀 .js 替换为 .min.js。 四、Makefile 的实例（1）执行多个目标定义多个伪目标，以便在清理过程中可以同时删除许多不同类型的文件： .PHONY: clean all cleanobj cleandiffcleanall: clean obj cleandiff\trm programcleanobj:\trm *.ocleandiff:\trm *.diff 通过调用 make cleanall，会执行所有清理目标，全面删除不同后缀的文件，方便项目管理。 （2）编译 C 语言项目使用 Makefile 编译 C 语言项目的基本结构示例如下： edit: main.o kbd.o command.o display.o\tcc -o edit main.o kbd.o command.o display.omain.o: main.c defs.h\tcc -c main.ckbd.o: kbd.c defs.h command.h\tcc -c kbd.ccommand.o: command.c defs.h command.h\tcc -c command.cdisplay.o: display.c defs.h\tcc -c display.cclean:\trm edit main.o kbd.o command.o display.o.PHONY: edit clean 在这个例子中，edit 目标依赖于多个模块的对象文件，编译时会自动处理这些依赖关系，从而实现将源代码编译为可执行文件的过程。清理目标则提供了方便快速的删除编译生成文件的方式。","categories":["2.语言","编译链接"]},{"title":"编译和链接","path":"/2024/01/17/2-语言-编译链接-编译和链接/","content":"gcc 编译过程GCC（GNU Compiler Collection）是一个强大的编译器，广泛应用于 Linux 环境中。GCC 负责将 C 语言源代码编译成可执行文件，许多 GNU 工具都是通过它完成编译的。以下是 GCC 的编译过程步骤和详细示例。 编译过程步骤 预处理源文件经过预处理，生成以 .i 结尾的中间文件。可以使用 -E 参数来生成这个文件。这个阶段主要处理 #include 指令引入的头文件和宏定义，将它们插入到源代码中。 示例： gcc -E hello.c -o hello.i 生成 hello.i 后，查看文件内容，可以发现除了源代码外，还有大量的头文件和宏定义内容。 编译从预处理文件生成汇编语言文件，使用 -S 参数。此步骤将源代码翻译成汇编语言，这些文件通常以 .s 后缀存储。 示例： gcc -S hello.i -o hello.s 在 hello.s 文件中，可以找到生成的汇编代码，可能会涉及到处理器架构相关的指令。 汇编汇编语言文件经过汇编，生成目标文件 .o。可以使用 -c 参数来进行这一步。目标文件包含机器代码，但尚未链接。 示例： gcc -c hello.s -o hello.o 查看 hello.o 文件时，会发现其中包含了二进制码，计算机能够理解的格式。 链接将目标文件链接，生成最终的可执行文件。这一过程涉及到将程序的各个部分整合在一起，包括所有引用和依赖。 示例： gcc hello.o -o hello 执行这个步骤后，便可以得到可执行的 hello 文件。 无论是在开发过程中，还是日常调试，使用 gcc hello.c -o hello 可以一步到位，自动执行所有上述步骤。 静态链接库和动态链接库静态链接库静态链接库是在程序编译时就被加载进来，形成一个整体。这使得最终生成的可执行文件体积更大，而且静态库无法共享。 动态链接库动态链接库则是在程序运行时被加载，这种方式允许多个程序共享同一段代码。 示例考虑以下的三个源文件，其中 hello.c 为独立文件，如果直接编译 hello.c，会因为缺少 main 函数而报错。解决方案有： 编译成对象文件并链接首先，将源文件编译为 .o 文件，然后进行链接，生成可执行文件。 使用静态链接库在 Linux 平台，库文件一般存放在 /usr/lib 和 /lib 目录。静态库以 libxxxx.a 为命名规则，动态库以 libxxxx.so.major.minor 命名，其中 major 和 minor 分别表示主版本号和副版本号。 静态库的生成可分为两步： 先编译源文件生成 .o 文件，每个文件中都有符号表。 使用 ar 命令将多个 .o 文件打包成一个 .a 文件，形成静态库。 示例： ar rcs libmyhello.a hello.o 使用时，通过链接器连入静态库。调用时，不需要指定库前缀和后缀，例如 -lmyhello，就可以链接 libmyhello.a。 gcc -o hello main.c -static -L. -lmyhello 其中 -static 选项表示使用静态链接库，-L. 选项指定当前路径为静态库搜索路径。 动态链接库生成动态链接库的过程不同。首先需要创建一个中间文件，使用 -shared 和 -fPIC 选项标记。-fPIC 表示生成的代码与特定内存地址无关，便于重用。 示例： gcc -shared -fPIC -c hello.cgcc -shared -fPIC -o libmyhello.so hello.o 最后，通过以下命令生成可执行文件： gcc -o hello main.c -L. -lmyhello 运行时，如果程序找不到 libmyhello.so，需要将其放在 /lib 或 /usr/lib 下，或在 /etc/ld.so.conf 文件中添加库文件目录，并运行 ldconfig 命令更新库缓存。","categories":["2.语言","编译链接"]},{"title":"CppCheck","path":"/2024/01/16/2-语言-调试输出-CppCheck/","content":"CppCheck 的安装和使用CppCheck 概述CppCheck 是一个旨在检测 CC++ 代码缺陷的静态检查工具。与 CC++ 编译器以及其他分析工具不同，CppCheck 专注于识别那些编译器无法捕捉到的 bug，而不会干扰于语法错误的检查。简单来说，静态代码检查是一种利用工具来评估们编写的代码是否安全且稳健，是否存在潜在的问题。 例如，考虑下面这段代码： int n = 10; char* buffer = new char[n]; buffer[n] = 0; 尽管这段代码符合语法规范，CppCheck 就可能会发出警告，提示此行代码可能导致缓冲区溢出。这种溢出的问题通常是因为数组下标超出范围，可能会导致程序崩溃或者数据损坏。CppCheck 在线静态分析中提供了更严格的检测，帮助开发者在编译之前识别和修复潜在的错误，这无疑是提升代码质量的一大利器。 目前比较流行的 CC++ 静态代码检查工具除了 CppCheck 外，还有 pc-lint 等。虽然 pc-lint 作为老牌工具其功能强大，但它是收费软件，并且配置上相对复杂。而 CppCheck 则是一个免费的开源软件，使用起来更加友好，适合广泛的开发者群体。 CppCheck 安装和使用要安装 CppCheck，请访问 CppCheck 官网 下载最新版本。CppCheck 的使用方式有两种，分别为 GUI 方式和命令行方式。 GUI 方式安装完成后，可以直接使用 cppcheck-gui 来检测代码，界面如下： 在界面中，可以选择要检查的文件或目录，设置检查选项，然后一键检测，非常直观方便。 命令行方式也可以通过命令行快速运行 CppCheck，命令行界面示例如下： 在命令行中，可以使用不同的参数来定制检查过程。例如，可以使用 --enable=style 来检查代码风格问题，或使用 --output-file=result.txt 将输出结果保存到文件中。 集成到 IDE 开发环境中使用Visual Studio (VS)可以通过以下步骤将 CppCheck 嵌入到 Visual Studio 中，方便地对项目中的文件进行检查，并支持错误的跳转功能。具体操作如下： 在 Visual Studio 中，打开菜单：工具 外部工具。 点击”添加”按钮。 在弹出的窗口中，设置标题，例如 Cppcheck。 设置命令为 C:\\Program Files (x86)\\Cppcheck\\cppcheck.exe（请根据实际安装路径调整）。 在参数框中输入：--quiet --verbose --template=vs $(ItemPath)。 在初始目录框中设置为 $(ItemDir)。 确保选中”使用输出窗口”复选框。 通过反复点击”上移”按钮，将该命令移动到列表顶部，以便更方便地识别。 点击”确定”保存设置。 这样一来，在 Visual Studio 中就可以通过工具菜单轻松调用 CppCheck 进行代码检查。 Qt Creator在 Qt Creator 中，同样可以通过简单的步骤将 CppCheck 集成到开发环境中。具体步骤如下： 打开 Qt Creator，点击菜单：工具 外部 配置... 添加。 在弹出的对话框中，填写如下参数： 命令：设置为 CppCheck 的可执行文件路径。 参数：可以输入 --enable=all 来启用所有检查。 初始目录：设置为项目的根目录。 以下是设置后的对话框示例： 完成设置后，可以通过菜单 工具 外部 CppCheck 来开始检查指定目录下的代码文件，确保开发过程中的代码质量。","categories":["2.语言","调试输出"]},{"title":"GDB调试","path":"/2024/01/15/2-语言-调试输出-GDB调试/","content":"GDB 调试指南GDB（GNU Debugger）是一种强大的调试工具，可以帮助开发人员逐步检查程序运行过程中的行为。使用 GDB，可以设置断点，单步执行代码，并查看变量的值，确保程序按照预期运行。 重新编译程序在使用 GDB 调试之前，程序必须以调试模式重新编译。这意味着需要在编译命令中添加 -g 选项。例如： gcc -g main.c -o main.out 执行上述命令后，会生成一个可以使用 GDB 进行调试的可执行文件 main.out。确保不要删除源代码文件 main.c，因为 GDB 在运行时需要源代码来显示相关的行号和变量信息。如若删除，GDB 将无法正确执行断点和单步调试。 启动调试开始调试 main.out 文件可以使用以下命令： gdb ./main.out 或者： gdb main.out 一旦进入 GDB 环境，可以使用 list 或其简写 l 命令列出当前调试程序的源代码。默认情况下，系统会显示当前程序的前 10 行代码。按回车键可以显示接下来的代码行。 断点与单步调试要启动程序并设置第一个断点，可以使用 start 命令。当程序启动时，GDB 会在 main() 函数的默认断点处暂停。例如，它会反馈如下信息： 默认断点1在main()处，具体行数为本文件的第13行 假设第 13 行的代码是： int a = 5; 要查看内存中变量的值，可以使用 print a 或其简写 p a。通过这个命令，可以检查变量 a 的当前值。由于 int a = 5; 这一指令尚未执行，因此在这之前， a 的值将是未初始化状态下的默认值。 在单步执行中，有几个重要的命令： n 或 next: 执行下一条指令。这个命令仅推进到下一行，不进入调用的函数。 s 或 step: 执行当前行并进入函数内部。如果当前行是一个函数调用，它会让进入该函数。 例如，当程序运行到一个函数时，使用 step 命令后，GDB 会显示当前被调用的函数的参数已被赋值，并且会定位到参数对应行。 查看函数调用堆栈使用 bt 命令可以查看当前函数的调用堆栈。每个函数都有自己的编号和当前执行行。例如，可能会得到如下输出： 编号0 change 函数 定位到第6行编号1 main函数 定位到第15行 这里的编号 0 表示当前在 change 函数，编号 1 表示可以跳转回 main 函数。 f num: 切换到指定的堆栈帧。例如，通过输入 f 1，可以返回到 main 函数并查看其位置。 退出调试完成调试后，输入 q 可以安全退出 GDB。 使用 GDB 调试的案例解析在调试过程中，可能会使用诸如取地址符 和十六进制符号 0x 等特性。例如，如果有如下变量赋值： int a = b; // 这将存储b的地址 在命令行调试中，可能看到下列内存地址的输出来反馈参数的值： a = 0xbffff064 // 变量a的地址b = 0xbffff068 // 变量b的地址 通过如下语句，将内存地址中的值赋给变量： int temp = *a; // temp现在为5，即a指向的值int temp = a; // temp现在为指向b的内存地址0xbffff064 使用 x 命令查看内存内容也是一种常见操作。例如，命令： x/3d 0x7fffffffde14 该命令将输出内存地址 0x7fffffffde14 处的连续 3 个值，并以十进制格式展示。 通过这些命令和操作，可以深入了解程序的内部运作，提高调试效率，确保代码的正确性与稳定性。 段错误借助 GDB 查找方法在调试程序时， segment fault（段错误）是常见且令人沮丧的问题之一。可以使用 gdb（GNU 调试器）来帮助定位和解决这些问题。以下是使用 gdb 和 ulimit 命令的详细指南，可以帮助发现和解决段错误。 使用 ulimit 设置资源限制ulimit 命令在 Unix 和 Linux 系统中用于控制 shell 启动进程所使用的资源。理解如何设置和查看这些限制至关重要，因为某些资源限制可能会导致程序意外崩溃或无法正常运行。 资源限制选项 -H：设置硬资源限制。硬限制是系统允许的最大值，只有超级用户可以修改。 -S：设置软资源限制。软限制是可以随时更改的，用户可以随意调整以适应其需求。 -a：显示当前所有资源的限制，包括文件描述符数量、堆栈大小等。 -c size：设置 core 文件（程序崩溃时生成的转储文件）的最大值，单位为 blocks。核心转储文件对于调试段错误非常有用。 -d size：设置数据段的最大值，单位为 kbytes。如果数据段超出此限制，程序可能会因内存不足而发生段错误。 -f size：设置创建文件的最大值，单位为 blocks。这可以防止程序生成过多或过大的临时文件。 -l size：设置可以在内存中锁定进程的最大值，单位为 kbytes。过高的锁定内存可能会消耗系统资源。 -m size：设置可以使用的常驻内存的最大值，单位为 kbytes。这有助于限制程序的内存使用。 -n size：设置内核可以同时打开的文件描述符的最大数量，单位为 n。如果此限制过低，程序可能无法开启新的文件或套接字。 -p size：设置管道缓冲区的最大值，单位为 kbytes。缓冲区限制可以影响输入输出的性能。 -s size：设置堆栈大小的最大限制，单位为 kbytes。若堆栈大小不够，可能会导致栈溢出。 -t size：设置 CPU 使用时间的最大限制，单位为 seconds。过高的使用时间可以影响系统性能。 -v size：设置虚拟内存的最大值，单位为 kbytes。设置虚拟内存的限制可以帮助避免内存溢出。 -u 程序数目：限制用户可开启的程序最大数目。这个限制取决于用户的机器和特性。 查看和设置资源限制要查看当前所有的资源限制，可以执行： ulimit -a 这将列出所有相关设置及其当前值，比如： core file size (blocks -c) unlimiteddata seg size (kbytes -d) 2097152file size (blocks -f) unlimited... 如果希望程序生成核心文件，从而方便后续调试，可以设置核心文件的最大值为无限制： ulimit -c unlimited 再次执行 ulimit -a 确认设置已经生效。 使用 GDB 调试程序当程序发生段错误时，生成的核心转储文件至关重要。使用 gdb 工具，可以方便地分析该文件并寻找导致崩溃的原因。 打开 gdb首先，使用如下命令打开的可执行文件和生成的核心文件： gdb xxx core 其中，xxx 是的可执行程序的名称，core 是生成的核心转储文件。成功启动后，gdb 会加载相关信息。 查看段错误要查看导致段错误的具体位置，可以使用以下命令： bt bt 表示 “backtrace”，这个命令会显示函数调用栈的详细信息。在调试过程中，这个信息可以帮助确定哪一部分代码出问题了。 列出出错位置代码如果想查看出错的具体源代码位置，可以使用： list 这个命令会显示当前所在函数的源码，帮助快速定位问题所在。 通过结合使用 ulimit 和 gdb，将能够更深入地了解并解决段错误，使的程序更加稳定和可靠。 GDB 简易调试方法GDB 可以对程序进行断点调试，单步调试，如果用 gdb 调试，需要对程序重新编译，格式为: gcc –gmain.c –o main.out 这样生成的 main.out 才能用 gdb 调试。 需要注意的是，在调试的时候不能删除原代码文件，即 main.c ，如果将 main.c 删除了，gdb 依然不支持断点、单步调试。 用 gdb 调试程序格式： gdb ./main.out 或gdb main.out 列出当前调试程序的部分（前 10 行）源代码 list 或者 l 再按一次回车（默认执行上一次命令），继续列出下面的源代码 单步调试命令： start 执行后显示：默认断点 1 在 main()处，断点处指令为： int a=5; 查看内存中变量的值 print a 简写 p a 回车显示 a 的值 因为 int a=5; 指令还没有执行完毕，所以 a 为编译器给的默认值。 下一条指令 n //n----next 执行一行源代码并进入函数内部 s //s----step 当前被调用函数将实参赋于形参，并定位 查看函数堆栈 bt 编号 0 change 函数 定位到第 6 行 编号 1 main 函数 定位到第 15 行 编号 0 在最上层，所以当前在 change 函数中 f 编号可以定位到哪一层函数 f(frame)切换调用的上下文，进入相应的栈里，使用该命令可以打印栈层编号，当前的函数名，函数参数值，函数所在的文件及行号，函数执行到的语句等等； f 1 进入到编号 1 的函数中，即 main 函数 并定位到 15 行的那条语句 q 退出调试 常用的 GDB 指令常见断点设置与删除命令 命令格式 作用 break + 设置断点的行号 用于在程序中对应行设置断点 tbreak + 行号或函数名 设置临时断点，到达后被自动清除 break + filename + 行号 用于在指定文件的对应行设置断点 break + 0x… 用于在内存某一位置处暂停 break + 行号 + if + 条件 用于设置条件断点，在循环中使用非常方便 info breakpoints/watchpoints 查看断点、观察点的情况 clear + 要清除断点的行号 用于清除对应行的断点 delete + 要清除断点的编号 清除断点和自动显示的表达式（区别：clear 提示行号，delete 提示编号） disable + 断点编号 让所有断点暂时失效（多个编号可用空格分隔） enable + 断点编号 与 disable 相反，使断点重新生效 awatch + 变量 设置观察点，变量被读或写时程序暂停 rwatch + 变量 设置观察点，变量被读时程序暂停 watch + 变量 同 awatch 数据相关命令 命令格式 作用 display + 表达式 显示表达式的值（程序到断点时自动显示） info display 显示当前所有需要显示的表达式情况 delete + display 编号 删除某个要显示的表达式 disable + display 编号 使某个要显示的表达式暂时无效 enable + display 编号 恢复 disable display 命令失效的表达式 undisplay + display 编号 结束某个表达式值的显示 whatis + 编号 查看某个表达式的数据类型 print（p）+ 变量或表达式 打印变量或表达式的值 set + 变量 = 变量值 改变程序中某个变量的值 运行环境相关命令 命令格式 作用 set args 设置运行参数 show args 显示运行参数 set width + 数目 设置 GDB 的行宽 cd + 工作目录 切换工作目录 run 程序开始执行 step（s） 进入式单步执行（进入子函数） next（n） 非进入式单步执行（不进入子函数） finish 一直运行到函数返回 until + 行数 运行到指定行号 continue（c） 执行到下一个断点或程序结束 return 返回值 改变程序流程，结束当前函数并返回指定值 call + 函数 在当前位置执行指定的函数 堆栈相关命令 命令格式 作用 back 或 bt 打印栈帧指针（可指定要打印的个数） frame 打印栈帧 info reg 查看寄存器使用情况 info stack 查看堆栈情况 up 跳到上一层函数 down 跳到下一层函数（与 up 相对）","categories":["2.语言","调试输出"]},{"title":"代码日志输出","path":"/2024/01/12/2-语言-调试输出-代码日志输出/","content":"宏定义通过一个宏定义把要打印的信息写到一个日志文件中，不仅可以记录程序每次运行的状态便于 debug，而且在发布时只需要注释掉宏定义而不必删除每一个使用该宏的地方，不会出现因删除代码而出现的错误。 宏还可以加一个参数传入文件的路径，就可以自定义日志文件的位置。 #define TRACEOUT(p) \\ \\time_t timeval; \\timeval=time(NULL); \\FILE *log; \\log = fopen(log.txt,a);\\fprintf(log,%s -- %s ,p,ctime(timeval));\\fclose(log); \\#define LOG_DBG(fmt,...) \\do \\fprintf(stdout,[DEBUG] %s:%d - fmt , \\__FILE__,__LINE__, ##__VA_ARGS__); \\ while(0)#define LOG_ERR(fmt,...) \\do \\fprintf(stderr,[ERROR] %s:%d - fmt , \\__FILE__,__LINE__, ##__VA_ARGS__); \\ while(0)int main()\tTRACEOUT(hello);\tLOG_DBG(hello);\tLOG_ERR(hello);\treturn 0; 函数#include stdarg.h#include stdio.h#include time.h#define LOG_FILE ./a.log#define LOG_DEFAULT( fmt, ... ) log_out( LOG_FILE, __FILE__, __LINE__, fmt, ##__VA_ARGS__)#define LOG_TOXFILE( flog, fmt, ... ) log_out( flog, __FILE__, __LINE__, fmt, ##__VA_ARGS__) int log_out(char* flog, char *file, int line, char* fmt, ...) va_list arg; char pre[128], tmp[1024]; long clock; struct tm *c_ptr; FILE *fp; time( clock ); c_ptr = localtime(clock); sprintf( pre, [%04d%02d%02d%02d%02d%02d_%s.%d], c_ptr-tm_year+1900, c_ptr-tm_mon+1, c_ptr-tm_mday, c_ptr-tm_hour, c_ptr-tm_min, c_ptr-tm_sec, file, line ); va_start(arg, fmt); vsprintf(tmp, fmt, arg); va_end (arg); //log to stdout if( !flog ) printf( %-32.32s %s, pre, tmp ); return 0; //log to file if( !(fp = fopen( flog, at ) ) ) return -1; fprintf( fp, %-32.32s %s, pre, tmp ); fclose( fp ); return 0; 调用方法： LOG_DEFAULT 日志输出到默认的日志文件 LOG_TOXFILE 日志输出到指定的日志文件，参数是 0，则日志打印到标准输出","categories":["2.语言","调试输出"]},{"title":"代码注释","path":"/2024/01/11/2-语言-调试输出-代码注释/","content":"注释部分函数部分 function/*************************************************Function: // 函数名称Description: // 函数功能、性能等的描述Calls: // 被本函数调用的函数清单Called By: // 调用本函数的函数清单Table Accessed: // 被访问的表（此项仅对于牵扯到数据库操作的程序）Table Updated: // 被修改的表（此项仅对于牵扯到数据库操作的程序）Input: // 输入参数说明，包括每个参数的作// 用、取值说明及参数间关系。Output: // 对输出参数的说明。Return: // 函数返回值的说明Others: // 其它说明*************************************************/ 全局变量 global variable/* The ErrorCode when SCCP translate *//* Global Title failure, as follows */ // 变量作用、含义/* 0 － SUCCESS 1 － GT Table error *//* 2 － GT error Others － no use */ // 变量取值范围/* only function SCCPTranslate() in *//* this modual can modify it, and other *//* module can visit it through call *//* the function GetGTTransErrorCode() */ // 使用方法 头文件 .h/************************************************************Copyright (C), 1988-1999, Huawei Tech. Co., Ltd.FileName: test.cppAuthor: Version : Date:Description: // 模块描述Version: // 版本信息Function List: // 主要函数及其功能1. -------History: // 历史修改记录author time version descDavid 96/10/12 1.0 build this moudle***********************************************************/ 配置文件 .cfg/*************************************************Copyright (C), 1988-1999, Huawei Tech. Co., Ltd.File name: // 文件名Author: Version: Date: // 作者、版本及完成日期Description: // 用于详细说明此程序文件完成的主要功能，与其他模块// 或函数的接口，输出值、取值范围、含义及参数间的控// 制、顺序、独立或依赖等关系Others: // 其它内容的说明Function List: // 主要函数列表，每条记录应包括函数名及功能简要说明1. ....History: // 修改历史记录列表，每条修改记录应包括修改日期、修改// 者及修改内容简述1. Date:Author:Modification:2. ...*************************************************/ DoxygenDoxygen 是一个程序的文件产生工具，可将程序中的特定批注转换成为说明文件。通常在写程序时，或多或少都会写上批注，但是对于其它人而言，要直接探索程序里的批注，与打捞铁达尼号同样的辛苦。大部分有用的批注都是属于针对函式，类别等等的说明。所以，如果能依据程序本身的结构，将批注经过处理重新整理成为一个纯粹的参考手册，对于后面利用的程序代码的人而言将会减少许多的负担。不过，反过来说，整理文件的工作对于来说，就是沉重的负担。 Doxygen 就是在写批注时，稍微按照一些它所制订的规则。接着，他就可以帮产生出漂亮的文档了。 因此，Doxygen 的使用可分为两大部分: 特定格式的批注撰写 利用 Doxygen 的工具来产生文档 目前 Doxygen 可处理的程序语言包含： CC++ Java IDL (Corba, Microsoft 及 KDE-DCOP 类型) 而可产生出来的文档格式有： HTML XML LaTeX RTF Unix Man Page而其中还可衍生出不少其它格式。HTML 可以打包成 CHM 格式，而 LaTeX 可以透过一些工具产生出 PS 或是 PDF 文档。 安装 安装 Doxygen 安装 graphviz graphviz 是一个由 ATT 实验室启动的开源工具包，用于绘制 DOT 语言脚本描述的图形。Doxygen 使用 graphviz 自动生成类之间和文件之间的调用关系图，如不需要此功能可不安装该工具包。 安装 Windows Help Workshop Doxygen 使用这个工具可以生成 CHM 格式的文档。 配置Doxygen 产生文档可以分为三个步骤。 在程序代码中加上符合 Doxygen 所定义批注格式 使用 Doxywizard 进行配置 使用 Doxygen 来产生批注文档 撰写正确格式的批注并非所有程序代码中的批注都会被 Doxygen 所处理。必需依照正确的格式撰写。原则上，Doxygen 仅处理与程序结构相关的批注，如 Function，Class ，档案的批注等。对于 Function 内部的批注则不做处理。Doxygen 可处理下面几种类型的批注。 JavaDoc 类型： /*** ... 批注 ...*/ Qt 类型： /*!* ... 批注 ...*/ 单行型式的批注： /// ... 批注 ... 或 //! ... 批注 ... 要使用哪种型态完全看自己的喜好。以笔者自己来说，大范围的注解会使用 JavaDoc 型的。单行的批注则使用”“ 的类型。此外，由于 Doxygen 对于批注是视为在解释后面的程序代码。也就是说，任何一个批注都是在说明其后的程序代码。如果要批注前面的程式码则需用下面格式的批注符号。 /*! ... 批注 ... *//** ... 批注 ... *///! ... 批注 .../// ... 批注 ... 上面这个方式并不适用于任何地方，只能用在 class 的 member 或是 function 的参数上。举例来说，若有下面这样的 class。 class MyClass public: int member1 ; int member2: void member_function();; 加上批注后，就变成这样： /*** 的自订类别说明 ...*/class MyClass public: int member1 ; /// 第一个 member 说明 ... int member2: /// 第二个 member 说明 ... int member_function(int a, int b);;/*** 自订类别的 member_funtion 说明 ...** @param a 参数 a 的说明* @param b 参数 b 的说明** @return 传回 a+b。*/int MyClass::member_function( int a, int b )\treturn a+b ; 当使用 Doxygen 产生说明文档时，Doxygen 会帮 parsing 的程式码。并且依据程序结构建立对应的文件。然后再将的批注，依据其位置套入于正确的地方。可能已经注意到，除了一般文字说明外，还有一些其它特别的指令，像是@param 及@return 等。这正是 Doxygen 另外一个重要的部分，因为一个类别或是函式其实都有固定几个要说明的部分。为了让 Doxygen 能够判断，所有就必需使用这些指令，来告诉 Doxygen 后面的批注是在说明什么东西。Doxygen 在处理时，就会帮把这些部分做特别的处理或是排版。甚至是制作参考连结。 首先，先说明在 Doxygen 中对于类别或是函数批注的一个特定格式。 /*** class 或 function 的简易说明...** class 或 function 的详细说明...* ...*/ 上面这个例子要说的是，在 Doxygen 处理一个 class 或是 function 注解时，会先判断第一行为简易说明。这个简易说明将一直到空一行的出现。或是遇到第一个”.” 为止。之后的批注将会被视为详细说明。两者的差异在于 Doxygen 在某些地方只会显示简易说明，而不显示详细说明。如：class 或 function 的列表。 另一种比较清楚的方式是指定@brief 的指令。这将会明确的告诉 Doxygen，何者是简易说明。例如： /*** @brief class 或 function 的简易说明...** class 或 function 的详细说明...* ...*/ 除了这个 class 及 function 外，Doxygen 也可针对档案做说明，条件是该批注需置于档案的前面。主要也是利用一些指令，通常这部分注解都会放在档案的开始地方。如： /*! \\file myfile.h\\brief 档案简易说明详细说明.\\author 作者信息*/ 如所见，档案批注约略格式如上，请别被 \\ 所搞混。其实，\\ 与”@” 都是一样的，都是告诉 Doxygen 后面是一个指令。两种在 Doxygen 都可使用。笔者自己比较偏好使用”@”。 接着来针对一些常用的指令做说明：@file 档案的批注说明。Doxygen 所支持的指令很多，有些甚至是关于输出排版的控制。可从 Doxygen 的使用说明中找到详尽的说明。 下面准备一组 example.h 及 example.cpp 来说明 Doxygen 批注的使用方式：example.h: @author 作者的信息 @brief 用于 class 或 function 的批注中，后面为 class 或 function 的简易说明。 @param 格式为 @param arg_name 参数说明,主要用于函式说明中，后面接参数的名字，然后再接关于该参数的说明。 @return 后面接函数传回值的说明。用于 function 的批注中。说明该函数的传回值。 @retval 格式为 @retval value 传回值说明,主要用于函式说明中，说明特定传回值的意义。所以后面要先接一个传回值。然后在放该传回值的说明。 /*** @file 本范例的 include 档案。** 这个档案只定义 example 这个 class。** @author garylee@localhost*/#define EXAMPLE_OK 0 /// 定义 EXAMPLE_OK 的宏为 0。/*** @brief Example class 的简易说明** 本范例说明 Example class。* 这是一个极为简单的范例。**/class Example private: int var1 ; /// 这是一个 private 的变数\tpublic: int var2 ; /// 这是一个 public 的变数成员。 int var3 ; /// 这是另一个 public 的变数成员。 void ExFunc1(void); int ExFunc2(int a, char b); char *ExFunc3(char *c) ;; example.cpp: /*** @file 本范例的程序代码档案。** 这个档案用来定义 example 这个 class 的* member function。** @author garylee@localhost*//*** @brief ExFunc1 的简易说明** ExFunc1 没有任何参数及传回值。*/void Example::ExFunc1(void)\t// empty funcion./*** @brief ExFunc2 的简易说明** ExFunc3()传回两个参数相加的值。** @param a 用来相加的参数。* @param b 用来相加的参数。* @return 传回两个参数相加的结果。*/int ExFunc2(int a, char b)\treturn (a+b);/*** @brief ExFunc3 的简易说明** ExFunc3()只传回参数输入的指标。** @param c 传进的字符指针。* @retval NULL 空字符串。* @retval !NULL 非空字符串。*/char * ExFunc2(char * c)\treturn c;","categories":["2.语言","调试输出"]},{"title":"使用Valgrind发现内存泄露","path":"/2024/01/10/2-语言-调试输出-使用Valgrind发现内存泄露/","content":"Valgrind 简介Valgrind 是一款强大的内存调试工具，可在 Linux 环境下使用，兼容多种架构，包括 x86、x86_64 和 ppc32。它专门设计用于对编译后的二进制程序进行内存监测，主要关注 C 和 C++ 程序中的动态内存管理，比如 C 语言中的 malloc 和 free，以及 C++ 中的 new 和 delete。这款工具的最大优势在于它能够有效识别和定位内存泄漏问题，这一问题通常会导致程序在运行时消耗过多内存，甚至引发崩溃。 Valgrind 是一套在 Linux 环境下运行的开源仿真调试工具的集合，采用 GPL V2 许可证。其核心部件称为 内核，这个内核充当了一个框架，为其他基于内核的调试工具提供服务和支持。在这个框架中，内核模拟了 CPU 环境，使得不同的工具可以在这种虚拟环境中执行。 此外，Valgrind 的其他工具类似于 插件，它们利用内核提供的服务来完成特定的内存调试任务。这些工具各有其独特的功能，可以帮助开发者提高程序的稳定性和性能。以下是几个重要的工具及其详细作用： Memcheck：这是 Valgrind 中最为常用的工具，负责检测程序中的内存泄漏、未初始化内存读取以及无效的内存访问等问题。想象一下，当一个程序在运行时动态分配了一块内存以存储用户输入的数据，但在程序结束时没有正确释放这块内存，导致内存持续被占用。Memcheck 可以通过提供详细的错误报告，帮助开发者准确定位这些内存泄漏。例如，开发者可能会看到类似于”在函数 foo() 中，分配的内存未被释放”的报告，这让他们可以追踪问题所在并及时修复，避免程序长时间运行导致的性能下降。 Cachegrind：这个工具用于分析程序的缓存使用情况，提供缓存命中率和踩踏率等信息，帮助开发者优化程序的性能。缓存命中率指的是程序对于已经存储在缓存中的数据的访问，若缓存命中率较高，程序的运行将更为迅速而高效；相反，高踩踏率则显示程序频繁地访问未缓存的数据，导致性能下降。例如，若 Cachegrind 反馈缓存踩踏率过高，开发者可以根据反馈重新考量数据的访问模式，或重构数据结构，以提升缓存效率。这种微调常常能显著提高程序的运行速度。 Callgrind：用于性能分析，记录程序函数的调用次数及调用关系。通过对函数调用的详细记录，开发者可以方便地发现运行中的瓶颈。例如，如果某个函数被调用的次数异常增多，它很可能成为程序的性能瓶颈，开发者就可以针对这一点进行深入的优化，从而提升整体性能。这种方式类似于在交通流量中找出拥堵路段，修复这些”堵点”可以大幅改善整体流畅度。 Helgrind：专门检查多线程程序中的竞争问题，它帮助开发者识别在访问共享资源时可能发生的竞争条件。假设一个多线程程序中多个线程同时尝试更新同一数据，若没有正确的同步机制，可能会导致数据不一致或错误的结果。Helgrind 能够监测到这些潜在的竞争情况，提醒开发者注意并采取适当的锁机制来确保数据的完整性。 Massif：它主要用于分析程序的堆栈使用情况，帮助开发者识别内存使用的热点。Massif 通过定期捕获程序的堆内存使用情况绘制内存分配图。这使得开发者可以轻松识别出哪些部分的内存占用率过高，从而采取措施减少内存使用。例如，若 Massif 报告某个功能模块内存占用接近极限，开发者就能够聚焦于该模块进行优化，可能是通过减少不必要的对象创建，或利用更高效的数据结构。 Extensions：开发者还可以利用 Valgrind 的核心功能，自行编写特定的内存调试工具。这就相当于开发者在现有工具的基础上，创造出一款符合自己独特需求的定制化工具，进一步提升程序的调试能力。 Valgrind 的体系结构如图所示，体现出内核与多种调试工具之间密切的协作关系。通过这种设计，Valgrind 不仅能够增强对程序的调试能力，还能为开发人员提供更为详尽的内存与性能分析，确保程序在各种操作条件下的可靠性。 了解 Linux 内存分布 内存分布 Memcheck 工具Valgrind 的核心组件是 Memcheck，它能够检查多种内存使用错误，包括但不限于以下几种常见问题： 未初始化的内存使用：当程序试图使用一个未初始化的变量，可能会导致不可预测的行为。例如，读取一个本应为零的缓冲区时，如果没有初始化，可能会得到一些垃圾值。 已释放内存的访问：这是一个典型的错误，表示程序试图通过指向已释放内存的指针读取或写入数据。例如，当 free 一个指针后，若继续使用该指针，很可能导致程序崩溃。 超出分配的内存范围：即尝试在已分配的内存块外进行读写，这不仅可能导致数据损坏，还可能引发安全隐患。举个例子，当分配了 10 字节的内存却试图写入 15 字节数据时，就会发生这种错误。 非法的堆栈访问：访问某些不应访问的堆栈区域，通常由于数组越界或错误的指针运算导致。 内存泄漏：指程序在动态分配内存后失去对该内存块的所有指针，导致这些内存无法再被访问或释放，最终可能导致程序的可用内存逐渐耗尽。 内存分配与释放的不匹配：指在使用 malloc 和 free、new 和 delete 时不匹配的情况。比如，如果用 malloc 分配了内存，但用 delete 去释放，就会产生错误。 重叠的内存操作：在使用 memcpy() 等函数时，若源地址和目标地址重叠，可能会导致意外的数据覆盖。 重复的释放：指尝试对同一内存块进行多次释放，导致未定义行为。 Memcheck 的内存检测原理Memcheck 是一种强大工具，可以有效识别程序中的内存问题，其核心机制在于两个全局的表格：Valid-Value 表和 Valid-Address 表。这两个表格通过比特位（bits）精确地追踪进程的内存状态，确保每个字节的可用性和有效性。Memcheck 检测内存问题的原理如下图所示： 地址空间管理对于进程的每一个字节（byte），Memcheck 会为其分配对应的 8 个 bits，用于记录这个字节是否拥有有效且已初始化的值。这意味着每当程序试图访问或修改内存时，Memcheck 都会查看与该字节相关联的 bits，以确定该内存位置的有效性。 例如，考虑一个程序试图读取数组中的一个元素。在进行读取操作之前，Memcheck 首先会检查该元素对应的 8 个 bits。如果这些 bits 中的任意一个指示该元素没有被初始化，程序就会被告知尝试访问未初始化的内存，这是因为这些 bits 确保了该内存的状态被正确追踪。 有效性跟踪除了 Valid-Value 表外，Memcheck 还维护了一个 1 bit 的 Valid-Address 表，专门用于标识内存地址是否可以被读写。每当程序试图进行读写操作时，该操作都会经过该表的验证。 假设一个程序企图修改一个无效的内存地址，无论是因为地址已经释放还是超出了有效范围，Memcheck 会提前捕获这个错误。一旦发现相关的 A bit 显示该地址无效，Memcheck 将立即报告为读写错误。这种即时反馈极大地帮助开发者定位问题，避免潜在的程序崩溃。 核心与虚拟 CPU 环境值得注意的是，Memcheck 的内部核（core）运行在一个类似于虚拟的 CPU 环境中。这意味着，当进程中的一个字节被加载到实际的 CPU 时，其对应的 V bit 也会一同被加载到虚拟环境中。这种机制确保了即便是在底层硬件交互的瞬间，内存的有效性记录依然得到维护。 当程序的寄存器中的值被用于生成内存地址，或当该值可以影响程序的输出时，Memcheck 会进行一次额外的检查，确保所有相关的 V bits 已被正确设置。如果发现这些 bits 指向一个尚未初始化的值，Memcheck 将发出关于使用未初始化内存的错误警告。这种设计进一步增强了程序运行的安全性和正确性。 总体来说，Memcheck 通过严密的内存追踪机制，帮助开发者有效识别并解决内存相关的问题，确保程序的稳定和高效。 Memcheck 内存问题检测机制Memcheck 是一个强大的工具，专门用于检测程序中的内存问题。其核心在于构建两个全局表，这使得它能够高效、准确地运行内存检查。 内存和寄存器监测对于进程中的每一个字节（byte），Memcheck 会对应地创建 8 个 bits。而每个 CPU 寄存器同样会对应一个 bit 向量。这个 bit 向量的作用是记录某个字节或寄存器的值是否有效且已初始。例如，如果程序试图访问一个数组的元素，而该元素之前未被初始化，Memcheck 的记录系统会标记这个字节的对应 bit，帮助开发者追踪导致错误的情况。 地址有效性跟踪此外，Memcheck 还为进程地址空间中的每一个字节创建了一个单独的 bit，用以记录该地址是否能被正确读写。所谓读写，是指程序尝试从该内存地址读取数据或将数据写入该内存地址。这一机制确保系统能快速识别出无效内存访问，避免程序因使用非法地址而崩溃。 检测原理Memcheck 的检测机制可总结为以下两个表： Valid-Value 表：用于追踪每个内存字节和寄存器的值是否有效。 Valid-Address 表：用于监控每个内存字节的可读写性。 读取与写入内存的过程当程序尝试读写内存中的某个字节时，Memcheck 首先检查该字节对应的有效地址 bit（A bit）。如果 A bit 表明该位置为无效，则 Memcheck 会立即报告一个读写错误。举例来说，如果程序尝试访问一个指向清空或未分配内存的指针，Memcheck 会捕捉到此类错误，提示开发者该操作是非法的。 虚拟 CPU 环境内核（core）运作像一个虚拟 CPU 环境。这样，当某个字节被加载到真实 CPU 时，其对应的有效值 bit（V bit）也同时加载进虚拟 CPU 环境。一旦寄存器的值用于生成内存地址，或可能影响程序的输出，Memcheck 就会进行又一次的检查，确保 V bits 记录的值是有效且已初始化的。如果发现该内存地址的值尚未被合理初始化，Memcheck 将会报告出错，提示开发者存在未初始化内存的风险。这种详细的检查机制大大简化了调试过程，减少了难以排查的问题。 通过这一系列的监控和记录，Memcheck 有效地帮助开发者识别和修复内存相关的错误，提升代码的稳定性和可靠性。 安装 Valgrind以下是 Valgrind 的安装步骤，确保有 wget 和 make 等基本工具： wget http://valgrind.org/downloads/valgrind-3.4.1.tar.bz2tar xvf valgrind-3.4.1.tar.bz2cd valgrind-3.4.1/./configure --prefix=/usr/local/webserver/valgrindmakemake install 使用示例准备好程序#include stdlib.h // 引入标准库，提供malloc和free函数的声明void fun() // 分配内存：为10个整数分配足够的空间 int *p = (int *)malloc(10 * sizeof(int)); // 检查内存是否分配成功 if (p == NULL) // 如果分配失败，输出错误信息并退出函数 fprintf(stderr, Memory allocation failed ); return; // 错误的内存访问：尝试访问数组的第11个元素（索引为10） // 这是越界访问，可能导致未定义行为 p[10] = 0; // 在 C/C++ 中，数组的有效索引是 0 到 9，而这里越界了 // 在实际应用中，访问越界的内存可能导致程序崩溃或数据损坏。 // 为了避免这种情况，确保访问的索引在合理范围内非常重要 // 正确的访问应该是 p[0] 到 p[9] // 记得释放分配的内存，防止内存泄漏 //free(p);int main() fun(); // 调用 fun 函数 return 0; // 返回 0，表示程序成功结束 细节说明： 使用 malloc 函数分配的内存等同于 10 个 int 类型的空间，每个 int 通常占用 4 字节，因此总共分配了 40 字节的内存。 在分配内存后，使用指针 p 存取内存，但必须确保访问的数组索引不超过初始化的大小。错误的写法 p[10] 实际上是访问了未分配的内存区域，可能导致程序意外崩溃。 在成功使用 malloc 之后，应该立即检查返回指针是否为 NULL，以确认内存是否成功分配。 最后，使用 free 函数释放掉之前分配的内存，以避免内存泄漏。这是内存管理中的一个好习惯，确保程序运行高效、稳定。 为了确保 Valgrind 能够准确发现并定位源代码中的错误，在编译程序时需要加入 -g 参数，开启调试信息。同时，为了避免优化影响调试，推荐使用 -O0 选项，这样虽然会降低程序的运行效率，但能够保证调试信息的准确性。这一过程所使用的示例程序名为 sample.c，编译器选择 gcc。生成可执行程序的命令如下： gcc -g -O0 sample.c -o sample 在此命令中，-g 选项使得编译器在生成的可执行文件中包含调试符号，从而帮助 Valgrind 定位到出错的源代码行。而 -O0 选项则禁止优化，确保每条代码都与源代码一致。 在 Valgrind 下，运行可执行程序Valgrind 主要用于调试内存相关的问题，这意味着可以直接对编译得到的二进制可执行文件进行分析，无需重新编译源代码。运行 Valgrind 命令的通用格式如下： valgrind [valgrind-options] your-prog [your-prog-options] Valgrind 的参数分为核心参数和特定工具的参数。核心参数适用于所有的 Valgrind 工具，而特定工具的参数则依赖于选择的具体工具。Valgrind 默认会启动 memcheck 工具，但也可以使用 --tool=tool name 选项指定其他工具。Valgrind 提供丰富的参数集以满足不同的调试需求，详细信息请参考其用户手册。 在这个示例中，选择使用 memcheck 工具，可以执行以下命令运行程序： valgrind ./sample 分析 Valgrind 的输出信息当运行上面的命令时，Valgrind 会产生一系列输出信息。这些信息将帮助定位到程序中的内存问题。输出中包含了多个部分： 左侧显示的数字（如 32372）标识了进程 ID，帮助用户跟踪正在分析的程序。 顶部的红色框显示 Valgrind 的版本信息，例如 “Valgrind-3.16.1”。 中间的红色框展示了 Valgrind 在运行被测试程序时检测到的内存错误。这些信息包括： 非法写操作的描述，例如”Invalid write of size 4”。 报错时的函数堆栈信息，包括函数的调用链（比如 fun() 到 main()）。 涉及非法写操作的具体地址空间，通常是类似于 “0x4a3c4” 的地址。 最底部的红色框会总结发现的内存问题，以及内存泄漏的统计报告。例如，可能会有”HEAP SUMMARY”部分，显示内存泄漏的大小（如”40 bytes”）。 根据这些信息，可以确切知道示例程序存在两个主要问题： 在 fun 函数中动态申请的堆内存没有被释放，导致内存泄漏。 代码中存在对堆内存的越界访问问题。 这两个问题均被 Valgrind 有效识别和标记，为修复代码提供了依据。通过仔细分析这些输出信息，开发者能够准确定位并修复潜在的错误。 Memcheck 工具进行 CC++ 的内存泄漏检测在系统编程中，有效地管理内存是至关重要的。随着程序与系统底层的接触越深，面临的内存问题也越多。处理这些问题时，常常会遇到棘手的调试挑战，所以使用合适的工具是非常关键的。在众多可用工具中，Valgrind 并不是一个新的名字，它是一个强大的开源内存管理框架。 Valgrind 是一个动态分析工具的框架，包含多种工具，各自针对不同类型的调试和分析任务，以帮助提高程序的质量和稳定性。Valgrind 的模块化架构使得开发新工具变得相对简单，而不会对现有功能产生负面影响。很多实用的工具都是作为标准配备，而一些工具则只对特定用户群体有用，比如 Lackey 和 Nulgrind 主要用于演示和测试目的。 在这篇文章中，将重点讨论 Memcheck 工具，它是 Valgrind 的核心功能之一。 使用 Valgrind MemcheckMemcheck 工具的基本使用方式如下： valgrind --tool=memcheck ./a.out 在以上命令中，valgrind 是调用工具的主命令，而 --tool 选项指定要使用的工具为 memcheck。a.out 是希望通过 Memcheck 进行测试的可执行文件。 Memcheck 工具可以检测多种与内存相关的问题，以下是一些主要的能力： 未释放内存的使用 对释放后内存的读写 对已分配内存块尾部的读写 内存泄漏 不匹配的使用 malloc/new/new[] 和 free/delete/delete[] 重复释放内存 将逐一探讨这些场景，使用代码示例和输出结果来说明。 1. 使用未初始化的指针#include stdio.h#include stdlib.hint main(void) char *p; char c = *p; // 未初始化的指针 printf( [%c] ,c); return 0; 当尝试通过未初始化的指针 p 读取内存时，运行 Memcheck 将显示如下输出： $ valgrind --tool=memcheck ./val==2862== Memcheck, a memory error detector==2862== Use of uninitialised value of size 8==2862== at 0x400530: main (valgrind.c:8)==2862== ...==2862== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 4 from 4) 2. 在内存释放后进行读写#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; free(p); // 先释放内存 char c = *p; // 再次访问已释放内存 printf( [%c] ,c); return 0; 运行上面的代码后，得到了以下结果，Memcheck 报告了一个无效读取： $ valgrind --tool=memcheck ./val==2849== Invalid read of size 1==2849== at 0x400603: main (valgrind.c:30)==2849== Address 0x51b0040 is 0 bytes inside a block of size 1 freed 3. 从已分配内存块尾部进行读写#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; char c = *(p + 1); // 访问超出分配的内存 printf( [%c] ,c); free(p); return 0; 该代码同样会引发内存读取问题： $ valgrind --tool=memcheck ./val==2835== Invalid read of size 1==2835== at 0x4005D9: main (valgrind.c:25) 4. 内存泄漏#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; // 还未释放，内存泄漏 return 0; 运行此代码时，Memcheck 会报告检测到内存泄漏： $ valgrind --tool=memcheck --leak-check=full ./val==2888== LEAK SUMMARY:==2888== definitely lost: 1 bytes in 1 blocks 5. 不匹配的使用 malloc/new/new[] 和 free/delete/delete[]#include stdio.h#include stdlib.h#include iostreamint main(void) char *p = (char*)malloc(1); delete p; // 错误，应该使用 free() return 0; 运行上述代码，Memcheck 提供了清晰的错误信息： $ valgrind --tool=memcheck --leak-check=full ./val==2972== Mismatched free() / delete / delete [] 6. 重复释放内存#include stdio.h#include stdlib.hint main(void) char *p = (char*)malloc(1); free(p); free(p); // 重复释放 return 0; 执行后会返回以下错误信息，表明对同一指针调用了两次释放操作： $ valgrind --tool=memcheck --leak-check=full ./val==3167== Invalid free() / delete / delete[] 在本文中，详细介绍了 Valgrind 内存管理框架，并通过 Memcheck 工具展示了它如何帮助开发者简化内存管理，避免常见的内存问题。 Valgrind 是一个强大的工具，能够检测到许多手动检查不易发现的内存错误。 如果想在开发环境中使用 Valgrind，Qt Creator 提供了对 Valgrind 的前端集成，可以轻松分析和优化代码。也可以使用 KCacheGrind 分析 Valgrind 输出的信息，从而进一步优化性能。 利用 valgrind 定位内存泄漏问题通过实例来看看如何利用 Valgrind 来定位内存泄漏问题。以下是要分析的程序示例： #include stdlib.h#include stdio.hchar* getMemory() char *p = (char *)malloc(30); return p;int main() char *p = getMemory(); p = NULL; return 0; 对于这段程序，任何对 CC++ 有基本了解的人都能轻易识别出其中的内存泄漏问题。getMemory 函数分配了 30 字节的内存，但在 main 函数中，仅仅将指针 p 设置为 NULL，却没有释放那段内存。接下来，使用 Valgrind 工具进行检测： [root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==19226== Memcheck, a memory error detector==19226== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==19226== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==19226== Command: ./a.out==19226====19226====19226== HEAP SUMMARY:==19226== in use at exit: 30 bytes in 1 blocks==19226== total heap usage: 1 allocs, 0 frees, 30 bytes allocated==19226====19226== 30 bytes in 1 blocks are definitely lost in loss record 1 of 1==19226== at 0x4C278FE: malloc (vg_replace_malloc.c:270)==19226== by 0x4005B5: getMemory() (in /root/valgrind-3.8.1/bin/a.out)==19226== by 0x4005CC: main (in /root/valgrind-3.8.1/bin/a.out)==19226====19226== LEAK SUMMARY:==19226== definitely lost: 30 bytes in 1 blocks==19226== indirectly lost: 0 bytes in 0 blocks==19226== possibly lost: 0 bytes in 0 blocks==19226== still reachable: 0 bytes in 0 blocks==19226== suppressed: 0 bytes in 0 blocks==19226====19226== For counts of detected and suppressed errors, rerun with: -v==19226== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 从上面的输出中可以清楚地看到，getMemory 函数中调用 malloc 的地方存在内存泄漏。输出中最左边的 19226 表示进程号，这对于多进程的调试尤为重要。 然而，在代码量较大的情况下，手动查找泄漏的地方可能会比较困难。可以使用 Valgrind 提供的更详细的信息，来标识出发生内存泄漏的代码行。为了实现这一点，需要在编译时加入 -g 参数，并且确保编译后的程序没有被 strip 处理。可以这样做： [root@xxx ~/valgrind-3.8.1/bin]# g++ -g test.cpp[root@xxx ~/valgrind-3.8.1/bin]#[root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==20448== Memcheck, a memory error detector==20448== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==20448== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==20448== Command: ./a.out==20448====20448====20448== HEAP SUMMARY:==20448== in use at exit: 30 bytes in 1 blocks==20448== total heap usage: 1 allocs, 0 frees, 30 bytes allocated==20448====20448== 30 bytes in 1 blocks are definitely lost in loss record 1 of 1==20448== at 0x4C278FE: malloc (vg_replace_malloc.c:270)==20448== by 0x4005B5: getMemory() (test.cpp:5)==20448== by 0x4005CC: main (test.cpp:11)==20448====20448== LEAK SUMMARY:==20448== definitely lost: 30 bytes in 1 blocks==20448== indirectly lost: 0 bytes in 0 blocks==20448== possibly lost: 0 bytes in 0 blocks==20448== still reachable: 0 bytes in 0 blocks==20448== suppressed: 0 bytes in 0 blocks==20448====20448== For counts of detected and suppressed errors, rerun with: -v==20448== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 可以看到，输出中已经显示了具体的文件名和行号。例如，getMemory 函数在 test.cpp 的第 5 行，main 函数在第 11 行。这些信息极大地方便了开发者迅速定位问题。 修复内存泄漏后，代码应该改为： #include stdlib.h#include stdio.hchar* getMemory() char *p = (char *)malloc(30); return p;int main() char *p = getMemory(); if (p != NULL) free(p); p = NULL; return 0; 在这个版本中，在确定 p 不为 NULL 时使用 free 函数释放了之前分配的内存。现在再次使用 Valgrind 检测一下： [root@xxx ~/valgrind-3.8.1/bin]# g++ -g test.cpp[root@xxx ~/valgrind-3.8.1/bin]#[root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==21033== Memcheck, a memory error detector==21033== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==21033== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==21033== Command: ./a.out==21033====21033====21033== HEAP SUMMARY:==21033== in use at exit: 0 bytes in 0 blocks==21033== total heap usage: 1 allocs, 1 frees, 30 bytes allocated==21033====21033== All heap blocks were freed -- no leaks are possible==21033====21033== For counts of detected and suppressed errors, rerun with: -v==21033== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 检验结果显示没有内存泄漏了，所有分配的内存块都成功释放。这意味着的代码现在更加安全和高效，确保在再次执行时不会导致内存的浪费或潜在的崩溃问题。 ARM 交叉编译1. 下载及编译准备首先，需要下载 Valgrind 的源代码并进行解压。可以使用以下命令： wget http://valgrind.org/downloads/valgrind-3.12.0.tar.bz2tar xvf valgrind-3.12.0.tar.bz2cd valgrind-3.12.0apt-get install automake./autogen.sh 下载指令说明：wget 用于从互联网下载文件，tar 用于解压缩打包文件。 依赖工具：automake 是自动化生成 Makefile 的工具，确保的系统中安装了它。 初始化脚本：./autogen.sh 会创建配置文件，使后续编译步骤顺利进行。 2. 交叉编译在配置阶段，需要对 configure 文件进行修改，以适应 ARM 架构。具体步骤如下： vi configure # 使用文本编辑器打开 configure 文件 找到如下行： armv7*) 将其修改为： armv7*|arm) 接下来，可以执行以下命令进行配置和编译： ./configure --host=arm-linux CC=arm-none-linux-gnueabi-gcc CPP=arm-none-linux-gnueabi-cpp CXX=arm-none-linux-gnueabi-g++makemake install --prefix=/home/dcj/valgrind 配置选项说明： --host=arm-linux：指定目标平台是 ARM。 CC=arm-none-linux-gnueabi-gcc：指定交叉编译器。 --prefix=/home/dcj/valgrind：指明安装路径，确保与开发板上目录一致。 成功后，在 /home/dcj/valgrind 目录下会生成四个重要的子目录：bin、include、lib 和 share。确保这些文件能够在的开发环境中找到。 如果不按预期设置 --prefix，在运行 Valgrind 时可能会出现错误提示： valgrind: failed to start tool ‘memcheck’ for platform ‘arm-linux’: No such file or directory 3. 运行将安装好的 Valgrind 目录通过 WinSCP 工具复制到目标板的 /home/dcj/ 下。完成后，需要为 bin 目录下的可执行文件给予执行权限： chmod -R +x /home/dcj/valgrind/bin/ 此时，如果在尝试运行 bin 目录下的 valgrind 时收到如下错误： valgrind: failed to start tool memcheck for platform arm-linux: Permission denied 解决方法：这是因为 Valgrind 的库文件权限不足。可以通过以下命令修复： export VALGRIND_LIB=/home/dcj/valgrind/lib/valgrind chmod -R +x /home/dcj/valgrind/lib/valgrind/ 环境变量设置：通过 export 声明环境变量，Valgrind 能够找到其必要的库文件。 权限修改：确保所有文件都有适当的执行与访问权限，这样 Valgrind 才能正常工作。 完成以上步骤后，便可以在 ARM 上运行 Valgrind 进行内存泄漏等问题检查。 补充Valgrind 无法发现的问题Valgrind 是一个强大的内存调试工具，然而，它存在一些显著的局限性。主要的问题之一是，它无法检查在栈上分配的静态数组的边界。例如，考虑以下代码： int main() char x[10]; x[11] = a; // 越界写入 在这个例子中，x 是一个大小为 10 的字符数组。然而，程序尝试访问 x[11]，这会导致越界写入。在实际应用中，这种错误可能会导致不可预测的行为，包括数据损坏或程序崩溃。然而，Valgrind 并不会发出警告。这是因为静态数组是在栈上分配的，Valgrind 并不跟踪栈内存的边界。 一种解决方案是将静态数组转换为动态分配的内存。具体来说，可以使用 malloc 来分配内存，但要注意在使用完后调用 free 来防止内存泄漏。比如： int main() char *x = (char *)malloc(10 * sizeof(char)); // 动态分配内存 if (x == NULL) return 1; // 检查内存分配是否成功 x[11] = a; // 仍然是越界写入，但Valgrind会捕捉到 free(x); // 释放内存 尽管这样可以让 Valgrind 能够检测出问题，但动态分配的内存可能引入其他问题，如未释放的内存（unfreed memory），从而增加内存管理的复杂性。 额外的警告信息Valgrind 的一个显著缺点是它消耗的内存量，通常是源程序需求的两倍。例如，如果的程序需要 100MB 的内存，Valgrind 可能会使其消耗高达 200MB。这在检测大型内存问题时可能会引发问题。 此外，Valgrind 的运行时间比普通执行程序要长，通常是因为它需要进行深度内存检查。这对于通常运行较快的程序来说，可能不是什么大问题，但对于本身执行速度较慢的程序，这可能会引起很大的困扰。例如，一段原本在十秒内完成的程序，使用 Valgrind 后，可能需要十分钟或更长时间。 这种内存消耗和运行时间的增加，对于开发人员在调试过程中来说，可能需要平衡严谨的内存检查与开发效率之间的关系。所以，对于在较大项目中频繁遇到内存问题的开发者来说，合理选择使用 Valgrind 的时机，将是提高工作效率的关键。","categories":["2.语言","调试输出"]},{"title":"内存泄漏检测工具比较","path":"/2024/01/09/2-语言-调试输出-内存泄漏检测工具比较/","content":"内存泄露检测工具比较 内存泄露和 malloc 调试库 在 Linux 和 Solaris 下，针对 C 和 C++ 程序的简单内存泄露检测。通过使用这一库，开发者可以方便地跟踪内存分配和释放，以识别潜在的泄露。例如，可以追踪每次 malloc() 的调用，查找没有相应 free() 的内存块。 Debug Malloc Library 这是一种专用的调试库，旨在帮助开发者快速定位内存问题。通过记录每个分配的内存块和对应的调用栈，它能显示何时及为何发生内存泄露。 Bruce Perens 的 malloc() 调试库 特别设计用于 Linux 分发版，Bruce Perens 开发的此库提供了内存分配的调试功能，允许程序员检测动态内存分配过程中的问题。 Linux 下的内存泄漏检测程序 提供多种工具用于分析 Linux 环境中程序的内存使用情况。开发者可以通过这些工具轻松查找无用的内存引用，以提高最终产品的稳定性。 跨平台的内存泄漏分析工具 在 Linux、Solaris 和 HP-UX 平台上，能够有效追踪 C++ 程序中的内存泄露。这类工具往往具有高度的可配置性，适应不同编程模型和编译环境。 Johan Lindh 的开源 C 语言内存错误检测工具 利用 GCC 的预处理器，Johan Lindh 开发的这一工具专注于检测 C 语言中的内存错误。它为开发者提供了一种低开销的解决方案以提高代码质量。 调试和性能分析工具 这些工具专注于 Linux 程序的调试和性能分析，特别是 C 和 C++ 语言的应用程序。此类工具通常提供可视化的性能报告，帮助开发者更好地理解程序的运行情况。 可视化工具 这种工具将性能数据以图形化方式呈现，帮助开发者更直观地理解程序执行的内存使用模式和性能瓶颈。 Firefox 扩展 一个专门为 Firefox 浏览器设计的扩展，能够识别与浏览器相关的内存泄漏。这对于网页开发者尤为重要，因为浏览器的内存管理直接影响用户体验。 Drip 和 IE Sieve 内存泄漏探测器 专为网页开发者设计，帮助识别 Internet Explorer 中的内存泄露。这两种工具可以展示由于 IE 的限制而导致的可避免的内存泄漏，从而提高网页性能。 Win32 应用程序资源泄漏探测器 通过监控 Win API 调用，这款工具能够检查任何 Win32 应用程序中的资源泄漏，包括内存、句柄等，帮助开发者发现并解决问题。 SAP 的内存分析软件 作为一种开源工具，SAP 可以辅助开发者快速定位 Java 程序中的内存泄漏。其基于 Eclipse RCP（Rich Client Platform），提供了友好的用户界面，简化了内存使用情况的分析。 动态跟踪（DTrace） 这是一个开源的动态跟踪工具，能够在类 Unix 操作系统上运行。通过跟踪内核和用户进程，开发者能够实时监测系统资源的使用情况，并及时进行调整以优化系统性能。 IBM Rational PurifyPlus 此工具集成了内存错误检测、应用程序性能描述和代码覆盖分析等多种功能，帮助开发人员发现 CC++、.NET、Java 和 VB6 代码中的潜在错误，并提供全面的解决方案。 Parasoft 专为 CC++ 应用程序设计的自动检测工具，能发现程序中的内存破坏、内存泄漏、指针错误和 IO 问题。利用 SCI 技术和变异测试等方法，Parasoft 提供了详细的错误症状和解决方案。 Compuware 的运行时错误检测工具 为 C++ 开发者设计，作为 Microsoft Visual Studio 和 C++ 6.0 的插件，帮助开发者迅速定位程序中的错误。 Electric Software 这个工具包集成了内存泄漏检查、代码剖析和函数调用跟踪等多种功能，适用于 C++ 和 .NET 开发者，提供全面的错误诊断和性能分析。 Compuware Java 功能模块 包含 Java 内存检测、代码覆盖率测试和性能分析等多种功能，帮助开发者实现高效的代码优化与性能提升。 Quest 的 Java 内存泄漏分析工具 专注于 Java 应用程序的内存使用，帮助开发者快速识别和修复内存泄漏，提高应用的稳定性和性能。 ej-technologies 的 JProfiler 一个全面的 Java 性能与内存分析工具，支持 J2SE 和 J2EE 应用程序，提供丰富的 IDE 和应用服务器整合功能，其直观的 GUI 可以帮助开发者快速识别性能瓶颈和内存泄漏。 BEA 的内存泄漏诊断工具 针对 Intel 平台优化，专注于 Java 内存泄漏的根本原因，提供高性能的内存使用分析。 SciTech Software AB 专注于 C# 和 VB.Net 程序的内存泄漏检测和优化，帮助开发者提高应用程序的性能和稳定性。 YourKit 被业界广泛认可的 Java 和 .NET 性能分析工具，能够深入分析应用程序性能，并定位潜在的内存问题。 AutomatedQA 的性能剖析和内存调试工具 为 .NET 和 Windows 程序提供详细的报告，帮助开发者识别和解决性能和内存泄漏问题，兼容多种编程语言和编译器。 微软 JavaScript 内存泄漏探测工具 由微软全球产品开发团队发布，用于探测 JavaScript 代码中的内存泄漏，作为 IE 浏览器的插件运行，专门针对 web 开发中的内存管理问题。 附录：内存泄漏的发生方式 常发性内存泄漏常发性内存泄漏指的是某段代码在程序运行过程中被反复调用时，每次执行都会占用额外的内存而未能正常释放。这种情况常常发生在循环结构或递归调用中，比如在一个不停创建对象的循环中，若创建的对象未被销毁，就会导致内存占用持续增加，从而造成泄漏。 偶发性内存泄漏偶发性内存泄漏则与特定的条件相关。只有在特定的操作条件下，执行某段代码时才可能发生内存泄漏。这种泄漏在不同的环境中可能表现得截然不同。例如，在特定版本的软件中，用户操作一种特定的功能可能触发内存泄漏，而在其他版本或未执行该功能时则不会。测试环境与测试方法的选择对发现这种问题至关重要，工程师通常需要模拟各种场景以确保漏泄问题被发现。 一次性内存泄漏一次性内存泄漏发生在某段代码只被执行一次的情况下，但由于算法或逻辑缺陷，依然会留下一块内存未被释放。典型的例子包括由于未释放大对象或未清理全局引用，导致在一次运行中的内存损失。例如，开发人员可能在初始化时分配了一个缓冲区，但未正确解除对该缓冲区的引用。 隐式内存泄漏隐式内存泄漏并不表现为传统意义上的”泄漏”，因为程序在运行结束时会释放所有申请的内存。然而，若程序需要长时间运行，如几天或几周而不释放内存，可能会导致系统总体内存耗尽，从而产生”隐式”效果。这在服务器或长期运行的应用中尤为棘手，例如长时间运行的数据库服务，若不定期清理引用，可能会使系统最终崩溃。 什么是系统资源？在 Windows 操作系统中，每当应用程序启动并运行时，系统不仅需要执行代码，还需要随时”跟踪”该程序的状态。这包括管理按钮、光标、菜单的位置，以及窗口状况等信息。这些信息被存储在名为堆（Heap）的内存块中。堆是一种特殊的内存管理结构，有效地分配和回收内存资源。 Windows 将堆分为两大类：用户资源堆（User Resource Heap）和GDI 资源堆（GDI Resource Heap）。用户资源堆由系统内核 User.exe 管理，而 GDI 资源堆由系统内核 Gdi.exe 管理。它们共同构成系统资源堆（System Resource Heap），通常合称为系统资源。 资源堆的分类微软将 Windows 的系统资源划分为五个堆，其中三个属于用户资源堆，两个属于 GDI 资源堆： 用户资源堆 16 位用户堆（User Heap）: 最大 64KB 32 位窗口堆（Windows Heap）: 最大 2MB 32 位用户菜单堆（User Menu Heap）: 最大 2MB GDI 资源堆 16 位 GDI 堆（GDI Heap）: 最大 64KB 32 位 GDI 堆（GDI）: 最大 2MB 这样的分类和大小说明了不论 CPU 的种类（如 P4 或 486）或内存大小（如 8MB 或 1GB），所有 Windows 用户的系统资源都相同。用户无法自主增加或减少这些资源的大小，操作系统将其固定，而这与硬件的档次毫无关系。 为了实时监控系统资源的使用情况，Windows 以百分比的形式展示可用用户资源（Free User Resource）和可用 GDI 资源（Free GDI Resource），用户可以通过”开始”菜单的”附件”中的”系统工具”找到”系统信息”，以查看当前系统资源的状态。 在 Linux 平台中调试 CC++ 内存泄漏方法C 和 C++ 程序的内存管理完全由程序员负责，从申请到释放内存，稍不注意便可能在系统中引入内存错误。这种错误往往后果严重，可能导致系统崩溃或内存耗尽等问题。本文将介绍在 Linux 环境中检测内存泄漏的方法，包括静态分析和动态检测两个角度，重点讲解静态分析工具 BEAM、动态检测工具 Valgrind 和 Rational Purify 的使用方法。希望本文能为处理其他产品或项目中与内存泄漏相关的问题提供借鉴。 内存问题的重要性由于 C 和 C++ 程序需手动管理内存，因此内存错误可能导致严重的问题。历史上，从计算机应急响应小组和供应商发布的安全公告中，许多都是因内存错误引起的。自上世纪 70 年代末期以来，程序员们一直在讨论这些问题，并且到 2007 年时其影响依旧显著。与其他类型的错误不同，内存错误通常隐蔽且难以重现，其症状常常不易在源代码中识别。例如，内存泄漏可能导致应用程序逐渐变得响应迟缓，最终使程序崩溃，而内存的浪费并不总是立刻显而易见。 内存错误的 C 和 C++ 程序可能表现为不同的问题：内存泄漏可能导致程序的运行时间越来越长，进而崩溃；而覆盖内存的问题使得程序变得脆弱，容易受到恶意攻击。这些问题表明了对 C 和 C++ 编程时内存管理，尤其是内存泄漏的重视是多么重要。 本文将探讨如何发现内存泄漏，接着使用不同工具定位这些内存泄漏，最后对这些工具进行比较，并简单介绍资源泄漏的处理（以句柄泄漏为例）。测试平台为：Linux (Redhat AS4)，但所介绍的方法和工具并不限于 CC++ 语言和 Linux 操作系统。 内存泄漏的定义内存泄漏通常指的是堆内存的泄漏。堆内存是指程序从堆中分配的内存，大小可以在程序运行期间动态确定，使用完后必须显式释放。这通常通过 malloc、realloc、new 等函数进行内存分配。忘记使用 free 或 delete 释放内存会导致该内存无法再被利用，这就是典型的内存泄漏。 1. 如何发现内存泄漏内存泄漏在代码检查过程中，某些简单的问题容易被识别。而一些较为严重的泄漏，可能在短时间内导致程序崩溃，或在内存不足时被系统报告，这也是比较容易发现的。然而，最难发现的是那些泄漏比较慢的问题，需要多天、几周甚至几个月才能显露出异常现象。 要在较短的时间内检测潜在的内存泄漏，可以利用内存监视工具收集一段时间内的堆栈内存信息，观察它的增长趋势。在 Linux 平台上，可以使用 ps 命令监视内存的使用，如下所示： ps -aux 2. 静态分析静态分析是一种低成本的调试方法，包括手动检测和使用静态分析工具。 2.1 手动检测采用一致的编程规范是防止内存问题的第一道防线。手动检测可以作为编码标准的补充。即使是专业的 CC++ 程序员，也可以通过查看不熟悉的代码，以非常低的成本快速识别内存问题。例如，通过查找 malloc() 和 free()，或者 new 和 delete 的配对，可以发现像以下示例中的内存泄漏问题。 #include stdio.h#include string.h#include stdlib.hint LeakTest(char * Para) if (NULL == Para) return -1; // 空参数处理 char * Logmsg = new char[128]; // 动态分配内存 if (NULL == Logmsg) return -2; // 内存分配失败 sprintf(Logmsg,LeakTest routine exit: %s. , Para); // 此处漏掉了释放 Logmsg 的代码 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); return 0; 在上述代码中，Logmsg 分配的内存没有被释放，就造成了内存泄漏。 2.2 静态代码分析工具有多种代码静态分析工具可用，例如 Splint、PC-LINT 和 BEAM。由于 BEAM 支持多种平台，这里将以它为例进行简单介绍。 BEAM 能够检测四类问题：未初始化的变量、废弃的空指针、内存泄漏和冗余计算，且支持多种平台（如 Linux x86、s390s390x、PowerPC、AIX、Windows 2000 以上等）。 以下是用于 BEAM 分析的代码示例： #include stdio.h#include string.h#include stdlib.hint *p;void foo(int a) int b, c; b = 0; if (!p) c = 1; if (c a) c += p[1]; // 这可能会导致错误int LeakTest(char * Para) char * Logmsg = new char[128]; if ((Para == NULL) || (Logmsg == NULL)) return -1; sprintf(Logmsg, LeakTest routine exit: %s. , Para); // 漏掉了 Logmsg 的释放 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); return 0; 在 Linux x86 环境中，使用 BEAM 进行分析的过程如下： ./beam-3.4.2/bin/beam_configure --c gcc./beam-3.4.2/bin/beam_configure --cpp g++./beam-3.4.2/bin/beam_compile --beam::compiler=compiler_cpp_config.tcl -cpp code2.cpp 从编译报告中，BEAM 会提示几个错误，例如内存泄漏和变量未初始化的问题。 2.3 内嵌程序可以重载内存分配和释放函数 new 和 delete，编写程序定期统计内存的分配和释放，进一步找出内存泄漏。这种方法较为复杂，详细示例不再赘述。 3. 动态运行检测用于实时检测的工具主要有 Valgrind 和 Rational Purify。 3.1 ValgrindValgrind 提供了一组工具来帮助程序员寻找程序中的 bug 并提高性能。其中，Memcheck 主要用于检查 CC++ 程序中的内存管理错误。Valgrind 能识别以下几种常见错误： 读写已释放的内存 读写超出分配范围的内存 使用未初始化的变量 向系统调用传递无效的参数 内存泄漏 3.2 Rational PurifyRational Purify 是一种针对难以发现的内存错误和运行时错误的工具。它能自动识别错误并定位，从而减少调试时间。Purify 支持多种平台，并可和其他主流开发工具集成。它可以检查每一个模块，甚至能发现复杂多进程应用中的错误。 在 Linux 上使用 Purify 时，需重新编译程序。通常通过修改 Makefile 中的编译器变量来实现。以下是编译示例 Makefile： CC=purify gcc 运行 Purify 的设置脚本并重新编译： ./purifyplus_setup.shmake 下面是使用 Purify 和 g++ 编译代码文件的示例命令，使用 -g 选项添加调试信息： purify g++ -g test3.cpp -o test 运行生成的可执行文件 ./test，就可以定位出内存泄漏的具体位置。 #include unistd.hchar * Logmsg;int LeakTest(char * Para) if (NULL == Para) return -1; // 空参数处理 Logmsg = new char[128]; for (int i = 0; i 128; i++) Logmsg[i] = i % 64; // 数据填充 if (NULL == Logmsg) return -2; // 内存分配失败 sprintf(Logmsg, LeakTest routine exit: %s. , Para); // 忽略释放 Logmsg 的代码 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); for (int i = 0; i 2; i++) if (i % 200 == 0) LeakTest(szInit); sleep(1); return 0; 记住，程序必须以调试版本编译，才能准确定位到内存泄漏发生的具体代码行。使用 -g 选项进行编译是必要的。","categories":["2.语言","调试输出"]},{"title":"常见的内存问题","path":"/2024/01/08/2-语言-调试输出-常见的内存问题/","content":"利用 Memcheck 发现常见的内存问题在 Linux 平台开发应用程序时，开发者经常会遇到内存使用不当的问题。总结了一些常见的内存错误，并说明了如何使用 Valgrind 的 Memcheck 工具来检测这些错误。 使用未初始化的内存在程序的不同上下文中，变量的初始值存在差异。全局变量和静态变量的初始值为 0，而局部变量和动态分配的变量则具有不确定的随机值。如果程序意外地使用了这些随机值，可能导致程序行为不可预测。 示例考虑以下示例代码： #include stdio.hvoid example() int a[5]; // a 是局部变量，其所有初始值为随机值 printf(%d , a[0]); // 使用未初始化的变量 a[0] 在这个例子中，数组 a 是一个具有随机初始值的局部变量，若在未对其进行初始化的情况下直接使用，将会带来不可预测的输出。假设这个文件名为 badloop.c，生成的可执行程序名为 badloop。用 Memcheck 对其测试结果如下： ==12345== Use of uninitialized value of size 4==12345== at 0x4005A1: example (badloop.c:5) 输出结果显示，在程序的第 5 行中，程序的跳转依赖于一个未初始化的变量。这准确地帮助发现了问题。 内存读写越界问题分析内存读写越界是指对不该访问的内存地址进行读写操作，例如数组越界或对动态分配的内存超出范围的访问。这样的操作可能导致对程序状态的严重影响。 示例典型的数组越界代码如下： #include iostreamvoid example() int pt[4]; int *p = pt; // p指向pt数组的起始地址 for (int i = 0; i 5; i++) p[i] = i; // 超出pt数组的范围 当运行这个文件 badacc.cpp 并用 Memcheck 测试时，结果如下： ==12345== Invalid write of size 4==12345== at 0x4005A1: example (badacc.cpp:6)==12345== Address 0x602010 is 4 bytes after a block of size 16 allocd 输出结果表明，在该程序的第 6 行，进行了非法的写操作，这帮助准确地发现了该问题。 内存覆盖问题分析C 语言允许直接操作内存，这种特性虽然强大，但也可能导致内存覆盖错误。当源地址和目标地址重叠时，操作的结果可能不如预期。 示例看看下列代码： #include cstringvoid example(char* x) strcpy(x + 10, x); // src 和 dst 发生重叠 在这里，src 和 dst 指向相互重叠的内存区域，调用 strcpy 时可能覆盖之前的值。假设这个文件名为 badlap.cpp，测试输出如下： ==12345== Invalid write of size 1==12345== at 0x4005A1: example (badlap.cpp:4) 输出表明在第 4 行有非法写操作，可以有效识别该内存覆盖问题。 动态内存管理错误问题分析动态内存管理不仅提供了灵活的内存控制能力，也容易引发错误。C 和 C++ 对动态内存的分配和释放有不同的方式，应保持一致性。 示例考虑以下代码： void example() int* p = (int*)malloc(sizeof(int)); // 使用 malloc 申请内存 delete p; // 错误使用 delete 释放内存 在这个例子中，用 malloc 申请的内存，使用 delete 释放会导致未定义行为。测试输出如下： ==12345== Invalid free() / delete / delete[] / realloc()==12345== at 0x4005A1: example (badmac.cpp:5) 输出结果显示在第 5 行，分配和释放函数不一致，成功识别了代码问题。 内存泄露问题描述内存泄露指在动态申请内存后未释放，导致该内存空间无法被访问。内存泄露常在大型项目中出现，开发者需培养良好的编程习惯，以防止此类问题。 示例考虑如下代码示例： struct Node int data; Node* left; Node* right;;void mk(Node** root) *root = new Node; // 动态申请内存int main() Node* root; mk(root); // 没有释放内存，造成内存泄露 测试这个文件 badleak.cpp 的输出如下： ==12345== 8 bytes in 1 blocks are definitely lost in loss record 1 of 1 Memcheck 成功检测到了内存泄露的情况，输出帮助发现了未释放的内存。 小结通过上述示例和分析，可以看出利用 Memcheck 识别和修复内存问题的强大功能。定期使用这一工具，能有效提高程序的稳定性和性能。","categories":["2.语言","调试输出"]},{"title":"段错误","path":"/2024/01/05/2-语言-调试输出-段错误/","content":"段错误是什么段错误，也称为”分段错误”，是指在程序运行过程中，软件试图访问的内存地址超出了操作系统为该程序所设定的有效内存空间。例如，这种情况可能发生在程序试图访问一个不存在的内存地址，或者非法访问系统保护的内存区域，以及尝试写入一个只读内存地址等。对于”段错误”，可以参考以下准确的定义： “分段错误是一种特定的错误状态，会在计算机软件运行时发生。简而言之，当程序尝试访问一个它没有权限访问的内存位置，或以不允许的方式进行内存操作（如写入只读位置或重写操作系统部分）时，就会产生段错误。” 段错误产生的原因 访问不存在的内存地址：程序可能指向一个未分配或已释放的地址，例如一个未初始化的指针。 int *ptr = NULL;*ptr = 0; // 尝试写入NULL地址 访问系统保护的内存地址：当程序试图修改或读取保留给操作系统的数据时，会导致段错误。 访问只读的内存地址：例如，程序试图对一个常量字符串进行修改，会产生错误。 char *ptr = test;strcpy(ptr, TEST); // 尝试写入只读内存 栈溢出：反复调用自身（如递归）而不设置适当的终止条件，会导致栈空间耗尽。 其他原因：如使用了已释放的内存、数据类型转换错误等。 段错误信息的获取段错误发生时，系统所提供的错误信息通常较少，为了准确诊断问题，可以通过以下工具获取详细信息。 1. dmesg使用 dmesg 命令可以查看最近发生的系统日志，包括段错误的具体信息，例如程序名称、内存地址、指令指针地址及堆栈指针地址等。 $ dmesg[ 2329.479037] segfault3[2700]: segfault at 80484e0 ip 00d2906a sp bfbbec3c error 7 in libc-2.10.1.so[cb4000+13e000] 2. -g 参数在使用 gcc 编译程序时添加 -g 参数，可以在生成的二进制文件中包含符号信息，方便后续调试。 $ gcc -g -o segfault3 segfault3.c 3. nm使用 nm 命令可以列出二进制文件中的符号表，包括符号地址、类型及名称等，有助于确定发生段错误的位置。 $ nm segfault308049f20 d _DYNAMIC08049ff4 d _GLOBAL_OFFSET_TABLE_...080483e4 T main 4. ldd使用 ldd 命令可以查看程序依赖的 lib。通过可视化库的信息，帮助确定段错误是程序本身导致，还是依赖库的问题。 $ ldd ./segfault3linux-gate.so.1 = (0x00e08000)libc.so.6 = /lib/tls/i686/cmov/libc.so.6 (0x00675000) 段错误的调试方法1. 使用 printf 输出信息在程序的关键代码附近加入 printf 输出，可以帮助追踪程序执行过程中的状态，使开发者能够快速定位段错误发生的位置。 为了便于使用 printf，可以利用条件编译，在编译时决定是否输出调试信息： #ifdef DEBUGprintf(Debug info: ...);#endif 2. 使用 gcc 和 gdb 确保程序在编译时加上 -g 参数以启用调试信息。 使用 gdb 命令启动调试： $ gdb ./segfault3 运行程序后，若出现段错误，gdb 会输出错误信息，指明发生错误的位置。 Program received signal SIGSEGV, Segmentation fault.0x001a306ain memcpy() from /lib/tls/i686/cmov/libc.so.6 通过 quit 命令结束调试会话。 3. 使用 core 文件和 gdb在 Linux 系统中，当程序因段错误而异常退出时，若配置正确，会生成一个 core 文件。该文件包含程序的运行状态信息，可以用 gdb 对其进行分析。 检查并可能修改 core 文件生成的限制： $ ulimit -c$ ulimit -c unlimited 运行程序生成 core 文件： $ ./segfault3Segment fault (core dumped) 使用 gdb 加载 core 文件进行调试： $ gdb ./segfault3 core 4. 使用 objdumpobjdump 可以提供程序的汇编代码，从而进一步分析段错误发生的指令。 查找最近的段错误信息，如地址、指针等。 使用 objdump 来查看汇编细节，并找到指向的汇编指令。 5. 使用 catchsegvcatchsegv 命令是专门捕获段错误的工具，通过动态加载库实现捕获并输出详细的错误信息。 一些注意事项 考虑错误原因：在面对段错误时，首先明确段错误的定义并追踪引发原因。 指针初始化：在定义指针后，要立即初始化，使用前确保其不为 NULL。 数组安全：确保数组被初始化，访问时避免越界。 内存管理：注意变量的生存周期，不要使用已释放的内存。 合理控制格式：在处理变量时，控制格式应当合理，避免类型错误。","categories":["2.语言","调试输出"]},{"title":"CANOpen 笔记","path":"/2024/01/04/3-协议-CAN-CANOpen-笔记/","content":"项目地址 CANopenNode https://github.com/CANopenNode/CANopenNode CANopenLinux https://github.com/CANopenNode/CANopenLinux CANopenDemo https://github.com/CANopenNode/CANopenDemo CANopenEditor https://github.com/CANopenNode/CANopenEditor 帮助文档 CANopenLinux https://canopennode.github.io/CANopenLinux CANopenDemo https://canopennode.github.io/index.html CANopenCANopen 是一种基于 CAN（Controller Area Network） 通信协议的高层协议和设备协议，定义了网络管理、设备配置、通信对象和应用对象等方面的标准，以确保不同设备之间的互操作性和通信的一致性。 协议CiA 通过一系列文件维护保持 CANopen 设备和通讯协议规定。基本配置由 CiA 301 CANopen 应用层和通信配置规范定义。规范包括： CANopen 对象字典中的数据类型、编码规则和对象 CANopen 通信服务和协议 CANopen 网络管理服务和协议 CANopen 通讯配置 – 物理层 预定义的通信对象标识符连接数集、与紧急事件相关的对象、时间标识和同步通信对象 此基本 CiA 301 配置规定由其他 CiA 文件进行了补充和扩展，为一些具体领域的设备和功能规定了设备、应用程序和接口配置。具体有以下几个部分，按照自身应用程序的实际情况引入。 CiA 302 – CANopen 附加应用层功能 CiA 303-1 – 布线和接头管脚分配 CiA 303-3 – 指示器规范 CiA 306 – CANopen 电子数据表规范 CiA 309 – 从其他网络接入 CANopen CiA 315 – CANopen 通用框架 CiA 401 – 通用 IO 模块的 CANopen 设备配置 CiA 402 – 驱动和运动控制的 CANopen 设备配置 OSI 模型CANopen 的 OSI 模型，Data link 和 Physical 是由 CAN 进行实现的，Presentation 和 Session 是由 CANopen 进行实现的。 物理层（Physical Layer）定义了物理介质、电气特性、传输速率和编码规范等。 数据链路层（Data Link Layer）划分数据帧、错误检测与纠正、流量控制。 网络层（Network Layer）提供路径选择、逻辑寻址、路由选择等功能。 传输层（Transport Layer）提供端到端的传输控制和错误恢复。 会话层（Session Layer）建立、维护、同步和恢复会话。 表示层（Presentation Layer）数据的加密、压缩、格式转换等。 应用层（Application Layer）用户数据交互和应用支持。 设备模型每个 CANopen 设备都遵循一个通用的设备模型，因此不同的设备能依据同样的 CANopen 标准。CANopen 设备模型的三个组成部分是： 通讯接口 对象字典 应用程序一个 CANopen 设备必须支持一定数量的网络管理服务 NMT，需要至少一个 SDO。每个生产或消费过程数据的设备需要至少一个 PDO。所有其它的通讯对象是可选的。 核心概念通讯模式 设备节点通信有 3 种模型：主设备从设备、客户端服务器和生产者消费者 通讯协议 协议用于通信，例如配置节点（SDO）或传输实时数据（PDO） 定义了设备之间通信的机制和方式，包括对象字典、服务数据对象（SDO）、过程数据对象（PDO）、网络管理（NMT）等。 设备状态 设备支持不同的状态。”主”节点可以更改”从”节点的状态，例如将其重置。 对象字典（Object Dictionary，OD） 每个 CANopen 设备都有一个对象字典，OD 带有指定设备配置的条目，类似于一个查找表，列出了设备中的所有参数和数据。对象字典包括通信对象和应用对象，使用 16 位索引和 8 位子索引进行标识。可以通过 SDO 访问。 EDS（Electronic Data Sheet） EDS 是用于 OD 的标准文件格式，允许更新设备的服务 通讯模式CANopen 通过不同的通讯模式在节点之间传输报文: 生产消费模式: 它是一个广播连接，以推送模式工作（信号生产节点向消费节点发送无任何特定要求的信息）和引入模式（消费节点向信号生产节点要求特定信息）。 用户机服务器模式: 通过 SDO 协议，用户节点向服务器节点要求数据（对象字典索引），然后服务器节点通过发送在指定索引处的对象内容来响应。 主机从机模式: 主机节点可在任何时候向从机节点发送或要求数据。例如：NMT 协议通信。 数据帧数据帧由帧头 + 数据区组成，帧头由功能 ID+NodeID+RTR(远程传输请求)构成。 11 位的 CAN ID 称为通信对象标识符（COB-ID），分为两个部分： 前 4 位等于功能代码 Function Code（代表一个 CANopen 通信对象） 后 7 位包含节点 IDNode ID CANopen 网络中使用的 COB-ID 标识符的预定义分配 数据区部分的定义就要通过 CANopen 中的重要概念，对象字典 OD 来实现。 对象字典 OD对象字典（OD）是 CANopen 协议的核心概念。它是一组预定义的 CANopen 对象，使用索引和子索引访问对象。对象字典提供了应用程序和设备之间的沟通方式，提供了配置该设备的途径，和与设备通信的方法。 所有 CANopen 节点必须具有对象字典（OD），对象字典是指含有描述的 CANopen 节点的 行为 的所有 参数 的 标准化结构。 设备（例如从设备）的 OD 条目可以由其他设备（例如主机）使用 SDO 通过 CAN 进行访问。例如，通过 SDO 可以使应用程序主机更改从属发送心跳的频率。 作为对象索引存储在对象字典中的信息包括： 通信和应用程序配置参数 标准化设备配置参数 制造商特定设备配置文件参数 设备配置静态数据类型 设备配置复杂数据类型 复杂和静态数据类型 制造商特定数据类型 其他 可以按照 CANopen 标准的指导，以预定义的方式添加自己特定的制造商配置和数据类型。制造商还可以通过扩展由标准设备配置和数据类型规范要求的标准设备功能，来增强其设备的功能。 主索引索引值低于 0x0FFF 的是一些数据类型定义。一个节点的对象字典的有关范围在 0x1000 到 0x9FFF 之间，该范围内定义了一系列称为子协议的文档，用于定义节点的通讯行为。 通讯子协议区域详细划分 通用通讯对象 OD 示例配置下图是一个 TPDO 的定义示例，该 TPDO 在主索引 0x1800 的子索引中定义该 TPDO 相关的通信参数，主要是 TPDO 的发送类型和触发事件等设置，同时在和 0x1800 地址对应的 0x1A00 中定义了映射参数，在该参数的子索引中，定义了具体的映射地址和对象。并给出了该 TPDO 消息在发送时数据区内容。 电子数据表（EDS）一个节点的对象字典是在电子数据文档（EDS：Electronic Data Sheet）中描述。 实际上，将使用适当的软件工具来配置管理复杂的 CANopen 网络。 一个电子数据表（EDS）是一个标准化的电子文件，描述为 CANopen 设备定义的通信功能和对象。此供应方生成的文件有 3 个区域： 关于 EDS 文件的信息 一般设备信息 具有默认变量的对象字典 EDS 文件可用作 CANopen 设备的配置和网络设置工具。 通讯协议通信对象CANopen 通信单元由必要的通信接口和协议软件组成，通过总线在节点之间进行通信对象的发送和接收。各种 CANopen 通信对象用于实现各种类型的通信，CANopen 协议定义了几种不同类型的通信对象，每种对象都用于特定的通信目的： 过程数据对象（PDO）：用于实时数据传输，具有高优先级和低延迟。PDO 传输的数据量小，但传输速度快，适用于传感器数据和控制命令等实时性要求高的场景。 服务数据对象（SDO）：用于非实时数据传输，如配置参数和大数据块的传输。SDO 传输的灵活性更大，但优先级较低，适用于设备配置和诊断等场景。 网络管理对象（NMT）：用于控制设备状态和网络操作模式，如启动、停止和复位设备。 同步对象（SYNC）：用于网络同步，确保所有节点在同一时间点进行操作。 时间戳对象（TIME）：提供时间参考，用于时间相关的操作。 紧急情况对象 (EMCY) ： 指定状态下可用的通讯对象及状态转换说明： 中括号内的字母表示处于不同状态那些通讯对象可以使用。 a. NMTb. Node Guard c. SDO d. Emergencye. PDO f. Boot-up 网络管理（NMT）所有的 CANopen 节点都有自己专属的 NMT 状态，而主站可以通过 NMT 去控制从站的状态。CANopen 的网络管理采取主机从机通信模式。整个网络被设置为一个”状态机”，其中一个设备被指定为 NMT 主机，其余设备被指定为 NMT 从机。NMT 主机控制和监控 NMT 从机的状态。通过 NMT 主机触发，NMT 从机进行状态转换，实现 CANopen 网络的各个阶段。 NMT 服务用于通过 NMT 命令来控制 CANopen 设备的状态。只有 NMT-Master 节点能够传送 NMT Module Control 报文。所有从设备必须支持 NMT 模块控制服务。NMT Module Control 消息不需要应答。为了更改状态，NMT 主设备发送 COBID+2 字节的消息。 COB-ID 为 0（function code0 和 node ID0），优先级为最高。 第一个 CAN 数据字节 Requested State 包含请求的状态 第二个 CAN 数据字节包含目标节点的节点 ID。节点 ID 0 表示广播命令。所有从节点都处理此消息。 通过具体的 NMT 协议，如启动协议、模块控制协议、心跳协议（Heartbeat Protocol）和节点监测，主机向从机发出状态更改命令，进行这些状态转换。NMT 主机向特定节点或所有节点发送 NMT 命令代码以改变状态。 在预运行状态下，应用程序配置工具可以使用SDO 通信，配置 NMT 从机和设置参数。由于设备尚未开始运行，因此在此状态下不能使用 PDO 通信。 一旦状态从预运行变为运行状态，节点中的所有通信对象都将变为活跃状态，并且运行节点之间均可进行 PDO 和 SDO 通信。在此阶段，也可以通过 SDO 访问对象字典。当节点状态更改为停止时，PDO 和 SDO 通信都将停止。 实际状态取值 步骤 Byte 0 取值（命令） 状态 （2） 01 operation （3） 02 stop （4） 80 pre-operation （5） 81 reset app （6） 82 reset communication 示例# node 0x6 进入 `operational` 模式000 01 06# 所有节点进入 `pre-operational` 模式000 80 00 服务数据对象（SDO）SDO 提供了直接访问 CANopen 设备对象字典的入口，入口条件包括数据类型及大小。 访问者被称作客户端(client)，对象字典被访问且提供所请求服务的 CANopen 设备别称作服务器(server)。任何类型的 SDO 传输都由客户端发起，数据字典 OD 持有者是服务端，客户端和服务端都可以主动中止传输。通常情况下 CAN 总线网络中只有一个客户端。 客户的 CAN 报文和服务器的应答 CAN 报文总是包含 8 字节数据（尽管不是所有的数据字节都一定有意义）。一个客户的请求一定有来自服务器的应答。如果超时没有确认，则客户端节点将会重新发送原报文。 SDO 服务用于访问更改 CANopen 设备的对象字典中的值。允许 CANopen 节点通过 CAN 网络读取另一个节点的对象字典编辑值。下载（Download）是指对对象字典进行写操作，上传（Upload）指对对象字典进行读操作。 客户端节点可以通过以下 CAN 帧广播来启动 SDO 下载到节点 5，这将触发节点 5（并被其他节点忽略）。SDO 客户端的”接收”（即请求）CAN 帧如下所示： SDO 消息变量数据区 Byte 说明： Byte0 命令字节，主要定义了以下内容： CCS（客户端命令说明符，Client Command Specifier）描述传输类型（下载 download上载 upload） n 是数据字节 4-7 中不包含数据的 bytes （如果设置了 e＆s 则有效） 如果设置，e 表示 快速传输(所有数据在单个 CAN 帧中)分段传输 如果设置，s 表示数据大小显示在 n 中 Byte1+Byte2 主索引字节（16 位）确认 OD 主索引 Byte3 子索引字节（8 位）确认 OD 子索引 Byte4-7 包含实际的数据内容 一旦节点（客户端）发送了 CAN 帧，从节点 5（服务端）便会通过 RSDO 进行响应，并带有 COB-ID585。该响应包含索引子索引和 4 个空数据字节。自然地，如果客户端节点请求上传（即从节点 5 OD 读取数据），则节点 5 将以字节 4-7 中包含的相关数据进行响应。 SDO 灵活，但会带来大量输出，使其不适用于实时操作数据。同时数据只能包含在后续 4 个字节中，对于较大的数据方案，无法一次传输完毕。因此 SDO 中实现了 2 种传送机制，两种传送机制实际包含 4 个请求应答协议，共有 5 个协议如下： 快速传送（Expedited transfer） ： 最多传输 4 字节数据 启动域下载 （Initiate Domain Download） 启动域上传 （Initiate Domain Upload） 分段传送（Segmented transfer） ： 传输数据长度大于 4 字节 域分段下载（Download Domain Segment） 域分段上传 （Upload Domain Segment） 域传送中止（Abort Domain Transfer）。 快速 SDOCommand specifier(CS)命令符: 0x40 读取命令 0x2F 写一个字节 0x4F 返回值响应一个字节 0x2B 写两个字节 0x4B 返回值响应两个字节 0x27 写三个字节 0x47 返回值响应三个字节 0x23 写四个字节 0x43 返回值响应四个字节 0x60 写成功应答 0x80 异常响应 启动域下载（Initiate Domain Download） Bit 7 6 5 4 3 2 1 0 客户端 0 0 1 - n n e s 服务器 0 1 1 - - - - n ： 如果 e=1 且 s=1，则有效，否则为 0；表示数据部分中无意义数据的字节数（字节 8－n 到 7 数据无意义）。 e ： 0 正常传送，1 加速传送（数据在一个帧中）。 s ： 是否指明数据长度，0 数据长度未指明，1 数据长度指明。 e 0， s 0： 由 CiA 保留。 e 0， s 1 ： 数据字节为字节计数器，byte 4 是数据低位部分（LSB），byte 7 是数据高位部分（MSB）。 e 1 ： 数据字节为将要下载（download）的数据。 启动域上传（Initiate Domain Upload） Bit 7 6 5 4 3 2 1 0 客户端 0 1 0 - - - - - 服务器 0 1 0 - n n e s n，e，s： 与启动域下载相同。 分段 SDO域分段下载（Download Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 0 0 t n n n c 服务器 0 0 1 t - - - - n ：无意义的数据字节数。如果没有指明段长度，则为 0。 c ： 0 有后续分段需要 download，1 最后一个段。 t ： 触发位，后续每个分段交替清零和置位（第一次传送为 0，等效于 requestresponse）。 域分段上传（Upload Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 1 1 t - - - - 服务器 0 0 0 t n n n c n，c，t ： 与域分段下载相同。 示例通讯示例 -upload 数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 40 00 14 02 00 00 00 00 若成功，应答： 585 4F 00 14 02 FE 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 40 02 18 01 00 00 00 00 若成功，应答：585 60 02 18 01 08 02 12 60 通讯示例 -download数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 2F 00 14 02 FE 00 00 00 若成功，应答： 585 60 00 14 02 00 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 23 02 18 01 08 02 12 60 若成功，应答：585 60 02 18 01 00 00 00 00 过程数据对象（PDO）PDO 属于过程数据，即单向传输，无需接收节点回应 CAN 报文来确认，从通讯术语上来说是属于”生产消费”模型。、生产者”生产数据”，并使用 Transmit PDO（TPDO）将其传输到”消费者”（主用户）。相反，它可以通过 Receive PDO（RPDO）从使用者接收数据。 PDO 服务用于在设备之间传输实时数据，例如来自温度传感器的温度数据。PDO 承载大量信息，被视为最重要的 CANopen 协议。PDO 消息可以包含 8 个完整字节的数据，并且它可以在单个帧中包含多个对象参数值。因此在 PDO 服务中用 1 帧完成 SDO 至少需要 4 帧的操作。 带有特定 11 位 CAN 标识符的 TPDO 由一个设备发送，并作为 RPDO 由零个或多个设备接收。每个 PDO 在对象字典中用 2 个对象描述： PDO 通讯参数：包含哪个 COB-ID 将被 PDO 使用，传输类型，禁止时间和定时器周期。在索引 0x1400+ 和 0x1800+ 的对象字典中。 PDO 映射参数：包含一个对象字典中对象的列表，这些对象映射到 PDO 里，包括它们的数据长度（in bits）。生产者和消费者必须知道这个映射，以解释 PDO 内容。在索引 0x1600+ 和 0x1A00+ 的对象字典中。 生产者节点可以被配置为每 100ms 响应消费者所广播的 SYNC 触发。然后，节点 5 可以例如在下面广播，以 COB-ID 185 的 TPDO： 注意数据区部分 3 个参数值的打包方式，这些值是由数据字典中对应的映射结构决定了一个 PDO 的数据类型和映射关系。 通信参数定义了该设备所使用的 COB-ID、传输类型、定时周期等。RPDO 通讯参数位于对象字典索引的 0x1400 to 0x15FF，TPDO 通讯参数位于对象字典索引的 0x1800 to 0x19FF。每条索引代表一个 PDO 的通信参数集，其中的子索引分别指向具体的各种参数。PDO 消息的内容是预定义的（或者在网络启动时配置的）。 Number of entries 参数条目数量：即本索引中有几条参数； COB-ID：即这个 PDO 发出或者接收的对应 CAN 帧 ID； 发送类型：即这个 PDO 发送或者接收的传输形式，通常使用循环同步和异步制造商特定事件较多； Inhibit time 生产禁止约束时间(110ms)：约束 PDO 发送的最小间隔，避免导致总线负载剧烈增加，比如数字量输入过快，导致状态改变发送的 TPDO 频繁发送，总线负载加大，所以需要一个约束时间来进行”滤波”，这个时间单位为 0.1ms； Event timer 事件定时器触发的时间(单位 ms)：定时发送的 PDO，它的定时时间，如果这个时间为 0，则这个 PDO 为事件改变发送。 SYNC start value 同步起始值：同步传输的 PDO，收到诺干个同步包后，才进行发送，这个同步起始值就是同步包数量。比如设置为 2，即收到 2 个同步包后才进行发送。 发送类型PDO 可以有多种发送类型： 同步（通过接收 SYNC 对象实现同步） 非周期：远程帧预触发传送或设备子协议中规定的对象特定事件预触发传送。 周期：传送在每 1 到 240 个 SYNC 消息后触发。 异步 远程帧触发传送。通过发送与 PDO 的 COB-ID 相同的远程帧来触发 PDO 发送 由设备子协议中规定的对象特定事件触发传送。（基本采用这种，例如定时传输，数据变化传输等） 由传输类型定义的不同 PDO 传输模式，传输类型为 PDO 通讯参数对象的一部分，由 8 位无符号整数定义。 间隔时间一个 PDO 可以指定一个禁止时间，即定义两个连续 PDO 传输的最小间隔时间，避免由于高优先级信息的数据量太大，始终占据总线，而使其它优先级较低的数据无力竞争总线的问题。禁止时间由 16 位无符号整数定义，单位 100us。 定时周期一个 PDO 可以指定一个事件定时周期，当超过定时时间后，一个 PDO 传输可以被触发（不需要触发位）。事件定时周期由 16 位无符号整数定义，单位 1ms。 映射参数RPDO 通讯参数 1400h to 15FFh，映射参数 1600h to 17FFh，数据存放为 2000h 之后厂商自定义区域； TPDO 通讯参数 1800h to 19FFh，映射参数 1A00h to 1BFFh，数据存放为 2000h 之后厂商自定义区域。 包含了一个对象字典中的对象列表，这些对象映射到相应的 PDO，其中包括数据的长度（单位，位），对于生产者和消费者都必须要知道这个映射参数，才能够正确的解释 PDO 内容。就是将通信参数、应用数据和具体 CAN 报文中数据联系起来。 子索引 0：PDO 中映射应用程序对象的数量： 值 0：映射被禁用。 值 1：子索引 0x01 有效。 值 2-8: 子索引 0x01 至 (0x02 至 0x08) 有效。 子索引 1-8： 应用对象 1-8： 位 16-31：索引 位 8-15：子索引 位 0-7：数据长度（位） 示例示例设备配置 节点 ID: 0x01 第二个 Transmit PDO (TPDO2): TPDO2 的 COB-ID: 0x280 + Node_ID 0x281 对象字典（Object Dictionary）定义： 0x1801: TPDO2 通信参数 子索引 0x00: 0x02 (表示有 2 个子索引) 子索引 0x01: 0x00000281 (TPDO2 的 COB-ID, 使能) 子索引 0x02: 0x00 (传输类型，假设为 0x00 表示同步传输) 0x1A01: TPDO2 映射参数 子索引 0x00: 0x02 (映射对象数量，表示有两个对象映射到这个 TPDO) 子索引 0x01: 0x60000208 (映射对象 0x6000，子索引 0x02，8 位) 子索引 0x02: 0x64010110 (映射对象 0x6401，子索引 0x01，16 位) 假设当前设备中的数据如下： 对象 0x6000，子索引 0x02: 0xAB 对象 0x6401，子索引 0x01: 0x1234 TPDO2 实际发送的 CANopen 数据帧报文由以下 3 个字节组成： Byte 0: 0xAB Byte 1: 0x34 (低 8 位) Byte 2: 0x12 (高 8 位) 实际的 CANopen 数据帧：CAN ID: 0x281 Data: [0xAB, 0x34, 0x12] 设置一个 TPDO Index 1800 + n，subindex 01 ，COB_ID（通讯对象的标识符）：包含 CAN-ID 和附加控制位的标识符 Index 1800 + n，subindex 02， 写传输类型 t， t 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t FD ：收到 PDO 请求后 t FE ：事件驱动（制造商指定） t FF ：事件传输，节点自发传输 PDO Index 1800 + n， subindex 03，抑制时间。 如果传输类型设置为 FE 和 FF，它是最小的 PDO 传输间隔，单位 100us，值为 0 禁用抑制时间。PDO 报文需要延时 t × 100us 的时间才发出，以此避免在多 PDO 报文同时发出时，引起的时间冲突 。 Index 1800 + n， subindex 05，时间定时器。 如果传输类型设置为 FE 和 FF，它是 PDO 传输间隔，单位 ms，值为 0 禁用。t 0xC8，200ms。 Index 1A00 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 18 02 FF 00 00 00 设置索引 Index 1800，事件传输 605 2F 00 18 05 C8 00 00 00 设置索引 Index 1800，时间间隔 200ms 605 2F 00 1A 00 00 00 00 00 设置子索引禁用 605 23 00 1A 01 10 00 30 400x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 23 00 1A 02 20 00 10 200x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） 605 2F 00 1A 00 02 00 00 00 设置映射数量，用多少设多少，这里用了 2 个 设置一个 RPDO Index 1400 + n, subindex 01 ，COB_ID（通讯对象的标识符） Index 1400 + n, subindex 02，写传输类型 t， t 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t FD ：收到 PDO 请求后 t FE ：事件驱动（制造商指定） t FF ：事件传输，节点自发传输 PDO Index 1600 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 14 02 FF 00 00 00 设置索引 Index 1400，事件传输 605 2F 00 16 00 00 00 00 00 设置子索引禁用 605 23 00 16 01 10 00 30 40 设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 2F 00 16 00 01 00 00 00 设置映射数量，用多少设多少，这里用了 01 定义映射时，先设置子索引禁用；再设置相应映射；然后设置映射数量对于 TPDO 来说，其通信参数中的 COB-ID 是自身的 COB-ID，当发送 TPDO 时用来表明这个 TPDO 是谁发出的。对于 RPDO 来说，其通信参数的 COB-ID 是发送方的 COB-ID，用来表示自己只接受某个 CAN 节点发过来的 TPDO。 同步（SYNC）SYNC 消息通常由应用程序主机触发。每个节点都以该同步报文作为 PDO 触发参数，因此该同步报文的 COB-ID 具有比较高的优先级以及最短的传输时间。一般选用 0x80 作为同步报文的 CAN-ID，将 SYNC 消息（COB-ID 080）发送到 CANopen 网络。 在网络范围内同步（尤其在驱动应用中）：在整个网络范围内当前输入值准同时保存，随后传送（如果需要），根据前一个 SYNC 后接收到的报文更新输出值。 主从模式：SYNC 主节点定时发送 SYNC 对象，SYNC 从节点收到后同步执行任务。 在 SYNC 报文传送后，在给定的时间窗口内传送一个同步 PDO。 用 CAL 中基本变量类型的 CMS 对象实现。 CANopen 建议用一个最高优先级的 COB-ID 以保证同步信号正常传送。SYNC 报文可以不传送数据以使报文尽可能短。 一般同步报文由 NMT 主机发出，CAN 报文的数据为 0 字节。但如果一个网络内有 2 个同步机制，就需要设置不同的同步节拍，比如某些节点按 1 个同步帧发送 1 次 PDO，其他的节点收到 2 个同步帧才发送 1 次 PDO，所以这里 PDO 参数中的同步起始值就起了作用。 在同步协议中，有 3 个约束条件： 同步命令：0x1005 中规定了同步帧的命令为 0x80； 通讯循环周期：索引 0x1006 规定了同步帧的循环周期； 同步窗口时间：索引 0x1007 约束了同步帧发送后，从节点发送 PDO 的时效，即在这个时间内发送的 PDO 才有效，超过时间的 PDO 将被丢弃。 示例配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值） 23 05 10 00 80 00 00 00 读取 1006 信息 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms 100000us） 23 06 10 00 A0 86 01 00 时间戳（TIME-stamp）时间标记对象（Time Stamp），NMT 主机发送自身的时钟，为网络各个节点提供公共的时间参考，即网络对时，这在故障诊断中非常需要。 时间戳协议采用广播方式，无需节点应答，CAN-ID 为 0x100，数据长度为 6，数据为当前时刻与 1984 年 1 月 1 日 0 时的时间差。节点将此时间存储在对象字典 1012h 的索引中。 主机发出带有 CAN ID 100 的 TIME 消息，TIME 服务包含一个 6 字节的日期和时间信息。其中最初的 4 个数据字节包含午夜之后的毫秒数，随后的 2 个字节包含自 1984 年 1 月 1 日以来的天数。 紧急情况（EMCY）紧急报文协议（Emergency protocol）用于设备发生致命错误（例如传感器故障）的情况，从而使其可以向网络的其余部分指示此错误。 受影响的节点以高优先级向网络发送发送设备内部错误代码，提示 NMT 主站。紧急报文属于诊断性报文，一般不会影响 CANopen 通讯，其 CAN-ID 存储在 0x1014 的索引中，一般会定义为 0x080 + node-ID，数据包含 8 个字节，例如，节点 5 具有 COB-ID 085 + 数据字节，数据字节包含有关错误的信息，可以查找厂商定义的错误代码。 紧急信息的内容如下 Bytes 0…1： CO_EM_errorCode_t，在本例中为 0x5000（设备硬件） Bytes 2：CO_errorRegister_t，本例中为 0x01（通用错误） Bytes 3：CO_EM_errorStatusBits_t 中的错误条件索引，本例中为 0x2F（CO_EM_NON_VOLATILE_MEMORY - 访问非易失性设备内存时出错） Bytes 4…7：附加信息参数，本例中为 0x00000014 或 0x00000074 紧急信息由 CO_errorReport() 函数内部触发。可以在 CO_EM_NON_VOLATILE_MEMORY 的源代码中查找紧急信息的来源。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不等于零，则禁止节点进入 NMT 运行状态，并且不能与其交换 PDO。 节点监测NMT 主机定期使用远程帧询问从机的当前状态，并将其与网络数据库中记录的早期状态相比较。任何不匹配和缺少 PDO 传输的状态都会以适当的错误代码表示，然后应用程序将采取适当的操作，如设备重置或错误标识。这称为节点监测，是通过使用节点监测协议得以实现。 NMT 从机使用一种称为生命监测的技术，通过在预定义的时间间隔里，内部检查节点监测帧的接收，来检测 NMT 主机的缺失。 现代设备设计使用 Heartbeat 协议进行节点监视，其中 NMT 从设备（Heartbeat Producer 心跳发出者）将周期性地向 NMT 主设备（Heartbeat Consumer 心跳使用者）发送 Heartbeat 报文。 这些报文之间的间隔是可配置的，并在主、从两个设备的对象字典中 Heartbeat producer time（心跳产生时间）对象上都进行设置。如果心跳报文在此时间限制内未到达，则发出者将被视为关机，使用者将采取补救措施，如设备重置或错误显示。 当一个 Heartbeat 节点启动后它的 Boot-up 报文是其第一个 Heartbeat 报文。Heartbeat 消费者通常是 NMT-Master 节点，它为每个 Heartbeat 节点设定一个超时值，当超时发生时采取相应动作。 示例读取心跳时间设置 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 2B 17 10 00 E8 03 00 00 Master 节点发送远程帧（无数据）NMT-Master - NMT-Slave COB-ID 0x700 + Node_ID NMT-Slave 节点发送如下报文应答 NMT-Master - NMT-Slave COB-ID 0x700 + Node_ID Byte0 Bit 7-0 : 状态 LSSLSS（Layer Setting Services）是一个用于配置和管理 CANopen 设备的一种服务。它提供了一些特定的功能，主要用于设备的初始化和配置，例如设置节点 ID 和波特率。LSS 对于在生产、调试和运行过程中配置 CANopen 设备非常有用。 LSS 的主要功能 设置节点 ID： 在 CANopen 网络中，每个节点都有一个唯一的节点 ID，范围为 1 到 127。LSS 允许动态设置或修改节点 ID，而不需要物理访问设备。这在设备初始安装和替换时特别有用。 设置波特率： CANopen 网络中的所有节点必须使用相同的波特率进行通信。LSS 允许动态修改设备的波特率，以便在不同的网络条件下进行适应和优化。 设备识别： LSS 可以用于识别网络中的设备。通过 LSS 服务，可以查询设备的唯一标识符（例如制造商代码、产品代码、序列号等），从而实现设备的识别和管理。 LSS 服务的主要操作 Switch Mode Global： 切换所有节点到配置模式或操作模式。 Switch Mode Selective： 选择性地切换特定节点到配置模式或操作模式。 Configure Node-ID： 设置节点 ID。 Configure Bit Timing Parameters： 设置 CAN 总线的波特率参数。 Identify Remote Slave： 识别网络中的设备，读取其唯一标识符。 LSS 协议的示例假设们需要将一个设备的节点 ID 设置为 0x02，并将波特率设置为 250 kbps。以下是使用 LSS 的步骤： 切换到配置模式： 发送 LSS Switch Mode Selective 命令，将目标设备切换到配置模式。 设置节点 ID： 使用 LSS Configure Node-ID 命令，设置设备的节点 ID。 设置波特率： 使用 LSS Configure Bit Timing Parameters 命令，设置设备的波特率。 切换到操作模式： 发送 LSS Switch Mode Global 命令，将所有设备切换到操作模式。 LSS 消息格式LSS 消息使用特定的 CAN 标识符和数据格式。以下是 LSS Switch Mode Selective 命令的示例： CAN ID：0x7E5（LSS 主站到从站） 数据：0x04 0x00 0x00 0x00 0x00 0x00 0x00 0x00（切换到配置模式） 设置节点 ID 的命令： CAN ID：0x7E5 数据：0x11 0x02 0x00 0x00 0x00 0x00 0x00 0x00（设置节点 ID 为 0x02） 设置波特率的命令： CAN ID：0x7E5 数据：0x13 0x03 0x00 0x00 0x00 0x00 0x00 0x00（设置波特率为 250 kbps，假设 0x03 表示 250 kbps）","categories":["3.协议","CAN"]},{"title":"CANOpen 调试","path":"/2024/01/03/3-协议-CAN-CANOpen-调试/","content":"作为 CAN Open 总线上的数据抓取设备，要求程序具有以下功能 能够作为总线上的从机设备，要求具有以下功能： HeartBeat 本设备 SDO 配置项 PDO 数据配置 如何通过主机 ASK 某一设备的数据 能够作为总线上的主机设备，要求具有以下功能： 从机设备的状态管理 PDO 数据采集 例如，预配置的过程数据对象 (PDO) 由生产者传输。每个 PDO 可能由多个节点使用。每个 CANopen 设备的其他有用的 CANopen 功能还包括：心跳生产者和消费者、紧急生产者、同步生产者或消费者、时间生产者或消费者、SDO 服务器（服务数据对象 - 从对象字典中提供变量）、NMT 从属（网络管理 - 启动或停止通信部分）、LSS 从属（节点 ID 和比特率的配置）。 CANopen 网络通常有一个具有命令功能的设备用于网络配置，例如：NMT 主站、LSS 主站、SDO 客户端、紧急消费者。CANopenNode 中的命令功能根据标准 CiA309-3 使用 Ascii 命令行接口实现。 使能 CAN 接口Linux 下 虚拟 CAN 设备modprobe 是 Linux 系统中的一个命令行工具，用于管理内核模块。内核模块是可以动态加载或卸载的可扩展组件，允许 Linux 内核在运行时添加或删除功能而不需要重启系统。常见的内核模块包括设备驱动程序、文件系统支持以及网络协议等。 创建一个虚拟 CAN 设备，并启用 sudo modprobe vcansudo ip link add dev can0 type vcansudo ip link set up can0 安装 CAN 监测调试工具，can-utils 项目地址 https://github.com/linux-can/can-utils sudo apt-get install can-utilscandump -td can0 #显示can消息 rk3568 的 can 使用时 ip link set can0 up 启用失败报错： can0: incorrect missing data bit-timing 驱动问题，设备树中的节点配置，需要将 kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi 中的 can0 节点中的 compatible = rockchip,canfd-1.0 修改为 compatible = rockchip,can-1.0，重新编译后下载 开发板 3568 的 CANifconfig can0 downip link set can0 up type can bitrate 500000ifconfig can0 upifconfig can1 downip link set can1 up type can bitrate 500000ifconfig can1 upip link set can0 downip link set can1 downip link set can0 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd onip link set can1 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd on#查询当前网络设备:ifconfig -a#关闭CAN:ip link set can0 down#设置比特率500KHz:ip link set can0 type can bitrate 500000#打印can0信息:ip -details -statistics link show can0#启动CAN:ip link set can0 up#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123#DEADBEEF#发送（标准帧,远程帧,ID:123）:cansend can0 123#R#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123#12345678#发送（扩展帧,远程帧,ID:00000123）:cansend can0 00000123#R#开启打印，等待接收:candump can0###########################################设置can fd#设置仲裁段1M波特率，数据段3M波特率:ip link set can0 type can bitrate 1000000 dbitrate 3000000 fd on#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123##1DEADBEEF#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123##1DEADBEEFifconfig -aip link set can0 type can bitrate 500000ip link set can0 upip link set can1 type can bitrate 500000ip link set can1 upcandump can0 cansend can1 123#DEADBEEFcansend can1 123#DEADBEEF 这个命令是用于配置 CAN（Controller Area Network，控制器局域网络）接口的 Linux 命令行指令。CAN 是一种用于实时应用的车辆、工业控制及自动化领域的串行通信协议。下面是对该命令各部分含义的详细解析： ip link set can0 up 这部分命令是用来设置指定的网络接口（%s 是一个占位符，通常在脚本中使用，运行时会被实际的接口名称替换）为活动状态（up）。这意味着它将启动指定的 CAN 接口，使其准备好进行数据传输。 type can 指定接口类型为 CAN 总线。这是告诉系统该接口应该被配置和处理为 CAN 总线接口，而不是以太网或其他类型的网络接口。 bitrate 500000 设置 CAN 总线的比特率（通信速度）。500000 代表具体的比特率值，例如 125000 表示 125Kbps。比特率是指每秒钟传输的位数，是 CAN 总线配置中的一个关键参数，需要所有连接到同一总线上的设备匹配。 sample-point 0.75 配置 CAN 位采样点的位置。采样点是在每个 CAN 位的哪个时间点进行信号采样以确定位的逻辑电平（0 或 1）。值范围从 0 到 1，其中 1 代表位时间周期的结束。这里设置为 0.75 意味着在每位的 75%时间点进行采样。 dbitrate 4000000 分布式比特率（Data Bit Rate）设置。这通常用于 FlexCAN（Flexible Data-Rate CAN）等高级 CAN 协议变体中，允许数据段的比特率与仲裁段不同。这里设置为 4000000 表示数据段的比特率为 4Mbps。但需要注意的是，标准 CAN 协议并不支持不同的数据和仲裁比特率，这一选项可能特定于某些高级 CAN 控制器或实现。 dsample-point 0.8 数据段的采样点位置，类似于上述的 sample-point，但特指数据段（如果适用）。在这个例子中，数据段的采样点被设置在每位的 80%时间点。 fd on 启用 CAN FD（Flexible Data-rate CAN）模式。CAN FD 是 CAN 总线协议的一个扩展，允许更灵活的数据长度和更高的数据传输速率，旨在提高 CAN 网络的数据吞吐量。 CAN 通信测试工具canutils 是常用的 CAN 通信测试工具包，内含 5 个独立的程序：canconfig、candump、canecho、cansend、cansequence。 这几个程序的功能简述如下： canconfig 用于配置 CAN 总线接口的参数，主要是波特率和模式。 candump 从 CAN 总线接口接收数据并以十六进制形式打印到标准输出，也可以输出到指定文件。 canecho 把从 CAN 总线接口接收到的所有数据重新发送到 CAN 总线接口。 cansend 往指定的 CAN 总线接口发送指定的数据。 cansequence 往指定的 CAN 总线接口自动重复递增数字，也可以指定接收模式并校验检查接收的递增数字。 ip CAN 波特率、功能等配置。 注意：busybox 里也有集成了 ip 工具，但 busybox 里的是阉割版本。不支持 CAN 的操作。故使用前请先确定 ip 命令的版本（iproute2）。上面工具包，网络上都有详细的编译说明。如果是自己编译 buildroot，直接开启宏就可以支持上述工具包。 BR2_PACKAGE_CAN_UTILS=yBR2_PACKAGE_IPROUTE2=y CAN 比特率和采样点计算目前 CAN 架构根据输入频率和比特率自动计算。采样点的规则按照 CIA 标准协议： /* Use CiA recommended sample points */if (bt-sample_point) sample_point_nominal = bt-sample_point; else if (bt-bitrate 800000) sample_point_nominal = 750;\telse if (bt-bitrate 500000) sample_point_nominal = 800;\telse sample_point_nominal = 875; 比特率计算公式（详细原理可以百度，这里只介绍芯片配置相关）： BitRate = clk_can / (2 *(brq + 1) / ((tseg2 + 1) + (tseg1 + 1) + 1)Sample = (1 + (tseg1 + 1)) / (1 + (tseg1 + 1) + (tseg2 + 1)) brq、tseg1、tseg2 见 CAN 的 TRM 中 BITTIMING 寄存器。 CAN Open 用例分析SDO 命令-状态恢复和存储紧急信息、错误寄存器和 NMT 运行前状态在未初始化的非易失性存储器中都有数据源。对象 0x1010 和 0x1011 用于存储和恢复数据，通常来自 CANopen 对象字典。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不为零，则可能禁止节点进入 NMT 操作状态，并且无法与其交换 PDO。 恢复所有非易失性存储器： CAN ID：0x600 + 节点 ID（表示从主机到从节点的 SDO 请求）。0x600 + 4 0x604。 命令字节：表示写入命令和数据长度。0x23 表示写入 4 字节数据（visible string）。 索引：对象字典索引。0x1011（字节顺序为低字节在前）。 子索引：对象字典子索引。0x01 数据：load：ASCII 码 l、o、a、d 分别为 0x6C、0x6F、0x61、0x64。 构建数据恢复 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x11 0x10），子索引（0x01），数据（0x6C 0x6F 0x61 0x64）。 can0 604 [8] 23 11 10 01 6C 6F 61 64 save：ASCII 码 s、a、v、e 分别为 0x73、0x61、0x76、0x65。 构建数据存储 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x10 0x10），子索引（0x01），数据（0x73 0x61 0x76 0x65）。 can0 604 [8] 23 10 10 01 73 61 76 65 NMT 命令-设置 NMT 状态报文可以发送给特定节点或所有节点。它们可以重置设备、通信或将远程设备的内部状态设置为运行、预运行（禁用 PDO）或停止（仅启用心跳生产者和 NMT 消费者）。 当出现了设置错误寄存器的紧急状况时，start 不起作用。 设置 Node ID 为 4 的设备状态为 reset。 000 82 04 Byte 0 取值（命令） 状态 01 start_remote_node 02 stop_remote_node 80 enter_pre-operational 81 reset_node 82 reset_communication SDO 命令-设置心跳包读取心跳时间设置CAN0 604 [8] 40 17 10 00 00 00 00 00 写入心跳时间设置 CAN ID：0x600 + 节点 ID（4） 0x604。 命令字节：0x2B 表示写入 2 字节（u16）。 索引：0x1017（字节顺序为 17 10）。 子索引：0x00。 数据：1000ms0x03E8，字节顺序为 E8 03。10000ms0x2710 can0 604 [8] 2B 17 10 00 E8 03 00 00 PDO 配置按以下步骤通过写入 OD 变量配置 PDO： 将 PDO 通信参数 COB-ID 中的第 31 位设置为 1，禁用 PDO。 只有禁用 PDO 时才能配置 Node-Id。 将 PDO 映射参数，子索引 0 设置为 0，禁用映射。 配置映射 通过设置 PDO 映射参数，子索引 0 至映射对象数启用映射 通过将 PDO 通信参数 COB-ID 中的第 31 位设置为 0 来启用 PDO 其他配置同步传输信号配置全局同步周期 SYNC 设置值保存在对象 1006h 中。 心跳CANopen 主站的对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 对象 1017h 的值(发生器心跳时间)被此处设置的值重写。适用于所有从站对象的对象 1017h(发生器心跳时间)的值被此处设置的值重写，对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 CAN Open 总线建设假定在一个 can open 网络中，node1 为主节点，node2 和 node3 为从节点，需要配置 node2，让 node2 接收 node3 的 TPDO 消息。 设备配置 设备名 节点地址 类型 Node 1 0x01 主节点（NMT Master） Node 2 0x02 从节点（NMT Slave） Node 3 0x03 从节点（NMT Slave） 其中 Node3 作为 TPDO 消息发出（生产者），期望 Node2 接收 Node3 消息。 PDO 参数配置配置所需信息配置 Node 3 的 TPDO： 确定 Node 3 的 TPDO 消息的 COB-ID 和映射对象。 在 Node 3 的对象字典中设置 TPDO 通信参数和映射参数。 配置 Node 2 的 RPDO： 设置 Node 2 的 RPDO 通信参数，使其接收 Node 3 的 TPDO 消息。 配置 Node 2 的 RPDO 映射参数，以处理从 Node 3 接收到的数据。 通讯参数和映射参数（OD）Node 3 的配置： TPDO 通信参数（0x1802）： 子索引 0x01: COB-ID 0x183 子索引 0x02: 传输类型（例如 0xFF，事件触发） TPDO 映射参数（0x1A02）： 子索引 0x00: 映射对象数量 2 子索引 0x01: 0x60000208（对象 0x6000，子索引 0x02，8 位） 子索引 0x02: 0x64010110（对象 0x6401，子索引 0x01，16 位） Node 2 的配置： RPDO 通信参数（0x1400）： 子索引 0x01: COB-ID 0x183（与 Node 3 的 TPDO COB-ID 一致） 子索引 0x02: 传输类型（例如 0xFF，事件触发） RPDO 映射参数（0x1600）： 子索引 0x00: 映射对象数量 2 子索引 0x01: 0x60000208（与 Node 3 的 TPDO 映射一致） 子索引 0x02: 0x64010110（与 Node 3 的 TPDO 映射一致） 配置过程设置 Node 3 的 TPDO 通信参数： CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 83 01 00 00] # 设置 COB-ID 为 0x183（启用）CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 3 的 TPDO 映射参数： CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 00 00 00 00] # 禁用 TPDO 映射CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 02 00 00 00] # 启用 TPDO 映射 设置 Node 2 的 RPDO 通信参数： CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 00 83 01 00 00] # 设置 COB-ID 为 0x183CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 2 的 RPDO 映射参数： CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 00 00 00 00] # 禁用 RPDO 映射CAN ID: 0x602 (SDO 请求)Data: [23 00 16 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x602 (SDO 请求)Data: [23 00 16 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 02 00 00 00] # 启用 RPDO 映射 通过上述步骤配置 Node 2 的 RPDO 通信参数和映射参数，使其能够接收和处理来自 Node 3 的 TPDO 消息。这种配置确保了 Node 2 能够正确接收和解析 Node 3 发送的 TPDO 数据，完成数据的有效传输和处理。 调试命令控制 NMT 状态 CAN0 000 [2] 01 04CAN0 000 [2] 02 04 控制节点 4 CAN0 000 [2] 01 00CAN0 000 [2] 02 00 控制所有节点 发送 SYNC 信号 CAN0 080 [0] 发送 ERROR 信号 CAN0 084 [8] 数据区根据实际错误定义 恢复参数，在 1011 的 01 写入 load CAN0 604 [8] 2F 11 10 01 6C 6F 61 64 读取 1005 信息（SYNC 的 COB-ID） CAN0 604 [8] 40 05 10 00 00 00 00 00 配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值）。 CAN0 604 [8] 23 05 10 00 80 00 00 00 读取 1006 信息(SYNC 通信周期) CAN0 604 [8] 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms 100000us）。 CAN0 604 [8] 23 06 10 00 A0 86 01 00 读取心跳时间设置 CAN0 604 [8] 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 CAN0 604 [8] 2B 17 10 00 E8 03 00 00 设置一个 TPDO配置 1800 的上报方式为异步，读取的话改 2F 为 40 CAN0 604 [8] 2F 00 18 02 FF 00 00 00 配置 1800 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 604 [8] 2B 00 18 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 604 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 604 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 604 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 604 [8] 2F 00 1A 00 02 00 00 00 设置 RPDO配置 1400 接收来自 181 的数据 CAN0 601 [8] 23 00 14 01 81 01 00 00 配置 1400 的上报方式为异步，读取的话改 2F 为 40 CAN0 601 [8] 2F 00 14 02 FF 00 00 00 配置 1400 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 601 [8] 2B 00 14 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 601 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 601 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 601 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 601 [8] 2F 00 1A 00 02 00 00 00","categories":["3.协议","CAN"]},{"title":"CANOpenNode 代码分析","path":"/2024/01/02/3-协议-CAN-CANOpenNode-代码分析/","content":"主文件 CO_main_basic.c进入 Main 函数中运行，最开始都是一些关于存储多线程功能启用部分的配置代码，后面们会根据宏定义来讲解。实际的第一行初始化代码从以下开始。 uint32_t heapMemoryUsed = 0;CO_config_t *config_ptr = NULL;CO = CO_new(config_ptr, heapMemoryUsed); 该函数的作用是创建一个 CAN open 对象，在单个 OD 的情况下，config 应为 NULL，参数从默认的 “OD.h “文件中获取。如果定义了 CO_USE_GLOBALS，那么函数将为所有 CANopenNode 对象使用全局静态变量。否则，它将从堆中分配所有对象。 CO_epoll_t epMain;err = CO_epoll_create(epMain, MAIN_THREAD_INTERVAL_US); 该函数创建 Linux epoll 监控 timerfd 和 eventfd。创建并配置多个 Linux 通知，以触发任务的执行。CO_epoll_create 中实现了 epoll 拦截并监控多个文件描述符，其中 timerfd 以恒定的定时器间隔触发，eventfd 则根据外部信号触发。 CO_CANptrSocketCan_t CANptr = 0;CANptr.can_ifindex = if_nametoindex(can0);CANptr.epoll_fd = epMain.epoll_fd; 设置用于 CO_CANinit 的指针参数，主要传入 CAN 设备名和监控的 epoll 描述符。 之后进入 CAN open 通讯初始化阶段，注意该阶段是可以通过 0x82 命令，即 CANopen communication reset 重置的。 CO_CANsetConfigurationMode((void *)CANptr);CO_CANmodule_disable(CO-CANmodule); 进入 CAN 配置，主要还是在通过 0x82 命令重启后，禁用 CANmodule 模块。 err = CO_CANinit(CO, (void *)CANptr, 0 /* bit rate not used */); 初始化 CAN 驱动，如果是通过 0x82 命令重启的通讯，也必须重新初始化。其中的波特率参数在 Linux 部分中还不被支持。之后是 LSS 部分的初始化，该部分内容属于 CiA 305，先略过，之后有时间在分析实现。 #define NMT_CONTROL \\ CO_NMT_STARTUP_TO_OPERATIONAL \\ | CO_NMT_ERR_ON_ERR_REG \\ | CO_ERR_REG_GENERIC_ERR \\ | CO_ERR_REG_COMMUNICATION err = CO_CANopenInit(CO, /* CANopen object */ NULL, /* alternate NMT */ NULL, /* alternate em */ OD, /* Object dictionary */ NULL, /* Optional OD_statusBits */ NMT_CONTROL, /* CO_NMT_control_t */ 500, /* firstHBTime_ms */ 1000, /* SDOserverTimeoutTime_ms */ 500, /* SDOclientTimeoutTime_ms */ false, /* SDOclientBlockTransfer */ CO_activeNodeId, //Node ID errInfo); 初始化除 PDO 对象外的 CAN open 通讯协议（同样也必须在 0x82 命令后调用）。 CO CANopen 对象。 em 紧急对象，用于不同的 CANopen 对象内部，通常用于错误报告。如果为空，则使用 co-em。如果为空，且 co-CNT_EM 为 0，则函数错误返回。 NMT 如果 co-CNT_NMT 为 0，则必须指定该对象；如果 co-CNT_NMT 为 1，则该对象将被忽略，可以为 NULL。NMT 对象用于 NMT 对象用于在 CO_process()内部检索 NMT 内部状态。 od CANopen 对象字典。之前有提到的 ODxyz.h 中定义。 OD_statusBits 传递给 CO_EM_init() 的参数。可以为空。 NMTcontrol 传递给 CO_NMT_init() 的参数。 firstHBTime_ms 传递给 CO_NMT_init() 的参数。 SDOserverTimeoutTime_ms 传递给 CO_SDOserver_init() 的参数。 SDOclientTimeoutTime_ms SDO 客户端的默认超时时间毫秒，一般为 500。 SDOclientBlockTransfer 如果为 “true”，则默认在 SDO 客户端设置块传输。 nodeId CANopen 节点 ID（1 … 127）或 0xFF（未配置）。在 CANopen 初始化中，它与 CO_LSSinit() 中的 pendingBitRate 相同。如果为未配置，则某些 CANopen 对象将不会被初始化或处理。 errInfo 也可以在函数返回 CO_ERROR_NO 的非关键错误中设置。 成功时返回 CO_ERROR_NO。 CO_epoll_initCANopenMain(epMain, CO); 该函数用于配置 CAN 接收后的自定义回调。自定义回调函数可由应用程序选择性注册，并在操作系统中配置线程。回调函数会在高优先级线程预处理完某些内容后调用，并且必须由低优先级线程进一步处理。例如，当接收到 CAN 报文并进行预处理后，回调应唤醒主线程处理函数。 CO_EM_initCallbackRx(CO-em, EmergencyRxCallback);CO_NMT_initCallbackChanged(CO-NMT, NmtChangedCallback);CO_HBconsumer_initCallbackNmtChanged(CO-HBcons, 0, NULL, HeartbeatNmtChangedCallback); CO_EM_initCallbackRx，初始化 Emergency 接收回调函数。该函数在收到错误条件后执行。 CO_NMT_initCallbackChanged，初始化 NMT 状态变化回调函数。该函数在 NMT 状态发生变化后被调用。该函数可能会唤醒处理 NMT 事件的外部任务。第一次调用会立即向消费者提供 当前的 NMT 状态。 CO_HBconsumer_initCallbackNmtChanged，初始化心跳消费者 NMT 更改回调函数，当 NMT 状态发生变化时调用的回调函数。 CO_TIME_set(CO-TIME, time_ms, time_days, TIME_STAMP_INTERVAL_MS); 设置当前时间，并设置生产者的间隔时间为 TIME_STAMP_INTERVAL_MS，以毫秒为单位，此处设置为 10000ms。 err = CO_CANopenInitPDO(CO, /* CANopen object */ CO-em, /* emergency object */ OD, /* Object dictionary */ CO_activeNodeId, errInfo); 必须在通信重置 0x82 部分的末尾调用该函数，否则某些 OD 变量将无法正确映射到 PDO 中。函数参数就是 CAN Open 对象，EM 对象，OD 对象，NodeID 以及错误信息这些。 CO_CANsetNormalMode(CO-CANmodule); 已完成所有对象初始化，设置状态，准备进入主循环函数。在主循环函数中，通过 epoll 监控多个文件描述符。 CO_epoll_wait(epMain);CO_epoll_processRT(epMain, CO, false);CO_epoll_processMain(epMain, CO, GATEWAY_ENABLE, reset);CO_epoll_processLast(epMain); CO_epoll_wait 函数会阻塞，直到 epoll 上注册了以下事件：timerfd、eventfd 或应用程序指定的事件。函数还会计算自上次调用以来的 timeDifference_us 并准备 timerNext_us。 CO_epoll_processLast，epoll 事件的关闭函数，此函数必须在 CO_epoll_wait() 之后调用。在它们之间是应用程序指定的处理函数，可以检查自己的事件并进行处理。应用程序还可以降低 timerNext_us 变量的值。如果将 timerNext_us 变量调低，则将重新配置间隔定时器，并提前触发 CO_epoll_wait()。 CO_epoll_processRT 和 CO_epoll_processMain 指定了处理函数，接下来先说明 CO_epoll_processRT 处理函数。 //CO_CANrxFromEpoll 如果 epoll 事件与任何 CAN 接口匹配，则返回 True。CO_CANrxFromEpoll(co-CANmodule, ep-ev, NULL, NULL);syncWas = CO_process_SYNC(co, ep-timeDifference_us,pTimerNext_us);CO_process_RPDO(co, syncWas, ep-timeDifference_us,pTimerNext_us);CO_process_TPDO(co, syncWas, ep-timeDifference_us,pTimerNext_us); 在 CO_epoll_processRT 中处理以上的 SYNCTPDORPDO 协议。 CO_CANmodule_process(co-CANmodule);CO_EM_process(co-em, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_NMT_process(co-NMT,NMTstate,timeDifference_us,timerNext_us);CO_SDOserver_process(co-SDOserver[i], NMTisPreOrOperational, timeDifference_us,timerNext_us);CO_HBconsumer_process(co-HBcons, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_TIME_process(co-TIME, NMTisPreOrOperational, timeDifference_us); 在 CO_epoll_processMain 中处理了以上的 EMNMTSDOServerHBTIME 协议。 CO_SINGLE_THREAD该参数在 Makefile 中通过-D 参数指定，作用是配置程序在单线程中运行。单线程运行时不同的事件（例如 CAN 接收或计时器到期）会触发循环通过堆栈（所有代码都是非阻塞的）。它需要较少的系统资源。 在多线程操作中，除了主线线程外，还建立了一个实时线程。RT 线程每毫秒运行一次，并使用外围设备读写、控制程序或类似程序处理 PDO 和可选应用程序代码。使用此配置必须考虑竞争条件，例如，从主线线程运行的应用程序代码在访问 OD 变量时必须使用 CO_(UN)LOCK_OD 宏。 CO_CONFIG_STORAGE该参数由 CO_CONFIG_STORAGE_ENABLE 在 CO_config.h 中使能，主要作用是依据 CiA 301 标准对控制数据进行存储和恢复。数据源通常是对象字典中的一组变量，但并不局限于 OD。在生成对象字典（OD.h 和 OD.c 文件）时，会根据 “存储组 “参数将 OD 变量分组为结构。 OD 对象 0x1010 - 存储参数OD 对象 0x1010 - 存储参数： 子索引 0：支持的最高子索引 子索引 1：保存所有参数，UNSIGNED32 子索引 2：保存通信参数，UNSIGNED32 子索引 3：保存应用参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其存储功能的信息： 位 0：如果设置，CANopen 设备根据命令保存参数 位 1：如果设置，CANopen 设备自主保存参数 写入值 0x65766173（’s’、’a’、’v’、’e’，从 LSB 到 MSB）可存储相应数据。相应数据。 OD 对象 0x1011 - 恢复默认参数 子索引 0：支持的最高子索引 子索引 1：恢复所有默认参数，UNSIGNED32 子索引 2：恢复通信默认参数，UNSIGNED32 子索引 3：恢复应用程序默认参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其恢复能力的信息： 位 0：如果设置，CANopen 设备恢复参数 写入值 0x64616F6C（’l’、’o’、’a’、’d’从 LSB 到 MSB）可恢复相应数据。相应数据。 CO_CONFIG_GTW网关对象由标准 CiA 309 - CANopen 从其他网络访问涵盖。它可以将 NMT 主站、SDO 客户端和 LSS 主站用作网关设备。 本次使用中不支持该形式，直接在 CO_config.h 中注释掉该模块即可。 数据字典 OD 操纵CANopen 数据字典 OD 基本上是一个 XML 文件，其中包含 CANopen 设备的所有信息。文件的大部分是所有对象字典变量的列表，其中包含所有必要的属性和文档。该文件可使用 OD 编辑器应用程序进行编辑，并可用作数据源，从中生成 CANopenNode 的对象字典。该文件还可用于 CANopen 配置工具，在运行的 CANopen 网络上与 CANopen 设备进行交互。 CANopen 还为 CANopen 设备描述指定了另一种类型的文件。它们是 INI 格式的 EDS 文件。可以在这两种格式之间进行转换。设备描述文件的扩展名为 “XDD”。该文件的名称应包含 CANopen 设备的供应商 ID，以 8 位十六进制数字的形式出现在名称的任意位置，并用下划线分隔。例如 “name1_12345678_name2.XDD”。CANopenNode 包含多个配置文件定义文件，每个 CANopen 对象一个。这些文件的扩展名为 “XPD”。它们采用与 XDD 文件相同的 XML 格式。XML 编辑工具可以使用 XPD 文件将准备好的数据插入正在编辑的设备描述文件 (XDD)。还有扩展名为 “XDC “的设备配置文件。这些文件描述了已配置的 CANopen 设备，并包含其他元素，如默认值、分母和设备调试元素。类似于 INI 格式的 “dcf “文件。 使用OD object是指对象字典中位于特定 16 位索引的对象。CANopen 中有不同类型的 OD 对象：变量、数组和记录（结构）。每个 OD 对象都包含指向实际数据、数据长度和属性的指针。在 OD_objectTypes_t 中被定义。 OD variable 是指定类型的基本变量。例如：int8_t、uint32_t、float64_t……或数据长度已知或未知的二进制数据序列。每个 OD 变量都以指定的 16 位索引和 8 位子索引存在于对象字典中。 OD entry指的是结构元素，其中包含 OD 对象的一些基本属性、OD 对象的类型指示以及指向 OD 对象所有必要数据的指针。OD 条目数组以及 OD 条目总数信息代表 CANopenNode 内部定义的对象字典。参见 OD_entry_t 和 OD_t。 应用程序和堆栈可通过通用的 OD_t 对象和 OD_find() 函数访问 OD 对象。无需直接访问定义对象字典的自定义结构。特定 OD 变量的属性可通过 OD_getSub()函数获取。通过 read 和 write 函数访问实际变量。 OD_getSub() 可以获取这两个函数的指针。参见 OD_stream_t。另请参见快捷方式： CO_ODgetSetters 用于访问不同类型的数据。 可以从不同的线程访问 OD 变量。CANopenNode 基本上在两个线程中运行：快速实时线程（PDO 处理等）和非关键时间主线程（SDO 等）。两个线程都可以访问 OD 变量，因此必须小心谨慎。CANopenNode 使用锁定机制，SDO 服务器在读取或写入 OD 变量时会阻止实时线程的执行。在 CO_storage 中也需要对 OD 变量进行同样的保护。更多信息请参见 CO_driver.h 中的 CO_critical_sections。 OD 文件-ODxyz.c.h一个 CANopen 设备的实际对象字典由一对 OD_xyz.h 和 ODxyz.c 文件定义。 后缀 “xyz “是对象字典的唯一名称。如果使用单个默认对象字典，则省略后缀。这样就可以配置多个对象字典。 用于定义 OD 的数据安排在多个结构中。不同的 OD 配置有不同的结构。用这些结构创建的数据对象可以是常量，也可以是变量。 实际的 OD 变量位于多个结构（即存储组）中。选定的组可以选择存储到非易失性存储器中。 手动编辑 ODxyz.h.c 文件非常容易出错。 OD 编辑工具可生成成对的 ODxyz.h.c 文件。该工具可以编辑 xml 格式的标准 CANopen 设备描述文件。Xml 文件可能还包括一些 CANopenNode 特有的非标准元素。然后，Xml 文件将用于自动生成 ODxyz.h.c 文件。 /* OD data declaration of all groups ******************************************/typedef struct uint32_t x1000_deviceType; struct uint8_t maxSubIndex; uint32_t vendorID; uint32_t productCode; uint32_t revisionNumber; uint32_t serialNumber; x1018_identity; ODxyz_PERSIST_COMM_t;typedef struct uint8_t x1001_errorRegister; uint8_t x1003_preDefinedErrorField_sub0; uint32_t x1003_preDefinedErrorField[8]; ODxyz_RAM_t;extern ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM;extern ODxyz_RAM_t ODxyz_RAM;extern OD_t *ODxyz;/* Object dictionary entries - shortcuts **************************************/#define ODxyz_ENTRY_H1000 ODxyz-list[0]#define ODxyz_ENTRY_H1001 ODxyz-list[1]#define ODxyz_ENTRY_H1003 ODxyz-list[2]#define ODxyz_ENTRY_H1018 ODxyz-list[3]#define ODxyz_ENTRY_H1000_deviceType ODxyz-list[0]#define ODxyz_ENTRY_H1001_errorRegister ODxyz-list[1]#define ODxyz_ENTRY_H1003_preDefinedErrorField ODxyz-list[2]#define ODxyz_ENTRY_H1018_identity ODxyz-list[3] #define OD_DEFINITION#include 301/CO_ODinterface.h#include ODxyz.h/* OD data initialization of all groups ***************************************/ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM = .x1000_deviceType = 0, .x1018_identity = .maxSubIndex = 4, .vendorID = 0, .productCode = 0, .revisionNumber = 0, .serialNumber = 0 ;ODxyz_RAM_t ODxyz_RAM = .x1001_errorRegister = 0, .x1003_preDefinedErrorField_sub0 = 0, .x1003_preDefinedErrorField = 0, 0, 0, 0, 0, 0, 0, 0;/* All OD objects (constant) **************************************************/typedef struct OD_obj_var_t o_1000_deviceType; OD_obj_var_t o_1001_errorRegister; OD_obj_array_t o_1003_preDefinedErrorField; OD_obj_record_t o_1018_identity[5]; ODxyzObjs_t;static CO_PROGMEM ODxyzObjs_t ODxyzObjs = .o_1000_deviceType = .dataOrig = ODxyz_PERSIST_COMM.x1000_deviceType, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .o_1001_errorRegister = .dataOrig = ODxyz_RAM.x1001_errorRegister, .attribute = ODA_SDO_R, .dataLength = 1 , .o_1003_preDefinedErrorField = .dataOrig0 = ODxyz_RAM.x1003_preDefinedErrorField_sub0, .dataOrig = ODxyz_RAM.x1003_preDefinedErrorField[0], .attribute0 = ODA_SDO_RW, .attribute = ODA_SDO_R | ODA_MB, .dataElementLength = 4, .dataElementSizeof = sizeof(uint32_t) , .o_1018_identity = .data = ODxyz_PERSIST_COMM.x1018_identity.maxSubIndex, .subIndex = 0, .attribute = ODA_SDO_R, .dataLength = 1 , .data = ODxyz_PERSIST_COMM.x1018_identity.vendorID, .subIndex = 1, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.productCode, .subIndex = 2, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.revisionNumber, .subIndex = 3, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.serialNumber, .subIndex = 4, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 ;/* Object dictionary **********************************************************/static OD_entry_t ODxyzList[] = 0x1000, 0x01, ODT_VAR, ODxyzObjs.o_1000_deviceType, NULL, 0x1001, 0x01, ODT_VAR, ODxyzObjs.o_1001_errorRegister, NULL, 0x1003, 0x09, ODT_VAR, ODxyzObjs.o_1003_preDefinedErrorField, NULL, 0x1018, 0x05, ODT_REC, ODxyzObjs.o_1018_identity, NULL, 0x0000, 0x00, 0, NULL, NULL;OD_t _ODxyz = (sizeof(ODxyzList) / sizeof(ODxyzList[0])) - 1, ODxyzList[0];OD_t *ODxyz = _ODxyz; OD_find 查找指定对象extern OD_t *ODxyz;void myFunc(OD_t *od) ODR_t odRet;//保存对象字典操作的返回值。 OD_entry_t *entry;//指向对象字典条目的指针。 OD_IO_t io1008;//用于对象字典I/O操作的结构体。 char buf[50]; OD_size_t bytesRd;//存储读取的字节数。 int error = 0; // 查找并初始化0x1008条目和其子索引0x00的IO结构体 entry = OD_find(od, 0x1008);//查找对象字典中的条目。 odRet = OD_getSub(entry, 0x00, io1008, false);//获取对象字典条目的子索引。 // 读取制造商设备名称 if (odRet == ODR_OK) /* Locking is necessary from mainline thread, but must not be used from * timer interval (real-time) thread. Locking is not necessary in the * CANoopen initialization section. Locking is also not necessary, if * OD variable is not mappable to PDO and not accessed from RT thread.*/ CO_LOCK_OD(CANmodule); odRet = io1008.read(io1008.stream, buf[0], sizeof(buf), bytesRd);//读取子索引的数据。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++; /* Use helper and set Producer heartbeat time at index 0x1017, sub 0x00 */ // 设置生产者心跳时间 CO_LOCK_OD(CANmodule); /* may not be necessary, see comment above */ odRet = OD_set_u16(OD_find(od, 0x1017), 0x00, 500, false);//设置对象字典条目的子索引值。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++; 直接根据结构体查找 OD 对象如何直接访问和操作 CANopen 对象字典（Object Dictionary）中的条目，而不是通过查找函数 OD_find 来间接访问。直接访问对象字典条目和变量比通过函数查找要快，因为它避免了函数调用和查找过程。 对象字典的头文件 ODxyz.h，其中定义了对象字典的所有条目和相关结构。 #include ODxyz.hvoid myFuncGlob(void) // Direct address instead of OD_find() OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; // Direct access to OD variable uint32_t devType = ODxyz_0.x1000_deviceType; ODxyz_0.x1018_identity.serialNumber = 0x12345678; OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; 直接获取对象字典中 0x1001 索引（错误寄存器）的条目指针 entry_errReg。这里使用的是直接声明的指针 ODxyz_1001_errorRegister，而不是通过 OD_find 函数查找。 uint32_t devType = ODxyz_0.x1000_deviceType; 直接读取对象字典中 0x1000 索引（设备类型）的变量 ODxyz_0.x1000_deviceType，并将其存储到本地变量 devType 中。ODxyz_0.x1018_identity.serialNumber = 0x12345678; 直接修改对象字典中 0x1018 索引（设备标识）的 serialNumber 字段，将其设置为 0x12345678。 如果 OD 对象已启用 OD 扩展，则不得直接访问其 OD 变量。只有通过读、写或辅助函数访问才有效。 修改 PDO 固定长度在 PDO 协议中，数据的接收是严格按照 PDO 中映射的数据长度来读取的，当数据不足时，该数据帧会被丢弃，当数据过长时，该数据帧会被截断。 在此次的应用程序中，由于该设备配置的 PDO 存在两种长度数据，所以需要将 PDO 的数据长度更改为兼容自定义的两种数据长度。 在 CO_PDO.c 文件中，有 RPDO 处理函数 CO_RPDO_process，其中的 for 循环，当小于 PDO-mappedObjectsCount 数量时，执行 1byte 的拷贝，所以此处们需要修改为当 iCO_PDO_MAX_SIZE 时执行拷贝，即对 PDO 中所有的数据进行拷贝，不管该字节是否有数据。","categories":["3.协议","CAN"]},{"title":"CAN和CANFD","path":"/2024/01/01/3-协议-CAN-CAN和CANFD/","content":"CAN 和 CANFD对于 CAN-FD 而言，数据比特率要大于等于件裁比特率，用 ip link set can0 type can bitrate 500000 这个命令操作 CAN-FD 是有问题的，换成 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on，而后就可以利用 CAN-FD 进行数据的收发 按照配置 CAN 的方式去配置 CAN-FD，导致少配置了 CAN-FD 的数据比特率，导致出错。之前配置 CAN 的指令为 ip link set can0 type canbitrate 500000，实际通过分析 CAN-FD 的驱动代码以及 CAN-FD 通信协议的报文格式发现，对于 CAN-FD，数据比特率是要大于仲裁比特率的。换用 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on 配置数据比特率之后，CAN-FD 就可以正常收发数据了, 分析:CAN-FD 采用了两种方式来提高通信的效率，其中一种叫可变及更高的数据传输速率:从控制场中的 BRS 位到 ACK 场之前(含 CRC 但为了保证总线的健壮可靠，仲裁段(ID 和 ACK)保持不变，采用原分界符)为可变速率，CAN-FD 数据段的传输速率最大可达 5MbitsCAN 总线用的速率(最高 1Mbits)。 注意:两种速率各有一套位时间定义寄存器，对于 CAN-FD 来说均要配置。 CAN 和 CANFDCAN 与 CAN-FD 主要区别： 传输速率不同 CAN：最大传输速率 1Mbps。 CAN-FD：速率可变，仲裁比特率最高 1Mbps（与 CAN 相同），数据比特率最高 8Mbps。 数据长度不同 CAN：一帧数据最长 8 字节 CAN-FD：一帧数据最长 64 字节。 帧格式不同和 ID 长度不同。 CANFD 不存在远程帧，CAN 报文中的 RTR（用于区别标准帧与远程帧）被替换为 RRS（远程请求替代位，默认值为 0） CANFD 报文的标准帧和扩展帧—IDE 为 1 表示为扩展帧、为 0 表示标准帧 FDF 用于传统 CAN 报文和 CANFD 报文，FDF 位为 0 时为传统报文，FDF 为 1 时为 CANFD 报文 BRS 位速率切换位，BRS 位为 0 时 CANFD 速率保持恒定速率、BRS 位为 1 时 CANFD 的数据段会被切换到高速率。 ESI 错误状态指示位：CAN 报文中发送节点的错误状态只有该节点自己知道，CANFD 报文中可以通过 ESI 标志位来告诉其他节点该节点的错误状态，当 ESI 为 1 时表示发送节点处于被动错误状态、当 ESI 为 0 时表示发送节点处于主动错误状态 CRC：随着数据场的扩大，为了保证信息发送的质量，CAN FD 的 CRC 计算不仅要包括数据段的位，还包括来自 SOF 的 Stuff Count 和填充位。通过比较 CRC 的计算结果，可以判断接收节点是否能够正常接收。 在 CAN 中，CRC 的位数是 15 位，而在 CAN FD 中，CRC 场扩展到了 21 位。 当传输报文为 15 字节时：CRC 15 位 当传输数据为 16 字节或更少时：CRC 17 位 当传输数据超过 16 字节时：CRC 21 位 CAN FD DLCDLC 和 数据长度的关系在 Linux 的 SocketCAN 中，struct canfd_frame 中的 len 字段表示实际的有效负载长度（即数据长度），而 CAN FD 协议使用的是 4-bit 的 DLC（Data Length Code）来表示帧中数据的长度。这两者之间的关系是通过一组映射规则来转换的。 在 CAN FD 协议中，DLC 是一个 4 位的字段，允许的取值范围为 0 到 15。这些 DLC 值并不是直接表示字节长度，而是与有效负载长度之间有一个固定的映射关系。具体映射如下： DLC 数据字节数 (Payload Length) 0-8 0-8 9 12 10 16 11 20 12 24 13 32 14 48 15 64 struct canfd_frame 中 len 和 DLC 的转换在 SocketCAN 中，应用程序通过 struct canfd_frame 来发送 CAN FD 帧。struct canfd_frame 中的 len 字段表示实际的有效负载长度，而内核会根据这个 len 值来确定对应的 DLC 值。转换规则如下： 如果 len 的值在 0 到 8 ，DLC 的值与 len 直接相等。例如，len 5，则 DLC 5。 如果 len 的值大于 8，系统会根据 DLC 与有效负载长度的固定映射来选择最小的 DLC，使得能传输指定的字节数。例如： len 9 到 len 12，DLC 9，对应 12 字节的负载。 len 13 到 len 16，DLC 10，对应 16 字节的负载。 len 17 到 len 20，DLC 11，对应 20 字节的负载。 len 21 到 len 24，DLC 12，对应 24 字节的负载。 len 25 到 len 32，DLC 13，对应 32 字节的负载。 len 33 到 len 48，DLC 14，对应 48 字节的负载。 len 49 到 len 64，DLC 15，对应 64 字节的负载。 实际发送时的 DLC 计算当在 SocketCAN 中使用 canfd_frame 结构体发送数据时： 在 len 字段中指定实际的数据长度。 内核会根据上述规则，自动计算并设置相应的 DLC 值，确保数据可以正确传输。 如果 len 的值不直接对应某个 DLC（如 len 33），内核会自动选择能容纳该数据长度的最小 DLC（在这个例子中，DLC 会被设置为 14，对应 48 字节）。 示例假设要发送 33 个字节的数据： struct canfd_frame 的 len 设置为 33。内核根据 len 值选择对应的 DLC 为 14（因为 DLC14 对应 48 字节的有效负载长度，可以容纳 33 个字节）。 实际发送时，CAN FD 帧会包含 33 字节的数据，DLC 会标记为 14，表示该帧允许的最大有效负载是 48 字节，尽管只使用了 33 字节。","categories":["3.协议","CAN"]},{"title":"CAN学习笔记","path":"/2023/12/29/3-协议-CAN-CAN学习笔记/","content":"概述介绍CAN 总线是一种串行通信协议，使用的是两条差分信号线，只能表达一个信号。简洁的物理层决定了 CAN 必然要配上一套复杂的协议。根据不同的距离、不同的网络，可配置不同的速度，最高速度为 1MBits。 CAN 2.0A 为标准格式，CAN 2.0B 为扩展格式。 可以多主方式工作，网络上的任意节点均可以在任意时刻主动地向网络上的其他节点发送信息，而不分主从，通信方式灵活。 网络上的节点 (信息) 可分成不同的优先级，可以满足不同的实时要求。 采用非破坏性位仲裁总线结构机制，当两个节点同时向网络上传送信息时，优先级低的节点主动停止数据发送，而优先级高的节点可不受影响地继续传输数据。 CAN 属性 属性 说明 报文（Messages） CAN 协议对数据、操作命令 (如读写) 以及同步信号进行打包，打包后的这些内容称为报文，简单来说就是具有固定格式的数据包。 信息路由（Information Routing） 报文寻找结点的方式。 位速率（Bit rate） 数据位的传输速度。 优先权（Priorities） 报文发送的优先权。 远程数据请求（Remote Data Request） 通过发送远程帧，需要数据的节点可以请求另一节点发送相应的数据帧。 多主机（Multimaster） 总线空闲时，任何结点都可以开始传送报文。 仲裁（Arbitration） 当 2 个及以上的单元同时开始传送报文，那么就会有总线访问冲突。仲裁是确定哪个单元的具有发送优先权。 安全性（Safety） CAN 的每一个节点均采取了强有力的措施以进行错误检测、错误标定及错误自检。 错误检测（Error Detection） 包括监视、循环冗余检查、位填充、报文格式检查。 错误检测的执行（Performance of Error Detection） 错误标定和恢复时间（Error Sinalling and Recovery Time） 任何检测到错误的结点会标志出已损坏的报文。此报文会失效并将自动地开始重新传送。如果不再出现新的错误，从检测到错误到下一报文的传送开始为止，恢复时间最多为 29 个位的时间。 故障界定（Fault Confinement） CAN 结点能够把永久故障和短暂扰动区分开来。永久故障的结点会被关闭。 连接（Connections） CAN 串行通讯链路是可以连接许多结点的总线。理论上，可连接无数多的结点。但由于实际上受延迟时间或者总线线路上电气负载的影响，连接结点的数量是有限的。 单通道（Single Channel） 总线是由单一进行双向位信号传送的通道组成。 总线值（Bus value） 总线可以具有两种互补的逻辑值之一：”显性”（可表示为逻辑 0）或”隐性”（可表示为逻辑 1）。 应答（Acknowledgment） 所有的接收器检查报文的连贯性。对于连贯的报文，接收器应答；对于不连贯的报文，接收器作出标志。 睡眠模式／唤醒（Sleep Mode Wake-up） 为了减少系统电源的功率消耗，可以将 CAN 器件设为睡眠模式以便停止内部活动及断开与总线驱动器的连接。CAN 器件可由总线激活，或系统内部状态而被唤醒。 工作原理当 CAN 总线上的节点发送数据时，以报文形式广播给网络中的所有节点，总线上的所有节点都不使用节点地址等系统配置信息，只根据每组报文开头的 11 位标识符解释数据的含义来决定是否接收。这种数据收发方式称为面向内容的编址方案。 当某个节点要向其他节点发送数据时，这个节点的处理器将要发送的数据和自己的标识符传送给该节点的 CAN 总线接口控制器，并处于准备状态；当收到总线分配时，转为发送报文状态。数据根据协议组织成一定的报文格式后发出，此时网络上的其他节点处于接收状态。处于接收状态的每个节点对接收到的报文进行检测，判断这些报文是否是发给自己的以确定是否接收。 层次结构CAN 被细分为三个层次，其中的对象层和传输层包括所有由 ISOOSI 模型定义的数据链路层的服务和功能。 对象层（the object layer）的作用范围包括： 查找被发送的报文。 确定由实际要使用的传输层接收哪一个报文。 为应用层相关硬件提供接口。 传输层（the transfer layer）的作用主要： 传送规则，也就是控制帧结构、执行仲裁、错误检测、出错标定、故障界定。 总线上什么时候开始发送新报文及什么时候开始接收报文，在传输层里确定。 位定时的一些普通功能也可以看作是传输层的一部分。 传输层的修改是受到限制的。 物理层（the phyical layer）的作用： 在不同节点之间根据所有的电气属性进行位信息的实际传输。当然，同一网络内，物理层对于所有的节点必须是相同的。 编程在对象层进行，这一层直接与应用层交互，并且提供了管理和处理 CAN 消息的接口。通过对象层，应用程序可以发送和接收 CAN 的打包消息。打包的过程就是在原始数据的基础上再加上帧起始段、仲裁段、控制段、CRC 校验、应答和帧结束，把这些内容按特定的格式打包好，就可以用一个通道表达各种信号了，当数据包被发送时，只要接收方按约定格式去解读，就能还原出原始数据。 传输层的功能主要由 CAN 控制器硬件和驱动程序实现。通常，程序员不直接操作传输层，而是通过对象层的 API 间接利用传输层的功能。传输层负责处理 CAN 协议的低级细节，如位级传输、错误处理和仲裁。 位填充是为了防止突发错误而设定的功能。位填充的规则如下： 5 位连续相同电平之后，必须填充一位反向位，即不允许有 6 个连续相同位； SOF 之前为总线空闲状态，不需要同步，因此不需要位填充； CRC 之后为固定格式，不允许填充； 由 CAN 控制器自动实现； 物理层通常由 CAN 收发器硬件和相关电气接口组成。 仲裁方式在总线空闲态，最先开始发送消息的单元获得发送权。多个单元同时开始发送时，各发送单元从仲裁段的第一位开始进行仲裁。连续输出显性电平最多的单元继续发送。即逐位地对比 各个结点发出的报文 ID。 由于线与的关系，显示位”0”可以覆盖隐性位”1”，因此 ID 最小的节点赢得仲裁，总线上表现为该结点的报文，其他结点失去仲裁，退出发送，转为接收状态。 标准格式 ID 与具有相同 ID 的远程帧或者扩展格式的数据帧在总线上竞争时，标准格式的 RTR 位为显性位的具有优先权，可继续发送。 位时序CAN 协议的通信方法位 NRZ(non-return to zero)方式。各个位的开头或结尾都没有附加同步信号。 发送单元以与位时序同步的方式开始发送数据。 接收单元根据总线上电平的变化进行同步并进行接收工作。 由发送单元在非同步的情况下发送的每秒钟的位数称为位速率。一个位可分为 4 段。 同步段（SS） 传播时间段（PTS） 相位缓冲段 1（PBS1） 相位缓冲段 2（PBS2） 这些段又由可称为 Time Quantum（以下称为 Tq）的最小时间单位构成。 1 位分为 4 个段，每个段又由若干个 Tq 构成，这称为位时序。 1 位由多少个 Tq 构成、每个段又由多少个 Tq 构成等，可以任意设定位时序。通过设定位时序，多个单元可同时采样，也可任意设定采样点。 采样点：是读取总线电平，并将读到的电平作为位值的点，位置在 PBS1 结束处。 设置位时序和计算位速率ip link set can0 type cantq 125 prop-seg 6 phase-seg1 7 phase-seg2 2 sjw 1 同步段（Sync Segment）: 固定为 1 TQ，用于同步位定时器。 传播时间段（Propagation Segment, prop-seg）: 用于补偿信号在总线上传播的时间延迟 相位缓冲段 1（Phase Buffer Segment 1, phase-seg1）: 用于提高抗干扰能力，允许时间调整。 相位缓冲段 2（Phase Buffer Segment 2, phase-seg2）: 也用于提高抗干扰能力，允许时间调整。 ip link set can0 type can: 设置名为 can0 的网络接口的类型为 CAN。 tq 125: 设置时间量化（Time Quantum，TQ）为 125 ns。TQ 是 CAN 控制器内部的基本时间单位，用于划分整个位时间。 prop-seg 6: 设置传播时间段（Propagation Segment）为 6 TQ。传播时间段用于补偿信号在 CAN 总线上传播的延迟。为 6 个时间量化，6 * 125 ns 750 ns。 phase-seg1 7: 设置相位缓冲段 1（Phase Buffer Segment 1）为 7 TQ。这个时间段用于调整边沿相位，通常包括采样点之前的时间。为 7 个时间量化，875 ns。 phase-seg2 2: 设置相位缓冲段 2（Phase Buffer Segment 2）为 2 TQ。这个时间段用于调整边沿相位，通常包括采样点之后的时间。为 2 个时间量化，250 ns。 sjw 1: 设置同步跳跃宽度（Synchronization Jump Width，SJW）为 1 TQ。SJW 用于重新同步时可以跳跃的最大时间量。为 1 个时间量化，1 * 125 ns 125 ns。 计算位时间和位速率 总位时间是所有段的时间总和： Sync Segment: 1 TQ Propagation Segment: 6 TQ Phase Buffer Segment 1: 7 TQ Phase Buffer Segment 2: 2 TQ 总时间量化数 1 + 6 + 7 + 2 16 TQ 总位时间 16 * 125 ns 2000 ns 2 μs 位速率（Bit Rate） 1 总位时间 1 2 μs 500 kbps 同步方式硬件同步接收单元在总线空闲状态检测出帧起始时进行的同步调整。 在检测出边沿的地方不考虑 SJW 的值而认为是 SS 段 在同步在接收过程中检测出总线上的电平变化时进行大的同步调整。 当检测出边沿时，根据 SJW 的值通过加长 PBS1 或缩短 PBS2（采样点位置在 PBS1 结束处），以调整同步，最大调整量不超过 SJW 的值。 边沿出现在 PTS 和 PBS1 之间时，通过加长 PBS1 边沿出现在 PBS2 时，通过缩短 PBS2 位填充位填充时为防止突发错误而设定的功能。在同样的电平持续 5 位时添加一个位的反型数据。 发送单元 发送数据帧和遥控帧时，SOF~CRC 段的数据，相同电平持续 5bits，下一位插入反型数据。 接收单元 接收数据帧和遥控帧时，SOF~CRC 段的数据，相同电平持续 5bits，需要删除下一个位再接收。如果数据仍然和前 5bits 相同，则被视为错误并发送错误帧。 数据帧帧类型为了更有效地控制通讯，CAN 一共规定了 5 种类型的帧 数据帧：发送单元向接收单元传送数据的帧。 远程帧：接收单元向发送单元请求数据的帧。 错误帧：检测出错误时向其它单元通知错误的帧。 过载帧：接收单元通知其尚未就绪的帧。 间隔帧：将数据帧及遥控帧与前面的帧分离开来的帧。 CAN 帧定义数据帧由帧起始、仲裁段、控制段、数据段、CRC、ACK、帧结束共 7 个段构成。数据帧和遥控帧有标准帧和扩展帧两种帧，标准帧有 11 个位的标识符 ID，扩展帧有 29 个位的 ID。 帧起始 (Start Of Frame,SOF)，1bit 表示帧开始的段，设置为 0。 仲裁段（Identifier，ID），11bits29bits 表示数据帧优先级的段 标准帧与扩展帧的构成有所不同，均禁止高 7 位为隐性 (ID1111111XXXX…) 仲裁段的内容主要为本数据帧的 ID，标准帧的 ID 有 11 个位，扩展帧的 ID 有 29 个位，在 CAN 协议中，ID 决定着数据帧发送的优先级，也决定着其它节点是否会接收这个数据帧。CAN 总线不对挂载在它之上的节点分配优先级和地址，对总线的占有权是由信息的 ID 决定的，即对于重要的信息，优先级高的 ID，能够优先发送出去 RTR 位 (Remote Transmission Request Bit) 远程传输请求位，用于区分数据帧和遥控帧的，为 0 表示数据帧，1 表示遥控帧。 控制段 控制段由 6 个位构成，表示数据段的字节数 IDE 位 (Identifier Extension Bit) 标识符扩展位，用于区分标准帧与扩展帧，为 0 表示标准帧，1 表示扩展帧 SRR 位 (Substitute Remote Request Bit) 只存在于扩展帧，它用于替代标准帧中的 RTR 位，扩展帧中的 SRR 位固定为 1，RTR 在数据帧中为 0，所以两个 ID 相同的标准帧与扩展帧，标准帧的优先级较高 DLC 数据长度码（Data Length Code） 数据的字节数必须为 0～8 字节 数据段（Data Field） 数据段可包含 0～8 个字节的数据 CRC 段 CRC 段是检查帧传输错误的段，由 15 个位的 CRC 值和 1 个位的 CRC 界定符 (隐性分隔位) 构成 CRC 是根据多项式生成的 CRC 值，CRC 的计算范围包括帧起始、仲裁段、控制段、数据段 接收方以同样的方式计算 CRC 值并进行比较，不一致时利用错误帧请求重新发送 ACK 段 ACK 段包括 ACK 槽位、ACK 界定符位 2 个位 发送单元的 ACK 段：发送单元在 ACK 段发送 2 个位的隐性位 接收单元的 ACK 段：接收到正确消息的单元在 ACK 槽发送显性位，通知发送单元正常接收结束，这称作”发送 ACK”或者”返回 ACK” 帧结束 (End Of Frame，EOF) 帧结束是表示该帧结束的段，由发送节点发送 7 个位的隐性位构成 CAN 数据帧的结束符长度并不是完全不定的，而是根据数据位速率（Data Bit Rate，DBR）而定。CAN 总线协议规定，对于数据位速率低于等于 125kbps 的网络，CAN 数据帧的结束符长度为 7 个位；对于数据位速率大于 125kbps 的网络，CAN 数据帧的结束符长度为 3 个位。这是因为在高速网络中，由于数据传输速率更快，所以 CAN 控制器可以更快地检测到结束位，因此可以减少结束符的长度，从而提高网络的传输效率。而在低速网络中，由于数据传输速率较慢，所以 CAN 控制器需要更长的时间来检测结束位，因此需要一个更长的结束符来确保数据帧传输的正确性和完整性。因此，CAN 数据帧的结束符长度是根据数据位速率而定的，并不是完全不定的。 Socket CAN 帧结构体 帧头，canid_t 定义了一个无符号的 32 位整形数，按位确定功能 0-28 位为标识符，如果是扩展帧，则高 11 位为标准 ID 29 位标识是数据帧还是错误消息 30 位说明是否是远程帧 31 位说明是标准帧还是扩展帧。 帧长，8 位无符号表示数据区长度 数据区，定义 CAN_MAX_DLEN 个 8 位无符号数，按照数组的形式申请 *__attribute__((aligned(8))) 告诉编译器，将变量 data 放在一个地址是 8 的倍数的内存位置上。 /* CAN payload length and DLC definitions according to ISO 11898-1 */#define CAN_MAX_DLC 8#define CAN_MAX_DLEN 8struct can_frame canid_t can_id; /* 32 bit CAN_ID + EFF/RTR/ERR flags */ __u8 can_dlc; /* frame payload length in byte */ __u8 data[CAN_MAX_DLEN] __attribute__((aligned(8)));;/** Controller Area Network Identifier structure** bit 0-28 : CAN identifier (11/29 bit)* bit 29 : error message frame flag (0 = data frame, 1 = error message)* bit 30 : remote transmission request flag (1 = rtr frame)* bit 31 : frame format flag (0 = standard 11 bit, 1 = extended 29 bit)*/typedef __u32 canid_t;typedef unsigned char __u8; 帧类型定义如下： /* special address description flags for the CAN_ID */#define CAN_EFF_FLAG\t0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG\t0x40000000U /* 远程帧 */#define CAN_ERR_FLAG\t0x20000000U /* error frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK\t0x000007FFU /* 标准帧 (SFF) */#define CAN_EFF_MASK\t0x1FFFFFFFU /* 扩展帧 (EFF) */#define CAN_ERR_MASK\t0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 实际对 can_frame 发送的处理是在 mcp251x_hw_tx 中进行 static void mcp251x_hw_tx(struct spi_device *spi, struct can_frame *frame, int tx_buf_idx)\tstruct mcp251x_priv *priv = spi_get_drvdata(spi);\tu32 sid, eid, exide, rtr;\tu8 buf[SPI_TRANSFER_BUF_LEN];\t//取can_id的31位，判断是标准帧还是扩展帧\texide = (frame-can_id CAN_EFF_FLAG) ? 1 : 0; if (exide)//如果是扩展帧，can_id的0-28位为ID，其中高11位为标准ID sid = (frame-can_id CAN_EFF_MASK) 18;\telse sid = frame-can_id CAN_SFF_MASK; /* Standard ID */\teid = frame-can_id CAN_EFF_MASK; /* Extended ID */\trtr = (frame-can_id CAN_RTR_FLAG) ? 1 : 0; /* 是否是远程帧*/\tbuf[TXBCTRL_OFF] = INSTRUCTION_LOAD_TXB(tx_buf_idx); //发送缓冲器控制寄存器地址\tbuf[TXBSIDH_OFF] = sid SIDH_SHIFT; //发送缓冲器标准ID高8位\t//5-7位存放发送缓冲器低3位,3位存放帧格式，0-1位存放扩展标识符低18位的高两位（16-17）\tbuf[TXBSIDL_OFF] = ((sid SIDL_SID_MASK) SIDL_SID_SHIFT) | (exide SIDL_EXIDE_SHIFT) | ((eid SIDL_EID_SHIFT) SIDL_EID_MASK);\tbuf[TXBEID8_OFF] = GET_BYTE(eid, 1); //存放扩展标识符低18位的8-15位\tbuf[TXBEID0_OFF] = GET_BYTE(eid, 0); //扩展标识符低18位的低8位（0-7）\tbuf[TXBDLC_OFF] = (rtr DLC_RTR_SHIFT) | frame-can_dlc; //6位存放远程帧标识符，0-3存放数据长度码\tmemcpy(buf + TXBDAT_OFF, frame-data, frame-can_dlc);//拷贝要发送的数据\tmcp251x_hw_tx_frame(spi, buf, frame-can_dlc, tx_buf_idx);\t/* use INSTRUCTION_RTS, to avoid repeated frame problem */\tpriv-spi_tx_buf[0] = INSTRUCTION_RTS(1 tx_buf_idx);\tmcp251x_spi_trans(priv-spi, 1); 帧长度位填充 3bits Classic CAN Standard Frame标准帧（不考虑位填充）共：108Bit 帧起始（1bit）、仲裁段（12bit）、控制段（6bit）、数据段（8×8bit）、循环冗余码段（16bit）、应答段（2bit）和帧结束（7bit） Classic CAN Extended Frame扩展帧（不考虑位填充）共：128Bit 帧起始（1bit）、仲裁段（32bit）、控制段（6bit）、数据段（8×8bit）、循环冗余码段（16bit）、应答段（2bit）和帧结束（7bit） CANFD Standard Frame标准帧（不考虑位填充；DLC 8）共：117Bit 帧起始（1bit）、仲裁段（12bit）、控制段（9bit）、数据段（8×8bit）、循环冗余码段（22bit）、应答段（2bit）和帧结束（7bit） CANFD Standard Frame标准帧（不考虑位填充；DLC 64）共：569Bit 帧起始（1bit）、仲裁段（12bit）、控制段（9bit）、数据段（64×8bit）、循环冗余码段（26bit）、应答段（2bit）和帧结束（7bit） CANFD CAN Extended Frame扩展帧（不考虑位填充；DLC 8）共：136Bit 帧起始（1bit）、仲裁段（32bit）、控制段（8bit）、数据段（8×8bit）、循环冗余码段（22bit）、应答段（2bit）和帧结束（7bit） CANFD CAN Extended Frame扩展帧（不考虑位填充；DLC 64）共：588Bit 帧起始（1bit）、仲裁段（32bit）、控制段（8bit）、数据段（64×8bit）、循环冗余码段（26bit）、应答段（2bit）和帧结束（7bit） SocketCAN 实例CAN 功能分析一个标准的 CAN 功能包括： CAN 接口号指定 CAN 接口号 can0 指定 CAN 通讯波特率或 TQ，单位 Kbps，默认为 500 Kbps 指定 CAN 发送帧 ID 指定 CAN 发送帧数据 需要包含数据的大小端模式转换 指定 CAN 帧发送间隔，单位 ms， 默认为 250ms, 最小值为 1ms 指定 CAN 帧发送次数 指定 CAN 发送帧为标准帧扩展帧 发送数据时错误判断，本地环回功能基于 LINUX SOCKET 机制实现的 CAN 接口，其基本的流程如下所示： 设置套接字 socket 指定 CAN 设备 ioctl 绑定套接字与设备 bind 设置过滤规则 setsockopt 发送接受报文 read/write 关闭套接字 close 示例代码#include stdio.h#include stdlib.h#include string.h#include unistd.h#include sys/socket.h#include sys/types.h#include linux/can.h#include linux/can/raw.hint main() int sock; struct sockaddr_can addr; struct ifreq ifr; struct can_frame frames[10]; // 一次最多读取10个CAN数据包 struct msghdr msg; struct iovec iov; char ctrlmsg[CMSG_SPACE(sizeof(struct timeval) + 3 * sizeof(struct timespec) + sizeof(__u32))]; int nbytes; sock = socket(PF_CAN, SOCK_RAW, CAN_RAW); strcpy(ifr.ifr_name, can0); ioctl(sock, SIOCGIFINDEX, amp;ifr); memset(amp;addr, 0, sizeof(addr)); addr.can_family = AF_CAN; addr.can_ifindex = ifr.ifr_ifindex; bind(sock, (struct sockaddr *)amp;addr, sizeof(addr)); memset(amp;msg, 0, sizeof(msg)); memset(amp;iov, 0, sizeof(iov)); iov.iov_base = frames; iov.iov_len = sizeof(frames); msg.msg_name = amp;addr; msg.msg_namelen = sizeof(addr); msg.msg_iov = amp;iov; msg.msg_iovlen = 1; msg.msg_control = amp;ctrlmsg; msg.msg_controllen = sizeof(ctrlmsg); while (1) nbytes = recvmsg(sock, amp;msg, MSG_DONTWAIT); if (nbytes 0) int num_frames = nbytes / sizeof(struct can_frame); printf(Received %d CAN frames: , num_frames); for (int i = 0; i num_frames; i++) printf( ID: 0x%X, DLC: %d, Data: , frames[i].can_id, frames[i].can_dlc); for (int j = 0; j frames[i].can_dlc; j++) printf(%02X , frames[i].data[j]); printf( ); usleep(1000); close(sock); return 0; 初始化SocketCAN 中大部分的数据结构和函数在头文件 linuxcan.h 中进行了定义。 CAN 总线套接字的创建采用标准的网络套接字操作来完成。网络套接字在头文件 syssocket.h 中定义。 套接字的初始化方法如下： int s;struct sockaddr_can addr;struct ifreq ifr;s = socket(PF_CAN, SOCK_RAW, CAN_RAW);//创建SocketCAN 套接字strcpy(ifr.ifr_name, can0);ioctl(s, SIOCGIFINDEX, ifr);//指定 can0 设备addr.can_family = AF_CAN;addr.can_ifindex = ifr.ifr_ifindex;bind(s, (structsockaddr *)addr,sizeof(addr)); //将套接字与 can0 绑定 参数配置#include stdio.h#include stdlib.h#include string.h#include unistd.h#include fcntl.h#include linux/can.h#include linux/can/raw.h#include linux/can/error.h#include linux/can/netlink.h#include linux/sockios.h#include sys/ioctl.h#include sys/socket.h#include net/if.h#define CAN_INTERFACE can0#define BITRATE 500000#define DBITRATE 4000000int set_bitrate(const char *ifname, int bitrate, int dbitrate) struct ifreq ifr; struct can_bittiming bt; struct can_bittiming dbt; // Open socket int s = socket(PF_INET, SOCK_DGRAM, 0); if (s 0) perror(socket); return -1; // Specify the interface name strncpy(ifr.ifr_name, ifname, IFNAMSIZ); // Bring the interface down if (ioctl(s, SIOCGIFFLAGS, ifr) 0) perror(SIOCGIFFLAGS); close(s); return -1; ifr.ifr_flags = ~IFF_UP; if (ioctl(s, SIOCSIFFLAGS, ifr) 0) perror(SIOCSIFFLAGS); close(s); return -1; // Set bitrate for classical CAN memset(bt, 0, sizeof(bt)); bt.bitrate = bitrate; ifr.ifr_data = (void *)bt; if (ioctl(s, SIOCSCANBT, ifr) 0) perror(SIOCSCANBT); close(s); return -1; // Set data bitrate for CAN FD memset(dbt, 0, sizeof(dbt)); dbt.bitrate = dbitrate; ifr.ifr_data = (void *)dbt; if (ioctl(s, SIOCSCANDBT, ifr) 0) perror(SIOCSCANDBT); close(s); return -1; // Bring the interface up if (ioctl(s, SIOCGIFFLAGS, ifr) 0) perror(SIOCGIFFLAGS); close(s); return -1; ifr.ifr_flags |= IFF_UP; if (ioctl(s, SIOCSIFFLAGS, ifr) 0) perror(SIOCSIFFLAGS); close(s); return -1; // Close socket close(s); return 0;int main() const char *ifname = CAN_INTERFACE; int bitrate = BITRATE; int dbitrate = DBITRATE; if (set_bitrate(ifname, bitrate, dbitrate) 0) fprintf(stderr, Failed to set CAN interface settings ); return 1; printf(CAN interface %s configured with bitrate %d and dbitrate %d , ifname, bitrate, dbitrate); return 0; 参数查看ip -details -statistics link show can0 canconfig can0 数据发送在数据收发的内容方面， CAN 总线与标准套接字通信稍有不同，每一次通信都采用 can_ frame 结构体将数据封装成帧。 结构体定义如 Socket CAN 帧结构体 数据发送使用 write 函数来实现。 如果发送的数据帧 (标识符为 0x123) 包含单个字节 (0xAB) 的数据，可采用如下方法进行发送： struct sockaddr_can addr;struct can_frame frame;struct ifreq ifr;//如果为扩展帧，那么frame.can_id = CAN_EFF_FLAG | 0x123;frame.can_id = 0x123;frame.can_dlc = 1; //数据长度为 1frame.data[0] = 0xAB; //数据内容为 0xABint nbytes = write(s, frame, sizeof(frame));//发送数据nbytes = send(s, frame, sizeof(frame), 0);nbytes = sendto(s, frame, sizeof(frame), 0, (struct sockaddr *)addr, sizeof(addr));//sendmsg struct msghdr msg;struct iovec iov;memset(msg, 0, sizeof(msg));msg.msg_name = addr;msg.msg_namelen = sizeof(addr);iov.iov_base = frame;iov.iov_len = sizeof(frame);msg.msg_iov = iov;msg.msg_iovlen = 1;nbytes = sendmsg(s, msg, 0); 如果要发送远程帧 (标识符为 0x123)，可采用如下方法进行发送： struct can_frame frame;frame.can_id = CAN_RTR_FLAG | 0x123;write(s, frame, sizeof(frame)); 数据接收数据接收使用 read 函数来完成，实现如下： struct can_frame frame;int nbytes = read(s, frame, sizeof(frame));nbytes = recv(s, frame, sizeof(frame), /*0*/MSG_DONTWAIT);nbytes = recvfrom(s, frame, sizeof(frame), 0, (struct sockaddr *)addr, sizeof(addr));struct msghdr msg;struct iovec iov;memset(msg, 0, sizeof(msg));memset(iov, 0, sizeof(iov));iov.iov_base = frame;iov.iov_len = sizeof(frame);msg.msg_iov = iov;msg.msg_iovlen = 1;nbytes = recvmsg(s, msg, 0); 错误处理当帧接收后，可以通过判断 can_id 中的 CAN_ERR_FLAG 位来判断接收的帧是否为错误帧。 如果为错误帧，可以通过 can_id 的其他符号位来判断错误的具体原因。 错误帧的符号位在头文件 linux/can/error.h 中定义。 例如以下代码用于设置 CAN 接口的错误过滤器 can_err_mask_t err_mask;err_mask = CAN_ERR_ACK | CAN_ERR_CRTL | CAN_ERR_BUSOFF | CAN_ERR_BUSERROR;ret = setsockopt(interface-fd, SOL_CAN_RAW, CAN_RAW_ERR_FILTER, err_mask, sizeof(err_mask));if(ret 0)\tlog_printf(LOG_ERR, CAN_ERROR_FILTER_FAILED, interface-ifName);\tlog_printf(LOG_DEBUG, DBG_ERRNO, setsockopt(can err));\treturn CO_ERROR_SYSCALL; CAN_ERR_ACK, CAN_ERR_CRTL, CAN_ERR_BUSOFF, CAN_ERR_BUSERROR 是 CAN 错误的不同类型。这些标志位分别表示收到错误应答、控制器错误、总线关闭、总线错误。 SOL_CAN_RAW 表示操作的是原始 CAN 套接字。 CAN_RAW_ERR_FILTER 是设置原始 CAN 套接字的错误过滤器选项。 过滤规则设置在数据接收时，系统可以根据预先设置的过滤规则，实现对报文的过滤。过滤规则使用 can_filter 结构体来实现，定义如下： struct can_filter canid_t can_id;\tcanid_t can_mask;; 过滤器工作原理：CAN 过滤器使用按位与（）操作来决定是否接收一个帧。 if ((received_can_id filter.mask) == (filter.can_id filter.mask)) // 接收此帧else // 丢弃此帧 通过这条规则可以在系统中过滤掉所有不符合规则的报文，使得应用程序不需要对无关的报文进行处理。在 can_filter 结构的 can_id 中，符号位 CAN_INV_FILTER 在置位时可以实现 can_id 在执行过滤前的位反转。 用户可以为每个打开的套接字设置多条独立的过滤规则，使用方法如下： structcan_filter rfilter[2];rfilter[0].can_id = 0x123;rfilter[0].can_mask = CAN_SFF_MASK;//#define CAN_SFF_MASK 0x000007FFUrfilter[1].can_id = 0x200;rfilter[1].can_mask = 0x700;//设置规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER,rfilter, sizeof(rfilter)); 第一个过滤器 (rfilter): can_id: 0x123mask: 0x7FF (CAN_SFF_MASK)这个过滤器将只接收 ID 为 0x123 的标准帧。因为掩码是 0x7FF，所以 ID 必须完全匹配。 第二个过滤器 (rfilter): can_id: 0x200mask: 0x700 这个过滤器将接收 ID 范围从 0x200 到 0x2FF 的帧。因为： 0x200 0x700 = 0x200 任何 0x2XX 的 ID 与 0x700 进行按位与操作后都等于 0x200 过滤规则禁用。原始套接字就会忽略所有接收到的报文。在仅需要发送数据的应用中，可以在内核中省略接收队列，以此减少 CPU 资源的消耗。禁用方法如下： //禁用过滤规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER, NULL, 0); 通过错误掩码可以实现对错误帧的过滤， 例如： can_err_mask_t err_mask = (CAN_ERR_TX_TIMEOUT | CAN_ERR_BUSOFF );setsockopt(s, SOL_CAN_RAW,CAN_RAW_ERR_FILTER,err_mask,sizeof(err_mask)); 缓冲区大小设置以下代码用于设置缓冲区大小为 512KB，并查询设置之后的缓冲区大小 //todo - modify rx buffer size? first one needs rootbytes = 512*1024;sLen = sizeof(bytes);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUFFORCE, (void *)bytes, sLen);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUF, (void *)bytes, sLen);/* print socket rx buffer size in bytes (In my experience, the kernel reserves * around 450 bytes for each CAN message) */sLen = sizeof(bytes);getsockopt(interface-fd, SOL_SOCKET, SO_RCVBUF, (void *)bytes, sLen);if (sLen == sizeof(bytes)) log_printf(LOG_INFO, CAN_SOCKET_BUF_SIZE, interface-ifName, bytes / 446, bytes); root 用户使用 SO_RCVBUFFORCE 设置缓冲区大小。 普通用户使用 SO_RCVBUF 设置缓冲区大小 回环功能设置在默认情况下， 本地回环功能是开启的，可以使用下面的方法关闭回环开启功能： int loopback = 0; // 0 表示关闭, 1 表示开启( 默认)setsockopt(s, SOL_CAN_RAW, CAN_RAW_LOOPBACK,loopback, sizeof(loopback)); 在本地回环功能开启的情况下，所有的发送帧都会被回环到与 CAN 总线接口对应的套接字上。 默认情况下，发送 CAN 报文的套接字不想接收自己发送的报文，因此发送套接字上的回环功能是关闭的。 可以在需要的时候改变这一默认行为： int ro = 1; // 0 表示关闭( 默认), 1 表示开启setsockopt(s, SOL_CAN_RAW, CAN_RAW_RECV_OWN_MSGS, ro, sizeof(ro)); 套接字状态利用 ioctl() 检查套接字状态 使用 ioctl() 函数结合 FIONREAD 命令可以查询当前套接字接收缓冲区中等待读取的字节数。如果返回的字节数大于 0，则表示有数据可供接收。示例代码如下： int bytes_available;ioctl(sock, FIONREAD, bytes_available);if (bytes_available 0) printf(套接字中有 %d 字节的CAN数据可接收 , bytes_available); // 现在可以读取数据 // ... else printf(套接字中没有可接收的CAN数据 ); ioctl() 函数和 SIOCSIFFLAGS ioctl() 函数：这是一个系统调用函数，用于在用户空间程序中向内核发出特定的控制命令，以实现对设备、接口等的配置和管理。 SIOCSIFFLAGS：这是 ioctl() 函数使用的一个常量，用于设置网络接口的标志。通过 ioctl() 和 SIOCSIFFLAGS，可以启用或禁用一个网络接口，设置接口的工作模式和其他标志位。 CAN 通讯设计硬件ARM 需要有 CAN 控制器和 CAN 收发器 CAN 控制器（CAN Controller）是负责实现 CAN 协议的逻辑部分的组件 CAN 收发器（CAN Transceiver）是负责 CAN 总线电平信号和 CAN 控制器之间的电信号转换的组件 CAN 控制器示例： 内置于微控制器中的 CAN 模块（例如 STM32 系列微控制器的内置 CAN 控制器）。 独立的 CAN 控制器芯片（例如 MCP2515）。 CAN 收发器示例： 常见的独立 CAN 收发器芯片（例如 MCP2551、TJA1050 等）。 先选择 CAN 控制器芯片，一般的 PC 和 ARM 都没有 CAN 控制器，一般是 MCP2515 和 SJA1000，主要区别是 MCP2515 是 SPI 接口，SJA1000 是 IO 接口。所以 MCP2515 占用资源少，5-6 个管脚就可以控制，SJA1000 占用的管脚就多。 内核Linux 中有对 CAN（Controller Area Network）总线的支持，主要通过 SocketCAN 子系统实现。内核编译时选择响应的支持芯片。 $ make linux-menuconfigNetworking support ---\tCAN bus subsystem support ---\t--- CAN bus subsystem support Raw CAN Protocol (raw access with CAN-ID filtering) Broadcast Manager CAN Protocol (with content filtering) CAN Device Drivers --- Virtual Local CAN Interface (vcan) Platform CAN drivers with Netlink support [*] CAN bit-timing calculation Microchip 251x series SPI CAN Controller SocketCAN 支持多种 CAN 控制器硬件，通过不同的内核驱动程序实现对具体硬件的支持。例如，以下是一些常见的 CAN 控制器驱动程序： sja1000：PhilipsNXP SJA1000 CAN 控制器 mcp251x：Microchip MCP251x SPI CAN 控制器系列（如 MCP2515） flexcan：FreescaleNXP FlexCAN 模块 这些驱动程序通常位于内核源代码树的 drivers/net/can 目录下。 驱动需要支持 CAN 控制器驱动，控制 CAN 控制器发送 CAN 帧。对于一般的 CAN 控制器，进行初始化时，最关键的是以下两步： 配置 CAN 的位时序； 配置 CAN 的消息报文； 应用程序CAN 数据发送跟踪当们在用户层通过 socket 进行 CAN 数据的发送时，需要进行以下操作： 创建一个套接字 socket，采用 AF_CAN 协议。 将创建的套接字返回描述符 sockfd，绑定到本地的地址。 通过 sendto 系统调用函数进行发送，sendto 的系统调用会发送一帧数据报到指定的地址，在 CAN 协议调用之前把该地址移到内核空间和检查用户空间数据域是否可读。 在 net/socket.c 源文件中，在 sendto 的系统调用 （sys_sendto） 里，会调用到 sock_sendmsg() 函数，接下来调用 __sock_sendmsg() 函数。 再往下一步就是 __sock_sendmsg_nosec 函数。在 __sock_sendmsg_nosec() 函数中会返回一个 sendmsg 函数指针。 在 /net/can/raw.c 源文件中，将 raw_sendmsg 函数地址赋给 sendmsg 函数指针，即在函数 __sock_sendmsg_nosec() 中 return sock-ops-sendmsg(iocb,sock, msg, size)，返回的函数指针将指向 raw_sendmsg() 函数。 在 net/can/af_can.c 源文件中，can_send 函数负责 CAN 协议层的数据传输，即传输一帧 CAN 报文（可选本地回环）。参数 skb 指针指向套接字缓冲区和在数据段的 CAN 帧。loop 参数是在本地 CAN 套接字上为监听者提供回环。 以下开始进行到 CAN 的底层驱动代码了，由于 CAN 驱动是编译进内核中，所以在系统启动时会注册 CAN 驱动。 注册 CAN 驱动过程中会初始化 d_can_netdev_ops 结构体变量。 在这个过程中，d_can_netdev_ops 结构体变量定义了 3 个函数指针，其中 (*ndo_start_xmit) 函数指针指向 d_can_start_xmit 函数的入口地址。 在 d_can_start_xmit() 函数中，会调用 d_can_write_msg_object() 函数准备消息报文进行传输。 CAN 数据接收跟踪对于网络设备，数据接收大体上采用中断 +NAPI 机制进行数据的接收。同样，们现在的 CAN 模块也是采用同样的方式进行数据的接收。由于们只针对 CAN 总线接收数据这条主线进行分析。因些，会忽略一些针对 CAN 协议的设置及初始化等相关代码。 NAPI（New API）是一种改进的网络数据接收机制，它通过减少中断处理的次数来提高性能。NAPI 的基本思想是延迟数据包的处理，使得多个数据包可以一次性地在中断处理程序中进行处理，从而减少了中断的数量，提高了系统的处理效率。 中断 +NAPI 机制的工作原理大致如下： 当网络数据包到达时，网络接口卡会生成一个中断通知操作系统。 中断服务程序会执行一些必要的处理，然后调用 NAPI 机制。 NAPI 机制会检查网络接口缓冲区中是否有足够的数据需要处理。 如果有足够的数据，NAPI 会立即开始处理这些数据，而不会再次触发中断。如果数据量不足，NAPI 会退出，并要求在将来的某个时候再次调用。 处理完数据后，系统可以选择性地决定是否重新启用中断服务程序。 通过将数据包的处理延迟到一组数据包到达时再进行，中断 +NAPI 机制能够大大减少中断的数量，提高系统的处理效率，特别是在高负载情况下。 在初始化 CAN 设备时，们需要给 CAN 设备分配 NAPI 功能。们通过 netif_napi_add() 函数将 CAN 设备添加到 NAPI 机制列表中。 将 CAN 设备添加到 NAPI 机制列表中后，在中断处理函数 d_can_isr 中，们通过 napi_schedule() 函数调度已经在 NAPI 机制列表中的 d_can_poll() 函数。该函数会通过轮询的方式接收数据。而根据 NAPI 机制，当中断产生后，会调度轮询机制同时关闭所有的中断。 当中断产生时，会调用函数 d_can_poll()，该函数即采用轮询的方式进行数据的接收。由于 CAN 总线状态中断具有最高优先权，在接收数据之前，需要对 CAN 总线的状态进行判断。而对于 CAN 总线错误状态有三种：主动被动关闭。 当总线状态数据状态正常时，从 CAN 模块的接收寄存器中接收数据。 测试要在 linux 下面配置和测试 CAN，需要安装以下三个组件。 iproute2 （配置 CAN 接口时需要） libsocketcan（使用 CAN 必须） CAN 的测试小工具 can-utils https://github.com/linux-can/can-utils 可以直接通过命令行形式控制 CAN # 配置CAN接口（假设设备名为`can0`）：ip link set can0 up type can bitrate 500000# 启动CAN接口ip link set up can0# 查看CAN接口状态ip -details link show can0# CAN 2.0 linkupip link set can0 up type can bitrate 100000# CAN 2.0 FD linkupip link set can0 up type can bitrate 500000 dbitrate 2000000 fd on# 命令来配置 CAN 总线的位速率：ip link set can0 type cantq 125 prop-seg 6 phase-seg1 7 phase-seg2 2 sjw 1# 可以使用 ip 命令直接设定位速率500kbps：ip link set can0 type can bitrate 500000# 当设置完成后，可以通过下面的命令查询 can0 设备的参数设置：ip -details link show can0# 当设置完成后，可以使用下面的命令使能 can0 设备：ifconfig can0 up# 使用下面的命令取消 can0 设备使能：ifconfig can0 down# 在设备工作中，可以使用下面的命令来查询工作状态：ip -details -statistics link show can0 负载计算在 CAN 总线上，发送一帧数据所需的时间可以通过帧的总位数和波特率来计算。 发送时间计算 发送时间 = 总位数 / 波特率= 111 位 / 500000 位/秒= 222 * 10^-6 秒 总线负载计算，是总线实际使用的带宽与总带宽的比值，通常表示为百分比。 总线负载 = ((总帧时间秒×每秒发送的帧数)/总可用时间秒)×100%总帧时间：一帧数据的发送时间每秒发送的帧数：一秒钟内发送的帧数总可用时间：每秒可用的时间，即 1 秒 假设每秒发送 1000 帧数据，则 1 秒内该总线上的负载为： 总帧时间：222 微秒 = 222 * 10^-6 秒每秒发送的帧数：1000 帧/秒总可用时间：1 秒总线负载=((222*10^−6 * 1000) / 1)×100%总线负载=22.2% Qt 中的 CAN 插件需要编译安装 socketCAN 插件， https://doc.qt.io/qt-5/qtserialbus-socketcan-overview.html ，关键字【Using SocketCAN Plugin】 pro 文件中添加 QT += serialbus QString errorString;const QListQCanBusDeviceInfo devices = QCanBus::instance()-availableDevices(QStringLiteral(socketcan), errorString);if (!errorString.isEmpty())\tqDebug() errorString; 多线程下利用线程权限进行高速的 CAN 通信用 PC 里能达到的 CAN 通信（使用 USBCAN-II）速度是 1ms 使用 3 个线程类：1 个用来接收，1 个用来发送，1 个用来解析 接收线程使用最高线程权限：QThread::HighestPriority，其余线程用 QThread::HighPriority 如何循环发送报文：在发送线程里再多加一个定时器，timeout 时间为需要循环发送的时间（可达到 1ms）； 用户在主界面设置需要发送的报文为 OBJ 结构体数组，然后通过构造函数的方式传到发送线程，最后发送就行了。 解析过程：接收函数循环接收报文，每接收到 n 帧就发送到解析线程，然后根据 ID 解析，将解析数据发送主界面显示（不要 append） 问题记录RK3568 在高速接收 CAN 帧消息时，出现 RCU 告警 rcu INFO: rcu_sched self-detected stall on CPU，CPU 占用跑满，该问题原因是错误帧中断过多导致的系统卡顿问题。 原因为 RK3568 默认的 CAN 驱动位 CANFD，调整设备树中的驱动为 CAN 后正常接收。 《Rockchip RK3568RK3568B2RK3568J Application Notice-RKAN18055》中提到存在以下设计缺陷：RK3568 作为发送方，扩展帧概率性变成标准帧，导致接收方存在丢帧情况，进而影响设备的正常通讯或者控制。产生原因是在发送扩展帧时候，内部寄存器状态值在特定组合条件下，触发 load 失败，从而最后按标准帧而非扩展帧的格式来发送 ID 和 DLC 段。RK3568 作为 接收方 概率性出现 CRC 校验错误和 ID 段填充位错误 ，导致接收方会往总线发送错误帧，由发送方进行重发。 3568 原生 CAN 驱动使用自收方案修改 kernelarcharm64bootdtsrockchiprk3568.dtsi 文件，注释掉下图部分，取消 workround 帧的配置，修改后会自动打开 CAN 的 TXtoRX，原生 CAN 发送扩展帧数据时，会收回自己发出的数据做校验，若校验不是扩展帧将重新发送一帧。 注意：此方案在扩展出来的 ID 部分 ID 为 0 时，会触发无限重发机制，慎用。","categories":["3.协议","CAN"]},{"title":"CAN总线的网络拓扑结构","path":"/2023/12/28/3-协议-CAN-CAN总线的网络拓扑结构/","content":"线性结构线性拓扑结构通常指的是一种基于多点连接的拓扑结构，信号线为 CAN-高电平和 CAN-低电平，两端端接一个 120 欧姆终端电阻，该线路称为主干线，也称为总线。所有的设备连接到共同的传输介质上，总线上任意节点发送信息，其它节点都能收到，这种从主干线分出的短分支线（也称为 stub）。Stub length（分支线长度）是指从主干线到终端节点的短分支线的长度。 根据 CAN 规范和实际工程经验，stub length 的长度应尽量保持短，以减少信号反射和失真。过长的 stub 会导致信号的反射，增加网络中的噪声和误码率。ISO 11898 CAN 标准：建议 stub length 应保持在 0.3 米（30 厘米） 以下。不同的速度对分支线长度的要求可能不同：在 1 Mbps 的速率下，stub length 通常被建议小于 30 厘米。在较低速率下，允许的 stub length 可以稍长，但一般不超过 3 米。 星型结构在 CAN 网络中，多个节点通过各自的分支线连接到一个中心节点或集线器上，由中央节点向目的节点传送信息，中央节点执行集中式通信控制策略。 树型结构 环型结构环形拓扑是将 CAN 总线首尾相接，形成环状，保证线缆的任意位置断开依然可以保证通讯。环形拓扑的终端电阻匹配采用分布式匹配方法，保证总体阻抗为 60 欧姆。 CAN 网络在CAN 总线（Controller Area Network）系统中，CAN 网桥和CAN 网关是两种用于连接多个 CAN 网络的设备，网桥和网关都是为了扩展系统的功能和灵活性，但网桥更关注物理层面的连接和扩展，而网关则在网络层面管理和优化数据传输。 CAN 网桥：用于物理连接不同的 CAN 网络，简单地转发报文，适用于同协议的网络互连，能够解决波特率不同或物理距离受限的问题。 CAN 网关：功能更强大，支持报文过滤、数据处理和协议转换，适用于连接不同协议的网络或需要智能数据管理的场景。 特性 CAN 网桥 CAN 网关 功能 转发 CAN 报文 转发、过滤、处理报文，协议转换 网络连接 连接同协议的 CAN 网络 连接不同协议或不同波特率的网络 报文处理 不修改报文，直接转发 可以修改、过滤或组合报文 应用场景 连接多个 CAN 网络，延长物理距离 连接不同协议网络，过滤数据流 CAN 网桥（CAN Bridge）CAN 网桥是一种用于连接两个或多个 CAN 网络的设备，使它们可以在相同或不同的波特率下进行通信。网桥的主要目的是物理上连接这些网络，透明地转发 CAN 报文，而不做协议转换或处理。 连接不同波特率的 CAN 网络：CAN 网桥允许将运行在不同波特率的 CAN 网络连接起来。例如，一个 CAN 网络可能运行在 1 Mbps，而另一个 CAN 网络可能运行在 500 kbps。CAN 网桥会在这些网络之间转发报文。 透明传输：CAN 网桥通常不改变报文的内容，它只是将接收到的报文从一个 CAN 网络转发到另一个网络。 延长 CAN 网络的物理距离：由于 CAN 总线的物理长度与波特率成反比，网桥可以通过将多个短的 CAN 网络连接在一起，间接增加网络的覆盖范围，而不会超出单个 CAN 网络的距离限制。 CAN 网关（CAN Gateway）CAN 网关是一种智能设备，不仅可以连接多个 CAN 网络，还能执行报文过滤、协议转换、数据处理等功能。相比 CAN 网桥，CAN 网关的功能更加灵活且复杂，它不仅仅是简单地转发数据，还能够根据设定的规则对数据进行转换或过滤。 协议转换：CAN 网关可以连接不同的网络协议，如将 CAN 报文转换为 LIN、FlexRay、Ethernet 等报文格式，并在不同网络之间进行数据交换。 报文过滤和路由：网关可以根据预设的规则对报文进行过滤、路由，即只转发部分符合条件的报文，或修改报文内容后再转发。这可以有效地降低网络负载，并增加数据传输的安全性。 数据处理：CAN 网关可以执行特定的应用逻辑，如根据收到的 CAN 消息执行某些操作，甚至可以将多条消息组合为一条消息再转发。 网络隔离和保护：CAN 网关在连接不同网络时，可以隔离这些网络，防止故障或攻击在不同网络之间传播。","categories":["3.协议","CAN"]},{"title":"CAN驱动中的NAPI","path":"/2023/12/27/3-协议-CAN-CAN驱动中的NAPI/","content":"NAPI 是在 Linux 上实现的一项技术，旨在提高网络数据处理的效率。它的核心理念是放弃传统的中断方式来读取数据，而是首先通过中断激活一个服务程序来处理数据接收。之后，服务程序利用轮询的方式（poll）来检查数据。这一方法有效提高了短小数据包的接收效率，显著减少了因频繁中断导致的 CPU 资源消耗。 理解 NAPI 的必要性在 NAPI 机制引入之前，网络设备处理接收数据包的方式完全依赖中断。以一个实际例子来看，假设接收到的数据包每个长度仅为几个字节。在一秒钟内，如果系统接收到 5000 个这样的数据包，会创造出 5000 次中断。这种情况下，处理每一次中断都要消耗 CPU 资源，导致系统无法高效运作。 NAPI 的出现就是为了解决这样的问题。通过将中断和轮询结合，系统可以在处理数据的同时，减少由于不断中断而浪费的资源，从而提高整体网络性能。 源码解析接下来，让们深入观察 NAPI 的实现细节。首先，在分配 CAN 设备时，们可以看到使用了 netif_napi_add 函数注册轮询函数 d_can_poll()。 struct net_device *alloc_d_can_dev(int num_objs) struct net_device *dev; struct d_can_priv *priv; dev = alloc_candev(sizeof(struct d_can_priv), num_objs / 2); if (!dev) return NULL; priv = netdev_priv(dev); netif_napi_add(dev, priv-napi, d_can_poll, num_objs / 2); priv-dev = dev; priv-can.bittiming_const = d_can_bittiming_const; priv-can.do_set_mode = d_can_set_mode; priv-can.do_get_berr_counter = d_can_get_berr_counter; priv-can.ctrlmode_supported = (CAN_CTRLMODE_LOOPBACK | CAN_CTRLMODE_LISTENONLY | CAN_CTRLMODE_BERR_REPORTING | CAN_CTRLMODE_3_SAMPLES); return dev; 在这段代码中，们首先分配一个 CAN 设备，并通过调用 netif_napi_add 函数将轮询函数 d_can_poll 注册到 NAPI 中。这个函数还设置了与网络接口设备相关的各种属性。 netif_napi_add() 函数的原型如下： void netif_napi_add(struct net_device *dev, struct napi_struct *napi, int (*poll)(struct napi_struct *, int), int weight) INIT_LIST_HEAD(napi-poll_list); napi-gro_count = 0; napi-gro_list = NULL; napi-skb = NULL; napi-poll = poll; napi-weight = weight; list_add(napi-dev_list, dev-napi_list); napi-dev = dev; #ifdef CONFIG_NETPOLL spin_lock_init(napi-poll_lock); napi-poll_owner = -1; #endif set_bit(NAPI_STATE_SCHED, napi-state); 在 netif_napi_add 函数中，它初始化了 NAPI 结构体中的各个字段，并将其添加到设备的 NAPI 列表中。这确保了当 NAPI 被激活时，能够正确处理轮询。 轮询函数 d_can_poll 的实现轮询函数 d_can_poll 的代码如下： static int d_can_poll(struct napi_struct *napi, int quota) int lec_type = 0; int work_done = 0; struct net_device *dev = napi-dev; struct d_can_priv *priv = netdev_priv(dev); if (!priv-irqstatus) goto end; /* status events have the highest priority */ if (priv-irqstatus == STATUS_INTERRUPT) priv-current_status = d_can_read(priv, D_CAN_ES); /* handle Tx/Rx events */ if (priv-current_status D_CAN_ES_TXOK) d_can_write(priv, D_CAN_ES, priv-current_status ~D_CAN_ES_TXOK); if (priv-current_status D_CAN_ES_RXOK) d_can_write(priv, D_CAN_ES, priv-current_status ~D_CAN_ES_RXOK); /* handle state changes */ if ((priv-current_status D_CAN_ES_EWARN) (!(priv-last_status D_CAN_ES_EWARN))) netdev_dbg(dev, entered error warning state ); work_done += d_can_handle_state_change(dev, D_CAN_ERROR_WARNING); if ((priv-current_status D_CAN_ES_EPASS) (!(priv-last_status D_CAN_ES_EPASS))) netdev_dbg(dev, entered error passive state ); work_done += d_can_handle_state_change(dev, D_CAN_ERROR_PASSIVE); if ((priv-current_status D_CAN_ES_BOFF) (!(priv-last_status D_CAN_ES_BOFF))) netdev_dbg(dev, entered bus off state ); work_done += d_can_handle_state_change(dev, D_CAN_BUS_OFF); /* handle bus recovery events */ if ((!(priv-current_status D_CAN_ES_BOFF)) (priv-last_status D_CAN_ES_BOFF)) netdev_dbg(dev, left bus off state ); priv-can.state = CAN_STATE_ERROR_ACTIVE; if ((!(priv-current_status D_CAN_ES_EPASS)) (priv-last_status D_CAN_ES_EPASS)) netdev_dbg(dev, left error passive state ); priv-can.state = CAN_STATE_ERROR_ACTIVE; priv-last_status = priv-current_status; /* handle lec errors on the bus */ lec_type = d_can_has_handle_berr(priv); if (lec_type) work_done += d_can_handle_bus_err(dev, lec_type); else if ((priv-irqstatus = D_CAN_MSG_OBJ_RX_FIRST) (priv-irqstatus = D_CAN_MSG_OBJ_RX_LAST)) /* handle events corresponding to receive message objects */ work_done += d_can_do_rx_poll(dev, (quota - work_done)); else if ((priv-irqstatus = D_CAN_MSG_OBJ_TX_FIRST) (priv-irqstatus = D_CAN_MSG_OBJ_TX_LAST)) /* handle events corresponding to transmit message objects */ d_can_do_tx(dev); end: if (work_done quota) napi_complete(napi); /* enable all IRQs */ d_can_interrupts(priv, ENABLE_ALL_INTERRUPTS); return work_done; 在这个轮询函数中，们处理了多种状态事件和错误处理，确保网络设备能够在接收消息时对状态进行响应并进行相应的处理。当工作完成的数量小于指定的限额时，函数会调用 napi_complete。 中断处理过程在中断处理函数中，们禁止设备接收中断，然后通知网络子系统以轮询模式快速接收数据。这个过程通过 napi_schedule() 函数完成。 static irqreturn_t d_can_isr(int irq, void *dev_id) struct net_device *dev = (struct net_device *)dev_id; struct d_can_priv *priv = netdev_priv(dev); priv-irqstatus = d_can_read(priv, D_CAN_INT); if (!priv-irqstatus) return IRQ_NONE; /* disable all interrupts and schedule the NAPI */ d_can_interrupts(priv, DISABLE_ALL_INTERRUPTS); napi_schedule(priv-napi); return IRQ_HANDLED; 在上述代码中，首先读取中断状态，然后根据状态选择禁用所有中断，并安排 NAPI 进行轮询处理。 NAPI 的启用与禁用由于可能存在多个 NAPI 结构实例，开发人员需要控制每个实例的使能与禁用，以确保网络接口的正常操作。在 d_can_open() 函数中使用 napi_enable()，在 d_can_close() 函数中使用 napi_disable() 方法进行管理。 napi_enable(priv-napi);napi_disable(priv-napi); 通过以上的实现，不仅确保了网络接收的高效性，还保证了在网络负载时能更平稳地维护设备状态。这一整套机制的建立，使得网络处理在高并发下仍能保持高效，极大地提升了系统的整体表现。","categories":["3.协议","CAN"]},{"title":"RK3568内核CAN修改验证笔记","path":"/2023/12/26/3-协议-CAN-RK3568内核CAN修改验证笔记/","content":"修改方案说明 设备树中原节点配置为 CANFD，修改为 CAN 设备树中修改节点接收缓冲区，由原来的 6 改为 32 修改驱动中的中断处理机制，原来是进中断直接处理，修改为 NAPI 的方式进入中断进行轮询处理 CAN 控制器工作原理Rockchip 的 CAN 控制器包含以下主要模块: 接口管理逻辑：连接外部主控制器，解释命令，控制寄存器寻址。 CAN 核心模块：负责 CAN 帧的串并转换。 发送缓冲器：存储待发送的完整报文。 验收滤波器：过滤不需要接收的报文。 接收 FIFO：存储从 CAN 总线接收的报文。 节点信息输入 ip -details link show can0 查看节点信息 CANFD 节点信息，节点中带有 FD 字样 CAN 节点信息 设备树配置Rockchip 的 CAN 控制器在设备树中进行配置。定义了 CAN 控制器的兼容性、寄存器地址、中断、时钟、复位、引脚配置等信息。设备树地址 kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi can0 compatible = rockchip,can-1.0;\tassigned-clocks = cru CLK_CAN0;\tassigned-clock-rates = 300000000;\tpinctrl-names = default;\tpinctrl-0 = can0m0_pins;\trx-fifo-depth = 32;\tstatus = okay;; kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi can0: can@fe570000 compatible = rockchip,rk3568-can-2.0;\treg = 0x0 0xfe570000 0x0 0x1000;\tinterrupts = GIC_SPI 1 IRQ_TYPE_LEVEL_HIGH;\tclocks = cru CLK_CAN0, cru PCLK_CAN0;\tclock-names = baudclk, apb_pclk;\tresets = cru SRST_CAN0, cru SRST_P_CAN0;\treset-names = can, can-apb;\ttx-fifo-depth = 1;\trx-fifo-depth = 6;\tstatus = disabled;; compatible 用来配置 CAN 控制器的驱动，默认启用的 CANFD # rockchip,can-1.0用来匹配can控制器驱动compatible=rockchip,can-1.0# rockchip,can-2.0用来匹配canfd控制器驱动。compatible=rockchip,can-2.0rockchip,can-1.0rockchip,canfd-1.0 assigned-clock-rates 用来配置 can 的时钟频率，如果 CAN 的比特率低于 1M 建议修改 CAN 时钟到 200M，信号更稳定。高于 1M 比特率的，时钟设置 300M 就可以。 pinctrl 根据实际连接情况配置 can h 和 can l 的 iomux 作为 can 功能使用。 IOMUX 是 InputOutput Multiplexer 的缩写，意思是输入输出多路复用器。在嵌入式系统和微控制器中，IOMUX 是一种硬件机制，用于配置芯片的引脚功能。 rx-fifo-depth: 决定接收 FIFO 缓冲区可以存储的 CAN 消息数量。默认该值设置为 6，这意味着接收 FIFO 可以容纳多达 6 条 CAN 消息，然后由软件处理，从而有助于确保消息接收的可靠性而不会丢失。需要在缓冲容量和资源使用间的权衡 rx-fifo-depth 的影响 缓冲容量: 更深的 FIFO 缓冲区可以存储更多的消息，这在 CAN 控制器以高频率接收消息且软件无法立即处理时非常有用，这有助于防止消息丢失。延迟: 更大的 FIFO 可能会引入轻微的延迟，因为消息可能会在缓冲区中等待更长时间才被处理。然而，与避免消息丢失的好处相比，这种延迟通常是最小的。资源使用: 增加 FIFO 深度可能会使用更多的硬件资源（例如内存），但对于合理的值来说，这通常可以忽略不计。系统响应性: 如果读取 FIFO 消息的软件不够快，拥有更深的 FIFO 可以帮助吸收突发的输入消息，从而使系统更具响应性并避免丢失消息。 内核配置要使用 CAN 功能，需要在内核配置中启用相关选项，内核配置文件地址 kernel/arch/arm64/configs/OK3568-C-linux_defconfig #y编译进内核#n不编译#m模块方式加载CONFIG_CAN=yCONFIG_CAN_ROCKCHIP=yCONFIG_CANFD_ROCKCHIP=y 修改内核中的 CAN FD 节点为 CAN 节点并关闭内核中的 CANFD 功能。修改 vi ./kernel/arch/arm64/configs/OK3568-C-linux_defconfig 中的 CONFIG_CANFD_ROCKCHIP=n，关闭 CANFD 驱动文件Rockchip 的 CAN 驱动文件通常位于内核源码的 drivers/net/can/rockchip/ 目录下。 网络设备驱动的中断处理 中说明了关于网络设备中断的处理 将给定的 CAN 驱动代码改为使用 NAPI(New API)进行开发，需要进行以下主要修改： //在 struct rockchip_can 中添加 NAPI 结构：struct rockchip_can struct can_priv can; struct napi_struct napi; // ... 其他成员 ...;//实现 NAPI 轮询函数：static int rockchip_can_poll(struct napi_struct *napi, int budget)//budget 每次调用 NAPI 轮询函数时最多处理的包数量。 struct rockchip_can *rcan = container_of(napi, struct rockchip_can, napi); struct net_device *ndev = rcan-can.dev; int work_done = 0; while (work_done budget) if (!(readl(rcan-base + CAN_STATE) RX_BUF_FULL)) break; rockchip_can_rx(ndev); work_done++; if (work_done budget) napi_complete_done(napi, work_done); // 重新启用中断 writel(readl(rcan-base + CAN_INT_MASK) ~RX_FINISH, rcan-base + CAN_INT_MASK); return work_done;//修改中断处理函数：static irqreturn_t rockchip_can_interrupt(int irq, void *dev_id) struct net_device *ndev = dev_id; struct rockchip_can *rcan = netdev_priv(ndev); u32 isr; isr = readl(rcan-base + CAN_INT); if (!isr) return IRQ_NONE; // 处理接收中断 if (isr RX_FINISH) // 禁用接收中断 writel(readl(rcan-base + CAN_INT_MASK) | RX_FINISH, rcan-base + CAN_INT_MASK); napi_schedule(rcan-napi); // 处理其他中断... return IRQ_HANDLED;//在驱动初始化函数中设置 NAPI：static int rockchip_can_probe(struct platform_device *pdev) // ... 其他初始化代码 ... netif_napi_add(ndev, rcan-napi, rockchip_can_poll, 64); // ... 其他初始化代码 ...//在 rockchip_can_open 函数中启用 NAPI：static int rockchip_can_open(struct net_device *ndev) // ... 其他初始化代码 ... napi_enable(rcan-napi); // ... 其他初始化代码 ...//在 rockchip_can_stop 函数中禁用 NAPI：static int rockchip_can_stop(struct net_device *ndev) struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... napi_disable(rcan-napi); // ... 其他清理代码 ...//在驱动卸载函数中删除 NAPI：static int rockchip_can_remove(struct platform_device *pdev) struct net_device *ndev = platform_get_drvdata(pdev); struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... netif_napi_del(rcan-napi); // ... 其他清理代码 ... 使用 NAPI 来处理接收数据能够提高性能并减少中断负载。NAPI 允许驱动在高负载情况下轮询接收数据，而不是为每个接收的帧生成中断。这可以显著提高系统的效率，特别是在高数据率的情况下。 LED 状态指示可以通过修改内核驱动，实现 LED 状态灯根据 CAN 收发数据情况变化，以显示 CAN 活动状态。 测试和使用 can-utils 工具包进行 CAN 接口的测试和使用 candump 用于接收数据 cansend 用于发送数据CANOpen 调试 中说明了相关命令的使用 OK3568 的 UART8 复用为 CAN2设备树中使能 CAN 功能 设备树kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi节点can2属性status = okay 关闭 UART8 功能 设备树kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi节点uart8属性status=disabled 修改完成后回到 OK3568-linux-source 目录执行.build.sh kernel 编译完成后单独烧写 OK3568-linux-sourcekernelboot.img 镜像文件即可。","categories":["3.协议","CAN"]},{"title":"Rockchip CAN驱动NAPI","path":"/2023/12/25/3-协议-CAN-Rockchip-CAN驱动NAPI/","content":"Rockchip 系列芯片的 CAN 驱动Rockchip 系列芯片的 CAN 驱动涉及多个关键方面，这些组成部分共同确保了 CAN 功能的正常运作。具体可以从以下几个方面进行详细阐述： 设备树配置在 Rockchip 芯片中，CAN 控制器的设备树配置是至关重要的。以 RK3588 为例，其 CAN 控制器在设备树中的配置示例如下： can0: can@fea50000 compatible = rockchip,can-2.0; reg = 0x0 0xfea50000 0x0 0x1000; interrupts = GIC_SPI 341 IRQ_TYPE_LEVEL_HIGH; clocks = cru CLK_CAN0, cru PCLK_CAN0; clock-names = baudclk, apb_pclk; resets = cru SRST_CAN0, cru SRST_P_CAN0; reset-names = can, can-apb; pinctrl-names = default; pinctrl-0 = can0m0_pins; tx-fifo-depth = 1; rx-fifo-depth = 6; status = disabled;; 在这段配置中，定义了多个关键元素： 兼容性：指定控制器的类型，通过 compatible 字段使得系统知道要使用哪个驱动。 寄存器地址：reg 字段定义了控制器的寄存器地址范围，系统通过这个地址与硬件进行交互。 中断设置：通过 interrupts 字段设置相应的中断类型，确保能及时响应 CAN 通讯请求。 时钟和复位：这些设置确保控制器在正确的时钟频率下工作，clocks 和 resets 字段分别配置了与控制器工作相关的时钟信号和复位信号。 引脚配置：pinctrl-names 和 pinctrl-0 字段指定了使用的引脚配置，接口的物理连接在此处被定义。 FIFO 深度：tx-fifo-depth 和 rx-fifo-depth 定义了发送和接收缓冲区的深度，影响数据处理能力。 驱动文件Rockchip 的 CAN 驱动文件通常位于内核源码的 drivers/net/can/rockchip/ 目录下。这个路径下的文件经过编译后，形成内核模块，提供与硬件交互的操作。 内核配置为了顺利启用 CAN 功能，需要在内核配置中启用相关选项。具体来说，用户需要确保 CONFIG_CAN 和 CONFIG_CAN_ROCKCHIP 这两个选项被开启。这通常通过修改 .config 文件或者使用 make menuconfig 命令完成。 CAN 控制器工作原理Rockchip 的 CAN 控制器包括以下主要模块： 接口管理逻辑：它负责与外部主控制器的连接，理解来自主控制器的命令，并控制寄存器的寻址。 CAN 核心模块：负责将数据帧进行串并转换，是数据通信的核心部分。 发送缓冲器：在 CAN 总线上发送前，完整的报文会存储在这个缓冲器中，确保数据的顺利传输。 验收滤波器：用于筛选不必要的报文，减轻系统负担，确保接收到的是有效数据。 接收 FIFO：从 CAN 总线接收的报文首先存储在此处，以备后续处理。 工作模式Rockchip 的 CAN 控制器支持两种工作模式： BasicCAN：这种模式仅支持标准 CAN 协议。它适用于大多数简单的应用场景。 PeliCAN：该模式支持 CAN 2.0B 协议，既可以处理标准帧又可以处理扩展帧，适应性更强，适合复杂的网络操作，例如多节点系统。 测试和使用可以使用 can-utils 工具包进行 CAN 接口的测试和使用。以下是一些常用命令： **candump**：用于接收和显示经过 CAN 网络的数据，方便进行实时监控。 **cansend**：用于发送数据到 CAN 网络，检验网络的通讯能力以及故障排除。 LED 状态指示通过修改内核驱动，有可能实现 LED 指示灯根据 CAN 数据的收发情况变化。这种可视化的状态指示，不仅增强了系统的用户体验，还能为故障排查提供便利。 如何在 Rockchip 平台上配置 CAN 驱动在 Rockchip 平台上配置 CAN 驱动涉及一系列步骤，需仔细执行以确保系统的正常运行。以下是详细的操作步骤和必要的注意事项。 1. 设备树配置首先，在设备树文件中配置 CAN 控制器。以 RK3588 为例，可在相应的 dtsi 文件中找到或添加 CAN 控制器的基本配置。下面的代码示例说明了如何定义 CAN 控制器： can0: can@fea50000 compatible = rockchip,can-2.0; reg = 0x0 0xfea50000 0x0 0x1000; interrupts = GIC_SPI 341 IRQ_TYPE_LEVEL_HIGH; clocks = cru CLK_CAN0, cru PCLK_CAN0; clock-names = baudclk, apb_pclk; resets = cru SRST_CAN0, cru SRST_P_CAN0; reset-names = can, can-apb; pinctrl-names = default; pinctrl-0 = can0m0_pins; tx-fifo-depth = 1; rx-fifo-depth = 6; status = disabled; // 初始状态为禁用; 具体说明 compatible 字段指定了该设备的兼容性。 reg 表示该设备的寄存器地址范围。 interrupts 定义了使用的中断类型及其编号。 clocks 和 clock-names 声明了所需的时钟。 resets 和 reset-names 表示重置控制信号。 2. 启用 CAN 控制器接下来，在特定板级的 DTS 文件中，将 CAN 控制器的状态 status 修改为 okay，以启用该控制器。修改后的代码示例如下： status = okay; // 确保控制器被启用 3. 内核配置为了使内核识别并支持 CAN 功能，需要在内核配置中启用相关选项。确保在配置文件中加入以下行： CONFIG_CAN=yCONFIG_CAN_DEV=yCONFIG_CAN_ROCKCHIP=y 说明 CONFIG_CAN 启用整个 CAN 功能支持。 CONFIG_CAN_DEV 使能 CAN 设备的支持。 CONFIG_CAN_ROCKCHIP 特别为 Rockchip 平台启用 CAN 驱动。 4. 编译驱动Rockchip 的 CAN 驱动源文件通常位于内核源码的 drivers/net/can/rockchip/ 目录下。确保这些文件被正确编译并包含在内核映像中。运行内核编译后，检查生成的模块是否已包含 CAN 驱动。 5. 测试和使用编译完成后，可以使用 can-utils 工具包对 CAN 接口进行测试。此工具包提供了一系列命令来操作 CAN 网络，以下是一些常用的命令示例： 示例命令 接收数据： candump can0 发送数据： cansend can0 123#DEADBEEF 说明 candump 命令用于监听并打印从 can0 接口接收到的数据。 cansend 命令则可用来发送特定的 CAN 消息，格式为 标识符#数据。 6. 可选：LED 状态指示可以通过修改内核驱动，使 LED 指示灯根据 CAN 的收发状态变换，从而指示 CAN 活动的状态。这需要在驱动中增加对 LED 控制的支持。 在 Rockchip 平台上优化 CAN 驱动性能的中断处理，可以通过实现 NAPI 机制和调整 NAPI 预算值来显著提高效率。以下是详细的实现步骤和示例代码。 使用 NAPI 机制处理中断 定义 NAPI 结构在驱动程序中，需要首先定义一个 napi_struct 结构体。这一结构体将承载与 NAPI 相关的数据和状态信息。 struct napi_struct napi; 在驱动初始化时注册 NAPI当驱动初始化时，通过 netif_napi_add 将 NAPI 结构添加到网络设备中。这里，rockchip_can_poll 是处理数据包的轮询函数，NAPI_POLL_WEIGHT 是初始的预算值。 netif_napi_add(dev, napi, rockchip_can_poll, NAPI_POLL_WEIGHT); 修改中断处理函数接下来，需修改中断处理函数，确保在接收到中断后禁用设备中断，并调度 NAPI。 static irqreturn_t rockchip_can_interrupt(int irq, void *dev_id) struct net_device *dev = (struct net_device *)dev_id; struct rockchip_can *priv = netdev_priv(dev); // 禁用设备中断 rockchip_can_disable_interrupts(priv); // 调度 NAPI if (napi_schedule_prep(priv-napi)) __napi_schedule(priv-napi); return IRQ_HANDLED; 实现 NAPI 轮询函数在轮询函数中，处理接收到的数据包。如果处理的包数量少于预算值，则完成 NAPI 调用，并重新启用中断。 static int rockchip_can_poll(struct napi_struct *napi, int budget) struct rockchip_can *priv = container_of(napi, struct rockchip_can, napi); int work_done = 0; // 处理接收的数据包 work_done = rockchip_can_rx(priv, budget); // 如果处理的包数量小于预算，完成 NAPI if (work_done budget) napi_complete_done(napi, work_done); rockchip_can_enable_interrupts(priv); return work_done; 调整 NAPI 预算值 通过 sysfs 接口动态调整 NAPI 预算使用 sysfs 接口允许用户在运行时调整 NAPI 的预算值。用户可以通过写入新值来动态更新预算。 static ssize_t napi_budget_store(struct device *dev, struct device_attribute *attr, const char *buf, size_t count) struct net_device *ndev = to_net_dev(dev); struct rockchip_can *priv = netdev_priv(ndev); unsigned int budget; if (kstrtouint(buf, 0, budget)) return -EINVAL; priv-napi.weight = budget; // 更新 NAPI 预算 return count;static DEVICE_ATTR_WO(napi_budget);// 在驱动初始化时创建 sysfs 接口device_create_file(ndev-dev, dev_attr_napi_budget); 根据实际性能测试结果调整预算值根据实际测试结果逐步调整预算，初始值可以为 16 或 32 然后根据性能反馈进行变化，直到找到最佳配置。 动态调整预算随着对负载情况的监控，可实现动态调整 NAPI 预算。比如当接收溢出次数超过阈值时，增加预算；当没有溢出时，减小预算。 static void rockchip_can_adjust_napi_budget(struct rockchip_can *priv) if (priv-rx_overflow_count THRESHOLD) priv-napi.weight = min(priv-napi.weight * 2, MAX_NAPI_WEIGHT); else if (priv-rx_overflow_count == 0) priv-napi.weight = max(priv-napi.weight / 2, MIN_NAPI_WEIGHT); 通过以上优化措施，可以有效减少中断的触发频率，从而提升整体系统性能。同时，利用灵活的 NAPI 预算调整，能够更好地平衡中断延迟与数据包吞吐量，这对保障数据通讯的高效性至关重要。在实际应用中，建议进行充分的测试和调优，以确定最适合 Rockchip 平台的 CAN 驱动配置。 如何在 Rockchip 平台上配置 NAPI 来优化 CAN 驱动性能在 Rockchip 平台上配置 NAPI（New API）来优化 CAN 驱动性能，是为了提高数据处理效率和降低中断开销。通过以下详细步骤，可以有效地实施这一配置。 1. 在驱动结构体中添加 NAPI 结构首先，需要在的驱动结构体中增加 NAPI 结构体，以便为 NAPI 提供所需的状态和上下文信息。 struct rockchip_can // 其他成员，如设备状态、配置参数等 struct napi_struct napi;; 例子：* 假设其他成员包括接收缓冲区指针和发送缓冲区指针，通过 NAPI，可以高效地处理接收和发送数据包。 2. 在驱动初始化函数中注册 NAPI接下来，在驱动的初始化函数中进行 NAPI 的注册。这样可以将的 NAPI 处理逻辑与网络设备联系起来。 static int rockchip_can_probe(struct platform_device *pdev) // 其他初始化代码 struct net_device *ndev = platform_get_drvdata(pdev); struct rockchip_can *priv = netdev_priv(ndev); netif_napi_add(ndev, priv-napi, rockchip_can_poll, NAPI_POLL_WEIGHT); // NAPI_POLL_WEIGHT 可以设置为 16 或 32 作为初始值 注：NAPI_POLL_WEIGHT 定义了处理轮询的权重，权重越大，处理能力越强，但会增加 CPU 使用率，所以需要根据实际情况选择合适的值。 3. 修改中断处理函数的中断处理函数需要进行调整，以便禁用当前设备中断并调度 NAPI。这样可以将中断事件转化为软中断处理，降低 CPU 的中断处理负担。 static irqreturn_t rockchip_can_interrupt(int irq, void *dev_id) struct net_device *ndev = dev_id; struct rockchip_can *priv = netdev_priv(ndev); // 禁用设备中断 rockchip_can_disable_interrupts(priv); // 调度NAPI napi_schedule(priv-napi); return IRQ_HANDLED; 例子：* 通过调用 rockchip_can_disable_interrupts() 函数，可以确保在处理中断时不会调度更多中断，有助于集中处理已经接收的数据。 4. 实现 NAPI 轮询函数接着，需要实现实际的 NAPI 轮询函数。这个函数将处理接收到的数据包，并在需要的情况下重新启用中断。 static int rockchip_can_poll(struct napi_struct *napi, int budget) struct rockchip_can *priv = container_of(napi, struct rockchip_can, napi); int work_done = 0; // 处理接收的数据包 work_done = rockchip_can_rx(priv, budget); if (work_done budget) napi_complete(napi); rockchip_can_enable_interrupts(priv); return work_done; 注：* 通过比较 work_done 和 budget 的值，来判断是否需要停止轮询并重新启用中断。 5. 添加动态调整 NAPI 预算的功能为进一步提升性能，添加动态调整 NAPI 预算的能力。依赖于接收溢出计数的情况来调整 NAPI 的权重，能够在高负载情况下优化性能。 static void rockchip_can_adjust_napi_budget(struct rockchip_can *priv) if (priv-rx_overflow_count THRESHOLD) priv-napi.weight = min(priv-napi.weight * 2, MAX_NAPI_WEIGHT); else if (priv-rx_overflow_count == 0) priv-napi.weight = max(priv-napi.weight / 2, MIN_NAPI_WEIGHT); 例子：* 如果设置的阈值为 100，当 rx_overflow_count 超过这个值时，NAPI 的权重会增大，以应对流量增加。 6. 在驱动的接收函数中调用动态调整函数最后，确保在接收数据包的函数中调用动态调整函数，以便自适应当前的网络负载情况。 static int rockchip_can_rx(struct rockchip_can *priv, int limit) // 接收处理逻辑 // ... rockchip_can_adjust_napi_budget(priv); return processed; 注：* 在这一过程中，不仅要处理接收到的数据包，还要实时调整 NAPI 的预算以应对变化。 通过以上配置，NAPI 机制可以有效减少中断频率，提高系统性能。动态调整 NAPI 预算的能力使得在不同负载情况下都能保持良好的性能。 在实际应用中，务必根据具体的 Rockchip 平台和 CAN 控制器的特性进行深入调试和优化。同时，进行全面的性能测试是非常重要的，这样可以找到最佳的 NAPI 配置参数，为最终用户提供稳定和高效的网络服务。 CAN 驱动在 Rockchip 平台上的性能优化方法在 Rockchip 平台上优化 CAN 驱动性能是一个多方面的工作，可以从以下几个关键领域着手： 中断处理优化 应用 NAPI 机制NAPI（New API）机制可以有效地处理中断，减少系统中的中断频率。例如，采用 NAPI 可将中断处理中断后的数据包处理转移到底半部，这样有助于降低 CPU 负担，提升系统的总体性能。 调整 NAPI 预算值在 NAPI 工作中，预算值的设置对性能有重要影响。合理地调整这个值，可以在保持低延迟的同时，增加业务吞吐量。例如，将预算值设定为较高的数字，以便在流量高峰时进行批量处理，从而减少中断的触发频率。 DMA 传输 启用 DMA 模式使用 DMA（直接内存访问）传输模式，可以让数据在外设与内存之间进行高效传送，显著减少 CPU 的干预。采用 DMA 后，CPU 可专注于其他任务，而不是每次数据传输都要介入。 优化 DMA 缓冲区设置根据应用类型，合理设置 DMA 的缓冲区大小和数量也至关重要。例如，在高频率数据传输场景中，可以增大缓冲区来适应数据流，反之，在较低频率场景中，适度减小缓冲区则有助于提高响应速度。 硬件过滤器配置 合理配置硬件过滤器合理使用 CAN 控制器的硬件过滤器，可以减少无关数据包的处理。例如，可以设置过滤规则，仅接收特定 ID 的数据包，从而避免系统处理大量无关信息，提升整体接收效率。 缓冲区优化 调整 FIFO 深度FIFO（先进先出）缓冲区的深度设置直接影响数据处理能力。在设备树配置中，用户可以设定: tx-fifo-depth = 1;rx-fifo-depth = 6; 根据具体应用需求，可以适当增加这些值。例如，在需要高数据吞吐量的场景中，将发送 FIFO 深度提高到 8 或 12 可能有利于提升性能。 时钟和波特率优化 选择合适的时钟源选择适合的时钟源和分频比非常重要，以确保 CAN 总线的波特率精准。如在某些应用中，高达 1Mbps 的波特率能够在数据传输的及时性和可靠性之间取得较好的平衡。 驱动代码优化 使用内联函数通过使用内联函数，可以显著减少函数调用开销，使性能提升更加明显。特别是在高频调用的场景下，这种方法能有效降低延迟。 优化数据结构和算法在驱动的关键路径中，改善数据结构和算法有助于提高数据处理速度。例如，通过采用更适合的哈希表结构，可以提高检索效率，减少计算开销。 内核参数调优 调整内核调度器参数适当调整内核的调度器参数，如优先级和时间片，可以优化 CAN 驱动的响应时间。例如，将 CAN 任务的优先级设置为比其他非实时任务更高，以确保数据处理的及时性。 考虑实时内核补丁引入 PREEMPT_RT 实时内核补丁能增加系统的实时性，使 CAN 驱动在数据交互时更加迅速、稳定。 硬件加速 启用硬件 CRC 校验功能如果 Rockchip 平台支持硬件 CRC 校验，可以将这一功能启用，从而减轻 CPU 的负担。硬件 CRC 校验能快速、高效地验证数据的完整性，提升通信的可靠性。 多路 CAN 优化 使用中断亲和性对于多路 CAN 接口，可以通过设置中断亲和性（IRQ affinity）将各个 CAN 控制器的中断分别分配给不同的 CPU 核心。这种方式能有效分散处理负担，提升整体系统的并行处理能力。 性能监控和调试 使用内核跟踪工具应用内核跟踪工具如 ftrace，可以帮助开发者深入分析驱动性能的瓶颈所在。通过这些工具，开发者可以识别出何时、何地发生了性能下降，从而迅速做出调整。 监控 CAN 错误计数器定期监控 CAN 错误计数器，有助于及时发现和处理通信问题。例如，若发现错误包频率急剧上升，表明可能存在硬件故障或配置问题，需及时检查。 通过以上囊括中断处理、DMA 传输、硬件配置等多方面的优化方法，用户可以显著提升 Rockchip 平台上 CAN 驱动的性能。需要注意的是，具体的优化效果可能会因不同的硬件配置和应用场景而异。因此，建议用户在真实环境中进行详细的测试和目标调优，以便获得最佳性能。","categories":["3.协议","CAN"]},{"title":"Rockchip CAN驱动及配置","path":"/2023/12/22/3-协议-CAN-Rockchip-CAN驱动及配置/","content":"设备树解析can1: can@fe580000 compatible = rockchip,canfd-1.0;\treg = 0x0 0xfe580000 0x0 0x1000;\tinterrupts = GIC_SPI 2 IRQ_TYPE_LEVEL_HIGH;\tclocks = cru CLK_CAN1, cru PCLK_CAN1;\tclock-names = baudclk, apb_pclk;\tresets = cru SRST_CAN1, cru SRST_P_CAN1;\treset-names = can, can-apb;\ttx-fifo-depth = 1;\trx-fifo-depth = 6;\tstatus = disabled;;can1 /omit-if-no-ref/\tcan1m0_pins: can1m0-pins rockchip,pins = /* can1_rxm0 */ 1 RK_PA0 3 pcfg_pull_none, /* can1_txm0 */ 1 RK_PA1 3 pcfg_pull_none;\t;\t/omit-if-no-ref/\tcan1m1_pins: can1m1-pins rockchip,pins = /* can1_rxm1 */ 4 RK_PC2 3 pcfg_pull_none, /* can1_txm1 */ 4 RK_PC3 3 pcfg_pull_none;\t;;can1 assigned-clocks = cru CLK_CAN1;\tassigned-clock-rates = 150000000;\tpinctrl-names = default;\tpinctrl-0 = can1m1_pins;\tstatus = okay;; 此设备树片段提供了 Rockchip CAN1 接口的配置信息，包括其基址、中断设置、时钟源、引脚配置和状态。在设备初始化过程中，Linux 内核将使用此设备树片段来设置和管理 CAN1 接口。 设备节点定义can1: can@fe580000 描述：这是一个名为 can1 的设备节点，标识为地址 0xfe580000。该节点负责描述 CAN1 控制器的硬件特性。这是设备树中的重要部分，因为它标识了一个特定的硬件资源。 主要属性解析 compatible 定义：compatible = rockchip,canfd-1.0; 作用：指定支持该设备节点的驱动程序。这里的字符串”rockchip,canfd-1.0”表明该设备符合 Rockchip 提供的 CAN FD 版本 1.0 的驱动要求。这有助于操作系统选择合适的驱动程序进行设备初始化和管理。 reg 定义：reg = 0x0 0xfe580000 0x0 0x1000; 作用：明确了设备寄存器的内存地址和大小。寄存器被映射至地址 0xfe580000，并占用 0x1000 字节，确保 CPU 能够与该硬件设备通信。 interrupts 定义：interrupts = GIC_SPI 2 IRQ_TYPE_LEVEL_HIGH; 作用：配置中断信息，表明该设备关联到通用中断控制器（GIC），使用 SPI（共享外设中断）编号为 2，并且中断类型为电平触发，具有高电平有效特性。这种配置确保设备能在发生重要事件时及时响应系统。 clocks 和 clock-names 定义：clocks = cru CLK_CAN1, cru PCLK_CAN1; 作用：定义此设备所需的时钟信号。CLK_CAN1 用于波特率生成（”baudclk”），而 PCLK_CAN1 是 APB（外设总线）的时钟信号。这有助于控制 CAN1 的运行频率。 resets 和 reset-names 定义：resets = cru SRST_CAN1, cru SRST_P_CAN1; 作用：指定用于复位该设备的控制线，其中 SRST_CAN1 控制 CAN1，SRST_P_CAN1 控制 APB 接口。这确保设备能够在系统启动或故障情况下复位。 tx-fifo-depth 和 rx-fifo-depth 定义：tx-fifo-depth = 1; 和 rx-fifo-depth = 6; 作用：设定发送和接收 FIFO（先进先出）缓冲区的深度。发送缓冲区深度为 1，意味着发送时最多仅可存放一个数据包；而接收缓冲区深度为 6，允许接收多达六个数据包，有助于提升数据传输效率。 status 定义：status = disabled; 作用：初始状态设为”禁用”，指示设备在启动时不处于活跃状态，这对于系统资源的有效管理至关重要。 引脚配置can1（设备节点内部） 描述：定义此 CAN1 接口的具体引脚配置。这部分确保指定正确的引脚以供设备正常通信。 can1m0_pins 定义：can1m0_pins: can1m0-pins ...; 内容： 引脚定义： 1 RK_PA0 3 pcfg_pull_none, /* can1_rxm0 */1 RK_PA1 3 pcfg_pull_none; /* can1_txm0 */ 描述：配置了 can1_rxm0 和 can1_txm0 的引脚，分别对应 RK_PA0 和 RK_PA1，并且禁止使用上拉或下拉电阻，这种方式确保信号的准确性。 can1m1_pins 定义：can1m1_pins: can1m1-pins ...; 内容： 引脚定义： 4 RK_PC2 3 pcfg_pull_none, /* can1_rxm1 */4 RK_PC3 3 pcfg_pull_none; /* can1_txm1 */ 描述：配置了 can1_rxm1 和 can1_txm1 的引脚，分别与 RK_PC2 和 RK_PC3 关联，同样选择不启用拉电阻，以确保数据传输的稳定性。 设备节点的附加属性can1 描述：引用之前定义的 can1 设备节点，提供额外的设备配置。 assigned-clocks 定义：assigned-clocks = cru CLK_CAN1; 作用：将时钟信号 CLK_CAN1 分配予此设备节点，以确保时钟源正确配置。 assigned-clock-rates 定义：assigned-clock-rates = 150000000; 作用：指定设备的时钟速率为 150,000,000 Hz。确保 CAN1 在高速模式下运作，有助于处理高速数据流。 pinctrl-names 和 pinctrl-0 定义： pinctrl-names = default; pinctrl-0 = can1m1_pins; 作用：设置引脚控制的名称为”default”，将引脚配置引用至 can1m1_pins，确保在初始化时选用正确的引脚配置。 status 定义：status = okay; 作用：标识 CAN1 接口的状态为”正常”，表明设备已准备好投入使用。 这个设备树片段提供了详尽的配置和功能说明，为 Rockchip CAN1 接口的初始化和使用提供了必要基础，确保驱动能够正确识别和操作相关硬件设备。 驱动程序该驱动程序主要适用于 Linux 内核版本 5.10.110，代码文件位于路径 linux-5.10/drivers/net/can/rockchip/rockchip_canfd.c。该驱动程序支持通过 Controller Area Network (CAN) 进行高效的通信，尤其是在嵌入式和汽车电子领域。 注册部分在注册部分，定义了一个设备树匹配表 rockchip_canfd_of_match，这个表包含了多个与特定设备兼容的条目。以下是具体的代码示例： static const struct of_device_id rockchip_canfd_of_match[] = .compatible = rockchip,canfd-1.0, .data = (void *)ROCKCHIP_CANFD_MODE\t, .compatible = rockchip,can-2.0, .data = (void *)ROCKCHIP_CAN_MODE\t, .compatible = rockchip,rk3568-can-2.0, .data = (void *)ROCKCHIP_RK3568_CAN_MODE\t,\t, // 结束标记，表明这个数组没有更多的条目; 设备兼容性 rockchip,canfd-1.0：代表支持新一代 CAN-FD 协议，能够处理更高数据速率和更大的数据帧。 rockchip,can-2.0：代表更加传统的 CAN 2.0 协议，广泛应用于车辆和工业控制中。 rockchip,rk3568-can-2.0：代表 Rockchip RK3568 芯片的特定兼容性，适用于中高端计算平台和自动化系统。 驱动程序结构定义static struct platform_driver rockchip_canfd_driver = .driver = .name = DRV_NAME, // 标识驱动程序的名称 .pm = rockchip_canfd_dev_pm_ops, // 电源管理操作 .of_match_table = rockchip_canfd_of_match, // 设备匹配表\t,\t.probe = rockchip_canfd_probe, // 探测函数\t.remove = rockchip_canfd_remove, // 移除函数; 结构字段说明 .driver：包含与驱动程序相关的信息，包括其名称、功耗管理和兼容性检测。 .name：通过 DRV_NAME 指定驱动程序的名称。这个名字通常在其他代码中被定义。 .pm：指向电源管理相关操作函数的指针，通常用于管理设备的电源状态，例如进入低功耗模式时的操作。 .of_match_table：指向设备树匹配表的指针，用来确定哪些设备可以由该驱动程序管理。 .probe：指向实际进行设备初始化的函数 rockchip_canfd_probe。该函数将被调用以设置设备并注册它到系统中。 .remove：指向清理设备的函数 rockchip_canfd_remove，用于管理设备的卸载过程，确保资源得到适当回收。 驱动程序模块注册module_platform_driver(rockchip_canfd_driver); 这个宏的作用是将定义好的 rockchip_canfd_driver 注册到内核中。一旦这个模块被加载，内核会自动调用定义的 probe 函数来初始化相应的设备。这一过程至关重要，因为它确保驱动程序能够正确地与硬件进行交互，并为用户提供稳定的操作界面。 通过这种方式，驱动程序可以有效地与系统通信，确保设备正常运行，并利用 CAN 总线进行高效数据传输。 探测设备的过程设备的名称为 rockchip,canfd-1.0。当设备树加载时，可以找到与其相匹配的驱动程序，并进一步调用 rockchip_canfd_probe 函数。此函数的主要目的是设置并注册设备，以便 Linux 内核能够与 Rockchip CANFD 控制器进行有效的通信。 static int rockchip_canfd_probe(struct platform_device *pdev) ... IRQ 获取和内存映射 IRQ 的获取 irq = platform_get_irq(pdev, 0); 此步骤获取 Rockchip CANFD 控制器的中断号。中断是用来向 CPU 通知发生了需要处理的重要事件的信号。如果无法正确获取中断号，将会打印错误消息，返回错误代码。 资源信息和虚拟地址映射 res = platform_get_resource(pdev, IORESOURCE_MEM, 0); 通过该调用，设备获取其相关的内存资源信息，通常包括设备的物理地址范围。 addr = devm_ioremap_resource(pdev-dev, res);if (IS_ERR(addr)) return -EBUSY; devm_ioremap_resource 函数会将设备的物理地址映射到内核的虚拟地址中。如果此映射失败，就返回错误代码。 CAN 设备的内存分配ndev = alloc_candev(sizeof(struct rockchip_canfd), 1);if (!ndev) dev_err(pdev-dev, could not allocate memory for CANFD device ); return -ENOMEM; 使用 alloc_candev 函数为 CAN 设备分配内存。在这条语句中，分配了一个大小为 sizeof(struct rockchip_canfd) 的内存块，用于存储设备的信息。如果分配失败，则返回内存不足的错误。 中断处理和复位控制 中断处理函数的注册 err = devm_request_irq(pdev-dev, irq, rockchip_canfd_interrupt, 0, ndev-name, ndev); 这行代码通过 devm_request_irq 函数注册了一个中断处理函数 rockchip_canfd_interrupt 以处理相应的中断事件。如果注册失败，系统会打印错误信息，并返回错误代码。 复位控制线的获取 rcan-reset = devm_reset_control_array_get(pdev-dev, false, false);if (IS_ERR(rcan-reset)) if (PTR_ERR(rcan-reset) != -EPROBE_DEFER) dev_err(pdev-dev, failed to get canfd reset lines ); return PTR_ERR(rcan-reset); 此代码用于获取 CAN 控制器的复位线。如果获取失败，将会打印相应的错误信息并返回。 时钟信息的获取与频率的设置rcan-num_clks = devm_clk_bulk_get_all(pdev-dev, rcan-clks);if (rcan-num_clks 1) return -ENODEV; 此处从设备中获取与 CAN 控制器相关的所有时钟信息。如果获取失败，则返回一个设备无效的错误。 初始化 CAN 配置rcan-mode = (unsigned long)of_device_get_match_data(pdev-dev); 通过上面的代码，从设备树中获取了有效的匹配数据，以确定控制器的工作模式。初始化 rcan 结构体的各个字段之后，基础设备信息被存入。 根据不同的工作模式（例如 ROCKCHIP_CANFD_MODE 和 ROCKCHIP_CAN_MODE），设置不同的控制器参数，决定 CAN 控制的工作模式、数据位速率配置等。 switch (rcan-mode) case ROCKCHIP_CANFD_MODE: // 设置 FD 模式的参数 break; case ROCKCHIP_CAN_MODE: // 设置常规 CAN 模式的参数 break; default: return -EINVAL; 网络设备操作 为设备设置网络操作，例如指定的网络设备操作 ndev-netdev_ops = rockchip_canfd_netdev_ops;，并为设备进行各种网络设备相关的初始化操作。 设备注册和运行时管理设备的运行时管理被启用，随后尝试同步获取电源。注册 CAN 设备也是非常关键的一步。 err = register_candev(ndev);if (err) dev_err(pdev-dev, registering %s failed (err=%d) , DRV_NAME, err); goto err_disableclks; 这段代码执行设备注册，确保 CAN 设备能作为网络设备正常运营。如果注册失败，即使显示错误信息，也要确保设备的电源管理得到妥善处理，最终确保资源的合理释放。","categories":["3.协议","CAN"]},{"title":"FreeModbus 协议","path":"/2023/12/21/3-协议-Modbus-FreeModbus-协议/","content":"FreeMODBUS 提供了 RTUASCII 传输模式及 TCP 协议支持。FreeModbus 遵循 BSD 许可证，这意味着用户可以将 FreeModbus 应用于商业环境中。 文件结构V1.6 版本支持主机与从机在同一协议栈中并行运行。它还支持在实时操作系统和裸机环境下的移植，以及多种请求模式供用户选择，比如阻塞与非阻塞模式，用户可以自定义超时时间，这在某种程度上为应用层提供了灵活的调用方式。同时，该协议栈支持所有常用的 Modbus 方法。 以下是源文件一览及其描述： 源文件 描述 FreeModbus\\modbus\\mb.c 提供 Modbus 从机设置及轮询相关接口 FreeModbus\\modbus\\ascii\\mbascii.c ASCII 模式设置及状态机 FreeModbus\\modbus\\functions\\mbfunccoils.c 从机线圈相关功能 FreeModbus\\modbus\\functions\\mbfuncdisc.c 从机离散输入相关功能 FreeModbus\\modbus\\functions\\mbfuncholding.c 从机保持寄存器相关功能 FreeModbus\\modbus\\functions\\mbfuncinput.c 从机输入寄存器相关功能 FreeModbus\\modbus\\functions\\mbfuncother.c 其余 Modbus 功能 FreeModbus\\modbus\\functions\\mbutils.c 一些协议栈中需要的小工具 FreeModbus\\modbus\\rtu\\mbcrc.c CRC 校验功能 FreeModbus\\modbus\\rtu\\mbrtu.c 从机 RTU 模式设置及状态机 FreeModbus\\modbus\\tcp\\mbtcp.c TCP 模式设置及状态机 FreeModbus\\port\\port.c 实现硬件移植的接口 FreeModbus\\port\\portevent.c 实现从机事件的移植接口 FreeModbus\\port\\portserial.c 从机串口移植 FreeModbus\\port\\porttimer.c 从机定时器移植 FreeModbus\\port\\user_mb_app.c 定义从机数据缓冲区，包含从机 Modbus 功能的回调接口 注：所有带有 _m 后缀的文件为主机模式必需使用的文件，若使用从机模式，则无需考虑这些文件。 主机流程所有的配置参数存放在 FreeModbus\\modbus\\include\\mbconfig.h 文件中。当前协议栈支持主机和从机两种模式，并允许同时启用这两种模式。从机支持 Modbus RTU Modbus ASCII 和 Modbus TCP，而主机目前仅支持常见的 Modbus RTU 模式。在设置过程中，需要关注广播的转换延时时间 命令响应的超时时间以及从机的数量。请注意，现在协议栈只支持连续的从机地址，且从机地址的起始值为 1。 使用主机前，需将协议栈整合至项目中，包括相关软件和硬件部分。移植完成后的流程如下： 调用 eMBMasterInit 方法初始化 Modbus 主机协议栈，同时进行相关硬件的初始化。 调用 eMBMasterEnable 方法启动 Modbus 主机。 在一个独立线程或定时器中，以一定的轮询周期周期性调用 eMBMasterPoll 方法，决定命令的响应时间。 利用主机请求 API 方法并设定请求的超时时间。该方法在得到结果之前不会返回。如果方法执行成功，且为读取命令，可以通过 Modbus 主机的数据缓冲区获取更新后的从机数据。 异常处理主要在主机正常使用时出现。针对错误码，用户需结合产品特性采取相应的处理措施。建议用户实现主机请求方法的重发机制，以增大响应成功的几率。一般而言，在收到帧数据错误或命令响应超时的情况下，需要进行重发。重发次数应自增，若超过设定阈值，则标记该从机掉线，未来的所有请求将会被拦截。而若在第二次重发命令时收到有效响应，则重发次数将被重置为零。用户也可选择调用主机请求方法或 FreeModbus\\port\\portevent_m.c 中的回调接口，灵活实现功能。 从机流程FreeModbus 是基于消息队列的协议。协议通过检测相应的消息来完成对应功能。协议栈的初始化及运行流程如下： 首先，调用 eMBInit(eMBMode eMode, UCHAR ucSlaveAddress, UCHAR ucPort, ULONG ulBaudRate, eMBParity eParity) 完成物理层设备的初始化。这一过程主要包括以下几个步骤： BOOL xMBPortSerialInit(UCHAR ucPORT, ULONG ulBaudRate, UCHAR ucDataBits, eMBParity eParity)：进行串口初始化，设定波特率、数据位数及校验方式。例如，可以将波特率设置为 9600，数据位数设为 8 位，无校验位。 BOOL xMBPortTimersInit(USHORT usTim1Timerout50us)：进行定时器初始化，设定 T35 定时所需的定时器常数。 调用函数（此步骤非必需）： eMBSetSlaveID(UCHAR ucSlaveID, BOOL xIsRunning, UCHAR const *pucAdditional, USHORT usAdditionalLen)：用以指定设备 ID，确保在总线上的每个从机都有唯一标识。 接下来，调用 eMBEnable(void) 以使能协议栈，主要包括以下几个重要步骤： static pvMBFrameStart pvMBFrameStartCur（函数指针）：协议栈初始化，将 eRcvState 设为 STATE_RX_INIT 状态。 调用 void vMBPortSerialEnable(BOOL xRxEnable, BOOL xTxEnable)：这一步使能接收和发送功能。 通过 void vMBPortTimersEnable(void)：使能超时定时器以便检测数据接收状态。 一旦超时定时器被使能，经过 T35 时间后，将发生第一次超时中断。在中断过程中，向协议栈发送消息 EV_READY（Startup finished）。同时，通过调用 void vMBPortTimersDisable(void) 关闭超时定时器，并将 eRcvState 设为 STATE_RX_IDLE，此时协议栈已准备接收串口数据。 注意：之所以首先启用超时定时器，是因为在初始化完成时，串口可能已经有待接收的数据。为了避免误判第一个数据为请求的开始，协议栈设置等待 T35 时间，以便明确接收下一帧请求。 主函数调用 eMBPoll(void) 来检测事件。如果发生串口接收中断且 eRcvState 为 STATE_RX_IDLE（在第 4 步中已设定为该状态），则接收到的字符将存入接收缓存中，并将 eRcvState 状态更新为 STATE_RX_RCV，同时清零超时定时器。在随后的数据到达时，会继续将数据存入接收缓存并重置超时定时器。 如果未接收到完整数据，则不会触发超时中断。超时中断的发生指示 T35 时间内未收到新的串口数据，根据 Modbus 协议的规定，这表示一帧请求数据的接收已完成。在此中断中，协议栈接收到消息 EV_FRAME_RECEIVED（Frame received），然后等待协议栈处理此消息。 主函数随后再次调用 eMBPoll(void)，如果检测到事件 EV_FRAME_RECEIVED，将调用 static peMBFrameReceive peMBFrameReceiveCur 以简单判断请求帧数据，并向协议栈发送消息 EV_EXECUTE（Execute function）。 当主函数调用 eMBPoll(void) 进一步检测到事件 EV_EXECUTE，根据相应的请求代码查找处理该功能的函数指针并执行处理。若请求不是广播消息，则会调用 static peMBFrameSend peMBFrameSendCur 来发送回复消息。在这一函数中，仅将需回复的数据复制到串口缓存，并将 eSndState 设为 STATE_TX_XMIT（Transmitter is in transfer state）。接着，调用 void vMBPortSerialEnable(BOOL xRxEnable, BOOL xTxEnable) 使能发送中断。发送中断使能后，由于串口发送寄存器通常为空，因此使能之后将直接进入发送中断处理。 在发送中断中，如果 eSndState 为 STATE_TX_XMIT（在第 7 步中已设置为此状态），则将串口缓存中的数据发送出去，并持续统计发送字符的数量。当发送完成后，协议栈会接收到消息 EV_FRAME_SENT（Frame sent）。 主函数再次调用 eMBPoll(void) 以检测到事件 EV_FRAME_SENT 后，不对该消息进行处理。 当串口再次接收到数据后，协议栈将重复步骤 6 至 9 以处理消息。 移植协议栈移植主要包括硬件和软件两个方面。以下所有说明主要针对 Modbus 主机模式。软件方面，支持在裸机和实时操作系统中移植。该协议栈允许单个主机与单个从机独立运行。此外，用户可以根据需要修改协议栈的事件回调接口，选择阻塞或非阻塞模式，设置主机资源的等待时限等。 软件在操作系统移植过程中，需关注以下文件：FreeModbus\\port\\portevent_m.c。此文件包含需要用户移植的接口。基于操作系统的移植主要需要利用操作系统的线程同步技术，Modbus 协议栈可借助操作系统自带的事件机制实现事件的发送 通知与等待。主机请求的线程与 Modbus 协议栈线程（Modbus Poll 线程）需通过事件机制完成同步。此外，主机的资源占用需引入信号量机制，默认值为 1，信号量确保多线程同时发送请求时，只有一个线程能使用主机。 在裸机移植环境下，事件通知机制需通过软件模拟来实现，因此事件等待和资源等待都必须依赖用户自定义的延时与标志变量，其复杂程度通常高于操作系统模式下的线程同步。 RT-Thread 接口 功能描述 xMBMasterPortEventInit 主机事件初始化 xMBMasterPortEventPost 主机发送事件 xMBMasterPortEventGet 主机获取事件 vMBMasterOsResInit 主机操作系统资源初始化 xMBMasterRunResTake 主机资源获取 vMBMasterRunResRelease 主机资源释放 vMBMasterErrorCBRespondTimeout 主机响应超时回调接口 vMBMasterErrorCBReceiveData 主机接收数据错误回调接口 vMBMasterErrorCBExecuteFunction 主机执行 Modbus 方法时出错回调接口 vMBMasterCBRequestSuccess 主机请求执行成功回调接口 eMBMasterWaitRequestFinish 主机等待请求完成处理的回调接口 数据缓冲区数据缓冲区的定义位于 FreeModbus\\port\\user_mb_app_m.c 文件顶部，支持四种数据类型。默认情况下，FreeModbus 从机采用一维数组作为缓存结构，而主机则使用二维数组存储网络内所有从机的数据。二维数组的列号表示寄存器 线圈及离散量地址，行号表示从机节点 ID，但需注意：行号需减去 1。例如，usMRegHoldBuf[2][1] 代表从机 ID 为 3 保持寄存器地址为 1 的从机数据。 数据处理回调接口Modbus 协议定义了四种不同的数据类型，所有的功能操作都围绕这些数据类型进行。由于不同用户的数据缓冲区结构可能存在差异，因此每种数据类型所对应的处理方式也需根据用户特定的数据结构进行定制实现。Modbus 数据处理回调接口： 接口 功能描述 eMBMasterRegInputCB 输入寄存器回调接口 eMBMasterRegHoldingCB 保持寄存器回调接口 eMBMasterRegCoilsCB 线圈回调接口 eMBMasterRegDiscreteCB 离散输入回调接口 硬件在移植 FreeModbus 协议栈的主机部分时，需要对串口和定时器配置进行必要的修改。这些配置文件位于 port 目录下，用户必须根据自身 CPU 的特性进行相应的调整。值得注意的是，协议栈默认包含了 STM32F103X 的移植文件，用户可以将其作为参考，以便更有效地进行移植。 串口串口的移植文件为 FreeModbus\\port\\portserial_m.c，用户需要修改以下接口方法，以确保串口的正确操作和通信功能： 接口方法 功能描述 vMBMasterPortSerialEnable 使能或失能串口的发送及接收功能。例如，使用 RS-485 总线时，需要特别注意收发模式的切换，以保证数据的正确传输。 vMBMasterPortClose 此方法用于关闭串口，确保资源的释放和后续操作的稳定性。 xMBMasterPortSerialInit 进行串口初始化，包括如果使用 RS-485，总线需要在此方法中初始化收发模式切换的引脚，以保证在通信时能够正确切换。 xMBMasterPortSerialPutByte 发送单字节数据至串口，确保数据能够被另一方接收。 xMBMasterPortSerialGetByte 从串口接收单字节数据，便于协议栈接收指令或数据。 prvvUARTTxReadyISR 串口发送完成中断服务程序接口，通常通过引用默认方法 pxMBMasterFrameCBTransmitterEmpty 来处理发送完成事件。 prvvUARTRxISR 串口接收中断服务程序接口，一般直接引用 pxMBMasterFrameCBByteReceived 方法，以处理接收到的数据。 此外，在文件的末尾必须添加 CPU 自带的串口服务程序，将发送及接收中断程序接口插入到相应的中断服务程序中，以增强系统的响应能力。 定时器定时器的移植文件为 FreeModbus\\port\\porttimer_m.c，用户需要对以下接口方法进行相应的修改，确保定时器能够正确运行： 接口方法 功能描述 xMBMasterPortTimersInit 初始化定时器，将定时器的预分频数和 T3.5 时间计数值分别备份到 usPrescalerValue 和 usT35TimeOut50us 中，为后续计时操作提供基准。 vMBMasterPortTimersT35Enable 设置定时器按照 T3.5 时间开始计数，以确保时间测量的准确性。 vMBMasterPortTimersConvertDelayEnable 激活定时器以进行广播帧的转换延时时间计数，确保系统能够适应不同类型的数据传输延时。 vMBMasterPortTimersRespondTimeoutEnable 设定定时器开始计数，根据响应超时时间，防止通信过程中出现无限等待的状况。 vMBMasterPortTimersDisable 禁用定时器，终止计数，以释放资源和避免资源浪费。 prvvTIMERExpiredISR 定时器中断服务程序接口，按照默认方式，直接引用 pxMBMasterPortCBTimerExpired 方法处理定时器到期事件。 注： usPrescalerValue 和 usT35TimeOut50us 已在文件顶部进行定义，确保用户在了解文件结构的情况下进行修改。 转换延时时间和响应超时时间的配置参数可以在 FreeModbus\\modbus\\include\\mbconfig.h 文件中找到，用户应根据系统的特性进行必要的调整，以优化系统性能。 除了上述的接口方法外，用户还需要在文件的末尾增加 CPU 自带的定时器中断服务程序，并将相关接口插入到现有的中断服务程序中，以确保系统能够稳定、高效地运行。 API在使用 Modbus 协议时，主机与从机的通信模式有着显著的差异。从机以被动的方式等待主机发出的请求，而主机则积极向从机发起请求，并处理从机反馈的信息。例如，在需要控制设备时，主机向从机发送的指令将直接改变操作状态，而从机仅在指令有关的情况下返回响应。值得注意的是，当主机发送广播请求时，从机无需返回任何反馈；因此，广播请求非常适合用于写入从机数据而不适用于读取从机数据。 在主机请求 API 中的所有方法都具有相同的返回值格式。以下是主要返回值的意义： MB_MRE_NO_ERR: 操作正常，没有检测到错误。 MB_MRE_NO_REG: 寄存器 线圈或离散输入地址不正确。 MB_MRE_ILL_ARG: 输入参数格式不符合要求。 MB_MRE_REV_DATA: 接收到的数据有误。 MB_MRE_TIMEDOUT: 响应超时，主机在设定时间内未收到从机响应。 MB_MRE_MASTER_BUSY: 主机忙，在设定时间内未发送请求。 MB_MRE_EXE_FUN: 主机收到响应后，执行 Modbus 方法时发生错误。 所有主机请求方法均为线程安全并采用阻塞模式。如果在设定的超时时间内未能获得主机资源，将返回“主机忙”的状态；成功获得资源后，系统会等待请求的结果再返回。 写单个保持寄存器该接口的目的在于将数据写入指定从机的某个保持寄存器。这意味着，通过适当的参数配置，可以有效地在主设备与从设备之间进行数据传输，以满足特定的控制需求。 功能接口: eMBMasterReqErrCode eMBMasterReqWriteHoldingRegister(UCHAR ucSndAddr, USHORT usRegAddr, USHORT usRegData, LONG lTimeOut); ucSndAddr：请求的从机地址，值为 0 代表广播，表示将请求发给所有可能的从机设备。这在需要同步多个设备状态时尤为重要。 usRegAddr：目标保持寄存器的地址，每个寄存器都有一个唯一的地址，用于标识和定位。 usRegData：将要写入到保持寄存器中的数据值，该值通常来自主设备的某个传感器或控制逻辑。 lTimeOut：请求的超时时长，考虑到通信的不稳定，支持永久等待，可以通过操作系统的永久等待参数进行设置。 写多个保持寄存器此接口允许同时向多个保持寄存器写入数据，提高了数据处理效率，适用于批量更新设备状态的场景。 功能接口: eMBMasterReqErrCode eMBMasterReqWriteMultipleHoldingRegister(UCHAR ucSndAddr, USHORT usRegAddr, USHORT usNRegs, USHORT *pusDataBuffer, LONG lTimeOut); ucSndAddr：请求的从机地址，值为 0 表示采用广播的方式。 usRegAddr：第一个写入寄存器的起始地址，后续的寄存器地址将根据此地址顺序递增。 usNRegs：表明将要写入的寄存器数量，确保一次请求可以覆盖多个寄存器，优化了通信时间。 pusDataBuffer：一个指针，指向包含待写入数据的数组，这里存储了将写入各个寄存器的具体数据。 lTimeOut：请求超时时长，支持永久等待，配置为适应具体应用的需求。 读多个保持寄存器通过该接口，可以快速读取多个保持寄存器的值，特别适合需要获取多个状态信息的应用场景。 功能接口: eMBMasterReqErrCode eMBMasterReqReadHoldingRegister(UCHAR ucSndAddr, USHORT usRegAddr, USHORT usNRegs, LONG lTimeOut); ucSndAddr：请求的从机地址，0 代表广播。 usRegAddr：要求读取的第一个寄存器的地址，用于标识读取开始的位置。 usNRegs：需要读取的寄存器数量，可以根据应用需求设置不同的数量。 lTimeOut：请求超时时间，支持永久等待，确保在通信环节中不放过任何数据。 读写多个保持寄存器此接口提供了一个复合操作，首先读取指定寄存器的数据，然后再向另外的寄存器写入新数据，适合于需要先获取状态再进行控制的情况。 功能接口: eMBMasterReqErrCode eMBMasterReqReadWriteMultipleHoldingRegister(UCHAR ucSndAddr, USHORT usReadRegAddr, USHORT usNReadRegs, USHORT *pusDataBuffer, USHORT usWriteRegAddr, USHORT usNWriteRegs, LONG lTimeOut); ucSndAddr：请求的从机地址，值为 0 表示使用广播模式。 usReadRegAddr：读取操作的第一个寄存器的地址，确定读取的起始点。 usNReadRegs：需读取的寄存器数量，能够高效获取多个寄存器数据。 pusDataBuffer：指向存放读取数据的数组，便于后续操作使用。 usWriteRegAddr：写入操作的第一个寄存器的地址，接收读取后的处理结果。 usNWriteRegs：需要写入的寄存器数量，确保数据覆盖多个寄存器。 lTimeOut：请求超时时间，支持永久等待，提升稳定性。 读多个输入寄存器此接口提供从多个输入寄存器读取数据的功能，高效获取外部设备的输入信息，适合实时监测与控制系统。 功能接口: eMBMasterReqErrCode eMBMasterReqReadInputRegister(UCHAR ucSndAddr, USHORT usRegAddr, USHORT usNRegs, LONG lTimeOut); ucSndAddr：请求的从机地址，0 代表广播，确保所有设备都能够被访问。 usRegAddr：要读取的输入寄存器的起始地址，表示数据读取的起点。 usNRegs：要读取的寄存器数量，支持一次性读取多个寄存器的值。 lTimeOut：请求的超时时间，支持永久等待，以保证数据在通信中的可靠获取。 写单个线圈该接口用于向指定从机的线圈写入数据，常用于控制状态的切换，例如开启或关闭设备的某个功能。 功能接口: eMBMasterReqErrCode eMBMasterReqWriteCoil(UCHAR ucSndAddr, USHORT usCoilAddr, USHORT usCoilData, LONG lTimeOut); ucSndAddr：请求的从机地址，值为 0 可选择广播。 usCoilAddr：目标线圈的地址，每个线圈都有独特的位置标识，这是进行控制的关键。 usCoilData：写入到线圈的目标数据，通常为开（1）或关（0）的状态值。 lTimeOut：请求的超时时间，支持永久等待，确保写操作能够顺利完成。 写多个线圈此接口可向多个线圈批量写入数据，提高了状态控制的效率，适合需要同时改变多个设备参数的场合。 功能接口: eMBMasterReqErrCode eMBMasterReqWriteMultipleCoils(UCHAR ucSndAddr, USHORT usCoilAddr, USHORT usNCoils, UCHAR *pucDataBuffer, LONG lTimeOut); ucSndAddr：请求的从机地址，0 为广播。 usCoilAddr：第一个写入线圈的起始地址，便于多线圈的操作。 usNCoils：写入的线圈总数，支持同时更新多个线圈的值。 pucDataBuffer：指向待写入数据的数组，每个位代表一个线圈的状态。 lTimeOut：请求的超时时间，支持永久等待，有助于提升操作的成功率。 读多个线圈此接口的功能是读取多个线圈的状态，适用于监测设备运行情况和状态变化。 功能接口: eMBMasterReqErrCode eMBMasterReqReadCoils(UCHAR ucSndAddr, USHORT usCoilAddr, USHORT usNCoils, LONG lTimeOut); ucSndAddr：请求的从机地址，0 代表广播。 usCoilAddr：读取操作的起始线圈地址，标识从哪一处开始获取信息。 usNCoils：要求读取的线圈数量，便于一次性获取多个状态的最新数据。 lTimeOut：请求的超时时间，支持永久等待，增强阅读操作的稳定性。 读多个离散输入此接口提供方法读取多个离散输入的实时数据，适用于传感器与开关状态的监测。 功能接口: eMBMasterReqErrCode eMBMasterReqReadDiscreteInputs(UCHAR ucSndAddr, USHORT usDiscreteAddr, USHORT usNDiscreteIn, LONG lTimeOut); ucSndAddr：请求的从机地址，0 代表广播。 usDiscreteAddr：读取离散输入的起始地址，用于标识读取操作的起点。 usNDiscreteIn：需读取的离散输入数量，灵活配置以满足不同应用需求。 lTimeOut：请求超时时间，支持永久等待，优化数据读入的可靠性。","categories":["3.协议","Modbus"]},{"title":"FreeModbus 解析","path":"/2023/12/20/3-协议-Modbus-FreeModbus-解析/","content":"RTU 流程分析执行 main() 中的 eStatus = eMBInit(MB_RTU, 0x0A, 0, 9600, MB_PAR_NONE);，进入初始化过程。其中，初始化的从设备地址为 0x0A，这是 Modbus 协议支持的范围内的有效地址，也就是说可以使用 1 到 247 之间的任意地址。因为设置为 RTU 模式，所以需要为 RTU 的一些参数赋值，这些参数通过以下初始化函数配置： pvMBFrameStartCur = eMBRTUStart;pvMBFrameStopCur = eMBRTUStop;peMBFrameSendCur = eMBRTUSend;peMBFrameReceiveCur = eMBRTUReceive;pvMBFrameCloseCur = MB_PORT_HAS_CLOSE ? vMBPortClose : NULL;pxMBFrameCBByteReceived = xMBRTUReceiveFSM;pxMBFrameCBTransmitterEmpty = xMBRTUTransmitFSM;pxMBPortCBTimerExpired = xMBRTUTimerT35Expired; 这些配置中，特别重要的是 xMBRTUReceiveFSM 和 xMBRTUTransmitFSM 这两个函数，它们定义了 Modbus 状态机的接收和发送状态。以下是接收状态机的图示： xMBRTUReceiveFSM 实现了 Modbus 接收状态机的转变逻辑，状态流程可以如下描述： 上电启动或复位：设备进入 STATE_RX_INIT 状态。在这个阶段，为了避免协议栈在初始化阶段接收到无效的串口数据，设备需要等待一个定时期，时长为 T35。若 T35 时间内无数据接收，才会进入 STATE_RX_IDLE 状态，开始接收有效数据。 进入接收状态：在 STATE_RX_IDLE 状态下，一接收到第一个字节，定时器启动并转换状态至 STATE_RX_RCV。每接收一个字节，定时器被复位，持续直到 T35 超时。如果接收到的数据格式符合要求，完整数据帧接收结束，重新进入 STATE_RX_IDLE 状态；若数据过长，系统转入 STATE_RX_ERROR 状态，等待接收完成后放弃当前帧，重新回到 STATE_RX_IDLE 状态。当然，所有状态的转换需要 BOOL xMBRTUTimerT35Expired(void) 函数的支持。 接下来是发送状态机的图示： 发送状态机 简单许多。其在 STATE_TX_IDLE 状态下，表示没有发送需求。当需要发送数据时，则进入 STATE_TX_XMIT 状态。 关于 xMBRTUTimerT35Expired 函数，若定时器的初始化设定时基为 50 微秒触发一次中断，Modbus 如何在不同波特率下判断 3.5 个字符的超时呢？在定时器中断时，调用 pxMBPortCBTimerExpired 函数。实际上，T35 超时的函数则是 xMBRTUTimerT35Expired，两者存在何种关系呢？在 eMBRTUInit 中，xMBPortTimersInit((USHORT) usTimerT35_50us) 进行了重新初始化。如果波特率大于 19200，设置固定的 1800 微秒，否则则使用 3.5 个字符的时间间隔。大波特率采用固定时间或许是为了避免因判断时间过小而误判正常的线路延迟。 运行到 eStatus = eMBEnable(); 这个步骤相对简单，执行此函数后激活协议栈、串口和定时器。 **进入 void eMBPoll();**，在这里有一个关键的检查，if (xMBPortEventGet(eEvent) == TRUE) 控制着事件处理状态机。这个事件处理实际上是关于一个事件队列的问题，事件通过 eQueuedEvent 被反馈到多个状态机和超时函数。例如，一次事件可能会通过 xMBPortEventPost(EV_FRAME_SENT); 被发送供后续调度。 确认 RTU 模式的运行流程后，可以进一步分析接收和发送的细节。 接收 Buffer 的使用及有效状态：接收数据时，状态为 STATE_RX_IDLE，此时可能表明一帧数据的传输已完成。从 mbrtu.c 中的 eMBInit 看，显然进入 STATE_RX_IDLE 状态后，接收的第一个字节会令状态变至 STATE_RX_RCV，并将剩余字节放置于 ucRTUBuf 中。接收字节的数据长度通过 usRcvBufferPos 进行管理，这一过程需要经过 T35 时间来验证是否结束接收。在 xMBRTUTimerT35Expired 函数中，状态为 STATE_RX_RCV 时触发了 xNeedPoll = xMBPortEventPost(EV_FRAME_RECEIVED);，这表明该状态会向 eMBPoll 发送一条消息以处理新接收的数据帧。 消息的提取与使用：当 eMBPoll 中的 if (xMBPortEventGet(eEvent) == TRUE) 检测到 EV_FRAME_RECEIVED 事件后，将调用 peMBFrameReceiveCur 以获取消息帧。此时调用的正是 eMBRTUReceive 方法。打开该函数，可以清楚看到它如何从 ucRTUBuf 中提取数据并赋值于从机地址 ucRcvAddress、帧内容地址 ucMBFrame 及数据长度 usLength（不包括地址位和 CRC 校验位）。 数据处理与反馈：消息取出后，接下来是在 eMBPoll 的 case EV_FRAME_RECEIVED 中，检查所接消息是否符合设定的目的地址。如果该消息不是广播且未发生异常，则进入 case EV_EXECUTE: 处理步骤，接下来通过功能码判断数据帧的目的。如果测得帧数据为协议栈支持的功能码，将调用相应的处理函数。例如，对于读取输入寄存器的请求，会调用 mb.c 中定义的 eMBFuncReadInputRegister，该函数本质上会调用 eMBRegInputCB. 结果的反馈：处理函数执行后，寄存器的值被提取，帧格式已准备好，数据发送的具体实现发生在串口发送完成的中断中。此时，prvvUARTTxReadyISR 被调用，接着是 pxMBFrameCBTransmitterEmpty，这会将发送状态机转入 STATE_TX_XMIT 并触发 xMBPortSerialPutByte 以发送数据。 RTU 源码分析eMBInitint main(void) eMBErrorCode eStatus; eStatus = eMBInit(MB_RTU, 0x0A, 0, 38400, MB_PAR_EVEN); /* Enable the Modbus Protocol Stack. */ eStatus = eMBEnable(); for(;;) (void)eMBPoll(); /* Here we simply count the number of poll cycles. */ usRegInputBuf[0]++; 首先，利用 eMBInit 函数来初始化 Modbus 协议栈，所使用的参数包括协议模式 MB_RTU、设备地址 0x0A、端口号 0、波特率 38400 和奇偶校验位 MB_PAR_EVEN。在 eMBInit 的内部，程序根据配置的模式选择适当的函数进行初始化： #if MB_RTU_ENABLED 0case MB_RTU: pvMBFrameStartCur = eMBRTUStart; pvMBFrameStopCur = eMBRTUStop; peMBFrameSendCur = eMBRTUSend; peMBFrameReceiveCur = eMBRTUReceive; pvMBFrameCloseCur = MB_PORT_HAS_CLOSE ? vMBPortClose : NULL; pxMBFrameCBByteReceived = xMBRTUReceiveFSM; pxMBFrameCBTransmitterEmpty = xMBRTUTransmitFSM; pxMBPortCBTimerExpired = xMBRTUTimerT35Expired; eStatus = eMBRTUInit(ucMBAddress, ucPort, ulBaudRate, eParity); break;#endif 在这段代码中，pvMBFrameStartCur、pvMBFrameStopCur 等变量分别指代不同的协议栈函数接口。通过这样的机制，可以为不同的通信模式赋值及初始化对应的操作函数。这种编写模式极为经典且值得借鉴。当 eMBRTUInit 成功执行后，底层的串口和定时器也将进行相应的初始化。初始化完成后，全局变量 eMBState 会被设置为 STATE_DISABLED，这标志着协议栈还未启用。 初始化参数包括从设备地址、端口号、波特率和奇偶校验位，同时还会初始化计时器以便后续的数据接收过程。 eMBEnableeMBErrorCode eMBEnable(void) eMBErrorCode eStatus = MB_ENOERR; if (eMBState == STATE_DISABLED) /* Activate the protocol stack. */ pvMBFrameStartCur(); eMBState = STATE_ENABLED; else eStatus = MB_EILLSTATE; return eStatus; 在调用 eMBEnable 函数时，该函数会首先确认协议栈的状态是否为 STATE_DISABLED。若条件满足，便会调用之前初始化的 pvMBFrameStartCur（即 eMBRTUStart）来激活协议栈。随后，全局变量 eRcvState 将被设定为 STATE_RX_INIT，串口和定时器功能也将被启用，标志着数据传输准备就绪。 eMBPoll在一个无限循环中，eMBPoll 函数会不断执行。首先，通过 xMBPortEventGet(eEvent) 来检查是否有事件发生。如果没有事件，则不进入状态机；这保证了在未接收到数据的情况下，控制流程不会被无谓的操作耗费。 当定时器到期后，收到了超时事件，这会调用 pxMBPortCBTimerExpired 函数。根据当前的接收状态 eRcvState，会触发不同的事件，例如在 STATE_RX_INIT 状态下，发送 EV_READY 事件，表明就绪状态；在 STATE_RX_RCV 状态下，发送 EV_FRAME_RECEIVED 事件，表明接收到数据帧。 switch (eRcvState) case STATE_RX_INIT: xNeedPoll = xMBPortEventPost(EV_READY); break; case STATE_RX_RCV: xNeedPoll = xMBPortEventPost(EV_FRAME_RECEIVED); break; case STATE_RX_ERROR: break; default: assert((eRcvState == STATE_RX_INIT) || (eRcvState == STATE_RX_RCV) || (eRcvState == STATE_RX_ERROR)); 此时，eMBPoll 将基于发送的事件执行相应的操作，协议栈便开始运行。 接收数据在 eMBPoll 循环中，串口中断被激活，数据接收时首先触发串口中断程序，调用接收状态机： BOOL xMBRTUReceiveFSM(void) BOOL xTaskNeedSwitch = FALSE; UCHAR ucByte; assert(eSndState == STATE_TX_IDLE); /* Always read the character. */ (void)xMBPortSerialGetByte((CHAR*)ucByte); switch (eRcvState) case STATE_RX_INIT: vMBPortTimersEnable(); break; case STATE_RX_ERROR: vMBPortTimersEnable(); break; case STATE_RX_IDLE: usRcvBufferPos = 0; ucRTUBuf[usRcvBufferPos++] = ucByte; eRcvState = STATE_RX_RCV; /* Enable t3.5 timers. */ vMBPortTimersEnable(); break; case STATE_RX_RCV: if (usRcvBufferPos MB_SER_PDU_SIZE_MAX) ucRTUBuf[usRcvBufferPos++] = ucByte; else eRcvState = STATE_RX_ERROR; vMBPortTimersEnable(); break; return xTaskNeedSwitch; 当前全局变量 eRcvState 为 STATE_RX_IDLE 时，接收状态机首先读取入队的字节。同时，启动了相应的定时器。当进入到 STATE_RX_RCV 状态后，继续接收字节，直到进入超时状态。超时发生后，协议栈将通过发送 EV_FRAME_RECEIVED 事件，告知接收状态已完成。 数据的处理数据接收之后，协议栈的 eMBRTUReceive 函数将进行 CRC 校验，并负责提取数据帧地址、长度或进行其他一致性检查。 eMBErrorCode eMBRTUReceive(UCHAR* pucRcvAddress, UCHAR** pucFrame, USHORT* pusLength) BOOL xFrameReceived = FALSE; eMBErrorCode eStatus = MB_ENOERR; ENTER_CRITICAL_SECTION(); assert(usRcvBufferPos MB_SER_PDU_SIZE_MAX); /* Length and CRC check */ if ((usRcvBufferPos = MB_SER_PDU_SIZE_MIN) (usMBCRC16((UCHAR*)ucRTUBuf, usRcvBufferPos) == 0)) *pucRcvAddress = ucRTUBuf[MB_SER_PDU_ADDR_OFF]; *pusLength = (USHORT)(usRcvBufferPos - MB_SER_PDU_PDU_OFF - MB_SER_PDU_SIZE_CRC); *pucFrame = (UCHAR*)ucRTUBuf[MB_SER_PDU_PDU_OFF]; xFrameReceived = TRUE; else eStatus = MB_EIO; EXIT_CRITICAL_SECTION(); return eStatus; 该函数会验证接收到的数据有效性，并在有效的情况下将数据转发至上层处理。当数据帧成功提取后，发送 EV_EXECUTE 事件，表示可以进行后续的处理。 在处理数据的阶段，系统会根据接收到的功能码在 xFuncHandlers 数组中查找对应的处理函数并执行。 case EV_EXECUTE: ucFunctionCode = ucMBFrame[MB_PDU_FUNC_OFF]; eException = MB_EX_ILLEGAL_FUNCTION; for (i = 0; i MB_FUNC_HANDLERS_MAX; i++) if (xFuncHandlers[i].ucFunctionCode == 0) break; else if (xFuncHandlers[i].ucFunctionCode == ucFunctionCode) eException = xFuncHandlers[i].pxHandler(ucMBFrame, usLength); break; if (ucRcvAddress != MB_ADDRESS_BROADCAST) if (eException != MB_EX_NONE) usLength = 0; ucMBFrame[usLength++] = (UCHAR)(ucFunctionCode | MB_FUNC_ERROR); ucMBFrame[usLength++] = eException; if ((eMBCurrentMode == MB_ASCII) MB_ASCII_TIMEOUT_WAIT_BEFORE_SEND_MS) vMBPortTimersDelay(MB_ASCII_TIMEOUT_WAIT_BEFORE_SEND_MS); eStatus = peMBFrameSendCur(ucMBAddress, ucMBFrame, usLength); break; 综上所述，整个流程包含了协议栈的初始化、启动、轮询、数据的接收及处理，得以形成一个完整的从机操作循环。通过有效的状态管理与事件机制，确保了数据传输的可靠与准确。 RTU 函数解析eMBInit 设置设备站号定义设备在 Modbus 网络中的唯一标识，这个站号通常用来区分不同的从设备。范围通常为 1 到 247，使得网络中的每个设备能够被明确识别。 设置函数接口准备和配置应用程序将要使用的函数接口，确保系统能够有效地与设备通信。 eMBRTUInit该函数负责初始化 RTU（Remote Terminal Unit）模式下的 Modbus 协议通信。 xMBPortSerialInit初始化串口设置，以确保能够通过串行接口进行数据传输。 设置打开串口的名称指定用于与设备通信的串口，例如 “COM3”。 serialInit包含一系列打开串口和配置其属性的步骤。 打开串口通过系统调用激活指定的串口，准备开始数据传输。 设置串口属性配置串口的基本通信参数，包括： 波特率：例如 9600 或 19200（单位：bits），决定数据传输的速度。 数据位：通常设置为 8 位，这是传输数据的基本单位。 奇偶校验位：设置为无、奇或偶，以便于错误检测。 计算计时器计时时间确定 Modbus 报文的超时时间，以确保及时响应。 xMBPortTimersInit初始化定时器以处理时间事件。 TimersInit配置定时器以单次触发模式，单位设为毫秒（ms），以便实时监控 Modbus 事件。 设置为 RTU 模式将通信模式配置为 RTU，以便按照 Modbus RTU 协议格式进行消息传输。 eMBState STATE_DISABLED将当前状态设为禁用，以便后续操作准备就绪。 eMBEnable pvMBFrameStartCur（函数指针指向 eMBRTUStart）开启 Modbus 通信帧并进入接收模式。 eRcvState STATE_RX_INIT设置接收状态为初始化，以检测接收的 Modbus 帧。 vMBPortSerialEnable( TRUE, FALSE );修改串口状态为接收模式，准备接收数据，同时禁用发送模式。 vMBPortTimersEnable启动超时计时器，开始监控接收状态。 定时器中断事件（判断 eRcvState）定义不同接收到状态时的行为。 STATE_RX_INIT将事件标志设置为 EV_READY，表示准备接收数据。 STATE_RX_RCV将事件标志设置为 EV_FRAME_RECEIVED，表示接收到完整的 Modbus 帧。 STATE_RX_ERROR或者处理接收过程中发生的错误情况。 执行完中断事件，定时器关闭中断处理完后，如无新的接收事件，则停止定时器。 eRcvState STATE_RX_IDLE设置接收状态为空闲，等待下一个帧的到来。 eMBState STATE_ENABLED状态更新为启用，表示设备已准备好接收和发送 Modbus 消息。 eMBPollxMBPortEventGet（判断事件）监控和处理事件，确定下一步操作。 EV_READY当设备准备好接收数据时触发相关事件。 EV_FRAME_RECEIVED当完整的 Modbus 帧被接收时触发。 peMBFrameReceiveCur（函数指针指向 eMBRTUReceive）开始处理接收到的帧。 校验数据长度和 CRC确认数据的完整性和有效性，防止因数据损坏而导致的错误响应。 保存设备站号存储来自 Modbus 帧中的设备站号，以便后续参考。 保存待校验数据首地址和长度记录数据的起始位置和长度，以便进行进一步的处理和操作。 检查设备站号是否相同确认接收的站号是否与预期的站号一致，以保证数据的正确性。 xMBPortEventPost将事件队列中的事件设为 EV_EXECUTE，准备执行相应操作。 EV_EXECUTE一旦接收到事件，执行相关操作并返回处理结果。 EV_FRAME_SENT标志表示数据帧已成功发送，确认数据传输的完成。","categories":["3.协议","Modbus"]},{"title":"libmodbus 手册","path":"/2023/12/19/3-协议-Modbus-libmodbus-手册/","content":"#include modbus.hcc files `pkg-config --cflags --libs libmodbus` DESCRIPTIONlibmodbus 是一个用于通过遵循 Modbus 协议的设备进行数据传输和接收的库。该库支持多种后端实现，能够通过不同的网络进行通信，例如采用串行通信的 RTU 模式或通过 Ethernet 的 TCPIPv6。有关 Modbus 协议的详细文档可访问 Modbus 官方网站。 libmodbus 为底层通信层提供了抽象，并在所有受支持的平台上提供统一的 API。 这份文档概述了 libmodbus 的基本概念，说明了该库如何在不同的硬件和平台间抽象 Modbus 通信，并提供了作为 libmodbus 库参考的函数手册。 ContextsModbus 协议包含多种变体（例如，串行 RTU 或 Ethernet TCP），为方便实现特定变体，本库设计了针对每种变体的后端。后端还可以灵活满足其他需求（例如实时操作）。每个后端都提供了用于创建新的 modbus_t 上下文的特定函数。modbus_t 上下文是一个不透明结构，包含与其他 Modbus 设备建立连接所需的所有信息，具体取决于所选变体。 RTU ContextRTU 后端（远程终端单元）用于串行通信，采用紧凑的二进制数据表示方式进行协议通信。RTU 格式在命令数据后附加一个循环冗余校验（CRC）作为错误检查机制，以确保数据的可靠性。Modbus RTU 是 Modbus 最普遍的实现方式。根据维基百科的信息，Modbus RTU 消息必须连续发送，不能在字符间停顿。 RTU 帧定义了从属设备（slave）和主设备（master）的角色，其中从属设备处理 Modbus 请求，而主设备发送请求。通信总是由主设备发起。 多个 Modbus 设备可以连接在同一物理链路上，因此在发送消息之前，必须使用 modbus_set_slave(3) 设置从属设备（接收方）。若运行的是从属设备，则其从属编号将用于过滤接收到的消息。 libmodbus 实现的 RTU 不基于时间，如原始 Modbus 规范中所述，而是尽可能快地发送所有字节。当所有预期的字符都被接收时，则响应视为完成。这种实现提供了非常快速的通信，但需要注意从设备的响应超时必须设置为小于主设备的响应超时（否则，当某个从设备不响应时，其他从设备可能会忽略主设备的请求）。 Create a Modbus RTU context modbus_new_rtu(3) Set the serial mode 获取串行模式: modbus_rtu_get_serial_mode(3) 设置串行模式: modbus_rtu_set_serial_mode(3) 获取 RTS: modbus_rtu_get_rts(3) 设置 RTS: modbus_rtu_set_rts(3) 设置自定义 RTS: modbus_rtu_set_custom_rts(3) 获取 RTS 延迟: modbus_rtu_get_rts_delay(3) 设置 RTS 延迟: modbus_rtu_set_rts_delay(3) TCP (IPv4) ContextTCP 后端实现了用于 TCPIPv4 网络通信的 Modbus 变体。由于底层处理了校验和的计算，因此不需要在应用层进行此操作。 Create a Modbus TCP context modbus_new_tcp(3) TCP PI (IPv4 and IPv6) ContextTCP PI（协议无关）后端实现了用于 TCP IPv4 和 IPv6 网络通信的 Modbus 变体。同样，底层处理了校验和的计算，因此此变体也不需要进行此操作。 与仅支持 TCP IPv4 的后端不同，TCP PI 后端提供了主机名解析，但额外消耗约 1KB 的内存。 Create a Modbus TCP context modbus_new_tcp_pi(3) Common在使用任何 libmodbus 函数之前，调用者必须使用上述函数分配并初始化 modbus_t 上下文，然后以下函数用于修改和释放该上下文： 释放 libmodbus 上下文: modbus_free(3) 设置从属 ID: modbus_set_slave(3) 启用调试模式: modbus_set_debug(3) Timeout settings 获取字节超时: modbus_get_byte_timeout(3) 设置字节超时: modbus_set_byte_timeout(3) 获取响应超时: modbus_get_response_timeout(3) 设置响应超时: modbus_set_response_timeout(3) Error recovery mode 设置错误恢复: modbus_set_error_recovery(3) Settergetter of internal socket 设置套接字: modbus_set_socket(3) 获取套接字: modbus_get_socket(3) Information about header 获取头长度: modbus_get_header_length(3) Macros for data manipulation MODBUS_GET_HIGH_BYTE(data) - 从字节中提取高字节 MODBUS_GET_LOW_BYTE(data) - 从字节中提取低字节 MODBUS_GET_INT64_FROM_INT16(tab_int16, index) - 从 tab_int16 中起始于 index 的四个 int16 构建一个 int64 MODBUS_GET_INT32_FROM_INT16(tab_int16, index) - 从 tab_int16 中起始于 index 的两个 int16 构建一个 int32 MODBUS_GET_INT16_FROM_INT8(tab_int8, index) - 从 tab_int8 中起始于 index 的两个 int8 构建一个 int16 MODBUS_SET_INT16_TO_INT8(tab_int8, index, value) - 将 int16 值设置到 tab_int8[index] 开始的两个字节 MODBUS_SET_INT32_TO_INT16(tab_int16, index, value) - 将 int32 值设置到 tab_int16[index] 开始的两个 int16 MODBUS_SET_INT64_TO_INT16(tab_int16, index, value) - 将 int64 值设置到 tab_int16[index] 开始的四个 int16 Handling of bits and bytes modbus_set_bits_from_byte(3) modbus_set_bits_from_bytes(3) modbus_get_byte_from_bits(3) Set or get float numbers modbus_get_float_abcd(3) modbus_set_float_abcd(3) modbus_get_float_badc(3) modbus_set_float_badc(3) modbus_get_float_cdab(3) modbus_set_float_cdab(3) modbus_get_float_dcba(3) modbus_set_float_dcba(3) modbus_get_float(3) (已弃用) modbus_set_float(3) (已弃用) Connection提供了一些函数用于与 Modbus 设备建立和关闭连接： 建立连接: modbus_connect(3) 关闭连接: modbus_close(3) 刷新连接: modbus_flush(3) ClientModbus 协议定义了不同的数据类型以及从远程设备读取和写入它们的函数。客户端使用以下函数发送 Modbus 请求： Read data modbus_read_bits(3) modbus_read_input_bits(3) modbus_read_registers(3) modbus_read_input_registers(3) modbus_report_slave_id(3) Write data modbus_write_bit(3) modbus_write_register(3) modbus_write_bits(3) modbus_write_registers(3) Write and read data modbus_write_and_read_registers(3) Raw requests modbus_send_raw_request(3) modbus_receive_confirmation(3) Reply an exception modbus_reply_exception(3) Server服务器等待客户端请求，并在涉及请求时给予回应。libmodbus 提供以下函数以处理请求： Data mapping modbus_mapping_new(3) modbus_mapping_free(3) Receive modbus_receive(3) Reply modbus_reply(3) modbus_reply_exception(3) ERROR HANDLINGlibmodbus 函数使用与 POSIX 系统中常见的标准约定来处理错误。通常，这意味着在发生失败时，libmodbus 函数将返回 NULL 值（如果是指针）或负值（如果是整数），实际错误代码将存储在 errno 变量中。 提供了 modbus_strerror() 函数，用于将 libmodbus 特定的错误代码转换为错误消息字符串；有关详细信息，请参考 modbus_strerror(3)。 MISCELLANEOUSLIBMODBUS_VERSION_STRING 常量指示程序编译时与哪个 libmodbus 版本相关联。变量 libmodbus_version_major、libmodbus_version_minor 和 libmodbus_version_micro 给出了程序链接的版本信息。","tags":["clippings"],"categories":["3.协议","Modbus"]},{"title":"libmodbus编译","path":"/2023/12/18/3-协议-Modbus-libmodbus编译/","content":"访问 GitHub 页面 libmodbus，点击绿色的“Code”按钮，然后选择“Download ZIP”进行下载。解压后即可获得源代码。 交叉编译在进行交叉编译时，建议添 加 --prefix 参数，以便将相关库集中管理，便于之后将其复制到开发板的相应目录中。因此，正确的配置命令应如下所示： ./configure --build=i686 --host=arm-none-linux-gnueabi --enable-static --prefix=/root/libmodbus-3.1.1/install/ make install 在 PC 上编译和安装的命令相对简单： ./configure make install 在开发板上运行诸如 unit-test-xxx 的程序时，必须首先确认网络和串口设置。如果需要测 试 TCP 连接，需要修改源代码中 的 IP 地址，因为默认设置的是回环地址。对于想要测 试 RTU 的情况，则需要将串口设备文件名修改为相应的名称。一般情况下，嵌入式开发板使用的设备文件 是 /dev/ttySx，具体是哪一个则依赖于开发板的配置。同时，在个人电脑上，串口通常 是 /dev/ttyUSB0。对于运行在虚拟机上的情况，确保串口设置是在虚拟机側而非本地主机上。 修改示例 在 unit-test-server.c 文件中的相应代码块： if (use_backend == TCP) ctx = modbus_new_tcp(192.168.169.209, 1502); query = malloc(MODBUS_TCP_MAX_ADU_LENGTH); else if (use_backend == TCP_PI) ctx = modbus_new_tcp_pi(::0, 1502); query = malloc(MODBUS_TCP_MAX_ADU_LENGTH); else ctx = modbus_new_rtu(/dev/ttyS1, 115200, N, 8, 1); modbus_set_slave(ctx, SERVER_ID); query = malloc(MODBUS_RTU_MAX_ADU_LENGTH); 在 unit-test-client.c 文件中的代码块： if (use_backend == TCP) ctx = modbus_new_tcp(192.168.169.209, 1502); else if (use_backend == TCP_PI) ctx = modbus_new_tcp_pi(::1, 1502); else ctx = modbus_new_rtu(/dev/ttyUSB0, 115200, N, 8, 1); 测试 在 test 目录 下，类 似 unit-test-server 的文件实际上不是可执行文件，而是一个脚本，它会调用同一目录 下 .lib/ 目录中的可执行文件。 在 P C 上，需要执行相应的脚本文件，而在嵌入式平台上，则需要直接运行对应的可执行文件。这一点对于正确执行测试程序至关重要，应确保在迁移或部署时注意文件类型和执行方式的相应差异。 Win 平台利用 Qt 编译准备源文件 进入 src 目录，选择所有 .cpp 和 .h 文件，包括 win32 文件夹中的 config.h。将这些文件复制到项目中的 modbus 文件夹中。 在 Qt 客户端中添加文件 打开 Qt Creator，选择项目，在左侧的项目文件管理器中右键点击项目名称，选择“添加现有文件”，找到先前复制的所有 .cpp 和 .h 文件并添加到工程中。 配置项目文件 在项目文件（.pro 文件）中，添加 LIBS += -lws2_32。此链接指令用于链接 Windows Socket 库，确保网络功能正常。 执行构建 执行构建操作并在代码中包含 #include config.h。这将确保配置文件被正确引用。 注意：在构建过程中，可能会遇到以下错误消息：error: undefined reference to qMain。此错误表明编译的工程缺少程序的 main 函数，这个函数 是 C++程序执行的起点。需要确认存在包含 main 函数的源代码文件。 常用 API 释放上下文 使用 modbus_free (); 来 释放之前分配的 Modbus 上下文，避免内存泄漏。 设置从设 备 ID 使用 modbus_set _slave (); 来设置当前 Modbus 从设备的 ID。 启动调试模式 使用 modbus_set_debug(); 启用调试信息，有助于排查问题。 超时设置 modbus_get_byte_timeout(); modbus_set_byte_timeout(); modbus_get_response_timeout(); modbus_set_response_timeout(); modbus_get_indication_timeout(); modbus_set_indication_timeout(); 错误恢复模式 使用 modbus_set_error_recovery();，可设置错误发生时的恢复策略。 设置或获取内 部 socket 使用 modbu s_set_socket(); 设置使用的 socket，和 modbu s_get_ socket(); 获取当前的 socket 信息。 获取头部信息长度 使用 modbus_get_head er_len gth(); 获取 Modbus 消息头的长度。 数据操作宏 MODBUS_GET_HIGH_BYTE(data); // 获取数据的高字节MODBUS_GET_LOW_BYTE(data); // 获取数据的低字节MODBUS_GET_INT64_FROM_INT16(tab_int16, index); // 从tab_int16[index]起始的四个int16构建一个int64MODBUS_GET_INT32_FROM_INT16(tab_int16, index); // 从tab_int16[index]起始的两个int16构建一个int32MODBUS_GET_INT16_FROM_INT8(tab_int8, index); // 从tab_int8[index]起始的两个int8构建一个int16MODBUS_SET_INT16_TO_INT8(tab_int8, index, value); // 将一个int16值设置到tab_int8[index]起始的两个字节MODBUS_SET_INT32_TO_INT16(tab_int16, index, value); // 将一个int32值设置到tab_int16[index]起始的两个int16MODBUS_SET_INT64_TO_INT16(tab_int16, index, value); // 将一个int64值设置到tab_int16[index]起始的四个int16 处 理 bit s 和 bytes 使用 modbus_set_bits_from_byte(); 使用 modbus_set_bits_from_bytes(); 使用 modbus_get_byte_from_bits(); 设置或获取浮点数 使用以下函数设置或获取浮点数： modbus_get_float_abcd(); modbus_set_float_abcd(); modbus_get_float_badc(); modbus_set_float_badc(); modbus_get_float_cdab(); modbus_set_float_cdab(); modbus_get_float_dcba(); modbus_set_float_dcba(); 连接管理 建立连接：使用 modbus_connect(); 关闭连接：使用 modbus_close(); 刷新连接：使用 modbus_flush(); *客户端操作 * Modbus 协议定义了不同的数据类型和函数，客户端可 以使用以下函 数向远程设备发送 Modbus 请求： 读数据： modbus_read_bits(); modbus_read_input_bits(); modbus_read_registers(); modbus_read_input_registers(); modbus_report_slave_id(); 写数据： modbus_write_bit(); modbus_write_registers(); modbus_write_bits(); modbus_write_registers(); 读写数据： mo dbus_write_and_read_registers(); Raw 请求： modbus_send_raw_request(); modbus_receive_confirmation(); 响应异常： modbus_reply_exception(); 服务器操作 服务器等待客户端请求，并在需要时给予响应。 启动监听： modbus_tcp_listen(); modbus_tcp_accept(); modbus_tcp_pi_listen(); modbus_tcp_pi_accept(); 接收请求：使用 modbus_receive(); 发送响应： modbus_reply(); modbus_reply_exception(); 错误处理 使用 modbus_strerror(); 可以获取错误信息的字符串描述。 RTU 上下文操作 使用 modbu s_n ew_rtu(); 创建一个 RTU 上下文 设置串口模式及属性： modbus_rtu_get_serial_mode(); modbus_rtu_set_serial_mode(); modbus_rtu_get_rts(); modbus_rtu_set_rts(); modbus_rtu_set_custom_rts(); modbus_rtu_get_rts_delay(); modbus_rtu_set_rts_delay(); TCP ( IPv4) 上下文 创建 TCP 上下文：使用 modbus_new_tcp(); TCP PI ( IPv4 和 IPv6) 上下文 创建 TCP PI 上下文：使用 modbus_new_tcp_pi();","categories":["3.协议","Modbus"]},{"title":"Modbus","path":"/2023/12/15/3-协议-Modbus-Modbus/","content":"Modbus 是一种广泛使用的通信协议，旨在连接电子设备并在它们之间传输数据。这个协议于 1979 年由 Modicon 开发，现已成为施耐德电气（Schneider Electric）的一部分。Modbus 已成为工业环境中的标准协议，特别是为监控控制和数据采集（SCADA）系统而设计。它有效地实现了自动化系统与各种连接设备之间的通信，这些设备包括传感器、执行器和控制器。 主要特点 开放且简单：作为一种开放标准，Modbus 的实现相对简单，显著促进了其在工业自动化设置中的普及。这种易于实施的性质鼓励开发者和组织将 Modbus 整合到其系统中，无需进行复杂的定制。 设备互操作性：Modbus 的一大优势在于它能够实现不同制造商设备之间的通信。这种特性支持多样化的设备，增强了工业自动化项目的灵活性和可扩展性。 实时通信：Modbus 旨在处理需要及时且确定性通信的应用。这一特性在延迟会影响操作安全或效率的场景下至关重要，例如制造过程或监控系统中。 低开销：Modbus 的通信过程对带宽和处理能力的需求较低。这种高效性使得 Modbus 可以集成到低能耗环境和具有成本效益、维护成本低的系统中，从而使其在小型操作和大型复杂安装中同样适用。 通信模式 Modbus TCP: 适用于现代化工业控制系统，特别是需要远程通信、大量设备、或者高速传输的场景。 易于集成到现有的以太网网络中。 Modbus ASCII: 用于小型系统或需要调试的场景。 适合低速通信且对带宽要求不高的环境。 Modbus RTU: 最常用的模式，适合资源受限、可靠性要求高的嵌入式系统和中小型工业系统。 Modbus Plus: 适用于大型分布式工业控制系统，需要多主站通信、高速传输和可靠性的场景。 需要专用硬件支持，通常仅在 Schneider Electric 系统中见到。 Modbus RTUModbus RTU 是最常用的 Modbus 模式，基于串口通信，使用二进制编码数据。 通信方式: 基于串行接口（如 RS-232 或 RS-485）。 数据编码: 数据以紧凑的二进制格式传输，通信效率高。 数据校验: 使用循环冗余校验 (CRC) 提高数据可靠性。 效率较高: 帧的开销比 ASCII 少，适合资源受限的系统。 应用场景: 小型和中型工业系统，如传感器、执行器和 PLC 通信。 | Address (1 byte) | Function Code (1 byte) | Data (n bytes) | CRC (2 bytes) | 地址: 标识设备，范围为 1-247。 功能码: 定义操作类型（如读写寄存器）。 数据: 包含具体操作的数据。 CRC 校验: 检测通信错误。 Modbus ASCIIModbus ASCII 是一种基于串口通信的 Modbus 协议，使用 ASCII 编码传输数据。 通信方式: 基于串行接口（如 RS-232 或 RS-485）。 数据编码: 数据以 ASCII 格式（每字节转化为两个可打印字符）进行传输。 调试容易: 因为数据是可读的 ASCII 字符，易于人工调试和诊断。 效率较低: ASCII 编码比 RTU 模式多占用传输带宽。 应用场景: 小型系统或需要简单调试的环境。 | Start (:) | Address (2 chars) | Function Code (2 chars) | Data (n chars) | LRC (2 chars) | End (CRLF) | 起始符 : 数据帧中每个字节用 2 个 ASCII 字符表示。 使用纵向冗余校验 (LRC) 检测数据错误。 Modbus TCPModbus TCP 是基于以太网的 Modbus 协议，使用 TCPIP 协议栈进行数据传输。 通信方式: 使用以太网传输数据，数据通过 TCPIP 网络进行传输。 数据帧格式: 不使用校验码 (如 CRC)，而是依赖 TCPIP 协议的内置校验机制。 速度: 高速传输，适合大规模系统和现代工业环境。 寻址: 使用 IP 地址来标识设备，不依赖传统的 Modbus 地址范围（1-247）。 应用场景: 大型工业自动化系统、分布式控制系统 (DCS)、SCADA 系统。 | Transaction ID (2 bytes) | Protocol ID (2 bytes) | Length (2 bytes) | Unit ID (1 byte) | Function Code (1 byte) | Data (n bytes) | Modbus PlusModbus Plus 的数据帧和其他 Modbus 协议不同，设计更加复杂，但封装了传统 Modbus 的功能码和数据结构。 通信方式: 专有的令牌环（Token Passing）网络架构，支持多主站设备。 传输介质: 使用专用的双绞线进行通信。 数据速率: 固定为 1 Mbps，比 Modbus RTU 和 Modbus ASCII 快得多。 地址范围: 支持 64 个设备，采用节点号寻址。 协议特性: 全双工通信，可同时处理多个请求和响应。 应用场景: 大型工业控制系统，特别是分布式控制系统（DCS）和多主设备的场景。 帧格式是为令牌环通信优化的，包含节点寻址、令牌管理和数据段。 对比 特性 Modbus TCP Modbus ASCII Modbus RTU Modbus Plus 通信方式 TCPIP 网络 串口（RS-232485） 串口（RS-232485） 专用双绞线 数据编码 二进制 ASCII 二进制 专用格式 效率 高 低 高 极高 校验方式 TCPIP 内置校验 LRC CRC 内置帧校验机制 拓扑结构 星型（以太网） 点对点或总线 点对点或总线 令牌环 最大设备数 基于 IP 地址 247 247 64 传输速率 取决于网络（1 Gbps 等） 低（ 115.2 kbps） 高（最大 1 Mbps） 固定 1 Mbps 支持多主设备 是 否 否 是 硬件要求 以太网卡 无需额外硬件 无需额外硬件 专用 Modbus Plus 硬件 适用场景 现代化工业控制系统 小型调试环境 小型和中型工业系统 多主站高速分布式系统 数据模型 寄存器和位： 线圈（Coils）：这些是可以读写的单比特值，通常表示设备的开关状态。 离散输入（Discrete Inputs）：类似于线圈，但这些单比特值为只读，常用于监测传感器等输入状态。 输入寄存器（Input Registers）：由 16 位值组成，通常为只读，主要用于输入设备的数据，例如温度读数。 保持寄存器（Holding Registers）：同样由 16 位值组成，可以读写，通常存储设备的配置参数或设定值。 寻址： Modbus 设备通过特定地址进行识别，RTU 和 ASCII 通信的地址范围为 1 至 247。对于 Modbus TCPIP 连接，设备使用其 IP 地址进行识别，使得在标准网络上易于访问。 功能代码功能代码指示在特定寄存器或输入上执行的操作类型： 读取线圈（0x01）：检索单比特输出的状态。 读取离散输入（0x02）：访问监测到的单比特输入状态。 读取保持寄存器（0x03）：读取存储在 16 位输出寄存器中的值，提供状态和控制信息。 读取输入寄存器（0x04）：从 16 位输入寄存器获取值，这些寄存器提供来自传感器的数据。 写入单个线圈（0x05）：命令单个输出比特更改其状态，以便实现即时控制操作。 写入单个寄存器（0x06）：在 16 位输出寄存器中设置特定值，用于控制应用。 写入多个线圈（0x0F）：在一次操作中更改多个输出比特的状态，提高了对多个设备控制的效率。 写入多个寄存器（0x10）：在一次操作中更新多个 16 位寄存器，从而简化通信和处理。 数据位计算机处理的语言是”0”和”1”组合而成的信息，即机器语言 01000001 ，01000010 ，01000011 ，01000100 ，01000101，01000110 A B C D E F 上面一组机器码分别代表的字符是 A，B，C，D，E，F；如 A: 是用 01000001 表示，共八个”0”或”1”，即数据位为八位. 数据位的含义：是一个字符可以用多少个位的组合来表示；设置数据位后，们就知道了数据长度，然后可以根据波特率(9600)计算出传输一个字符 A 需要多少时间。 停止位知道一个字符何时传输结束。目前常用的停止位是一位与二位。 停止位是一个高电平(1)，当接收方接收到连续的高电平时，表示一个字符传输结束。 起始位是一个低电平(0),当接收方接收连续的低电平时，表示下一个字符的传输开始。 如果停止位可靠(1 位或是 2 位)，那么干扰造成低电平起始位假象的可能性就不大，所以不用设置起始位。 校验方式在传输的数据中再加上一个校验位防止干扰。目前所用的校验方式为： 偶校验(even):简单表示为”e” ，保证总的 1 的个数是偶数； 如果一个字符中”1”的个数是奇数那么校验位就置为”1”； 如果一个字符中”1”的个数是偶数，那么校验位就置为 0； 奇校验(odd):简单表示为”o” ，保证总的”1”的个数是奇数； 如果一个字符中”1”的个数是偶数，那么校验位就置为 1； 如果一个字符中”1”的个数是奇数，那么校验位就置为 0； 无校验(none):简单表示为”n” ，没有校验位； 奇偶校验方式不可能完全校验一个字符发送是否正确。当只是”1”的位置改变了，”1”的个数还是奇数，虽然发送的是 A，接收到的是 B，但是奇校验还认为是正确的字符； 为了解决奇偶校验方式的上述缺陷，每种标准协议都会要求校验和计算，比如 MODBUS 通讯协议的 RTU 方式是 CRC 校验计算；MODBUS 通讯协议的 ASCII 方式是 LRC 校验计算； 奇偶校验：判断一个字符传输的是否正确； 校验和： 判断一组字符传输的是否正确； 终端电阻光从空气进入水面时，水面从反射回一些光线，这是因为空气与水的媒质不同。光进入不同的媒质时，会在临界点反射。 电信号传输也一样，在传输过程中如果传输末端阻抗突然减小甚至没有，信号就会在此产生反射，这种反射会造成传输线路数据混乱，所以加一个偏置电阻，人为地保持阻抗平衡，减弱信号反射对线路的影响 Modbus 开发和调试工具 Modbus Poll：一个实用工具，可以模拟 Modbus 主设备，允许用户发送请求并观察响应，以进行测试和验证。 Modbus Slave：模拟从设备，提供一个受控环境来测试主从之间的交互。 Wireshark：必备的网络协议分析工具，捕获和分析 Modbus TCP 数据包，对于故障排除和性能监测非常有价值。 libmodbus：广泛使用的 C 库，简化了在自定义应用中实施 Modbus 协议，促进了开发并提供了强大支持。","categories":["3.协议","Modbus"]},{"title":"MQTT","path":"/2023/12/14/3-协议-MQTT-MQTT/","content":"协议内容 MQTT（消息队列遥测传输协议，Message Queuing Telemetry Transport）MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议）是一种基于客户端与服务器的消息发布订阅模式的“轻量级”通讯协议，构建于 TCPIP 协议基础之上。MQTT 协议特别针对低带宽和不可靠网络环境下的远程传感器与控制设备的通信设计，具有以下主要特性： 发布订阅消息模式：这种模式允许一对多的消息发布，显著减少了应用程序之间的耦合，使得系统设计更加灵活。 负载内容屏蔽：消息传输过程中，MQTT 可以对负载内容进行处理，确保信息的有效性与安全性。 TCPIP 网络连接：协议默认使用 TCPIP 提供稳定的网络连接，确保数据在传输过程中的完整性与可靠性。 消息服务质量（QoS）：MQTT 提供三种不同级别的质量服务，以满足不同应用场景的需求。 小型传输和低开销：MQTT 消息头的大小固定为 2 字节，这使得协议具有最小化协议交换的能力，从而降低网络流量的消耗。 Last Will 和 Testament 特性：此特性允许客户端在异常断开连接时，向其他订阅者发送一条最后的消息，这在许多关键应用场景中极具价值，例如物联网设备的实时状态监控。 协议原理在实现 MQTT 协议时，客户端与服务器之间的通信涉及三种身份角色：发布者（Publisher）、代理（Broker，即服务器）和订阅者（Subscriber）。以下是关于每种角色的简要说明： 发布者：负责发送消息，并可以同时充当订阅者。 代理：作为消息的中介，接受来自发布者的信息并转发给相应的订阅者。 订阅者：接收来自主题的消息，订阅相关主题后将自动获取消息内容。 MQTT 消息的结构由主题（Topic）和负载（Payload）组成： Topic：理解为消息的类型。订阅者订阅特定的主题后，将会接收到与该主题相关的所有消息内容。 Payload：收到的具体消息内容，订阅者在处理信息时所使用的实际内容。 MQTT 协议建立了客户端到服务器的连接，确保有序、无损的、基于字节流的双向传输。当应用数据通过 MQTT 网络发送时，服务质量（QoS）与主题名（Topic）直接相关联。 服务器与客户端服务器（Broker）MQTT 服务器，即“消息代理”，可以是一个独立的应用程序或一台设备。它位于发布者与订阅者之间，执行以下功能： 接收来自客户端的网络连接请求。 处理客户端发布的应用信息，确保其能够被有效转发。 处理订阅与退订请求，维护客户端的订阅状态。 将应用程序的消息广播给订阅的客户端，确保信息传递的及时性与准确性。 客户端通过 MQTT 协议进行通信的应用程序或设备，始终与服务器保持网络连接。客户端可以执行以下操作： 发布其他客户端可能会订阅的信息。 订阅其他客户端发布的消息，获取实时数据。 退订或删除之前的订阅消息，保持信息流的有效性。 断开与服务器的连接，结束通信会话。 实现细节订阅（Subscription）在订阅过程中，客户端需要提供主题筛选器（Topic Filter）和最大服务质量（QoS），这将与客户端的会话（Session）关联。会话可以包括多个订阅，每一个订阅都具有不同的主题筛选器。 会话（Session）每个客户端在与服务器连接后创建一个会话，客户端与服务器之间会进行状态交互。这样的会话能够跨越多个网络连接，保持状态一致性。 主题名（Topic Name）主题名是连接到特定应用程序消息的标签，服务器根据订阅的主题匹配，将消息发送给所有关联的客户端。 主题筛选器（Topic Filter）主题筛选器使用通配符进行筛选，允许订阅者通过更灵活的表达式匹配多个主题。 负载（Payload）负载是关键的消息体，包含了下列类型的消息： CONNECT（连接）：消息体内容包括客户端的 ClientID、订阅的 Topic、消息内容及用户名和密码等信息。 SUBSCRIBE（订阅）：消息体列举出一系列要订阅的主题及其对应的 QoS。 SUBACK（订阅回执）：消息体用于确认服务器对 SUBSCRIBE 申请的主题及 QoS 的回复。 UNSUBSCRIBE（取消订阅）：消息体说明需要取消订阅的主题。 PUBLISH（推送）：数据部分包含实际发送的消息内容。 通过上述结构与功能，MQTT 协议能够在众多物联网应用和远程设备之间实现高效、灵活的消息传递和管理。","categories":["3.协议","MQTT"]},{"title":"libusb的交叉编译","path":"/2023/12/13/3-协议-USB-libusb的交叉编译/","content":"下载软件包前往 SourceForge 网站，选择最新版本的 libusb-1.0.21 和 libusb-compat-0.1.5。请注意，libusb-1.0 和 libusb-compat-0.1 的函数命名和编译时链接方式存在显著不同。确保下载这两个包，因为这是编译和开发 USB 设备时必不可少的基础库。 解压和配置解压下载的文件。在终端中，运行以下命令来配置编译环境： ./configure --host=arm-none-linux-gnueabi 此命令指定了交叉编译工具链以支持 ARM 架构。执行时，有可能出现如下错误提示： configure: error: udev support requested but libudev not installed 如果遇到此错误，解决方式是执行以下命令，以禁用 udev 支持： ./configure --disable-udev 编译和安装接下来，执行 make 命令以进行编译。若没有问题，可以继续使用 sudo make install 安装，但可能会遇到以下报错： ../libtool: line 1085: arm-none-linux-gnueabi-ranlib: command not foundmake[2]: *** [install-libLTLIBRARIES] Error 127 解决此问题需要进入 root 权限。在终端中输入： sudo -i 切换至 root 权限后，再次执行以下命令： make install 若成功，系统将生成所需的库文件，从而完成安装过程。 编译时链接库文件在程序编译时，需确保链接库文件。首先，通过 -L 参数指定动态库的路径。接着，选择合适的链接库，使用下列选项： -lusb -lusb-1.0 为了确认使用的函数所在的库，可以使用 nm 命令查看动态库内的函数。例如，运行以下命令可查看某个动态库中的所有函数： nm 动态库名 若链接库不正确，编译时会出现大量 undefined reference 错误。如果在编译过程中提示 cannot find -lusb，则说明系统仅安装了 libusb-1.0，但缺少 libusb-compat-0.1。确保两者均已安装，以避免产生错误。","categories":["3.协议","USB"]},{"title":"USB挂载监测","path":"/2023/12/12/3-协议-USB-USB挂载监测/","content":"功能程序监测到插入U盘后，自动执行执行U盘内和本地指定文件夹双向同步功能 要点 Linux 下如何用 QT 检测到 U 盘已经插入，并实现 mount 与 umount 实现方式使用 qt 自带的 QDBus 可以实现，下面为连接代码，当系统有设备插入时，可以调用 slotDeviceAdded(QString udi) 函数。 在 pro 文件中应该加入 QT +=dbus #include QtDBus/QDBusConnection#include QDbusInterface//以下为检测设备的插入 QDBusConnection::systemBus().connect( org.freedesktop.Hal, /org/freedesktop/Hal/Manager, org.freedesktop.Hal.Manager, DeviceAdded, this, SLOT(slotDeviceAdded(QString )));//以下为检查设备的拨出 QDBusConnection::systemBus().connect( org.freedesktop.Hal, /org/freedesktop/Hal/Manager, org.freedesktop.Hal.Manager, DeviceRemoved, this, SLOT(slotDeviceRemoved(QString ))); 在 slotDeviceAdded(QString udi) 函数中，要使用到 QDBusInterface device(org.freedesktop.Hal, udi, org.freedesktop.Hal.Device , QDBusConnection::systemBus()); 通过 HAL 可以查询到设备为 volume 的设备，然后通过判断是否为devsd 的设备，就可以判断出是否为 U 盘，然后调用 mount 就可以了。 这时记录下 U 盘的 UDI，在检测到设备拨出时，再查询一下 U 盘的 UDI 是否还在，就知道 U 盘是否被拨出了。","categories":["3.协议","USB"]},{"title":"USB权限设置","path":"/2023/12/11/3-协议-USB-USB权限设置/","content":"因 Linux 系统下将涉及到 usb 底层驱动的调用，运行时，一定要加 sudo 获取权限运行，否则 USB 设备没有权限操作。 现通过创建 UDEV 规则，配置 USB 权限后，可以调用指定设备不加权限运行。 输入 lsusb，查看当前的 USB 设备的 ID，确定需要配置的 USB。 创建一个新的 udev 规则。名称取为：99-myusb.rules sudo vi /etc/udev/rules.d/99-myusb.rules 在 99-myusb.rules 文件中，输入以下内容 ##ACTION==add,SUBSYSTEMS==usb, ATTRSidVendor==04d8, ATTRSidProduct==0053, GROUP=users, MODE=0777 这条 udev 规则的作用是，当供应商 ID 为 04d8 且产品 ID 为 0053 的 USB 设备插入系统时，将该设备的用户组设置为 users，并赋予所有用户读、写、执行的全部权限。 插拔一下 USBCAN 设备或重启一下电脑后，即可不加 sudo 权限运行程序了 对某个特定 USB 设备设置权限。每当这个设备插入系统时，规则会自动应用。 ACTION==add：这表示规则在设备添加（插入）时生效。udev 可以根据不同的动作（如添加、移除等）触发规则，add 动作指设备插入时。 SUBSYSTEMS==usb：表示规则适用于 USB 子系统的设备。udev 管理系统中的设备，子系统用于分类，USB 是其中一种。 ATTRSidVendor==04d8：表示设备的供应商 ID（Vendor ID）为 04d8。每个 USB 设备都有唯一的供应商 ID，用于标识设备的制造商。 ATTRSidProduct==0053：表示设备的产品 ID（Product ID）为 0053。每个供应商的不同产品有不同的产品 ID，用于区分供应商的各个设备。 GROUP=users：表示设备的用户组被设置为 users。这决定了哪些用户组的成员有权访问该设备。 MODE=0777：表示设备的权限模式被设置为 0777，即所有用户对该设备都有读、写、执行权限。","categories":["3.协议","USB"]},{"title":"USB的权限设置最高","path":"/2023/12/08/3-协议-USB-USB的权限设置最高/","content":"使用 lsusb -vvv 命令找出 USB 设备的 vendorID 和 productID 创建一个新的 udev 规则红色框中的为新建的 udev 规则 新建文件内容： $ sudo vi/etc/udev/rules.d/50-myusb.rulesSUBSYSTEMS==usb, ATTRSidVendor==067b, ATTRSidProduct==2303, GROUP=users, MODE=0666 用自己的”idVendor”和”idProduct”来替换。MODE”0666”表示 USB 设备的权限。建立新文件内容 建立好文件之后重启即可","categories":["3.协议","USB"]},{"title":"USB设备节点名不固定","path":"/2023/12/07/3-协议-USB-USB设备节点名不固定/","content":"方案一Linux 下 USB 设备节点名不固定以 USB 转串口设备为例，这类设备在 Linux 系统中的节点名通常是 ttyUSBx，其中 x 是一个数字，范围从 0 到 n。Linux 内核会依据设备插入的顺序为这些设备分配编号。例如，当首先插入一个 USB 转串口设备，它会被识别为 ttyUSB0，接下来插入的设备会依次被命名为 ttyUSB1、ttyUSB2 等。 这种基于插入顺序的命名方式有一个明显的问题：如果仅凭设备节点名 ttyUSBx 来区分这些设备，那么末尾的数字会随着设备的插入和拔出而变化，这就导致设备的顺序可能会时常变动，从而引发混淆。比如，设备 A 可能在某次启动时成为 ttyUSB0，而在下次重启或重新插入时却变成 ttyUSB1。由于在 dev 目录下没有提供固定显示 ttyUSB 的方法，因此必须寻求其他的标识方式。 每个 USB 端口都有一个唯一的标识符，比如 3-1.1、3-1.2，这就类似于每个商店都有一个独特的门牌号。依靠这些端口号来区分设备，就能有效解决问题。步骤非常简单，就是先找到设备的端口号，然后根据这个端口号来识别挂载在该端口上的 USB 设备，从而清楚知道它对应的节点名是 ttyUSB0 还是 ttyUSB1。 关于端口号的查看方法连接好两个 USB 转串口设备后，可以用以下命令查看当前连接的设备信息： ls -l /sys/class/tty/ttyUSB* 假设得到的输出结果如下： lrwxrwxrwx root root 2017-08-01 13:40 ttyUSB0 - ../../devices/ff540000.usb/usb3/3-1/3-1.1/3-1.1:1.0/ttyUSB0/tty/ttyUSB0lrwxrwxrwx root root 2017-08-01 13:43 ttyUSB1 - ../../devices/ff540000.usb/usb3/3-1/3-1.2/3-1.2:1.0/ttyUSB1/tty/ttyUSB1 从输出中可以看到，ttyUSB0 所在的端口号是 3-1.1，而 ttyUSB1 则是在 3-1.2。这表明，3-1.1 端口的设备先插入，因此它被命名为 ttyUSB0。如果反向插入这两个设备，3-1.1 上的设备将会成为 ttyUSB1，而 3-1.2 上的设备将成为 ttyUSB0。因此，设备节点 ttyUSBx 的不确定性对的操作带来了难题，尤其是在上层软件需要通过串口节点 devttyUSBx 进行数据读取时。 解决方案当前的问题是，在的硬件架构上，两台 USB 转串口设备在通电后几乎同一时间启动。这就意味着，每次启动后，ttyUSB0 和 ttyUSB1 的指向可能会变动，无法保证它们总是对应到上一次的固定端口。为了解决这个问题，可以使用 bash 和 Python 的正则表达式进行组合，以确保始终能够获取到正确数据的端口。 以下是具体的步骤： 在第一次通电时，通过命令 ls -l /sys/class/tty/ttyUSB* 确定哪个端口（如 3-1.1）是所需要的数据端口。 在后续的每次通电中，需要重新获取挂载在此端口上的 ttyUSB 设备。如果将这个设备创建一个固定名称的软链接（如 ttydata），那么以后每次打开 devttydata 就能始终找到与 3-1.1 对应的设备，无论它是 ttyUSB0 还是 ttyUSB1。 创建一个文件夹 getUSB，其中包含： cmd.sh：使用 bash 脚本获取 /sys/class/tty/ttyUSB* 的相关信息，并保存在 device_usb.txt 中。 getUSB.py：读取 device_usb.txt 的信息，以判断当前挂载在端口 3-1.1 上的是 ttyUSB0 还是 ttyUSB1，并将结果保存在 usbdev 中。 cmd.sh#!/bin/bashdeclare -i a=0declare -i b=0#等待一段时间，若未检测到 ttyUSB0 设备则自动跳出循环while [[ ! -e /sys/class/tty/ttyUSB0 ]]do sudo sleep 0.01s a=a+1 if [ $a -eq 300 ];then break fidone# 如果ttyUSB0被检测到，则也跳出循环while [[ ! -e /sys/class/tty/ttyUSB1 ]]do sudo sleep 0.01s b=b+1 if [[ $b -eq 300 || $a -ne 0 ]];then break fidone# 检查是否没有 ttyUSB 设备# 如果成功检测到两个 ttyUSB 设备，则记录信息到 device_usb.txtif [[ ! -e /sys/class/tty/ttyUSB0 ! -e /sys/class/tty/ttyUSB1 ]]; then echo 未检测到 ttyUSB0 或 ttyUSB1else tty1=$(ls -l /sys/class/tty/ttyUSB0) tty2=$(ls -l /sys/class/tty/ttyUSB1) sudo ls -l /sys/class/tty/ttyUSB0 /sys/class/tty/ttyUSB1 ./device_usb.txtfi# 非空检测if [ ! -n $tty1 ]; then echo tty1 为空fi# 延迟 0.01s 确保 device_usb.txt 完成写入sudo sleep 0.01s# 删除旧的 USB 设备软链接if [ ! -e /dev/ttydata ]; then echo -------------/dev/ttydata 未找到else echo /dev/ttydata 已存在 sudo rm /dev/ttydatafi# 调用 Python 脚本获取正确的 USB 接口./getUSB.py usbdev=$(cat ./usbdev) echo 当前设备为: echo $usbdev# 将设备软链接到 /dev/ttydata 之后每次打开这个 ttydata 即可sudo ln -s /dev/$usbdev /dev/ttydata getUSB.py#!/usr/bin/python# coding:utf-8import re # 引入正则表达式模块# 打开 device_usb.txt 文件以读取设备信息with open(./device_usb.txt, rb) as sss: # 创建一个新文件 usbdev 来存储输出结果 with open(./usbdev, wb) as www: s_read = sss.read() # 正则表达式根据特定模式匹配 r = rusb3/3-1/3-1\\.1.+(ttyUSB[0-9]) # 利用正则找到与端口 3-1.1 相关的 ttyUSB 设备 output = re.findall(r, s_read) # 将结果写入 usbdev 文件 www.write(output[0]) 完成上述步骤后，设置开机项目，将 getUSB 文件夹放到一个固定位置，然后在 /etc/rc.local 中增加 cmd.sh 的启动项。这样，每次开机后，都会从 /dev/ttydata 获取到与固定端口对应的数据，从而简化了开发过程，避免了因设备节点不确定性带来的麻烦。 方案二接入 USB 设备首先，确保将 USB 设备连接到计算机，接下来需要执行以下命令： devlabel add -d /dev/sda1 -s /dev/usbdevice 这里，/dev/sda1 是 USB 设备的名称。要确认 USB 设备的确切名称，可以使用以下命令： fdisk -l 如果 fdisk 命令没有显示出设备信息，可以尝试使用另一种方法。在终端中，检查以下目录是否存在： /proc/scsi/usb-storage-# 其中，# 代表数字（如 0、1、2、3 等）。如果 /proc/scsi/usb-storage-# 存在，继续检查： /proc/scsi/usb-storage-#/# 在这个目录中，查看最后一行是否包含： Attach: YES 如果是，那么可以确定设备的名称如下： /dev/sda 代表 0 /dev/sdb 代表 1 /dev/sdc 代表 2 接下来，/dev/usbdevice 是定义的用户设备名称，可以随意选择一个目录并命名。举例来说，可以命名为 /dev/myusb。 注意：automount 选项可以选择性地去掉。如果在 devlabel 重新启动时，/etc/fstab 中有这个设备项目且该设备存在（具备相同的 UUID），则系统会自动挂载该项目。 创建挂载目录创建一个挂载点目录，使系统能够将 USB 设备正确连接： mkdir /mnt/usb 修改 etcfstab 文件打开 /etc/fstab 文件，并添加以下一行： /dev/usbdevice /mnt/usb auto noauto,owner 0 0 这条记录的意义在于，系统每次插入 USB 存储设备时，都会自动将其挂载到 /mnt/usb 目录下。这一操作的前提是该目录必须存在。 解决方案思路当任何 USB 设备插入时，hotplug 程序会自动运行 updfstab 程序。如果新的 USB 存储设备被检测到，该程序会在 /etc/fstab 中为它添加一条记录。这条包含了实际设备名称（如 /dev/sda1）和 kudzu 选项。kudzu 选项的作用是，如果设备不存在，就会删除这一行记录。 为了确保这一行能够保留在文件中，需要删除 kudzu 选项，同时将设备名称改为 devlabel 设备名称。例如，将 /dev/sda1 改为 /dev/usbdevice。记得同时创建挂载点（如 /mnt/usb）。这样，修改后的内容就符合上述的第三步。 使用更简单的方法最后，还有一种方法，对来说，这是当前最简单的做法。可以直接编辑 /etc/hotplug/usb.agent 文件，找到以下段落： add)if [ -x /sbin/devlabel ]; then /sbin/devlabel restartfi 在上述代码后面添加以下内容： [ -x /usr/sbin/udisk ] /usr/sbin/udisk 此处，udisk 是一个简单的挂载脚本，其内容如下： #! /bin/shmount | grep /mnt/usbif [ $? = 0 ]; then umount /mnt/usb rmdir /mnt/usbelse mkdir /mnt/usb mount /dev/sda1 /mnt/usbfi 这样做的目的在于，每当 USB 设备连接时，hotplug 程序会自动运行。在脚本中加入挂载功能后，USB 设备的自动挂载将变得非常方便。尽管如此，对于设备的卸载操作，用户还是需要使用 umount 命令（或者直接运行 udisk，如果使用第三种办法）。这和 Windows 系统的处理方式相似。","categories":["3.协议","USB"]},{"title":"自动挂载U盘","path":"/2023/12/06/3-协议-USB-自动挂载U盘/","content":"某些场景下，服务器可能没有必要的键盘等输入设备、屏幕等输出设备。此时需要在没有人为干预的情况下实现当插入 U 盘或者硬盘后自动挂载，并执行某些脚本动作。 必要组件udev udisks busybox (需要用到 blkid)可以直接获取到设备的卷标，这样就可以指定挂载路径名称了。 实现规则编写编写 udev 规则实现 U 盘插入时候的动作。规则文件写在 /etc/udev/rules.d 下。 如上， 通过规则定义 U 盘插入与拔出的动作即可，动作的具体实现可以在规则中编写，也可以通过指定执行脚本来实现。本文的规则中仅指定执行脚本。 规则如下： ENVDEVTYPE=partition,RUN+=/lib/udev/automount.sh,ENVREMOVE_CMD=/lib/udev/autounmount.sh 脚本编写将脚本文件写在 /lib/udev 下，根据上文规则，应该分别实现插入的动作脚本和拔出的动作脚本。 插入动作脚本主要在于需要获取到设备的卷标，来确定挂载的路径(即 $ID_FS_LABEL) #!/bin/shmount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$DEVNAME##*/fiif [ -n $mount_point ];thenmkdir -p /media/$mount_pointmount -t $ID_FS_TYPE -o gid=100,dmask=000,fmask=111,utf8,flush,rw,noatime,users$DEVNAME /media/$mount_pointfi 拔出动作脚本在 U 盘拔出时候，及时删掉挂载的路径 mount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$DEVNAME##*/fiif [ -n $mount_point ];thenumount -l /media/$mount_point rm -r /media/$mount_pointfi 自动执行动作脚本这样，当 U 盘插入时，/media/ 下就会出现于卷标相同的文件夹，并挂载上了 U 盘。因此，需要实现 U 盘插入自动执行的话，通过轮询探测 /media/ 下相应目录是否存在即可。如: UDISK=$1# ---------------main control area ---------------while (true)do\t# probe mounted disk\tif [ -e$UDISK ];\tthen echoMounted device [$UDISK] found !\telse echoDevice not found [$UDISK] !\tfi\techoSleep for sometime...\tsleep 3sdone 需要注意的问题新版本的 udev 可能会遇到 mount 失效的问题，通过查询资料可知，udev 的 rules 运行于独立的文件空间上，与用户的文件空间不同，因此及时挂载上了，用户也无法访问。因此需要将 udev 的运行方式改为共享。 修改方式如下： 拷贝一份 /usr/lib/systemd/system/systemd-udevd.service 到 /etc/systemd/system/ （推荐） 编辑 /etc/systemd/system/ 将 MountFlags 改为 shared 重启即可。","categories":["3.协议","USB"]},{"title":"ZeroMQ笔记","path":"/2023/12/05/3-协议-ZeroMQ-ZeroMQ笔记/","content":"概述ZeroMQ 是一种高效的基于消息队列的多线程网络库，旨在简化网络通信的复杂性。它对底层套接字类型、连接处理、数据帧，甚至路由的细节进行了极大的抽象，使得开发者能够使用跨越多种传输协议的套接字。可以认为，ZeroMQ 在网络通信中增加了一层新的抽象，位于应用层和传输层之间（按照 TCPIP 的划分）。这层抽象能够实现可伸缩的通信，支持在分布式系统中并行工作。 总体架构ZeroMQ 的设计使得几乎所有的 IO 操作都是异步的，从而确保主线程不会被阻塞。当用户调用 zmq_init 函数时，可以根据传入的参数创建对应数量的 IO 线程。每个 IO 线程都配备一个绑定的 Poller，Poller 采用经典的 Reactor 模式实现，根据不同操作系统平台，使用不同的网络 IO 模型，如 select、poll、epoll、devpoll 以及 kequeue 等。 主线程和 IO 线程之间通过 Mail Box 进行消息传递。当服务器开始监听或者客户端发起连接时，主线程会相应地创建 zmq_connecter 或 zmq_listener，并通过 Mail Box 将其绑定到 IO 线程。紧接着，IO 线程将 zmq_connecter 或 zmq_listener 添加到 Poller 中，以侦听读写事件。在 Server 和 Client 第一次通信时，会使用 zmq_init 发送身份标识进行认证。认证完成后，双方为此次连接创建一个 Session，以后双方通过 Session 进行通信。每个 Session 都将关联到相应的读写管道。主线程在进行消息的收发时，只需通过管道读取和写入数据。值得注意的是，Session 并不直接与内核交换 IO 数据，而是通过连接到 Session 的 Engine 来与内核交互。 编程模式在数据需要并行化处理的场合，采用消息队列进行通信的方式往往优于传统的共享状态方法。ZeroMQ 对消息通信的模式进行了总结，提供了多种模式选择。 ZeroMQ 不是对套接字的简单封装，不适合用来实现已存在的网络协议。它有独特的通信模式，这些模式并不局限于底层的点对点通信方式。与 TCP 协议相比，ZeroMQ 提供了一种更高层级的协议选择（并且 ZeroMQ 也不仅仅基于 TCP，它同样适用于进程间和进程内通信）。 ZeroMQ 将通信需求分为四类，其中一类是一对一即对称通信，虽然支持传统的 TCP socket 模型，但并不推荐使用。其余三类模型更为常用。 请求-回应模型：在此模型中，请求端主动发送请求并等待回应。在请求端的角度看，收发是配对的，而在回应端则是发送和接收的对应关系。请求端和回应端可以为 1:N 模式。通常将 1 理解为 Server，将 N 理解为 Client。ZeroMQ 完美地支持路由功能（使用组件 Device 实现），将 1:N 扩展为 N:M 模式。在这一模型中，底层的端点地址对于上层是隐藏的，每个请求都隐含了回应地址，应用程序对此并不需要关注。 发布-订阅模型：在该模型中，发布端只负责单向发送消息，同时不关心数据是否全部成功发送到订阅端。如果发布端开始传送信息时，订阅端尚未连接，消息将被丢弃。但一旦订阅端连接成功，将确保消息不会丢失。同样，订阅端只是接收数据，不能发送反馈。如果发布端和订阅端之间需要交互（例如确认订阅者的连接状态），可使用额外的套接字，通过请求-回应模型来满足。 管道模型：在此模型中，数据流单向推进，从 PUSH 端向 PULL 端进行数据传输。这个模型可通过多种组合解决任何分布式和并行处理的需求。ZeroMQ 专注于解决消息通讯这一核心问题，表现得极为出色。 基于这些定义清晰的模型，ZeroMQ 的 API 显得简单易用。开发者无需使用 bind/listen/accept 来建立服务器，因为模型本身是 1:N 类型的，不需要为每个通道保存句柄。此外，Server 的启动顺序也不再是问题，Client 在 Server 启动之前就可以工作。 ZeroMQ 中的 Transient（短暂）和 Durable（持久）套接字并不是底层实现使用短连接或长连接的区别，而是概念上的不同。Durable 套接字的生命周期可大于一个进程，即使进程退出，重新启动后依旧能够维持连接。尽管如此，这并不意味着它能够拯救因错误崩溃的程序。对于 ZeroMQ，若内存有限，也可以选择将数据传输缓冲区存储在磁盘中。 在网络游戏的架构中，基于 ZeroMQ 的服务器设计非常合适。对于玩家的 Client-Server 部分，可以考虑编写一个前端程序进行连接，而服务器内的服务集群则可以利用 ZeroMQ 的协议进行通信。 通信协议ZeroMQ 提供了四种通信协议，分别用于进程内、进程间、机器间和广播等场景。通信协议的配置非常简单，只需使用类似于 URL 的字符串来指定，格式包括 inproc://、ipc://、tcp:// 和 pgm://。ZeroMQ 会自动根据这些字符串解析出协议、地址和端口号等信息。 工作流程 安装在 UNIX 类系统上构建 确保安装了 libtool、pkg-config、build-essential、autoconf 和 automake。 检查 uuid-dev 包或等效的 RPM 是否已安装。 解压 .tar.gz 源代码归档。 运行 ./configure，然后执行 make。 如要系统级安装 ZeroMQ，运行 sudo make install。 在 Linux 系统上，安装 ZeroMQ 后，运行 sudo ldconfig。 在 Windows 上构建 需要 Visual Studio 2008 或更高版本。 解压 .zip 源代码归档。 在 Visual C++ 中打开解决方案文件 builds\\msvc\\msvc.sln。 编译该解决方案。 ZeroMQ 的库文件将位于 lib 子目录下。","categories":["3.协议","ZeroMQ"]},{"title":"Linux下的CH34x串口驱动","path":"/2023/12/04/3-协议-串口-Linux下的CH34x串口驱动/","content":"ch341.ko 是一个 Linux 内核模块，用于支持 CH341 USB 转串口芯片。要在内核中编译该模块，需要找到其配置选项。这个配置选项通常在 Linux 内核的配置文件中定义，并且可以通过配置内核选项来启用。 判断是否识别使用 lsusb 命令可以看到有 Bus 001 Device 005: ID 1a86:7523 QinHeng Electronics CH340 serial converter 是能识别出 ch34x 设备 检查串口是否被驱动加载输入指令 ls /dev/ttyUSB* 将会列出 USB 的加载情况。如果提示 No such file or directory 则是没有被驱动加载。 占用情况因报文件不存在错误，采用 dmesg|grep tty 命令检查发现，被 brltty 进程占用。 brltty 是一个后台进程（守护进程），为盲人提供对 LinuxUnix 控制台的访问（当处于文本模式时），使用可刷新盲文显示。 移除该 apt remove brltty。 权限chmod a+rw /dev/ttyUSB0 即可 重装驱动-单独编译下载最新的驱动 CH341SER_LINUX https://github.com/WCHSoftGroup/ch341ser_linux 解压后进入 “driver” 目录下 输入 make 命令编译驱动，正常编译完成后，将会看到生成了 ch341.ko 模块 输入 sudo make load 或者 sudo insmod ch341.ko 动态加载驱动（重启需要再次加载），或者输入 sudo make install 安装驱动（重启不丢失） 输入 sudo make unload 或者 sudo rmmod ch341.ko 或者 sudo make uninstall 卸载驱动 如果编译失败，可能是 ch34x.c 和实际内核版本不匹配，uname -r 可查看操作系统的发行版号，之后在 https://elixir.bootlin.com/linux/latest/source 中查找对应内核版本的源代码文件，一般位于 /drivers/usb/serial/ch341.c，替换后重新编译 如果 insmod 失败，查看 /lib/modules/$(uname -r)/kernel/drivers/usb/serial 目录下是否已经有了 ko 模块，将目录中生成 ko 文件复制到此处，使用 lsmod 查看模块 重装驱动-交叉编译编译一个 ARM64 的 ch341 的 ko 文件，用于 4.19.206 内核的 Linux，ch341.ko 模块的定义位于 drivers/usb/serial/Kconfig 文件中，通过配置 USB_SERIAL_CH341 选项可以在内核中启用该模块。编译内核时根据配置生成相应的模块文件，然后通过 modprobe 加载即可使用该模块。 在 drivers 目录下的所有文件中，在文件的内容中查找字符串 CH341grep -r CH341 drivers/ 确认串口类型，是 CH341 还是 PLX2303 ch341.c 文件中的 usb_device_id 是否包含要使用的 VID，PID（lsusb 命令查看） 查找配置选项，在 Linux 内核源代码目录中，驱动程序的配置选项通常定义在 Kconfig 文件中。要查找 ch341 驱动的配置选项，可以在内核源代码目录下运行以下命令：grep -r CH341 drivers/ 这将搜索包含 CH341 字符串的所有文件，通常会找到类似以下的条目： drivers/usb/serial/Kconfig:config USB_SERIAL_CH341drivers/usb/serial/Kconfig:\ttristate USB CH341 single port serial driver 配置内核，知道配置选项后，可以使用 make menuconfig 或 make nconfig 等工具来配置内核。在 USB Serial Converter support 菜单下，找到并启用 USB CH341 single port serial driver 选项。或者配置 USB_SERIAL_CH341=m，将其设置为模块（M）或内联（*），如果希望编译为模块，选择 M。 Device Drivers --- [*] USB support --- * USB Serial Converter support --- * USB CH341 single port serial driver 编译内核和模块，配置完成后，编译内核和模块： makemake modulesmake modules_install 加载模块，编译完成后，可以使用 modprobe 加载模块：modprobe ch341 验证模块加载，使用 lsmod 验证模块是否成功加载，如果显示 ch341 模块，则说明加载成功。lsmod | grep ch341 重装驱动-apt包提供了一些可能默认没有包含的额外内核模块。 sudo apt install linux-modules-extra-$(uname -r) 手动加载 ch341 驱动程序： sudo modprobe ch341 检查驱动程序是否已加载： lsmod | grep ch341 检查设备是否被识别： dmesg | grep ch341 KO 文件开机自动加载/etc/modules 文件中添加模块打开 /etc/modules 文件： sudo vi /etc/modules 在文件末尾添加想要加载的 KO 文件的名字（不需要路径，只需要模块名），比如： my_module 使用 modprobe 配置文件创建一个新的文件在 /etc/modprobe.d/ 目录，例如 custom.conf： sudo vi /etc/modprobe.d/custom.conf 添加如下内容，指定模块名称： install your_module_name /sbin/insmod /path/to/your/module.ko 使用 rc.local 文件打开 /etc/rc.local 文件： sudo vi /etc/rc.local 在 exit 0 之前添加 insmod 命令，指定模块的完整路径： sudo insmod /path/to/your/module.koexit 0 创建 systemd 服务创建一个新的服务文件，例如 load-module.service： sudo vi /etc/systemd/system/load-module.service 在文件中添加以下内容，指定模块路径： [Unit]Description=Load custom kernel module[Service]Type=oneshotExecStart=/sbin/insmod /path/to/your/module.koExecStop=/sbin/rmmod your_module_nameRemainAfterExit=true[Install]WantedBy=multi-user.target","categories":["3.协议","串口"]},{"title":"Qt串口实现","path":"/2023/12/01/3-协议-串口-Qt串口实现/","content":"基于 QextSerialPort在 Qt4 中，串口的读写操作可以通过使用 QextSerialPort 这个外部类来实现。需要注意的是，不同操作系统对该类的支持程度有明显差异： Linux：在 Linux 系统中，仅支持轮询方式来读取串口数据。这意味着程序将通过不断检查串口是否有数据可供读取，来实现数据接收。 Windows：在 Windows 系统中，支持两种串口数据读取方式：轮询方式和事件驱动方式。这种灵活性使得开发者可以 based on 需求来选择实现的方式。 QextSerialBase 作为一个基础类，继承自 QIODevice 类，主要负责提供操作串口所需的一系列变量和函数。而 Win_QextSerialPort 和 Posix_QextSerialPort 则分别是针对 Windows 和 Linux 的具体实现，均继承自 QextSerialBase。 Win_QextSerialPort 类专为 Windows 平台设计，增强了在该平台下进行串口操作时的一些功能，如通过串口通信聚合不同线程的信号，确保更高效的数据传输。 Posix_QextSerialPort 类则为 Linux 平台而生，遵循 POSIX 标准，适用于 Linux 下的串口数据处理。 在 QextSerialBase 类中，还有一个重要的枚举变量 QueryMode，它可取两个值：Polling 和 EventDriven。此枚举定义了读取串口的方式，也可以称为查询模式。具体而言： 查询方式 Polling：这种方式中，读写函数的执行是同步的，意味着程序在执行读写操作时，会阻塞当前线程。信号在这种模式下无法使用，因此无法响应数据到达的事件。开发者需要自己创建定时器以定期检查串口是否有新数据可供读取。这种方法的好处在于其开销较小，适合一些对实时性要求不高的应用场景。 事件驱动方式 EventDriven：与 Polling 完全不同的是，此方式使用事件机制来处理串口的读取。当数据到达时，系统会发出 readyRead() 信号，开发者可以将该信号与自定义的槽函数关联，以异步（非阻塞）的方式读取串口的数据。这种方式能有效提高程序的响应性能和用户体验，适合对实时性有较高要求的应用。 需要注意的是，Windows 下同时支持上述两种模式，而 Linux 只支持 Polling 模式。 在使用 Qt 编写串口程序时，根据目标平台的不同，需要引用不同的文件。在 Windows 平台，可以使用以下文件： qextserialbase.cpp 和 qextserialbase.h win_qextserialport.cpp 和 win_qextserialport.h 而在 Linux 环境下，则需引入： qextserialbase.cpp 和 qextserialbase.h posix_qextserialport.cpp 和 posix_qextserialport.h 这种文件架构的设计，使得程序在跨平台时，可以根据操作系统的特性进行相应的适配，确保良好的性能和兼容性。 轮询方式在轮询模式下，读写函数可以异步地同时执行。然而，由于此模式的特性，信号不能正常工作。为了检测串口是否有数据，可以启用一个定时器。定时器会定期检查串口缓冲区的数据可用性，具体实现步骤如下： 使用 bytesAvailable() 函数来查询已获得的字节数。 一旦字节数达到预设的目标数量，就可以利用 readAll() 函数将数据读取到一个 QByteArray 类型的变量中。 读取操作的特点： 串口每次读取 8 字节的数据，如果缓冲区中剩余的数据少于 8 字节，则读取的小于 8 字节的数据。 事件驱动方式在事件驱动模式下，当串口接收到数据时，串口的实例化对象会发出 readyRead 信号。可以关联此信号到相应的数据读取槽函数，以便在数据达到时立刻进行处理。使用这一模式时，调用读写函数会快速返回。 具体代码示例如下： myCom-write(xxxxxx.toAscii()); 在这种模式下，bytesToWrite 可以用来获取将要发送的字节数。但需注意，此函数不适用于轮询模式。 串口操作步骤以下是打开串口并设置相关参数的基本步骤： 定义串口对象：指定串口名及查询模式。 打开串口：可以选择只读（QIODevice::ReadOnly）、只写（QIODevice::WriteOnly）或读写（QIODevice::ReadWrite）。 设置串口参数： 波特率：可以设置为 9600 等其他值。 数据位：通常设置为 8 位，Qt5 中默认为 8 位。 奇偶校验：可以设置为无（PAR_NONE），Qt5 中默认为无校验。 停止位：一般设置为 1 位（STOP_1），Qt5 中默认为 1 位停止位。 数据流控制：如不需要，则设置为无（FLOW_OFF），Qt5 中默认为无数据流控制。 设置延时：控制串口的读写时间，不过在使用 readyRead 信号时，这个时间设置不会生效。 以下是实际的代码示例： myCom - open(QIODevice::ReadWrite);// 以读写方式打开串口myCom - setBaudRate(BAUD9600);// 设置波特率为9600myCom - setDataBits(DATA_8);// 设置数据位为8位myCom - setParity(PAR_NONE);// 设置奇偶校验为无myCom - setStopBits(STOP_1);// 设置停止位为1位myCom - setFlowControl(FLOW_OFF);// 设置数据流控制为无 注意事项：在 Qt4 中，串口参数的设置是在打开串口之后进行的，而在 Qt5 中，设置参数应在打开串口之前进行。这样可以确保串口的配置在实际使用前是正确的。 基于 Qt5 自带串口类在 Qt 工程文件 pro 中添加 QT += serialport 同步读取 实例化和配置串口首先，创建一个 QSerialPort 对象，并通过 setPortName 函数指定要打开的串口名称。接着，通过 setBaudRate 函数设置串口的波特率，比如 9600 波特。最后，通过 open 函数打开串口，这里可以选择只读或读写方式。代码如下： QSerialPort serialPort;QString serialPortName = COM6; // 指定串口名称int serialPortBaudRate = QSerialPort::Baud9600; // 设置波特率为9600serialPort.setPortName(serialPortName);serialPort.setBaudRate(serialPortBaudRate);if (!serialPort.open(QIODevice::ReadOnly)) return 1; // 如果打开失败，返回错误代码 数据读取操作打开成功后，可以使用 readAll() 和 waitForReadyRead() 函数进行数据读取。首先，从串口读取所有可用的数据，然后利用 waitForReadyRead(5000) 等待最多 5 秒，检查是否有新数据到达。如果数据到达，将其追加到读取缓冲区。需要注意，readAll() 结束时并不能区分读取失败或超时，因此可以通过 error() 函数判断具体错误类型。 QByteArray readData = serialPort.readAll();while (serialPort.waitForReadyRead(5000)) // 等待新数据到达 readData.append(serialPort.readAll());// 使用error()判断错误类型if (serialPort.error() == QSerialPort::ReadError) standardOutput QObject::tr(Failed to read from port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; else if (serialPort.error() == QSerialPort::TimeoutError readData.isEmpty()) standardOutput QObject::tr(No data was currently available for reading from port %1) .arg(serialPortName) endl; else standardOutput QObject::tr(Data successfully received from port %1) .arg(serialPortName) endl; standardOutput readData endl; // 打印接收到的数据 异步读取与 Qt4 的 Qextserialport 类不同，Qt5 的 QSerialPort 提供信号机制，当串口接收到数据时会发出 readyRead 信号，发生错误时会发送 error 信号。首先，实例化并打开串口，接着启动定时器进行监测，或者直接打印接收到的数据。这里定义了一个 SerialPortReader 类，其构造函数接收 QSerialPort 参数。 connect(m_serialPort, SIGNAL(readyRead()), SLOT(handleReadyRead()));connect(m_serialPort, SIGNAL(error(QSerialPort::SerialPortError)), SLOT(handleError(QSerialPort::SerialPortError)));connect(m_timer, SIGNAL(timeout()), SLOT(handleTimeout())); 处理数据接收当接收到 readyRead 信号时，执行 handleReadyRead 函数，该函数将读取缓冲区的数据存储在 m_readData 中。如果定时器未激活，则启动定时器。 void SerialPortReader::handleReadyRead() m_readData.append(m_serialPort-readAll()); if (!m_timer.isActive()) m_timer.start(5000); // 启动定时器 打印数据如果定时器超时，调用 handleTimeout 函数。如果 m_readData 为空，表明没有可读数据；否则，打印成功接收到的数据。 void SerialPortReader::handleTimeout() if (m_readData.isEmpty()) m_standardOutput QObject::tr(No data was currently available for reading from port %1) .arg(m_serialPort-portName()) endl; else m_standardOutput QObject::tr(Data successfully received from port %1) .arg(m_serialPort-portName()) endl; m_standardOutput m_readData endl; // 打印接收到的数据 m_readData.clear(); // 清空读取数据缓冲区 处理错误如果串口发出了 error 信号，表示发生错误，执行 handleError 函数以打印错误信息。 void SerialPortReader::handleError(QSerialPort::SerialPortError serialPortError) if (serialPortError == QSerialPort::ReadError) m_standardOutput QObject::tr(An I/O error occurred while reading the data from port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 同步发送在将串口以只写方式打开后，创建要发送的数据，并将其转换为 QByteArray 类型。 QByteArray writeData = QString(hello).toLatin1(); // 准备要发送的数据 在发送数据之前，判断数据是否为空。如果为空，则不进行发送并输出错误信息： if (writeData.isEmpty()) standardOutput QObject::tr(Either no data was currently available on the standard input for reading, or an error occurred for port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 如果不为空，使用 write 函数进行发送并检查是否成功发送。 qint64 bytesWritten = serialPort.write(writeData); // 发送数据if (bytesWritten == -1) standardOutput QObject::tr(Failed to write the data to port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 else if (bytesWritten != writeData.size()) standardOutput QObject::tr(Failed to write all the data to port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 else if (!serialPort.waitForBytesWritten(5000)) standardOutput QObject::tr(Operation timed out or an error occurred for port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码standardOutput QObject::tr(Data successfully sent to port %1).arg(serialPortName) endl; 异步发送首先，实例化并打开要使用的串口，之后启动一个单次触发的定时器，超时后将数据发送出去。这里定义了一个 SerialPortWriter 类，构造函数带有 QSerialPort 参数，并提供公共方法给 SerialPortWriter 对象调用，参数为要发送的 QByteArray 类型数据。 SerialPortWriter::SerialPortWriter(QSerialPort *serialPort, QObject *parent) : QObject(parent), m_serialPort(serialPort), m_standardOutput(stdout), m_bytesWritten(0) m_timer.setSingleShot(true); connect(m_serialPort, SIGNAL(bytesWritten(qint64)), SLOT(handleBytesWritten(qint64))); connect(m_serialPort, SIGNAL(error(QSerialPort::SerialPortError)), SLOT(handleError(QSerialPort::SerialPortError))); connect(m_timer, SIGNAL(timeout()), SLOT(handleTimeout())); 处理发送结果在 handleBytesWritten 函数中，判断实际发送的字节数与原始字节数是否一致。如果一致，则打印发送成功的信息并退出程序。 void SerialPortWriter::handleBytesWritten(qint64 bytes) m_bytesWritten += bytes; if (m_bytesWritten == m_writeData.size()) m_bytesWritten = 0; m_standardOutput QObject::tr(Data successfully sent to port %1).arg(m_serialPort-portName()) endl; QCoreApplication::quit(); // 退出程序 处理超时和错误如果在 5 秒内未收到 bytesWritten 信号，则认为发送超时，调用 handleTimeout 函数输出超时信息并退出程序。 void SerialPortWriter::handleTimeout() m_standardOutput QObject::tr(Operation timed out for port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 处理发送过程中发生的错误信息。 void SerialPortWriter::handleError(QSerialPort::SerialPortError serialPortError) if (serialPortError == QSerialPort::WriteError) m_standardOutput QObject::tr(An I/O error occurred while writing the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 发送数据将数据发送并判断发送的字节数量，并在接下来的 5 秒内启动定时器，检测数据发送后的 bytesWritten 信号。 void SerialPortWriter::write(const QByteArray writeData) m_writeData = writeData; qint64 bytesWritten = m_serialPort-write(writeData); if (bytesWritten == -1) m_standardOutput QObject::tr(Failed to write the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 else if (bytesWritten != m_writeData.size()) m_standardOutput QObject::tr(Failed to write all the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 m_timer.start(5000); // 启动定时器","categories":["3.协议","串口"]},{"title":"Qt串口实现","path":"/2023/12/01/2-语言-Qt-Qt串口实现/","content":"基于 QextSerialPort在 Qt4 中，串口的读写操作可以通过使用 QextSerialPort 这个外部类来实现。需要注意的是，不同操作系统对该类的支持程度有明显差异： Linux：在 Linux 系统中，仅支持轮询方式来读取串口数据。这意味着程序将通过不断检查串口是否有数据可供读取，来实现数据接收。 Windows：在 Windows 系统中，支持两种串口数据读取方式：轮询方式和事件驱动方式。这种灵活性使得开发者可以 based on 需求来选择实现的方式。 QextSerialBase 作为一个基础类，继承自 QIODevice 类，主要负责提供操作串口所需的一系列变量和函数。而 Win_QextSerialPort 和 Posix_QextSerialPort 则分别是针对 Windows 和 Linux 的具体实现，均继承自 QextSerialBase。 Win_QextSerialPort 类专为 Windows 平台设计，增强了在该平台下进行串口操作时的一些功能，如通过串口通信聚合不同线程的信号，确保更高效的数据传输。 Posix_QextSerialPort 类则为 Linux 平台而生，遵循 POSIX 标准，适用于 Linux 下的串口数据处理。 在 QextSerialBase 类中，还有一个重要的枚举变量 QueryMode，它可取两个值：Polling 和 EventDriven。此枚举定义了读取串口的方式，也可以称为查询模式。具体而言： 查询方式 Polling：这种方式中，读写函数的执行是同步的，意味着程序在执行读写操作时，会阻塞当前线程。信号在这种模式下无法使用，因此无法响应数据到达的事件。开发者需要自己创建定时器以定期检查串口是否有新数据可供读取。这种方法的好处在于其开销较小，适合一些对实时性要求不高的应用场景。 事件驱动方式 EventDriven：与 Polling 完全不同的是，此方式使用事件机制来处理串口的读取。当数据到达时，系统会发出 readyRead() 信号，开发者可以将该信号与自定义的槽函数关联，以异步（非阻塞）的方式读取串口的数据。这种方式能有效提高程序的响应性能和用户体验，适合对实时性有较高要求的应用。 需要注意的是，Windows 下同时支持上述两种模式，而 Linux 只支持 Polling 模式。 在使用 Qt 编写串口程序时，根据目标平台的不同，需要引用不同的文件。在 Windows 平台，可以使用以下文件： qextserialbase.cpp 和 qextserialbase.h win_qextserialport.cpp 和 win_qextserialport.h 而在 Linux 环境下，则需引入： qextserialbase.cpp 和 qextserialbase.h posix_qextserialport.cpp 和 posix_qextserialport.h 这种文件架构的设计，使得程序在跨平台时，可以根据操作系统的特性进行相应的适配，确保良好的性能和兼容性。 轮询方式在轮询模式下，读写函数可以异步地同时执行。然而，由于此模式的特性，信号不能正常工作。为了检测串口是否有数据，可以启用一个定时器。定时器会定期检查串口缓冲区的数据可用性，具体实现步骤如下： 使用 bytesAvailable() 函数来查询已获得的字节数。 一旦字节数达到预设的目标数量，就可以利用 readAll() 函数将数据读取到一个 QByteArray 类型的变量中。 读取操作的特点： 串口每次读取 8 字节的数据，如果缓冲区中剩余的数据少于 8 字节，则读取的小于 8 字节的数据。 事件驱动方式在事件驱动模式下，当串口接收到数据时，串口的实例化对象会发出 readyRead 信号。可以关联此信号到相应的数据读取槽函数，以便在数据达到时立刻进行处理。使用这一模式时，调用读写函数会快速返回。 具体代码示例如下： myCom-write(xxxxxx.toAscii()); 在这种模式下，bytesToWrite 可以用来获取将要发送的字节数。但需注意，此函数不适用于轮询模式。 串口操作步骤以下是打开串口并设置相关参数的基本步骤： 定义串口对象：指定串口名及查询模式。 打开串口：可以选择只读（QIODevice::ReadOnly）、只写（QIODevice::WriteOnly）或读写（QIODevice::ReadWrite）。 设置串口参数： 波特率：可以设置为 9600 等其他值。 数据位：通常设置为 8 位，Qt5 中默认为 8 位。 奇偶校验：可以设置为无（PAR_NONE），Qt5 中默认为无校验。 停止位：一般设置为 1 位（STOP_1），Qt5 中默认为 1 位停止位。 数据流控制：如不需要，则设置为无（FLOW_OFF），Qt5 中默认为无数据流控制。 设置延时：控制串口的读写时间，不过在使用 readyRead 信号时，这个时间设置不会生效。 以下是实际的代码示例： myCom - open(QIODevice::ReadWrite);// 以读写方式打开串口myCom - setBaudRate(BAUD9600);// 设置波特率为9600myCom - setDataBits(DATA_8);// 设置数据位为8位myCom - setParity(PAR_NONE);// 设置奇偶校验为无myCom - setStopBits(STOP_1);// 设置停止位为1位myCom - setFlowControl(FLOW_OFF);// 设置数据流控制为无 注意事项：在 Qt4 中，串口参数的设置是在打开串口之后进行的，而在 Qt5 中，设置参数应在打开串口之前进行。这样可以确保串口的配置在实际使用前是正确的。 基于 Qt5 自带串口类在 Qt 工程文件 pro 中添加 QT += serialport 同步读取 实例化和配置串口首先，创建一个 QSerialPort 对象，并通过 setPortName 函数指定要打开的串口名称。接着，通过 setBaudRate 函数设置串口的波特率，比如 9600 波特。最后，通过 open 函数打开串口，这里可以选择只读或读写方式。代码如下： QSerialPort serialPort;QString serialPortName = COM6; // 指定串口名称int serialPortBaudRate = QSerialPort::Baud9600; // 设置波特率为9600serialPort.setPortName(serialPortName);serialPort.setBaudRate(serialPortBaudRate);if (!serialPort.open(QIODevice::ReadOnly)) return 1; // 如果打开失败，返回错误代码 数据读取操作打开成功后，可以使用 readAll() 和 waitForReadyRead() 函数进行数据读取。首先，从串口读取所有可用的数据，然后利用 waitForReadyRead(5000) 等待最多 5 秒，检查是否有新数据到达。如果数据到达，将其追加到读取缓冲区。需要注意，readAll() 结束时并不能区分读取失败或超时，因此可以通过 error() 函数判断具体错误类型。 QByteArray readData = serialPort.readAll();while (serialPort.waitForReadyRead(5000)) // 等待新数据到达 readData.append(serialPort.readAll());// 使用error()判断错误类型if (serialPort.error() == QSerialPort::ReadError) standardOutput QObject::tr(Failed to read from port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; else if (serialPort.error() == QSerialPort::TimeoutError readData.isEmpty()) standardOutput QObject::tr(No data was currently available for reading from port %1) .arg(serialPortName) endl; else standardOutput QObject::tr(Data successfully received from port %1) .arg(serialPortName) endl; standardOutput readData endl; // 打印接收到的数据 异步读取与 Qt4 的 Qextserialport 类不同，Qt5 的 QSerialPort 提供信号机制，当串口接收到数据时会发出 readyRead 信号，发生错误时会发送 error 信号。首先，实例化并打开串口，接着启动定时器进行监测，或者直接打印接收到的数据。这里定义了一个 SerialPortReader 类，其构造函数接收 QSerialPort 参数。 connect(m_serialPort, SIGNAL(readyRead()), SLOT(handleReadyRead()));connect(m_serialPort, SIGNAL(error(QSerialPort::SerialPortError)), SLOT(handleError(QSerialPort::SerialPortError)));connect(m_timer, SIGNAL(timeout()), SLOT(handleTimeout())); 处理数据接收当接收到 readyRead 信号时，执行 handleReadyRead 函数，该函数将读取缓冲区的数据存储在 m_readData 中。如果定时器未激活，则启动定时器。 void SerialPortReader::handleReadyRead() m_readData.append(m_serialPort-readAll()); if (!m_timer.isActive()) m_timer.start(5000); // 启动定时器 打印数据如果定时器超时，调用 handleTimeout 函数。如果 m_readData 为空，表明没有可读数据；否则，打印成功接收到的数据。 void SerialPortReader::handleTimeout() if (m_readData.isEmpty()) m_standardOutput QObject::tr(No data was currently available for reading from port %1) .arg(m_serialPort-portName()) endl; else m_standardOutput QObject::tr(Data successfully received from port %1) .arg(m_serialPort-portName()) endl; m_standardOutput m_readData endl; // 打印接收到的数据 m_readData.clear(); // 清空读取数据缓冲区 处理错误如果串口发出了 error 信号，表示发生错误，执行 handleError 函数以打印错误信息。 void SerialPortReader::handleError(QSerialPort::SerialPortError serialPortError) if (serialPortError == QSerialPort::ReadError) m_standardOutput QObject::tr(An I/O error occurred while reading the data from port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 同步发送在将串口以只写方式打开后，创建要发送的数据，并将其转换为 QByteArray 类型。 QByteArray writeData = QString(hello).toLatin1(); // 准备要发送的数据 在发送数据之前，判断数据是否为空。如果为空，则不进行发送并输出错误信息： if (writeData.isEmpty()) standardOutput QObject::tr(Either no data was currently available on the standard input for reading, or an error occurred for port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 如果不为空，使用 write 函数进行发送并检查是否成功发送。 qint64 bytesWritten = serialPort.write(writeData); // 发送数据if (bytesWritten == -1) standardOutput QObject::tr(Failed to write the data to port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 else if (bytesWritten != writeData.size()) standardOutput QObject::tr(Failed to write all the data to port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码 else if (!serialPort.waitForBytesWritten(5000)) standardOutput QObject::tr(Operation timed out or an error occurred for port %1, error: %2) .arg(serialPortName) .arg(serialPort.errorString()) endl; return 1; // 返回错误代码standardOutput QObject::tr(Data successfully sent to port %1).arg(serialPortName) endl; 异步发送首先，实例化并打开要使用的串口，之后启动一个单次触发的定时器，超时后将数据发送出去。这里定义了一个 SerialPortWriter 类，构造函数带有 QSerialPort 参数，并提供公共方法给 SerialPortWriter 对象调用，参数为要发送的 QByteArray 类型数据。 SerialPortWriter::SerialPortWriter(QSerialPort *serialPort, QObject *parent) : QObject(parent), m_serialPort(serialPort), m_standardOutput(stdout), m_bytesWritten(0) m_timer.setSingleShot(true); connect(m_serialPort, SIGNAL(bytesWritten(qint64)), SLOT(handleBytesWritten(qint64))); connect(m_serialPort, SIGNAL(error(QSerialPort::SerialPortError)), SLOT(handleError(QSerialPort::SerialPortError))); connect(m_timer, SIGNAL(timeout()), SLOT(handleTimeout())); 处理发送结果在 handleBytesWritten 函数中，判断实际发送的字节数与原始字节数是否一致。如果一致，则打印发送成功的信息并退出程序。 void SerialPortWriter::handleBytesWritten(qint64 bytes) m_bytesWritten += bytes; if (m_bytesWritten == m_writeData.size()) m_bytesWritten = 0; m_standardOutput QObject::tr(Data successfully sent to port %1).arg(m_serialPort-portName()) endl; QCoreApplication::quit(); // 退出程序 处理超时和错误如果在 5 秒内未收到 bytesWritten 信号，则认为发送超时，调用 handleTimeout 函数输出超时信息并退出程序。 void SerialPortWriter::handleTimeout() m_standardOutput QObject::tr(Operation timed out for port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 处理发送过程中发生的错误信息。 void SerialPortWriter::handleError(QSerialPort::SerialPortError serialPortError) if (serialPortError == QSerialPort::WriteError) m_standardOutput QObject::tr(An I/O error occurred while writing the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 发送数据将数据发送并判断发送的字节数量，并在接下来的 5 秒内启动定时器，检测数据发送后的 bytesWritten 信号。 void SerialPortWriter::write(const QByteArray writeData) m_writeData = writeData; qint64 bytesWritten = m_serialPort-write(writeData); if (bytesWritten == -1) m_standardOutput QObject::tr(Failed to write the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 else if (bytesWritten != m_writeData.size()) m_standardOutput QObject::tr(Failed to write all the data to port %1, error: %2) .arg(m_serialPort-portName()) .arg(m_serialPort-errorString()) endl; QCoreApplication::exit(1); // 退出程序 m_timer.start(5000); // 启动定时器","categories":["2.语言","Qt"]},{"title":"RS232","path":"/2023/11/30/3-协议-串口-RS232/","content":"RS232 与 RS485 信号类型 RS232 是一种使用共模信号的串行通信标准，适用于短距离数据传输，常见于个人电脑与调制解调器之间的连接。 RS485 则采用差模信号，适合长距离通信，常用于工业自动化系统中的设备间通信，具有更强的抗干扰能力。 DB9 和 DB25 引脚定义 流程打开设备节点打开特定的设备节点是进行串口通信的第一步，可以使用系统调用 open 来实现。例如： int iFd = open(DEV_NAME, O_RDWR | O_NOCTTY); O_RDWR 表示以读写模式打开设备。 O_NOCTTY 表示打开该设备时不把它作为控制终端。 遇到打开失败的情况，可以使用 perror 来打印错误信息。 设置串口配置属性串口设备的配置包括波特率、数据位、校验方式等，可以通过 struct termios 来管理这些设置。配置操作通常包括： 获取当前属性使用 tcgetattr 获取当前串口的配置信息，以便在此基础上进行修改。 设置波特率波特率决定了数据传输速率，通过 cfsetispeed 和 cfsetospeed 设置输入和输出的波特率，例如： cfsetispeed(opt, B115200);cfsetospeed(opt, B115200); 这里设置为 115200 波特率，适合大多数高速设备。 设置数据位数据位通常设置为 8 位，可以通过以下配置实现： opt.c_cflag |= CS8; 设置奇偶校验位将校验位设置为无，以确保数据传输的简单性。通过位操作可以方便地修改相应标志位。 设置控制标志 **本地标志 c_lflag**：通过按位与操作移除某些标志，例如禁止回显。 **输入标志 c_iflag**：通过按位与操作移除一些输入处理设置。 **输出标志 c_oflag**：同样通过按位与操作来清除不必要的输出处理。 控制字符组 c_cc设置最小可读字符数和超时时间，例如： opt.c_cc[VMIN] = 255; // 每次读取至少 255 个字符opt.c_cc[VTIME] = 150; // 超时设置 更新和刷新串口设置在完成配置后，可使用 tcsetattr 更新设置，表示当前的配置立即生效： if (tcsetattr(iFd, TCSANOW, opt) 0) return -1; 调用 tcflush 可清空串口缓冲区，确保发送和接收数据不受干扰。 数据收发的示例代码下面的实例演示了如何发送和接收数据： unsigned char ucBuf[1000];for (int i = 0; i 1000; i++) ucBuf[i] = 0xff - i; // 填充数据write(iFd, ucBuf, 0xff); // 发送数据int len = read(iFd, ucBuf, 0xff); // 接收数据printf(get data: %d , len);for (int i = 0; i len; i++) printf( %x, ucBuf[i]); // 以十六进制方式打印接收到的数据 通过 write 函数向串口发送数据，使用 read 函数接收返回的数据，随后打印出数据的字节数和具体内容。 关闭设备在完成数据收发后，应使用 close 关闭已打开的串口设备以释放资源： close(iFd); 通过这些步骤，可在操作系统中有效地管理串口通信，进行数据的发送和接收。 代码#include stdio.h#include stdlib.h#include unistd.h#include sys/types.h#include sys/stat.h#include fcntl.h#include termios.h#include errno.h#include limits.h#define DEV_NAME /dev/ttyO1int main(void)\tint iFd, i;\tint len;\tunsigned char ucBuf[1000];\tstruct termios opt; iFd = open(DEV_NAME, O_RDWR | O_NOCTTY);\tif(iFd 0) perror(DEV_NAME); return -1; if (tcgetattr(iFd, opt)0) return -1; opt.c_lflag = ~(ECHO | ICANON | IEXTEN | ISIG);\topt.c_iflag = ~(BRKINT | ICRNL | INPCK | ISTRIP | IXON);\topt.c_oflag = ~(OPOST);\topt.c_cflag = ~(CSIZE | PARENB);\topt.c_cflag |= CS8;\topt.c_cc[VMIN] = 255;\topt.c_cc[VTIME] = 150;\tcfsetispeed(opt, B115200);\tcfsetospeed(opt, B115200); if (tcsetattr(iFd, TCSANOW, opt)0) return -1; tcflush(iFd,TCIOFLUSH);\tfor (i = 0; i 1000; i++) ucBuf[i] = 0xff - i; write(iFd, ucBuf, 0xff);\tlen = read(iFd, ucBuf, 0xff);\tprintf(get date: %d , len);\tfor (i = 0; i len; i++) printf( %x, ucBuf[i]); printf( );\tclose(iFd);\treturn 0;","categories":["3.协议","串口"]},{"title":"UART","path":"/2023/11/29/3-协议-串口-UART/","content":"UART 协议概述UART（通用异步收发器）是一种广泛应用于设备间通信的异步串行通信协议。它通过串行方式逐位传输数据，通常用于连接计算机与各种外部设备，如调制解调器、传感器和微控制器等。UART 具有全双工通信能力，意味着数据可以同时在两个方向上传输。 同步串口 USRT同步串口通过专门的时钟信号线来实现数据传输的同步。发送方和接收方依赖于时钟信号将数据流转换为电平信号。这种方式适合需要高数据传输速率和精确时序的应用场景。 异步串口 UART异步串口则不使用共享时钟信号。定位信息包含在电平序列中，通信双方需事先约定数据帧的格式，包括波特率、数据位、停止位和奇偶校验等。线路空闲时，电平为高，一旦检测到下降沿，则视为起始位。接收方根据约定格式接收数据帧，并继续检测下一个起始位。异步串口的同步是以帧为单位的，适用于大多数低速通信场景。 UART 的工作特点数据采样UART 协议是一种低速数据通信标准，典型波特率为 115200 或 9600。UART 字符格式通常包含 1 个起始位、5~8 个数据位、1 个可选的奇偶位和 1 个停止位。由于接收器和发送器异步工作，接收器通常采用对输入数据流的高度采样方式，通常为 16 次采样，以确保数据的准确性。 UART 帧区分在 UART 中，MAX-IDL 参数用于设置空闲字符的数量。UART 控制器会开始计数接收到的空闲字符。如果在接收下一数据字符之前，接收到的空闲字符数量超过 MAX-IDL，则会产生空闲时间，缓冲区被关闭，并向 CPU 发出中断请求。这种机制有助于区分不同的数据帧。 空闲字符的位数计算公式为：1（起始位）+ 数据长度（5、6、7、8）+ 1（若使用奇偶校验）+ 停止位（1）。例如，1 个起始位，8 位数据，无校验，1 个停止位，则空闲字符 MAX-IDL 为 10 位。 UART 地址识别在多站系统中，可能存在多个设备，每个设备都有特定的地址。UART 帧可以扩展一位，以区别地址字符和正常数据字符。UART 支持两种操作模式： 自动多站模式：当地址与预置值匹配时，UART 控制器自动接收随后的数据。 非自动多站模式：UART 控制器接收所有数据，地址字符被写入新的缓冲区。 综上所述，UART 协议通过数据采样来确定位值，具有简单准确的定帧模式，并广泛用于多站系统中，支持自动多站和非自动多站两种模式，以区分地址和数据。 几种重要寄存器在 UART 的工作中，对寄存器的理解和正确配置至关重要。以下是 MPC860 的一些重要寄存器： 管脚配置寄存器：用于设置收发管脚的功能。 波特率配置寄存器：负责配置波特率。 通信处理命令寄存器：用于发出和阻止命令的判断。 SCC 通用模式寄存器：用于选择协议和配置传输格式。 发送和接收缓冲区描述器：用于数据的收发和错误判断。 UART 的特定参数：用于初始化 UART。 SCC 协议专用模式寄存器：用于设置 UART 的多站模式。 事件寄存器：用于判断中断类型。 屏蔽寄存器：用于收发使能。 UART 与 RS-232 和 COM 口UART 是异步串行通信的总称，包括 RS-232、RS-499、RS-423、RS-422 和 RS-485 等接口标准。UART 主要定义了通信口的电气特性、传输速率、连接特性和机械特性。COM 口是 PC 上的异步串行通信口的简称，通常基于 RS-232 标准。 嵌入式开发中的 UART 应用UART 协议广泛应用于嵌入式系统中，支持 RS-232、RS-422、RS-485 串口通信和红外（IrDA）等。UART 的工作原理是逐位传输数据，包含以下几个关键部分： 起始位：发送逻辑”0”信号，表示数据传输开始。 数据位：构成一个字符的数据位，通常为 5 至 8 位。 奇偶校验位：用于校验数据传输的正确性。 停止位：表示字符数据的结束，可以是 1 位、1.5 位或 2 位的高电平。 空闲位：表示线路上没有数据传送，处于逻辑”1”状态。 波特率：衡量数据传送速率的指标，通常以每秒传送的位数表示。 在实际应用中，UART 通过 SCI（串行通信接口）模块进行控制，广泛应用于工控、手机、PC 等设备中。通过合理配置 UART，可以实现高效的数据传输和设备间的通信。 实例UART（Universal Asynchronous Receiver and Transmitter）共有 256 bytesin Ch0 64 bytesin Ch1 and Ch4 16 bytesin Ch2 and Ch3 其中 ch0 和 ch4 有其他特殊作用 Thissection includes UART operationssuch as: Data transmission Data reception Interrupt generation Baud-rate generation Loop-back mode Infrared modes AFC The data frame for transmission is programmable. Itconsists of these bitsthat are specified bythe line control register(ULCONn): A Start bit Five to eight data bits An optional parity bit（校验位） One to two stop bits UART 的实现与代码示例在实现 UART 时，通常需要配置波特率、数据格式和工作模式。以下是一个简单的 UART 初始化和数据发送接收的示例代码： //设置通道工作模式（中断模式/查询模式）//设置数据传输格式//发送数据/接收数据（TXDn-----发送/RXDn-----接受）void serial_init() GPA1.GPA1CON = (GPA1.GPA1CON ~0xFF) | (0x22); // GPA1_0: RX; GPA1_1: TX UART2.ULCON2 = 0x3; // Normal mode, No parity, One stop bit, 8 data bits UART2.UCON2 = 0x5; // Interrupt request or polling mode /* Baud-rate 115200: src_clock: 100MHz * DIV_VAL = (100*10^6 / (115200*16) - 1) = (54.3 - 1) = 53.3 * UBRDIV2 = (Integer part of 53.3) = 53 = 0x35 * UFRACVAL2 = 0.3*16 = 0x5 */ UART2.UBRDIV2 = 0x35; UART2.UFRACVAL2 = 0x5;unsigned char getchar() unsigned char c; while (!(UART2.UTRSTAT2 0X1)); // 等待接收数据 c = UART2.URXH2; // 读取接收到的数据 return c;void putc(const char data) while (!(UART2.UTRSTAT2 0X2)); // 等待发送缓冲区空 UART2.UTXH2 = data; // 发送数据 if (data == ) // 如果发送的是换行符，则发送回车符 putc(\\r);","categories":["3.协议","串口"]},{"title":"基于QSerialPort的串口通信","path":"/2023/11/28/3-协议-串口-基于QSerialPort的串口通信/","content":"初始化定义一个 QSerialPort 类，串口参数的设置应在打开串口之前完成 QSerialPort *ComNodeIns;ComNodeIns = new QSerialPort;ComNodeIns-setBaudRate(/*QSerialPort::Baud115200*/230400);ComNodeIns-setParity(QSerialPort::NoParity);ComNodeIns-setDataBits(QSerialPort::Data8);ComNodeIns-setStopBits(QSerialPort::OneStop);ComNodeIns-setFlowControl(QSerialPort::NoFlowControl);//轮询可用的串口foreach(const QSerialPortInfo info, QSerialPortInfo::availablePorts())\tQString comName = info.portName(); ComNodeIns-setPortName(comName);//设置缓冲区大小// ComNodeIns-setReadBufferSize(6000);//以只读方式打开串口if (ComNodeIns-open(QIODevice::ReadOnly))// ComNodeIns-readAll();//\tconnect(ComNodeIns, SIGNAL(readyRead()), this, SLOT(SlotDataReady()));\t// static QTimer getTimer;\t// connect(getTimer, SIGNAL(timeout()), this, SLOT(SlotDataReady()));\t// getTimer.start(5);//判断串口是否打开if (!ComNodeIns-isOpen())//2.1 open failed\tprintf(%s open Failed ,comName.toLocal8Bit().data());\temit sendNoEquipment();else //2.2 open success\tprintf(%s open OK ,comName.toLocal8Bit().data()); 数据发送-缓冲池发送在多线程情况下，会出现显示发送成功，返回值正常，但是接收端没有接收到数据的情况，该情况的原因是如果线程之中如果使用 while(1) 循环，循环过快，导致 connect 来不及处理数据，所以使用 waitForBytesWrittenwaitForReadyRead 将循环进行阻塞，当有数据读入时取消阻塞，进入下一轮循环。 static int sendIndex = 0;static int sendFailed = 0;//需完整轮询所有缓冲区，保证没有被遗漏的需要发送的数据for(int i=0; iINDEX_OF_BUFF; i++)\tif(sendMsg[i].nodeMutex.tryLock()) if(sendMsg[i].nodeStatus == 1) int Tr = ComNodeIns-write(sendMsg[i].nodeData); ComNodeIns-waitForBytesWritten(5); if(Tr=0) sendFailed++; //总发送失败次数 recvMsg[i].nodeIndex += 1;//存入发送失败次数 else sendIndex++; sendMsg[i].nodeStatus = 0; recvMsg[i].nodeIndex = 0; recvMsg[i].nodeMutex.unlock(); 数据接收-缓冲池接收static int recvIndex = 0;ComNodeIns-waitForReadyRead(1);int Tr = ComNodeIns-bytesAvailable();if(Tr0)\tfor(int i=0; iINDEX_OF_BUFF; i++) if(recvMsg[i].nodeMutex.tryLock()) if(recvMsg[i].nodeStatus == 0) recvMsg[i].nodeStatus = 1; recvMsg[i].nodeData = ComNodeIns-readAll(); recvMsg[i].nodeIndex = recvIndex++; recvMsg[i].nodeMutex.unlock(); return;//将所有数据存入缓冲区后直接跳出循环 recvMsg[i].nodeMutex.unlock(); 数据处理方式-帧头校验/** * @brief SerialPortDriver::SlotDataReady * receive Serial Buffer Content */void SerialPortDriver::SlotDataReady() quint8 *getData_p; quint64 unSize; //unRead bytes in serial buffer bool bCountinue = false; QByteArray baPacket; do //1.detect frame head if (m_bNewCmd)//new msg received while (1) if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE)//msg length longer than head // printf(no msg %d ,ComNodeIns-bytesAvailable()); break;// else // printf(=====================get msg %s ,qPrintable(QDateTime::currentDateTime().toString(HH:mm:ss zzz))); m_readData = ComNodeIns-read(FRAME_HEAD_SIZE);//read msg head getData_p = (quint8 *)(m_readData.data()); if (getData_p[0] == MSG_HEAD getData_p[6] == MSG_HEAD_END)//compare msg head end m_unNeedReadNu = getData_p[4]-FRAME_HEAD_SIZE; m_bNewCmd = false; break; else//drop error msg printf(ERROR: MSG RECEIVE HEADEND FAILED!!! ); // ComNodeIns-read(NULL,1); //2.read full frame unSize = ComNodeIns-bytesAvailable(); if (m_unNeedReadNu0 m_unNeedReadNu = unSize) m_readData.append(ComNodeIns-read(m_unNeedReadNu)); else m_readData.append(ComNodeIns-read(unSize)); m_unNeedReadNu = m_unNeedReadNu - unSize; break; //3.send to message deal module baPacket = m_readData; slotDealFrame(baPacket); m_bNewCmd = true; m_unNeedReadNu = 0; //4.continue read if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE) bCountinue = true; while (bCountinue);","categories":["3.协议","串口"]},{"title":"基于QSerialPort的串口通信","path":"/2023/11/28/2-语言-Qt-基于QSerialPort的串口通信/","content":"初始化定义一个 QSerialPort 类，串口参数的设置应在打开串口之前完成 QSerialPort *ComNodeIns;ComNodeIns = new QSerialPort;ComNodeIns-setBaudRate(/*QSerialPort::Baud115200*/230400);ComNodeIns-setParity(QSerialPort::NoParity);ComNodeIns-setDataBits(QSerialPort::Data8);ComNodeIns-setStopBits(QSerialPort::OneStop);ComNodeIns-setFlowControl(QSerialPort::NoFlowControl);//轮询可用的串口foreach(const QSerialPortInfo info, QSerialPortInfo::availablePorts())\tQString comName = info.portName(); ComNodeIns-setPortName(comName);//设置缓冲区大小// ComNodeIns-setReadBufferSize(6000);//以只读方式打开串口if (ComNodeIns-open(QIODevice::ReadOnly))// ComNodeIns-readAll();//\tconnect(ComNodeIns, SIGNAL(readyRead()), this, SLOT(SlotDataReady()));\t// static QTimer getTimer;\t// connect(getTimer, SIGNAL(timeout()), this, SLOT(SlotDataReady()));\t// getTimer.start(5);//判断串口是否打开if (!ComNodeIns-isOpen())//2.1 open failed\tprintf(%s open Failed ,comName.toLocal8Bit().data());\temit sendNoEquipment();else //2.2 open success\tprintf(%s open OK ,comName.toLocal8Bit().data()); 数据发送-缓冲池发送在多线程情况下，会出现显示发送成功，返回值正常，但是接收端没有接收到数据的情况，该情况的原因是如果线程之中如果使用 while(1) 循环，循环过快，导致 connect 来不及处理数据，所以使用 waitForBytesWrittenwaitForReadyRead 将循环进行阻塞，当有数据读入时取消阻塞，进入下一轮循环。 static int sendIndex = 0;static int sendFailed = 0;//需完整轮询所有缓冲区，保证没有被遗漏的需要发送的数据for(int i=0; iINDEX_OF_BUFF; i++)\tif(sendMsg[i].nodeMutex.tryLock()) if(sendMsg[i].nodeStatus == 1) int Tr = ComNodeIns-write(sendMsg[i].nodeData); ComNodeIns-waitForBytesWritten(5); if(Tr=0) sendFailed++; //总发送失败次数 recvMsg[i].nodeIndex += 1;//存入发送失败次数 else sendIndex++; sendMsg[i].nodeStatus = 0; recvMsg[i].nodeIndex = 0; recvMsg[i].nodeMutex.unlock(); 数据接收-缓冲池接收static int recvIndex = 0;ComNodeIns-waitForReadyRead(1);int Tr = ComNodeIns-bytesAvailable();if(Tr0)\tfor(int i=0; iINDEX_OF_BUFF; i++) if(recvMsg[i].nodeMutex.tryLock()) if(recvMsg[i].nodeStatus == 0) recvMsg[i].nodeStatus = 1; recvMsg[i].nodeData = ComNodeIns-readAll(); recvMsg[i].nodeIndex = recvIndex++; recvMsg[i].nodeMutex.unlock(); return;//将所有数据存入缓冲区后直接跳出循环 recvMsg[i].nodeMutex.unlock(); 数据处理方式-帧头校验/** * @brief SerialPortDriver::SlotDataReady * receive Serial Buffer Content */void SerialPortDriver::SlotDataReady() quint8 *getData_p; quint64 unSize; //unRead bytes in serial buffer bool bCountinue = false; QByteArray baPacket; do //1.detect frame head if (m_bNewCmd)//new msg received while (1) if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE)//msg length longer than head // printf(no msg %d ,ComNodeIns-bytesAvailable()); break;// else // printf(=====================get msg %s ,qPrintable(QDateTime::currentDateTime().toString(HH:mm:ss zzz))); m_readData = ComNodeIns-read(FRAME_HEAD_SIZE);//read msg head getData_p = (quint8 *)(m_readData.data()); if (getData_p[0] == MSG_HEAD getData_p[6] == MSG_HEAD_END)//compare msg head end m_unNeedReadNu = getData_p[4]-FRAME_HEAD_SIZE; m_bNewCmd = false; break; else//drop error msg printf(ERROR: MSG RECEIVE HEADEND FAILED!!! ); // ComNodeIns-read(NULL,1); //2.read full frame unSize = ComNodeIns-bytesAvailable(); if (m_unNeedReadNu0 m_unNeedReadNu = unSize) m_readData.append(ComNodeIns-read(m_unNeedReadNu)); else m_readData.append(ComNodeIns-read(unSize)); m_unNeedReadNu = m_unNeedReadNu - unSize; break; //3.send to message deal module baPacket = m_readData; slotDealFrame(baPacket); m_bNewCmd = true; m_unNeedReadNu = 0; //4.continue read if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE) bCountinue = true; while (bCountinue);","categories":["2.语言","Qt"]},{"title":"IIC总线","path":"/2023/11/27/3-协议-其他-IIC总线/","content":"三轴陀螺仪的芯片 MPU-6050 芯片驱动是采用 IIC 总线协议和处理器进行通信。学习一下 IIC 总线的协议并总结在此： 处理器和芯片间的通信可以形象的比喻成两个人讲话： 说的别人得能听懂：双方约定信号的协议。 的语速别人得能接受：双方满足时序要求。 IIC 协议（传输数据的通道）：两条线可以挂多个设备。（只有主设备具有控制 SCL） 区分设备：IIC 设备里有个固化的地址。只有在两条线上传输的值等于 IIC 设备的地址时，才作出响应。 开始信号：处理器让 SCL 时钟保持高电平，然后让 SDA 数据信号由高变低就表示一个开始信号。同时 IIC 总线上的设备检测到这个开始信号它就知道处理器要发送数据了。 停止信号：处理器让 SCL 时钟保持高电平，然后让 SDA 数据信号由低变高就表示一个停止信号。同时 IIC 总线上的设备检测到这个停止信号它就知道处理器已经结束了数据传输。 再看数据怎么传：SDA 上传输的数据必须在 SCL 为高电平期间保持稳定：因为外接 IIC 设备在 SCL 为高电平的期间采集数据方知 SDA 是高或低电平。SDA 上的数据只能在 SCL 为低电平期间翻转变化。 响应信号（ACK）：处理器把数据发给外接 IIC 设备，如何知道 IIC 设备数据已经收到呢？就需要外接 IIC 设备回应一个信号给处理器。处理器发完 8bit 数据后就不再驱动总线了（SDA 引脚变输入），而 SDA 和 SCL 硬件设计时都有上拉电阻，所以这时候 SDA 变成高电平。那么在第 8 个数据位，如果外接 IIC 设备能收到信号的话接着在第 9 个周期把 SDA 拉低，那么处理器检测到 SDA 拉低就能知道外接 IIC 设备数据已经收到。 IIC 数据从最高位开始传输。 多个设备挂载情况下如何访问其中一个设备而不影响其他设备 用 7bit 表示从地址，那么可以挂载的从设备数是 2 的 7 次方 128 个。处理器想写的话：先发送起始位，再发一个 8bit 数据：前 7bit 表示从地址，第 8bit 表示读或者写。0write 是处理器往 IIC 从设备发，1read 是 IIC 从设备往处理器发。第 9 个时钟周期回复响应信号。下面就以 AT24Cxx 为例详细说明一下： 首先发出一个 start 信号，从设备地址，RW（0，写），回应 ACK 表示有这个从设备存在。这时候是处理器从指定的从设备读数据的从设备里 8bit 存储地址的指定。所以这里 RW 是 0 为写。ACK 回应有这个设备的话，处理器把要访问的从设备里的 8bit 存储地址写好。ACK 对方回应。继续一个 start 信号+从设备地址，最低位是高电平表示读数据，回应 ACK 表示有这个从设备存在。在读数据的时候，每发出一个时钟，处理器会将 SDA 上的数据存起来。那么发出 8 个时钟后处理器就能得到 8 位的数据。这时候若想连续读就不断回应 ACK 信号否则就发出停止信号。 读的过程： start 信号，从设备地址，《写（ack），待读取存储地址（ack）》 start 信号，从设备地址，《读（ack），8 个时钟（no ack）》 从设备就把对应的数据反馈给处理器。 start 信号，从设备地址，写，紧跟连续两个字节的数据：要写的地址，对方收到 8bit 地址后回应 ACK，再 8bit 数据发给从设备，对方收到 8bit 数据后回应 ACK，处理器写完后发送停止信号。","categories":["3.协议","其他"]},{"title":"通讯备注","path":"/2023/11/24/3-协议-其他-通讯备注/","content":"传输方式需要注意传输方式与通讯协议两个概念 485 通讯，232 通讯，这讲的是采用何种传输方式。既然是传输方式，重要就是”传输”两字，不管是 232 还是 485，只是起到传输作用，可以传输 MODBUS 通讯协议信息，也可以传输其他通讯协议信息 MODBUS 通信标准协议可以通过各种传输方式传播，如 232、485 等。工业通讯协议有 modbus,interbus,canbus 等，modbus 分 RTU 和 ASCII，interbus 是串行通讯，是传感器调节器总线系统。canbus 是 real-time 数据总线。 终端电阻光从空气进入水面时，水面从反射回一些光线，这是因为空气与水的媒质不同。光进入不同的媒质时，会在临界点反射。 电信号传输也一样，在传输过程中如果传输末端阻抗突然减小甚至没有，信号就会在此产生反射，这种反射会造成传输线路数据混乱，所以加一个偏置电阻，人为地保持阻抗平衡，减弱信号反射对线路的影响。 波特率波特率是每秒钟传输的数据位数；什么是位数呢？计算机处理的语言是”0”和”1”组合而成的信息，即机器语言。一个”0”或是一个”1”就是一个位； 如果把波特率设为 9600，即一秒钟之内能够传输 9600 个”0”或是”1”，它决定了通讯的数据传输速度。 常用的波特率数值有：2400、4800、9600、19200、38400、57600、115200；其值越大，通讯传输速度越高，那么是不是把波特率的数值设置的越大越好呢？当然不是，它要根据现场传输条件来决定，波特率设置的越大，要承担的通讯失败风险越大。 数据位前面说过，计算机处理的语言是”0”和”1”组合而成的信息，即机器语言。01000001 ，01000010 ，01000011 ，01000100 ，01000101，01000110 。上面一组机器码分别代表的字符是 A，B，C，D，E，F；如 A: 是用 01000001 表示，共八个”0”或”1”，即数据位为八位；数据位的含义：是一个字符可以用多少个位的组合来表示。 设置数据位后，们就知道了数据长度，然后可以根据波特率(9600)计算出传输一个字符 A 需要多少时间。如果数据位设为 8,则：896000.00083 秒即传输一个字符”A”需要 0.83 毫秒的时间（这不是正确的计算，原因在停止位的解释中再论述。） 定义一个标准，方便通讯双方分析。 合法的数据位值：4、5、6、7、8，目前常用的数据位是 8 位与 7 位。 停止位 设置了数据位，就可以正常通讯了吗？不是。接收方何时才知道一个字符传输结束了，这就需要一个停止位，有停止位当然还需要一个起始位来告诉接收方一个字符的传输开始。目前常用的停止位是一位与二位。 还有一个问题，为什么在通讯格式中不用设置起始位？停止位是一个高电平(1)，当接收方接收到连续的高电平时，表示一个字符传输结束。 起始位是一个低电平(0),当接收方接收连续的低电平时，表示下一个字符的传输开始。如果停止位可靠(1 位或是 2 位)，那么干扰造成低电平起始位假象的可能性就不大，所以不用设置起始位。 假如设置停止位为 2，则一个起始位，两个停止位，8 个数据位，总位数为 11。1196000.0011 秒，即传输一个字符”A”需要 1.1 毫秒的时间（这还不是正确的计算，原因在校验方式的解释中再论述。） 校验方式如果抗干扰处理的不理想，在通讯传输过程中，”0”可能会变成”1”，或是将”1”干扰成”0”，造成传输错误。干扰是消除不了的，提高抗干扰能力也只是提高而已，并不能完全防止干扰。所以因为干扰造成的传输错误一定会发生。接收方如何知道接收到字符是否正确呢？解决方式就是加上一个校验，即在传输的数据中再加上一个校验位。 目前所用的校验方式为： 偶校验(even):简单表示为”e” ； 偶校验：如果一个字符中”1”的个数是奇数那么校验位就置为”1”；如果一个字符中”1”的个数是偶数，那么校验位就置为”0”；从而保证总的 1 的个数是偶数；比如设置数据位为 8 位，字符”A”是：0100 0001 其”1”的个数是 2 个，为偶数。那么校验位则为”0” 真正发送的信息为：0100 0001 0 奇校验(odd):简单表示为”o” ； 奇校验：如果一个字符中”1”的个数是偶数，那么校验位就置为 1；如果一个字符中”1”的个数是奇数，那么校验位就置为 0；从而保证总的”1”的个数是奇数；比如设置数据位为 8 位，字符”A”是：0100 0001 其”1”的个数是 2 个，为偶数。那么校验位则为”1” 真正发送的信息为：0100 0001 1 无校验(none):简单表示为”n” ； 无校验：没有校验位； 校验位的作用： 如果在传输过程中，由于干扰将某个”0”变成了”1”，偶校验时，”1” 的个数因为干扰变成奇数，奇校验时，”1” 的个数因为干扰变成偶数，接收方会返回一个奇偶校验错误信息给发送方。比如：当采用奇校验时，发送”A”字符的 0100 0001 1。当传输到接收方，由于干扰变成了 0100 0011 1。接收方接收到四个”1”，是偶数，不符合奇校验的”1”的个数为奇数的规定，所以返回一个奇偶校验错误信息给发送方。 注意：奇偶校验方式不可能完全校验一个字符发送是否正确。比如采用奇校验方式时，发送”A”字符时 0100 0001 1。由于干扰接收方接收到的是 0100 0010 1 (是”B”)。由于只是”1”的位置改变了，”1”的个数还是奇数，虽然发送的是 A，接收到的是 B，但是奇校验还认为是正确的字符；为了解决奇偶校验方式的上述缺陷，每种标准协议都会要求校验和计算，比如 MODBUS 通讯协议的 RTU 方式是 CRC 校验计算； MODBUS 通讯协议的 ASCII 方式是 LRC 校验计算； 有些朋友对于奇偶校验 与 校验和计算 这两个概念分不清楚。 奇偶校验：判断一个字符传输的是否正确； 校验和： 判断一组字符传输的是否正确； 通讯格式为：9600，o，8，2。一个起始位，八个数据位，一个校验位，两个停止位，总位数为 12。1296000.00125 秒，传输一个字符”A”需要 1.25 毫秒的时间；这个计算值才是最后的理论计算值。可以大致评估传输一组字符需要的时间。当然，选用无校验方式，计算传输方式不需要加上校验位。","categories":["3.协议","其他"]},{"title":"Qt的socket通信","path":"/2023/11/23/3-协议-网络-Qt的socket通信/","content":"在 Qt 中执行收发工作较为耗时或交互频率较高的时候，为了使得通信过程不造成 UI 的卡顿现象，一般要求通信工作在次线程（子线程）中完成。 将 Qt 套接字对象移动到次线程，并在主线程中直接调用套接字接口，此时存在 “以其他线程对象为父对象，在本线程创建子对象” 的告警。 定义一个 workker 类对象，将其移动到次线程中，由其负责对 m_socket 套接字对象的操作，包括使用套接字进行连接、断开、数据发送等操作。套接字对象没有进行过 moveToThread 操作，其还是归属于创建它的主线程，但相关函数调用线程却为所在的次线程。 在多线程情况下需要注意，线程的构造函数和 run 函数所隶属的线程是不一致的，如果在构造函数中初始化节点时，会出现警告 QSocketNotifier: socket notifiers cannot be enabled from another thread 套接字的相关接口只能在套接字对象所属的线程内调用（如果套接字对象没有执行过 moveToThread 操作，那么套接字对象的所属线程就是创建它的线程）。因此，如果想支持在次线程中执行连接断开服务、数据收发过程，则必须的要将套接字对象本身进行 moveToThread 操作，且要将其他线程对该对象的操作转换到 moveToThread 后的线程内。 //.h#pragma once#include QTcpSocket//该对象最终运行在次线程中class TcpClient : public QTcpSocket Q_OBJECTpublic: TcpClient(QObject *parent = NULL); ~TcpClient();public: // void ClientConnectToHost(const QString address, quint16 port); // void ClientSendingData(const QByteArray c_btaData); // bool IsOnline();signals: //转换来自主线程的链接操作 void SignalConnectToHost(const QString address, quint16 port);signals: //转换来自主线程的发送操作 void SignalSendingData(const QByteArray c_btaData);signals: //在次线程中缓冲并滑动解析TCP流后/按约定格式再发布 void SignalPublishFormatRecvData(const QString c_btaData);private: //标记连接情况 bool m_bOnLine = false; //缓冲收到的流数据 QByteArray m_btaReceiveFromService;; //.cpp#include QThread#include QDebug#include QHostAddress#include tcp_client.hTcpClient::TcpClient(QObject *parent) : QTcpSocket(parent) //自动连接在信号发射时被识别为队列连接/信号在主线程发射 connect(this, TcpClient::SignalConnectToHost, this, [](const QString address, quint16 port) //test record# in child thread id 20588 qDebug(SlotConnectToHost ThreadID:%d, QThread::currentThreadId()); // connectToHost(QHostAddress(address), port, QIODevice::ReadWrite); , Qt::AutoConnection); //连接了TCP服务端 connect(this, QAbstractSocket::connected, this, []() //test record# in child thread id 20588 qDebug(SlotHasConnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = true; , Qt::DirectConnection); //断开了TCP服务端 connect(this, QAbstractSocket::disconnected, this, []() //test record# in child thread id 20588 qDebug(SlotHasDisconnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = false; , Qt::DirectConnection); //收到了TCP服务的数据 connect(this, QIODevice::readyRead, this, []() //test record# in child thread id 20588 qDebug(SlotIODeviceReadyRead ThreadID:%d, QThread::currentThreadId()); //读取全部数据 m_btaReceiveFromService.append(this-readAll()); // int iFindPos = m_btaReceiveFromService.indexOf(\\r ); //检查分隔符 while (-1 != iFindPos) //分割数据流 QString strPublish = m_btaReceiveFromService.left(iFindPos); //发布解析后的格式数据 emit SignalPublishFormatRecvData(strPublish); // m_btaReceiveFromService.remove(0, iFindPos + strlen(\\r )); // iFindPos = m_btaReceiveFromService.indexOf(\\r ); , Qt::DirectConnection); //执行数据发送过程 connect(this, TcpClient::SignalSendingData, this, [](const QByteArray c_btaData) //test record# in child thread id 20588 qDebug(SlotSendingData ThreadID:%d, QThread::currentThreadId()); // this-write(c_btaData); , Qt::AutoConnection);//TcpClient::~TcpClient()//跨线程转换void TcpClient::ClientConnectToHost(const QString address, quint16 port) emit SignalConnectToHost(address, port);//跨线程转换void TcpClient::ClientSendingData(const QByteArray c_btaData) emit SignalSendingData(c_btaData);//是否在线bool TcpClient::IsOnline() return m_bOnLine; //main /using of my tcp clientUpdateCamera::UpdateCamera(QWidget *parent) : QMainWindow(parent) //创建TCP客户端 m_pmyTcpSocket = new TcpClient(); // m_pThreadSending = new QThread(); // m_pmyTcpSocket-moveToThread(m_pThreadSending); // m_pThreadSending-start(); //连接到相机的TCP服务 connect(ui.pushButton_connect, QPushButton::clicked, []() ... m_pmyTcpSocket-ClientConnectToHost(strIPUsing, SER_PORT); ); //文件发送 connect(ui.pushButton_file_sending, QPushButton::clicked, []() ... //执行客户端文件发送过程 m_pmyTcpSocket-ClientSendingData(DataOfBin); ); //接收服务端发送的数据 /从子线程到主线程的队列连接 connect(m_pTcpClient, TcpClient::SignalPublishFormatRecvData, this, [](const QString c_btaData) ui.textEdit-append(c_btaData); ui.textEdit-moveCursor(QTextCursor::End); if (ui.textEdit-toPlainText().size() 2 * 1024 * 1024) ui.textEdit-clear(); , Qt::AutoConnection); QIODevice::readyRead 信号的 DirectConnection 连接的 lambda 槽函数执行结果，可得出：如果一个 Tcp 对象被归属到了子线程 X 中，那么 readyRead 信号最终将从此子线程 X 发出。connected 信号、disconnected 信号等其发射线程，都是套接字对象的所在线程。 当 connect 内部使用 lambda 表达式做槽函数时，注意选择有 Qt::ConnectionType 参数的那个函数版本，否则将默认为直接连接。 //默认为直接连接connect(const QObject *sender, PointerToMemberFunction signal, Functor functor)//可以配置连接方式 //Qt::UniqueConnections do not work for lambdasconnect(const QObject *sender, PointerToMemberFunction signal, const QObject *context, Functor functor, Qt::ConnectionType type) 默认的连接方式 Qt::AutoConnection 在 connect 后生效的时刻是 emit 发射的时候，而不是执行 connect 语句的时候。因此先执行 moveToThread 还是先执行 connect 过程是无关紧要的。具体可参见帮助文档中提及的：If the receiver lives in the thread that emits the signal, Qt::DirectConnection is used. Otherwise, Qt::QueuedConnection is used. The connection type is determined when the signal is emitted.","categories":["3.协议","网络"]},{"title":"Qt的socket通信","path":"/2023/11/23/2-语言-Qt-Qt的socket通信/","content":"在 Qt 中执行收发工作较为耗时或交互频率较高的时候，为了使得通信过程不造成 UI 的卡顿现象，一般要求通信工作在次线程（子线程）中完成。 将 Qt 套接字对象移动到次线程，并在主线程中直接调用套接字接口，此时存在 “以其他线程对象为父对象，在本线程创建子对象” 的告警。 定义一个 workker 类对象，将其移动到次线程中，由其负责对 m_socket 套接字对象的操作，包括使用套接字进行连接、断开、数据发送等操作。套接字对象没有进行过 moveToThread 操作，其还是归属于创建它的主线程，但相关函数调用线程却为所在的次线程。 在多线程情况下需要注意，线程的构造函数和 run 函数所隶属的线程是不一致的，如果在构造函数中初始化节点时，会出现警告 QSocketNotifier: socket notifiers cannot be enabled from another thread 套接字的相关接口只能在套接字对象所属的线程内调用（如果套接字对象没有执行过 moveToThread 操作，那么套接字对象的所属线程就是创建它的线程）。因此，如果想支持在次线程中执行连接断开服务、数据收发过程，则必须的要将套接字对象本身进行 moveToThread 操作，且要将其他线程对该对象的操作转换到 moveToThread 后的线程内。 //.h#pragma once#include QTcpSocket//该对象最终运行在次线程中class TcpClient : public QTcpSocket Q_OBJECTpublic: TcpClient(QObject *parent = NULL); ~TcpClient();public: // void ClientConnectToHost(const QString address, quint16 port); // void ClientSendingData(const QByteArray c_btaData); // bool IsOnline();signals: //转换来自主线程的链接操作 void SignalConnectToHost(const QString address, quint16 port);signals: //转换来自主线程的发送操作 void SignalSendingData(const QByteArray c_btaData);signals: //在次线程中缓冲并滑动解析TCP流后/按约定格式再发布 void SignalPublishFormatRecvData(const QString c_btaData);private: //标记连接情况 bool m_bOnLine = false; //缓冲收到的流数据 QByteArray m_btaReceiveFromService;; //.cpp#include QThread#include QDebug#include QHostAddress#include tcp_client.hTcpClient::TcpClient(QObject *parent) : QTcpSocket(parent) //自动连接在信号发射时被识别为队列连接/信号在主线程发射 connect(this, TcpClient::SignalConnectToHost, this, [](const QString address, quint16 port) //test record# in child thread id 20588 qDebug(SlotConnectToHost ThreadID:%d, QThread::currentThreadId()); // connectToHost(QHostAddress(address), port, QIODevice::ReadWrite); , Qt::AutoConnection); //连接了TCP服务端 connect(this, QAbstractSocket::connected, this, []() //test record# in child thread id 20588 qDebug(SlotHasConnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = true; , Qt::DirectConnection); //断开了TCP服务端 connect(this, QAbstractSocket::disconnected, this, []() //test record# in child thread id 20588 qDebug(SlotHasDisconnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = false; , Qt::DirectConnection); //收到了TCP服务的数据 connect(this, QIODevice::readyRead, this, []() //test record# in child thread id 20588 qDebug(SlotIODeviceReadyRead ThreadID:%d, QThread::currentThreadId()); //读取全部数据 m_btaReceiveFromService.append(this-readAll()); // int iFindPos = m_btaReceiveFromService.indexOf(\\r ); //检查分隔符 while (-1 != iFindPos) //分割数据流 QString strPublish = m_btaReceiveFromService.left(iFindPos); //发布解析后的格式数据 emit SignalPublishFormatRecvData(strPublish); // m_btaReceiveFromService.remove(0, iFindPos + strlen(\\r )); // iFindPos = m_btaReceiveFromService.indexOf(\\r ); , Qt::DirectConnection); //执行数据发送过程 connect(this, TcpClient::SignalSendingData, this, [](const QByteArray c_btaData) //test record# in child thread id 20588 qDebug(SlotSendingData ThreadID:%d, QThread::currentThreadId()); // this-write(c_btaData); , Qt::AutoConnection);//TcpClient::~TcpClient()//跨线程转换void TcpClient::ClientConnectToHost(const QString address, quint16 port) emit SignalConnectToHost(address, port);//跨线程转换void TcpClient::ClientSendingData(const QByteArray c_btaData) emit SignalSendingData(c_btaData);//是否在线bool TcpClient::IsOnline() return m_bOnLine; //main /using of my tcp clientUpdateCamera::UpdateCamera(QWidget *parent) : QMainWindow(parent) //创建TCP客户端 m_pmyTcpSocket = new TcpClient(); // m_pThreadSending = new QThread(); // m_pmyTcpSocket-moveToThread(m_pThreadSending); // m_pThreadSending-start(); //连接到相机的TCP服务 connect(ui.pushButton_connect, QPushButton::clicked, []() ... m_pmyTcpSocket-ClientConnectToHost(strIPUsing, SER_PORT); ); //文件发送 connect(ui.pushButton_file_sending, QPushButton::clicked, []() ... //执行客户端文件发送过程 m_pmyTcpSocket-ClientSendingData(DataOfBin); ); //接收服务端发送的数据 /从子线程到主线程的队列连接 connect(m_pTcpClient, TcpClient::SignalPublishFormatRecvData, this, [](const QString c_btaData) ui.textEdit-append(c_btaData); ui.textEdit-moveCursor(QTextCursor::End); if (ui.textEdit-toPlainText().size() 2 * 1024 * 1024) ui.textEdit-clear(); , Qt::AutoConnection); QIODevice::readyRead 信号的 DirectConnection 连接的 lambda 槽函数执行结果，可得出：如果一个 Tcp 对象被归属到了子线程 X 中，那么 readyRead 信号最终将从此子线程 X 发出。connected 信号、disconnected 信号等其发射线程，都是套接字对象的所在线程。 当 connect 内部使用 lambda 表达式做槽函数时，注意选择有 Qt::ConnectionType 参数的那个函数版本，否则将默认为直接连接。 //默认为直接连接connect(const QObject *sender, PointerToMemberFunction signal, Functor functor)//可以配置连接方式 //Qt::UniqueConnections do not work for lambdasconnect(const QObject *sender, PointerToMemberFunction signal, const QObject *context, Functor functor, Qt::ConnectionType type) 默认的连接方式 Qt::AutoConnection 在 connect 后生效的时刻是 emit 发射的时候，而不是执行 connect 语句的时候。因此先执行 moveToThread 还是先执行 connect 过程是无关紧要的。具体可参见帮助文档中提及的：If the receiver lives in the thread that emits the signal, Qt::DirectConnection is used. Otherwise, Qt::QueuedConnection is used. The connection type is determined when the signal is emitted.","categories":["2.语言","Qt"]},{"title":"Socket套接字","path":"/2023/11/22/3-协议-网络-Socket套接字/","content":"Socket 最初是作为网络上不同主机之间进程的通信接口，后来应用越来越广，在同一主机上的不同进程之间通信也可以用 Socket。 简单来说，当网络上不同主机之间的两个进程（A、B）采用 Socket 进行通信时，那么它们之间需要建立一个通信端点，即创建 Socket，创建 Socket 时就分配端口号和网络地址。当进程 A 向进程 B 发送数据时，进程 A 必须要知道进程 B 的网络地址及端口号。 Socket 采用 CS 模型进行设计的，即 ClientServer，面向客户端—服务器模型。 每一个 Socket 都用一个半相关描述： {协议，本地地址，本地端口} 一个完整的 Socket 则用一个相关描述: {协议，本地地址，本地端口，远程地址，远程端口} 套接字套接字，另外一种进程间通信的方式。之前的 IPC 机制只能限定在一台计算机系统上进行资源共享。而套接字接口可以使，一台机器上的进程和另外一个机器上的进程通信。 什么是套接字套接字是一种通信机制，凭借这种机制，客户服务器系统的工作即可以在本地单机上工作，也可以跨网络进行。 套接字和管道类型，同样是读写类文件描述符的操作。不同的是，套接字明确的将客户和服务器分开来。套接字机制可以实现多个客户连接一个服务器。 套接字连接首先，服务器应用程序使用 socket 来创建一个套接字，它是系统分配给该服务器进程的类似文件标识符的资源，它不能与其它进程共享。ps：线程貌似也不行。 接下来，服务器进程会给套接字起个名字。本地套接字的名字是 Linux 文件系统中的文件名。对于网络套接字，它的名字是与客户连接的特定网络有关的服务标识符（端口号或访问点）。这个标识符将允许 Linux 将进入针对特定端口号的连接转接到正确的服务器进程。例如：Web 服务器一般在 80 端口上创建有关套接字，这是一个专用于此目的的标识符。Web 浏览器知道对于用户想访问的 Web 节点，应该使用端口 80 来建立 HTTP 连接。 用系统调用 bind 来给套接字命名(关联于本地某个文件)然后服务器进程就开始等待客户连接这个命名套接字。系统调用 listen 的作用是，创建一个队列并将其用于存放来自客户的请求连接。服务器通过系统调用 accept 来接受客户的连接。服务器调用 accept 时，它会创建一个与原来的命名套接字不同的新套接字。这个套接字只用来与这个特定客户进行通信，而命名套接字则被保留下来继续处理来自其它客户的连接。 基于套接字系统的客户端更加简单。客户首先调用 socket 创建一个未命名套接字，然后将服务器的命名套接字作为一个地址（或标识符）来调用 connect 与服务器建立连接。 一旦连接建立，就可以想使用底层的文件描述符那样用套接字来实现双向的数据通信。 套接字属性套接字的特性有 3 个属性确定，它们是：域（domain）、类型（type）和协议（protocol） 套接字的域域指定套接字通信中使用的网络介质。 最常见的套接字域是 AF_INET,它指的是 Internet 网络。许多 Linux 局域网使用的都是此网络。 还有一个域是 UNIX 文件系统域 AF_UNIX,即使一台还未联网的计算机上的套接字也可以使用这个域。这个域的底层协议就是文件输入输出，而它的地址就是文件名。当运行这个程序时，就可以在当前目录下看到这个地址。 服务器计算机上可能有多个服务器正在运行。客户可以通过 IP 端口来指定一台机器上某个特定服务。在系统内部，端口通过分配一个唯一的 16 位的整数来标识，在系统外部，则需要通过 IP 地址和端口号的组合来确定。套接字作为通信的终点，它必须在开始通信之前绑定一个端口。知名的服务通常也有一些端口，比如 ftp（21）和 httpd（80）等。在选择端口时不要随意选择以避免端口被占用的情况。一般情况下，小于 1024 的端口号都是为系统服务保留的。 套接字类型一个套接字域可能有多种不同的通信方式，而每种通信方式又有其不同的特性。但 AF_UNIX 域的套接字没有这样的问题，它提供了一个可靠的双向通信路径。在网络域中，就需要注意底层网络的特性，以及不同的通信机制是如何受到它们的影响。 因特网提供了两种通信机制：流（stream）和数据包（datagram）。他们有着截然不同的服务层次。 流套接字 流套接字（在某些方面类似于标准输入输出流）提供的是一个有序、可靠、双向字节流的连接。ps：使用 TCP 中的序号机制保证大的消息将被分片、传输、再重组。这很像一个文件流，它接受大量的数据，然后以小数据块的形式将它们写入底层磁盘。 流套接字由底层 SOCK_STREAM 指定，它们是在 AF_INET 域中通过 TCPIP 连接实现。 TCPIP 代表的是传输控制协议（Transmission Control Protocol）网际协议（Internet Protocol）。IP 协议是针对数据包的底层协议，它提供一台计算机通过网络到达另一台计算机的路由。TCP 协议提供排序、流控和重传，以保证大数据的传输可以完整地到达目的地或报告一个适当的错误条件。 数据报套接字 与流套接字相反，由类型 SOCK_DGRAM 指定的数据报套接字不建立和维持一个连接。它对可以发送的数据报的长度有限制。数据报作为一个单独的网络消息被传输，它可能丢失、复制或无序到达。 数据报套接字在 AF_INET 域中通过 UDPIP 连接实现，它提供的是一种无序的不可靠服务。但从资源的角度来看，相对来说它们开销比较小，因此不需要维护网络连接。而且不需要花费时间来建立连接，所以它们的速度也很快。 数据包适用于信息服务中的”单次（single-shot）”查询，它主要用来提供日常状态信息或执行低优先级的日志记录。服务器的奔溃不会给客户造成不便，也不会要求客户重启。 字节流套接字（SOCK_STREAM）字节流的套接字可以提供可靠的数据传输、面向连接的通讯流。数据按何种顺序发送，就按何种顺序接收。例如，当按顺序发送 A-B-C，那么在数据到达接收端时，它的顺序也是 A-B-C。字节流套接字采用的是 TCP（Transmission Control Protocol）协议。保证了数据传输的可靠性。 数据报套接字（SOCK_DGRAM）数据报套接字定义了一种无连接的服务。所谓无连接服务，简单来说，即在发送数据时，无需在收发两端建立类似 TCP 那样的握手连接，在发送时，将数据打包，然后加上远程 IP 地址，即可把该数据包发送出去。 数据通过相互独立的报文进行传输。并且是无序的、不可靠的传输。 原始套接字（SOCK_ROW）先启动服务器，通过调用 socket() 函数建立一个套接字，然后调用 bind() 函数将该套接字和本地网络地址联系在一起，再调用 listen() 函数使套接字做好侦听的准备，并规定它的请求队列的长度，之后就调用 accept() 函数来接收连接。 客户端在建立套接字之后就可调用 connect() 和服务器建立连接。 连接一旦建立，客户端和服务器之间就可以通过调用 recv()recvfrom() 函数和 send()sendto 函数来进行发收数据。 最后，待数据传送结束后，双方调用 close() 函数关闭套接字。 套接字协议暂时使用默认值。 创建套接字socket 系统调用创建一个套接字并返回一个描述符，该描述符可以用来访问该套接字。 int socket(int domain, int type, int protocol); 创建的套接字是一条通信线路的一个端点。domin 指定协议族，type 指定这个套接字的通信类型，protocol 指定使用的协议。 参数 domain 的取值包括：AF_UNIX 和 AF_INET 前者用于 UNIX 和 Linux 文件系统实现本地套接字，后者用于 UNIX 网络套接字，通过包括因特网在内的 TCPIP 网络进行通信的程序。 参数 type 取值包括：SOCK_STREAM 和 SOCK_DGRAM protocol：通常不需要选择，将该参数设为 0 表示使用默认协议。 套接字地址每个套接字域都有其之间的地址格式。 在 AF_UNIX 域中，套接字的地址由结构 sockaddr_un 来表示，该结构定义在头文件 sysun.h 中。 struct sockaddr_un sa_family_t sun_family; /*AF_INET*/ char sun_path[]; /*pathname*/; 在 AF_UNIX 域中，套接字的地址由 char sun_path[]指定。 在 AF_INET 域中，套接字的地址由 sockadd_in 来指定。该结构定义在 netinetin.h 中，它至少包括以下几个成员： struct sockaddr_in short int sin_family; /*AF_INET*/ unsigned short int sin_prot; /*Port number*/ struct in_addr sin_addr; /*Internet address*/;struct in_addr unsigned long int s_addr；； 命名套接字要想让 socket 创建的套接字可以被其它进程使用，服务器程序就必须给该套接字命名，即将套接字关联到一个文件系统的路径名。 int bind(int sockfd,const struct sockaddr * address,siz_t address_len); bind 系统调用 address 的地址值与文件描述符 socket 的未命名套接字相关联。地址结构体的长度由 address_len 传递。 传入参数时需要将一个特定的地址结构体指针（struct sockaddr_inun）转换为执行通用地址类型(struct sockaddr)。成功返回 0，失败返回-1 并设置 errno 创建套接字队列为了接受多个套接字（客户端）的连接，服务器程序必须创建一个队列来保存未处理的请求。它用 listen 系统调用来完成这一操作。 int listen(int socket,int backlog); arg1：命名套接字，arg2：队列的最大长度，即等待处理进入的客户端个数，超过则导致客户端请求失败。与 bind 返回相同，成功返回 0，失败返回-1 并设置 errno 接受连接accept 系统调用来等待客户建立对该套接字的连接。 int accept(int socket, struct sockaddr * address, size_t *address_len); accept 系统调用只有当客户端试图连接到由 socket 参数指定的套接字上时才返回。这里的客户指，在套接字队列中排在第一个的未处理连接。 套接字必须先由 bind 调用关联一个文件系统的路径名（即为套接字命名），然后由 listen 调用为其分配一个连接队列。 连接客户的地址将被放到 address 参数指向的 sockaddr 结构中。如果不关心客户端的地址，则将其值设为 NULL 即可。 参数 address_len 指定客户结构的长度。如果客户地址的长度超过这个值，它将被截断。 如果套接字队列中没有未处理的连接。accept 将堵塞直到有客户建立连接为止。可以通过对套接字描述符设置 O_NONBLOCK 标志来改变这一行为，使用函数 fcntl。 int flags = fcntl(socket,F_GETFL,0);fcntl(socket,F_SETFL,O_NONBLOCK | flags) 当有未处理的客户连接时，accept 函数将返回一个新的套接字描述符。发送错误时，返回-1 并设置 errno 请求连接客户程序通过一个未命名的套接字和服务器监听套接字之间建立连接的方法来连接到服务器。使用 connect 调用 int connect(int sockfd, const struct sockaddr *address, size_t address_len); 参数 socket 指定的套接字将连接到参数 address 指定的服务器套接字，address 指向的结构的长度有参数 address_len 指定。 参数 sockfd 指定的套接字必须通过 socket 调用获得一个有效的文件描述符。成功返回 0，失败返回-1，设置 errno。 如果连接不能立刻建立，connect 调用将被堵塞一段不确定的超时时间。一旦超时时间到达，连接将被放弃，connect 调用失败。但如果 connect 调用被一个信号中断，而该信号又得到了处理，connect 还会失败。 关闭套接字使用 close 函数来终止服务器和客户上的套接字连接，就如同对底层文件描述符进行关闭一样。应该总是在连接的两端都关闭套接字。对于服务器来说，应该在 read 调用返回为 0 即没有数据可读的情况下关闭套接字，但如果有一个套接字是一个面向连接类型的，并且设置了 SOCK_LINGER 选项，close 调用会在该套接字 还有未传输数据时堵塞。此举，需要设置套接字选项。 套接字通信文件系统套接字的缺点是，除非程序员使用一个绝对路径名，否则套接字将创建在服务器的工作目录下。 为了接受客户的连接，需要创建一个服务器及客户都可访问的全局目录（如：tmp 目录）。 而对网络套接字来说，只需要选择一个未被使用的端口号即可。 其它端口号及通过他们提供的服务通常都列在系统文件etcservices 中，在选择端口号，注意不好选择在该配置文件中的端口号。 其实也不用看，没有那么好的运气能碰到，只要选择端口号在 3000 以上，应该就没事。 出于演示的目的，将使用这个回路网路（一个只包含它自身的回路（loopback）网路）。回路网络对于调试网络应用程序很有用处，因为它排除了任何外部网络问题。回路网路中只包含一台计算机，传统上它被称为 localhost，标准地址：127.0.0.1。 每一个与计算机进行通信的网路都有一个与之关联的硬件接口。一台计算机可能在每个网络中都有一个不同的网路名。当然也就会有几个不同的 IP 地址。 主机字节序和网络字节序在 Linux 机器上运行新版本的服务器和客户端时，可以用 netstat 命令来查看网路连接情况。 $ netstat -A inetActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 localhost:9741 localhost:51246 TIME_WAIT 现在可以看到这条对应的服务器和客户的端口号。 Local Address 一栏显示的服务器的地址和端口号，Foreign Address 一栏显示的远程客户的地址和端口号。 可是，当在程序中选择的端口为 3366 时，在命令中输出的却是 9741.为什么不同呢？ 答案是：通过套接字传递的端口号和地址都是二进制数字。不同的计算机使用不同的字节序来表示整数。 比如：Inter 处理器采用小端字节序和网络传输采用的大端字节序。大端字节序意思为数据的地址随之内存的地址变大而变大。 为了使不同类型的计算机可以通过网络传输的多个字节整数的值达成一致，需要定义一个网络字节序。客户和服务器程序必须在传输前，将它们的内部整数表示方式转化为网络字节序。通过以下函数实现： unsigned long int htonl(unsigned long int hostlong);unsigned short int htons(unsigned short int hostshort);unsigned long int ntohl(unsigned long int netlong);unsigned short int ntohs(unsigned short int netshort); 这些函数将 16 位和 32 位整数在主机字节序和标准的网络字节序之间进行转换。函数名是与之对应的转换操作的简写形式。如果计算机本身的主机字节序和网络字节序相同，这些操作的实际上就是空操作。 转换之后的 netstat 操作。 $ netstat -A inetActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 localhost:3366 localhost:34411 TIME_WAIT 为了让不同体系结构的计算机上的客户和服务器可以正确的操作，总是在网络程序中使用这些转换函数是很有必要的。 网络信息到目前为止，的客户和服务器程序一直是把地址和端口号编译到程序的内部。对于一个更通用的服务器和客户程序来说，可以通过网络信息函数来决定应该使用的地址和端口。 如果有足够的权限，可以将自己的服务添加到etcservices 文件中的已知服务列表中，并在这个文件中为端口号分配一个名字，使用户可以使用符号化的服务名而不是端口号的数字。 类似的，如果给定一个计算机的名字，可以通过调用解析地址的主机数据库函数来确定它的 IP 地址。这些函数通过查询网络配置文件来完成这一工作，如ecthosts 文件或网络信息服务。常用的网络信息服务有 NIS（Network Information Service，网络信息服务，以前叫 Yellow Pages，黄页服务）和 DNS（Domain Name Service，域名服务） 主机数据库函数在接口头文件 netdb.h 中声明。 struct hostent *gethostbyaddr(const void *addr, size_t len, int type);struct hosten *gethostbyname(const char *name); 这些函数返回的数据结构中至少会包含以下几个成员： struct hostent char *h_name; /* official name of host */ char **h_aliases; /* alias list */ int h_addrtype; /* host address type */ int h_length; /* length of address */ char **h_addr_list; /* list of addresses */ 如果没有查询的主机或地址有关的数据项，这些信息函数将返回一个空指针。 类似的，与服务及其关联端口号有关的信息也可以通过一些服务信息函数来获取。 struct servent *getservbyname(const char *name,const char *proto);struct servent *getservbyport(int port,const char *proto); proto 参数指定用于连接服务的协议，它有两个取值 tcp 和 udp，前者用于 SOCK_STREAM 类型的 TCP 连接，后者用于 SOCK_DGRAM 类型的 UDP 数据报。 返回的数据结构中至少会包含以下几个成员： struct servent char * s_name; /* name of the service*/ char ** s_aliases; /* list of aliases*/ int s_port; /* The IP port number*/ char *s_proto; /* The service type, usually tcp or udp */; 如果想获得某台计算机上的主机数据库信息，可以调用那个 gehostbyname 函数并且将结果打印出来。注意，要将返回的地址列表信息转化为正确的 IP 地址类型，需用函数 int_ntoa 将它们从网络字节序转成主机字节序的字符串后打印出来。 char *inet_ntoa(struct in_addr in); 这个函数的作用是，将有关因特网主机地址转化为一个点分四元组格式的字符串。失败时返回-1，但 POSIX 规范未定义错误类型。 最后一个函数：gethostname，得到主机的名称 int gethostname(char *name, int legth); 这个函数的作用，将当前主机的主机的名字写入 name 指向的字符串中。主机名将以 NULL 结尾。参数 length 指定了字符串 name 的长度，如果返回的主机名太长，它就会被截断。调用成功返回 0，失败返回-1，适当的设置 errno 编写一个连接到标准服务的程序：使用 gethostbyname 得到主机的 IP 地址，getservbyname 得到服务的端口，最后使用 connect 请求服务。 多客户目标：如何让单个服务器进程在不堵塞、不等待客户请求到达的前提下处理多个客户。 select 系统调用在编写 Linux 应用程序时，经常会遇到需要检查好几个输入的状态才能确定下一步行动的情况。如果是在一个单用户系统中，运行一个”忙等待”循环还是可以接受的，它不停地扫描输入设备看是否有数据，如果有数据到达就读取它。但这种做法很消耗 CPU 的时间。 select 系统调用允许程序同时在多个底层文件描述符上等待输入的到达（或输出的完成）。这意味着程序可以一直堵塞到有事情可做为止。类似的，服务器也可以通过同时在多个打开的套接字上等待请求到来的方法来处理多个客户。 select 函数对数据结构 fd_set 进行操作，它是由打开的文件描述符而构成的集合。 有一组定义好的宏来控制这个集合。 void FD_ZERO(fd_set *fdset);void FD_CLR(int fd, fd_set *fdset);void FD_SET(int fd, fd_set *fdset);int FD_ISSET(int fd, fd_set *fdset); 顾名思义，FD_ZERO 用于将 fd_set 初始化为空集合，FD_SET，FD_CLR 就是添加和删除由 fd 传入到集合中文件描述符。 如果 FD_ISSET 宏中参数 fd 属于 fd_set 中一个元素，FD_ISSET 宏将返回非零值。 fd_set 结构中可以容纳的文件描述符的最大数目有常量 FD_SETSIZE 指定。 select 函数通过一个超时值来防止无限期的堵塞。这个超时值由一个 timeval 结构给出。这个结构定义在头文件 systime.h 中，它由以下几个成员组成： struct timeval time_t tv_sec; /* seconds */ long tv_usec; /* microseconds */; 类型 time_t 在头文件 systypes.h 中被定义一个整数类型。 select 系统调用的原型为： int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *except, struct timeval *timeout); select 调用用于测试文件描述符集合中，是否有一个文件描述符已处于可读，可写或其它状态，之后它将堵塞以等待某个文件描述符进入上述状态。 参数 nfds 指定需要测试的文件描述符的数目，测试的描述符范围从 0 到 nfds-1。3 个文件描述符都设为 NULL，表示不执行对应测试。 select 函数会在发生以下情况时返回：readfds 可读，writefds 可写，exceptfds 相应（不知道什么时候会出现以下情况，旧版中定义为出错时。）如果这三种情况都没有发送，函数将在 timeval 指定的一段超时时间后返回，如果 timeval 参数是一个空而且套接字上也没有进入那三种状态，调用将一直堵塞下去。 当 select 返回时，描述符集合将被修改以指示哪些描述符正处于可读、可写或其它状态。 然后使用 FD_ISSET 对描述符进行测试，来找出需要处理的描述符。如果 select 是因为超时而返回的，所有的描述符集合将被清空。 select 调用成功将返回发生变化的描述符总数，出错返回-1 并设置 errno。 多客户服务器可以让 select 调用同时检查监听套接字和客户的连接套接字。一旦 select 调用指示有活动发生，就可以使用 FD_ISSET 来遍历，所有连接的文件描述符，以检查是哪个套接字上面活动发生。 如果是套接字可读的话，这说明正有一个客户请求连接，即服务器使用 socket 函数创建的套接字描述符有活动，此时就可以调用 accept 函数接受客户端的连接，如果是某个客户套接字描述符活跃，一个客户需要服务端进行读写操作。如果读操作返回 0 则表明有一个客户进程已经结束，可以关闭套接字并把它从描述符集合中删除。 数据包在有些情况下，在程序中花费时间来建立和维持一个套接字连接是不必须要的。 当用户需要一个短小的数据查询并期望接受到一个短小的相应时，一般就使用 UDP 提供的服务。例如主机上的 daytime 服务。 因为 UDP 提供的是不可靠服务，所以可以会发现数据包或响应会丢失。如果数据包对于来说非常重要，就需要小心编写 UDP 程序，以检查错误并在必要是重传。 使用 UDP 数据包是，需要使用 sendto 和 recvfrom 来代替原有使用在套接字上的 read 和 write 调用。 sendto 系统调用从 buffer 缓冲区中给使用指定套接字地址的目标服务器发送一个数据包。 int sendto(int sockfd, void *buffer, size_t len, int flags, struct sockaddr *to, socklen tolen); 在正常调用中，flags 参数一般被设置为 0. recvfrom 系统调用在套接字上等待从特定地址到来的数据包，并将它放入 buffer 缓冲区。 int recvfrom(int sockfd, void *buffer, size_t len, int flag, struct sockaddr *to, socklen fromlen); 在正常调用中，flags 参数一般被设置为 0. 两个函数的调用，成功返回操作的字符数，错误返回-1，并设置 errno 通过以上函数可以创建出一个 UDP 服务器，一个使用 sendto 函数发数据，一个使用 recvfrom 函数接数据。另外通过使用 setsocketopt 函数来设置套接字描述符的超时情况。也可以采用使用 sigaction 信号访问的方式来实现","categories":["3.协议","网络"]},{"title":"TCP和UDP","path":"/2023/11/21/3-协议-网络-TCP和UDP/","content":"握手分析ClientSend：SYN + seq100 ServerSend：SYN + ACK + seq200 + ack101 ClientSend：ACK + ack201 TCP 连接建立在 TCPIP 协议中，TCP 协议提供可靠的连接服务，采用三次握手建立一个连接。 服务器必须准备好接受外来的连接。这通过调用 socket、 bind 和 listen 函数来完成，称为被动打开(passive open)。 第一次握手：客户通过调用 connect 进行主动打开(active open)。这引起客户 TCP 发送一个 SYN（表示同步）分节（SYNJ），它告诉服务器客户将在连接中发送到数据的初始序列号。并进入 SYN_SEND 状态，等待服务器的确认。 第二次握手：服务器必须确认客户的 SYN，同时自己也得发送一个 SYN 分节，它含有服务器将在同一连接中发送的数据的初始序列号。服务器以单个字节向客户发送 SYN 和对客户 SYN 的 ACK（表示确认），此时服务器进入 SYN_RECV 状态。 第三次握手：客户收到服务器的 SYN+ACK。向服务器发送确认分节，此分节发送完毕，客户服务器进入 ESTABLISHED 状态，完成三次握手。 分析 客户端的初始序列号为 J，而服务器的初始序列号为 K。在 ACK 里的确认号为发送这个 ACK 的一端所期待的下一个序列号。因为 SYN 只占一个字节的序列号空间，所以每一个 SYN 的 ACK 中的确认号都是相应的初始序列号加 1.类似地，每一个 FIN（表示结束）的 ACK 中的确认号为 FIN 的序列号加 1.完成三次握手，客户端与服务器开始传送数据，在上述过程中还有一些重要概念。未连接队列：在三次握手协议中，服务器维护一个未连接队列，该队列为每个客户端的 SYN 包(synj)开设一个条目，该条目表明服务器已收到 SYN 包，并向客户发出确认，正在等待客户端确认包。这些条目所标识的连接在服务器处于 SYN_RECV 状态，当服务器收到客户端确认包时，删除该条目，服务器进入 ESTABLISHED 状态。 TCP 连接终止TCP 连接终止需四个分节。 第一次握手：某个应用进程首先调用 close，称这一端执行主动关闭。这一端的 TCP 于是发送一个 FIN 分节，表示数据发送完毕。 第二次握手：接收到 FIN 的另一端执行被动关闭（passive close）。这个 FIN 由 TCP 确认。它的接收也作为文件结束符传递给接收端应用进程（放在已排队等候应用进程接收到任何其他数据之后） 第三次握手：一段时间后，接收到文件结束符的应用进程将调用 close 关闭它的套接口。这导致它的 TCP 也发送一个 FIN。 第四次握手：接收到这个 FIN 的原发送端 TCP 对它进行确认。 面向字节的数据传送流（如 TCP 字节流、Unix 管道等）也使用 EOF 表示在某个方向上不再有数据待传送。在 TCP 字节流中，EOF 的读或写通过收发一个特殊的 FIN 分节来实现。 TCP 服务器 Server 创建套接字 socket 绑定 IP，PORTbind 设置监听套接字 listen 等待建立连接 accept 收发数据 read/write recv/send recvfrom/sendto 关闭连接 close TCP 客户端 Client 创建套接字 socket 绑定 bind 建立连接 connect 收发数据 read/write 关闭连接 close UDP 服务器 Server 创建套接字 socket 绑定地址 接收数据 发送数据 UDP 客户端 Client 创建套接字 socket 发送数据 接收数据","categories":["3.协议","网络"]},{"title":"套接字的超时检测","path":"/2023/11/20/3-协议-网络-套接字的超时检测/","content":"网络通信中，很多操作会使得进程阻塞，这时们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 通过 setsockopt 设置套接字属性 SO_RCVTIMEOstruct timeval t = 5, 0 if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, t, sizeof(t)) == -1) perror(setsockopt); return -1; memset(peeraddr, 0, sizeof(peeraddr)); len = sizeof(peeraddr); if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) printf(errno=%d: %s , errno, strerror(errno)); if (errno == EAGAIN) printf(timeout ); return -1; 设定 select 函数的一个参数实现超时处理struct timeval t= 3, 0; while (1) 。。。。。。 t.tv_sec = 3; t.tv_usec = 0; if ((ret = select(maxfd+1, rdfs, NULL, NULL, t)) == -1) perror(select); return -1; 。。。。。。 设定一个定时器捕捉 SIGALRM 信号做超时控制struct sigaction act; sigaction(SIGALRM, NULL, act); //获取SIGALRM信号的属性 act.sa_handler = handler; // 设置SIGALRM信号的处理函数 sigaction(SIGALRM, act, NULL); // 设置SIGALRM信号的属性 alarm(3); // 定时器设置3秒钟 while (1) if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) if (errno == EINTR) printf(timeout ); return -1; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["3.协议","网络"]},{"title":"16-8禁食软件架构设计","path":"/2023/11/17/4-软件-0杂项-16-8禁食软件架构设计/","content":"介绍这个应用程序旨在帮助用户记录每日的禁食时间，以确保实现稳定、健康的十六小时禁食计划。 奖励机制为了鼓励用户坚持禁食，应用可以提供多种奖励机制。例如，当用户连续一周达成目标时，可以解锁特定的健康食谱，或是获得积分，这些积分能够兑换成商品或服务。此外，用户还可以分享自己的成就，获得社交平台的赞赏和反馈，增强保持禁食习惯的动力。 功能记录 开始计时：用户只需点击一个按钮便可启动计时器，记录禁食的起始时间。 结束计时：再次点击同一按钮可停止计时器，这使得用户能够轻松地监控禁食的持续时间。 在使用过程中，如果应用意外退出，系统会妥善记录这一中途退出情况，确保用户在下次启动时能够顺利续写禁食时间。 当程序启动时，它会自动读取上次的计时状态和禁食日志。这意味着如果用户没有结束禁食状态，应用会根据中间经过的时间继续计时，从而维持一贯的禁食周期。 若用户想要重新开始禁食，应用会首先检查日志中是否已经记录了当天的禁食时间。如果当天有记录且不想覆盖，计时将不会启动。反之，如果用户选择覆盖，之前的禁食时间将被清除，系统将重新启动定时器。 例如，当用户在 “2023-07-26 10:10:10” 点击开始计时后，应用将开始记录当前的禁食状态。 在用户想要结束计时时，系统会停止计时器，并将当前的时间、禁食时间及状态进行记录，比如： 记录格式为 “2023-07-26 10:10:30 0”，表示结束计时并显示当前时间和状态。 最终，应用将保存当前日期及禁食时间，如 “2023-07-26 0 0 20”，这代表禁食持续了 20 分钟。 查询用户可以随时查询到每日的禁食时间。系统会保存每日的禁食数据，并在发现重复记录时提供弹窗提示，帮助用户选择最有效的数据进行查看。 查询时，用户可以根据点击的日期查看对应的禁食时长，这样能够让用户清晰了解自己的坚持情况。 此外，应用会形象化地显示出用户的禁食进度。禁食达到目标时，表格中的状态将以绿色标识；未达到时，则以红色标识，以便于用户快速识别自己的表现。 目标用户可以轻松设定每日的禁食目标，并实时查看目标达成情况。表格将清楚地展示每日设定的目标与目前的达成状态，帮助用户防止懈怠并鼓励持续进步。 设置用户能够根据个人健康需求设置每日的禁食时长。同时，应用支持手动设立目标，允许用户根据自身情况灵活调整禁食计划，增强个性化体验。","categories":["4.软件","0杂项"]},{"title":"ETF小助手功能更新","path":"/2023/11/16/4-软件-0杂项-ETF小助手功能更新/","content":"管理功能，添加删除 计算功能，今日估值，持仓成本， 显示功能，显示当前估值和成本比较 历史记录，显示历史曲线 10 日20 日等均线 【×】北向资金实现方式 API 实时涨跌https://fundgz.1234567.com.cn/js/007345.js?v=20200908175500 数字为基金代码，rt 为时间戳， /*****功能：获取基金实时信息，天天基金数据接口：http://fundgz.1234567.com.cn/js/基金代码.js传入：基金代码输出：基金实时信息 -- dictfundcode -- 基金代码name -- 基金名称jzrqv -- 上一交易日dwjz -- 基金净值（截止上一交易日）gsz -- 估算净值（实时）gszzl -- 估算涨幅（实时）gztime -- 更新时间（实时）******/jsonpgz( fundcode: 007345, name: : 富国科技创新灵活配置混合, jzrq: 2020-09-17, dwjz: 1.9441, gsz: 1.9717, gszzl: 1.42, gztime: 2020-09-18 15:00); 基金净值数据http://fund.eastmoney.com/f10/F10DataApi.aspx?type=lsjzcode=007345page=1per=49sdate=2020-09-01edate=2020-09-18 基金列表http://fund.eastmoney.com/js/fundcode_search.js 返回数据 var r = [ [ 000001, HXCZHH, 华夏成长混合, 混合型, HUAXIACHENGZHANGHUNHE ], [ 000002, HXCZHH, 华夏成长混合(后端), 混合型, HUAXIACHENGZHANGHUNHE ]] 基金详情http://fund.eastmoney.com/pingzhongdata/007345.js?v=20200908175500 基金公司列表http://fund.eastmoney.com/js/jjjz_gs.js 返回数据 var gs= op: [ [ 80163340, 安信基金 ], [ 80036782, 招商基金 ] ] 基金增幅排名http://fund.eastmoney.com/data/rankhandler.aspx?op=phdt=kfft=gprs=gs=0sc=zzfst=descsd=2016-03-29ed=2017-03-29qdii=tabSubtype=,,,,,pi=1pn=50dx=1v=0.6370068000914493 ft： fund type 类型 所有-all 股票型-gp 混合型-hh 债券型-zq 指数型-zs 保本型-bb QDII-qdii LOF-lof 当前基金净值http://fundgz.1234567.com.cn/js/[基金代码].js?rt=[时间戳] （其中时间戳 rt 用于避免浏览器缓存数据，可省略）。 例如，http://fundgz.1234567.com.cn/js/001186.js，返回的结果类似于：jsonpgz({“fundcode”:”001186”,”name”:”富国文体健康股票”,”jzrq”:”2022-09-20”,”dwjz”:”1.9300”,”gsz”:”1.9187”,”gszzl”:”-0.58”,”gztime”:”2022-09-21 15:00”});。这是一个文本数据，需要进一步处理。可以使用 Python 中的 requests、re、json 等库进行处理，将文本转化为字典格式，以便提取所需信息，代码示例如下： import requestsimport jsonimport redef realtmfundinfo(fundcode): fund_id = fundcode real_time_url = fhttp://fundgz.1234567.com.cn/js/fund_id.js org_content = requests.get(real_time_url) fund_info = org_content.text fund_info = re.findall(r\\.+\\, fund_info) fund_info = json.loads(fund_info[0]) return fund_infofund_info = realtmfundinfo(001186)print(fund_info) 历史基金净值http://fund.eastmoney.com/pingzhongdata/[基金代码].js?v=[时间戳] （时间戳 v 可省略）。 例如，http://fund.eastmoney.com/pingzhongdata/001186.js，可获取该基金的申购费率、持仓股票、历史单位净值、历史累计净值等多个信息。返回基金的净值日期（date）、单位净值（nav）、累计净值(cumnav)、净值回报率(equityReturn)、每份派送金(unitMoney).处理返回的文本数据的 Python 代码示例如下： import requestsimport jsonimport reimport pandas as pddef htrfundinfo(fundcode): fund_id = fundcode history_tmurl = fhttp://fund.eastmoney.com/pingzhongdata/fund_id.js org_content = requests.get(history_tmurl) fund_info = org_content.text # 提取单位净值 temp_nav = re.findall(rdata_networthtrend\\s=\\s(\\(\\.+\\\\));\\/\\*累计净值走势\\*\\/, fund_info)[0] temp_nav = json.loads(temp_nav) temp_nav = pd.DataFrame(temp_nav) temp_nav.rename(columns=x:date,y:nav, inplace=True) n = len(temp_nav[date]) for i in range(n): temp_nav[date][i] = time.strftime(%y-%m-%d, time.localtime(temp_nav[date][i]/1000.)) temp_nav = temp_nav.set_index(date) # 提取累计净值 temp_cumnav = re.findall(rdata_acworthtrend\\s=\\s(\\(.+\\));\\/\\*累计收益率走势\\*\\/, fund_info)[0] temp_cumnav = eval(temp_cumnav) return temp_navfund_nav = htrfundinfo(001186)print(fund_nav)","categories":["4.软件","0杂项"]},{"title":"Shodan","path":"/2023/11/15/4-软件-0杂项-Shodan/","content":"ShodanShodan 是一种独特的搜索引擎，专门用来查找互联网上在线设备。这与 Google 等传统搜索引擎不同，因为 Google 主要用于搜索网页内容，而 Shodan 可以根据设备类型如 webcams、linksys、cisco、netgear 以及 SCADA 系统等进行具体搜索。用户能通过 Shodan 搜索指定的设备或特定类型的设备，查找目标设备在互联网上的状态与信息。 如需在 Windows 系统上访问 Shodan，只需打开以下链接：Shodan Shodan 工作原理Shodan 的工作原理是基于主动扫描网络。在其架构中，Shodan 会定期扫描互联网中的设备，收集各种设备返回的 banner 信息。这些 banner 信息通常涵盖设备类型、软件版本以及其他网络附属信息。Shodan 利用这些数据，能够分析出网络中最常用的 Web 服务器类型、可匿名登录的 FTP 服务器数量，或者对应 IP 地址的设备类型等。例如，通过分析数据，Shodan 可能会得出在某一地理区域，某款路由器的市场占有率和活跃度。 Shodan 的使用在 Shodan 的搜索界面，用户可以在左上角输入关键字进行搜索。搜索结果随后会显示，在界面上可以看到如下信息： Results map：可视化搜索结果的地图，帮助用户了解地理分布。 **Top services (Ports)**：显示使用频率最高的服务和端口，例如，端口 80 和 443 通常与网页服务有关。 **Top organizations (ISPs)**：列出最多的组织或互联网服务提供商（ISP）。 Top operating systems：显示网络中最常见的操作系统，如 Windows、Linux 等。 在主页面中，用户可以浏览具体的搜索结果。每个条目下方都有 details 按钮，点击后可查看更详尽的信息。此外，通过点击 Exploits，Shodan 将帮助查找针对不同平台和设备的可利用漏洞。还可以访问 Shodan Exploits，进行进一步的漏洞研究。用户也可以通过 Maps 选项查看设备的地理分布。 如果有需要生成报告的需求，可以选择 Create Report 功能。同时，点击 Explore 则能查看其他用户使用最多的搜索项。 当直接使用关键字搜索未能达到预期结果时，可以运用以下搜索过滤命令进行精细化搜索。 使用搜索过滤以下是 Shodan 中可用的搜索过滤命令： hostname：搜索特定主机或域名，如 hostname:google port：搜索某一端口或服务，如 port:21，常见用于 FTP 服务。 country：以国家为条件过滤，如 country:CN。 city：可按城市搜索，如 city:Hefei。 org：按组织或公司过滤，如 org:google。 isp：按 ISP 过滤，如 isp:China Telecom。 product：针对操作系统、软件或平台进行搜索，如 product:Apache httpd。 version：搜索特定软件版本，例：version:1.6.2。 Kali 中安装 ShodanShodan 提供了一个官方的 Python 库，用于简化其在 Kali Linux 中的使用。安装命令如下： git clone https://github.com/achillean/shodan-python.git cd shodan-pythonpython setup.py install 常用命令 alert：管理账户的网络提示。 convert：转换输入数据文件。 count：返回搜索结果的数量。 download：下载搜索结果并保存到文件。 honeyscore：检查一个 IP 是否属于蜜罐。 host：查看某个 IP 的所有可用详细信息。 info：显示账户的基本信息。 init：初始化 Shodan 命令行工具。 myip：打印用户的外部 IP 地址。 初始化 Shodan 与数据处理在使用之前，通过以下命令启动 Shodan： shodan init API_Key 统计查询结果的数量： shodan count SSH 下载查询结果并保存。例如，下载新搜索到的微软 IIS 6.0 的数据： shodan download microsoft-data microsoft iis 6.0 下载的文件将包含 JSON 格式存储的目标 banner 信息。默认情况下，此命令仅会下载 100 条结果，若想获取更多，需要申请升级账户。 解析下载的数据，以获取例如 IP 地址、端口、组织等信息： shodan parse --fields ip_str,port,org --separator , microsoft-data.json.gz 使用 Shodan 扫描给定的 IP 或网段： shodan scan IP/NETBLOCK 利用 Shodan 查找数据： shodan search microsoft iis 6.0 这里的查询结果在命令行中直接显示，默认包括 IP、端口号、主机名和 HTTP 数据。用户也能自定义显示字段，比如只显示 IP 地址、端口号、组织名称和主机名： shodan search --fields ip_str,port,org,hostnames microsoft iis 6.0","categories":["4.软件","0杂项"]},{"title":"云电脑性能","path":"/2023/11/14/4-软件-0杂项-云电脑性能/","content":"参数 海马云 ToDesk 网易云游戏 腾讯 START 海星云 顺网云电脑 极云普惠云电脑 云 (电脑游戏) 名称 海马云 ToDesk 网易云游戏 腾讯 START 海星云 顺网云电脑 极云普惠云电脑 运行平台 PC安卓 PC安卓 PC安卓TV PC安卓TV PC安卓TV pc安卓 pc安卓ios 游戏库 500+ 自带游戏 排队严重 WeGame 游戏居多 300+ 200+ 200+ 配置 12700kf+4090 8 核 16 线程+RTX 3060 高端配置 10 代 i5+RTX 3070 12 代 i5+407010 代 i5+2060s 10 代 i5+206012 代 i5+3060Ti 或 4070 最高卡支持 4090 3060 未知 3070 4070 4070 默认支持最高分辨率 4K 2K 144Hz 未知 1080p 4K 2K 1080p 内存 64G32G 32G 未知 依赖云端配置 32G 32G 32G16G 延迟 低 低 未知 超低 低 低 中 资费 2.4 元小时 420~1020 金币小时 1.98 ~ 3.6 元小时 180 云币小时 未知 4 ~ 6 元小时 1.6 ~ 4 元小时 2.7 ~ 4 元小时（冲 50 ） 综合评分 ⭐⭐⭐ ⭐⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ 主页网址 海马云 ToDesk 网易云游戏 腾讯START 海星云 顺网云电脑 极云普惠云电脑 青椒云 支持 PC安卓IOS 另有不适用于游戏服务或者可能服务已经关闭的尚未介绍的有以下平台： 虎牙 YOWA 云游戏 达龙云游戏 咪咕快游 蘑菇云游戏 易云咖 领沃云游戏 小悟云 鲸云游戏 菜鸡云游戏 天翼云游戏 国外有 参数 GeForce NOW Xbox Cloud Gaming Shadow Amazon Luna PlayStation Plus Boosteroid 网易云游戏 腾讯 START 云游戏名称 GeForce NOW Xbox Cloud Gaming (xCloud) Shadow Amazon Luna PlayStation Plus Premium Boosteroid 网易云游戏 腾讯 START 运行平台 PCMacAndroidiOS智能电视 XboxPCAndroidiOS PCMacAndroidiOS PCMacAndroidiOSFire TV PS4PS5PC PCMacAndroidiOS AndroidiOSPC AndroidiOSPC 游戏库 1500+ 350+ 自带游戏 100+ 800+ 400+ 100+ 100+ 最高分辨率 4K60fps 1080p60fps 4K60fps 1080p60fps 1080p60fps 1080p60fps 1080p60fps 1080p60fps 延迟 低 低 低 中 低 中 未知 低 功能 游戏跨平台同步 游戏跨平台同步 完整 PC 体验 游戏Twitch 集成 游戏PS 独占 游戏 游戏 游戏 月费 (美元) $9.99-$19.99 $14.99 (Game Pass Ultimate) $29.99 $9.99 $17.99 $9.99 ¥59 (~$8) 按时计费 数据中心 全球 30+ 全球 26 个地区 美国欧洲 美国 未公开 欧洲北美 中国 中国 综合评分 910 8.510 810 7.510 810 7.510 710 710 注意: 评分和部分技术细节可能因个人体验和网络条件而异。 价格可能会随时间变化,建议查看最新官方定价。 游戏库数量可能会随时间增减,数据仅供参考。","categories":["4.软件","0杂项"]},{"title":"基于Qt的RSS阅读器开发","path":"/2023/11/13/4-软件-0杂项-基于Qt的RSS阅读器开发/","content":"什么是 RSSRSS 语法 channel 元素 描述 category 可选的。为 feed 定义所属的一个或多个种类。 cloud 可选的。注册进程，以获得 feed 更新的立即通知。 copyright 可选。告知版权资料。 description 必需的。描述频道。 docs 可选的。规定指向当前 RSS 文件所用格式说明的 URL。 generator 可选的。规定用于生成 feed 的程序。 image 可选的。在聚合器呈现某个 feed 时，显示一个图像。 language 可选的。规定编写 feed 所用的语言。 lastBuildDate 可选的。定义 feed 内容的最后修改日期。 link 必需的。定义指向频道的超链接。 managingEditor 可选的。定义 feed 内容编辑的电子邮件地址。 pubDate 可选的。为 feed 的内容定义最后发布日期。 rating 可选的。feed 的 PICS 级别。 skipDays 可选的。规定忽略 feed 更新的天。 skipHours 可选的。规定忽略 feed 更新的小时。 textInput 可选的。规定应当与 feed 一同显示的文本输入域。 title 必需的。定义频道的标题。 ttl 可选的。指定从 feed 源更新此 feed 之前，feed 可被缓存的分钟数。 webMaster 可选的。定义此 feed 的 web 管理员的电子邮件地址。 item 元素 描述 author 可选的。规定项目作者的电子邮件地址。 category 可选的。定义项目所属的一个或多个类别。 comments 可选的。允许项目连接到有关此项目的注释（文件）。 description 必需的。描述此项目。 enclosure 可选的。允许将一个媒体文件导入一个项中。 guid 可选的。为项目定义一个唯一的标识符。 link 必需的。定义指向此项目的超链接。 pubDate 可选的。定义此项目的最后发布日期。 source 可选的。为此项目指定一个第三方来源。 title 必需的。定义此项目的标题。 RSS 阅读器功能文字**字体** **字号** **背景** **翻页** 图片**缩放** **移动** **下载** 视频**播放/暂停** **快进** **进度条** **音量** **下载** 设置**订阅** **自动/手动同步** 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式eg. https://rsshub.app/6v123/latestMovies 6v123_latestMovies eg. https://rsshub.app/t66y/20/2 t66y_20_2 页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["4.软件","0杂项"]},{"title":"应用软件开发流程","path":"/2023/11/10/4-软件-0杂项-应用软件开发流程/","content":"从软件工程的角度看，嵌入式应用软件的开发拥有一定的生命周期。整个过程包括需求分析、系统设计、代码编写、调试和维护等阶段。在这些阶段，软件工程中的多个理论同样适用嵌入式应用软件的开发。然而，与其他通用软件相比，嵌入式软件的开发具有显著的独特性： 需求分析阶段必须考虑硬件性能的影响。嵌入式系统的功能实现往往依赖于特定的硬件设备。例如，如果目标是开发一个图像处理的嵌入式系统，需确保所选硬件能够满足图形处理的性能需求。 在系统设计阶段，重心转向任务的划分及其接口，而不是模块的划分。模块的划分则在任务设计阶段进行。这意味着在确定如何实现系统的具体功能时，必须首先分析任务之间的关系和交互。 调试时，采用交叉调试方式。这是一种在硬件和软件共同测试的环境下，针对目标系统进行调试的方法，能够有效检查软件在实际硬件上的表现。 软件调试完成后，固化到嵌入式系统中，后期的维护工作相对较少。这种特性使得嵌入式软件的更新和修复操作变得更加集中和规范。 需求分析在这一阶段，分析需求后形成需求说明，主要聚焦系统的功能需求，包括： 系统功能：详细列出所有实现的功能，比如控制电机、传感器信号采集等。 系统输入与输出：明确系统接受的数据类型和格式，以及生成的输出结果。 外部接口需求：如用户界面、与其他系统的交互方式等，确保用户能够方便地操控系统。 性能要求：关于响应时间、处理速度及安全性等方面的具体要求，例如，是否需要满足某一特定的实时性标准。 在实时系统中，常用状态变迁图（State Transition Diagram）来描述系统。在设计状态图时，需详尽考虑各个系统运行状态，尽量将所有可能的状态列出来，包括许多用户不需了解的内部状态，并针对异常情况制定相应处理措施。 同时，需清晰描述人机接口，即操作员与系统之间的交互。这种交互对用户的操作体验至关重要。比如，对于复杂的系统，编写操作手册显得极为必要，提供精准的操作步骤，使用户能够快速上手使用系统。状态变迁图和操作手册脚本的结合，有助于让系统说明更加清晰明了。 在分析系统功能后，决定所用的硬件和软件平台。硬件平台的考虑因素包括： 微处理器的处理速度和内存空间大小。 外部扩展设备是否满足功能要求。例如，数量和种类的传感器是否足够支撑运算。 微处理器对外部事件的响应速度是否满足实时性要求和其稳定性。 对于软件平台，需要关注的内容包括操作系统的实时性支持程度、多任务管理能力、网络功能等与所选硬件的兼容性。此外，开发环境的丰富程度和使用便利性也是关键因素。显然，成本始终是决策的重要因素，嵌入式 Linux 因其高性价比受到广泛青睐。 任务和模块划分在需求分析完成，确定系统功能后，接下来的步骤是进行任务划分。每个任务的本质是一段无限循环的代码，是受到竞争资源控制的最小运行单元。合理的任务划分会大幅提高系统的运行效率、实时性和吞吐量。 任务划分时应遵循以下步骤和原则： 进行数据流分析：在功能需求的基础上，使用数据流图分析系统的数据流情况，识别主要子系统和其组成部分。 划分任务：识别出系统所有功能及其数据流后，需要判断哪些功能可并行执行，哪些功能则需串行操作。并行的功能通常属于不同的任务，而串行的则可纳入同一任务中。 划分任务时需考虑： IO 依赖性：功能变换如依赖于 IO 设备，其运行速度会受到限制，需作为独立任务。 功能的时间关键性：时间敏感的功能需优先处理，不应与其他任务混合执行。 计算需求：进行大量计算但时间要求不紧迫的任务可以设置为低优先级。 功能内聚性：紧密相关的功能应作为一个任务，以减少通信开销。 周期执行：定期执行的任务应被设计为独立任务。 定义任务接口：任务划分之后，明确各任务间的接口，确保数据格式及访问方式的具体化。通常由任务间通信模块和任务同步互斥模块来处理接口问题。通信模块负责任务间的数据传递，需确保数据一致性的同步和互斥。 软件开发流程软件开发流程分为多个阶段： 需求确认：创建需求规格说明书，确保所有需求被准确记录和理解。 概要设计：利用系统用例图和用例场景描述系统的高层设计。 详细设计：撰写系统设计报告及数据库设计报告，详细描述每个模块的实现逻辑。 编码：实现设计文档中确定的逻辑。 单元测试、集成测试、系统测试：逐步验证代码的正确性和系统的完整性。 维护：对软件进行必要的更新和修复。 详细设计详细设计的核心任务是确保每个模块的实现算法逻辑正确，并使其描述清晰易懂。详细设计应包括： 确定各模块的实现算法，选择适当工具表示算法过程。 确定模块所需的数据结构。 详细界定模块接口，包括外部用户界面和其他模块的接口。 编写每个模块的测试用例以确保代码符合预期。 在详细设计中使用的工具包括： 图形工具：用图形表示过程细节，如程序流程图等。 表格工具：用表格列出操作与条件。 语言工具：使用伪码等高级语言描述过程细节。 这些工具的结合使用能有效提升详细设计的质量，让开发者和其他利益相关者更好地理解软件功能与实现细节。","categories":["4.软件","0杂项"]},{"title":"游戏架构","path":"/2023/11/09/4-软件-0杂项-游戏架构/","content":"solarRTS 的设计架构 目标类 地图类 生产类 子弹类 主程序 关卡得分基础属性 游戏窗口加载 地图绘制 坐标点初始化 友军加载 敌军加载 子弹加载 事件加载 开始游戏 结束游戏 玩法 长按屏幕弹出菜单，创建","categories":["4.软件","0杂项"]},{"title":"论文下载方法","path":"/2023/11/08/4-软件-0杂项-论文下载方法/","content":"浙江省公共资源门户网址： https://zjisa.zjlib.cn/home/zy_home.jsp 登录后进入 知网数据库总站（含会议、博硕论文） 万方数据库本地镜像（含学位、会议论文）等模块下载 上海研发公共服务平台网址： https://lib.sgst.cn/ 登录后选择文献服务，基于万方数据 进入个人中心后签到赠送积分用于下载文献 其他浙江图书馆网址： https://www.zjlib.cn/ 上海图书馆网址： https://www.library.sh.cn/#/index 绍兴图书馆网址： https://www.sxlib.com/jypxwgzy/index.htm 贵州数字图书馆网址： https://www.gzlib.org/","categories":["4.软件","0杂项"]},{"title":"软件随手记","path":"/2023/11/07/4-软件-0杂项-软件随手记/","content":"工具软件：utools 图床：PicGo 终端：MobaXterm RSS 阅读：Lettura 磁盘空间分析：SpaceSniffer 重复文件清除：Duplicate Cleaner Pro 5 笔记软件：Obsidian 搜索软件： Archivarius 3000 设置索引目录，支持 txt／pdf／word／xls／ppt /azw3／epub／mobi／md 等常见文档 压缩包内文档的搜索 Everything grep -r PDF 翻译：彩云小译（网页） https://fanyi.caiyunapp.com 翻译软件：deepL 视频播放软件 VLC 项目地址： https://github.com/videolan/vlc CuteMarkEd 基于 Qt5 开发,一款开源免费的 Markdown 编辑器，项目地址 https://github.com/cloose/CuteMarkEd 每日菜单 项目地址 https://github.com/YunYouJun/cook 下载软件 Aria2 和 AriaNG AriaNG 是 mayswind 大神做的一个前端界面 aria2 是命令行下载工具 下载一个 bt 任务或者磁力链手动增加 tracker 列表，列表地址 https://github.com/ngosang/trackerslist 手机 ed2k 转存pikpak Photoprism 安卓应用程序 playmods.netapkmody.ioplatinmods.comgamekillerapp.commoddroid.comgamedva.comjojoy.iomodded-1.comandroeed.ru","categories":["4.软件","0杂项"]},{"title":"4.打印控制命令","path":"/2023/11/06/4-软件-3D打印-4-打印控制命令/","content":"https://reprap.org/wiki/G-code G 代码命令Klipper 支持以下标准的 G-Code 命令： 移动 (G0 or G1): G1 [Xpos] [Ypos] [Zpos] [Epos] [Fspeed]驻留：G4 P毫秒返回原点：G28 [X] [Y] [Z]关闭步进电机：M18或M84等待当前移动完成： M400使用绝对/相对挤出距离：M82， M83使用绝对/相对坐标：G90, G91设置坐标：G92 [X坐标] [Y坐标] [Z坐标] [E坐标]设置速度因子覆写百分比：M220 S百分比设置挤压因子覆盖百分比：M221 Spercent设置加速度：M204 Svalue 或 M204 Pvalue Tvalue注意：如果没有指定S，同时指定了P和T，那么加速度将被设置为P和T中的最小值。获取挤出机温度：M105设置挤出机温度：M104 [Tindex] [Stemperature]设置挤出机温度并等待：M109 [Tindex] Stemperature。注意：M109总是等待温度稳定在请求的数值上。设置热床温度：M140 [Stemperature]设置热床温度并且等待：M190 Stemperature注意：M190总是等待温度稳定在请求的数值上。设置风扇速度：M106 Svalue停止风扇：M107紧急停止：M112获取当前位置：M114获取固件版本：M115 限位开关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令： QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确，如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） [stepper_X]endstop_pin: ^PE5 #修改前endstop_pin: ^!PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令 PID_CALIBRATE HEATER=heater_bed TARGET=100 它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速 M106 S64 ，然后发送命令 PID_CALIBRATE HEATER=extruder TARGET=245 它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。 GCode 协议指令Klipper G-Code 协议指令 https://www.klipper3d.org/G-Codes.html marlin G-Code 协议指令 https://marlinfw.org/meta/gcode/ 部分使用到的命令 命令 用途 M112 使 Klipper 进入 “shutdown”（关闭）状态 FIRMWARE_RESTART 重新加载配置文件并重启 SAVE_CONFIG 保存配置文件 GET_POSITION 获取位置 ps -ef | grep klippy 查看使用的 printer.cfg 文件位置 QUAD_GANTRY_LEVEL 调平","categories":["4.软件","3D打印"]},{"title":"3.上位机平台配置","path":"/2023/11/03/4-软件-3D打印-3-上位机平台配置/","content":"本文章中针对针对某款嵌入式开发板搭建 3D 打印机的上位机平台环境，记录相关的操作以备细节遗忘。 镜像烧录选用镜像为 Ubuntu18.04，注意 ARMV7 版本构建需要的很多包不支持，不推荐构建。 分区扩展由于 emmc 给定的分区太小，需要对文件系统分区的大小进行扩容操作 ext4 格式的文件， 制作一个大于 6GB 的 EXT4 空文件, 由于安装的软件较多时，文件系统会很大，可以根据情况自行更改。 sudo dd if=/dev/zero of=ubuntu18_rootfs.ext4 bs=1500M count=3 将新建的 ubuntu18_rootfs.ext4 文件格式化为 ext4 格式。 sudo mkfs.ext4 ubuntu18_rootfs.ext4 新建一个临时的文件夹 rootfs_tmp,将 ubuntu18_rootfs.ext4 文件挂载到临时目录 rootfs_tmp,并拷贝文件系统。 mkdir -p rootfs_tmpsudo mount -o loop ubuntu18_rootfs.ext4 ./rootfs_tmpsudo cp -avrf ./ubuntu-rootfs/* ./ 拷贝完后，卸载挂载的 ubuntu18_rootfs.ext4 文件，即完成了文件系统的制作。 sudo umount ./rootfs_tmp ubuntu18_rootfs.ext4 就是可以用于下载的。 SD 卡启动 101 EMMC 启动 010 列出 USB 设备 ~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -l usb 烧录 ~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -c port=usb1 -w ./flashlayout_myir-image-ubuntu18/trusted/FlashLayout_sdcard_stm32mp157c-ya157c-512d-v2-ubuntu18.tsv 磁盘空间扩展扩容 安装相关工具并查看当前分区情况，parted 是硬盘分区工具，这里用来查看磁盘分区情况，按需删除不需要的分区，以及扩展分区容量 sudo apt update sudo apt intall -y parted resize2fssudo fdisk -l 删除分区 # 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看分区编号(parted) print# 如果该分区后面有分区的话，删除该分区(parted) rm 8# 再次查看分区(parted) print# 删除扩展分区(parted) rm 7# 保存更改并退出(parted) quit 增加分区 # 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看磁盘信息(parted) print# 直接扩展分区(parted)resizepart 6# 这里输入的数值，就是上方输出中 End: 后方的数值End? [9713MB]? 21.5GB# 扩展完成之后退出 parted(parted) quit#此时分区容量已经扩展完成了，但是文件系统还未识别扩展的容量，所以扩展的容量还没法使用。下面扩展一下已经重新分区的文件系统$ sudo resize2fs /dev/mmcblk1p6#此时不出意外的话应该扩容完成了，可以使用 df -h 来查看容量。 磁盘空间管理 当前目录按照空间使用大小排序(-h 参数，按 MB 显示)sudo du -s * | sort -nr 磁盘按照空间使用大小排序(-h 参数，按 MB 显示)df -h 磁盘空间整理apt-get clean 把安装的软件的备份也删除，不会影响软件使用。 挂载 SD 卡到开发板上，由于磁盘空间不足，安装位置设置挂载目录为主目录，指定 HOME=/mnt，打印 echo $HOME 确认已经成功设置 磁盘格式化mkfs.ext4 /dev/mmcblk1 磁盘新建分区fdisk /dev/mmcblk1 进入磁盘管理，输入 F 查询当前磁盘剩余未分区内容 SD 卡自动挂载编译 /etc/fstab 文件 /dev/mmcblk1p1 /mnt/sdcard vfat rw,relatime,fmask=0000,dmask=0000,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro 0 0 网络连接利用 Win32DiskImager-1.0.0-binary 烧录 SD 后发现没有无线网卡驱动，ko 格式不兼容，待测试验证换个镜像用 stmcubeProgram 烧录后问题解决 WIFI 启动 wlan0sudo ifconfig wlan0 up 启动时提示 SIOCSIFFLAGS: Operation not possible due to RF-kill，利用 rfkill list，查看 Wireless LAN 是否被软件阻止 Soft blocked: yes，然后输入 sudo rfkill unblock wifi 解开，并输入 rfkill list 确认状态。之后在执行上述语句，启动 wlan0。 扫描 Wifi，需要在 2.4GHz 频段 sudo iw dev wlan0 scan | grep SSIDsudo iwlist wlan0 scanning | grep SSID 设置 Wifi 配置 #生成配置文件sudo wpa_passphrase lemonade 12245612 ./wifi.conf#关闭wpa_supplicantsudo killall wpa_supplicant#初始化 wpa_supplicant# -D 指定驱动名称# -B 在后台运行守护进程# -c 配置信息的路径# -i 监听的wifi接口sudo wpa_supplicant -B -Dnl80211 -c./wifi.conf -iwlan0 设置 DHCP 利用 udhcpc 自动获取udhcpc -i wlan0 编辑配置文件自动获取 IPsudo vi /etc/systemd/network/wlan0.network [Match]Name=wlan0[Network]DHCP=yes 编辑完成后重启服务，systemctl restart systemd-networkd 利用 dhclient 自动获取 #释放租约sudo dhclient -r wlan0#重新获取租约sudo dhclient wlan0 需要设置 DNS 服务echo nameserver 8.8.8.8 /etc/resolv.conf 查看网卡信息ip addr show wlan0 测试网络连通性ping 360.com 有线设置有线网络的 IP 地址自动获取 软件源配置编辑源配置文件 sudo vi /etc/apt/sources.list ubuntu 18.04 for arm 清华源配置# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse ubuntu 18.04 for arm 中科大源配置deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universe 更新 python 版本armv7 上使用 python3.8 安装时依赖包编译不通过，版 安装 Python3.8，并查看安装路径 sudo apt install python3.8which python3.8 为了方便使用，建议创建软连接，首先把之前的软连接删除： sudo rm -rf /usr/bin/python3sudo rm -rf /usr/bin/pip3 创建 python3 和 pip3 的软连接： sudo ln -s Python3Path /usr/bin/python3sudo ln -s Python3Path /usr/bin/pip3 更换 pip 地址pip下载网络问题 网络问题导致无法 clone 在主机的浏览器上登录 github 下载 klipper 和 moonrarker 的压缩包，到开发板上解压 解压后，修改 kiauh 中的 klipper .sh 和 moonrarker.sh 中指定的目录位置，文件夹的名称及路径设置为脚本中的名称和路径 WIFI 配置脚本Wifi 连接脚本，执行 ifup_wifi_sta.sh -ssid Lemonade -passwd 12345678 #!/usr/bin/env sh#File: /usr/bin/ifup_wifi_sta.shSSID=PASSWD=WLAN=wlan0WPA_FILE=/etc/wpa_supplicant.confDRIVER_NAME=nl80211usage()\techo Usage: ./ifup_wifi_sta [-ssid wifi_sta_name] [-passwd wifi_sta_passwd] [-driver nl80211 or wext]clean_stage()\tkillall udhcpc\tkillall wpa_supplicant\tkillall hostapd\tkillall udhcpd\tsleep 1enable_wifi()\tT_HCI=phy0\tRFKILL_SYS_PATH=/sys/class/rfkill/\tdir=`ls $RFKILL_SYS_PATH`\tfor i in$dir\tdo if [ $T_HCI == `cat $RFKILL_SYS_PATH$i/name` ];then echo 0 $RFKILL_SYS_PATH$i/state echo find$T_HCI enable it sleep 1 echo 1 $RFKILL_SYS_PATH$i/state fi\tdoneparse_input_info()\twhile [ $# -gt 0 ];do case $1 in -ssid) SSID=$2 shift ;; -passwd) PASSWD=$2 if [ $#PASSWD -lt 8 ];then echo passwd should be 8...64 exit fi shift ;; -driver) DRIVER_NAME=$2 shift ;; -h) usage exit ;; esac shift $(( $# 0? 1:0))\tdone\techo SSID:$SSID PASSWD:$PASSWDDRIVER:$DRIVER_NAMEconnect_wifi()\tif [ -n $SSID ];then head -n4 $WPA_FILE $WPA_FILE.tmp wpa_passphrase $SSID $PASSWD$WPA_FILE.tmp mv $WPA_FILE $WPA_FILE.bak mv $WPA_FILE.tmp $WPA_FILE\tfi\twpa_supplicant -B -i$WLAN -c$WPA_FILE -D$DRIVER_NAME /dev/null 21obtain_dns()\ttime=10\twhile [ $time -gt 0 ];do state=`wpa_cli -i$WLAN -p/var/run/wpa_supplicant status | grepwpa_state | awk -F[=] print $2` if [ $state=COMPLETED ];then udhcpc-i $WLAN exit fi let time -= 1 sleep 1\tdone\techo connectwifi errorparse_input_info $@clean_stageenable_wificonnect_wifiobtain_dns 自启动脚本配置#!/bin/sh# 启动服务# root@ok3568:/home/forlinx# cat /etc/systemd/system/startfrp.service# [Unit]# Description=startfrp# Requires=network-online.target# After=network-online.target# [Install]# WantedBy=multi-user.target# [Service]# Type=simple# User=root# RemainAfterExit=yes# ExecStart=/home/forlinx/S99Startfrp.sh# Restart=always# RestartSec=10# 目标地址用于检查网络连接，这里使用的是 Google 的公共 DNS 服务器TARGET=8.8.8.8# 检查以太网接口check_ethernet() local interface=$1 if ethtool $interface | grep -q Link detected.*: yes; then echo Ethernet interface $interface is connected. #释放mlan0接口当前通过DHCP获得的IP地址租约。-r选项代表release，即释放已有租约。 #请求一个新的IP地址租约。通过DHCP协议获取一个新的IP地址配置，包括IP地址、子网掩码、默认网关以及DNS服务器地址等信息。 dhclient -r $interface dhclient $interface else echo Ethernet interface $interface is NOT connected. fi# 检测无线网络并连接（注意：此部分涉及安全信息，请谨慎处理）connect_wireless() wpa_passphrase lemonade 12245612 ./wifi.conf\tkillall wpa_supplicant\twpa_supplicant -B -Dnl80211 -cwifi.conf -imlan0\trm ./wifi.conf\t#udhcpc -i mlan0\tdhclient -r mlan0\tdhclient mlan0# 网络检查函数，ping 目标地址，如果成功返回 0，否则返回 1check_network() sleep 1\tping -c 1 $TARGET /dev/null 21\treturn $?# 主程序开始echo Checking Ethernet interfaces...check_ethernet eth0check_ethernet eth1# 连接无线网络柠檬水，这里仅作为示例，请勿直接使用明文密码echo Attempting to connect to wireless network lemonade...iwlist wlan0 scanning | grep SSIDconnect_wireless# 检查网络是否连接if check_network; then\techo Network is connected. Executing commands...\t# 执行 insmod 命令\t/sbin/insmod /home/forlinx/ch341.ko\tif [ $? -ne 0 ]; then echo Failed to execute insmod command exit 1\tfi\t# 执行 frpc 命令\t/home/forlinx/frp_0.58.1_linux_arm64/frpc -c /home/forlinx/frp_0.58.1_linux_arm64/frpc.toml if [ $? -ne 0 ]; then echo Failed to execute frpc command exit 1\tfi\techo Commands executed successfullyelse\techo Network is not connected. Exiting...\texit 1fi","categories":["4.软件","3D打印"]},{"title":"2.固件及控制软件配置","path":"/2023/11/02/4-软件-3D打印-2-固件及控制软件配置/","content":"控制架构目前 3D 打印机的主流架构一般情况下，有以下两种方式： 上位机（运行 fluidd 控制软件）+ 下位机（运行 kilpper 固件）+Web 显示 由于手头上正好有一块 Linux 开发板，所以准备采用上位机方案，局域网部署（OctoPrint 和 Fluidd 二选一安装配置即可。） 下位机（运行 marlin 固件）+ 串口屏显示 优点：只需要一块控制板加上串口屏，不需要上位机控制软件，节约成本 缺点：屏幕小，显示的信息少 固件在 3D 打印机中，固件控制着 3D 打印机的运动和操作。3D 打印机的固件通常是预装在单片机上的，但用户也可以根据需要进行更新和修改，以实现更好的性能和功能。 负责将 G 代码转换为实际的运动和操作，例如将 G 代码中的坐标转换为电机的运动，控制加热器的温度等。 负责处理传感器的输入，例如温度传感器、限位开关等，并根据这些输入控制 3D 打印机的运动和操作。 在 3D 打印领域，主流的固件有以下几种： Marlin：3D 打印机领域最流行的固件之一，因为它具有广泛的硬件支持和强大的功能。Marlin 支持多种传感器和功能，如自动床平衡、断电续打、LCD 屏幕等。Marlin 还提供了一套易于使用的配置文件，可以通过修改这些文件来对 3D 打印机进行高度自定义。由于 Marlin 是开源软件，因此用户可以根据自己的需要进行修改和定制，以实现更好的性能和功能。 Klipper：Klipper 是一款比较新的开源固件，它具有更高的计算能力，可以实现更快的运动和更高的精度。 Repetier：Repetier 是另一款流行的开源固件，它具有类似于 Marlin 的功能和支持。 Smoothie：Smoothie 是一款基于 ARM 处理器的开源固件，它支持多个独立的电机和传感器，并具有良好的可扩展性。 本次机器组装选择的方案是 klipper，可以很方便的直接在上位机修改打印机参数，不需要每次修改参数后重新烧写固件 Klipper 固件配置及烧写Klipper 官方文档 https://www.klipper3d.org/zh/Overview.html ，建议详细阅读，很多参数和问题都有说明，首先获取 klipper 源码 git clone https://github.com/Klipper3d/klipper.git 执行脚本安装一些系统依赖、设置。* 安装很慢时，可以更换下 pip 的源 pip下载网络问题 ./klipper/scripts/install-ubuntu-22.04.sh 然后配置和构建 elf 文件 cd ~/klipper/make menuconfigmake 需要确定连接到微控制器的串行端口 ls /dev/serial/by-id/*ls /dev/ttyUSB* 可以用命令行或软件工具来刷写固件，刷写时要确保端口没有被占用 sudo service klipper stopmake flash FLASH_DEVICE=/dev/ttyUSB0sudo service klipper start 控制软件上位机主板采用一块手头空余的 Linux 主板，软件采用 FluiddMainsail，如果是上位机的形式，则由运行在上位机的 3D 打印机控制软件来控制 3D 打印机，主要考虑因素: ARM 架构，功耗低（需要长时间工作） USB 接口，连接下位机 网口，局域网 Web 显示打印机控制（可选） 显示屏，本地显示打印机控制（可选） WIFI，可以无线打印（可选） 监控模块，可以远程查看打印情况（可选） 先在 WSL 环境下搭建调试 Fluidd， 适用于 3D 打印机的 Klipper 固件，提供 WEB 页面和控制。 KIAUHKIAUH 全称 Klipper Installation And Update Helper，该脚本可以直接完成所有环境配置。 在通过该脚本进行安装时，需要实时从 github 和 pip 下载文件，由于网络不稳定的情况导致安装失败的，可以下载 klippermoorakerfluidd 等文件后，置于~目录下，并修改 kiauh 中的 scripts 文件夹下的相关脚本，将脚本中的 clone 部分注释，避免网络不稳定导致的错误。pip 部分可以修改 pip 源，稳定下载。 界面如下所示： 执行脚本前需要安装 git sudo apt-get update sudo apt-get install git -y 下载 KIAUH 到本地： git clone https://github.com/dw-0/kiauh.git 执行脚本 ./kiauh/kiauh.sh KIAUH 的主菜单中。将看到多个操作可供选择，具体取决于想要执行的操作。要选择操作，只需在”执行操作”提示中输入相应的数字，然后按 ENTER 确认即可。 moonraker选择 1 Install,需要输入密码，之后选择 2 moonraker，安装完成后进入浏览器输入 http://127.0.0.1:7125/server/info 测试 moonraker 是否正常安装。 moonraker 的作用： Moonraker is the API that fluidd communicates with, which in turn communicates with Klipper. All three components are required for a healthy printer. 如果出现 pip 下载速度太慢导致的失败，参阅 pip下载网络问题 无法构建 pillow 和 streaming-form-data 这两个包的轮子（wheels），检查发现是头文件没有导致的错误，将 /usr/include/python3.6 下的所有头文件拷贝至 /usr/include fluidd选择 1 Install 之后选择 4 Fluidd 进行安装，安装完成后访问 http://127.0.0.1 正常打开 fluidd 页面 安装之前进入 kiauh/resources 下，编辑 fluidd 文件可以更改端口。 Mainsail修改 /kiauh/resources/mainsail 中的 80 端口为 9090，安装 mainsail 到 9090 端口 配置打印机配置文件，一般在用户主目录中名为 printer.cfg 的文件 配置文件示例 /home/linux/printer.cfg。 刷写 Klipper 后，名称可能会改变，检查 USB 节点名称： ls /dev/serial/by-id/*或者ls /dev/ttyUSB* 确认节点名称并写入配置文件中去。 /dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0或者/dev/ttyUSB0 用这个唯一的名字更新配置文件。更新 [mcu] 部分，类似于： [mcu]serial: /dev/ttyUSB0 在编辑该文件后，发出 restart 或 FIREWARE_RESTART 命令以重新加载配置（命令根据实际上位机）。如果 Klipper 配置文件被成功读取，并且成功找到并配置了微控制器，那么 “status” 命令将报告打印机已准备就绪。 默认的 Klipper 启动脚本在 /tmp/klippy.log 中放置日志，提供更详细的信息。 WSL 问题解决由于本次安装是在 WSL 中的 Ubuntu 进行安装的，所以有以下两个问题需要解决 1）systemd 中的服务无法启动导致的 moonraker.service 无法运行 Windows 版本要求 (已验证 Win11 22H2) 启动 windows Power Shell，更新 wsl wsl --update 进入 Ubuntu wsl ~ 编辑配置 sudo vi /etc/wsl.conf 添加以下内容 [boot]systemd=true 保存并退出 ubuntu exit 在 windows power shell 中关闭 ubuntu wsl --shutdown 然后重新进入 ubuntu wsl ~ 查询 systemd 服务 sudo systemctl status 2）在 WSL 中无法打开 Windows 的 USB 端口 WSL2 内核要求 5.10.60.1 进入 Ubuntu wsl ~ 查询内核版本 uname -a 退出 Ubuntu exit 安装 usbipd-win winget install usbipd 进入 Ubuntu，安装客户端工具 sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 退出 Ubuntu，添加 USB 设备到 WSL 中去 usbipd wsl list //列出所有连接到Windows的USB设备。usbipd wsl attach --busid //添加USB设备进入Ubuntu，需要管理员权限usbipd wsl detach --busid //停止USB设备共享usbipd wsl attach -a --busid 2-7 // -a 自动绑定 进入 Ubuntu，查看已经连接的 USB 设备 lsusb 配置 udev，允许非 root 用户访问 USB 设备,需要在设备连接前完成该操作。需要将根据自己 USB 设备编写的 60-myusb.rules 文件复制到 /etc/udev/rules.d 嵌入式部署时相关问题部署 3d 打印机环境到开发板，所有环境已部署完毕，目前需要解决的问题点是需要编译 ch341 在 linux 环境下的驱动，驱动内核版本 4.19.204 详见 Linux下的CH34x串口驱动","categories":["4.软件","3D打印"]},{"title":"1.架构及硬软件介绍","path":"/2023/11/01/4-软件-3D打印-1-架构及硬软件介绍/","content":"3D 打印机3D 打印（3D printing）是一种快速成型技术，也被称为添加制造（Additive Manufacturing，AM）。它是一种通过将材料逐层叠加以构建三维实体物体的过程。与传统的制造方法不同，3D 打印不需要模具或切削工具，而是通过从计算机辅助设计（CAD）模型中生成的数字模型直接创建物体。 FDM（熔融沉积成型）：FDM 是目前最常见的 3D 打印技术，它使用热塑性材料通过打印头喷出的方式逐层堆积，最终形成所需的物体。FDM 打印机的结构和控制系统比较简单，价格也比较实惠，因此广泛应用于家庭、办公室和教育等领域。 SLA（光固化成型）：SLA 使用紫外线激光器或 LED 光源照射光敏树脂，使其逐层固化成为所需的物体。SLA 打印机的精度和表面光滑度比 FDM 更高，但价格也更贵。 SLS（选择性激光烧结）：SLS 使用激光束将热塑性粉末烧结在一起，逐层堆积形成所需的物体。SLS 打印机可以使用多种材料，可以打印出更复杂的结构，但价格也更昂贵。 DLP（数字光处理）：DLP 使用光敏树脂和数字投影仪，通过投影仪将光固化在涂层的树脂上，逐层堆积形成所需的物体。DLP 打印机的速度和精度都比较高，但价格也较贵。 FDM通过将加热的材料挤出打印头，逐层堆积形成打印件 打印头 打印床热床 控制系统（主板、电机、传感器和用户界面） 打印材料 G-Code 一种用于控制数控机床（包括 3D 打印机、数控铣床、数控车床等）运动和操作的编程语言。 结构结构主要分为两部分： 一个负责三维空间的移动的组件 (三维移动部分) 一个负责进料、融化材料和挤出材料的组件（挤出部分） 打印时材料会一层又一层地堆积在之前已经「挤出来」的材料上，所以在这两个组件共同协作下就能打印出一个完成的 3D 物体了。 结构 - 三维移动部分打印机在 3D 的空间运动的传动方式有很多种，一般较为便宜的打印机会选择笛卡尔结构。笛卡尔结构指的是 X Y Z 方向上的运动是独立的，这种方式比较直观，结构也比较简单。常用的 3D 打印机的结构有以下几种： Prusa i3 型：控制 XZ 轴，Y 轴通过工作台的移动来实现。CoreXY 型：CoreXY 最大的特别之处在于其 X、Y 电机是协同运作的，并且它的同步带在不同同步轮的摆放下能够形成多种不一样的缠绕方法。由于两个电机的协同运动，电机带动的力比单一电机的力要大，且会减少在 XY 方向面上的一个电机重量，提高精准性。**CoreXY 结构：CoreXY 结构采用的是两个电机通过传动带和滑块来实现打印头的运动，其中 X 和 Y 轴的传动带交叉布置，使得打印头的运动方向可以在 X 和 Y 轴上独立控制。CoreXY 结构的优点是打印速度快，同时打印头的重量对定位精度的影响较小，同时可以实现较大的打印范围。缺点是结构复杂，需要更多的零件和更高的制造精度，同时维护和升级也较为困难。 Um Ultimaker 型：X 轴、Y 轴的电机都在静止的框架上，但挤出头在两个互相垂直的光轴的交叉处。**UM 结构（Ultimaker 结构）：UM 结构采用的是直线轴承和滑块来实现运动，其中 X 和 Y 轴分别由两个电机驱动，通过传动带和滑块来实现打印头的运动。UM 结构的优点是定位精度高，速度快，同时结构简单，易于维护和升级。缺点是打印头的质量和稳定性对定位精度有较大影响，同时打印头的重量也会影响打印速度。 MB：主要体现在挤出电机一般都装在喷头旁，近程进丝，双光轴承载挤出组件，X 方向的运动一般是通过电机带动同步带，通过带传动使两边一起运动。 delta 三角洲（并联臂）型 结构 - 挤出部分挤出部分分为以下： 挤出头 送料步进电机 送料步进电机驱动板 FDM 3D 打印机除了怎么动的很关键以外，怎么取料、融化材料、挤出材料也非常重要。 其中取料和挤出材料是由挤出机处理的，融化材料则是由热端处理的。 挤出机从材料盘中将材料拉出来，送进去热端融化。 并持续往热端送更多的料让融化的材料从喷嘴中挤出来。 其中挤出机的精度和挤出的速度决定了打印质量和速度。精度高意味着可以更好的控制挤出的量。挤出的材料太多或者太少对打印的质量影响都非常大。挤出的速度快就很直接的决定了能打印多快。 而影响挤出机的精度和速度的两个关键因素就是： 挤出机的类型 挤出机的齿轮数量 FDM 挤出机分为两个大类： 远端挤出机（鲍登挤出机） 优点 轻量化喷头：由于挤出机和步进电机位于机器外壳，喷头的重量较轻，惯性小，能够实现更高的移动速度（可达 200~300mms），因此适合高速打印。 精准定位：轻量的喷头使得定位更为精准，适合需要高精度的打印任务。 缺点 送料阻力大：由于送料距离较远，材料在特氟龙管中的摩擦阻力较大，要求步进电机具备更大的力矩，增加了电机的负担。 回抽不精准：在高速打印时，远端挤出机的回抽距离和速度要求较大，导致在使用弹性材料时可能出现输送不畅的情况。 维护复杂：由于挤出机与喷头分离，连接部分（如特氟龙管和气动接头）容易出现故障，维护相对复杂。 近端挤出机（直接挤出机） 优点 精准控制：近端挤出机对送料量的控制更为精确，回抽也更为精准，适合高速打印时的细节处理。 低力矩要求：对步进电机的力矩要求相对较低，能够在高速情况下保持稳定的挤出性能。 换料方便：由于结构紧凑，换料过程相对简单，适合频繁更换材料的应用场景。 缺点 重量问题：喷头较重，尤其是在双喷头打印机中，增加了运动时的惯性，可能导致加速和减速困难，从而影响打印精度。 维护不便：喷头、挤出机和步进电机集成在一起，拆装和维护相对不便。 压力影响：较重的喷头对光轴或导轨的压力较大，可能导致长时间使用后出现的调平困难. 另外一个影响挤出机精度的就是挤出机的齿轮了。较低端的机器一般都是配备都是单齿轮，虽然对比双齿轮的挤出机，无论是对材料的咬合能力还是挤出精度都表现更差，但它便宜而且工作，对于预算相对比较紧张的朋友是一个不错的选择。 传动系统传动系统分为以下几个部分： Xyz 步进电机 限位开关 步进电机驱动板 同步带 传动系统是 3D 打印机中负责移动打印头（或喷嘴）和打印平台的机械组件。它在 3D 打印过程中发挥以下作用： 控制位置：传动系统通过精确的运动控制，将打印头定位在正确的位置，以便在每个层次上精确地添加材料。 三维定位：传动系统的运动控制使得打印头可以在 X、Y、Z 三个方向上精确移动，从而实现三维打印。 打印速度：传动系统的运动控制还影响到打印速度。更快的传动系统能够加快打印速度，但需要保持精确性和稳定性，以确保打印质量不受影响。 自动校准：一些高级的传动系统具备自动校准功能，能够自动检测打印平台和打印头的位置，从而保持打印的准确性和稳定性。 加热部分加热部分分为以下： 热床 MOS 管 打印机的热床就是用来承载挤出机挤出来的材料。是 3D 打印机上的一个移动平台，用于支撑正在打印的物体。其主要作用如下： 粘附和稳定：打印平台上的特殊表面或涂层（例如热床、胶水、胶带等）可以提供粘附性，确保打印的第一层材料牢固地附着在平台上，并防止其在打印过程中发生位移或变形。 - 塑料在不同的温度下粘性不一样，控制床的温度可以让不同的塑料在保持形状的同时达到最大的粘性。如果温度太高则有可让打印的形状变形，温度太低则有可能让打印的材料不粘床。床的温度和热端的温度共同决定了可以打印什么材料。如果能顺利融化材料，但是他并不能稳定的黏在床上，打印也会有非常大几率失败。 平整度：打印平台的调平性（平整度）对于打印质量至关重要。如果平台不平整，可能导致打印的物体底部出现变形或不平整的表面。 防止翘曲：特定类型的 3D 打印材料，例如 ABS（丙烯腈 - 丁二烯 - 苯乙烯）等，有时容易在冷却过程中产生翘曲。热床可以在打印过程中加热，有助于减少材料翘曲，提高打印的成功率。 电气系统电气系统分为以下几个模块： 电源 主板（需要烧录固件代码如 Marlin） 显示屏 传感器加热模块等 了解各模块的所需电源电压，功耗等信息选取合适电源 了解打印机的所需功能，进行针对性选择主板 扩展 Octoprint 远程监控模块 3d 打印的成功率和模型文件、材料、切片 gcode 代码、天气、机器等关联，然后只有在打印中才能知道模型有没有出问题，octoprint 连接 Wifi，通过网页端远程摄像头监控进度，同时能够开始和停止打印机的操作。 自动调平 通常机器在几天内调平过一次之后很大几率不用重新调平，但是对机器的一举一动包括机器自己的老化都会影响热床的位置移动和变形，自动调平模块 3D touch（也有别的）能够让完全手动的调平变成半自动调平。 双 Z 结构 顾名思义就是有两根 Z 轴。 单一的 Z 轴由于在一边容易导致 Z 轴变形造成模型垂直方向变形。同时也可能会让 XY 平面在变形的 Z 轴运动受阻。 双 Z 结构不仅能够减少变形，同时增强 Z 轴的稳定性。 硬件硬件选型硬件采用 MKS Gen L v2.1，固件采用 Klipper pin 口图 硬件相关主要考虑因素: 驱动电机数量（根据 3D 打印机的结构方案确定） 限位开关 风扇控制 挤出头控制 热敏电阻（热床加热棒挤出头） 单下位机方案需要支持屏幕接口 上位机方案需要支持 USB 连接 系统固件KlipperKlipper 是一个高性能、灵活的 3D 打印机固件，它通过将一些计算工作转移到更强大的主机（如 Raspberry Pi）上来提高打印质量和速度。 MarlinMarlin 是目前最流行的 3D 打印机固件之一，支持广泛的硬件平台和 3D 打印机模型，具有丰富的功能和高度的可定制性。 控制软件fluiddFluidd 是一个基于网页的控制界面，用于管理和监控运行 Klipper 固件的 3D 打印机。它提供了用户友好的界面和实时监控功能。GitHub 地址: https://github.com/fluidd-core/fluidd安装手册: https://github.com/dw-0/kiauh Make-meMake-me 是一个通过 WiFi 控制 Replicator 2 打印机的开源项目，使用 GitHub 的聊天机器人 Hubot 来监控和完成打印任务。目前只支持 Mac 的 OS X。 Pepeteir-ServerPepeteir-Server 是一个新型的 Repeteir 产品，可以在 Raspberry Pi 上运行，支持控制多台打印机，内存消耗极小。它的网页操作界面简单，但不支持 Mac 和 PC。 OctoprintOctoprint 是一个完全基于网页的 3D 打印机控制程序，可以远程控制打印机，并通过网络摄像头监控打印过程。支持 Raspberry Pi。 BotqueueBotqueue 是一个开源的远程打印机控制软件，可以控制多台打印机。用户上传 .stl 文件后，软件会完成切片和打印工作。它支持为每台打印机设置独立的切片特性。 切片软件切片软件用于将 3D 模型按层切片，并生成用于打印的 G 代码。 CuraCura 由 Ultimaker 开发，兼容多种 3D 打印机。它不仅可以切片，还提供 3D 打印机控制界面，尤其适用于 Ultimaker 的 3D 打印机。 Slic3rSlic3r 是开源且免费的切片软件，因其快捷性和高度可定制化而广受欢迎。许多 3D 打印机制造商提供默认的 Slic3r 配置文件（.INI 文件），可以用作初始设置。 Skeinforge另一款非常流行的切片软件。同样开源，免费。 kisslicerKISSlicer 是一款跨平台的切片软件，名称源自 “Keep It Simple”（保持简单），目标是提供一个简单易用的界面。 PrintrunPrintrun 既是控制软件，也是切片软件，可以独立完成从切片到打印的整个过程。支持 Mac、Linux 和 PC 操作平台。 Repetier-HostRepetier-Host 与 Printrun 类似，是一款综合性软件，具有切片、零件定位和机器控制功能。用户界面相对更复杂但更直观，同样支持 Mac、Linux 和 PC 操作平台。 3D 建模软件BlenderBlender 是一款开源的 3D 建模软件，功能强大且完全免费。它不仅可以用于 3D 建模，还支持动画、渲染、雕刻等多种功能，适用于各种复杂的 3D 设计和制作。 TinkercadTinkercad 是一个由 Autodesk 开发的在线 3D 建模工具，适合初学者使用。它基于浏览器，无需下载软件，界面友好且易于使用。 Fusion 360Fusion 360 同样由 Autodesk 开发，是一款功能强大的云端 3D CAD、CAM 和 CAE 工具。它适用于从初学者到专业人士的各个层级，提供了全面的建模、仿真和制造功能。 SketchUpSketchUp 是一款广受欢迎的 3D 建模软件，以其直观的用户界面和易用性著称。它有免费版本（SketchUp Free）和专业版本（SketchUp Pro），适用于建筑、工程、游戏开发等多个领域。 FreeCADFreeCAD 是一款开源的 3D CAD 建模软件，适合于产品设计、机械工程以及建筑设计。它具有模块化的架构，可以通过插件扩展其功能。 SolidWorksSolidWorks 是一款由 Dassault Systèmes 开发的专业 3D CAD 软件，广泛应用于工程设计、产品设计和制造业。它功能强大，但价格较高，通常用于工业级应用。 OnshapeOnshape 是一个基于云的 3D CAD 建模软件，适用于团队协作和设计项目。它无需安装，直接在浏览器中运行，支持实时协作和版本控制。 OpenSCADOpenSCAD 是一款开源的 3D CAD 建模软件，适用于创建精确的 3D 模型。它使用编程语言来定义模型，适合那些有编程经验的用户。 切片软件-Cura 的使用设置打印机长宽高200*200*200mm 打印头孔径 0.4mm 材料直径 1.75mm 配置 Cura 设置可见性可以根据自己在切片时实际需要调整的相关参数进行显示 移动和缩放模型长按鼠标滚轮中键，可平移视角 长按鼠标右键，可旋转视角 滚动鼠标滚轮，可放大缩小视角 选中模型后，在 Cura 的左侧，依次功能为 移动 缩放 旋转 镜像 单一模型设置 支撑拦截器 在相应位置添加方块减少支撑应用右击模型，可进行”复制”、”清空平台”、”居中模型等设置 设置打印参数点击右侧的打印参数设置栏，选择多种模式 质量即层高：数值越小，打印物体表面效果越好，打印时间越长。默认选择 0.15mm 填充打印模型内部的模型密度，默认以网格状的形式填充。默认选择 20% 如果填充率过低，也会有一定程度导致翘边，不同的内部填充图案也可以有效减少翘边。 材料主要设置打印时喷嘴和热床的温度。一般耗材上会写有打印温度。也可通过打印温度塔测试出每种最耗材品牌最佳的打印温度。建议首层温度用 230°C，容易粘床。 打印 PLA，热床的温度建议在 50-60°C。 速度PLA 建议打印速度为 60mms，±20 也在常用速度。 过快步进电机会丢步，按实际情况设置 移动当喷嘴移动到非打印区域上方时回抽耗材 当打印出现拉丝情况，可调整回抽设置。建议回抽距离用 2.0mm，回抽速度用 50mms，加大数值可减少拉丝情况。如果打印过程中喷嘴有碰到打印物的情况，可勾选 Z 轴抬升。 附着加大模型第一层与打印平台的接触面积，增加附着力，让模型在打印过程中更稳固。当打印模型的高度较高，接触面积较小时使用。 skirt 裙边 在打印模型前，在模型外围打印一圈，让喷头里面的出丝比较顺滑,主要用于擦净喷头 brim 在模型的边缘处加上薄薄的一层，防止翘边，适用于打印较高的物体且接触面较小，容易倒塌的时候 raft 底座，在底座上在打印模型，适用于接触面多且复杂的情况 支撑在模型的悬垂部分生成支撑结构，防止模型倒塌。作为入门最难的一个设置。通常角度过大，打印过程中悬空部位则需要添加支撑，否则容易下垂。支撑与模型接触面往往很粗糙，影响模型质量。 支撑悬垂角度越大，需要支撑部位（红色部分）则越小。建议 45-50 间。 添加支撑的最小悬垂角度，当角度为 0 时，将支撑所有悬垂，当角度为 90 度时，不提供任何支持 Cura 提供普通支撑和树型支撑两种选择。 树型支撑对模型影响更小，也节省材料。注意，它只适合于非平面的悬空，如鼻尖，指尖或拱形。对于平面的悬空，树形支撑无法提供足够的稳定性。 正常支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：0支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。支撑 XY 距离：1-1.5mm 树形支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：1连接支撑锯齿形: 勾选支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。支撑 XY 距离：1-1.5 保存和预览点击右下角的切片，等待切片完毕后，可在预览界面预览打印效果、耗材用量及预计用时。拉动最右边进度条，可查看每层打印情况。点击右下角保存 gcode 文件准备打印。 特殊操作 偏好设置”—“基本”—“自动下降模型到打印平台” 假如只想打印一半模型，可解除 Z 轴限制，可使模型下降至负数。切片后只会打印平台上方部分。","categories":["4.软件","3D打印"]},{"title":"AI应用软件了解","path":"/2023/10/31/4-软件-AI-AI应用软件了解/","content":"1. 文本生成 AI 名称 公司 是否开源 功能简介 ChatGPT-4 OpenAI 否 最先进的大语言模型之一,具有强大的自然语言理解和生成能力,可用于写作、编程、分析等复杂任务 Claude3 Anthropic 否 擅长长文本处理和信息整理,最新版本在多项基准测试中表现优异 Gemini Google 否 多模态 AI 模型,具备出色的语音和图像理解能力 Poe Quora 否 集成多个顶级大语言模型的平台,用户可选择不同模型对话 NewBing Microsoft 否 基于 GPT-4 开发的 AI 搜索助手,集成在 Bing 搜索引擎中 通义千问 阿里巴巴 否 支持 10 万字长文本处理的大语言模型 豆包 字节跳动 否 注重陪伴和对话体验的 AI 助手 天工 昆仑万维 否 可生成文本、图像和音乐的 AI 平台 扣子 - - 专注于创建和部署自定义 AI 智能体的平台 2. 图像生成 AI 名称 公司 是否开源 功能简介 Stable Diffusion Stability AI 是 开源的文本到图像生成模型,可免费使用 Midjourney Midjourney 否 付费的高质量图像生成服务,以艺术风格著称 DALL-E 3 OpenAI 否 最新图像生成模型,集成在 ChatGPT 中 Dreamina 字节跳动 否 字节跳动开发的图像生成 AI 通义万象 阿里巴巴 否 集成在通义千问中的图像生成模型 混元助手 腾讯 否 腾讯开发的图文生成 AI Akuma - - 新兴的 AI 图像生成平台,提供多样化创作工具 3. 视频生成 AI 名称 公司 是否开源 功能简介 Sora OpenAI 否 文本到视频生成模型,能创建高质量、逼真的视频内容 Stable Video Diffusion Stability AI 是 开源的视频生成模型 Runway Runway 否 提供 AI 视频编辑和生成工具的平台 Pika Pika Labs 否 专注于短视频创作的 AI 工具 Haiper - - 新兴的 AI 视频生成平台 Dreamina 字节跳动 否 字节跳动的视频生成 AI 产品 Pixverse - - 提供 AI 视频创作和编辑功能的平台 Vidu 清华大学 - 清华大学开发的视频生成 AI Money Print Turbo - - 全自动视频制作工具,可生成文案、素材、字幕和背景音乐 4. 音频生成 AI 名称 公司 是否开源 功能简介 Suno Suno 否 AI 音乐创作平台,提供免费额度 Stable Audio Stability AI 是 Stability AI 开发的音频生成模型 天工音乐 昆仑万维 否 AI 音乐创作工具 网易天音 网易 否 网易开发的 AI 音乐生成平台 5. AI 浏览器和编程助手 名称 公司 是否开源 功能简介 Perplexity Perplexity AI 否 基于 AI 的智能搜索引擎,提供精准的信息检索和问答服务 GitHub Copilot MicrosoftOpenAI 否 AI 编程助手,集成在多个代码编辑器中 6. 照片说话和音频模仿 名称 公司 是否开源 功能简介 Emo 阿里巴巴 否 AI 换脸和表情动画工具 SadTalk - 是 开源的 AI 换脸和口型同步技术 GPT-SoVITS - 是 开源的 AI 语音克隆和转换工具 Openvoice 微软 否 微软开发的 AI 语音克隆技术 剪映 字节跳动 否 短视频编辑 App,集成 AI 语音克隆功能 魔音工坊 - - 专注于 AI 语音合成和克隆的在线平台 7. PPT 制作和视频编辑 名称 公司 是否开源 功能简介 讯飞智文 科大讯飞 否 AI 辅助文档创作工具 Gamma Gamma 否 基于 AI 的演示文稿制作平台 WPS AI 金山办公 否 集成的 AI 助手,支持 PPT 等文档智能生成 腾讯智影 腾讯 否 AI 视频创作和编辑平台 剪映 字节跳动 否 短视频编辑 App,集成多种 AI 功能 其他说明：PyTorch 2.0.1PyTorch 2.0.1 是一款开源机器学习库，广泛用于深度学习的研究和生产环境。其更新版引入了多个改进的功能，旨在加速训练过程和优化资源使用。例如，GPU 加速优化使得计算过程更加高效，这对于处理大型数据集至关重要。根据近年研究，使用 PyTorch 进行深度学习训练的模型相较于使用其他框架在相同硬件条件下，训练效率提升了约 15% 至 30% 。 主要特性 动态计算图：与静态计算图相比，动态计算图使得模型在训练过程中的灵活性大大提升。这种设计理念使得用户可以随时调整网络结构，类似于构建小型程序时随时编排逻辑，使得开发过程更加直观。 简化的 API：PyTorch 2.0.1 提供了简化的 API 设计，使得实现自定义层、损失函数变得更加容易。正如 TensorFlow 的 Keras API 简化了神经网络的构建，PyTorch 同样通过精简接口降低了学习曲线，使得新手能够更快上手。 高性能模型训练：通过引入加速技术和分布式训练，PyTorch 2.0.1 能够有效提高训练速度。这一点在训练大型神经网络时尤为重要。例如，在 ImageNet 数据集上的态势表明，采用 GPU 并行训练的模型训练时间相比于单机训练减少了 50% 以上。 CUDA 11CUDA 11 是 NVIDIA 提供的并行计算平台和编程模型，专门为 GPU 优化，能够显著提高计算性能。最新的 CUDA 11 版本支持多个深度学习框架，尤其是对 PyTorch 2.0.1 的优良兼容性，增强了大规模数据处理的能力。这种性能提升在使用卷积神经网络（CNN）处理图像数据时尤为明显。在多项研究中，使用 CUDA 11 的模型训练效率是以往版本的两倍。 关键优势 资源管理：CUDA 11 提供了更好的内存管理功能，例如快取和动态内存分配，使得 GPU 资源可以更高效地被利用。根据 2022 年的研究数据，在相同的硬件条件下，采用 CUDA 11 的程序在内存使用上减少了 20%。 支持最新硬件：CUDA 11 与最新的 NVIDIA GPU 完美兼容，例如 A100 和 V100，加速高性能计算和深度学习任务将不再是瓶颈。此举使得开发者能够在更高的硬件平台上，获得更佳的性能提升。 增强的数学库：CUDA 11 课程进行了多项更新，针对深度学习所需的矩阵运算提供了高效的支持。这种优化使得神经网络的训练和推理性能得到了显著提升，相当于在数学操作上实现了加速，使得整体算法运行速度大幅度提升。 condaConda 是一个开源的包管理系统和环境管理系统，广泛用于管理 Python 及其依赖项。通过 Conda，用户可以创建隔离的环境，以便在同一系统上管理不同版本的库和工具。这种能力类似于虚拟机的运作方式，但更加轻量和灵活，使开发者能够轻松测试新的库和版本，而不会影响已有项目的稳定性。 功能亮点 环境隔离：Conda 允许用户定义多个独立的环境，每个环境可以拥有各自的 Python 版本和依赖包。通过使用 conda create -n myenv python=3.8 命令，快速创建一个新的环境，例如为旧项目加载所需的库时，可以避免版本冲突的麻烦。 多平台支持：无论是在 Windows、macOS 还是 Linux 平台，Conda 都能顺利运行。这种多平台兼容性在很多深度学习研究项目中至关重要，尤其是在合作研究或跨团队开发时，确保了环境的统一性和可移植性。 简化依赖管理：Conda 自动处理包及其依赖关系的安装和版本管理，用户无需手动解决复杂的依赖问题。功能类似于 npm 对 JavaScript 的管理方式，这种便捷的安装方式允许开发者专注于编码而非环境配置。 FastGPT + ollamaFastGPT 是一个优化过的 GPT 架构，旨在提升大语言模型的推理速度和效果。结合 Ollama，提供了一种高效的模型应用场景，使得开发者可以基于现代架构快速部署和测试语言模型。与传统的模型部署方式相比，FastGPT + ollama 以简洁和高效著称，适用于生产环境的实时推理需求。 效应 性能提升：使用 FastGPT 模型在生成文本时，响应时间通常降低到原来的 50%。在语音识别和自然语言处理任务中，这种性能优化显著提升了用户体验。根据一项 2023 年的研究，FastGPT 的使用能有效提高提供智能客服服务时的响应时间和准确率。 简单部署：Ollama 平台为开发者提供了易于理解的界面和工具集，使得语言模型的集成变得轻松。与 Docker 相似，Ollama 使得跨平台部署成为可能，确保了模型能够在各种环境中运行。 应用多样化：FastGPT + ollama 组合支持多种下游任务，如机器翻译、自动摘要和对话生成，扩展了人工智能在各个行业中的应用潜力。这种灵活性使得模型的商业应用更加广泛和深入，如在客服、市场分析等领域展现出巨大的潜力。 通过深入了解 PyTorch 2.0.1、CUDA 11、Conda 以及 FastGPT + ollama，使用者能够更好地把握这些工具在深度学习和机器学习中的应用优势，从而优化开发流程，提高生产效率。 huggingface.coHugging Face Transformers 是一个开源 Python 库，其提供了数以千计的预训练 transformer 模型，可广泛用于自然语言处理 (NLP) 、计算机视觉、音频等各种任务。 Hugging Face Hub 是一个协作平台，其中托管了大量的用于机器学习的开源模型和数据集，可以将其视为 ML 的 Github。 Hugging Face Spaces 是 Hugging Face Hub 上提供的一项服务，它提供了一个易于使用的 GUI，用于构建和部署 Web 托管的 ML 演示及应用。该服务使得用户可以快速构建 ML 演示、上传要托管的自有应用，甚至即时部署多个预配置的 ML 应用。","categories":["4.软件","AI"]},{"title":"GPT-SoVITS项目笔记","path":"/2023/10/30/4-软件-AI-GPT-SoVITS项目笔记/","content":"项目地址 https://github.com/RVC-Boss/GPT-SoVITS","categories":["4.软件","AI"]},{"title":"MaterialSearch 本地素材搜索","path":"/2023/10/27/4-软件-AI-MaterialSearch-本地素材搜索/","content":"项目地址 https://github.com/chn-lee-yumi/MaterialSearch","categories":["4.软件","AI"]},{"title":"Ollama项目笔记","path":"/2023/10/26/4-软件-AI-Ollama项目笔记/","content":"安装Linux使用以下命令安装 Ollama： curl -fsSL https://ollama.com/install.sh | sh 支持的模型用户可以访问模型库的页面，获取可用模型的详细信息，链接为 Ollama 模型库。以下是常用命令示例： 使用命令 ollama.exe list 列出本地已下载的模型。 运行 qwen 模型，通过命令 ollama run qwen，如果本地未下载，则系统会自动进行下载。 NAME SIZE FEATURES codellama:latest 3.8 GB - llama3:latest 4.7 GB - starcoder2:3b 1.7 GB - qwen:4b 2.3 GB - nomic-embed-text - 配置更换保存位置Windows在 Windows 系统上，默认情况下 Ollama 将模型文件存储在系统盘（通常是 C 盘）。可以通过查看帮助文档了解如何更改模型的存储目录： ollama.exe serve --help 执行上述命令后，会返回类似以下的帮助信息： Start ollamaUsage: ollama serve [flags]Aliases: serve, startFlags: -h, --help help for serveEnvironment Variables: OLLAMA_HOST The host:port to bind to (default 127.0.0.1:11434) OLLAMA_ORIGINS A comma separated list of allowed origins. OLLAMA_MODELS The path to the models directory (default is ~/.ollama/models) OLLAMA_KEEP_ALIVE The duration that models stay loaded in memory (default is 5m) 从帮助文件中可以确认，通过设置环境变量 OLLAMA_MODELS 可以自定义模型的存放目录。可以通过系统设置中的环境变量界面修改，也可以在命令行中直接配置，如下所示： set OLLAMA_MODELS=d:\\ollama Linux在 Linux 系统中，模型的默认保存位置为 ~/.ollama/models。要更改这一目录，可以设置环境变量 OLLAMA_MODELS，示例如下： export OLLAMA_MODELS=/data/ollama 导出模型以 qwen:7b 模型为例，首先查看模型的详细信息： ollama show --modelfile qwen:7b 返回的信息样式如下： # Modelfile generated by ollama show# To build a new Modelfile based on this one, replace the FROM line with:# FROM qwen:7bFROM /Users/m2max/.ollama/models/blobs/sha256-87f26aae09c7f052de93ff98a2282f05822cc6de4af1a2a159c5bd1acbd10ec4TEMPLATE if .System |im_start|system .System","categories":["4.软件","AI"]},{"title":"Stable Diffusion项目笔记","path":"/2023/10/25/4-软件-AI-Stable-Diffusion项目笔记/","content":"项目地址 https://github.com/AUTOMATIC1111/stable-diffusion-webui AIGCAIGC 又称生成式 AI (Generative AI)，是继专业生产内容（PGC， Professional-generated Content）、用户生产内容（UGC， User-generated Content）之后的新型内容创作方式，可以在对话、故事、图像、视频和音乐制作等方面，打造新的数字内容生成与交互形式。 与所有人工智能技术一样，AIGC 的能力由机器学习模型提供，这些模型是基于大量数据进行预先训练的大模型，通常被称为基础模型（Foundation Models）。如今以基础模型为驱动的 AIGC 应用迭代速度呈现指数级发展，从由 Stable Diffusion 文生图模型驱动的 AI 作画应用，再到以大语言模型（LLM）驱动的智能聊天机器人，深度学习模型不断完善、开源预训练基础模型的推动以及大模型探索商业化的可能，都在成为这场人工智能颠覆性革命的主要驱动力。 Stable Diffusion 是 2022 年发布的深度学习文字到图像生成模型。它主要用于根据文字的描述产生详细图像，修复（向现有图像添加特征）、修复（从现有图像中删除特征）以及在文本提示的引导下生成图像到图像的转换；尽管它也可以应用于其他任务，如内补绘制、外补绘制，以及在提示词指导下产生图生图的翻译。 它是一种潜在变量模型的扩散模型，由慕尼黑大学的 CompVis 研究团体开发的各种生成性类神经网络。它是由初创公司 StabilityAI、CompVis 与 Runway 合作开发，并得到 EleutherAI 和 LAION​（英语）的支持。 stable-diffusion-webui 仓库地址： https://github.com/AUTOMATIC1111/stable-diffusion-webui Python 版本要求： Python 3.10.6； Git：需安装 Git，下载安装； 模型下载：推荐 C 站；https://civitai.com/ 或参考本文 模型下载部分； 功能1 选择合适的模型，确保照片风格符合期望使用稳定扩散（Stable Diffusion，简称 SD）可以将想象力转化为艺术创作。在开始绘制之前，至关重要的是明确画作的风格。这可以是二次元动漫风格、三维真实照片风格，或者是专注于盲盒模型的表现。确保在选定要生成的照片风格后，切换至适合该风格的大模型，因为不同的模型会直接影响生成照片的整体风格。 在 SD 界面左上角的“Stable Diffusion 模型”选项里，选择适合的模型。例如，如果希望生成一位仿真人物的 AI 小姐姐，则可以选择“chilloutmix”这个大模型，以保证渲染出的效果最为贴近预期。 2 写好关键词，实现事半功倍的效果在选好模型后，需深入思考希望画面中包含的元素，并排除不希望出现的内容。这一过程通过撰写关键词来实现，关键词的准确性直接影响生成图像的效果。 正面关键词生成图像时，关键词是最重要的环节。准确描述想要的照片内容是至关重要的。关键词中包含的内容越详细，生成的图像就越接近脑海中的想象。例如，如果希望生成一位漂亮的小姐姐站在大街上的场景，可以使用以下几种表达方式： 1女孩，漂亮，站着，大街 1漂亮女孩，站在大街上 1个漂亮女孩站在大街上 这三种表达方式无论是单词、短语还是完整句子均可适用，通常推荐将关键词用逗号隔开，并保证使用英文，这是 SD 能有效识别的语言。 完成关键词输入后，点击右侧的“生成”按钮，便可生成 SD 中的首幅图像。 不过，如上所述的关键词可能稍显简略，因此建议在写关键词时采取一定模板。首先，可写出体现照片质量的关键词，这会使生成的图像更加精致。例如： 最高质量 超高清画质 大师的杰作 8k画质 在英文中，这些词语可分别翻译为： Highest quality Ultra-high definition Masterpieces 8k quality 接下来，针对图像的主体进行详细描述。若要生成一位女孩形象，可以具体描述其特征，比如说： 一个女孩 非常精致的五官 极具细节的眼睛和嘴巴 长发，卷发 细腻的皮肤 大眼睛 对于英文翻译为：1girl, very delicate features, very detailed eyes and mouth, long hair, curly hair, delicate skin, big eyes. 可以自由调整这些内容，但建议保留像“精致的五官”、“细节的眼睛”这类描述，以提升图像质量。 接下来，考虑女孩的服饰和配饰，例如裙子、毛衣、牛仔裤等，还可以指定颜色。例子包括： 白色的毛衣，项链（white sweater, necklace）。 最后，可以为背景、天气、姿势和构图等内容添加额外信息，例如： 在街上 阳光 上半身照片（street, sunshine, upper body photos）。 按这种结构整理关键词，步骤清晰、更易于修改。注意每一行最后要用英文逗号分隔，否则将会造成识别错误。关键词书写的基本公式为： 画质 + 主体 + 主体细节 + 人物服装 + 其他（背景、天气、构图等） 如何提高关键词的权重如果生成的图像未能完美反映期望中的“卷发（curly hair）”，可通过给关键词加权重来引起 SD 的注意。其方法有两种： 使用括号加权： 使用单括号（(curly hair)）可使权重提升至 1.1 倍，双括号（((curly hair))）使其增加到 1.21 倍，以此类推。记得使用英文括号。 带数值的括号： 可以在括号中指定数字（(curly hair:1.3)），数字大于 1 表示增加权重，低于 1 则表示降低权重。 添加负面关键词在频繁生成照片的过程中，可能会发现生成的图像中出现了不希望出现的元素，如多出手指或多余手部。这时候，需要通过负面关键词告知 SD 不希望出现的内容。 例如： 低质量 多余的手 不好看的脸 对于新手，可以直接使用： (worst quality:2), (low quality:2), (normal quality:2), lowres, ((monochrome)), ((grayscale)), bad anatomy, DeepNegative, skin spots, acnes, skin blemishes, (fat:1.2) 提示词（Prompt）负面提示词（Negative prompt）Ultra-realistic 8k CG,masterpiece,best quality,(photorealistic:1.4),absurdres,HDR,RAW photo,(film grain:1.1),Bokeh,((Depth of field)),raytracing,detailed shadows,dim light,1 girl,full body,((looking at viewer:1.2)),(suspension:1.5),(spread legs:1.2),(shibari:1.4),sexy,(rope:1.3),bound hands,(arms behind back:1.2),(naughty_face:1.3),shaking,struggling,( half naked :1.4),small clothes,(single ponytail:1.3),(blushing face:1.2),((nsfw:1.4)),(nude:1.2),(dim-lit room :1.2),wooden interior,metal chains,(ropeburns on wrists:1.3),( bra showing:1.3),curvy body,hanging planters,minimal furnishings,lora:deliberate_v2:0.4,(from above:1.2) 第一个框框是提示词 (Prompt) 告诉 AI 要生成哪些东西；第二个框框是负向提示词 (Negative prompt) 告诉 AI 不要生成哪些东西。提示词（关键词）越靠前，生成时越先考虑； 1.越前面的词，SD 越会优先考虑，所以重要的词放前面；2.同类词语放在一起，不要放重复词，比如描写背景的就都写一起；3.只写必要的关键词。 (photorealistic:1.4)：关键词:权重的组合； lora:deliberate_v2:0.4：模型:权重的组合；lora:deliberate_v2 即调用 modelsLora 文件夹下的 deliberate_v2 模型； 提示词调用 LoRA 模型示例：我们把 deliberate_v2.safetensors 放在 modelsLora 文件夹下； 提示词优化从照片提取提示词：image → prompt https://imagetoprompt.com/ （根据所提供的照片写提示词） 正面提示词参考stunning environment / 令人惊讶的环境 / 让AI根据其他关键字做出充满创造力的风景aerial view / 空中鸟瞰 / 鸟瞰远景镜头landscape / 风景画 / 通常是山野风情画背景aerial photography / 鸟瞰绘图 / 类似aerial viewmassive scale / 宏伟构图 / 建筑物的密度与高度有可能被夸大street level view / 街头景色 / 从路面上平视的街景lush vegetation / 植物茂盛 / 植物茂盛的景色idyllic / 瑞士乡间 / 理想退休人士居住的天堂般宁静乡间overhead shot / 正上方鸟瞰 / 正上方或斜上方视角Matte painting / 接景 / 将数种风景地貌拼接在一起blurry background / 模糊背景 / 将背景模糊创造聚焦效果 wallpaper / 壁纸poster / 挂报sharp focus / 鋭焦hyperrealism / 超写实主义insanely detailed / 密密麻麻的细节lush detail / LUSH化妆品美颜filigree / 植物纹精工金饰intricate / 丝线精工金饰crystalline / 水晶首饰perfectionism / 完美主义max detail / 最大化细节spirals / 漩涡纹tendrils / 植物首饰ornate / 复杂装饰纹angelic / 天使般decorations / 盛装embellishments / 礼服镶嵌碎花hard edge / 棱角分明breathtaking / 令人屏息embroidery / 刺綉tiara / 王冠 负面提示词参考Easy Negative / 简单负面worst quality / 最差品质low quality / 低品质normal quality / 正常品质lowers / 降低monochrome / 单色grayscales / 灰阶skin spots / 皮肤斑点acnes / 脓疮，痘疤skin blemishes / 皮肤瑕疵age spot / 老人斑6 more fingers on one hand / 多手指deformity / 畸形bad legs / 畸形腿error legs / 错腿bad feet / 脚型不正malformed limbs / 畸形四肢extra limbs / 多余肢体ugly / 丑poorly drawn hands / 差劲画技的手poorly drawn feet / 差劲画技的足poorly drawn face / 差劲画技的脸text / 文字mutilated / 伤口extra fingers / 多余手指mutated hands / 突变手掌mutation / 突变bad anatomy / 差劲生理结构cloned face / 重复面孔disfigured / 变形fused fingers / 手指融合 3 两分钟打造你的专属模特通过输入关键词，现代生成图像技术已经能轻松创造出一幅比较吸引人的小姐姐照片。然而，假如希望生成 5678 张展示同一张脸的照片，该如何实现呢？这时，Lora 模型就显得尤为重要。 什么是 Lora 模型？Lora 模型的最大优势在于，它能够固定照片的特征，包括人物特征、动作特征，以及照片风格。通过这种方式，用户可以确保生成的图像在某些方面保持一致。 操作步骤 选择 Lora 模型点击“生成”区域中的第三个按钮，随后会弹出一个选项框。在框中找到 Lora 选项，系统会列出事先下载并保存在电脑中的 Lora 模型。 添加 Lora 模型一旦找到想要使用的 Lora，点击它，模型会自动添加到关键词的文本框中。 Lora 的叠加使用前面提到的几张照片正是利用了这三个 Lora，这证明 Lora 是可以叠加使用的。然而，建议初学者在使用时不要添加过多的 Lora，因为如果生成的照片出现问题，很难确定具体是哪个 Lora 导致的。 分隔符使用Lora 之间需要用英文逗号进行分隔。 权重调整每个 Lora 后面都有数字，这个数字用来调整该 Lora 的权重。通常情况下，权重值为 1。增大权重可能会导致生成的照片效果变得奇怪，因此用户通常只会降低权重。 实验组合不同的权重组合会产生不同的照片效果，因此进行多次尝试是很重要的。 选择合适的 Lora 模型选择 Lora 模型时，需要回归到最初希望生成的照片类型。如果目标是生成真人模特的照片，那么在最开始选择的时候就应该使用真人的大模型，确保所选的 Lora 也是针对真人模特的，这样生成的照片效果会更加自然和真实。 4 为什么生成的图像会与他人不同在使用大型生成模型时，尽管采用同样的模型、输入的关键词、Lora 配置以及其他参数，生成的图像仍可能大相径庭。这种差异的原因之一便是“随机数种子（Seed）”的存在。 随机数种子的作用随机数种子在生成图像的过程中扮演了至关重要的角色。它能够影响图像的基本结构，相当于在绘画之初为作品所绘制的线稿。具体而言，随机数种子决定了图像的基础轮廓，包括人物的形状、姿势和位置等细节。例如，即便所有参数设置一致，如果随机数种子不同，生成的角色可能会有完全不同的外观与表现。 随机数种子的具体表现当随机数种子的值为“-1”时，Stable Diffusion（通常简称 SD）会自动为此次图像生成分配一个随机的种子值。这可以被视作生成了一个独特的线稿，使得每次生成的图像具备其独有的特征。更深入地说，这种随机性使得每次生成的结果都可能呈现出不同的风格和细节，即使其他参数完全相同。 如何查看随机数种子若想检查生成图像所使用的随机数种子，可以在生成图像后的信息栏中找到一串英文字符，这其中便包含了当前照片所用的种子值。通过这种方式，用户可以明确地了解每次生成的图像的“基础线稿”是如何变化的。 生成相似图像的必要条件最终，只有当所有生成参数，包括随机数种子，均与他人的照片设置一致时，才能生成与之相似的图像。例如，如果两位用户在同一个场景下都选择了相同的模型、关键词和 Lora 配置，然而却使用了不同的随机数种子，则生成的图像很可能会呈现出显著差异。因此，获取一致的随机数种子对生成相似图像至关重要。 5 一分钟生成自己的二次元造型使用 Stable Diffusion，在不到一分钟的时间内，无论是 2.5D 还是 2D 风格的照片，它都能够生成出色的作品。 接下来，使用图生图的功能，可以将自己的照片转化为二次元风格的图像。为确保生成高质量的二次元图像，需要注意以下步骤： 选择合适的大模型：在进行生成之前，一定要选择一个适合生成二次元风格图像的大模型。这样的选择将直接影响生成效果的质量。 设置正面关键词：正面关键词是影响图像生成的重要因素。可以输入与照片质量和主题相关的一些关键词，例如： 高质量 高清画质 大师杰作 极致的细节 8K 主题关键词可以具体指向，例如“女孩”。 负面关键词设置：对于负面关键词，可以简单地复制之前提到的内容，旨在排除那些不需要的特征或细节，以便进一步优化生成效果。 上传照片：在指定的空白区域点击，上传自己希望生成二次元风格的照片。 调整重绘幅度：重绘幅度的设置决定了生成的照片与原始照片之间的差异程度。 当重绘幅度设置为 1 时，照片被完全转变，与原始照片毫无关系。 若目标是生成二次元图像，可以将重绘幅度设置在 0.6 到 0.8 之间，这样生成的作品会保留一些原始照片的特征，同时又能展现出全新的视觉风格。 6 随便画几笔，你就是“神笔马良”许多人在日常生活中都有随意涂鸦的习惯。尽管这些涂鸦常常显得幼稚或不甚美观，但是否曾想过，这些简单的线条和形状，经过人工智能的处理，能够生成什么样的艺术作品呢？ 看看下面的两张图。左边的图是本人在电脑上胡乱涂鸦的结果，实际上，这幅画的美感远不及专业艺术作品，甚至可以说显得相当粗糙和简单。 然而，当我将这幅作品上传到名为 SD 的人工智能程序时，事情发生了惊人的变化。在我告知 SD 这幅画的主题后，它竟然生成了一幅十分漂亮的图像。这次体验让我感慨，似乎我的涂鸦天赋得到了意外的认可，感到了一丝自豪。 这种现象就是 SD 图生图中的涂鸦功能。操作方式非常简单。首先，在软件的界面上，寻找一个空白区域，并上传一张纯白的图片，这便是你的画纸。 在右边的面板中，有两个小按钮可调整画笔的大小和颜色。使用这些工具后，在画纸上尽情挥洒创意，自由地绘制。 完成基本的涂鸦后，下一步是选择合适的大模型来确定想要的艺术风格。SD 提供了多种风格选项，从写实到抽象，用户可根据个人喜好进行选择。 确定了风格之后，输入几条关键词来引导 AI 生成画作。开始时，可以使用一些与照片质量相关的词汇，确保 AI 理解用户的期待。随后，详细描述涂鸦的主题，比如将“河流”和“森林”用英语表达为“river”和“forest”。 最后，设置下面的重绘幅度到合适的范围，通常在 0.6 到 0.8 之间，最后点击生成，就可以等待 AI 给出令人惊喜的美丽画作。 7 怎么给二次元老婆换衣服假如拥有一张非常好看的照片，但觉得她的衣服不够吸引人，想要在不改变其他细节的情况下为她换上更好看的衣服，一些简单的方法可以帮助实现这一目标。 使用图生图的局部重绘功能 导入照片首先，将需要调整的照片导入设计软件。确保图像质量较高，这样可以获得更好的效果。 涂黑衣服部分在右侧找到画笔工具，调整到合适的大小。将人物的衣服部分涂黑，确保其他部分保持原样。这个步骤的准确性非常重要，建议小心操作，以免误涂到非目标区域。 输入关键词接下来，输入描述新衣服的关键词。首先可以输入一些与质量相关的词汇，比如“高质量”、“高清画质”、“8K”等来保证成品的清晰度。 描述新衣服在输入框中详细描写想要生成的衣服。例如，可以写成：“粉色汉服，精致的裙子，极具细节的服装”。这样的描述可以帮助生成模型理解用户的需求，从而制作出更贴合期望的服装样式。 添加负面关键词为确保生成效果理想，可以直接复制之前使用的负面关键词。这样做能够避免生成不想要的元素，确保效果更符合想法。 点击生成完成上述步骤后，点击生成按钮，就可以得到效果图。系统会根据输入的信息生成一套新的衣服。 换脸的操作方法使用相同的局部重绘功能，也可以实现换脸的效果。只需要将涂黑的部分替换为脸部，输入的关键词应集中在五官特征及其他面部细节上。这样就能够根据用户的描述生成新的人物面孔。 指定衣服颜色的技巧如果希望指定衣服的颜色，仅仅依靠关键词可能不足以确保准确性。这时可以考虑使用以下方法： 导入照片同样地，首先导入需要处理的照片。 涂鸦重绘功能在右侧选择涂鸦重绘工具，调整画笔大小和颜色，能够自己设计衣服颜色，比如希望看到“蓝色的衣袖，粉色的衣服，还要有黄色的花纹”等。 添加关键词继续如前边所述，输入所需的关键词，以确保系统能够生成合适的效果。每次点击生成按钮，都会得到不同的新衣服，展现出多样化的风格。 8 两步拯救超糊照片SD 有一个强大的功能，不仅仅能生成全新照片，还能有效修复模糊的照片，恢复画质的效果比许多其他软件都要出色。 使用后期处理恢复画质在 SD 中，恢复画质的功能被称为“后期处理”。用户可以通过简单的操作将相对清晰的效果带回那些过于模糊的图像。首先，点击界面上的空白区域上传需要修复的图片。 在上传完后，用户将会看到一个名为“Upscaler 1”的选项，这实际上是提供放大效果的工具。对于二次元风格的图片，建议选择“R-ESRGAN4x+Anime68”这个选项。而对于其他实物照片，则可以选择“R-ESRGAN4x”。通过这些选项，可以获得比其他放大器更佳的画质效果。 在确认选项选择无误后，点击生成按钮，即可开始修复过程。 修复真人照片的特别步骤值得注意的是，SD 同样能够修复真人的照片，不过在这一过程中，选用的步骤和参数会有所不同。首先，需将目标照片导入到 SD 软件中。对于真人照片，在放大器的选择中，应指定为“无（None）”，以确保插件不会对整体效果造成干扰。 接着，向下滚动至“GFPGAN 强度”选项。这个参数专为人脸修复而设，将强度调整至最大值（1）能够获得最佳效果。调整完毕后，用户只需点击“生成”按钮，便会见证人脸部分的显著修复。 需要注意的是，该方法虽能有效修复人脸，但对于脸部以外的区域，模糊的程度仍然可能保持不变。因此，在处理时应有此心理准备，修复效果主要集中在人脸部分。 9 获取大佬的咒语在网络上，常常能够看到各路大佬分享的精美图片，许多人希望能够模仿这些作品，却常面临无法精确复制的困境。实际上，Stable Diffusion（SD）中有一个强大的功能，能够帮助用户轻松获取这些图片背后的“咒语”或关键词。 PNG 图片信息首先，用户可以选择使用“PNG 图片信息”功能。将想要解析的照片导入系统后，右侧面板会自动显示该图的详细信息。这些信息包括： 正面关键词：图片展现出的主要特征和主题。 负面关键词：避免在生成新图时出现的元素。 其他种子和大模型信息：这些信息可以帮助生成器选择合适的生成参数。 例如，当将一张包含阿尼亚（动漫角色“间谍 x 家庭”）的照片导入后，可能会看到以下关键词： 正面关键词：anya, 1girl, school uniform 负面关键词：无 其他信息：特别的生成设置和模型编号。 将这些信息整合后，可以前往“文生图”页面。将全部信息粘贴到关键词文本框，并点击“生成”按钮下方的第一个小按钮，SD 会自动处理这些信息并分配到合适的生成位置，确保最终作品能够展现与原图类似的效果和模型。在满足大模型和 Lora 条件的情况下，用户能够生成出一张近似的图像。 标签器（Tagger）如果在导入图片后，右侧未能显示生成信息，这可能表明该照片并非直接从 SD 下载的 PNG 格式。这时，可以使用“标签器（Tagger）”功能。这个工具能够帮助用户生成关键词。 例如，导入一张包含阿尼亚的照片后，系统会输出以下关键词： 具体信息：anya (spy x family), 1girl, solo, school uniform, pink hair, green eyes, looking at viewer, open mouth, ahoge, meme, salute, child, parody, upper body, black dress 这些关键词详细描述了图中元素，包括角色（阿尼亚）、服装（校服）、特色（粉色头发和绿色眼睛）等，通过这些信息，可以确保生成的新作品保留原图的精髓。 10 一招让你自由指定女神的姿势如今，生成美女照片的技术已经相当成熟。可以根据个人需求定制出独一无二的面容和服饰，这为许多创作者和爱好者提供了无限的可能性。然而，如何让这些照片中的小姐姐摆出指定的姿势，仍然是许多人面临的挑战。 传统方法的局限性传统上，试图通过关键词来描述所需姿势的方法往往不够准确，生成的照片可能无法真实反映想要的动作。此外，使用图生图的方式虽可实现某种效果，却常常导致人脸特征的变化，让人感到失望。这些问题促使人们寻求更有效的方法来控制生成的图像。 使用“ControlNet”功能寻找解决方案在这里，“ControlNet”技术就显得尤为重要。这个功能的核心在于它能够精确控制照片的线条，无论是人物的动作还是建筑物的形状等。通过对线条的解析，用户可以在生成的图片中实现更高的精准度。 步骤详解假设需要将左边照片中的小姐姐姿势转变为右边小姐姐的姿势，并最终得到第三张照片。以下是具体的实现步骤： 设置大模型与关键词首先，依照平常的方法，填写所需的“大模型”和关键词，以生成一张想要的小姐姐照片。 启用 ControlNet在生成照片后，向界面的底部移动鼠标，点击“ControlNet”选项。 上传姿势照片点击空白区域，选择上传包含指定姿势的照片。选择一张清晰且能正确反映出目标姿势的图片，这将是实现精确转换的关键。 启用姿势识别点击“启用”按钮。在“预处理器”和“模型”的选项中，选择“openpose”。这个功能专门用于让计算机识别并提取人物的姿势信息。 预览处理结果然后，点击“预览预处理结果”按钮。此时，生成的照片右侧会显示出与原照片相对应的人物姿势线条。这些线条将为后续生成提供基础。 生成最终照片最后，点击生成照片按钮，系统将根据步骤中的设定，将左边的小姐姐图像转换为指定姿势。此时，既保留了原有面部特征，又达成了所需动作的要求。 11 插画师的福音，线稿秒上色随着 AI 绘画技术的迅猛发展，越来越多的人开始关注这一领域。有观点认为，未来许多画师的职业可能面临威胁。然而，实际上，会使用 AI 绘画工具的画师，相较于不会使用的同行，必然具备显著的优势。 例如，当其他画师为了一幅线稿的上色而耗费整整一天的时间时，运用 AI 技术的画师只需不到一分钟便可完成一幅质量上乘的作品。这样一来，在工作效率上，即使作品量相同，AI 绘画的画师便能够远远领先于其他画师。 以下展示了一张我在网上找到的线稿图，经过 SD 上色处理所得到的结果。这次上色是利用“ControlNet”这一功能完成的。操作步骤如下： 上传线稿首先，打开 “ControlNet” 的状态栏。 在空白处上传目标线稿图。 启用功能 点击“启用”按钮，以便启动上色过程。 设置输出 点击“反转输出颜色”，确保颜色准确反映在设计中。 选择模型 在模型选项中选择“Canny”的模型，以帮助更好地识别图像边缘。 接下来，设置必要的内容以优化上色效果： 选择合适的模型假如目标为生成二次元风格的作品，则应选择相关模型，确保所选模型能够符合预期风格。 输入关键词就像撰写描述一样，首先要输入照片质量相关的关键词，如“最高质量”、“大师杰作”等，确保生成过程优质。随后，指定要使用的具体颜色。例如，可以输入如下描述： “可爱女孩，五官精致，银色长发，白皙的皮肤，水汪汪的大眼睛，精致的眼睛和嘴巴。” 为了增添画面的层次感，还可以添加一个简单的背景。 如需更精致的色彩表现，可以通过进一步输入关键词来进行细化。 负面关键词如果需要排除某类元素，只需复制之前所用的关键词即可，以确保不加入不必要的干扰。 通过这一系列操作，不论线稿多么复杂，在 SD 中都能快速上色完成。 12 小白也能进行室内设计“ControlNet”有着另一个非常实用的功能，就是室内设计。想象一下，如果希望对某间房间进行重新装修，想要直观地看到不同风格的效果，以下步骤将提供帮助： 上传房间照片首先，打开“ControlNet”的状态栏。 上传待设计房间的照片，以便于软件理解当前空间布局。 启用设计功能 单击“启用”按钮，启动室内设计功能。 设置预处理器和模型 选择“msld”作为预处理器和模型，这个选择可以更好地处理房屋的线条，确保设计效果的精准。 选择大模型 切换到现实照片所对应的大模型，这将帮助生成符合实际的样式。 输入关键词 先输入影响照片质量的关键词，接着明确设计的主体，如“一个客厅”。 生成新风格设计 完成这些步骤后，只需要点击生成按钮。 其他VAE对于新手而言，深入了解 VAE 的基础工作原理并非必要。理解 VAE 的主要作用足矣：它能够对照片进行加滤镜处理和微调，从而顾及照片的美观。 例如，使用 VAE 处理后的照片相比于未经处理的照片，色彩更加鲜明、生动。未加 VAE 的照片往往显示为灰蒙蒙的状态，缺乏光泽和细节。 在实际操作中，若对照片的色彩没有特别要求，选择一种合适的 VAE 并应用即可。下图展示了作者偏好的 VAE 效果： 迭代步数可以将生成图片的过程视作在画一幅画，而迭代步数则是指在画布上绘制的笔触数量。通常，将参数设置在 20 到 30 之间既可获得良好的图像质量。在此范围内，低于 20 步的图像质量往往不尽如人意。 不过，需要注意的是，步数并非越多越好。超过 30 步时，某些电脑配置可能无法承受高负载，从而无法产生最终图像。因此，对于配置较低的电脑，可以将设置定在 20 至 25 步，而配备较好硬件的可以选择 25 至 30 步。 采样方法不同的采样方法就如同选择不同的绘画风格。面对多种采样方法，选择合适的往往让人困惑。可通过观察他人发布的优质照片，了解他们使用的采样方法，从而结合自身需求做出决策。 在测试中发现，euler a、dpm++2s a karras 和 dpm++2M karras 这几种采样方法生成的照片质量较高且出图速度较快，适合日常使用。 面部修复与高分辨率修复这两项功能的使用非常直接，遵循原则即可。 面部修复：该项功能适用于生成包含真人照片的作品，能够有效提升面部细节，确保其自然与生动。 高分辨率修复：此项功能要求电脑配置相对较好。配置较低的电脑若尝试使用该功能，生成的照片可能无法正常显示，因此需要谨慎选择。 图片分辨率（图片大小）调节图片的宽度和高度可用来控制照片的尺寸。一般情况下： 生成正方形照片的理想设置为：宽度 512 像素 × 高度 512 像素。 生成长方形照片的理想设置为：宽度 512 像素 × 高度 768 像素。 对配置较低的电脑用户而言，应避免网络上看到的高达 1024 或 2048 的设置，这可能导致电脑无法正常处理图像。 生成多图通过调整“总批次数”和“单批数量”这两个参数，可以一次性生成多张图像。例如，将两个参数都设置为 2，意味着会进行两批生成，每批两张图像，从而总共生成 4 张照片。 在日常使用中，若需多个图像，只需调整“总批次数”即可。相应地，“单批数量”则指示同时生成的图像数量，若显卡性能不足，建议避免进行多张图像的同时生成。 用脚本进行照片对比在生成一张照片过程中，用户常会输入多种关键词。为了观察不同关键词或有无特定关键词对输出照片的影响，可以利用脚本中的“提示词矩阵”功能。 例如，可以通过添加关键词“最高质量”（the best quality）来比较其带来的效果。书写格式为：关键词|需要对比的关键词，形成的效果是生成一张含有两幅照片的拼图，能直观见到差异。 此外，如果希望比较在不同采样方法下，迭代步数的不同生成的照片，用户可使用脚本中的“XYZ 图表”功能。选择 X 轴表示“迭代步数”，输入需要比较的步数，并选择 Y 轴为“采用器”，最后生成的图像能够展示在不同采样方法和迭代步数下结果的一览图。 这样的比较将帮助选择出最符合自己需求的采样方式和迭代步数。 模型下载1.1 筛选模型类型在网站页面的右上角，点击 筛选按钮。在弹出的框框中，寻找需要的模型类型： Checkpoint：通常指较大且功能全面的模型。 LoRA：指较小且专注于特定任务的模型。 这两种类型是最常用的选择。 1.2 下载模型浏览模型时，可以通过查看模型的预览照片，找到感兴趣的模型并点击进入。在页面右侧会有一个 “Download” 按钮，点击后便可将文件保存到本地计算机。文件的保存位置将在下一节详细说明。 另外，左上角的 “Images” 功能可以浏览其他用户已制作的图片，找到喜欢的可以直接点击进入。 在深入的页面中，可以看到该图像的所有信息。点击 Lora 或 Checkpoint，可直接跳转到相关模型的下载页面。页面下方展示的是相应图片的关键词和其他相关信息，点击 “Copy…Data” 可以复制这些信息。 回到 **Stable Diffusion (SD)**，将复制的关键词粘贴到文本框中，并点击右侧按钮，便可自动加载相关信息。需注意的是，对大模型的选择需要手动更换。 通过这些步骤，可以生成出与专业制作者相似的照片。当然，由于每个人的计算机网络配置不同，生成的照片可能会有细微差别。 2. 模型下载到哪里模型下载后，存放于 Stable Diffusion 文件夹。具体的路径一般为： models/Stable-diffusion models/Lora models/VAE modelsStable-diffusion 文件夹下的是基础模型，对应类型名称 Checkpoints，又称大模型（你可以在 http://127.0.0.1:7860/ 页面左上角选择大模型）； modelsLora 文件夹选的是微调模型；（可以在提示词中调用） modelsVAE 文件夹下放的是美化模型；（可以在提示词中调用） 用户可以在自己电脑中直接找到以上文件夹，确保模型能够被顺利识别与使用。 3. 如何分辨模型若用户下载了一个模型，却不清楚其类型或放置位置，可借助 秋叶的模型解析工具 (链接为 https://spell.novelai.dev/)。使用时，只需将模型文件拖动到该工具的空白处，系统将自动弹出模型的详细信息。在“模型种类”中，即可清晰看到该模型的类型。","categories":["4.软件","AI"]},{"title":"人工智能知识结构","path":"/2023/10/24/4-软件-AI-人工智能知识结构/","content":"基础知识 Python 编程语言 基础语法与数据结构 常用库：NumPy、Pandas、Matplotlib 面向对象编程与函数式编程 机器学习基础 监督学习与非监督学习 回归、分类、聚类算法 评估指标：准确率、召回率、F1-score 等 自然语言处理（NLP）基础 文本预处理：分词、词性标注、命名实体识别等 经典模型：TF-IDF、Word2Vec、GloVe 等 数学基础 线性代数：矩阵运算、特征值与特征向量等 微积分：导数、积分、多变量函数等 概率统计：概率分布、贝叶斯定理、假设检验等 前沿算法和框架 Transformer、BERT 等算法原理 Transformer 架构及其注意力机制 BERT、GPT 等模型的工作原理与应用场景 深度学习框架 TensorFlow PyTorch 框架对比与选择 NLP 技术 词嵌入（Word Embeddings） 循环神经网络（RNN）及其变种（LSTM、GRU） 自然语言生成（NLG）与理解（NLU） 工程化实践 模型部署 REST API 部署 云服务（如 AWS、GCP、Azure） 边缘设备部署 模型优化 模型压缩：量化、剪枝、知识蒸馏等 高效推理：ONNX、TensorRT 等 集成与应用 将 LLM 集成到 Web 应用、移动应用等 构建对话系统、自动摘要等具体应用 实践项目 参与开源 LLM 项目 贡献代码、文档或测试 学习社区最佳实践 自主实现 LLM 应用 选题、需求分析 数据收集与清洗 模型训练与调优 应用部署与测试 持续学习 关注 LLM 领域最新研究成果 阅读顶会论文（如 ACL、EMNLP、NeurIPS 等） 关注相关技术博客与新闻 参加机器学习比赛 Kaggle 比赛 各类 NLP 挑战赛（如文本生成、对话系统等） 应用优化 性能优化 提高模型推理速度 减少资源占用 模型调整 调整超参数 修改模型结构 数据扩充 增加训练数据量 进行数据增强","categories":["4.软件","AI"]},{"title":"语音转文字并美化方案","path":"/2023/10/23/4-软件-AI-语音转文字并美化方案/","content":"获取视频文件转为音频 传入音频文件，调用腾讯云 API 进行转文字 部署 ollma3，调用 API 进行文案优化 返回优化后的文案，调用文案生成视频 获取生成后的视频 部署 wsl，优化 3568 的 photo，利用 clash 局域网代理","categories":["4.软件","AI"]},{"title":"Field-Oriented Control (FOC) 矢量控制 磁场定向控制_sensorless field oriented control of a pmsm中文-CSDN博客","path":"/2023/10/20/4-软件-FOC-Field-Oriented-Control-FOC-矢量控制-磁场定向控制-sensorless-field-oriented-control-of-a-pmsm中文-CSDN博客/","content":"永磁同步电机（PMSM, Permanent Magnet Synchronous Motor）由于它噪声小、高效节能的显著优势，广泛被用于新能源汽车、机器人伺服和家电等领域。上图是一个 PMSM 的示意图，ABC 为三相交流电，外圈为定子，内部为转子。转子为永磁体（permanent magnet）。当定子线圈通上 ABC 三相交流电后，由于电磁效应带动转子转动，而转子转动的频率和 ABC 三相交流电的频率相同，所以叫同步电机（synchronous motor）。 和 PMSM 非常相似的一种电机叫做 BLDC Motor（直流无刷电机，Brushless DC）。它们显著的区别在于反电动势（back EMF）的波形。BLDC 的反电动势呈梯形状，而 PMSM 的反电动势呈正弦波状。这两者的差异的原因是由于 PMSM 的定子绕组线圈缠绕呈正弦分布，而 BLDC 的定子绕组线圈缠绕为集中式。 下面的动图展现了 BLDC 和 PMSM 在控制上的差异： 浅蓝色箭头代表转子的磁场矢量方向，可以看到浅蓝色箭头在 BLDC 和 PMSM 都是在不停旋转，并且这个旋转会产生力矩（torque）带动机械负载的运动。BLDC 的转子旋转是一顿一顿的，PMSM 的转子旋转是非常连续平滑。控制 BLDC 的最经济的方法是 6 步换向法。通常通过检测转子角度位置，来依次给定子换向，这样的换向，造成了输出力矩有波动。而 PMSM 通过 FOC 控制，不需要换向，可以使得转子保持连续、平滑的转动。这样的”平滑”效应就是 Field Oriented Control（FOC）的结果。定子三相交流电流生成的空间磁场向量，通过控制驱动转子磁场旋转，形成力矩–—— 这就是 Field Oriented Control（磁场定向控制）。 MTPA（最大力矩电流比控制，Maximum Torque Per Amp） 永磁同步电机一般分为两种：SPM（表贴式）和 IPM（内嵌式）。从控制的角度 SPM 要比 IPM 简单很多，们先以 SPM 为例，暂不考虑弱磁（一种高转速情况下的控制方法）。如果们的目标是”相同的电流输入，达到最大的输出力矩”。假设下图中上下端是定子，中间的是转子。让们人为改变定子磁场矢量和转子磁场矢量的夹角，当夹角为 0 度的时候，没有输出任何力矩，因为磁性的南北极互相吸引。再让们旋转转子，改变一下夹角，会觉得力矩增大。当定子和转子磁场向量成 90 度的时候，产生的力矩最大。这是们想达到的效果 – 最大化电流的利用效率，们称之为：MTPA(Maximum Torque Per Amp)。在这种状态下，输出的力矩和输入的电流幅度成正相关。们只需要调整电流的幅值，就可以控制电机输出的力矩。如果们需要根据反馈来调整电机的电流、速度和位置，可以通过三个 PI 控制器的级联的电流环、速度环和位置环来实现。但最终，还是通过对电流的控制来实现。 通过上面的介绍，们可以把 ABC 三相交流电形成的磁场，看着一个矢量。FOC 最重要的原则就是使这个电流矢量和永磁体转子转动形成的磁场矢量保持垂直。由于转子是在不停的转动，FOC 的任务就是：1.不停的观测转子的角度2.将电流矢量的角度保持和转子磁场矢量垂直（MTPA）上图右侧是 ABC 三相交流电的示意图。三种颜色代表三相交流电 ABC。它们的相位差为 120 度，们可以把它们表示为上图左侧的矢量形式（abc 矢量坐标系）。它们合成的总矢量是淡蓝色。 为了研究方便，们将静止的 abc 坐标系变为静止的 αβ 坐标系，这一步也叫 Clarke 变换： 接着，们将静止的 αβ 坐标系变为旋转的 dq 坐标系，这一步也叫 Park 变换： 在经历 Clarke-Park 变换后，三相交流电变成了”直流电”：Id（深蓝）和 Iq（红色），它们实际上是电流矢量在 dq 坐标系的投影。d 表示 direct（直接），q 代表了 quadrature（正交）。如果是 SPM，为了使得电流效率最高（MTPA），们只要使 Id 0，即所有的电流都作用于正交 – 产生力矩。这样大大简化了控制。 们通过控制 Id、Iq 去产生相应的 Vd、Vq，经过反 ParkClarke 变换和 SVPWM（Space Vector Pulse Width Modulation）调制电压信号，经过门驱动（Gate Driver）和逆变器（Inverter）产生三相电压 Va、Vb、Vc，最后将 Va、Vb、Vc 输入到 PMSM，完成了 FOC。上图是 FOC 的控制信号示意图，其中蓝色的模块是软件实现模块，灰色的为硬件部分。 们经常听到，电流环的的控制周期为 100us（10K Hz）。通常来说，上面的蓝色部分一般在 DSP 或者 MCU 的 ISR（interrupt service routine，中断服务程序）中实现。也就是说，每隔 100us，DSP 或者 MCU 就有专门的 ISR 函数做如下处理动作：1.测量出转子的角度（θ），得出所需的 Id、Iq 电流。将所需要的 Iq 电流向量和该角度保持垂直。在 MTPA 情况下，如果是 SPM，所需 Id 设为 0。2.测量出实际相电流（Ia、Ib、Ic），通过 ClarkePark 变换产生实际 Id、Iq 电流。3.利用上述的所需电流和实际电流信号差，通过 PI 控制器，得出 Vd、Vq。4.经过反 ParkClarke 变换、SVPWM 产生占空比，交给逆变器生成 Va、Vb、Vc 驱动电机。 Field-Oriented Control (FOC)磁场定向控制（FOC），也称为矢量控制，是一种用于控制永磁同步电动机（PMSM）和交流感应电动机（ACIM）的技术。 FOC 在整个扭矩和速度范围内都具有良好的控制能力。 FOC 的实现需要将定子电流从固定参考系转换为转子磁通参考系（也称为 d-q 参考系）。 矢量控制是建立在被控对象准确的数学 模型 上，使交流电机控制由外部宏观稳态控制深入到电机内部电磁过程的瞬态控制。矢量控制通过坐标变换将交流电机内部复杂耦合的非线性变量变换为相对坐标系为静止的直流变量（电流、磁链、电压等），实现近似解耦控制，并从中找到约束条件，获得某一目标的最佳控制策略，id0 控制是矢量控制的一种特定的控制策略，在转子坐标系内实现永磁同步电机交直轴电流解耦，由于 id、iq 双电流闭环的存在，使电机 iq 电流动态跟随系统力矩给定（tektiq，kt 为电机力矩系数），实现电机电磁力矩控制。 速度控制和转矩控制是 FOC 最常用的控制模式。位置控制模式不太常见。大多数牵引应用使用转矩控制模式，在该模式下，电动机控制系统遵循参考转矩值。在速度控制模式下，电机控制器遵循参考速度值，并生成用于形成内部子系统的转矩控制的转矩参考。在位置控制模式下，速度控制器构成内部子系统。 FOC算法 的实现需要电流和转子位置的实时反馈。使用传感器测量电流和位置。也可以使用无传感器技术，该技术使用估计的反馈值代替实际的基于传感器的测量。 Permanent Magnet Synchronous Motor (PMSM)下图为永磁同步电机（PMSM）的 FOC 架构： AC Induction Motor (ACIM)下图为交流感应电动机（ACIM）的 FOC 架构： PMSM的数学模型（Mathematical Model of PMSM） 原理解析 | Field Oriented Control（磁场定向控制）的 Simulink 实现","tags":["clippings"],"categories":["4.软件","FOC"]},{"title":"FOC（磁场定向控制）及电机控制技术简介-RoboticsCV","path":"/2023/10/19/4-软件-FOC-FOC（磁场定向控制）及电机控制技术简介-RoboticsCV/","content":"前言 理论基础 FOC驱动器与无刷电调的区别 无刷电机驱动原理 基础知识 BLDC驱动原理 电机模型和运动分析 驱动电路简述 FOC原理 FOC项目（开源） 参考 前言理论基础 BLDC（Brushless DC Motor），无刷直流电机，与传统的有刷直流电机（Brushed DC Motor）相比具有更高效率、更长寿命和更低的维护要求。除此之外，BLDC 还具有高功率密度（体积小、重量轻、功率输出大）和高转速的优势。 PMSM（Permanent Magnet Synchronous Motor），永磁同步电机，亦称无刷交流电机（BLAC, Brushed AC Motor）。PMSM 具有和 BLDC 类似的结构特点。 FOC（Field-Oriented Control），磁场定向控制技术，也被称作矢量控制（Vector Control），是一种用于交流电机控制的高级控制算法。它通过准确控制电机的磁场方向和大小，实现对电机速度和转矩的精确控制。 FOC 驱动器与无刷电调的区别电调（ESC）的全称为电子调速器（Electronic Speed Controller），是一种硬件产品。FOC 则是一种电机驱动控制方法。 无刷电机驱动原理电机由两个主要组成部分构成：固定的定子（stator）和旋转的转子（rotor），无刷电机也不例外。转子又分为内转子和外转子两类。最熟悉的、在航模和无人机上使用的就是外转子结构的无刷电机，而内转子无刷电机则通常用于家电、工业驱动和机器人等应用。 注：若线圈是转子则磁极是定子，若线圈是定子则磁极是转子。下图所示无刷电机属于前一种结构。 另一组常见的概念是相数和极数。电机的相数，可以简单理解为电机定子线圈的组数。电机的极数则是指电机转子上磁极的数量（一对磁极包括一个 N 极和一个 S 极）。下图所示为一个具有12个电机绕组槽（slot）、16个磁极（magnet）的三相无刷直流电机示意图。 常见电机的相数，通常有以下几种： 单相电机（Single-Phase Motor）：单相电机具有一个绕组（相），通常用于低功率应用，如小型家用电器、风扇、泵等。单相电机的运行起动相对简单，但通常功率较低。 三相电机（Three-Phase Motor）：三相电机具有三个绕组（相），广泛应用于工业和商业领域，包括大型马达、制造设备、电动车、空调等。它们通常比单相电机具有更高的功率和效率，因为它们的电流分布更均匀，能够提供平稳的旋转力矩。 步进电机（Stepper Motor）：步进电机通常具有多个相，通常是两相、四相或八相。它们通过逐步激活不同的相来实现精确的角度控制，因此在需要精确位置控制的应用中非常有用，如打印机、CNC 机床和 3D 打印机。 通过相数和极数可用以下公式计算转速（单位：转每分钟，RPM）：转速 (60 * 电源频率) (极对数 * 相数) 这个公式称为同步转速公式，它描述了电机转子旋转的速度与相数和极对数之间的关系。需要注意的是，这个公式是针对同步运行状态下的电机转速，实际运行时可能存在一定的滑差。 基础知识 左手定则（电动机原理。事实后面介绍的安倍定则也适用于解释电机的运动原理）：用于判断导线在磁场中的受力方向。拇指与其他四指方向垂直且在同一平面，磁感线从手心垂直穿过，四指指向电流方向，则大拇指指向的就是安培力方向（即导体受力方向）或洛伦兹力。（当电流方向与磁场平行时，电荷运动方向也与磁场方向平行，所受洛伦兹力为零） 右手螺旋定则（安培定则）：用于判断电流的感应磁场方向。一般来说有两种情况，分别为”单根导线的感应磁场方向”和”通电螺线管的磁场方向”。左图所示，右手大拇指指向电流方向，则四指弯曲方向就是磁场方向。右图所示，四指蜷握并顺着电流方向，则拇指指向的就是磁场方向，即 N 极。 右手定则（发电机原理）：用于判断导线切割磁感线时所产生的电流的方向。伸开右手，使大拇指跟其余四指垂直并且都跟手掌在一个平面内，让磁感线垂直穿入手心，大拇指指向导体运动方向，则其余四指所指方向即为感生电动势方向。（注：利用反电动势测量电路获取转子位置，是无感电调工作原理之一） BLDC 驱动原理BLDC 驱动原理基于电子换向技术，相比传统有刷直流电机，它没有碳刷和机械换向器。BLDC 的驱动依靠精确改变电机上多个定子线圈（假设线圈绕组是定子如航模无刷电机）的电流交变频率和幅值（表现为多个波形变化曲线及其相序关系），在定子周围形成磁场, 驱动转子永磁体转动。因此可以将研究的重点放在如何改变多个定子线圈的相序和电流，而这需要交给驱动电路、控制器、传感器（若是闭环控制）这些硬件以及控制器上的算法软件，所以到了具体实现这一步，就得靠硬件和软件！ 电机模型和运动分析为了分析方便，以简化的三相二极内转子电机为例（且转子为磁极、定子为绕组）。事实上，定子的三相绕组有星形连结和三角连结两种方式，其中星形连结更为常用（连接方式是每一相引出导线的一头，而另一头和其他相两两相连），而后续就采用该模型做分析。 假设此时对 A、B 极分别施加正、负电压，那么由右手螺旋定则可以判断出线圈磁极的方向如下图红色箭头和蓝色箭头所示（绿色箭头可以理解为两线圈合成的磁极方向）。此时当转子处于与 C 点与转轴中点连线重合的角度时，受到的力矩最大（两个磁极一推一拉），直到旋转到与 AB 连线平行的且磁铁内部磁力线方向和 AB 间磁力线方向一致的时候，才是稳定的平衡位置。换句话说，AB 相通电会让转子努力转到下图右边的状态。 以此类推，可以得到每个通电状态线圈绕组的磁极方向，进而获得转子的方向和角度（方向重叠、角度相反），就是下图中的 6 个状态，每个状态相隔 60°，即完整的一周转动包括 6 个状态，共进行了 6 次换相： 注：事实上，横坐标 1 和 2 的中间位置也是一个力平衡点。但此处三相均没有换向，因此未计入状态之一。 推荐一篇呈现了运动规律动画演示的 博文。在这篇文章中，电机为外转子磁极结构，且极数为 12。该电机旋转一周所需的总步数为 12*336（极数乘以相数得到的结果，反映了电机中磁场变化的次数，决定了电机旋转一周所需的步数。总极对数越高，电机通常会具有更平滑的输出特性。至于绕组数量如何确定还没有深究，但似乎可以使用公式 线圈绕组数360(相邻磁极夹角 + 360(pole*3))) 计算出正确的值，感兴趣的朋友可以自行研究下。 驱动电路简述无刷电机的驱动电路主要使用三相逆变电路来实现。逆变电路的主要功能是将直流电转换为交流电（通过前一节的分析可知，无刷电机驱动需要在不同时刻施加不同方向的电压，故需要逆变电路）。逆变器的工作原理是通过控制开关器件（如晶体管或 MOSFET）的导通和截止，来改变电流的方向和幅值，从而产生所需频率和幅值的交流电。 逆变电路一般是采用半桥 MOS 电路实现。两个功率开关器件即 MOS 管组成上、下桥臂，以中间点作为输出，提供方波型号。这种结构在 PWM 电机控制、DC-AC 逆变、电子镇流器等场合有着广泛的应用。由于开关延时的存在，当其中的一个管子栅极信号变为低时，它并不会立刻关断，因此一个管子必须在另一个管子关断后一定时间方可开启，以防止同时开启造成的电流穿通，这个时间称为死区时间。 用 3 个半桥电路就可以组合成三相逆变电路，每个半桥引出的一根输出线跟无刷电机的一根相线相连，就完成了最基本的无刷驱动电路。 FOC 原理FOC 项目（开源）SimpleFOC ODrive 参考稚晖君 【自制FOC驱动器】深入浅出讲解FOC算法与SVPWM技术 DengFOC 主页文档 FOC最基本原理、clark变换 、park变换、附代码 野火 电机应用开发实战指南","tags":["clippings"],"categories":["4.软件","FOC"]},{"title":"1. Git介绍和基本命令","path":"/2023/10/18/4-软件-Git-1-Git介绍和基本命令/","content":"版本控制版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 Git 是免费、开源的分布式版本控制系统。 集中式版本控制系统集中管理的中央服务器，保存着所有文件的修改历史版本。 协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。 分布式版本控制系统远程仓库同步所有版本信息到本地的每个用户 本地可以查看所有的历史版本信息，偶尔远程更新，查看其他用户修改提交到远程 用户即使离线也可以本地提交，push 推送到远程服务器才需要联网 每个用户都保存了历史版本 工作区域 Workspace：电脑本地看到的文件和目录，在 Git 的版本控制下，构成了工作区。 IndexStage：暂存区，一般存放在.git 目录下，即.gitindex,它又叫待提交更新区，用于临时存放未提交的改动。执行 git add，这些改动就添加到这个区域。 Repository：本地仓库，执行 git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 HEAD 指向最新放入仓库的版本。当执行 git commit，文件改动就到本地仓库。 Remote：远程仓库，云端版本库 文件状态 Untracked: 文件未加入到 git 库，未参与版本控制，处于未跟踪状态。通过 git add，可以变为 Staged 状态 Unmodified：文件已经加入 git 库，版本库中的文件快照内容与文件夹中还完全一致。 Unmodified 的文件如果被修改, 就会变为 Modified。如果使用 git remove 移出版本库，则成为 Untracked 文件。 Modified：文件被修改进入 modified 状态，文件这个状态通过 stage 命令可以进入 staged 状态 staged：暂存状态. 执行 git commit 则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为 Unmodified 状态。 正向工作流 git 的正向工作流程一般就这样： 从远程仓库拉取文件代码回来；git pull 在工作目录，增删改文件； 把改动的文件放入暂存区；git add 将暂存区的文件提交本地仓库；git commit 将本地仓库的文件推送到远程仓库；git push 常用命令 git clone [url] #克隆远程仓库git add [dir/file]#添加目录/文件到暂存区git commit [--amend] -m [msg] #提交暂存区到仓库区,msg为说明信息(amend用新的commit覆盖提交)git log [--oneline] [-p [file]]#查看提交历史(online精简模式)(p指定文件)git blame #列表方式查看指定文件的提交历史git diff #显示暂存区和工作区的差异git diff #显示暂存区和工作区的差异git diff filepath #filepath路径文件中，工作区与暂存区的比较差异git diff HEAD filepath #工作区与HEAD ( 当前工作分支)的比较差异git diff branchName filepath #当前分支文件与branchName分支的文件的比较差异git diff commitId filepath #与某一次提交的比较差异git status [-s] [--show-stash] #查看当前工作区暂存区变动(-s概要信息)（show-stash显示暂存文件）git pull/fetch #拉取远端代码#git pull = git fetch+ git merge。pull的话，拉取远程分支并与本地分支合并#fetch只是拉远程分支，怎么合并，可以自己再做选择。git pull #拉取远程仓库所有分支更新并合并到本地分支。git pull origin master #将远程master分支合并到当前本地master分支git pull origin master:master #将远程master分支合并到当前本地master分支，冒号后面表示本地分支git fetch --all #拉取所有远端的最新代码git fetch origin master #拉取远程最新master分支代码git push #推送到远端git push origin master #将本地分支的更新全部推送到远程仓库master分支。git push origin -d #删除远程branchname分支git push --tags #推送所有标签 # git rebase`rebase`又称为衍合，是合并的另外一种选择。 `rebase`好处是： 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：`git pull --rebase`# git stash`stash`命令可用于临时保存和恢复修改git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作git stash list 显示保存的工作进度列表git stash pop stash@num 恢复工作进度到工作区git stash show ：显示做了哪些改动git stash drop stash@num ：删除一条保存的工作进度git stash clear 删除所有缓存的stash。# git reflog显示当前分支的最近几次提交# git blame`git blame filepath`记录了某个文件的更改历史和更改人# git remotegit remote 查看关联的远程仓库的名称git remote add url 添加一个远程仓库git remote show [remote] 显示某个远程仓库的信息","categories":["4.软件","Git"]},{"title":"2. Git服务器环境搭建和客户端使用","path":"/2023/10/17/4-软件-Git-2-Git服务器环境搭建和客户端使用/","content":"服务端 安装 git 和 ssh sudo apt-get install gitsudo apt-get install openssh-server openssh-client 增加 git 用户并生成文件夹 sudo adduser gitsudo mkdir /home/git 创建 ssh 证书认证文件 sudo mkdir /home/git/.sshsudo touch /home/git/.ssh/authorized_keys 临时修改文件的权限 sudo chmod 777 /home/git/.ssh/authorized_keys 把需要访问 git 服务器的客户端公钥 id_rsa.pub的内容复制到 authorized_keys 文件 修改 authorized_keys 文件的权限 sudo chmod 700 /home/gitsudo chmod 700 /home/git/.sshsudo chmod 600 /home/git/authorized_keyssudo chown -R git:git /home/gitsudo chown -R git:git /home/git/.sshsudo chown -R git:git /home/git/.ssh/authorized_keys 为了安全考虑禁止登录 git 服务器的 shell，修改 git 的 shell 用 /usr/bin/git-shell 把 /etc/passwd 的 git:x:1004:1004:,,,:/home/git:/bin/bash 改成： git:x:1004:1004:,,,:/home/git:/usr/bin/git-shell 保存 建代码仓库 sudo mkdir /home/Repo #创建仓库的目录sudo git init --bare /home/Repo/test.git #创建仓库sudo chown -R git:git /home/Repo/test.git #修改权限为git 以后每创建一个新的仓库，记得最后一步操作: 修改仓库所属用户为 git。 客户端 安装 git Linux 环境下 sudo apt-get install git Windows 环境下直接安装 Git安装包 配置连接 通过密钥方式 ssh-keygen -t rsa [-C 的邮箱地址] 会生成 id_rsa.pub 文件,添加该公钥到到服务器 Linux 环境下，密钥默认位于 /home/ubuntu/.ssh/id\\_rsa Windows 环境下密钥位于 C:\\Users\\xxx.ssh\\id\\_rsa.pub 通过用户名密码 git config –global user.name usernamegit config –global user.email username@gmail.com 在连接 git 时，会需要输入账号密码，直接输入即可 附注：增量备份 -Git 服务器备份通过 rsync 使用 crontab 建立每天凌晨 3 点定时触发的任务 crontab -e 0 3 * * * * rsync -av -e ssh -i /path/to/id_rsa /homt/git/ remote_user@X.X.X.X:~/backup","categories":["4.软件","Git"]},{"title":"3. Git常用操作","path":"/2023/10/16/4-软件-Git-3-Git常用操作/","content":"项目创建对于网络项目git clone [url] 将 GitHub 中的网络项目复制到本地，只需在修改完之后 commit 即可，然后更新仓库代码，就可同步修改。 对于本地项目首先要创建一个文件夹用以存放文件，然后使用 git init 对进行初始化操作 git status 得到 git 中文件的状态 git add filename 将 filename 文件加入到 git 本地仓库中去（git rm -cached 可移除） git commit -m ‘status’ 表示提交信息（status 表示附加信息） 之后对本地项目进行关联 git remote add origin [url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 关联之后可以向远程仓库提交代码（更新仓库代码） 日常 push`git status` #获取状态`git add . `#添加文件到暂存区`git commit -m 20191121 push `#提交文件`git push origin master `#推送 日常 pull git diff 比较工作目录和 Index 中的代码。 git fetch 当于从远程获取最新版本到本地，不会自动 merge ，比 Git pull 更安全些 git checkout app/model/user.rb 将 user.rb 文件从上一个已提交的版本中更新回来，未提交的工作目录中的内容全部会被覆盖 首次使用配置 ssh ssh-keygen -t rsa ssh -T git@github.com 将.ssh 下的 pub 公钥复制到 github 账号中的设置-SSH，添加密钥即可 首次使用设置用户 git config (--global) user.name username git config (--global) user.email username@gmail.com git config --global user.name liuluhuagit config --global user.email 718050012@qq.com 上传下载常用命令 git push origin（仓库名） master（分支） 更新仓库代码（上传） git pull origin（仓库名） master（分支） 更新本地代码（下载） 回退历史版本 git log git reset --hard \\[commit\\_id] git revert \\[commit\\_id] 网络项目 git clone \\[url] git remote add origin \\[url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 版本情况 git tag 查看版本情况 git tag V1.0 新建版本 git checkout V1.0 切换至版本 V1.0 分支情况 git branch 查看当前分支情况 git checkout a 切换到分支 a git checkout -b a 新建分支 a 并切换到分支 a git branch -d a 删除 a 分支 git merge a 将 a 分支的代码合并到 master 分支上","categories":["4.软件","Git"]},{"title":"4. Git分支","path":"/2023/10/13/4-软件-Git-4-Git分支/","content":"分支Git 是一个流行的分布式版本控制系统，一般都是存在多个分支的，开发分支，回归测试分支以及主干分支等 在 Git 中，分支是指指向 Git 提交历史中某个特定提交的指针。 每个分支都包含在 Git 提交历史中的一系列提交，这些提交构成了分支的历史记录。 分支在 Git 中非常重要，因为它们允许多个开发人员同时在同一个代码库中工作，而不会相互干扰。 通过创建分支，每个开发人员都可以在自己的分支上进行工作，而不会影响其他人的工作。 这样，开发人员可以在不干扰其他人的情况下，独立地开发和测试新功能，最终将这些更改合并到主分支中。 在 Git 中，分支操作非常简单。以下是一些常用的 Git 分支操作： 创建分支要创建一个新分支，请使用以下命令： git branch branch-name 这将创建一个名为 branch-name 的新分支。 注意，此时仍然在当前分支上工作。 git checkout -b branch-name 新建一个分支，并且切换到新的分支 branch-name 查看分支要查看所有分支，请使用以下命令： git branch 这将列出所有分支，当前分支将用一个星号标记。 git branch -r 查看所有远程的分支 git branch -a 查看所有远程分支和本地分支 删除分支要删除一个分支，请使用以下命令： git branch -d branch-name 这将删除名为的分支。 注意，如果该分支包含未合并的更改，则必须使用 -D 选项而不是 -d 选项来强制删除该分支。 切换分支要切换到另一个分支，请使用以下命令： git checkout branch-name 这将使从当前分支切换到名为 branch-name 的分支。 注意，需要在切换分支之前将所有更改提交或保存。 合并分支要将一个分支合并到另一个分支，请使用以下命令： git merge branch-name 将名为 branch-name 的分支合并到当前分支中。 注意，如果两个分支上都有对同一文件的更改，则可能会发生冲突。在这种情况下，需要手动解决冲突并提交更改。 git merge –no-ff origindev 在当前分支上合并远程分支 dev git merge –abort 终止本次 merge，并回到 merge 前的状态 以上是一些常用的 Git 分支操作。使用这些操作，可以轻松地创建、切换、合并和删除分支。这些操作使多人协作变得更加容易，因为每个开发人员都可以在自己的分支上进行工作，并将更改合并到主分支中。在实际开发中，分支操作是非常重要的，最好能够熟练掌握并运用这些操作","categories":["4.软件","Git"]},{"title":"5. Git撤销或回退","path":"/2023/10/12/4-软件-Git-5-Git撤销或回退/","content":"撤销或回退在 Git 中，撤销和回退是指撤销或回退先前的提交或更改。 简单介绍下 Git 中的撤销和回退操作，以及如何使用它们来管理代码库。 可以把版本库上的提交回退到暂存区，修改记录保留 git reset –-soft [] 可以把版本库上的提交回退到工作区，修改记录保留 git reset –-mixed [] 可以把版本库上的提交彻底回退，修改的记录全部 revert。git reset –-hard reset 和 revert 的区别git reset 和 git revert 的主要区别在于它们对历史记录的处理方式。git reset 会删除历史记录并永久删除更改，而 git revert 会创建一个新的提交来撤销更改并保留历史记录。 git reset 命令会将 HEAD 指针指向指定的 commit，并将暂存区和工作目录恢复到该 commit 的状态。这意味着在执行 git reset 后，之前的更改将不再存在于工作目录和暂存区中。如果希望永久删除一些更改并且不再需要它们，可以使用 git reset。 git revert 命令会创建一个新的提交来撤销指定的提交。这意味着在执行 git revert 后，之前的更改仍然存在于工作目录和暂存区中，并且需要提交一个新的撤销提交。如果想要保留更改历史记录并且不想永久删除更改，可以使用 git revert。 获取 IDgit log 获取到想要回退的 commit_id 撤销回退未提交的更改**(add 之后，commit 之前)** 要撤销未提交的更改，请使用以下命令： git checkout file-name 将名为 file-name 的文件恢复到上一个提交的状态。 本地本次的更改也不再保存，恢复到上一个提交 (commit) 的状态 git reset HEAD --file 回退暂存区里的某个文件，回退到当前版本工作区状态 保存工作区的更改，只是撤销 git add 这一步操作 git checkout . 将所有文件恢复到最新提交的状态。请注意，此操作将删除所有未提交的更改。 撤销回退上一个提交**(commit 之后，push 之前)** 撤销上一个提交 git reset HEAD~1 将 HEAD 指针移动到上一个提交。 工作区保留先前的更改，需要重新添加到暂存区 (git add) 回退到上一个提交 git reset --hard HEAD~1 将 HEAD 指针和工作树都重置为上一个提交的状态。 请注意，此操作将删除所有未提交 (commit) 的更改。 撤销回退到特定的提交**(push 之后)** 撤销到特定版本 git revert commit_id 这将创建一个新的提交，该提交撤销名为 commit-hash 的提交所做的更改。 本次撤销操作也会作为一次提交 (push) 进行保存 回退到特定版本 git reset --hard commit_id 将 HEAD 指针和工作树都重置为名为 commit-hash 的提交的状态。 请注意，此操作将删除所有未提交的更改。 回退完成后，git push -f 强制提交","categories":["4.软件","Git"]},{"title":"6. Git标签","path":"/2023/10/11/4-软件-Git-6-Git标签/","content":"标签在 Git 中，tag 是用于标记某个特定提交的名称。它类似于一个快照，可以用于标记版本、发布或重要的里程碑。Git 中有两种类型的 tag：轻量级标签和附注标签。 轻量级标签是一个简单的指向某个特定提交的引用，类似于一个分支，但不会随着新的提交而移动。创建轻量级标签的方法很简单，只需在命令行中输入 git tag tag-name 即可。例如，git tag v1.0 将创建一个名为 v1.0 的轻量级标签。 附注标签是一个包含标签名称、标签创建者、标签创建日期和标签说明的 Git 对象。它们是 Git 中最常用的标签类型，可以用于发布版本、重要的里程碑和其他重要的提交。创建附注标签的方法是使用 -a 标志和标签名称，然后输入标签说明。例如，git tag -a v1.0 -m Release version 1.0 将创建一个名为 v1.0 的附注标签，并将其说明设置为 “Release version 1.0”。 标签可以使用 git push 命令推送到远程存储库中，以便在其他计算机上使用。例如，要将名为 v1.0 的标签推送到远程存储库，可以使用 git push origin v1.0 命令。 git tag #列出所有taggit tag [tag] #新建一个tag在当前commitgit tag [tag] [commit] #新建一个tag在指定commitgit tag -d [tag] #删除本地taggit push origin [tag] #推送tag到远程git show [tag] #查看特定taggit checkout -b [branch] [tag] #新建一个分支，指向某个tag","categories":["4.软件","Git"]},{"title":"Git 同步时报错","path":"/2023/10/10/4-软件-Git-Git-同步时报错/","content":"Git 同步时报错在使用 Git 进行同步时，有时会遇到这样的错误信息：”error: RPC failed; curl 92 HTTP2 stream 7 was not closed cleanly: CANCEL (err 8)”。这一错误通常意味着存在网络连接问题、Git 配置未优化，或是 HTTP2 协议支持不足。为了解决这个问题，以下是详尽的解决方案及步骤。 error: RPC failed; curl 56 Failure when receiving data from the peererror: 6920 bytes of body are still expectedfetch-pack: unexpected disconnect while reading sideband packetfatal: early EOFfatal: fetch-pack: invalid index-pack output 1. 检查网络环境这个错误往往源于网络的不稳定性，因此首先应确保网络连接畅通。 确保网络稳定：观察连接状态，检查是否有消失的网络信号，是否出现了频繁的断线重连。如果在使用无线网络时，尝试靠近路由器或者切换到有线连接。 关闭代理：在一些网络环境中，尤其是公司网络或公共 Wi-Fi，可能由于防火墙或其他限制导致连接问题。在这种情况下，可以尝试通过代理来进行连接。执行以下命令来配置 HTTP 或 SOCKS 代理： git config --global http.proxy http://代理地址:端口git config --global https.proxy http://代理地址:端口 例如，如果的代理地址是 proxy.com，端口是 8080，那么可以这样设定： git config --global http.proxy http://proxy.com:8080git config --global https.proxy http://proxy.com:8080 使用 VPN：如果在中国大陆访问 GitHub 等国外网站时常遇到网络问题，考虑使用 VPN 工具来提高连接稳定性。 2. 禁用 HTTP2 协议某些版本的 Git 对 HTTP2 的支持可能并不稳定，可以尝试强制使用 HTTP1.1 的协议： git config --global http.version HTTP/1.1 这种设置通常可以帮助解决因为协议不兼容引起的错误。 3. 调整 Git 缓存设置在传输大文件时，缓冲区过小可能会导致错误。可以通过增加 Git 的缓冲区设置来解决： git config --global http.postBuffer 524288000 # 设置缓冲区为500MBgit config --global http.maxRequestBuffer 524288000 # 设置请求缓冲区git config --global core.compression 0 # 禁用压缩 例如，设置 http.postBuffer 为 500MB 使得大型文件的上传更为顺畅。 4. 降低并发请求如果请求数过多，可能会导致服务器无法处理。通过限制同时请求的数量，可以减少服务器压力，缓解错误： git config --global http.maxRequests 10 该命令将最大请求数限制为 10。 5. 检查 Git 和 cURL 版本确保的 Git 和 cURL 版本是最新的。老旧的版本可能存在未修复的缺陷，导致连接问题。 git --versioncurl --version 若发现版本较旧，建议通过官方网站或包管理工具进行升级。例如，在 Ubuntu 系统上，可以使用： sudo apt updatesudo apt install git curl 6. 克隆单个分支在同步大的版本库时，下载所有内容可能会导致错误。相反，尝试只克隆需要的分支，这样可以减少传输量： git clone --single-branch --branch 分支名 仓库地址 在此命令中，只需替换 分支名 和 仓库地址 为目标分支名和仓库链接。 7. 验证远程仓库地址确保配置的远程仓库地址是正确且可访问的。可以使用以下命令查看当前配置的远程地址： git remote -v 如果发现地址错误，可以通过以下命令进行更新： git remote set-url origin 正确的地址 确保 正确的地址 是要访问的实际仓库地址。 编辑 .gitconfig 找到 .gitconfig 文件位置 不同操作系统的文件路径如下： Windows: C:\\Users\\YourUsername\\.gitconfig LinuxMacOS: ~/.gitconfig 确保替换 YourUsername 为实际的用户名称，以找到正确的文件。 打开 .gitconfig 文件 使用任何文本编辑器打开此文件，具体示例如下： 在 Windows 上，可以使用记事本打开： notepad C:\\Users\\YourUsername\\.gitconfig 在 Linux 上，用 nano 编辑： nano ~/.gitconfig 编辑文件内容 在打开的文件中，添加或修改配置信息，以下是一个示例配置： [user] name = Your Name email = your.email@example.com[http] postBuffer = 524288000 maxRequests = 10\tversion = HTTP/1.1[core] editor = vim 这个示例中，包括用户名、电子邮件、HTTP 请求的缓冲大小和默认文本编辑器。这样的配置可以帮助用户在使用 Git 时更加顺畅。 保存更改 完成编辑后，务必保存并关闭文件。确保所做的所有更改都已保存，以便在下次使用 Git 时能有效应用这些新的配置。","categories":["4.软件","Git"]},{"title":"GitHub加速访问","path":"/2023/10/09/4-软件-Git-GitHub加速访问/","content":"Git clonegitclone.com 是一个 github.com 缓存加速网站，通过缓存经常访问的 github 仓库，加速 git clone from github 操作。当使用 clone 仓库时 git clone https://gitclone.com/github.com/xxxxx/xxxxx 会创建一个镜像，以后其他开发者 clone 时就可以使用镜像缓存进行 clone，速度得到了很大的提升，一般 git clone from github 只能达到 20ks，经过 gitclone.com 加速后可以达到 1.2Ms。 第三方加速镜像站通过第三方 github 镜像站进行加速访问，网站的内容跟 GitHub 是完整同步的镜像，然后在这个网站里面进行下载克隆等操作。 镜像站 https://github.com.cnpmjs.org git clone https://github.com/xxxxx/xxxxx替换为git clone https://github.com.cnpmjs.org/xxxxx/xxxxx 镜像站 https://hub.fastgit.org git clone https://github.com/xxxxx/xxxxx替换为git clone https://hub.fastgit.org/xxxx/xxxx GitHub 文件加速利用 Cloudflare Workers 对 github release 、 archive 以及项目文件进行加速，部署无需服务器且自带 cdn. https://gh.api.99988866.xyz https://g.ioiox.com https://www.7ed.net/gitmirror/hub.html GitHub-Raw通过 GitHub raw 域名并非 github.com 而是 raw.githubusercontent.com，上方的 GitHub 加速如果不能加速这个域名，那么可以使用 Static CDN 提供的反代服务。 将 raw.githubusercontent.com 替换为 raw.staticdn.net 即可加速 https://github.com/xxxxx/xxxxx替换为https://raw.githubusercontent.com/xxxx/xxxxhttps://raw.staticdn.net/xxxx/xxxxhttps://raw.gitmirror.com/xxxx/xxxx jsdelivr 加速通过 jsdelivr 唯一美中不足的就是它不能获取 exe 文件以及 Release 处附加的 exe 和 dmg 文件。 https://github.com/xxxxx/xxxxx替换为下面 jsdelivr 地址https://cdn.jsdelivr.net/gh/xxxxx/xxxxx/ 部署免费 gh-proxy通过 Cloudflare Workers 和 gh-proxy 开源项目对 GitHub 文件加速,通过 Cloudflare Workers 部署无需服务器且自带 CDN。开源项目: gh-proxy 文件加速自行部署。 使用 Github 镜像站可以通过修改 Github 的链接来加速访问。例如，如果直接访问 https://github.com 速度很慢，可以尝试将其改为 https://github.hscsec.cn 以加速访问。当 GitHub 资源访问缓慢时使用下面任意网址仅替换掉 https://github.com 域名即可。 推荐的镜像站有： https://github.hscsec.cn https://521github.com https://mirror.ghproxy.com https://gh.api.99988866.xyz","categories":["4.软件","Git"]},{"title":"GitLab部署","path":"/2023/10/06/4-软件-Git-GitLab部署/","content":"手动部署 GitLab 环境1. 安装依赖包首先，需要安装一些必要的依赖包，以确保环境运行顺畅。这些包包括： curl：用于获取文件和数据的工具。 policycoreutils-python：为 SELinux 提供管理工具的 Python 包。 openssh-server：SSH 服务，用于安全远程访问。 以下命令用于安装这些依赖包： sudo yum install -y curl policycoreutils-python openssh-server 2. 配置 SSH 服务接下来，需要配置 SSH 服务，以便能够安全地管理 GitLab 服务器。 启动 SSH 服务使用下面的命令来启动 SSH 服务： sudo systemctl start sshd 设置 SSH 服务为开机自启动确保 SSH 服务在系统重启后自动启动，运行以下命令： sudo systemctl enable sshd 3. 安装 Postfix 以发送通知邮件需要安装 Postfix，它是一个广泛使用的邮件传输代理，可以用来发送邮件通知。 安装 Postfix运行以下命令，以安装 Postfix： sudo yum install postfix 设置 Postfix 为开机自启动确保 Postfix 在重启时自动启动： sudo systemctl enable postfix 启动 Postfix 服务使用以下命令来启动 Postfix 服务： sudo systemctl start postfix 4. 配置 Postfix需要编辑 Postfix 的配置文件，使其能够接受外部连接。 编辑 Postfix 配置文件运行以下命令来打开 Postfix 主配置文件： vim /etc/postfix/main.cf 找到以下行： set_inet 将其修改为： inet_interfaces = all 保存配置文件并退出按 Esc 键退出编辑模式，然后输入 :wq 并回车，以保存并关闭文件。 5. 添加 GitLab 软件包仓库接下来，需要添加 GitLab 的官方软件包仓库，使用以下命令： curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 6. 安装 GitLab安装 GitLab 的命令如下，用 GitLab 服务器的公网 IP 地址替换占位符： sudo EXTERNAL_URL=http://GitLab服务器的公网IP地址 yum install -y gitlab-ce 获取公网 IP 地址可以在 ECS 管理控制台的实例与镜像 实例页面找到 GitLab 所属 ECS 实例的公网 IP 地址。 7. 使用浏览器访问 GitLab在浏览器中输入 GitLab 服务器的公网 IP 地址。成功访问后，将看到如下页面，表示环境搭建成功，并且系统会提示设置新密码。 8. 登录 GitLab输入登录信息在浏览器的地址栏中，输入 ECS 服务器的公网 IP，进入 GitLab 的登录界面。首次登录时，使用用户名 root，密码为首次访问 GitLab 时设置的新密码。 登录成功后界面成功登录后，将看到如下界面： 9. 创建项目在 GitLab 中，可以轻松创建新项目。 安装 Git 工具首先，确保已安装 Git 工具，用于版本控制。可以使用 Linux 自带的软件源安装 Git： yum install git 生成密钥文件使用以下命令生成 SSH 密钥文件，以便能够与 GitLab 安全地进行交互： ssh-keygen 查看公钥文件运行以下命令以查看生成的公钥内容，并将其用于 GitLab 的配置中： cat .ssh/id_rsa.pub 10. 在 GitLab 中创建项目新建项目在 GitLab 的主页中，单击”New Project”按钮，新建一个项目。 配置项目设置与项目相关的各项配置，然后单击”Create project”按钮完成项目创建。 添加 SSH Key点击”Add an SSH key”按钮，将第二步中生成的公钥粘贴到相应的配置框中。 完成后，将看到 SSH key 已成功添加的提示信息。 保存项目地址项目地址在进行克隆操作时需要用到，请务必保存该地址。 11. 简单配置 Git 用户信息为了在项目中正确记录提交者信息，需要配置 Git 用户的姓名和电子邮件地址。 git config --global user.name testname git config --global user.email abc@example.com 12. 克隆项目使用以下命令将在 GitLab 上创建的项目克隆到本地： git clone git@iZ****3Z:root/test.git 执行后，将在本地生成同名目录，该目录中会包含项目的所有文件。 13. 上传文件进入项目目录使用以下命令进入刚克隆的项目目录： cd test/ 创建并上传文件创建一个要上传到 GitLab 的文件，例如： echo test /root/test.sh 将目标文件或目录复制到项目目录下： cp /root/test.sh ./ 将文件加入版本控制使用以下命令将新创建的文件 test.sh 添加到 Git 的暂存区： git add test.sh 提交更改执行提交操作，记录此次更改： git commit -m test.sh 推送到 GitLab 服务器将本地更改同步到 GitLab 服务器： git push -u origin master 14. 验证文件同步在网页中查看，将看到上传的 test.sh 文件已经成功同步到 GitLab 中。确认同步成功的界面如下：","categories":["4.软件","Git"]},{"title":"在 Git 中忽略文件和文件夹","path":"/2023/10/05/4-软件-Git-在-Git-中忽略文件和文件夹/","content":"什么是 .gitignore 文件.gitignore 文件是一个用于告知 Git 哪些文件和目录不应被追踪的纯文本文件。它为开发者提供了一种管理和维护项目中不需要版本控制的文件的简便方法。旨在优化版本控制的效率，确保其他开发者在使用代码库时不必处理那些特定于个人环境的文件。 Git 文件状态在任何当前工作的 Git 仓库中，文件的状态可分为三类： 追踪的（tracked）: 这些是 Git 所知道的文件或目录，包括用 git add 添加和用 git commit 提交到主仓库的文件。 未被追踪的（untracked）: 这些文件是在工作目录中创建的，但尚未被 Git 暂存（没有使用 git add 命令）。 被忽略的（ignored）: 这些文件是需要从 Git 的关注中排除的，无论它们在工作目录中是否存在。简单来说，被忽略的文件不会被提交到版本库中。 所有被忽略的文件都会列在 .gitignore 文件中。 如何创建一个 .gitignore 文件通常情况下，.gitignore 文件位于仓库的根目录下，也就是包含该项目的所有文件和子目录的主目录。尽管推荐放在根目录，.gitignore 文件可以放在项目中的任何子文件夹中，甚至可以在同一项目中有多个 .gitignore 文件。 在类 Unix 系统（比如 macOS 或 Linux）上，可以使用命令行创建 .gitignore 文件： 打开终端程序。 使用 cd 命令导航到项目的根目录。 输入以下命令以创建 .gitignore 文件： touch .gitignore 注意，任何以点（.）开头的文件在默认情况下都是隐藏的。在命令行中，运行 ls 命令将看不到这些文件。要查看所有文件，包括隐藏文件，使用： ls -a 在 .gitignore 文件中应该包括什么通过 .gitignore 文件应当添加的文件类型通常是那些不需要被提交的文件，具体包括但不限于： 操作系统生成的文件: 各种操作系统会创建特定的隐藏文件。例如，macOS 上的 .DS_Store 文件记录用户对文件夹的展示偏好。 IDE 或编辑器生成的配置文件: 这些文件通常适应个人用户的配置。比如，VS Code 会生成 .vscode 文件夹用于存储用于特定项目的配置信息。 编程语言或框架生成的临时文件: 如 .o 文件，通常是编译生成的，不需被版本控制。 软件包管理器生成的文件夹: 例如，使用 npm 时会在项目中创建 node_modules 文件夹，里面包含所有依赖的封装库。 敏感信息的存储文件: 本地项目中可能存在包含凭证的文件，如 .env 文件，它们包含需要保密的 API 密钥和环境变量。 运行日志文件: 比如 .log 文件，能够提供系统操作的历史及错误记录，但对于版本控制而言并无价值。 如何在 Git 中忽略文件和文件夹要在 .gitignore 文件中忽略特定文件，只需提供文件在项目中的路径。例如，要忽略根目录下的 text.txt 文件，可以在 .gitignore 文件中写入： /text.txt 如果要忽略根目录下的 test 目录中的 text.txt 文件，可以写成： /test/text.txt 或者简化为： test/text.txt 若要忽略项目中的所有同名文件，只需写入文件名： text.txt 如此，所有位置的 text.txt 文件都会被忽略。 在要忽略整个目录及其内容时，需在目录名称末尾加上斜杠： test/ 这样，名为 test 的目录以及其内部的所有文件和子目录都会被忽略。 使用通配符进行忽略设置若需忽略所有以特定字词开头的文件或目录，可以使用通配符 *。例如，要忽略所有以 img 开头的文件或目录，使用： img* 要忽略所有以 .md 结尾的 Markdown 文件，可以写： *.md 这会匹配项目中所有扩展名为 .md 的文件。 如何忽略先前已提交的文件一旦文件被提交到 Git 仓库中，如果需要忽略它，首先需要确保该文件已被添加到 .gitignore 文件中。示例：如果需要忽略名为 .env 的文件，步骤如下： 将 .env 添加到 .gitignore: echo .env .gitignore 通过以下命令告知 Git 不再追踪 .env 文件，且从索引中将其删除： git rm --cached .env 此命令会使 .env 文件从 Git 版本控制中移除，但依然保留在本地文件系统中。 最后，添加并提交 .gitignore 更新： git add .gitignoregit commit -m 更新忽略的文件 通过上述步骤，原本已提交的文件便可从版本控制中移除，并被顺利忽略。","categories":["4.软件","Git"]},{"title":"版本控制方案","path":"/2023/10/04/4-软件-Git-版本控制方案/","content":"Git 方案1. 仓库创建 仓库创建基于当前的项目，例如备份仪表项目仓库，LSA 项目等 2. 分支创建 项目主分支保存项目代码及文档，负责发布代码 项目开发分支保存项目源码，分支仅管理员可见 项目运行分支保存项目头文件及库文件代码，分支所有人可见 项目人员开发分支基于运行分支创建，仅该人员有权限，该人员开发任务基于该分支进行修改代码 3. 代码提交 各人员代码仅提交在单独分支，提交完成后，由管理员审核后，同步源代码至开发分支 4. 版本回退 SVN 方案","categories":["4.软件","Git"]},{"title":"荧光定量 PCR中基线、阈值、 Ct 值","path":"/2023/10/03/4-软件-PCR-荧光定量-PCR中基线、阈值、-Ct-值/","content":"基线 (Baseline)基线指的是在 PCR（聚合酶链式反应）扩增反应的初始几个循环中，荧光信号的变化极小，基本保持在一个稳定的水平。这一段的荧光信号表现为接近一条直线，这样的直线称为基线。通常，这个基线区域显示了背景荧光信号，对后续的数据分析至关重要，因为它帮助确定真实的扩增信号何时开始超出背景噪声的水平。 阈值线 (Threshold)在 PCR 反应的前 15 个循环中所获得的荧光信号通常被视为荧光的本底信号。为了便于后续分析，许多实验室会将荧光阈值设定为 PCR 3—15 个循环荧光信号标准差的 10 倍。这个阈值线通常是在 PCR 扩增的指数期内设定的。 不同厂家会采用不同的算法设定阈值： 罗氏的算法：一般选择 3-12 个循环（可调，灵活变化），以基线的 10 倍标准差为依据。 大多数其他厂家的做法：同样选择 3-12 个循环，设定为基线平均值的 1.05-1.1 倍，旨在更好地反映实时荧光信号的变化。 CT 值CT 值，即循环阈值，在荧光曲线与阈值线的交点位置对应的循环数。这个值反映了每个 PCR 反应管内所需的扩增循环数，以达到设定的荧光域值。研究显示，各模板的 CT 值与其起始拷贝数的对数之间存在线性关系：起始拷贝数越高，CT 值越小，反之亦然。通过使用已知起始拷贝数的标准品，可以绘制出一条标准曲线。在这条曲线上，横坐标是起始拷贝数的对数，纵坐标是 CT 值。只需获得未知样品的 CT 值，就可以从标准曲线上得到该样品的起始拷贝数。 归一数据的归一化是过程中的另一重要步骤，包含两个主要方法： 荧光曲线减去基线平均值：这一操作可以去除背景信号的影响，增强信号的对比度。 荧光曲线除以最大值（或平台期的平均值）：这一方法有助于标准化信号强度，使得不同样本数据之间可比较。 扩增曲线在 PCR 过程中，以循环数为横坐标，实时荧光强度为纵坐标所绘制的曲线称为扩增曲线。评估扩增曲线是否良好的指标主要有以下几个方面： 曲线拐点清楚：尤其在低浓度样本的指数期，应表现明显。良好的扩增曲线在基线区域平坦，无明显上扬现象，确保低浓度样本的指数期凸显。 曲线指数期斜率与扩增效率成正比：斜率越大，扩增效率越高，意味着样本中的目标序列被快速且有效地产生。 标准的基线应保持平直或略微下降：无明显的上扬趋势，表示反应过程稳定且没有干扰。 各管的扩增曲线平行性好：表明各反应管的扩增效率相近，有助于获得可靠的一致性结果。 熔解曲线 (-RFUdT)熔解曲线分析是在对 PCR 产物进行加热时，随着温度升高，双链扩增产物逐渐解链，从而导致荧光强度下降的过程。在达到某一特定温度时，大量的产物会快速解链，荧光信号将急剧下降。不同 PCR 产物的 Tm（熔化温度）不同，因此不同产物的荧光信号发生迅速下降的温度也会有所不同。通过熔解曲线，可以有效鉴定 PCR 产品的特异性，确认扩增的结果是否可靠。 拷贝数拷贝数用单位 copiesml 表示，常用于生化检测中检查 DNA 复制状况。这里： copies 是 copy 的复数形式，表示从原始 DNA 复制出新 DNA 的个体副本。 ml 则是每毫升的度量。 结合起来，copiesml 表示每毫升待测样本中 DNA 的复制数量，这一参数对于评估样本中的 DNA 含量和扩增效率至关重要。","categories":["4.软件","PCR"]},{"title":"vim安装","path":"/2023/10/02/4-软件-VIM-vim安装/","content":"配置文件 地址 1. 安装环境sudo apt install git cscopewget -qO - https://raw.github.com/ma6174/vim/master/setup.sh | sh -x wget 是一个强大的命令行工具，专门用于从互联网下载文件。它的灵活性和可配置性使其成为开发者和系统管理员的首选工具。 参数 -q 表示下载时以静默模式运行，这样既可以避免显示进度条，也不会干扰标准输出，保持终端的整洁。 -O - 指定将下载的文件直接输出到标准输出（通常是终端），这样用户可以第一时间看到脚本的执行结果，而无需在本地保存该文件。 URL 地址 https://raw.github.com/ma6174/vim/master/setup.sh 指向一个在 GitHub 上托管的 Shell 脚本，它负责设置 Vim 的安装和配置。 | 是管道符号，它将前一个命令的输出直接传递给下一个命令，允许用户在一条命令中链式调用多个操作。 sh 用来执行 Shell 脚本的命令，将下载后的脚本内容执行。 -x 则在执行脚本时提供详细的调试信息，这对排查潜在问题非常有帮助。 setup.sh 内容解析#!/bin/bashecho 安装将花费一定时间，请耐心等待直到安装完成~~if which apt-get /dev/null; then sudo apt-get install -y vim vim-gnome ctags xclip astyle python-setuptools python-dev gitelif which yum /dev/null; then sudo yum install -y gcc vim git ctags xclip astyle python-setuptools python-develfi## Add HomeBrew support on Mac OSif which brew /dev/null;then echo You are using HomeBrew tool brew install vim ctags git astylefisudo easy_install -ZU autopep8sudo ln -s /usr/bin/ctags /usr/local/bin/ctagsmv -f ~/vim ~/vim oldcd ~/ git clone https://github.com/ma6174/vim.gitmv -f ~/.vim ~/.vim_old mv -f ~/vim ~/.vimmv -f ~/.vimrc ~/.vimrc_oldmv -f ~/.vim/.vimrc ~/ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundleecho ma6174正在努力为安装bundle程序 ma6174echo 安装完毕将自动退出 ma6174echo 请耐心等待 ma6174vim ma6174 -c BundleInstall -c q -c qrm ma6174echo 安装完成 这段脚本的目的是方便用户快速安装 Vim 及其依赖。首先，它通过检测系统包管理器（apt-get 或 yum）来安装必要的软件包。这样的设计保证了在不同 Linux 发行版上的兼容性。它还为 Mac 用户提供通过 HomeBrew 安装的选项。 具体步骤： 安装 Vim 和其他工具：根据系统类型，脚本会安装 Vim、ctags、xclip 等包，使用户可以编辑代码、生成标签等。 **自动安装 autopep8**：这是一个格式化 Python 代码的工具，通过简单的命令行可以保持代码风格的统一。 克隆配置库：从 GitHub 克隆自定义的 Vim 配置，确保用户能收到最新的配置与功能。 2. 配置cd /usr/includesudo ctags -Rcd -vim .vimrc 在配置 Vim 的过程中，用户首先切换到 /usr/include 目录，执行 sudo ctags -R 命令，生成整个目录下文件的标签。这一操作将帮助 Vim 实现高效的代码跳转和自动补全，提升开发效率。 接下来，用户需要编辑 .vimrc 配置文件： set tags=/usr/include/tags 此行配置指明了 Vim 使用 /usr/include 目录下的标签文件，以加速代码导航。 3. 安装 zshZsh（Z Shell）是一种灵活且功能丰富的命令行 Shell，相对于默认的 Bash，它提供了许多便利的特性。例如，Zsh 有出色的自动补全机制，可以根据输入的部分命令推测用户的意图；同时，它的历史记录管理也做得非常出色，能够快速找到过去执行的命令。 安装与设置 Zsh用户可以通过以下命令安装 Zsh，并将其设置为默认 Shell： sudo apt install zshchsh -s /bin/zsh sudo apt install zsh 安装 Zsh 命令行工具。 chsh -s /bin/zsh 更改当前用户的默认 Shell 为 Zsh，从此开始使用更加强大的命令行体验。用户在下次登录后就会看到 Zsh 的界面。","categories":["4.软件","VIM"]},{"title":"curl 命令","path":"/2023/09/29/4-软件-Web-curl-命令/","content":"依赖库libcurl 安装示例如下: #ubuntusudo apt-get install libcurl4-openssl-dev#centosyum install libcurl-devel#macos（本身自带curl，这一步非必须）brew install curl#windows（这里的 cpu 架构请根据实际环境灵活选择）vcpkg install curl:x64-windows 备注：建议安装最新版的 libcurl 库，否则可能存在 libcurl 库内存泄露 bug 问题。 curl 命令是一个功能强大的命令行传输工具，用于发送请求和下载文件。它支持多种协议，如 HTTP、HTTPS、FTP 等，可以设置请求头、请求参数等 发送 GET 请求curl URLcurl URL?a=1b=nihao 发送 POST 请求curl -X POST -d a=1b=nihao URL 发送 json 格式请求：curl -H Content-Type: application/json -X POST -d abc:123,bcd:nihao URLcurl -H Content-Type: application/json -X POST -d @test.json URL -H 代表 header 头 -X 是指定什么类型请求(POSTGETHEADDELETEPUTPATCH) -d 代表传输什么数据 查看所有 curl 命令： man curl 或者 curl -h请求头：H,A,e响应头：I,i,Dcookie：b,c,j传输：F(POST),G(GET),T(PUT),X输出：o,O,w断点续传：r调试：v,–trace,–trace-ascii,–trace-time 测试端口可以用它来测试端口是否开启。 curl -v ip:port 出现 Connection refused 表示端口关闭； 出现 Connected to ip(ip) port(#0)表示端口开启； 出现 No route to host 表示 IP 错误或者 iptables 限制。","categories":["4.软件","Web"]},{"title":"Nginx学习笔记","path":"/2023/09/28/4-软件-Web-Nginx学习笔记/","content":"Nginx功能Nginx 是一款功能强大的网络服务器，广泛用于处理高并发连接。以下是 Nginx 的一些主要功能： Web 服务器：可以高效地提供静态内容，如 HTML 页面、图片和视频。 负载均衡：将请求分散到多个后端服务器，确保用户在高流量情况下依然获得快速响应。例如，当网站流量突然增加时，Nginx 可以根据配置智能地将请求分配给不同的服务器，避免单台服务器过载。 API 网关：作为微服务架构中的中间层，Nginx 可以管理 API 请求，将其路由到适当的服务，并提供统一的接口给前端应用。 DDoS 防御：利用流量限制和 IP 黑名单等技术，Nginx 能有效抵御分布式拒绝服务（DDoS）攻击，确保网站继续正常服务。 反向代理：使用户请求经过 Nginx 后转发至后端服务器，为用户提供了透明的访问体验。比如，用户向 Nginx 请求数据，而用户并不知道数据实际上来自于不同的后端服务。 Web 应用防火墙：通过配置规则，对进入的请求进行过滤，帮助保护应用免受常见攻击，如 SQL 注入和跨站脚本（XSS）攻击。 缓存：Nginx 可以缓存响应内容，减少后端服务器的负担，从而提高网站性能。例如，访问量较大的网页在初次请求后，会被缓存，后续请求将直接从缓存中读取，提高了响应速度。 下载在大多数基于 Debian 的系统中，使用以下命令安装 Nginx： sudo apt install nginx -y 安装完成后，访问服务器的公网 IP 地址，将看到 Nginx 的默认欢迎页面，表明安装成功。 配置 NginxNginx 的主要配置文件位于 /etc/nginx/ 目录下。要修改默认的配置文件，可以使用以下命令： sudo vi /etc/nginx/sites-enabled/default 根据配置文件中的 root 指令，确认网页根目录位置为 /var/www/html。如果想方便访问，可以链接网页根目录到用户的主目录： ln -s /var/www/html ~/html 配置文件进入 Nginx 的配置目录： cd /etc/nginx/sites-enabled 默认的配置文件可能以 default 命名。可以删除此文件并替换为的自定义页面配置。输入以下内容： server listen 8080; # 设置 Nginx 监听的端口 root /home/ubuntu/html; # 网站根目录，确保使用绝对路径 location / index index.php index.html index.htm; # 默认访问的首页 # 如果使用 PHP，这里是 PHP 文件解析的配置示例 # location ~* \\.php$ # fastcgi_index index.php; # fastcgi_pass 127.0.0.1:9000; # include fastcgi_params; # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param SCRIPT_NAME $fastcgi_script_name; # # 自定义错误页面规则 # error_page 404 /404.html; # location = /40x.html # error_page 500 502 503 504 /50x.html; # location = /50x.html 对于反向代理的配置示例如下： http upstream backend1 server 127.0.0.1:8000; # 定义后端服务器（服务1） upstream backend2 server 127.0.0.1:8001; # 定义后端服务器（服务2） server listen 80; # Nginx 监听的端口 location /service1/ proxy_pass http://backend1; # 将请求转发到服务1 location /service2/ proxy_pass http://backend2; # 将请求转发到服务2 在编辑完配置文件后，可以使用以下命令检查配置文件的正确性： nginx -t 确保没有错误后，重新启动 Nginx 服务以使更改生效： sudo systemctl start nginxsudo systemctl enable nginx # 设置开机自动启动 随后，直接在浏览器中输入服务器的 IP 地址加上设置的端口即可访问网站。 修改页面，重载页面在修改完页面内容后，如果需要 Nginx 重新加载配置，可以使用： sudo nginx -s reload 常用命令 查看 Nginx 版本： nginx -v 配置文件所在位置为 /etc/nginx，主配置文件通常命名为 nginx.conf。 检查配置文件中的潜在问题： nginx -t 重新加载 Nginx 配置文件以应用更改： nginx -s reload 停止 Nginx 服务： nginx -s quit # 或使用 nginx -s stop 关键配置项说明 events: 定义 Nginx 事件处理模型。 http: 设置 HTTP 相关的配置选项。 server: 每个 server 块定义了一台虚拟服务器。 include: 用于包含外部配置文件。 listen: 指定 Nginx 监听的端口号。 server_name: 设置允许的主机名，支持多个域名。 root: 定义网站根目录的位置。 index: 指定默认访问的页面名称。 return: 发送特定的 HTTP 响应。 location: 处理特定 URI 的请求，支持完全匹配和正则表达式匹配。 rewrite: 用于 URL 重写，可以改变请求的 URL 格式。 proxy_pass: 指定请求转发的目标地址。","categories":["4.软件","Web"]},{"title":"Nginx配置","path":"/2023/09/27/4-软件-Web-Nginx配置/","content":"URL 最后的斜杠当访问的 URL 最后没有斜杠时，Nginx 会自动为其补上斜杠，并进行 301 跳转。这意味着用户在访问某个路径时，如 http://example.com/path，将会被重定向到 http://example.com/path/。 使用 proxy_pass 的注意事项如果在配置中使用了 proxy_pass 等流量转发手段，则需要关闭绝对路径： absolute_redirect off; 这个设置确保了在斜杠的处理上 Nginx 不会直接跳转到后端，而是保留相对路径。 如果的 Nginx 版本低于 1.11.8，需要使用禁止端口跳转的选项： port_in_redirect off; 或者，可以编写判断规则，检查无斜杠的 URL 是否是文件。如果不是，可以加一个斜杠。下面是一个示例配置： if ( -d $request_filename ) rewrite ^/(.*)([^/])$ https://api.myserver.com/$1$2/ permanent;if (-d $request_filename) rewrite [^/]$ $scheme://$http_host$uri/ permanent; 推荐方案选择上述两种方法之一，后者会强制一些 API 的 URL 加上斜杠，例如： 请求 GET myserver.com/api?param=1 会被强制转变为 myserver.com/api/?param=1。这会导致请求失败，因为不是所有 API 都支持尾部斜杠。 在具体的配置中，可以针对 location 进行设置： location /api proxy_pass http://127.0.0.1:1111/;location /api/ proxy_pass http://127.0.0.1:1111/; 基本认证准备工具时，如果在 Debian 或 Ubuntu 系统上，可以使用 apache2-utils，而在 RHELCentOSOracle Linux 系统上，则用 httpd-tools。 生成密码文件可以使用以下命令创建密码文件并添加用户： htpasswd -c /etc/apache2/.htpasswd user1htpasswd /etc/apache2/.htpasswd user2 配置基本认证以下是设置 API 保护的示例： location /api auth_basic Administrator’s Area; auth_basic_user_file /etc/apache2/.htpasswd; 如果某些资源不需要认证，可以使用以下配置： location /public/ auth_basic off; IP 控制可以灵活地设置哪些 IP 地址能够访问特定服务，这对于提高安全性非常有用。例如： location /api satisfy all; deny 192.168.1.2; # 阻止特定 IP 访问 allow 192.168.1.1/24; # 允许特定网段访问 allow 127.0.0.1; # 允许本地访问 deny all; # 阻止其他所有 IP auth_basic Administrator’s Area; auth_basic_user_file conf/htpasswd; Satisfy 指令可以设置为 all（全部条件满足）或 any（只需一个条件满足即可）。 按路径反代通过指定路径，将流量转发至下级服务。若配置如下： location /path/ proxy_pass http://127.0.0.1:4444; 那么所有到达 /path/ 的请求会被转发至 http://127.0.0.1:4444。 案例分析案例 1：设置路径为 /path： location /path proxy_pass http://127.0.0.1:4444/; 对这个路径的请求结果如下： GET myserver.com/path - 返回 OK。 GET myserver.com/path/ - 成功重定向，可能返回 301 或 404。 GET myserver.com/path?param=1 - 返回 OK。 GET myserver.com/path/?param=1 - 返回 301 后重定向，可能返回 404。 案例 2：设置路径为 /path/： location /path/ proxy_pass http://127.0.0.1:4444/; 此时的请求结果： GET myserver.com/path - 返回 301，重定向至 /path/。 GET myserver.com/path/ - 返回 OK。 GET myserver.com/path?param=1 - 成功重定向，返回 OK。 GET myserver.com/path/?param=1 - 返回 OK。 案例 3：设置路径为 = /path： location = /path proxy_pass http://127.0.0.1:4444/; 其请求结果为： GET myserver.com/path - 返回 OK。 GET myserver.com/path/ - 返回 404。 GET myserver.com/path?param=1 - 返回 OK。 GET myserver.com/path/?param=1 - 返回 404。 总结对于 RESTful API，建议直接使用 location = /path，这样不会有 301 重定向。而对于普通网站，则建议使用 location /path/ 以确保有效的重定向。 WebSocket 代理如果需要将请求反代到 WebSocket 协议，必须在 Header 中添加 Upgrade 字段，具体示例如下： http map $http_upgrade $connection_upgrade default upgrade; close; server location /chat/ proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; 使用 Docker引入 Nginx 后，使用 Docker 部署服务变得容易许多，只需执行以下命令： docker pull someimagedocker run -v 映射空间 -p 本地端口:docker端口 完整配置示例以下是一个完整的 Nginx 配置示例： user root;worker_processes 1;load_module /usr/lib/nginx/modules/ngx_stream_module.so;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events worker_connections 1024;stream map $ssl_preread_server_name $backend_name myserver.com myserver; api.myserver.com api; cdn.myserver.com cdn; default bad; upstream myserver server 127.0.0.1:666; upstream api server 127.0.0.1:777; upstream cdn server 127.0.0.1:888; upstream bad server 127.0.0.1:400; server listen 443 reuseport; listen [::]:443 reuseport; proxy_pass $backend_name; ssl_preread on; http include /etc/nginx/mime.types; default_type application/octet-stream; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 120; client_max_body_size 20m; gzip on; ssl_protocols TLSv1.2 TLSv1.3; server listen 80; listen [::]:80; server_name myserver.com api.myserver.com cdn.myserver.com; return 301 https://$host$request_uri; server listen 80 default_server; listen [::]:80 default_server; server_name _; return 400; server listen 127.0.0.1:888 ssl http2; ssl_certificate /path/to/my/public.cer; ssl_certificate_key /path/to/my/private.key; ssl_client_certificate /etc/nginx/ssl/cert/cloudflare.crt; ssl_verify_client on; root /share; server listen 127.0.0.1:777 ssl http2; root /path/to/api; index index.html; absolute_redirect off; if (-d $request_filename) rewrite [^/]$ $scheme://$http_host$uri/ permanent; location /private/ auth_basic Login required; auth_basic_user_file /etc/nginx/passwd/.htpasswd; autoindex on; location /public/ autoindex on; location /service/ proxy_pass http://127.0.0.1:8080/; ssl_certificate /path/to/my/public.cer; ssl_certificate_key /path/to/my/private.key; server listen 400 ssl; ssl_reject_handshake on;","categories":["4.软件","Web"]},{"title":"Nginx配置详解","path":"/2023/09/26/4-软件-Web-Nginx配置详解/","content":"序言Nginx 是由 Igor Sysoev 为俄罗斯访问量第二的 rambler.ru 网站研发的，首次发布于 2004 年。凭借开源的特性，Nginx 在过去的近二十年中迅速发展，成为一个接近成熟与完善的高性能服务器软件。 Nginx 具备丰富的功能，能够作为 HTTP 服务器、反向代理服务器以及邮件服务器使用。它支持多种协议和功能，包括 FastCGI、SSL、虚拟主机、URL 重写和 Gzip 压缩等。通过支持众多第三方模块的扩展，Nginx 的应用场景更加多样化，满足不同用户的需求。 Nginx 以其卓越的稳定性、丰富的功能集以及低系统资源消耗的特性赢得了广泛认可。目前在全球活跃的网站中，Nginx 的使用率达到了 12.18%，相当于约 2220 万个网站在使用这个强大的工具。 如果对于 Nginx 的了解还不够深入，可以在百度百科或相关书籍中找到更多的介绍与评价，这些资料中通常会有各种夸耀与亮点展示。 Nginx 常用功能 HTTP 代理与反向代理 反向代理是 Nginx 作为 Web 服务器最常用的功能之一。Nginx 配置灵活，能够根据请求的 URL 模式和服务器负载情况，智能选择转发的目标服务器。 例如，当用户请求某个特定格式的图片时，Nginx 可以将该请求转发至专门处理静态文件的文件服务器，而对于动态网页请求，则转发至 Web 服务器。这种基于正则表达式的转发策略灵活多变，只要正则表达式正确并配套相应的服务器处理逻辑，就可以自由切换请求的处理路径。此外，Nginx 还具备错误页跳转和异常判断的能力，若某台服务器出现故障，Nginx 能够自动将请求转发给另一台正常运行的服务器，从而提高系统的可靠性。 负载均衡 Nginx 提供了多种负载均衡策略，包括内置的轮询、加权轮询和 IP 哈希等。同时，Nginx 也允许用户根据需求自定义扩展负载均衡策略，确保能够满足各种复杂的业务需求。 轮询：将请求平均分配给各个服务器，适合负载均匀的情况。 加权轮询：根据服务器的处理能力分配请求，适合服务器性能差异较大的场景。 IP 哈希：通过对客户端 IP 进行哈希运算，将来自同一 IP 的请求总是指向同一台服务器，从而解决了会话不共享的问题，适用于需要保持用户状态的场合。 Web 缓存 Nginx 能够对不同类型的文件进行灵活的缓存处理，支持使用 FastCGI_Cache 来缓存动态生成的内容。通过与第三方模块 ngx_cache_purge 结合，用户可以针对特定 URL 的缓存内容进行增、删、改的操作，以便更好地管理缓存。 Nginx 相关地址 源码：Nginx 源码库 官网：Nginx 官方网站 Nginx 配置文件结构下载并安装完 Nginx 后，打开 conf 文件夹中的 nginx.conf 文件。这是 Nginx 服务器的基础配置文件，默认配置就储存在其中。 在该文件中，注释以 # 符号开始。对于刚接触 Nginx 的用户，熟悉其文件结构非常重要。 默认配置示例#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events worker_connections 1024;http include mime.types; default_type application/octet-stream; #log_format main $remote_addr - $remote_user [$time_local] $request # $status $body_bytes_sent $http_referer # $http_user_agent $http_x_forwarded_for; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / root html; index index.html index.htm; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html root html; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ # proxy_pass http://127.0.0.1; # # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; # # deny access to .htaccess files, if Apaches document root # concurs with nginxs one # #location ~ /\\.ht # deny all; # # another virtual host using mix of IP-, name-, and port-based configuration # #server # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / # root html; # index index.html index.htm; # # # HTTPS server # #server # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / # root html; # index index.html index.htm; # # 此示例展示了 Nginx 文件结构的基本组成部分： ... #全局块events #events块 ...http #http块 ... #http全局块 server #server块 ... #server全局块 location [PATTERN] #location块 ... location [PATTERN] ... server ... ... #http全局块 文件结构详细解析 全局块：配置影响 Nginx 整体运行的指令。例如，指定运行 Nginx 的用户和组、Nginx 进程的 PID 文件存放路径、日志路径的设置以及允许的工作进程数。 events 块：影响 Nginx 服务器处理与用户的网络连接的配置，包含每个工作进程的最大连接数，选择事件驱动模型（如 epoll、kqueue 等），以及是否允许一个进程同时接收多个网络连接。 http 块：允许定义多个服务器的配置，涵盖大多数 Nginx 功能和第三方模块的设置。这包括定义 MIME 类型、日志格式、是否启用 sendfile 传输文件、设置连接超时时间等。 server 块：用于配置虚拟主机的相关参数。在一个 HTTP 块中可以定义多个 server 块，每个块代表一个独立的虚拟主机。 location 块：根据请求的路由配置服务器行为，处理不同的页面请求。 详细配置示例以下是一个配置文件示例，用于进一步理解 Nginx 的使用，同时也是搭建测试环境时的参考： ########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #指定日志路径与级别，位置可在全局、http或server块设定，级别包括debug、info、notice、warn、error、crit、alert、emergevents accept_mutex on; #启用连接序列化，避免惊群现象，默认开启 multi_accept on; #设置进程是否可同时接受多个连接，默认为关闭 #use epoll; #设定事件驱动模型，可选项有select、poll、kqueue、epoll等 worker_connections 1024; #设定最大连接数，默认为512http include mime.types; #引入文件类型映射表 default_type application/octet-stream; #默认文件类型，通常为text/plain #access_log off; #关闭访问日志 log_format myFormat $remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for; #自定义日志格式 access_log log/access.log myFormat; #定义使用自定义格式的访问日志 sendfile on; #允许使用 sendfile 方式传输文件，默认为 off sendfile_max_chunk 100k; #设定每次调用 sendfile 的最大传输量，默认为不设上限。 keepalive_timeout 65; #设定连接超时时间，默认为75秒 upstream mysvr server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #设定备用服务器 error_page 404 https://www.baidu.com; #自定义错误页 server keepalive_requests 120; #设定单连接请求的最多次数 listen 4545; #设定监听端口 server_name 127.0.0.1; #设定监听的地址 location ~*^.+$ #请求过滤，使用正则表达式匹配，~表示大小写敏感，~*表示不敏感 #root path; #根目录位置 #index vv.txt; #设置默认首页 proxy_pass http://mysvr; #将请求转发至 mysvr 定义的服务器池 deny 127.0.0.1; #拒绝的 IP allow 172.18.5.54; #允许的 IP 注意事项在上面的配置中，重要的点如下： $remote_addr 与 $http_x_forwarded_for 用于记录客户端的 IP 地址； $remote_user 记录客户端用户名； $time_local 记录访问的时间及其时区； $request 记录请求的 URL 和 HTTP 方法； $status 用于记录请求的状态，通常 200 表示成功； $body_bytes_sent 记录发送给客户端数据的大小； $http_referer 保存来自哪个页面访问的来源； $http_user_agent 记录客户端使用的浏览器信息； 惊群现象是指，当一个连接到达时，其他睡眠进程会被唤醒，但实际响应该连接的只有一个进程，可能导致资源浪费和性能下降。 每个指令后必须用分号结束。","tags":["clippings"],"categories":["4.软件","Web"]},{"title":"Web3.0","path":"/2023/09/25/4-软件-Web-Web3-0/","content":"什么是 Web3.0Web3.0 是互联网的下一代版本，也被称为”分布式互联网“或”价值互联网”。与 Web1.0 和 Web2.0 不同，Web3.0 将建立在区块链技术之上，具有去中心化、安全性和隐私性等特点。它将为用户提供更多的控制权，让他们能够更好地管理自己的数据和资产。Web3.0 的应用场景包括去中心化金融、数字身份验证、物联网、供应链管理等。 去中心化金融Web3.0 的去中心化特点使其非常适合用于金融领域。未来，Web3.0 有望成为去中心化金融（DeFi）的主流形态，为用户提供更加安全、透明和高效的金融服务。 数字身份验证Web3.0 可以使用分布式身份验证技术来保护用户的身份和隐私。未来，Web3.0 有望成为数字身份验证的主流形态，为用户提供更加安全和便捷的身份验证服务。 物联网Web3.0 可以与物联网技术结合，从而实现更加智能和自动化的物联网应用。未来，Web3.0 有望成为物联网的主流形态，为用户提供更加便捷、智能和安全的物联网服务。 供应链管理Web3.0 可以使用区块链技术来实现供应链管理的透明化和自动化。未来，Web3.0 有望成为供应链管理的主流形态，为企业提供更加高效、安全和可靠的供应链管理服务。 去中心化数据用户在 Web3.0 网络中产生的各种数据，包括但不限于以下几类： 个人身份信息：Web3.0 应用可以使用分布式身份验证技术来保护用户的身份和隐私。这些身份信息包括用户的姓名、地址、电话号码、电子邮件地址等个人信息。 数字资产信息：Web3.0 使用区块链技术来管理数字资产，这些数字资产包括加密货币、数字艺术品、游戏道具等。 交易记录：Web3.0 应用中的交易记录是公开的，这意味着任何人都可以查看交易的发起方和接收方，以及交易的时间和金额等信息。 用户行为数据：Web3.0 应用可以记录用户在网络中的行为数据，例如用户访问的网站、搜索的关键词、点击的广告等。 这些数据可以通过 AI 进行分析和处理，从而提供更好的服务和体验。例如，AI 可以使用用户的个人身份信息来提供更加个性化的服务；使用数字资产信息来分析用户的投资偏好；使用交易记录和用户行为数据来预测市场趋势等。 元宇宙是一种虚拟现实（虚拟的真实世界）的概念，它是一个基于区块链和数字资产的虚拟世界，用户可以在其中进行交互和交易。具体来说，Web3.0 提供了以下数据方面的支持： 数字资产管理 去中心化身份验证 智能合约 资产数字资产 NFTNFT 是非同质化代币（Non-Fungible Token）的缩写，它是一种基于区块链技术的数字资产。与传统的加密货币不同，NFT 是不可替代的，每一个 NFT 都是独一无二的，拥有独特的价值和属性。在 Web3.0 中，NFT 可以用来代表各种数字资产，这为 Web3.0 提供了更加开放和自由的数字资产交易环境，也为数字内容的创作者提供了更多的收益来源。 NFT 的最大特点是可以用来代表任何类型的数字资产，例如数字艺术品、音乐、视频、游戏道具等。通过区块链技术，NFT 可以保证数字资产的唯一性和真实性，并且可以实现数字资产的所有权、交易和流通。 NFT 的交易通常是在区块链上进行的，交易记录和资产所有权都会被永久地记录在区块链上，使得交易过程更加透明和可追溯。近年来，NFT 在数字艺术品市场上得到了广泛的应用，一些数字艺术品以高价成交，引起了社会各界的广泛关注。 探讨Web3.0 应用的去中心化的特点使其相对于传统互联网应用更难被追踪。这是因为 Web3.0 应用不依赖于中心化的机构或公司来管理和维护网络，而是由网络中的节点共同维护和管理。这意味着没有单一的控制点，使得监管和追踪变得更加困难。 此外，Web3.0 应用使用加密技术来保护用户的数据和资产，使得用户可以在不泄露个人信息的情况下使用网络。这有助于防止个人信息被滥用和泄露。 然而，应该注意的是，Web3.0 应用并不是完全匿名的。虽然用户可以使用假名或匿名身份来访问网络，但是他们的行为和交易仍然可以被追踪。例如，区块链上的交易记录是公开的，这意味着任何人都可以查看交易的发起方和接收方。因此，虽然 Web3.0 应用相对于传统互联网应用更难被追踪，但仍然需要注意个人信息的保护和隐私的维护。 应用场景智能合约 自动化和执行合同，而 AI 可以帮助智能合约更好地理解和分析合同条款。这可以提高智能合约的效率和准确性，从而降低成本和风险。 分析和预测市场趋势 帮助用户做出更明智的投资决策。 更好的用户体验 例如通过自然语言处理技术来实现更智能的客户服务。 物联网和供应链管理 优点 ** 去中心化：**Web3.0 建立在区块链技术之上，具有去中心化的特点。这意味着没有中心化的机构或公司掌控网络，而是由网络中的节点共同维护和管理，从而降低了单点故障的风险。 ** 安全性：**Web3.0 使用加密技术和智能合约来保护用户的数据和资产，从而提高了网络的安全性。由于数据和资产的所有权归用户所有，他们可以更好地控制自己的信息和资产。 ** 隐私性：**Web3.0 使用加密技术保护用户的隐私，使得用户可以在不泄露个人信息的情况下使用网络。这有助于防止个人信息被滥用。 ** 开放性：**Web3.0 是开放的网络，任何人都可以参与其中，从而促进了创新和发展。这使得 Web3.0 更具有包容性和透明性。 ** 智能合约：**Web3.0 使用智能合约来自动化和执行合同，从而降低了成本和风险。智能合约可以在不需要中介的情况下执行交易，从而提高了效率和可靠性。 缺点 技术和性能难题：Web3.0 需要整合多种新技术，例如区块链、人工智能、物联网等，这些技术本身也存在一些难题和挑战。例如，区块链技术目前仍然存在扩展性和性能问题，人工智能技术需要大量的数据和计算资源支持，物联网技术需要解决设备互联互通的问题等等。 标准化问题：Web3.0 需要建立一系列的标准和规范，以确保不同的技术和应用能够互相兼容和协同工作。目前，Web3.0 标准化还处于初步阶段，需要各方共同努力推进标准的制定和实施。 安全和隐私问题：Web3.0 的去中心化特性使得其更加安全和去中心化，但同时也带来了一些安全和隐私问题。例如，区块链技术本身并不是完全安全的，智能合约和去中心化应用也存在漏洞和攻击的风险。同时，Web3.0 的去中心化特性也可能导致个人隐私泄露的问题。 用户体验问题：Web3.0 需要为用户提供更加安全、去中心化和智能化的互联网体验，但是在实现过程中也需要考虑到用户体验的问题。例如，去中心化应用的使用门槛较高，需要用户具备一定的技术知识和操作能力，这可能会影响用户的使用体验。 ** 法律监管不完善：**Web3.0 的去中心化特点可能会导致法律监管的困难。例如，一些 Web3.0 应用可能涉及非法活动，但由于缺乏中心化的机构，可能难以监管和惩罚。","categories":["4.软件","Web"]},{"title":"Linux下配置clash代理访问Github","path":"/2023/09/22/4-软件-代理穿透-Linux下配置clash代理访问Github/","content":"安装 Clash可以通过以下链接找到 Clash 的下载地址：Clash Releases。 在下载完成后，记得为 Clash 二进制文件赋予执行权限，并运行以下命令： ./clash-linux-amd64 -d . 这条命令会在当前目录下生成配置文件和 IP 数据库文件。如果 IP 数据库下载失败，还可以手动下载并将其上传到服务器。接下来，需要使用本地的配置文件替换默认配置，以下是必要的配置参数： port: 7890socks-port: 7891redir-port: 7892allow-lan: falsemode: Global# 设置日志输出级别（默认级别为 silent，不输出任何内容，以避免日志内容过大导致程序内存溢出）。# 日志级别有 5 种：silent / info / warning / error / debug。级别越高，日志输出量越大，更适合调试。如果需要可以自行开启。log-level: info# Clash 的 RESTful APIexternal-controller: 0.0.0.0:9090# RESTful API 的口令secret: # 可以将静态网页资源（如 clash-dashboard）放置在某一目录，Clash 将为其提供服务。# external-ui: folderproxies: - name: Standard|广台|IEPL|01 type: ss server: ************* port: 3026 cipher: rc4-md5 password: *************** udp: true plugin: obfs plugin-opts: mode: http host: ****************** 由于默认设置为全局代理，可以省略源配置文件中的 rules 标签，这样可以显著减小配置文件的体积。 接下来，再次执行命令： ./clash-linux-amd64 -d . 如果执行成功，将看到代理服务已经启动完毕。 配置 ClashClash 提供了一个方便的 Web 接口用于管理，首先请设置 Web 接口的口令。接着，登录腾讯云控制台，开放 9090 端口以便访问。 在浏览器中，访问以下网址： http://clash.razord.top/#/proxies 在页面中，host 字段填入的服务器公网 IP，密钥 为上一步设置的口令。通过这个界面，可以轻松切换代理，查看日志，修改端口等。 完成测试后，确认代理功能正常。为了减少日志输出，可以将 Clash 的日志记录级别降低，以防止过多日志导致程序崩溃。 要将 Clash 作为后台服务运行，可以使用以下命令： nohup ./clash-linux-amd64 -d . 切记定期更新配置文件，以确保使用最新的代理设置。 在 Linux 终端使用代理使用 proxychains 工具来便捷地在特定环境下使用代理。 安装 proxychains 完成后，需要修改配置文件 /etc/proxychains4.conf，在 [ProxyList] 项目下添加 Clash 的 socks5 代理监听端口： [ProxyList]# add proxy here ...# meanwhile# defaults set to torsocks5 127.0.0.1 7891 使用代理安装 Metasploit 框架，可以执行以下命令： proxychains curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb msfinstallchmod 755 msfinstallproxychains ./msfinstall 通过这样的方法，可以确保所有通过 proxychains 发出的请求都能够走 Clash 配置的代理，实现安全与高效的网络访问。","categories":["4.软件","代理穿透"]},{"title":"内网穿透方案","path":"/2023/09/21/4-软件-代理穿透-内网穿透方案/","content":"内网穿透，也称为 NAT 穿透或端口转发，是一种技术手段，用于在没有公网 IP 的情况下，使外网用户能够访问内网中的设备和服务。其基本原理是通过中转服务器或特定的网络配置，将内网设备的 IP 地址和端口映射到外网，从而实现内外网之间的通信。 具有公网 IP服务器端具有公网 IP获取公网 IP+DDNS 解析什么是 DDNSDDNS 的意思是动态域名解析。是解决有公网 IP ，但是公网 IP 不固定的问题，用固定的域名代替动态变化的公网 IP。 无公网 IP 网络环境用内网穿透方案，即类似如 nat123 内网映射方式，将内网 IP 映射成域名（自动生成二级域名或用自己域名）地址，然后通过域名来访问。 DDNS (Dynamic Domain Name System) 是一种可以动态更新域名解析的服务，它可以让的域名指向一个动态 IP 地址，而不是一个固定的 IP 地址。它可以让的域名跟随的设备，而不需要每次更改 IP 地址时都去更新域名解析。 适用情况： 路由器是公网 IP，但是公网 IP 不固定 检测方法： 用百度搜索 IP，百度会显示当前的 IP 地址，把这个 IP 地址和路由器的 IP 地址作比较，如果一致，说明是公网 IP，如果不一致，说明是运营商用一个 IP 然后经过多层 NAT 之后分配的内网 IP。 具有公网 IP 云服务器FRP将内网端口映射到公网服务器，通过公网服务器 + 端口的形式访问内网端口。需要了解配置 frps 和 frpc 的配置文件如何配置，针对特定端口进行开放 下载 frp 文件，根据实际要部署的环境的架构利用 wget 下载相应版本 项目地址 https://github.com/fatedier/frp 安卓版本仓库地址 https://github.com/FrpcCluster/frpc-Android 下载完成后 tar -xvf 解压，进入目录，修改 fps.toml 配置文件 文档地址 https://gofrp.org/zh-cn/docs/ frps 服务端配置安装前需 uname -a 查看云服务器的外网处理器架构,根据不同的架构下载不同 frp 版本，x86_64 的 下载 后缀带 amd 的即可 wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz 解压后编辑 frps.toml 文件 #bindAddr = 0.0.0.0bindPort = 9085 //内网设备绑定的端口# auth tokenauth.token = ****** //接入验证码，需要和设备端保持一致# Configure the web server to enable the dashboard for frps.# 使能dashboard(非必要)# 使能控制面板# 控制面板必须配置port# dashboard is available only if webServer.port is set.webServer.addr = 0.0.0.0webServer.port = 9086webServer.user = lemonadewebServer.password = lemonade# console or real logFile path like ./frps.log # 使能log(非必要)# 输入的日志文件log.to = ./frps.log //日志存储位置# trace, debug, info, warn, errorlog.level = info //存储等级log.maxDays = 3 //时间 netstat -ntlp 查看端口占用情况 启动 frps 服务 ./frps -c ./frps.toml， 需要注意服务器开通指定端口的防火墙 frpc 客户端配置 //具有公网IP的服务器地址serverAddr = 124.222.246.*** //接入端口serverPort = 9085//接入tokenauth.token=******[[proxies]]//将本设备的5000端口映射到服务器的9087端口name = frp-nas//类型type = tcp localIP = 0.0.0.0//本地端口localPort = 5000//公网端口remotePort = 9087[[proxies]]name = frp-nas-sshtype = tcplocalIP = 0.0.0.0localPort = 9090remotePort = 9088 微软的 devtunnel缺点是穿透的地址最长只能保持 30 天，执行安装命令： #Windowswinget install Microsoft.devtunnel#Linux curl -sL https://aka.ms/DevTunnelCliInstall | bash 登录自己的账户 devtunnel user login [-g] #-g代表github账户 假定需要将本机的 9006 端口做为对外穿透的端口，则命令为： devtunnel host -p 9006 [--allow-anonymous] [--expiration 2d] [--allow-anonymous] 允许任何人都可以访问 [--expiration 2d] 设置有效时间，过期自动删除，默认为 30 天，最大值为 30 天 如果需要创建多个端口，则可以改为： devtunnel host -p 9006 9007 9008 由于一个 powershell 窗口同一时间默认只能运行一个 devtunnel 进程，所以如果需要创建并监听多个内网映射端口，则需要像上面那样同时填写多个端口 查看当前系统中隧道端口列表： devtunnel list 查看某个隧道详细信息 假定隧道 id 为 “liuluhua”，列出 liuluhua 当前的一些配置或状态信息 devtunnel show liuluhua 托管某个隧道 假定们在其他 powershell 窗口里创建了一个隧道 “liuluhua”，们现在当前 powershell 中托管监控它 devtunnel host liuluhua 删除某个隧道： 假定要删除的某个 隧道 id 为 “liuluhua” devtunnel delete liuluhua 删除全部的隧道： devtunnel delete-all #devtunnel port create lemonade -p 5245#devtunnel host lemonadedevtunnel create [隧道名] -a#-a 表示可以表示隧道可以匿名访问#执行成功会输出隧道信息devtunnel port create [隧道名] -p 8080#隧道名为可选，默认为刚才创建的隧道#可以添加多个端口devtunnel host [隧道名]#隧道名为可选，默认为刚才创建的隧道#devtunnel delete [隧道名]#可以删除隧道 cloudflare控制台页面 https://dash.cloudflare.com 要有一个 Cloudflare 的账号，并且添加了所需要使用的域名，同时，开通 Cloudflare Zero Trust。 Tailscale免费版 构建虚拟局域网 —ZeroTier、Tailscale 以及蒲公英 在 zerotier 创建虚拟局域网，客户端安装后复制虚拟局域网 ID 加入即可实现访问，但是连接速度不稳定 进阶方式可以自己搭建 moon 服务器和 planet 服务器，但是也需要公网服务器 私有部署zerotier-planet服务 一分钟自建zerotier-planet 学习文档内网穿透 - Jonnyan的原创笔记 - 亖亖亖 (mrdoc.fun) cpolar 内网穿透cpolar 官网地址: https://www.cpolar.com 使用一键脚本安装命令 curl -L https://www.cpolar.com/static/downloads/install-release-cpolar.sh | sudo bash 向系统添加服务 sudo systemctl enable cpolar 启动 cpolar 服务 sudo systemctl start cpolar cpolar 安装成功后，在外部浏览器上访问 Linux 的 9200 端口即:【http:服务器的局域网 ip:9200】，使用 cpolar 账号登录,登录后即可看到 cpolar web 配置界面,结下来在 web 管理界面配置即可。 登录后，点击左侧仪表盘的隧道管理——创建隧道，创建一个的公网 http 地址隧道 隧道名称：可自定义命名，注意不要与已有的隧道名称重复 协议：选择 http 本地地址：8380(本地访问的地址) 域名类型：免费选择随机域名 地区：选择 China Top 隧道创建成功后，点击左侧的状态——在线隧道列表,查看所生成的公网访问地址，有两种访问方式,一种是 http 和 https。使用上面的 Cpolar https 公网地址,在任意设备的浏览器进行访问,即可成功看到界面,这样一个公网地址且可以远程访问就创建好了,使用了 cpolar 的公网域名,无需自己购买云服务器,即可到公网进行远程访问了！ 如果们需要长期异地远程访问，由于刚才创建的是随机的地址，24 小时会发生变化。另外它的网址是由随机字符生成，不容易记忆。如果想把域名变成固定的二级子域名，并且不想每次都重新创建隧道来访问，们可以选择创建一个固定的 http 地址来解决这个问题。 固定公网地址们接下来为其配置固定的 HTTP 端口地址，该地址不会变化，方便分享给别人长期查看的博客，而无需每天重复修改服务器地址。配置固定 http 端口地址需要将 cpolar 升级到专业版套餐或以上。 登录 cpolar 官网，点击左侧的预留，选择保留二级子域名，设置一个二级子域名名称，点击保留,保留成功后复制保留的二级子域名名称。保留成功后复制保留成功的二级子域名的名称。返回登录 Cpolar web UI 管理界面，点击左侧仪表盘的隧道管理——隧道列表，找到所要配置的隧道，点击右侧的编辑。修改隧道信息，将保留成功的二级子域名配置到隧道中 域名类型：选择二级子域名 Sub Domain：填写保留成功的二级子域名 点击更新(注意,点击一次更新即可,不需要重复提交) 更新完成后,打开在线隧道列表,此时可以看到公网地址已经发生变化,地址名称也变成了固定的二级子域名名称的域名 最后,们使用固定的公网 https 地址访问,可以看到访问成功,这样一个固定且永久不变的公网地址就设置好了，可以随时随地进行异地访问！ freedns42","categories":["4.软件","代理穿透"]},{"title":"远程桌面","path":"/2023/09/20/4-软件-代理穿透-远程桌面/","content":"TeamViewerVNC选择 lightdm 作为 Display Manager。首先更新系统软件包列表并安装必要的软件包： sudo apt updatesudo apt install -y xserver-xorg-video-dummy x11vnc xfce4 接下来配置 X11 服务器以使用虚拟视频设备。编辑etcX11xorg.conf 文件并添加： Section Device Identifier Configured Video Device Driver dummy VideoRam 256000EndSectionSection Monitor Identifier Configured Monitor HorizSync 5.0 - 1000.0 VertRefresh 5.0 - 200.0 ModeLine 1920x1080 148.50 1920 2448 2492 2640 1080 1084 1089 1125 +Hsync +VsyncEndSectionSection Screen Identifier Default Screen Monitor Configured Monitor Device Configured Video Device DefaultDepth 24 SubSection Display Depth 24 Modes 1920x1080 EndSubSectionEndSection 完成配置后，重启设备以应用更改：sudo reboot，之后配置和启动 x11vnc 服务。 查看设备 IP 地址：ip addr 启动 x11vnc 服务：x 代表端口号 sudo x11vnc -display :x -auth /var/lib/lightdm/.Xauthority 然后就可以在 PC 机上使用 ip+5900+x 地址来 VNC 远程连接。 安装必要的软件包sudo apt updatesudo apt install tigervnc-server #tightvncserver 桌面环境没有桌面环境的话，则需要安装相关的桌面环境 vncserver -geometry 1920x1080 :1 配置 VNC Server运行 vncserver 命令来首次配置。它会提示设置密码和查看连接所需的信息。 修改配置文件sudo nano ~/.vnc/xstartup 将其中的内容修改为以下类似的内容，以确保有正确的桌面环境启动： #!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESSgnome-session # #!/bin/sh#export XKL_XMODMAP_DISABLE=1#export XDG_CURRENT_DESKTOP=GNOME-Flashback:GNOME#export XDG_MENU_PREFIX=gnome-flashback-#gnome-session --session=gnome-flashback-metacity --disable-acceleration-#check 重启 VNC Servervncserver -kill :1 # 假设的 VNC 实例是 :1vncserver -geometry 1920x1080 :1 VNCserver 的端口为 5900+X，如果想要 VNC 端口在 9099 时，则设置 VNC 实例为 vncserver -geometry 1920x1080 :3199 设置防火墙如果启用了防火墙，需要允许 VNC 相关的端口通过。VNC 通常使用 5900 + 显示编号的端口，例如第一个实例是 5901。 例如，如果使用 ufw 防火墙，可以运行以下命令： sudo ufw allow 5901 这样，就完成了 Ubuntu 20 上 VNC Server 的基本配置，可以通过 VNC 客户端使用设置的密码和服务器的 IP 地址及端口进行连接。","categories":["4.软件","代理穿透"]},{"title":"MySQL使用","path":"/2023/09/19/4-软件-数据库-MySQL使用/","content":"MySQL 简介1. 什么是数据库？数据库（Database）是一个按照数据结构来组织、存储和管理数据的仓库。这个概念首次出现于六十多年前，随着信息技术和市场的发展，特别是在二十世纪九十年代后，数据管理的需求逐渐演变，不再仅仅是存储和管理数据，而是形成了多样化的用户所需的数据管理方式。目前，数据库不仅包括简单存储数据的表格，还涵盖了能够进行海量数据存储及处理的大型数据库系统，广泛应用于各个领域。 主流的数据库系统包括：SQL Server、MySQL、Oracle、SQLite、Access、MS SQL Server 等。本文将重点讨论 MySQL。 2. 数据库管理是干什么用的？数据库管理的功能主要包括： 将数据保存到文件或内存。 接收特定的命令，并对文件进行相应的操作，例如增、删、改、查（CRUD）。 通过使用数据库管理系统（DBMS，Database Management System），用户无需再手动创建文件和文件夹，可以通过直接传递命令，让软件代为进行文件操作。 MySQL 安装MySQL 是开放源代码的关系型数据库管理系统（RDBMS），使用结构化查询语言（SQL）进行数据库管理。作为 WEB 应用环境中常用的 RDBMS 之一，MySQL 以其高效、灵活而被广泛应用。 使用 MySQL 的基本条件 安装 MySQL 服务端。 安装 MySQL 客户端。 客户端连接服务端。 客户端发送命令，服务端接收并执行相应操作（如增、删、改、查等）。 下载地址：MySQL 下载页面 安装指南： Windows 安装请参考：博客 Linux 安装请参考：博客 上述链接中提供了完整的安装步骤，安装完成后，可通过命令 mysql.server start 启动 MySQL 服务。 MySQL 操作一、连接数据库通过以下命令连接到数据库： mysql -u 用户名 -p 例如： mysql -u root -p 常见错误： ERROR 2002 (HY000): Cant connect to local MySQL server through socket /tmp/mysql.sock (2) 该错误表明 MySQL 服务器守护进程（Unix）或服务（Windows）未运行。 退出连接：通过输入 QUIT 或按 Ctrl+D 退出连接。 二、查看数据库、创建数据库、使用数据库 查看所有数据库： SHOW DATABASES; 默认数据库： mysql：存储用户权限相关数据。 test：用于用户测试。 information_schema：存储 MySQL 本身的架构相关数据。 创建数据库： CREATE DATABASE db1 DEFAULT CHARSET utf8 COLLATE utf8_general_ci; -- 使用utf8编码CREATE DATABASE db1 DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci; -- 使用gbk编码 使用数据库： USE db1; 显示当前数据库中的所有表： SHOW TABLES; 三、用户管理 创建用户： CREATE USER 用户名@IP地址 IDENTIFIED BY 密码; 删除用户： DROP USER 用户名@IP地址; 修改用户名： RENAME USER 用户名@IP地址 TO 新用户名@IP地址; 修改密码： SET PASSWORD FOR 用户名@IP地址 = PASSWORD(新密码); 注：用户权限相关数据保存在 mysql 数据库的 user 表中，可以直接对其操作（不建议）。 四、权限管理数据库及权限管理： 数据库名.*：数据库中的所有内容。 数据库名.表：指定数据库中的某一表。 数据库名.存储过程：指定数据库中的存储过程。 *.*：所有数据库。 用户及 IP 权限： 用户名@IP地址：该用户仅能在特定 IP 下访问。 用户名@192.168.1.%：该用户可以在特定 IP 段访问（% 表示任意）。 用户名@%：可以在任意 IP 访问（默认 IP 地址为 %）。 查看权限： SHOW GRANTS FOR 用户@IP地址; 授权： GRANT 权限 ON 数据库.表 TO 用户@IP地址; 取消授权： REVOKE 权限 ON 数据库.表 FROM 用户@IP地址; 授权实例： GRANT ALL PRIVILEGES ON db1.tb1 TO 用户名@IP;GRANT SELECT ON db1.* TO 用户名@IP;GRANT SELECT,INSERT ON *.* TO 用户名@IP;REVOKE SELECT ON db1.tb1 FROM 用户名@IP; MySQL 表操作1. 查看表 查看数据库所有表： SHOW TABLES; 查看表所有内容： SELECT * FROM 表名; 2. 创建表CREATE TABLE 表名 ( 列名 类型 是否可以为空, 列名 类型 是否可以为空) ENGINE=InnoDB DEFAULT CHARSET=utf8; 示例： CREATE TABLE `tab1` ( `nid` INT(11) NOT NULL AUTO_INCREMENT, -- NOT NULL 表示不能为空, AUTO_INCREMENT 表示自增 `name` VARCHAR(255) DEFAULT zhangyanlin, -- DEFAULT 表示默认值 `email` VARCHAR(255), PRIMARY KEY (`nid`) -- 把nid列设置为主键) ENGINE=InnoDB DEFAULT CHARSET=utf8; 注释： 默认值：创建列时可以指定，如果未主动设置则自动添加默认值。 自增：为某列设置自增时，插入数据时无需设置此列，自动增加（表中只能有一个自增列）。 主键：一种特殊的唯一索引，不允许有空值。 3. 删除表DROP TABLE 表名; 4. 清空表内容DELETE FROM 表名; -- 删除表里全部数据TRUNCATE TABLE 表名; -- 清空表但保留结构 5. 修改表 添加列： ALTER TABLE 表名 ADD 列名 类型; 删除列： ALTER TABLE 表名 DROP COLUMN 列名; 修改列： ALTER TABLE 表名 MODIFY COLUMN 列名 类型; -- 修改类型ALTER TABLE 表名 CHANGE 原列名 新列名 类型; -- 修改列名及类型 添加主键： ALTER TABLE 表名 ADD PRIMARY KEY(列名); 删除主键： ALTER TABLE 表名 DROP PRIMARY KEY; 添加外键： ALTER TABLE 从表 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表 (主键字段); 删除外键： ALTER TABLE 表名 DROP FOREIGN KEY 外键名称; 修改默认值： ALTER TABLE 表名 ALTER 列名 SET DEFAULT 值; 删除默认值： ALTER TABLE 表名 ALTER 列名 DROP DEFAULT; 6. 基本数据类型MySQL 的数据类型大致可以分为数值、时间和字符串： 数值类型： BIT[(M)]：表示二进制位，长度(m)范围是从 1 到 64。 TINYINT[(M)] [UNSIGNED] [ZEROFILL]：小整数，范围为有符号的 -128 到 127 和无符号的 0 到 255。 INT[(M)][UNSIGNED][ZEROFILL]：整数，范围为有符号的 -2147483648 到 2147483647 和无符号的 0 到 4294967295。 BIGINT[(M)][UNSIGNED][ZEROFILL]：大整数，范围为有符号的 -9223372036854775808 到 9223372036854775807 和无符号的 0 到 18446744073709551615。 DECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]：用于精确的小数，m 是数字总个数，d 是小数点后个数。 字符串类型： CHAR(m)：表示固定长度的字符串，最多 255 个字符，即使内容小于 m，也会占用 m 的长度。 VARCHAR(m)：表示变长的字符串，最多 255 个字符，长度小于最大值的字符串可以存储。 TEXT：用于保存变长的大字符串，最多 65535 个字符。 ENUM：枚举类型，可以有最多 65535 个不同元素。 时间日期类型： DATE：格式为 YYYY-MM-DD。 TIME：格式为 HH:MM:SS。 DATETIME：格式为 YYYY-MM-DD HH:MM:SS。 MySQL 表内容操作表内容的操作主要包括增加、删除、修改和查询（增删改查——CRUD)。 增： INSERT INTO 表 (列名, 列名...) VALUES (值, 值,...);INSERT INTO 表 (列名, 列名...) VALUES (值, 值,...),(值, 值, 值...); 示例： INSERT INTO tab1(name, email) VALUES(zhangyanlin, zhangyanlin8851@163.com); 删： DELETE FROM 表; -- 删除表里全部数据DELETE FROM 表 WHERE id=1 AND name=zhangyanlin; -- 删除特定行数据 改： UPDATE 表 SET name=zhangyanlin WHERE id1; 查： SELECT * FROM 表;SELECT * FROM 表 WHERE id 1;SELECT nid, name, gender AS gg FROM 表 WHERE id 1; 查询条件示例： 条件判断使用 WHERE。 通配符使用 LIKE。 限制结果集使用 LIMIT。 排序使用 ORDER BY，如 ASC（升序）或 DESC（降序）。 分组使用 GROUP BY。","categories":["4.软件","数据库"]},{"title":"MYSQL安装","path":"/2023/09/18/4-软件-数据库-MYSQL安装/","content":"MySQL 环境搭建指南安装 MySQL要在的系统上安装 MySQL 服务器，只需输入以下命令： sudo apt install mysql-server -y 这里的 -y 选项让安装过程自动确认，避免了每一步手动输入 yes 的麻烦。 查看和管理 MySQL 服务状态安装完成后，可以使用下列命令来查看和管理 MySQL 服务： sudo service mysql status 这个命令会告诉 MySQL 服务当前的状态，是正在运行还是已停止。例如，可能会看到服务状态为 active (running)，这意味着 MySQL 正在正常工作。 启动 MySQL 服务： sudo service mysql start 这条命令将启动 MySQL 服务。之后，可以再次运行状态检查命令，确认服务已成功启动。 停止 MySQL 服务： sudo service mysql stop 如果需要维护系统或更新配置，可以使用此命令安全地停止 MySQL。 重启 MySQL 服务： sudo service mysql restart 这条命令会先停止服务再重新启动，对于更新配置文件后的应用非常有用。 查看并更新 MySQL 密码查看 MySQL 的配置文件，可以使用以下命令： sudo cat /etc/mysql/debian.cnf 这将显示包含 MySQL 的一般配置，特别是与 Debian 映像相关的设置，其中可能包含默认的用户名和密码。 使用默认用户名和密码进行登录： mysql -u [your-username] -p 在这里，需要替换 [your-username] 为实际的用户名（如 root）。系统将在提示输入密码时，可以使用在上一步中找到的默认密码。 更新 root 用户密码一旦成功登录到 MySQL，可以更新 root 用户的密码。输入以下 SQL 命令来更新密码： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY newpasswd; 将 newpasswd 替换为想要设置的新密码。mysql_native_password 是 MySQL 中一种广泛使用的身份验证方法。 变化生效后，可以退出 MySQL： exit; 然后，用新密码再次登录，确保一切设置正确： mysql -u root -p 系统会提示输入新设置的密码。输入后如果一切顺利，将成功登录。 创建 Qexo 数据库为了满足 Qexo 应用程序的需求，现在需要创建一个新的数据库。在 MySQL 提示符下执行以下命令： CREATE DATABASE qexo; 此命令创建一个名为 qexo 的新数据库，可以根据需要进一步配置和管理这个数据库以用于应用程序数据存储。 一旦创建成功，可以通过以下命令查看所有数据库，确认 qexo 数据库的存在： SHOW DATABASES; 这将列出所有现有的数据库，包括刚刚创建的 qexo。这样就完成了 MySQL 环境的搭建，可以开始使用这个数据库进行更多的操作了。","categories":["4.软件","数据库"]},{"title":"Sqlie使用","path":"/2023/09/15/4-软件-数据库-Sqlie使用/","content":"数据库基础安装数据库 sudo apt-get install sqlite3 数据库指令操作打开一个数据库 sqlite3 my.db 常用查询: .table //查看数据库中的表.schema tablename //查看相应表的结构.database //查看当前打开的数据库.quit //退出当前数据库.help //列出帮助信息 创建表: create table movies (id int, name text, time int, auth text); 删除表: drop table tablename; 添加信息: insert into movies values (.....);insert into movies values (.....); 查询信息: select * from movies ; 删除信息: delete from movies where id=1; 更新信息: update tablename set name= where id=2; 添加字段: alter table tablename add column sex char ; //创建名字为tong.db的数据库sqlite3 tong.db//创建一个叫user的table,里面有name, agecreate table user(name, age integer);//name的默认类型是字符串，用taotao//age的类型相当于int//删除一个tabledrop table user;//向user中存储数据insert into user values（taotao, 18）;//增加一个column叫num,类型是 integeralter table user add column num integer;//更新数据update user set name=taotao,age=18 where num=110;//打印所有信息select * from user;//打印某一个信息select * from user where name=taotao;//删除一个叫taotao的人delete from user where name=taotao;//查看有哪几个表.tables//查看某一个表的属性.schema user//退出.q 示例代码#include stdio.h#include stdlib.h#include sqlite3.h#include string.h#define SQL_NAME ./chen.db#define TAB_NAME tbint fun(void *buf, int num, char **val, char **name)\tint i;\tfor(i = 0; i num; ++i) printf(%s:%s , name[i], val[i]); printf(========%d=== , num);\treturn 0;int main(int argc, const char *argv[])\tchar buf[200] = \\0;\tsqlite3 *db = NULL;\tif(SQLITE_OK != sqlite3_open(SQL_NAME, db)) fprintf(stderr, OPEN SQLITE3 ERROR. ); exit(EXIT_FAILURE);\t#if 1\t/* #include stdio.hint main()\tchar a = A;\tchar buf[80];\tsprintf(buf, The ASCII code of a is %d. , a);\tprintf(%s, buf);\treturn 0;输出ASCII 的值*/\tsprintf(buf, create table if not exists %s (id, sex, score float);, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, NULL, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE);\t/*\t功 能: 将s所指向的某一块内存中的每个字节的内容全部设置为ch指定的ASCII值, *\t块的大小由第三个参数指定,这个函数通常为新申请的内存做初始化工作 */\tmemset(buf, 0 , sizeof(buf));\tsprintf(buf, insert into %s values(chen, B, 90);, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, NULL, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE); #endif\tmemset(buf, 0, sizeof(buf));\tsprintf(buf, select * from %s ;, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, fun, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE); sqlite3_close(db);\treturn 0;","categories":["4.软件","数据库"]},{"title":"将MySQL数据库拷贝到另一台机器","path":"/2023/09/14/4-软件-数据库-将MySQL数据库拷贝到另一台机器/","content":"可以在支持相同浮点格式的不同架构之间复制 MyISAM 表的结构和数据文件，这些文件包括 .frm、.MYI 和 .MYD。这些文件分别用于存储表的定义、索引和数据。值得注意的是，MySQL 会处理所有字节交换的问题，因此在不同平台间移动这些文件通常是可行的。 如果需要在不同架构之间转移整个数据库，最有效的方式是使用 mysqldump 工具。该工具可以生成一个包含 SQL 语句的文件，这些语句可以用来重建数据库结构和数据。转移步骤如下： 生成转储文件：可以使用以下命令创建数据库的转储文件。 mysqldump db_name db_name_dump.sql 这个命令创建了一个名为 db_name_dump.sql 的文件，里面包含了重建 db_name 数据库所需的所有信息。 传输文件：将生成的文件通过网络或 USB 驱动器移动到目标机器。 导入数据库：在目标机器上使用以下命令将转储文件导入到 MySQL 中。 mysql db_name db_name_dump.sql 要查看可用的选项，可以运行如下命令： mysqldump --help 如果要将数据迁移到更新版本的 MySQL，推荐使用 mysqldump --opt 选项，它可以优化生成的转储文件，这些文件更小且处理速度更快。 在同一网络下，两台机器之间移动数据库的便捷方式是如下命令的组合： mysqladmin -h other_hostname create db_namemysqldump --opt db_name | mysql -h other_hostname db_name 第一行命令会在目标机器上创建一个新的数据库，第二行将原机器的数据库转储并同时导入到目标机器。 若需在低速网络下从远程机器复制数据库，可以使用压缩选项来减少数据量，命令如下： mysqladmin create db_namemysqldump -h other_hostname --opt --compress db_name | mysql db_name 另外，还可以将备份结果保存到压缩文件中，以便节省存储空间。例如： mysqldump --quick db_name | gzip db_name.contents.gz 这一命令将数据库以压缩格式备份到文件 db_name.contents.gz 中。然后在目标机器上，使用以下命令解压并导入数据： mysqladmin create db_namegunzip db_name.contents.gz | mysql db_name 除了 mysqldump，还可以利用 mysqldump 和 mysqlimport 快速转移数据库，尤其对大型表格更为高效。转移步骤如下： 创建输出目录并备份数据库： mkdir DUMPDIRmysqldump --tab=DUMPDIR db_name 上述命令会在 DUMPDIR 目录中创建多个文件，含有数据库结构和数据。 将 DUMPDIR 目录中的文件传输到目标机器上。 导入数据库： mysqladmin create db_name # 创建数据库cat DUMPDIR/*.sql | mysql db_name # 创建表mysqlimport db_name DUMPDIR/*.txt # 加载数据 请务必复制 MySQL 数据库，因为授权表同样存储于此。在新的机器上可能需要以 MySQL root 用户身份运行命令，直到生成所需的 MySQL 数据库。 在成功导入 mysql 数据库后，务必执行以下命令，以使服务器重新加载授权表信息： mysqladmin flush-privileges","categories":["4.软件","数据库"]},{"title":"ARINC422","path":"/2023/09/12/4-软件-航电-ARINC422/","content":"ARINC 422 协议ARINC 422 则因其高效的点对点通信能力适合于快速数据传输。 ARINC 422 是一种用于航空电子设备间串行数据通信的协议，主要用于传输数字信号。它是一种单向通信协议，通常用于传输数据和指令。 ARINC 422 协议内容 数据格式： ARINC 422 使用二进制编码，数据以串行形式发送。 波特率： 常用的波特率为 100 kbps，传输距离可达 1,200 米。 信号电平： 使用差分信号，具有较强的抗干扰能力。逻辑”1”和逻辑”0”通过电压差来表示。 数据帧结构ARINC 422 的一帧数据通常包含以下部分： 起始位（Start Bit）： 通常为 1 位，表示数据帧的开始。 数据位（Data Bits）： 通常为 8 位（可以根据具体应用有所变化），用于传输实际的数据内容。 奇偶校验位（Parity Bit）： 可选，1 位，用于检测传输错误。可以设置为偶校验或奇校验。 停止位（Stop Bits）： 通常为 1 或 2 位，表示数据帧的结束。 一帧数据的内容分布示例假设一帧数据的结构如下： 1 位：起始位 8 位：数据位 1 位：奇偶校验位 1 位：停止位 +---------+----------+-------------+-----------+| Start | Data | Parity | Stop || Bit | Bits | Bit | Bit |+---------+----------+-------------+-----------+| 1 | 8 | 1 | 1 |+---------+----------+-------------+-----------+","categories":["4.软件","航电"]},{"title":"ARINC429","path":"/2023/09/11/4-软件-航电-ARINC429/","content":"ARINC 429 协议ARINC 429 以其单向、广播式的特性和复杂的数据帧结构适合于多设备间的信息共享 概述ARINC 429 是由美国航空无线电公司制定的一种单向串行通信协议，广泛应用于民用和军用飞机的电子系统中。其主要特点包括： 单向传输：信息只能从发送器流向接收器。 差分信号：采用双极性归零码进行信号传输，具有良好的抗干扰能力。 数据帧结构ARINC 429 的数据单元由 32 位组成，具体分布如下： Bit 1-8：Label（标签域），用于标识数据类型（八进制表示）。 Bit 9-10：SDI（源目的地标识符），指示数据来源或目的地。 Bit 11-28 或 29：Data Field（数据域），包含实际传输的数据，通常使用 BCD 或二进制数表示。 Bit 30-31：SSM（信号状态矩阵），描述数据的状态或性质。 Bit 32：Parity Bit（校验位），用于奇偶校验以确保数据的完整性。 MPIO429（Multi-Protocol IO 429）是一种基于 ARINC 429 协议的多功能输入输出模块，通常用于航空电子系统中，支持对不同种类的飞机数据总线进行通信。ARINC 429 协议广泛应用于航空领域，特别是在飞行控制、导航、发动机管理、机载传感器数据传输等方面。 MPIO429 的功能特点数据传输速度：支持 ARINC 429 协议的标准传输速率，通常为 12.5 kbps 或 100 kbps，适合低速数据传输。 多通道支持：MPIO429 模块通常会提供多个通道，允许同时处理多个 ARINC 429 信号，可以连接多个设备并处理更多数据。 ARINC 429 协议与 MPIO429 数据传输方式：ARINC 429 使用单向数据传输，一般分为发射器和接收器，每个设备通过一个独立的信号线发送或接收数据。 数据帧结构：ARINC 429 数据帧包含多个字段，包括起始位、数据位、标签（label）、数据和奇偶校验位等，传输的数据一般是飞行数据、环境监控、传感器数据等。 应用场景 飞行控制系统：用于飞行状态、控制指令等数据的传输。 航空电子设备：如雷达、导航、仪表等设备的数据通信。 发动机控制系统：监控发动机状态、控制指令等。 在 ARINC 429 协议中，一个接口通常是单向的，即每个 ARINC 429 信号线路只能作为输入或输出之一。这是因为 ARINC 429 本身设计为点对点的单向数据传输协议，每条线路只有一个发送器和一个接收器。 为什么 ARINC 429 是单向的？ 简化设计和减少干扰：ARINC 429 的单向通信减少了信号冲突的可能性，并且可以在硬件和协议层面上简化电气设计。这使得通信更加可靠，尤其在飞机这种对数据传输可靠性要求极高的环境中。 速度和时序：ARINC 429 的传输速率比较低（通常为 12.5 kbps 或 100 kbps），并且通信是基于时间分片的，因此单向传输更容易管理。 双向通信的实现尽管 ARINC 429 本身是单向的，但某些系统可能会使用多个 ARINC 429 通道来实现双向通信。比如： 双通道设计：如果一个设备既需要发送数据，又需要接收数据，通常会为每个方向提供独立的通道（输入和输出），每个通道都连接到不同的 ARINC 429 总线或接口。 其他协议组合：有些设备可能还会采用其他协议（如 MIL-STD-1553 或 CAN）来实现双向通信，这些协议支持全双工通信，即同一条线路可以同时进行数据输入和输出。 在 ARINC 429 协议下，一个接口本身通常不能同时进行输入和输出，但可以通过增加通道或使用其他协议来实现双向通信。 ARINC-429 是一个关键的标准，用于商用飞机航空电子系统之间的数字数据传输。这个协议旨在确保不同设备间的互换性，使得不同制造商的航空电子设备可以无缝协作，显著提升了系统的灵活性与安全性。 ARINC 429 通常被称为 Mark 33 数字信息传输系统（DITS）总线。尽管它主要用于航空电子领域，但这种总线技术也成功应用于地面车辆、武器系统以及其它商业和军事设备。举例来说，在现代战斗机中，ARINC 429 可以用于通讯导航设备和火控系统之间的数据交换，确保设备间能够准确地共享关键信息。 ARINC-429 标准的组成部分 PART 1: 提供了 ARINC 429 的功能基本描述，包括支持的物理和电气接口，数据字格式、标准标签和地址分配以及相关示例。这部分确保设备制造商可以理解和实现与该标准相关的基本要求。 PART 2: 定义了 ARINC 429 离散量字及按标签顺序的位分配，确保数据传输的正确性和兼容性。 PART 3: 描述了 ARINC 429 的数据传输协议及其通过大块或者文件格式进行数据传输的消息定义，为后续的数据交互提供框架。 PART 4: 列出了多年来发表的 ARINC 429 第 1 部分的补编档案，并作为 ARINC 429 第 18 号补编的一部分进行更新（2012 年）。这为研究和开发人员提供了丰富的历史背景和技术演变的信息。 数据传输特点ARINC 429 的数据传输特点在于其简单的单向总线通信数据流设计。与典型的多向数据总线不同，ARINC-429 的单向设计能显著提升系统的可靠性。如下图所示，发送器（Sender）可以同时支持最高 20 个接收器（Receiver），每个接收器可以独立接收消息而不产生信号冲突。 ┌──────────┐ ┌─────────┐ ┌────────────┐│RECEIVER_1│ │ ... │ │ RECEIVER_N │└──────────┘ └─────────┘ └────────────┘ ▲ ▲ ▲ │ │ │┌─────────┐──────────────┴──────────────────┘│ SENDER │└─────────┘ 双向传输: 添加一根额外线缆即可实现双向数据传输，允许接收器在需要时转变为发送器。 数据字格式: 每个数据字（WORD）为 32 位，代表特定的工程单位，如高度、气压等，标准的数据传输速率分为高速（100 kbs）和低速（12.5 kbs）。 设备标识: 各个设备通过设备 ID 号进行管理，违反了 ARINC 429 的地址分配原则，从而允许更灵活的数据管理。 信号自锁: 对于数据字之间的连续区分，一个至少 4 位的空或零电压标识可以让系统在没有单独时钟信号的情况下正常工作，这就是 ARINC 429 的自锁特性。 数据字结构通过 ARINC-429 总线发送的数据以 32 位字的形式传输，每个字包含多种信息。结构示例如下： ┌──┬─────┬───────────────────────┬─────┬───────────────────────┐│P │ SSM │ DATA │ SDI │ LABEL │└──┴─────┴───────────────────────┴─────┴───────────────────────┘ LABEL: 8 位标签用于解释数据字段。举个例子，标签为 372 的航向参考系统提供了风向信息，而标签为 203 的空气数据计算机则提供气压高度，312 则表示地面速度。这样的标准化标签使得不同厂商的设备能够使用相同的参数定义。 SDI: 2 位源目的地标识符，帮助发送器识别消息应发送给哪个接收器，若不需要该标识符，这部分可以用作额外的数据位。 DATA: 19 位数据部分，承载具体的数值信息。 SSM: 符号状态矩阵，提供信息的状态指示。 P: 奇偶校验位用于错误检测，采用奇数奇偶校验确保数据接收的准确性。ARINC 429 仅规定检测错误的方法，而不包括纠错机制。 SSM 的状态可根据 LABEL 的不同而有所不同，如下： 00 (0)：故障； 01 (1)：无计算数据或输出无效； 10 (2)：功能实验； 11 (3)：正常。 #include stdio.htypedef unsigned int uint32_t;// 获取二进制表示中位1的个数int getBit1Count(uint32_t x) uint32_t i = 0, count = 0, temp = x; for (i = 0; i 32; i++) if (1 == (temp 0x00000001)) count++; // 如果最低位为1，计数增加 temp = temp 1; // 右移一位，检查下一位 return count; // 返回1的总数// 设置校验位uint32_t setCheckBit(uint32_t x) // 如果当前x中1的个数为偶数，则设置校验位 if (getBit1Count(x) % 2 == 0) x = x ^ 0x80000000; // 0x80000000在二进制中为1000...0000 else x = x ^ 0x00000000; // 如果已经是奇数个1，不做改变 return x; // 返回新的数值// 打印出每一位的值void print_bits(uint32_t x) uint32_t i = 0; for (i = 0; i 32; i++) printf(%d, (x 0x80000000) 31); // 输出最高位 x = x 1; // 左移，检查下一个位 // 检查校验位并还原原始值uint32_t checkAndRestore(uint32_t x) uint32_t bit1Count = getBit1Count(x); // 获取1的个数 if (bit1Count % 2 == 0) printf(错误! ); // 输出错误信息 return 0; // 返回0，表示出错 else printf(正确! ); // 校验成功的提示 // 删掉最高位的校验位 x = x 0x7FFFFFFF; // 通过与运算清除最高位 return x; // 返回还原后的数值int main() uint32_t data[] = 0, 100, 101, 1001, 0x23456; // 初始化测试数据 uint32_t i = 0, set; // 遍历每个数据并进行处理 for (i = 0; i 5; i++) printf(设置校验位之前: ); print_bits(data[i]); // 打印二进制表示 printf(,%d个1, 0x%x , getBit1Count(data[i]), data[i]); // 打印1的个数和十六进制值 set = setCheckBit(data[i]); // 设置校验位 printf(设置校验位之后: ); print_bits(set); printf(,%d个1, 0x%x , getBit1Count(set), set); // 打印设置后数据的状态 printf(校验和还原:0x%x , checkAndRestore(set)); // 校验并还原 printf(------- ); // 分隔线 return 0; 输出 设置校验位之前: 00000000000000000000000000000000,0个1, 0x0设置校验位之后: 10000000000000000000000000000000,1个1, 0x80000000正确! 校验和还原:0x0-------设置校验位之前: 00000000000000000000000001100100,3个1, 0x64设置校验位之后: 00000000000000000000000001100100,3个1, 0x64正确! 校验和还原:0x64-------设置校验位之前: 00000000000000000000000001100101,4个1, 0x65设置校验位之后: 10000000000000000000000001100101,5个1, 0x80000065正确! 校验和还原:0x65-------设置校验位之前: 00000000000000000000000001111101001,7个1, 0x3e9设置校验位之后: 00000000000000000000000001111101001,7个1, 0x3e9正确! 校验和还原:0x3e9-------设置校验位之前: 00000000000000100011010001010110,8个1, 0x23456设置校验位之后: 10000000000000100011010001010110,9个1, 0x80023456正确! 校验和还原:0x23456------- ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ └────────────────────┴────────────────────┴─────────────┘ ┌──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐LSB │ 8 │ 7 │ 6 │ 5 │ 4 │ 3 │ 2 │ 1 │ MSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘LSB: 最低有效位 MSB: 最高有效位 注意到，上述表中的最低有效位（LSB）和最高有效位（MSB）概念相对较为特殊，和们平时理解的可能是反着的。 并且，8 位数字被划分为三个部分，其中百位数通常用二进制 11 表示，即为数字 3，而十位数和个位数最多可以用二进制 111 表示，也就是数字 7。因此，上述内容实际上是在将 8 位数字分成三段，每段表示一个 8 进制数，且高低位顺序相反。这种表示方式被称为 反向八进制。 最大的 Label 值们可以观察到，最大的 Label 值为 377，这对应了八进制中的最大三位数。 实际示例以 312 作为飞机的 ground speed 进行编码的示例，过程如下： 百位数： 取出数 3，它用二进制 11 表示。在反转高低位后，结果仍为 11。 十位数： 取出数 1，它用三位二进制表示为 001。在反转高低位后，得到 100。 个位数： 取出数 2，用三位二进制表示为 010，反转后保持为 010。 在这个过程中，们的每一位都被处理并正确编码。 ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ ├────────────────────┼────────────────────┼─────────────┤ │ 2 │ 1 │ 3 │ ├──────┬──────┬──────┼──────┬──────┬──────┼──────┬──────┤ MSB │ 0 │ 1 │ 0 │ 1 │ 0 │ 0 │ 1 │ 1 │ LSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘ 通过对照 ARINC429P1 的 ATTACHMENT 6 中的值，可以确认上述编码过程的正确性。 示例代码以下代码展示了如何实现这种编码及解码。 #include stdio.htypedef unsigned int uint32_t;// 打印出每一位void print_bits(uint32_t x) uint32_t i = 0; for (i = 0; i 32; i++) printf(%d, (x 0x80000000) 31); x = x 1; // 翻转指定数的比特位uint32_t reverse_bits(uint32_t x, uint32_t from, uint32_t to) uint32_t result = 0; for (uint32_t i = from; i = to; i++) result += (x i 1) (to - i); return result;// 编码函数uint32_t encodeLabel(uint32_t word, uint32_t x) if (x 377) printf(out of range); return 0; // 清零word的前8位 word = 0xffffff00; // 编码百位数 uint32_t hundreds = (x % 1000) / 100; hundreds = reverse_bits(hundreds, 0, 1); word = word | hundreds; // 编码十位数 uint32_t tens = (x % 100) / 10; tens = reverse_bits(tens, 0, 2); word = word | (tens 2); // 编码个位数 uint32_t ones = x % 10; ones = reverse_bits(ones, 0, 2); word = word | (ones 5); return word;int main() print_bits(reverse_bits(0x4, 0, 2)); // Outputs: 100 - 001 printf( ); print_bits(reverse_bits(0x1, 0, 2)); // Outputs: 001 - 100 printf( ); print_bits(reverse_bits(0x1, 0, 31)); // Outputs: 1 - 10000000000000000000000000000000 printf( ------------ ); uint32_t word = 0x22849800; print_bits(encodeLabel(word, 313)); printf( ); print_bits(encodeLabel(word, 323)); printf( ); return 0; 输出结果运行后程序的输出结果示例： 00000000000000000000000000000001 00000000000000000000000000000100 10000000000000000000000000000000 ------------ 00100010100001001001100011010011 00100010100001001001100011001011 解码过程理解了编码之后，解码便变得简单。以下是解码的实现： uint32_t decodeLabel(uint32_t word) // 获取低8位 word = 0xff; // 得到百位数 uint32_t hundreds = word 0x3; hundreds = reverse_bits(hundreds, 0, 1); // 得到十位数 uint32_t tens = (word 2) 0x7; tens = reverse_bits(tens, 0, 2); // 得到个位数 uint32_t ones = (word 5) 0x7; ones = reverse_bits(ones, 0, 2); return hundreds * 100 + tens * 10 + ones; 附加信息在计算机系统和数据处理领域，还有一些重要的编码标准和技术，例如： BNR：二进制补码小数 BCD：二进制编码十进制 IOS5：IOS5 编码的字母与数字 离散量：用于处理不连续的数据 图形表示：在地图和显示器上显示的线条、圆形以及文字数字，这些通常使用与 ISO 5 字母数字数据传输类似的技术。ARINC 特性 744A 提供了具备图形功能的全格式打印机，这使得附加信息和示例图形字符的传输成为可能。","categories":["4.软件","航电"]},{"title":"ARINC653","path":"/2023/09/08/4-软件-航电-ARINC653/","content":"ARINC653 介绍ARINC653 作为一个标准，主要阐述了模块化综合航空电子设备 IMA(Integrated Modular Avionics)使用的应用软件的基线操作环境。其定义了航空应用与下层操作环境之间的接口和数据交换的模式以及服务的行为，并描述了嵌入式航空电子软件的运行时环境。 在实际应用过程中，航空电子中的核心模块软件包括两类: 应用软件和核心软件。ARINC653 定义的就是位于应用软件和操作系统 OS 之间的 APEX(APplication EXecutive)接口，APEX 接口是操作系统为应用软件提供的一个功能集合。利用这个功能集合，应用软件可以控制系统的调度，通信和内部状态信息。 APEX 接口相当于为应用提供的一种高层语言。 而对于 OS 来说，是关于参数和入口机制的定义。 ARINC653 标准一个重要的标准就是将航空电子软件进行分时，分区管理。采用二级调度，分区内基于优先级进行调度，分区间通过时间窗口进行时间轮转调度。同时定义了分区内的进程接口，进程间通信接口，分区间通信的 Port 标准接口，并且为了增强系统的可靠性定义了系统级，分区级，进程级别的健康监控管理接口。 分区和区间管理分区（Partitioning）是 ARINC653 中一个核心概念。在 IMA(Integrated Modular Avionics)系统中，一个核心模块会包含一个或多个航空电子应用，并且这些应用要能够独立运行。分区就是航空电子应用中的一个功能划分。分区的单位称为区间，区间内的每一个执行单元称为进程。每一个区间具有自己独立的数据、上下文和运行环境，这样做的好处是能够防止一个区间的错误影响到其他区间。另外，它能使得整个系统容易验证、确认和认证。 区间化以及区间的管理和调度是由 OS 来实现的。ARINC653 为区间的调度规定了一种基于时间窗的循环调度算法。 为了完成各区间的周期性调度，由 OS 维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表,在规定的时间窗口内激活对应区间的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 ARINC supplement 1 对主时间框架的时间定义原则进行了补充。它规定主时间框架的大小应该是核心模块中所有区间周期的最小公倍数的正整数倍，并应考虑到每个区间每次执行的时间长度和执行频率。 在 ARINC653 Supplement 1 发布时又增加了系统区间属性和启动条件属性。区间的工作模式包括空闲，冷启动，热启动和正常四种，如图 3 所示。每个区间所需资源在系统构建时指定，在区间初始化完成时区间对象创建。OS 在进入运行模式时启动应用区间，然后区间进入正常运行模式。监测管理功能在响应致命错误时将重启区间或者停止区间的运行。 根据 ARINC653 标准的规定，需要模块操作系统提供时空隔离机制的支持，因此内核和分区应用在空间上和时间上应进行隔离保护。 下面分两部分论述系统空间时间分配，首先是基于整个模块操作系统的空间和时间分配情况，后面是基于 APEX 接口的实现上的空间和时间分配。 ●空间隔离 在操作系统中，以分区为资源分配单位。采用复平面空间的方式，每个应用都有独立的 4G 空间，从而实现用户与操作系统，用户与用户之间在存储空间上进行隔离，达到互不影响的目的。 从 APEX 接口的设计实现上来讲，空间分配包含两部分的内容： APEX 分区上的资源分配 即使用的是应用分区上的空间资源，包括了各个 APEX 对象管理控制块资源。 分区管理 进程管理 分区健康监控 信号量 事件 黑板 缓冲 时间管理 采样端口 队列端口 内核空间的资源分配 主要是 APEX 接口调用过程中需要在内核分配的资源，列表如下： 内核的域管理 内核的任务管理 内核的周期对象管理 内核信号量 内核黑板 内核消息队列另外，在 APEX 内核支持层封装的对分区间通信的端口的支持，也是在内核空间分配的端口控制管理资源，包括了端口控制链和通道控制链。 ●时间隔离 目前 OS 为基于 APEX 接口的应用分区提供了时间调度表调度策略。通过配置时间调度表，可以控制各个分区在时间点上的运行分配。由操作系统维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表，在规定的时间窗口内激活对应域的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 接口清单 分区管理分区是一个应用运行的资源单位。一个分区是一个独立的应用环境：它由数据、自己的上下文关系、配置属性和其它项组成。分区的运行要满足时间和空间的要求。 通过分区可以实现应用间的隔离和保护，分区也是应用隔离保护的单位，每个分区有独立的运行空间和堆空间，不同分区的运行空间不会重叠。当一个应用出现致命错误，出现的最坏情况就是应用被系统删除或者重启动。而这个应用的错误不会影响到其他分区，更不会影响到操作系统口。 分区具有独立的调度策略，每个分区在属于自己时间窗口内运行。 一个分区则由一个或多个并发执行的进程组成，分区内的所有进程将共享分区所占有的系统资源。分区管理要求系统中同时可以运行多个不同类型的应用，同时在时间上和空间上互不影响。分区管理主要包括：分区的属性定义、分区的工作状态转换、分区的控制和分区的调度。 函数功能 分区状态的获取 设置分区模式 分区间通信分区间通信是 ARINC 653 标准中使用的一种通用表达方式，其主要定义两个或多个分区间的通信，标准的分区间通信是一项基本需求以支持应用软件的可重用性和可移植性。所有的分区间通信都通过消息进行。消息被定义为有限长度的连续数据块。 消息从单个的源发出，到一个或多个目标。消息的目标是分区而不是分区内的进程。分区通过已定义的访问点访问通道，访问点称为端口(port)。通道由一个或多个端口以及相关的资源组成。端口提供所需的资源以允许特定的分区在特定的通道中发送或接收消息。分区可以通过各自的资源和目的端口使用多个通道交换消息。通道将一个发送端口通过中间端口和一个或多个接收端口连接起来。每个单独的通道都可以配置在专门的模式下运行。可以使用两种传送模式，采样模式(samplingmode)和队列模式(queuingmode)。因此提供了采样端口服务和队列端口服务。 分区间通信遵循以下原则： 发送方和接受方并不关心对方的具体名字和物理位置，以避免系统的其他地方修改之后引起分区的变化。 消息只能有一个源，但可以有若干个目的； 来自不同端口的消息不需要按照它们发送的时间顺序到达它们的目的。 函数功能 采样端口服务 根据采样端口的周期性数据特点，采用内核提供的黑板机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX 内核支持层来实现具体的黑板写和读功能。需要注意的是源端口不用创建对应的黑板。APEX 内核支持层只为目的端口创建对应的黑板。 由于采样端口的数据具有周期性特点，因此存在数据有效性判断。对采样端口数据有效性的定义如下：数据停留在端口的时间小于用户设置的数据刷新周期时间。 数据停留时间从端口获取数据的系统时间一发送数据到端口的系统时间。 队列端口服务 根据队列端口的消息队列数据特点，采用内核提供的消息队列机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX内核支持层来实现具体的消息的发送和接收功能。需要注意的是源端口不用创建对应的消息队列。APEX 内核支持层只为目的端口创建对应的消息队列。 进程管理完成应用进程的管理，进程是操作系统运行的基本单位。 在分区内的执行体是由一个或多个进程组成，每个进程隶属于特定的分区，分区内的各进程之间并发执行。进程管理主要负责分区内进程的创建、调度和删除等管理工作。 进程分为按固定频率执行的周期进程和由事件触发的非周期进程两类，操作系统应具备对这两类进程的调度能力；进程在出现故障时应允许重新初始化或者终止；对于访问临界区的进程，为保证安全性，在访问时进程管理应禁止调度。 函数功能 创建进程 停止进程 挂起进程 解挂进程 设置进程优先级 分区内通信支持分区内的进程之间相互通信。按通信机制划分，分区内通信共有两种。一种是缓冲区和黑板，用于进程间通信。另一种是信号量和事件，用于进程间同步。 缓冲区和黑板的差别是：缓冲区允许消息以队列的形式存储，消息不允许覆盖，而黑板在任何时刻最多只保留一个消息，消息允许覆盖；信号量和事件的差别是：信号量用于对系统资源的访问，而事件用来完成进程之间的同步／异步操作。 提供了两种分区内通信机制： 函数功能 允许分区内进程间通过缓冲区和黑板进行通信。 通过计数信号量或事件实现进程间的同步。 缓冲 Buffer消息队列 MessageQueue在缓冲区中，消息的每个新实例都携带唯一不同的数据，因此传送时不允许覆盖前一个。缓冲允许在消息队列中存储多个消息。发送进程发送的消息以 FIFO 顺序存储在消息队列中。这种排队模式下不应该丢失任何消息。缓冲中能够存储的消息数量是由缓冲大小确定并在创建时指定的。等待在缓冲上的进程以 FIFO 或者优先级排队。优先级排队的情况下，相同优先级的进程按照 FIFO 顺序排队。排队规则在创建缓冲时定义。如果有进程等待缓冲消息并且缓冲(变得)不为空，则按照应用排队规则算法(FIFO 或者优先级)来确定哪个排队的进程接收此消息。OS 将把该进程从进程队列上移出，将其置为就绪状态。OS 将把消息从缓冲消息队列中移出。 当进程试图从空缓冲接收消息，或者发送消息到满的缓冲，将发生进程重调度。调用进程将被放入队列一段指定的时间，如果在该段时间内没有消息被接收或者发送，OS 将自动从队列中移出该进程，将其置为就绪状态。 黑板 Blackboard黑板是分区内进程间的一种通信机制。它和消息队列一样支持在多个源和目的之间的传输。黑板与消息队列最大的不同点是消息队列允许消息排队，而黑板不允许消息排队。 只要预先分配的存储空间足够大，那么进程可以创建尽可能多的黑板。 当进程进入一个等待状态时，分区需要重新进行进程调度。超时机制限制或者避免了等待时间过长的现象出现。 黑板是不支持排队的，写到黑板上的任何消息可能被擦除或者被新写入的消息覆盖掉。任务可以从黑板上读取一条信息、显示一条信息或者擦除黑板。 试图从空的黑板上读取信息的操作将会导致进程重新调度，进行该操作的进程将会进入队列中等待一段指定时间，如果在该段时间内没有消息被写到黑板上，dOS 将会将该进程从等待队列上移出并将其状态变为就绪。 当有消息被写到黑板上时，所有等待在黑板队列上的进程将会从队列上被移出并设置为就绪状态，该消息会被保持在黑板上。当黑板被擦除时，它会变空。 信号量 Semaphore信号量服务提供了计数信号量。 计数信号量是一种同步对象，常用于对分区内资源访问的控制。计数信号量的计数值一般用于反映当前合法资源的数量。 为了使用信号量，必须在初始化阶段中对其进行创建。创建信号量时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 事件 Event事件是一种同步对象，用于通知进程等待条件的出现。同一分区内的进程可以设置和清除事件，还可以在本分区内创建的事件上等待。 分区内创建的事件能够被分区内的所有进程使用。事件创建时，被设置为 down 状态。为了通知事件条件的发生，可以设置指定的事件为 up 状态，所有等待该事件的进程的状态将从等待变为就绪，然后进行重调度。等待事件的进程的执行顺序应该只依赖于分区内进程调度规则。 为了使用事件，必须在初始化阶段中对其进行创建。创建事件时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 时间管理时间管理为分区提供了功能接口来控制周期和非周期进程。 周期进程就是以特定频率执行的进程。类似的，只在特定事件之后执行的进程为非周期进程或事件驱动进程。 对于周期进程，分区内每个进程都可以确定一段执行时间来作为进程周期执行的最大时间长度。这个时间长度可用以设定进程的 Deadline 时间。操作系统会通过周期性地评估 Deadline 时间来判断进程是否在分配的时间内完成了执行。在进程执行周期的最后，应该调用 PERIODIC W 舭 T 服务来获取新的 Deadline。新 Deadline 的计时将从进程的下一个周期开始。 对于所有进程，TIMED—WAIT 服务允许进程挂起自己一段时间。待挂起时间到达以后，进程又可以被重新调度。 函数功能 使进程指定时间等待 使进程周期性等待 获取系统时间 健康监控健康监控用于监视硬件、应用程序和操作系统的状态，当发现故障时，记录故障并进行故障隔离，防止故障的蔓延，同时按故障级别(模块级、分区级和任务级)进行必要的恢复。健康监视的另一个功能是在系统配置时，用于检测系统配置的一致性和完整性。 ARINC 对健康监控处理的错误进行了分级，错误有可能发生在模块级、分区级和进程级。模块级错误仅影响模块内的所有分区。分区级错误仅影响该分区。进程级错误影响分区内的一个或者多个进程，或者是整个分区。如下给出各个级别的错误类型定义。 ●模块级错误： 模块初始化阶段出现模块配置错误； 模块初始化阶段出现其它错误： 系统功能执行期间的错误； 分区转换时发生的错误； 加电故障。 ●分区级错误： 分区初始化阶段出现分区配置错误； 分区初始化错误； 进程管理中的错误； 故障处理过程的错误。 ●进程级错误： 应用进程产生的应用错误； 非法的操作系统请求； 进程执行错误(溢出、存储区冲突…)。 错误的级别是由系统人员在状态监控的配置表中定义的，并且与诊断的错误和系统状态相一致的。任何级别上发生的错误，根据其错误特性，将会扩散到其被处理的更高级别上。 故障响应机制依赖于错误级别。模块级和分区级的故障响应是由一张模块状态监控表和每个分区的单独分区状态监控表驱动的。进程级故障响应由应用程序员使用分区的专门(最高优先级)的进程一一错误处理进程决定。程序员可以通过状态监控服务确定错误和故障进程，然后在进程级(例如，停止，启动进程，replenish)或者分区级(例如，设置分区模式：空闲，冷启动，热启动)采取恢复措施。错误处理进程中发生的错误被视为分区级错误。 函数功能 报告错误消息 创建错误处理进程 激活处理进程 启动分区 分区启动： 分区启动后，操作系统内核会为该分区创建一个初始任务。 初始任务的作用：主要用于初始化 APEX 接口，执行分区配置表中的初始化步骤。 初始任务的参数：例如优先级和任务栈大小，这些参数通常由 APEX 接口的具体实现决定，对于使用 APEX 接口的用户来说，这些参数是透明的，即用户不需要手动设置这些参数。 APEX 配置信息的入口参数的结构。 typedef structvoid* processInfo； /*进程整体配置信息*/void* bufferInfo； /*缓冲区整体配置信息*/void* bbInfo； /*黑板整体配置*/void* semInfo； /*信号量整体配置信息*/void* eventInfo； /*事件整体配置信息*/void* queuingInfo；/*队列端口配置信息*/void* samplingInfo； /*采样端口配置信息*/void* hmInfo； /*分区健康监控配置信息*/)T_APEX_CONFIG_INFO； 初始化 APEX 接口 APEX INIT 调用： 初始任务会以分区配置表为参数，调用 APEX 接口的初始化入口函数 APEX INIT。 系统对象的初始化：APEX 接口根据分区配置表中的各项参数，初始化系统对象。系统对象包括各种系统资源，如队列、缓冲区、信号量等。 创建系统进程：APEX 接口接着会创建一些关键的系统进程，比如初始进程和 IDLE 进程。这些进程对于分区的基本操作和管理至关重要。 初始任务的结束：在完成上述初始化步骤后，初始任务的生命周期就结束了，系统进程开始接管分区的运行。 值得注意的是， APEX 接口的初始化是一个分界线，从此之后创建的任何进程或对象都必须在分区配置表中有对应的配置，否则创建将会失败，IDLE 等系统进程也不例外。而在初始化 APEX 接口之前创建的系统对象的生命周期必须到此结束，不能延续到 APEX 接口初始化之后，以初始任务为例，在 APEX 接口初始化过程就会被终止。以保证 APEX 接口之上应用程序的可移植性不受具体 OS 的影响。 设置分区为 NORMAL 模式 USERMAIN 的调用： 由系统进程之一的初始进程调用用户程序的入口函数 USERMAIN。 分区应用程序的执行：用户可以在 USERMAIN 函数中创建自己的用户进程和其他系统对象（例如信号量、事件、任务等）。 设置分区模式为 NORMAL：在用户程序的初始化步骤完成后，系统将分区的模式设置为 NORMAL。这意味着分区已经准备好并开始执行用户定义的进程。 初始进程的结束：一旦所有用户进程创建完成并开始运行，初始进程的生命周期也结束。 分区间切换 分区切换概述： 分区间切换是指在一个多分区系统中，操作系统从一个分区切换到另一个分区。切换通常是由系统调度器在时间片到期或者根据特定条件触发的。 时间分片：系统通常会以固定的时间片进行分区切换，即每个分区在其时间片内独占 CPU 资源。 切换过程： 时间片到期或切换请求：当分配给当前分区的时间片到期，或者有其他条件触发了分区切换请求，系统调度器将会进行分区切换。 保存当前分区状态：在切换之前，操作系统会保存当前分区的状态，包括寄存器、任务栈和其他重要数据。 加载新分区状态：系统调度器加载下一个分区的状态，并将处理器控制权转移到新分区。 切换完成：新分区开始执行其任务，并在其时间片内独占 CPU 资源。 分区间切换的关键点： 隔离性：确保不同分区的资源和状态相互隔离，以防干扰。 实时性：需要保证分区切换的延迟在可接受的范围内，以满足系统的实时性要求。 分区内进程切换 进程切换概述： 分区内进程切换是指在同一个分区内，从一个进程切换到另一个进程。通常由分区内的调度器管理。 切换过程： 进程调度：分区内的调度器根据调度算法（如优先权调度）决定下一个要执行的进程。 保存当前进程状态：保存当前进程的寄存器值、堆栈指针和其他状态信息。 恢复新进程状态：加载新进程的寄存器值和堆栈指针，恢复新进程的执行上下文。 切换完成：新进程开始执行。 进程间切换的关键点： 优先级：进程调度通常依赖于优先级，确保高优先级的进程能够得到及时处理。 上下文切换：需要有效地管理进程的上下文切换，减少上下文切换的开销，以提高系统性能。 APEX 时间调度（ApexTime Scheduling） APEX 时间调度概述： ApexTime 是 ARINC 653 规范的一部分，用于管理系统中的时间分片和时间资源。它保证了任务在预定的时间段内能够得到执行，满足实时任务的需求。 时间调度的关键功能： 时间分片：系统将时间划分为固定长度的时间片，分配给不同的任务或分区。这确保了每个任务都有公平的执行机会。 时间分区：APEX 接口通过时间分区机制管理任务执行的时间，确保任务在预定的时间内运行，满足实时系统的要求。 定时器管理：APEX 提供了定时器服务，用于管理任务的超时和周期性调度，支持任务在特定时间点或间隔内执行。 时间调度的实现： 调度算法：APEX 接口可能会使用轮转法、优先级调度或其他调度算法来管理任务的时间片和优先级。 系统调用：用户任务可以通过 APEX 提供的系统调用来请求时间服务，例如设置定时器、请求时间片等。 实时保障：通过精确的时间管理和调度算法，APEX 确保了系统能够满足严格的实时性要求。","categories":["4.软件","航电"]},{"title":"ARINC825","path":"/2023/09/07/4-软件-航电-ARINC825/","content":"ARINC825 协议栈ARINC825 规范全称为机载 CAN 网络通用标准（The General Standardization of CAN for Airborne Use）。顾名思义，ARINC825 规范是建立在 CAN 物理网络基础上的高层规范。ARINC825 协议物理层和数据链路层与 CAN 总线基本一致，而在网络层则增加了特殊的路由寻址、数据包封装和流速控制等功能；并在传输层引入了逻辑信道划分与数据包重发等功能。 物理层接口为了确保可靠的通信，ARINC825 的电气特性、总线收发条件、数据率等规定均符合 ISO 11898 标准。规范中还特别强调了每一位的时序计算及电磁兼容性。ARINC825 支持以下数据率：1Mbs、500Kbs、250Kbs、125Kbs 及 83.333Kbs。 定义了三种通信模型 用于广播消息的一对多格式 用于定向节点点对点通信的定向消息传递（使用节点寻址和端口定义） 用于节点服务的点对点格式（用于 CS 类型服务的点对点通信） 概览数据帧一对多格式定向消息点对点周期性健康消息节点服务数据载荷健康消息数据载荷带宽高完整性协议高可用性消息总线拓扑结构通信网络设计报文传输模式和 ID 结构ARINC825 规范对 CAN 2.0B 扩展帧的 29 位标识进行了划分。其中高 3 位被用于逻辑通信通道（Logical Communication Channels, LCC）标识，按优先级从高到低依次为异常事件通道（EEC）、正常工作通道（NOC）、节点服务通道（NSC）、用户自定义通道（UDC）、测试与维护通道（TMC）及 CAN 基本帧兼容通道（FMC）。其中 EEC 和 NOC 通道用于多播（Any-to-Many）通信，NSC 和 TMC 通道用于端到端（Peer-to-Peer）通信。 ARINC825 协议支持 ATM（Anyone to Many）和 PTP（Peer to Peer）两种传输模式，报文一般采用 29 位扩展 ID，并实现了逻辑信道（LLC）的定义与划分，具体如表 4-1 所示。而且，ARINC825 协议的报文结构又按照传输模式不同而有所区别。 ATM 模式ATM 模式是传统的 CAN 总线收发模式，通信节点间为对等关系，采用广播方式发送数据，并按照报文 ID 进行逐位仲裁和屏蔽接收，其报文 ID 域结构如图所示，包括功能标识（Function ID, FID）、区域标识（Local, LCL）、加密标识（Private, PVT）、数据对象代码（Data Object Code, DOC）和冗余标识（Redundancy Channel Identifier, RCI）。 ATM 通信的优势在于能够与网络中所有的节点建立持续的数据链接，但是 ATM 需要处理非自身的数据包，增加了接收节点的工作量。 PTP 模式PTP 模式则扩展了是传统的 CAN 总线收发模式，允许网络中任意两个节点间采用基于客户端服务器（ ClientServer ）的面向连接或无连接两种通信方式，其报文 ID 域结构如图所示，可支持 512 个不同的服务器节点和 128 种不同的服务类型。 Server FID(Function ID) + SID(Server ID) +RCI 部分统称为 NID（Node ID） 高度完整性协议ARINC825 协议针对系统控制器受到干扰时可能产生的错误，在 CAN2.0B 故障检测机制的基础上，加入了高度完整性协议（High Integrity Protocol）。如图 4-4 所示，该协议以减少数据载荷为代价，引入 MIC 校验码与 SN 号，对报文正确性及完整性进行验证。 数据域消息格式，共包含 8bytes，前 5bytes 为有效数据载荷，第 6byte 为 SN 码，即消息序列号，第 7-8bytes 为 MIC，及数据完整性校验结果 高完整性校验范围，共包含 12bytes，即 29bits 的帧 ID，3bits 的补充位，8bytes 的数据域 处理时，先设置每个节点独立的消息序列号 按照高完整性校验范围，依次逐字节进行高完整性校验运算，得到 16bits 的 CRC 码作为数据完整性校验结果 带宽管理传统的 CAN 总线协议是基于多主竞争下的位仲裁机制来管理总线的访问权和带宽，优先级较高的数据帧可以连续不受制约地访问总线，在总线载荷繁重时会造成低优先级数据帧较大的不确定延时。 ARINC825 引入时间触发总线调度技术，时间触发总线调度控制基于两个概念，Major Frame（主时间帧）和 Minor Frame（基本时间帧）。整个网络的数据传输周期（在一个周期内，每个数据包至少能得到一次传输机会）称为一个 主时间帧，它包含若干个基本时间帧 。Minor Frame 是总线中传输频率最 大的帧的周期，是 ARINC825 规范中进行带宽管理的最小时间单位。 同一时间帧内的数据帧采用多主竞争发送，只要控制总线中各个节点在基本时间帧内的发送，就可以保证总线节点间通信的确定性。 计算总线负载时，需要选取一个时间片段进行分析，使用时间间隔最小的基本时间帧作为发送间隔（Transmission Interval），可以计算出最大的总线负载。 ARINC 825 网络节点设计分为处理端，控制端和收发端 处理端接收由传感器等设备采集到并发送过来的消息，并将接收到的消息进行处理，处理后的消息满足 CAN 和 ARINC825 网络的确定性和完整性要求 时间片管理模块 规划时间片通信调度机制：所有节点具有相同的主时间片和次时间片，主时间片包括若干次时间片和空闲时间窗(也称为仲裁窗)，每个次时间片的时间长度不小于系统内所有的节点依次进行总线竞争的时间，主时间片是当前系统周期消息的最大周期发送时间，即周期消息刷新时间，且次时间片是主时间片的偶分数。 消息接收和处理模块 通过给定的时间片，接收传感器等设备的消息并进行格式化处理 通过给定的时间片，接收控制端返回的消息并进行格式化处理 消息完整性校验模块 进行高度完整性校验，步骤见 高度完整性协议 片外 SDRAM 控制模块 存储格式化处理后的消息和完整性校验的校验结果，按照格式化的消息，独立的帧 ID，完整性校验的校验结果进行分别存储 串口通信模块 将处理完成的消息发送给控制端 控制端控制端通过热冗余进行数据的收发，以满足 ARINC825 的可用性要求 双链路冗余模式，每个节点第一主节点的消息均发送到同一个 ARINC825_A 总线中，第二主节点的消息均发送到同一个 ARINC825_B 总线中 系统中存在两条独立的通信链路，用于传输相同的数据或执行相同的任务。这两条链路同时工作，当其中一条链路出现故障时，另一条链路可以继续传输数据或执行任务，从而保证系统的正常运行。 双链路节点混合冗余模式，每个节点第一主节点的消息混合发送到两路 ARINC825 总线中 ，若干节点的第一主节点的消息交替发送至 ARINC825_A 和 ARINC825_B 总线中，同时节点中的第二主节点的消息发送至另一路 ARINC825 总线中。 系统中不仅存在两条独立的通信链路，而且每个链路中的节点也可能存在冗余配置 冗余是指重复配置系统的一些部件，当系统发生故障时，冗余配置的部件介入并承担故障部件的工作，由此减少系统的故障时间。热备是一种备份方式，即系统中存在一个主设备处于运行状态，同时有一个备份设备也处于通电运行状态（但可能未承担主要工作任务），随时准备在主设备出现故障时立即接管工作。 收发端直接和总线进行交互 网关处理同步网关发送参考消息，总线上各节点接收到参考消息后，时间基准归零。保证总线上所有节点具有相同的主时间片和基本时间片，主时间片包含若干基本时间片和空闲时间窗口。基本时间片的时间长度不小于系统内所有节点同时进行总线竞争所需的总时间。基本事件片分为同步相和异步相，同步相用于传输周期性消息，异步相用于传输非周期性消息竞争，空闲时间窗口用于传输非周期性消息。 在 ARINC 825 规范中，主次时间帧的同步通常由 CAN 网络中的网关或中央控制节点发出同步信号，以确保所有节点的时间帧保持一致。然而，除了由网关发起的同步信号外，还有其他几种方式可以实现主次时间帧的同步或协调，具体如下： 分布式时钟同步 一种方式是通过分布式时钟同步机制，让各个节点根据共同的参考时钟（如 GPS、PTP）来协调其本地时钟。每个节点可以定期接收时钟校准信号，从而调整其主次时间帧，使其与网络中的其他节点保持一致。这个方法适用于大规模系统，特别是在需要精准同步的应用中。 事件驱动同步 另一种方法是通过特定事件或消息的触发来实现同步。比如，当某一特定节点发送一个关键消息时，其他节点可以根据这个事件作为触发信号来调整自身的主次时间帧。这种方式可以适应系统中具有异步特性的操作场景。 静态调度表 在某些系统中，可以使用静态调度表来提前规划好所有节点的时间帧。每个节点在设计时就被赋予了固定的时间周期，用于发送或接收数据。这种方法通常用于具有固定通信模式的实时系统。所有节点根据预定义的调度表来操作，而不依赖动态的同步信号。 分层架构同步 在复杂的系统中，可能会使用分层架构来实现时间同步。一个高级别的控制节点可以管理主时间帧的同步，而次时间帧可以由各个子网络或次节点自己管理。这种架构可以减少中央节点的同步负担，提供一定的灵活性。 自主同步的节点 在某些情况下，系统中的每个节点可以自主管理自己的主次时间帧，而无需依赖中央同步。每个节点可以根据自己内部的调度机制来划分主次时间帧，只要确保与其他节点的通信在规定的窗口内进行即可。这种方式适合一些分布式系统，节点间的时间不需要严格同步，而只需要在某些时刻进行协调。 多网关同步 当网络规模较大或具有不同功能区块时，可能会使用多个网关或中央控制单元。这些网关分别负责自己区域的同步任务，而通过跨网关的通信来确保整个网络的主次时间帧协调。这种方式可以增加系统的可靠性和扩展性。 自主主次时间帧的实现理论上，可以让各个节点自主使用自己的主次时间帧，但这取决于应用场景的具体需求。在一些情况下，这种分布式时间管理可以简化系统设计，但会增加节点之间的协调难度，尤其是在高实时性要求的系统中。如果各个节点的主次时间帧不严格同步，可能会导致数据传输延迟、不一致或数据丢失的问题。因此，节点自主时间帧的应用需要谨慎考虑网络拓扑结构、消息优先级和通信窗口的合理分配。","categories":["4.软件","航电"]},{"title":"IMA系统开发方法的研究","path":"/2023/09/06/4-软件-航电-IMA系统开发方法的研究/","content":"随着 IMA 架构的推广应用，IMA 架构已成为大型民用飞机系统的典型架构，而 IMA 系统的开发涉及到与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方利益相关者提出的约束。 本文主要从两个方面探讨 IMA 系统的开发方法:一是与飞机制造商的交互，通过飞机级任务的运行场景捕获功能系统的需求，协商 IMA 可驻留的飞机系统，确定 IMA 系统的功能、性能需求;二是技术、环境、利益相关者等多方提出的约束，包括成熟技术复用、适航要求、维修性要求、装机环境要求、时间和成本、人为因素、公司战略等方面的约束要求。 IMA 系统开发方法的研究旨在帮助开发人员深入了解这些利益相关者对 IMA 的影响，为 IMA 系统设计实践提供参考。 随着飞机对航电系统需求的不断增长,机载系统的功能和性能要求不断提高,现代航空电子系统越来 越呈现复杂系统特征,联合式架构已远不能满足航电系统的发展要求。为解决上述问题,20 世纪 90 年代国外开始了综合模块化航空电子系统的研究工作,并很快取得技术突破;而微电子技术和集成电路的迅速发展,强大的微处理器技术、集成电路集成度的不断增长和成本降低,大大促进了综合模块化航空电子(Integrated Modular Avionics,IMA)架构的推广应用,IMA 架构成为大型民用飞机系统的典型架构。 目前 IMA 技术的发展日趋成熟,开放式 IMA 系统架构能够满足大型客机对航空电子系统高灵活性、高可靠性以及便于升级换代的要求,综合化航电系统得到了广泛关注,并逐步成为民用客机航空电子系统发展的主流趋势。典型代表包括美国波音公司 B787 飞机、欧洲空客公司的 A380 飞机和 A350 飞机等先进干线飞机。国的大型客机 C919 也采用 IMA 系统架构。 IMA 系统简介 DO-297 中对 IMA 的定义是:”IMA 是一组灵活的、可重用的、可互操作的共享硬件和软件资源,当把这些资源综合在一起时可以构建一个平台,该平台按一组确定的安全和性能需求进行设计和验证,能提 供各种服务,并驻留执行飞机功能的应用”。 由此可见,IMA 系统由 IMA 平台以及一组驻留应用组成,其中 IMA 平台通常包含 1 个或多个模块组件,驻留应用通常也包含 1 个或多个组件。 联合式架构下,每个航电功能都有各自特定的独享的计算资源(处理器、数据通信和接口),这些计算资源驻留在各自独立的现场可更换单元(Line Replaceable Unit,LRU)中。 IMA 系统架构为高度集成的实时系统提供所必需的核心资源框架,提供公共硬件计算模块的集中计算资源,为航电系统的通用处理功能构建了一个独立的通用处理平台,提供公共硬件计算模块的集中计算资源。 IMA 架构为多个飞机功能的驻留提供了公共计算资源,取代了联合式架构中航电功能面向任务的专用计算机。以前联合式航空电子应用软件嵌入在面向任务的专用计算机中,现在则驻留在 IMA 系统的公共核心计算资源上,提高了系统资源的利用率和可用性。 IMA 平台属复杂机载设备,为飞机功能提供支持通用功能的公共平台,如计算功能、网络传输功能、数据转换功能;而且,IMA 平台与机上多个驻留应用软件、机载设备组件(如传感器、控制器、显示器、作动器等)进行交互,并为驻留应用软件提供支持其运行的执行环境,包括硬件资源和平台基础服务。虽然 IMA 平台可以驻留多个飞机功能,但是 IMA 平台本身并不具备专用的飞机功能。因此,开发 IMA 平台可独立于专用飞机功能和驻留应用进行定义与开发。 IMA 系统开发方法 由于 IMA 系统驻留多个飞机功能,因此 IMA 系统的综合化程度、系统内和系统间的相互关系的复杂度相对于单一功能实现方式的联合式架构均有了很大的提升,联合式架构的开发方法很难适用于 IMA 架构的开发。 IMA 系统的开发涉及与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方 利益相关者提出的约束。 其主要可划分为两个方面: 一是与飞机制造商的交互,IMA 系统供应商可捕获飞机级任务的运行场景和飞机功能需求,并参与飞机系统联合设计即飞机功能的划分和分配、迭代,协商可驻留在 IMA 平台上的飞机功能,确定 IMA 系统的功能、性能需求; 二是技术、环境、利益相关者等多方提出的约束,包括 IMA 成熟技术复用、适航条款、维修性要求、装机环境要求、人为因素、公司战略等方面的约束要求。这两个方面与 IMA 系 统 开发的关系如图所示。 图中,垂直方向代表自顶向下分解的功能性能维度,水平方向代表 IMA 系统开发的约束集(图 1 黑斜线外侧的区域),这两个维度的交集(黑斜线内侧的区域)是可接受的方案设计。显而易见,功能性能需求和开发约束集这两个方面决定了 IMA 系统的解决方案,IMA 系统开发不但要考虑飞机级自顶向下分解出 IMA 系统的功能性能需求,还要考虑这些约束集对方案设计的”限制”,才能交付出满足装机要求的 IMA 系统。 一、功能性能需求 随着飞机任务复杂度的提升,飞机功能和系统功能之间并不是简单的一对一的分配关系,一个飞机级功能可能由多个系统完成,一个系统也可能完成多个飞机级功能。飞机级功能分配的过程也是确定飞机级系统架构的过程,需要对多种因素进行设计权衡。飞机级功能分配首先应确定初步飞机级系统架构,然后 根据初步飞机级系统架构将飞机级功能分配到相关系统,经过多次迭代安全性评估结果以及与系统供应商的协商结果,确定最终的飞机级系统架构及分配给特定系统的功能。 飞机功能分配阶段,飞机制造商自顶向下分解来自飞机系统的功能,确定驻留在 IMA 平台上的飞机功能,形成 IMA 系统的顶层需求。IMA 系统开发商应积极联系飞机制造商、参与飞机系统设计过程即联合设计阶段,向飞机制造商提供来自 IMA 的技术支持(包括 IMA 架构、模块设计、硬件设计、软件设计、安全性评估、平台资源、运行效率等),以实现航空电子系统逻辑架构到 IMA 公共处理资源的映射,通过双方协商联合设计 IMA 系统初步架构确保满足飞机级系统架构的要求。 同时,联合设计还有助于 IMA 系统开发商更好地了解飞机级顶层需求、确定 IMA 系统需求并向下分解、制定公司战略、将系统级需求作为开发下一代可认证 IMA 平台的输入等工作,为 IMA 系统开发奠定了基础。 IMA 平台为多个飞机功能提供公共计算资源以及通用接口资源,支持同时驻留多个飞机功能,其开发涉及多个机载系统的参与。基于 IMA 架构的飞机级功能分配过程中,飞机系统被划分为计算处理功能和系统专用功能两部分,其中飞机系统的计算处理功能可被分配到 IMA 系统中实现,系统专用功能则必须保留由具有特殊接口的专用设备完成; 由于 IMA 系统主要提供公共计算资源以及通用接口资源,不能满足所有驻留功能的需求,对于一些需要特殊资源的系统功能, 需要 IMA 系统和系统专用设备共同实现。此外,基于 IMA 架构下除完成联合式架构下飞机级功能分配工作外,还需要通过对安全性、平台资源、运行效率等多种因素进行权衡,确 定可驻留在 IMA 平台中的系统功能。 飞机功能分配到 IMA 系统后,需要再多次逐级向下进行功能分解,一直分解到软硬件可进行设计实现的程度。功能性能的需求在层与层之间的追踪关系必须严格得到保证,即设计过程中任何层级的描述和考虑始终对最顶层———任务层负责,这样才能确保最终的设计实现与飞机任务需求。 二、约束集 IMA 系统开发不但要考虑飞机级自顶向下分解出 IMA 系统的功能性能需求,还要考虑这些约束集对方案设计的”限制”。”约束”经常以需求的形式出现,例如认证需求,同样,来自于顶层飞机级任务的功能性能需求将逐级分解到底层———实现层,以驱动底层需求生成某种形式的解决方案。对于 IMA 开发商,识别飞机级任务的需求与约束之间的差异性非常重要,在 多方协商以及解决方案的”权衡”中起到至关重要的作用。 1、适航认证需求 适航认证需求源自飞机级的定义,是飞机制造商与适航认证的局方达成一致的结果,中国民用航空局 发布的适航规章(或者美国联邦航空管理局或欧洲航空安全局使用。例 如,中国民 用航空规章第 25 部适用于航空运输类飞机的适航认证。国内民用飞机以 CCAR 25 部为审定基础,但考虑到型号后续发展以取得 FAA 和 EASA 颁发的型号合格证的需要,因此在设计过程中往往会同时考虑 FAA 颁发的适航规章 14CFR 25 和 EASA 颁发的适航认证规范 CS 25 的要求。 下面以 CCAR 25 条款为例说明适航认证需求到飞机系统和航电系统的分解。条款 §25.1301 规定, “(a)所安装的每项设备必须符合下列要求:(1)其种类和设计与预定功能相适应。”其中设备的设计与安装符合”预定功能”是指在飞机的运行和环境条件下,设 备功能正常。在研制过程中设备的功能及性能指标通常在设备规范中明确,作为后续研制的依据。此需求是通过符合技术标准规定来满足的,而 TSO 又会调用一系列行业标准,例如美国航空无线电技术委员会 发布的相关最低操作性能标准,这些需求都需要与认证机构进行讨论并达成一致。 此外,功能性能需求和适航需求生成的约束均对系统子系统的可靠性需求产生影响。通常,飞机任务成功率的目标是电子设备可靠性要求的关键驱动因素。但是,适航规章的安全性段落也包括可靠性需求。例如,适航规章 CCAR 25 中安全性相关条款§25.1309 以相应可接受的符合性方法 AC 25.13091A 描述安全性需求及其与可靠性需求之间的关系。飞机安全性相关的失效状况影响与可靠性之间的关系如表 1 所列。 表 1 功能危害性影响分类 由于飞机功能的失效可能会对飞机性能产生不利影响,所以必须评估飞机功能的失效影响。如果失效影响涉及到机组人员和或乘客,那么相关飞机功能的失效概率必须是远不可能发生的。例如:如果某飞机功能失效对飞机乘员的影响包括对少数乘客或机组人员造成严重的致命的伤害,那么该飞机功能的失效概率不能高于 1×10-7飞行小时。由此可见,飞机级的安全性要求被转换成功能子功能级的可靠性需求。 在功能层及以下层级不存在”安全性”需求,只有可靠性需求;这些可靠性需求将伴随着功能一起逐级向下分解,以确保满足顶层功能级的初始可靠性需求。因此,系统子系统的可靠性指标必须同时满足顶层任务分解的可靠性需求和来自适航安全性的可靠性需求。 2、运营需求 飞机运营必须考虑要求强制执行的功能和性能需求。如欧洲颁发规章作为”委任规章 No.9652012”,根据欧洲议会和理事会的 No.2162008 规定,制定航空运营相关的技术需求和行政程序。飞机运营要求由局方发布规章制定航空运营相关的技术需求和行政程 序,这些规章包括对运营组织方的不同类型的需求。对于飞机功能,为了进行特定类别的操作飞机必须装备机载电子设备,如”商用航空运输”。 常见的相关飞机功能包括,高度告警系统、地形识别及告警系统、防碰撞系统、天气探测设备、飞行机组对讲系统、座舱语音及飞行数据记录仪、最小无线电导航与通信功能等。这些功能来自飞机运营的需求,而不是适航;而且,这些设备的装机必须满足适航认证的要求,即满足安全性、可靠性的要求。 3、行业标准和推荐实践 所有航电设备和相关功能的分配和实现都应与行业标准、规定保持一致,分别规定并逐项详细说明,以获取认可和航空可批准的性能(即适航性),行业互换性符合航空实践(即考虑人为因素,材料,表面处理,制造工艺)以及与通用航空领域规定保持一致。常用行业标准和推荐实践包括: (1) RTCA,美国航空无线电技术委员会,协调 MOPS 和最低航空系统性能标准并达成共识。符合 MOPS 和 MASPS 的标准通常由 TSO 提出,因此 TSO 是设备获得 FAA 认可、装机使用资格的基础。 （2）EUROCAE ,欧洲民航设备组织,是欧洲相当于 RTCA 的机构,负责制定欧洲的航空标准。EUROCAE 标准是设备获得 EASA 认可、装机使用资格的基础。 （3）SAE ,汽车工程学会,负责航空电子相关功能和性能领域的航空航天标准和航空航天推荐实践的编写和汇总,如飞行操纵和飞行控制、飞行座舱显示和信号、维护实践、应用人为因素。 （4）ARINC，航空无线电公司,由航空公司电子工程委员会组成,根据电子设备特性制定类型、尺寸和功能约定,是设备之间独 立于系统制造商实现互换性所必需的。该特性定义了设备的功能性能、系统间和控制显示接口的连接器引脚层等规定。 4、时间和成本目标 与航电功能相关的时间和成本目标必须在飞机级 的设计和开发过程中被识别,并向下分解到系统级作为系统供应商的成本目标或预算,IMA 系统开发需关注开发周期、开发成本、飞行和维护机组的培训费用、维护成本等因素。 5、企业标准 企业标准可能需要在开发过程中进行特定的考 虑,如首选工具、首选开发功能、特殊开发软件的使用、特定的命名、归档、记录规定等。这些标准可能会偏离 或增加以其他方式或从行业通用实践中获得的标准, 由其他项目应用或因成本的考虑等因素产生的标准。 6、最低性能要求(MPS) 航电设备包研发过程中的一个关键参数是各功能 的性能要求。性能要求将适用于每个航电设备功能, 因此每个航电设备功能必须毫无例外地派生出所需的 性能 指 标 值,MPS 源 于认证和操作批准需求,例 如 IMA 模块 MPS 来自 TSO 153。 7、复用需求 复用需求与公司战略和公司标准密切相关。根据 公司制定的商业计划和技术发展战略,航空电子设备研发项目可能是公司已经参与或者希望在未来参与的多个类似项目之一。在这种情况下,可应用到多个项目的技术复用会为公司节约开发成本,提高利润。 反过来说,技术复用也可能会在设计方面规定约束,包括文档、功能分区、系统性能、系统成本,甚至系统功能。当前项目可能只需要这些功能的一个子集,但是将来的技术重用的需求可能会更为广泛。 而且,复用需求可能会迫使公司使用专用的项目管理和财务功能,由于公司项目管理和财务工作只能 在当前项目上收取部分费用,其余工作的收费将在复用项目中产生。 8、环境 目标飞机为航电设备提供装机环境,航电功能必须在机上运行性能必需的等级。环境特性包括:温度、高度(气压)、空气质量和湿度、振动和冲击、气压梯度(爆炸)、电磁特性和对射频信号的敏感性、闪电效应的敏感性等。实际的飞机环境为每种试验”类型”给出一组特定的值和参数,因此必须从标准 RTCA DO 160 中选出适用环境特性的相关章节。 环境适应性设计是航电设备研发工作中非常重要和相当严苛的一个方面,因为设备装机环境需求方面 出现错误将会导致已完成研发的设备无法应用到预期的装机环境中,而设计更改到位后,代价高昂的试验和评估功能的工作可能必须重新开展。 例如,IMA 系统开发者对装机环境要求的理解出错,温度范围未完全覆盖,那么元器件的选型就会出错,设备的散热加热设计、结构设计可能不满足散热要求。 9、重量 飞机制造商在飞机初步设计中确定了飞机的总体重量,以及分配给各系统和航电设备包的重量”预算”,并向下分解到各子功能。IMA 架构下,因为 IMA 硬件可能是整个系统架构中的通用公共计算资源,而 IMA 平台的重量可能与驻留应用的数量不存在线性关系, 因此重量设计具有一定的优势,而”正确的”初步系统架构定义则变得非常重要。 从飞机设计的视角来看,超过或低于重量预算都可能是不利于飞机设计的,因此设备重量设计出现偏 差应该及时与飞机制造商进行协商。 10、功耗 与重量预算类似,飞机制造商在飞机初步设计中将功耗预算分配给系统和航电设备包,这些将作为整体飞机功耗组成的一部分。 功耗不超出预算非常重要,因此在航电系统设计阶段初期,分配给各系统的功耗预算必须被尽可能精确地分配,以便飞机功能初步验证架构设计的可行性。在 IMA 架构下,面向软件的飞机应用与硬件需求不存在线性关系,这是 IMA 架构的优点,但它以更复杂的设计迭代和系统复杂性为代价。 11、散热 散热预算与功耗预算相辅相成。散热需要设计机械接口,根据设备装机运行环境的温度和湿度,与航电系统设计工作进行协调,选择正确散热方式(如自然散热、强迫风冷散热、传导散热、液体冷却等)是至关重要的。 散热在很大程度上影响了航电设备的平均故障间隔时间(MTBF),而航电设备硬件的内部热分布需要根据实际硬件设计进行专用的特殊的热设计,通过在设备内部设计专用的热传递路径,包括热布局、散热方式、散热介质、热传输路径、风道、液冷通道等,以便将设备内部的热量传导到散热区。 任何散热需求都可能规定后续具体的要求,例如大气洁净度、大气温度、压力和湿度;而且考虑到飞机 服役寿命和设备将来潜在的功能升级或设计更改,可能会提出更高的散热需求。 12、维护和修理需求 维护和修理需求是考虑从机场外场维护到车间维修等各种维修场景、不同维护级别的维护、修理需求。 IMA 系统开发示例 由于 IMA 系统驻留多个飞机功能,因此 IMA 系统的综合化程度、系统内和系统间的相互关系的复杂度相对于单一功能实现方式的联合式架构均有了很大的提升,IMA 系统开发除了完成传统的飞机级功能分配外,还需要通过安全性、平台资源、运行效率等多种因素权衡确定哪些系统驻留在 IMA 平台中以及 IMA 系统与驻留 ATA 系统的关系等。 为了便于理解本文介绍的 IMA 系统开发方法,本外场维护需要设备具有一定的故障报告和诊断的能力,既有与飞机操作人员的数据链路,也有与飞行机组人员到达后的沟通交流,以便航线维护人员在规定的时间内做出响应。 因此,飞机航线维护规定内部航电设备失效状态和飞机级安装问题(如线缆、连接器、系统内部通信故 障)并汇总形成通用语言的故障报告,既可以通过维护电脑的诊断功能输出,也可以通过与飞行机组人机 接口输出,用于航线维护人员成功响应故障并保持低概率无故障发现 (NFF)状况。 一旦设备从飞机上拆除,假定设备具备良好的故节以起落架系统、座舱显示系统、飞行管理系统和机上维护系统到 IMA 系统的驻留为例,通过飞机系统功能 IMA 平台通用资源的分配以及对约束的权衡来进一步说明 IMA 系统开发方法。LGS 由起落架收放系统、刹车控制系统、车轮转向控制系统、起 落 架 监 控 系 统四个功能子系统以及三个独立的起落架组成。 LGERS 负责起落架的控制以及监控功能,由 LG-ERS 命令通道和自检测通道组成;BCS 负责飞机刹车控制以及监控功能,由 BCS 命令通道、监控通道和自检测通道组成;WSCS 负责起落架前轮转向控制液压伺服阀的控制和监控功能,由 WSCS 命令通道和监控通道组成;LGMS 负责刹车温度监控与指示、胎压检测与指示、刹车散热风扇的控制功能,由 LGMS 控制功能和自检测功能组成;以上各子系统命令通道的开发保证等级(DAL)均为 A 级,监控通道的开发保证等级均为 B 级,且必须考虑命令通道与监控通道的隔离性。其中 IMA 平台通用处理资源可以满足 LGS 各应用软件的处理需求,四个功能子系统可以驻留在 IMA 平台上;但是起落架需要特殊的飞机接口来实现,因此不能驻留在 IMA 平台上。 CDS 由 6 个显示单元和 2 个键盘控制单元组成 CDS 软件驻留在每个显示单元上,IMA 平台仅提供通用数据传输和接口的驻留。 FMS 包括飞行计划、飞行优化与预测、导航和飞行指引四部分功能,均由应用软件实现。因此,FMS 的应用软件均驻留在 IMA 系统中,飞行管理功能由 IMA 系统实现。 OMS 包括数据加载与配置管理、中央维护系统、飞机状况监控系统三部分功能。IMA 平台的硬件资源可以满足这三部分的功能需求,因此 OMS 所有功能都驻留在 IMA 平台上。 初步飞机级功能到 IMA 的分配示意如图 2 所示。 图 2 IMA 系统中飞机级功能分配示意图 从图 2 可以看出,FMS、OMS 这两个系统均由软件实现,因此均驻留在 IMA 系统上,与 IMA 系统一起实现系统功能;LGS 的应用软件部分均驻留在 IMA 系统上,与各自系统的专用设备一起实现系统功能;CDS 的通信功能和接口数据转换功能驻留在 IMA 系统上, 与 CDS 系统的专用设备、显示器与键盘控制单元,一起实现显示系统的功能。 飞机级功能分配阶段,IMA 平台供应商首先需要考虑使用能够满足各系统应用软件驻留的要求,其次 要初步评估平台性能以确保满足各系统驻留应用的运行需求,还需要详细考虑 2.2 节描述的各项约束,逐步实现 IMA 系统的开发,例如: **(1)适航认证约束:**识别适航认证需求,即必须满足的适航规章,如大型运输类飞机以 CCAR 25 部为审定基础。 **(2)适航符合性约束:**确定 IMA 系统适航方法,如采用 DO 297 作为 IMA 系统开发和认证的可接受的符合性方法,IMA 系统通过增量式认可方法获得安装批准。 **(3)安全性约束:**如驻留应用 DAL A 级的安全性要求、命令通道与监控通道的隔离性要求等。 **(4)供电约束:**余度供电的隔离性要求以及应急供电的要求等。 **(5)环境约束:**根据 LGS 的需求,确定 IMA 平台,尤其关注执行 LGS 接口数据转换功能的远程接口单元的安装环境、安装方式、功耗及散热条件等。 **(6)MPS:**TSO 是局方颁布的民用航空器上所用的特定零部件的最低性能标准。IMA 系统相关的 TSO 分为两大类: ① TSO-153,适用于 IMA(硬件)模块单元。覆盖到 IMA 系统用到的两类硬件组件——通用硬件模块和驻留这些硬件模块的机柜。 ② 功能 TSOs,适用于飞机功能单元。 (7) 复用: 考虑到开发周期、认证成本、研制风险等因素,IMA 系统开发首选采纳成熟技术的复用,包括驻留系统以及 IMA 平台技术的复用。 (8) 维修保障性约束: 确定平均修复性时间、维修间隔等。 通过考虑这些约束集对 IMA 系统方案设计的”限制”,系统设计人员将来自于顶层飞机级任务的功能性能需求逐级分解到底层实现层,最终以驱动底层需求生成具体的解决方案。 以驻留在 IMA 系统的飞行管理系统为例,其飞机功能分配到 IMA 系统的功能性能需求层次结构如图 3 深色图框所示。最顶层的任务描述与最底层的设计实现从不同的角度描述了同一个飞机功能,”最顶层”是从飞机级任务的角度抽象地描述整个飞机的预期操作;”最底层”的设计实现层则是从软硬件设计实现的角度,描述飞机级任务的最终实现。”设计实现层”描述的是具体的设计”需求”,可以逐级向上追溯到最顶层的”任务”描述,即最底层的需求是从最顶层的任务分解而捕获到的。 图 3 功能性能需求层次结构示意图 由图 3 可以看出,设计实现层的软件和硬件模块组成了飞行指引功能,逐级向上看,飞行指引功能是飞行管理功能的组成部分,飞行管理功能是航电系统的组成部分,航电系统是飞机系统的组成部分。一般情况下,从飞机层到最终的设计实现层之间会包括 7~10 层级(某些复杂系统可能会超过 10 层),相邻层与层之间的功能性能需求存在一一对应的关系,需求自顶向下逐层分解,而底层设计实现逐层向上集成,最终支持顶层飞机级任务功能的实现。 结 论 无论是基于传统的联合式架构还是复杂可复用的 IMA 架构的航电设备研发,都与飞机整体定义密切相关,都需要满足飞机的功能性能要求以及各种”限制因素”。本文通过研究 IMA 系统开发中与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方利益相关者提出的约束,帮助开发人员深入了解这些利益相关者对 IMA 的影响,为 IMA 系统开发提供参考。 （以上文章来源于作者：韩嫚莉，高杨，高瑞坤，作者单位：中国航空工业集团 西安航空计算技术研究所）","tags":["clippings"],"categories":["4.软件","航电"]},{"title":"术语缩写ABBR","path":"/2023/09/05/4-软件-航电-术语缩写ABBR/","content":"类别 术语 全称 关键功能 导航系统 VOR VHF Omnidirectional Range 提供磁方位引导 DME Distance Measuring Equipment 测量飞机到地面台的斜距 着陆系统 LOC Localizer 水平校准跑道中心线，ILS 组成部分 GS Glide Slope 垂直校准下滑角度，ILS 组成部分 通信系统 HF High Frequency 远距离语音数据通信（3-30 MHz） VHF Very High Frequency 视距内空中交通管制通信（118-136 MHz） 惯性导航 AHRS Attitude and Heading Reference System 提供飞机的姿态（俯仰、滚转、航向）信息 ADAHRS Air Data and Attitude Heading Reference System AHRS + 空速数据，增强导航能力 AHRRATE Attitude and Heading Reference System Rate AHRS 测量的角速率数据 ADCRATE Air Data Computer Rate 空速数据计算机更新频率 空速测量 IAS Indicated Airspeed 直接读取的指示空速，受仪表误差影响 CAS Calibrated Airspeed 校正仪表误差后的真实空速 EAS Equivalent Airspeed 考虑空气密度影响的当量空速 TAS True Airspeed 飞机相对于空气的真实速度 GS Ground Speed 飞机相对于地面的速度 1. 导航系统（Navigation Systems）VOR（VHF Omnidirectional Range，甚高频全向信标） 含义：一种短程无线电导航系统，通过地面台发射全向信号，帮助飞机确定相对于地面台的磁方位角。 功能：提供方位引导，用于航路导航和进近程序，覆盖范围约 200 海里。 频段：VHF 频段（108.00–117.95 MHz）。 DME（Distance Measuring Equipment，测距仪） 含义：通过询问-应答机制测量飞机与地面台之间的斜距。 功能：提供精确的距离信息（单位：海里），常与 VOR 或 ILS 共址，用于航路导航和进近阶段。 频段：UHF 频段（962–1213 MHz）。 2. 着陆系统（Landing Systems）LOC（Localizer，航向信标） 含义：仪表着陆系统（ILS）的水平引导组件，指示飞机与跑道中心线的左右偏差。 功能：在进近阶段提供横向引导，确保飞机对准跑道中轴线。 频段：VHF 频段（108.10–111.95 MHz）。 GS（Glide Slope，下滑信标） 含义：ILS 的垂直引导组件，指示飞机是否偏离标准下滑道（通常为 3°）。 功能：提供垂直角度校准，确保飞机以安全高度降落。 频段：UHF 频段（329.15–335 MHz）。 3. 通信系统（Communication Systems）HF（High Frequency，高频通信） 含义：利用电离层反射实现远距离通信的无线电系统。 功能：适用于跨洋或极地等超视距场景，支持语音和数据传输。 频段：HF 频段（3–30 MHz）。 VHF（Very High Frequency，甚高频通信） 含义：基于视距传播的短程通信系统。 功能：用于机场塔台、航路管制及飞机间通信，覆盖范围约 200 海里。 频段：VHF 频段（118–136 MHz）。 4. 惯性导航与姿态测量系统（Inertial Navigation and Attitude Reference Systems）AHRS（Attitude and Heading Reference System，姿态和航向参考系统） 作用：AHRS 采用陀螺仪、加速度计和磁力计测量飞机的姿态和航向，提供滚转角、俯仰角和航向角信息。 功能：比传统机械式陀螺仪更精准，广泛用于航空电子系统，为飞行控制、自动驾驶仪和导航系统提供姿态参考。 ADAHRS（Air Data and Attitude Heading Reference System，空速数据和姿态航向参考系统） 作用：ADAHRS 是 AHRS 的增强版，集成了空速数据测量功能，包括静压、动压、温度和 GPS 数据。 功能：提供冗余的姿态信息，并结合空速数据优化飞行控制和导航精度，广泛用于商用航空、军用航空和无人机。 AHRRATE（Attitude and Heading Reference System Rate，姿态和航向参考系统角速率） 作用：AHRRATE 表示 AHRS 测量的角速率（滚转角速率、俯仰角速率、偏航角速率）。 功能：用于计算飞机的姿态角，提供给飞行控制系统，帮助检测飞机的旋转运动，防止失速。 ADCRATE（Air Data Computer Rate，空速数据计算机更新率） 作用：ADCRATE 指空速数据计算机（ADC）更新静压、动压和温度数据的频率，单位为 Hz（赫兹）。 功能：较高的 ADCRATE 提供更平滑和实时的空速数据，提高飞行控制系统的响应速度。 5. 空速测量（Airspeed Measurement）IAS（Indicated Airspeed，指示空速） 作用：IAS 是飞机空速表直接读取的速度值，不考虑任何误差修正。 功能：用于基本飞行操控，但会受到安装误差和气流影响。 CAS（Calibrated Airspeed，校正空速） 作用：CAS 是对 IAS 进行校正后的空速，修正了仪表误差和安装误差。 功能：提供比 IAS 更准确的空速数据，适用于空速限制计算。 EAS（Equivalent Airspeed，当量空速） 作用：EAS 是在标准海平面条件下，具有与当前高度相同动压的空速。 功能：考虑了空气密度影响，用于高速、高空飞行的性能计算。 TAS（True Airspeed，真空速） 作用：TAS 是飞机相对于周围空气的真实飞行速度，考虑了空气密度变化。 功能：用于飞行计划和性能计算，通常在飞行计算器或 FMS（飞行管理系统）中获取。 GS（Ground Speed，地速） 作用：GS 是飞机相对于地面的飞行速度，由 TAS 结合风速计算得出。 功能：用于航行和航路规划，在无风情况下 GS 等于 TAS。 VOR 和 ILS 的数据是否由 NAV 接收？是的，VOR（甚高频全向信标） 和 ILS（仪表着陆系统） 的信号通常都是由 NAV 接收机（VHF NAV Receiver）接收的。 1. NAV 接收机的作用NAV（Navigation）接收机 负责接收和解码 VHF 频段（108.00 – 117.95 MHz）中的导航信号，并将信息传输给航电系统，如主飞行显示器（PFD） 或 自动驾驶仪（AP）。 NAV 设备主要接收以下信号： VOR 信号（提供磁方位信息） ILS 信号（包括 LOC 和 GS） DME 信号（如果 NAV 设备支持） 2. VOR 和 ILS 如何被 NAV 接收？ 系统 频率范围 功能 由 NAV 接收？ VOR 108.00 – 117.95 MHz 提供方位角（Radial）信息 ✅ 是 LOC（ILS） 108.10 – 111.95 MHz 提供水平方向的跑道对准信息 ✅ 是 GS（ILS） 329.15 – 335.00 MHz 提供垂直方向的下滑角信息 ✅ 是（部分 NAV 设备集成 GS 接收） DME 962 – 1213 MHz 提供距离测量 ✅ 是（但有些飞机的 DME 独立于 NAV） 3. VOR 与 ILS 的接收方式① VOR（VHF Omnidirectional Range） VOR 站点发射一个基准信号和一个可变信号。 NAV 接收机解码 VOR 信号，计算飞机与 VOR 站的磁方位角（Radial）。 显示在 HSI（水平情况指示器）或 CDI（航道偏离指示器）上。 ② ILS（Instrument Landing System）ILS 由两个主要部分组成： LOC（Localizer，本地 izer） 发送水平方向信号，指示飞机是否对准跑道中心线。 NAV 接收 LOC 信号，并在 HSICDI 上显示航道偏离信息。 GS（Glide Slope，下滑道） 发送垂直方向信号，指示飞机是否在正确的下滑路径上。 NAV 接收机（如果支持 GS）会解码 GS 信号，并在 PFDCDI 上显示下滑角信息。 4. NAV、DME 和 ILS 的关系有些 NAV 设备同时集成 DME 功能，但在某些飞机上，DME 是独立的接收设备，用于测量飞机与导航台的距离。例如： VORDME 站点可以同时提供方位（VOR）和距离（DME）。 ILSDME 进近使用 ILS 提供航向+下滑角，DME 提供距离信息。 5. NAV1 和 NAV2 如何影响 VORILS？ NAV1 和 NAV2 可以分别调谐不同的 VOR 或 ILS 频率，用于交叉检查信号。 进近时，NAV1 一般用于 ILS 着陆，NAV2 可能用于监听备用 VOR 台。 总结✅ VOR 和 ILS 的信号都是由 NAV 接收机接收的。✅ LOC（跑道对准）和 GS（下滑道）均属于 ILS，LOC 由 NAV 直接接收，GS 可能由 NAV 或专用 GS 接收机处理。✅ DME 可能集成在 NAV 中，但某些飞机的 DME 是独立设备。 在航空电子系统中，NAV Audio（导航音频）的 Filter（滤波器） 和 Volume（音量） 是用于优化导航信号音频输出的关键控制功能，以下是它们的详细作用： 1. NAV Audio Filter（导航音频滤波器） 功能：用于过滤导航音频信号中的干扰噪声（如引擎噪音、无线电杂波），仅保留导航设备（如 VOR、ILS、ADF）发出的关键音频标识。 典型应用： 当调谐到 VOR 导航台时，导航台会发送摩尔斯代码（如“● ● ●—”代表某台站），滤波器会抑制背景噪音，确保代码清晰可辨。 在 ILS 进近时，滤除高频干扰，确保航向道（Localizer）的音频调制信号纯净。 滤波器类型：通常为带通滤波器（仅允许特定频率通过）或噪声抑制滤波器（消除低频高频杂音）。 2. NAV Volume（导航音频音量） 功能：调节导航音频的输出音量，使飞行员能在不同环境噪声（如引擎声、气象干扰）下清晰听到导航提示。 典型应用： 起飞降落阶段：调高音量以压制引擎噪音，确保关键导航信号（如 ILS 航向偏差提示）可闻。 巡航阶段：调低音量以避免持续音频干扰。 操作逻辑：通常与通信音频（COM）分开控制，避免导航提示与 ATC 通话互相干扰。 3. 实际应用场景 VOR 导航：飞行员通过滤波器消除杂音后，清晰听到 VOR 台的摩尔斯代码，确认正确调谐；通过音量控制调整音频强度。 ILS 进近：滤波器确保航向道（Localizer）的音频调制信号稳定，音量调节使偏差提示（如“滴滴”声）在嘈杂环境中可识别。 ADF（自动定向仪）：滤除中波广播干扰（如 AM 电台），专注接收 NDB（无方向信标）的音频信号。 4. 设计意义 安全性：清晰的导航音频帮助飞行员实时确认设备工作状态（如是否调谐正确），避免误判。 人机交互：独立的音量控制使飞行员能根据任务优先级（如进近时侧重导航，巡航时侧重通信）灵活调整音频平衡。 总结 NAV Audio Filter：净化信号，确保导航标识（如摩尔斯代码、调制音）清晰可辨。 NAV Volume：动态调节音量，适应不同飞行阶段的噪声环境。两者共同保障飞行员高效、准确地接收导航信息，是航电系统人机交互的关键设计。","categories":["4.软件","航电"]},{"title":"航电系统的平台说明","path":"/2023/09/04/4-软件-航电-航电系统的平台说明/","content":"航电系统航空电子系统是完成飞行任务相关功能的子系统，由无线电通信、导航、自动驾驶和显示管理等多个系统构成，包括机载计算机及在其之上运行的软件、通讯、传感器、控制器等。 航电系统先后经历了分立式，联合式，综合式和高度综合式四个阶段。 综合模块化航空电子系统（Integrated Modular Avionics，IMA）是目前航电系统体系中的典型结构。 综合模块化航空电子系统开发过程的指南文件 DO-297 中对 IMA 的定义是:”IMA 是一组灵活的、可重用的、可互操作的共享硬件和软件资源,当把这些资源综合在一起时可以构建一个平台,该平台按一组确定的安全和性能需求进行设计和验证,能提 供各种服务,并驻留执行飞机功能的应用”，通俗的来说，IMA 结构的主要功能是将多个功能独立的机载设备作为整体统一考虑，在模块级进行综合集成。IMA 平台适航审定的各适航标准之间的相互支撑关系如图。 在 IMA 结构中，以驻留在 IMA 系统的飞行管理系统为例，其飞机功能分配到 IMA 系统的功能性能需求层次结构如图。最顶层的任务描述与最底层的设计实现从不同的角度描述了同一个飞机功能。 顶层是从飞机级任务的角度抽象地描述整个飞机的预期操作 底层的设计实现层则是从软硬件设计实现的角度,描述飞机级任务的最终实现 “设计实现层”描述的是具体的设计”需求”,可以逐级向上追溯到最顶层的”任务”描述,即最底层的需求是从最顶层的任务分解而捕获到的 行业标准针对 IMA 体系结构，常用行业标准和推荐实践包括: RTCA (Radio Technical Commission for Aeronautics) RTCA 是美国的标准组织，负责制定航空领域的最低操作性能标准（MOPS）和最低航空系统性能标准（MASPS）。RTCA 制定的标准用于 FAA 的技术标准命令（TSO），从而使设备符合 FAA 认证。 DO-178C：软件认证标准，规定了航空软件的开发和验证过程，确保其安全性和可靠性。 DO-254：硬件设计和开发标准，特别针对航空电子设备中的复杂电子硬件（如 FPGA 和 ASIC）。 DO-297：由 RTCA 提出的指南，提供了 IMA 系统的开发、集成和认证的框架。该标准阐明了模块化航空电子系统的开发流程和认证要求。 EUROCAE (European Organisation for Civil Aviation Equipment) EUROCAE 是欧洲的标准制定组织，类似于 RTCA，主要服务于欧洲民航局（EASA）的认证需求。 ED-12C：与 RTCA DO-178C 相同，是航空软件开发的欧洲标准。 ED-80DO-254：航空电子设备中的硬件开发标准。 SAE (Society of Automotive Engineers) SAE 是汽车和航空领域的标准组织，覆盖从汽车到航空航天等多领域的技术和安全标准。SAE 的标准在航空电子、自动驾驶汽车等领域有广泛应用。 ARP4754A：航空系统开发标准，规定了复杂航空系统的开发流程。 ARP4761：航空系统安全性评估标准，结合失效模式与影响分析（FMEA）和故障树分析（FTA）来评估系统的安全性。 ARINC (Aeronautical Radio, Inc.) ARINC 是一个航空标准组织，制定航空电子设备的互联互通和规范标准，广泛用于航空公司和航空制造商之间的设备兼容性。 ARINC 429：航空电子设备之间的数字数据通信协议，广泛用于商业航空系统中的航电通信。 ARINC 653：实时操作系统（RTOS）的标准接口，广泛应用于航空嵌入式系统，特别是分区多任务操作系统。 ARINC 661：航空座舱显示系统的标准接口，规定了用户界面和座舱显示器的设计标准。 ARINC 664：与以太网兼容的航空网络标准，适用于现代航空网络通信，特别是 AFDX（Avionics Full-Duplex Switched Ethernet）网络。 ARINC 818：用于航空系统视频传输的协议。 IMA 系统作为体系结构定义了应用分区概念，ARINC 653 是为 IMA 设计的一个关键标准，定义了分区操作系统的接口标准。规定了在航空电子系统中如何实现时间和空间分区，以确保不同应用程序之间的隔离，防止它们相互干扰。符合 ARINC653 规范的 IMA 架构从上而下划分为应用软件、实时操作系统(Real-Time Operating Systems, RTOS)、硬件三个层级，层级之间通过虚拟的接口层进行交互。 空间分区：当某一个分区的应用软件发生错误或故障时不会影响其他分区内应用软件的正常运行 时间分区：系统会提供相对完整独立的时间窗口给系统中的各个分区进行调度，每一个分区都有自己对应的一个或多个时间片，只有当轮到该分区的时间片时，才会激活并被操作系统调用并运行，以确保时间维度上的确定性 应用软件 操作系统ARINC653 标准航 电 应 用 软 件 标 准 接 口 653（AvionicsApplication Software Standard Interface 653，ARINC653）是一种嵌入式操作系统应用程序接口标准，目前是国际上在飞行器软件方面比较通行的软件运行标准。 在 ARINC653 标准中定义了一个主时间帧，再将主时间帧中分成多个小时间段，每个时间段分配给一个应用程序进程执行。随着航空软件系统的执行，主时间帧周而复始运行，使各个应用程序进程都能有效获得硬件资源。同时，由于每个进程只会在分配的小时间段中执行，从而避免了在时间上多个进程同时执行造成的相互影响。与小时间段相对应，利用处理器存储器管理单元（Memory Management Unit，MMU）、存储器控制器分区（bank）控制等硬件技术，每个应用程序进程运行时使用相互独立的一段存储器，从而避免了在存储器空间上多个进程同时执行造成的相互影响。 ARINC653 通过使应用软件中的各进程在时间和空间上同时分开获得了较高的软件运行安全性，有效控制了进程发生错误的影响范围，避免了因为某一进程发生错误时威胁到整个航空软件系统运行，进而威胁到飞行器安全飞行的情况发生。 ARINC653 的详细接口实现见 ARINC653 FACE 标准未来机载能力环境（Future Airborne Capability Environment，FACE）在 2010 年由美国海军航空系统司令部发起、开源组织（OpenGroup）提出，其策略是在己安装好硬件的军用航电平台上建立软件通用操作环境，使 FACE 组件应用在不同平台上时可被重新部署，从而实现跨平台的可移植性和重用性。 FACE 采用”分段式”架构，自顶向下分为操作系统段、IO 服务段、平台特定服务段、传输服务段和可移植组件段，每个段间的接口都进行了标准化定义，使得基于 FACE 标准的应用系统可以从任意一个段间接口开始设计具有自身特色功能段。相比 ARINC653 中只定义了应用程序分时分区使用硬件的软件接口，FACE 标准包含了应用程序从顶层通用服务到底层 IO 的全部内容，制定了应用程序各组件的标准化接口，为应用程序赋予了可移植性、开放性和灵活性，大幅提高了电子系统设计的便利性，为航电设备即插即用等应用场景提供了有效技术支撑。 系统架构简介嵌入式操作系统（Embedded Operating System）是一种运行在嵌入式系统硬件上的基础软件，其基本功能是对硬件进行有效管理并对硬件进行一定程度的抽象以便应用软件调用。在军工领域，嵌入式操作系统在具备基本功能的基础上，还需要具有实时性（Real-time）、安全性（Security Safety）等特点。 主流使用的嵌入式操作系统美国 欧洲 日本 国内自研且有军工应用 国内自研 符合 ARINC653 的 OS 国内外 OS 安全认证 操作系统调度单核处理器调度算法在单核处理器中，每次调度只有一个任务在运行，只有等待当前任务结束或该任务的时间片结束后才能切换到下一任务运行，追求 CPU 利用率和吞吐率的最大化，关于 CPU 利用率等参数见 CPU参数说明 先到先服务（First-Come, First-Served，FCFS） FCFS 是一种广泛使用而又相对简单的调度算法，其采用的是先进先出（First-Input,First-Output，FIFO）队列。任务从 FIFO 队列头部开始顺次分配给处理器执行，任务执行完成后便从队首删除，并从队首取出新的任务执行。而当某一任务准备就绪后便将该任务链接到 FIFO 队列的队尾，如此循环往复的执行。FCFS 是一种非抢占式的任务调度算法，其优点是简单易懂，缺点则是缺乏灵活性，任务执行效率低下。 最短作业时间（Shortest-Job-First，SJF） SJF 是指对处理时间短的任务优先进行调度运行，其拥有可抢占与非抢占两种调度模式。这是种可以极大缩短调度的平均等待时间的调度方案，但遗憾的是这仅仅只是一种理想的方案，因为计算机是很难预先知道随机任务运行所需要占用处理器的时间。 优先权调度（Priority） 优先权调度指的是系统会按照某种权值分配策略来给每个任务分配一个对应的权值，以此来衡量任务的优先级别，优先级别最高的任务最先分配给处理器进行执行，对于具有相同优先级别的任务，将其按照 FCFS 的顺序来进行执行。以上讲到的 SJF 调度算法便是优先权调度的一个特例，其权值分配策略为任务运行时间的倒数。 轮转法调度（Round Robin，RR） RR 算法是在 FCFS 算法中加入时间片抢占策略而形成的，是对 FCFS 算法的优化。在任务调度过程中，如果任务 A 的运行时间小于设定的时间片，则会自动释放处理器；反之，如果任务 A 的运行时间大于时间片，则系统会产生定时器中断，先保存任务 A 的执行状态文件，然后将其添加到 FIFO 队列的尾部；与此同时，系统会从 FIFO 队列的队首调出任务 B 来进行执行。RR 调度算法的性能与时间片大小有着直接的关系，当时间片选取过小时，单位时间里进行任务切换的次数就会变多，从而增加系统的内存消耗，影响系统任务调度的效率；与之相反，当时间片选取无限大时，对于大量使用 RR 调度算法的任务来说，其调度效率趋同与 FCFS 算法，容易造成任务的阻塞。因此使用 RR 算法进行任务调度时，选择适当长度的时间片非常重要。 多队列调度（Multilevel Queue） 多队列调度是一种两层的调度模型，其将所有的任务划分为多个任务队列，先以任务队列为调度单元，队列之间采用某种合适的调度算法。再以队列中的任务为调度单元，在每一个队列内部采用某种合适的调度算法。 多级反馈队列（Multilevel Feedback Queue） 多级反馈队列调度是一种广泛使用却异常复杂的调度算法，它是对多队列调度算法的优化。在多队列调度中，任务分配到某队列后便固定不能进行移动，导致任务调度过程缺乏灵活性。而在多级反馈队列调度中，优化了这种固定的设计，允许任务在队列中进行移动，提高了调度的灵活性与高效性。 ARINC653 调度在 ARINC653 标准的实现中，分为分区调度和分区内的进程调度： 分区间调度： 采用 轮转法调度（Round Robin，RR），通过固定长度的时间片按循环顺序分配处理器时间，实现了各分区的公平和隔离。 分区内进程调度： 采用 优先权调度（Priority Scheduling），根据进程的优先级分配执行顺序，确保关键任务的实时性和响应速度。 关于分区调度的实现和流程见 运行流程 多核处理器调度算法多核任务调度典型应用模式： 对称多处理（Symmetric Multi-Processing，SMP） SMP 模式是指同一个核心操作系统映像负责协调所有处理器核上的任务调度工作，在这种模式下，所有的分区任务允许动态分配到任何空闲的处理器核上进行执行，可以更好的实现负载均衡性。 非对称多处理（Asymmetric Multi-Processing，AMP） AMP 模式是指某一任务与某个处理器核绑定之后，就不允许在此处理器核之外的其他处理器核上运行。相比较于 SMP 模式下所有处理器核共享一个全局的核心操作系统映像，AMP 模式下各个处理器核都有自己独立的操作系统映像，且每个处理器核都可以根据实际调度需求选择加载合适的操作系统映像，如加载 Windows 映像、Linux 映像、VxWorks 映像等等，以形成该处理器核独立的调度域，对调度域内的任务资源进行管理。 绑定多处理（Bound Multi-Processing，BMP） BMP 模式是一种比 SMP 更加灵活的多核处理器调度模式。相比较 SMP 模式，BMP 模式在保证 SMP 模式下任务全局动态调度的同时，允许对一些有特殊需求的任务绑定到指定的处理器核上进行调度，增加了灵活性。 多核处理器的负载均衡 硬件平台能力指标综合计算能力指标 网络互联能力指标 嵌入式平台的优点 平台 CPU 为 AMD PPC440 GPU 为 ATI Tech M7500E 操作系统 LynxOS-178，POSIX，多处理器多线程，实时，分区 ARINC653 目前平台的限制点 功耗 发热 GPU 采用的 RISC 的指令集 PPC 平台 ARM 平台 RK NXP TI","categories":["4.软件","航电"]},{"title":"面向航空电子系统的嵌入式操作系统","path":"/2023/09/01/4-软件-航电-面向航空电子系统的嵌入式操作系统/","content":"航空电子系统发展历程航空电子系统是现代军事航空器的核心组成部分，随着技术进步，其发展经历了多个阶段，逐渐向功能更强大、集成度更高的方向演进。从上世纪 70 年代至今，航空电子系统的演化不仅提升了飞行器的性能，还增强了其在复杂作战环境中的适应能力和战斗力。 主要发展阶段二代机（1970 年代）二代机的航空电子系统大多采用了 独立式 架构。这一时期，飞机的电子设备主要基于单一的处理器，缺乏互连功能。因此，各个系统之间无法直接沟通，只能依赖传统的手动操作。比如，最典型的代表是美国的 F-4 幽灵战斗机，这款飞机虽然在战斗中表现优异，但其电子系统的局限性却在现代战斗条件下显得愈发明显。 三代机（1990 年代）进入 1990 年代，航空电子系统开始向 联合式 架构演化。这一时期的战机如 F-15 和 F-16 采用了多处理器设计，并加入了系统间的互连，允许各电子系统之间共享信息，从而大大提高了战术决策的速度和准确性。例如，F-16 的综合 avionics 系统允许地面和空中指挥官实时获取飞行器状态和敌方情报，增强了战斗能力。 三代半（1990 年代末至 2000 年代初）在此阶段，航空电子系统日益向 综合式 发展。综合式航空电子系统实现了局部综合，具体包括功能分区和任务浮动，能够在不同的作战条件下快速切换功能。比如，FA-18 大乌鸦战斗攻击机就采用了这种设计，使其在执行多种任务时，能够快速适应新任务的需求。 四代机（2000 年代至今）最新的 先进综合式 航空电子系统在 20 世纪末和 21 世纪初逐步普及，标志着科技的质变。这类系统具有信息综合能力，能够进行高速并行处理，不仅大幅提高了数据处理能力，还有着高置信度和极好的扩展性与升级能力。例如，F-35 闪电 II 战斗机就采用了极为复杂的 MCM（多芯片模块）和 SoC（系统级芯片）技术，同时配备了集成机架和液冷技术，以确保其在各种恶劣条件下的稳定运行。 未来展望随着科技的不断进步，航空电子系统的设计将更加注重软件密集型的发展趋势，这将促进智能化、网络化的趋势，未来的战斗机不仅能够速战速决，也将能够面对更加复杂的战场环境，保障战争中的信息优势。整体来看，航空电子系统的进步不仅反映了航空技术的发展，也代表了军事战略思想的演变与创新。 机载计算机的发展历程随着航空技术的不断进步，机载计算机的设计和功能日趋综合化，这种趋势在新一代飞机航电系统中表现得尤为明显。综合化的最终目标是提高飞机的智能化水平和操作效率，从而有效降低全寿命成本。 关键特性新一代航电系统结合多种关键特性，以满足现代航空飞行的多样化需求。这些特性包括： 任务性能 可用性：系统需要做到在各种极端情况下依然保持高效运作。例如，某些航电系统能在电力不足或部分硬件故障的情况下继续执行关键任务。 可伸缩性：航电系统要能够方便地扩展，以加入新的功能或设备。例如，在快速升级后，旧有系统能够支持新型传感器的接入。 可测试性：可以通过内置的自测试功能，及时发现并隔离系统故障，确保飞行安全。 可维护性：设计应简化维护程序，减少地面支持人员的工作时间，提升技术的可靠性。 进程隔离性：不同任务之间的处理过程应该能够互相隔离，以减少相互干扰的风险。 安全性：应对网络安全威胁和系统故障提供保障，例如采用多重认证机制。 可移植性：系统设计应允许在不同平台上轻松部署和使用，例如将相同软件应用于不同型号的飞机。 运行性能 开放式结构：采用开放标准，以便于不同制造商的设备能顺利连接和通信。 系统层次结构：分层设计使得系统更容易理解、扩展和管理，每个层级可以独立维护。 模块化结构：各个部分可以独立更换，故障检测和维修将变得更加快捷。 高速互联结构：为了实现快速数据传输，舱内网络需要支持百兆甚至千兆速度，这对于飞机的各系统协调至关重要。 标准信息结构：统一的信息格式确保不同设备之间的高效数据交换。 标准通信协议：制定业内通用的协议，使得不同设备和系统能够顺畅互动。 标准构件：推行通用组件，能有效降低生产成本，也使得维护过程更为便捷。 全寿命成本在考虑机载计算机的发展时，全寿命成本是一个不可忽视的重要概念。它不仅包括设备的采购费用，还涵盖了运营、维护和最终报废的相关支出。通过提升系统的可用性、可维护性等特性，可以从根本上降低整体的全寿命成本。例如，采用高度可测试和可维护的设计理念，不仅减少了地面维护人员的工作量，也显著减少了故障停机时间，从而优化了运营效率并降低了长期支出。 通过这些先进的设计原则和技术，们能够构建出更安全、更灵活、更具适应性的航空电子系统，以满足未来日益增长的航空需求。 IMA从军用飞机发展到民用飞机集成模块化架构（IMA）最初在军事航空领域取得了显著成果，逐渐扩展到民用航空。例如： F-22 与 F-35：这两种战斗机利用 IMA 架构实现简化的系统集成和升级，使得今后的技术更新更加迅速与经济。 A380：作为世界上最大的客机，A380 采用该架构支持复杂航电系统的高效集成，提高了整个飞机的系统协同效率。 B787：波音 787 通过 IMA 实现更高的系统集成度，增强了飞行性能并降低了运营成本。 从美国飞机发展到其它国家美国在航空技术领域的先锋角色促使其它国家也开始采用 IMA。例如： 法国、德国、英国的联合项目：这些国家的军用飞机技术，如欧洲战斗机，借鉴了美国的设计理念，推动了针对北约及其盟友的航空系统现代化。 瑞典的 SAAB DIMA：这一项目展示了瑞典在战斗机系统集成方面的创新，充分利用了 IMA 的设计优点，提升了飞行器的战斗能力和维护效率。 从局部综合发展到全局综合随着技术的发展，航空电子系统的集成也变得更加全面和系统化。例如： ICNIS（集成航空电子系统网络）：实现了在飞行过程中对飞机各种系统的全面监控和控制，包括飞行导航和自卫系统。 IEWS（增强型预警系统）：这一系统不仅提高了威胁检测能力，还与飞机其他系统如通信和导航系统紧密集成，提升了整体作战效能。 IVMS（智能车辆管理系统）：通过对飞机内部各种状态的实时监测，确保了航空器的高效运转和安全性。 从新飞机综合到老飞机的更新IMA 的应用不仅限于新一代飞机的开发，还广泛应用于老旧飞机的现代化改造。例如： F-16 EF Block 60：这一升级版本通过整合 IMA 技术，显著增强了其传感器融合能力和作战范围，使得老旧的战斗机在现代空战环境中更具竞争力。 IMA 的定义与优势IMA（集成功能架构）是一种将硬件和软件资源整合的系统，这些资源具有可共享、灵活、可重用和互操作的特性。当这些资源被整合在一起时，它们形成一个强大的平台，能够为在其上运行的执行飞机功能的应用程序提供设计和验证过的服务。这些服务不仅具备预订的安全级别，还满足特定的应用性能需求。 功能综合与物理综合IMA 的综合化好处可分为两大类：功能综合和物理综合。 功能综合功能综合通过集成多种应用程序的功能，显著提高了整个系统的运行性能。例如，在现代战斗机中，飞行控制系统、导航系统和武器控制系统可以共享信息，优化反应速度和决策效率。通过功能综合，飞行员能够在同一界面上获取所有必要信息，增强其操作能力。 物理综合物理综合则涉及硬件资源的有效利用，能够降低开发成本和重复成本。具体来说，这些好处包括： 降低单个通用系统的设计成本：通过设计可互换的模块，整个系统可以更快速地开发和调整。 降低扩充与维护的重复成本：当系统硬件和软件标准化时，维护和升级变得更加简便，减少了在添加新功能时的资源浪费。 降低修复成本与提高起飞率：与传统系统相比，集成组件通常具有更高的可靠性，因此在执行任务时，飞机的维修需求减少，提升了任务完成的成功率。 降低备份成本：当不同应用共享相同的硬件资源时，所需备份和冗余部件的数量减少。 降低采购价格：由于通用部件可以从多个供应商处采购，增加了竞争，这有助于降低单个部件的价格。 综合化带来的成本效益集成的好处体现为成本的显著减少，涵盖设计、采购、运行和更新的各个环节。例如： 设计和采购的简化：可重用的硬件和软件组件大幅降低了从头开始设计新系统的需求。 体积、重量和功耗的削减： **体积减少 50%**：通过优化系统设计，减少不必要的物理空间需求，使飞行器在设计和内部布局上更加灵活。 **重量减少接近 30%**：轻量化的材料和集成功能的设计，使得飞机在飞行中更高效，进一步提升了燃油效率和载重能力。 **电源功耗降低到大约 16%**：高效的能源管理系统使得飞机在运行中消耗更少的电力，延长了电池和发电机的使用寿命。 可靠性改进 20 多倍：通过多次验证和测试的集成设计，确保了系统的稳定性和安全性，减少了故障发生的频率。 综上所述，IMA 所带来的集成效果不仅在成本上带来显著的优势，还在飞机的性能和可靠性上实现了质的提升。这样一来，飞行器能够在执行复杂任务时展现更高的效率和安全性，也确保了其在现代航空领域的竞争力。 综合化对机载计算机的严峻挑战一般的困难 设计复杂性增加 随着系统整合程度的提高，机载计算机的设计变得更加复杂。例如，新的综合系统可能需要同时考虑多个子系统，如导航、通信和引擎控制，每个子系统都有独特的功能和要求。这种复杂性不仅增加了设计的难度，还可能导致潜在的技术问题。 制造与测试的困难 综合化的设计使得制造和测试流程更加复杂。在生产中，不同系统的交互关系可能会导致组装时的困难，且每一个模块的质量控制都变得至关重要。同时，测试阶段也需要考虑系统间的兼容性和协同工作能力，这可能会增加测试时间和成本。 认证过程的挑战 认证是确保机载计算机安全和可靠的关键环节。随着综合系统的复杂性增加，认证流程会变得尤为繁琐，因为需要评估不同系统之间的交互和风险。例如，在一个高度综合的系统中，任何子系统的错误都可能影响整体功能，这使得认证的深度和广度都显著提升。 实时操作系统的需求 对于机载计算机而言，实时性能至关重要。综合化系统需要在快速变化的环境中作出快速反应，因此，严格要求操作系统能够执行任务时保持时间上的可靠性。同时，系统还需具备隔离保护能力，以防止故障或攻击影响到其他关键模块。 高要求的检错定位能力 综合化系统的故障诊断和定位能力需要极大提升，以满足复杂操作中的实时响应。例如，在飞机飞行过程中，任何一个小错误都可能导致重大安全隐患。因此，时代要求更高效的故障监测和排查机制，以及时解决潜在问题。 综合化的主要特点 资源共享（Resource Sharing） 综合系统强调资源的共享，这要求这些共享的资源具备更高的信息处理能力。例如，多个传感器可能需要共享数据以提高飞行监控的精准度，因此，它们必须能够快速处理和传递大数据量的信息。 高效通信能力 在综合化系统中，各个共享资源之间需要具备高效的通信能力，以满足高耦合程度的需求。 举个例子，飞行控制系统与导航系统需要实时共享飞行数据，以确保导航的精准及飞行安全。 软件结构的适应性 随着系统规模扩大和复杂性增强，软件结构必须能够应对实时性、可靠性和安全性等多重要求。比如，为了保证系统在面对突发情况时的稳定性，可以采用模块化设计，使得各个模块可以独立更新或维护，从而降低整体系统的风险。 综合化对机载计算机提出的严峻挑战主要挑战（1）：高性能的处理单元 处理器能力： F-22 的计算机集成处理（CIP）速度为 400 百万指令每秒（Mips），而 F-35 的集成计算机处理（ICP）速度则提升至 40.8 十亿指令每秒（Gips），提升幅度达到 100 倍。这意味着，在同样的时间内，F-35 能处理的计算量是 F-22 的 100 倍，使其在复杂任务中展现出更强的处理能力。 每个数据处理逻辑资源模块（LRM）能够达到数十亿次运算能力，支撑更高层次的系统维护任务。 新一代处理器： 新一代系统采用多核多处理架构，每个逻辑资源模块上配置多个处理器，通常为 16 核处理器。此种设计不仅提升了处理器的并行计算能力，同时也使得系统能高效处理大量数据，提升响应速度。 智能化处理： 针对复杂计算任务，这些机载计算机还采取了智能处理技术，配备智能处理器，实现自学习和适应性计算。这一变化将推动机载计算机在飞行、导航等关键领域中的智能化水平，提供更为精准的决策支持。 主要挑战（2）：高性能的网络 网络速度： F-35 使用 1-2Gbs 的光纤通道（FC）网络，提供了高带宽的通信能力，使得飞行器内部各系统间的数据传输迅速而可靠。 在一般军用飞机中，基础网络常常建立在 4Gbs 的光纤通道网络（FC-AE）上，确保了关键数据的稳定传输。 民用航空与航电网络： 民机航电系统利用 100Mbs 的 ARINC664 P7 以太网络，将其转化为全双工交换式以太网，显著提高了系统的可靠性和确定性，确保每个系统能高效地获取所需数据。 先进网络技术： TTE 网络：事件触发以太网，支持高达 1Gbs 的同步数据传输，确保数据传输的高确定性，适用于对实时性要求极高的飞行控制系统。 TSN 网络：时间敏感网络，能够提供 1Gbs 和 10Gbs 的数据传输能力，适应多种业务的同时高效传输，适合复杂飞行任务的技术需求。 主要挑战（3）：高性能的软件 软件规模与复杂性： 随着飞行器系统的综合化，软件的规模逐渐增大，功能日益复杂。例如，F-22 的整个软件配置总计达到 1.7 百万行源代码（MSLOC），其中航空电子软件占 87%，也就是 1.5 百万行，涉及雷达、通信导航干扰等多个子系统。 F-35 的软件配置： F-35 的全机软件总行数达到 15 百万行： 机载软件约占 6 百万行，其中任务系统软件为 4.5 百万行，飞行器管理软件 1.5 百万行。 地面开发（包含模拟器）软件也占 6 百万行，辅助性软件则为 3 百万行。 综合化对机载计算机提出的严峻挑战机载计算机在现代航空电子系统中的角色愈发重要，然而，随着系统综合化程度的提升，这些计算机面临了前所未有的挑战。以下是对这些挑战的详细分析。 软件复杂性增强实时性机载计算机必须满足不同类型任务的实时要求，包括周期性任务、非周期性任务以及偶发任务。例如，飞行控制系统需确保在飞行过程中实时处理来自传感器的数据，以便准确调整飞行姿态，而气象雷达则需快速更新天气信息。在这种情况下，任何延迟都可能危及飞行安全，导致无法及时响应突发情况。 可靠性系统的可靠性变得尤为重要，特别是在多种应用的环境下。故障的影响呈现出更复杂的模式，比如，一个故障可能会影响到多个并行运行的应用。为此，采纳分布式容错机制成为必要，通过检测、滤波、诊断、屏蔽、降级、重构和恢复等手段来保证系统的正常运行。例如，在一个机载通信系统中，如果一部分设备出现故障，系统必须能够迅速识别并重构，以避免整体通信中断。 安全性安全性挑战源自于多个独立任务在同一计算资源上的共享。这些任务往往具有不同的关键性和安全级别。例如，导航系统与乘客娱乐系统同时运行，共享同一处理器。如果导航系统受到攻击，可能导致数据泄露或系统崩溃，进而危及飞行安全。因此，确保故障不会在应用之间传播，是保证整体系统安全性的重要课题。 综合化对系统结构的挑战综合式（局部综合）系统采用综合式设计能够大幅度节省成本，提升资源利用率。例如，通过将多个应用整合到一个硬件平台上，可以减少设备采购和维护费用。然而，这种整合带来了新的风险，由于各个应用之间交互频繁，故障更易传播，信息安全风险加大。例如，在一个综合化飞行管理系统中，如果导航应用出现故障，可能会干扰到飞行监控和调度等其他功能，造成影响广泛的后果。 IMA 结构目标为了应对综合化带来的结构挑战，集成模块化架构（IMA）应运而生。它旨在实现实时、可靠和安全的资源共享。共享的概念意味着不同应用之间可以有效分配资源，包括处理器、存储器、数据通道及设备等。这种方式允许资源的持久共享或分时占用，增强了系统的灵活性。例如，利用 IMA 结构时，多个应用可以在不同时间段使用同一处理器，从而降低资源闲置率，同时确保每个应用在关键时刻都能获得足够的计算能力。 在面对这些挑战时，机载计算机的设计者们需要不断探索新的技术和方法，确保航空电子系统不仅满足当前的需求，还能适应未来的变化。 航空电子系统的发展趋势ARINC653 简介ARINC653 是航空电子系统中不可或缺的标准，旨在为机载操作系统提供可靠的框架。自 1997 年首次提出以来，该标准已经经历了多个版本的发展，目前已纳入中国军用标准 GJB5357-2005。这标志着它在不同领域的广泛应用和对系统的影响力。 综合化对机载操作系统的需求随着航空电子设备的复杂性增加，集成度也随之提升。航空公司和制造商们希望通过综合化系统来减少机载设备的成本，同时降低系统的重量、体积与功耗。为了实现这一目标，必须高效利用计算资源，这促使了多任务在单个 CPU 上同时运行的需要，这正是 ARINC653 所解决的核心问题之一。 天脉嵌入式实时操作系统天脉嵌入式实时操作系统是结合 ARINC653 规范而生的创新，具备强大的实时计算能力，能够满足航空电子系统的高要求。例如，天脉系统可以在飞行器的导航和控制系统中处理来自多个传感器的数据，保证在关键时刻提供精确反馈。 ARINC653 规范解析技术推动与需求牵引 计算机技术飞速发展：90 年代末，CPU 的性能相比 80 年代有了显著提升。小型 CPU 的处理能力开始可以替代以往需要大型机才能完成的任务。这种技术进步为航空电子系统的复杂性奠定了基础。 行业需求：综合化航空电子系统的趋势要求更多的功能汇聚于更少的设备中，这导致了对资源共享的迫切需求。比如，现代飞机可能有多个系统同时在运行，从导航到通讯，各系统之间对资源的竞争变得尤为关键。 面临的新问题在资源共享背景下，新问题随之产生： 任务间干扰：传统的”联合式”航空电子系统中，各个任务有独立的计算资源，采用物理隔离防止干扰。然而，随着高度共享计算资源的需求上升，如何确保不同任务不互相影响就成了大问题。 解决方案：ARINC653 的分区概念ARINC653 提出了”分区”概念，以有效隔离任务，确保一个任务的运行错误不会影响到其他任务。比如，某个导航系统的故障不会影响到通信系统的正常应答。 降低测试与验证的成本通过引入分区，各任务之间实现了”隔离”，这使得测试和验证可以根据不同的重要性级别进行。假设有一个任务是用于紧急制动，另一个是用于娱乐系统，这两个任务可以在不同的分区中独立进行测试，各自的审核标准也不必统一，提高了效率。 ARINC653 规范的主要特征实时系统的确定性实时系统最重要的特性之一是其时间确定性，即不仅要求计算结果的准确性，更需要结果产生的时效性。ARINC653 通过两级任务调度机制（分区调度与进程调度）来确保实时性能。 健康监控机制为了保证系统的高可用性和便于维护，ARINC653 引入了健康监控机制。这个机制负责监控应用软件、操作系统以及硬件的健康状态，及时报告故障，帮助隔离问题，避免故障的扩散。例如，当某个传感器出现故障时，系统可迅速采取措施，继续确保飞行安全。 通过结合技术进步和行业需求，ARINC653 不仅为航空电子系统提供了更高的可靠性和安全性，也极大地推动了航空领域的技术创新和发展。 ARINC653 简介ARINC653 标准ARINC653 是一种航空电子系统的标准，主要用于确保航空航天应用的软件和系统的可靠性与安全性。它涵盖以下几个核心部分： 分区管理（Partition Management）分区管理允许系统在不同的功能模块之间进行资源的合理分配和隔离。这种方法可以实现多个应用程序安全、稳定地运行在同一硬件平台上，避免由于一个应用的崩溃影响到其他应用。例如，航电系统的飞行控制和通信导航等不同分区可以独立运行，从而提高整个系统的鲁棒性。 进程管理（Process Management）此部分定义了进程的创建、调度和终止等行为，以确保操作系统能够高效处理多个任务。良好的进程管理可提高系统响应速度，支持关键任务的实时处理。例如，在飞行过程中，导航与避障的进程需要确保其延迟最小，以快速响应外部环境的变化。 时间管理（Time Management）时间管理规定了系统内的时间调度与同步机制。这确保了系统中各个分区能够以严格的时间约束执行任务，尤其重要的是，在航空电子应用中，任何延迟都可能导致安全隐患。例如，在飞行控制中，实时数据处理的时间精度至关重要，以确保飞行器的有效控制。 存储器管理（Memory Management）存储器管理涉及到在分区之间的内存分配与保护。通过有效的内存管理，系统可以防止一个分区对另一个分区的干扰，从而提升整体安全性。在一个航电系统中，图像处理和导航计算需要分别存储和管理其数据，以避免由于资源竞争导致的系统不稳定。 通讯（Communications）分区内通讯分区内通讯确保不同模块之间的数据交换可以顺畅进行。例如，飞行数据与导航信息的实时共享。 分区外通讯分区外通讯则允许系统与外部设备或者其他系统进行交互，以获取外部信息并进行相应处理。这种能力在复杂的航空任务中尤为重要，比如与地基控制中心进行状态更新。 健康监控（Health Monitoring）健康监控系统帮助检测和评估机载系统的整体健康状态，实时反映可能出现的故障。这可以通过监控软件与硬件的状态来实现，及时发现问题并采取措施。例如，在飞行中，系统会持续监控发动机的温度和压力等重要参数。 综合化对机载操作系统的需求天脉嵌入式实时操作系统应用情况高安全性的实时操作系统（RTOS）逐渐成为满足 ARINC653 接口标准的主流选择。这是因为航空电气系统的复杂性和对任务管理的高要求，需要操作系统能够迅速响应变化并保证各系统模块的稳定运行。 例如，天脉嵌入式实时操作系统通过高效的任务调度和分区管理能力，支持飞行控制、导航、通信等关键功能的独立性和冗余，成为现代航电系统的重要基础。 综合核心处理机硬件平台在综合机载操作系统架构中，使用了专用的核心处理机硬件平台，具备实时容错和分布式系统支持。这一平台通常由多个专用计算机组成，连接了 1553B 总线，确保数据的快速传输与处理。 对于航空应用而言，性能可靠的硬件平台是实施复杂任务处理的关键，能够支持从传感器数据处理到飞行控制等各种应用的无缝整合。 任务软件综合核心处理机的软件平台包罗万象，包括但不限于： 传感器信息融合：用于整合来自多个传感器的数据提升信息的准确性。 导弹发射申请：控制武器发射时机和安全。 图像融合处理：将不同来源的图像进行合成，提升监控效果。 自动目标提示：通过算法提升目标识别准确度和速度。 这类系统不仅限于雷达或通信导航识别，还涉及电子战中的信号处理和数据管理，为现代空中作战提供了全面的支持。 独立的子系统在复杂的机载系统中，独立的子系统角色日益凸显。各自独立的计算机和控制模块能够在极端条件下保持任务的连续性和稳定性。例如，航行系统可以在不干扰武器控制系统的情况下，独立实现飞行路径的计算和调整。 综合化概念—-计算机应用软件综合通过综合核心处理机硬件和软件平台，构建出一个高效且灵活的机载操作系统，为日益增长的航空电气需求提供支持。这样的平台能够处理更多的功能模块，处理更复杂的任务，有效应对未来航空技术的挑战。 综合化对机载操作系统的需求地面开发环境现代机载操作系统的发展需要在多模块的硬件框架内运作。这些硬件通常数量众多，种类繁多，每一个组件都致力于实现高安全性和实时性，提供容错机制，并具备分布式操作能力。 高安全实时容错分布式操作系统这种操作系统是机载设备的核心，能够支持多个任务软件模块，例如： 各种传感器信息融合：将来自不同传感器的数据整合，提高态势感知。 导弹发射申请及控制：确保发射流程的安全性与实时响应。 图象融合处理：通过多视图融合提取更完整的信息。 自动目标提示、无源测距：有效识别和计算目标距离。 任务评估与战术管理：提供战场环境下的决策支持。 嵌入培训与响应管理：通过模拟训练提升飞行员技能。 每个模块的设计都使得操作系统能够应对复杂的战场环境，确保信息的快速处理和响应。 雷达与电子战的整合对于机载作战系统来说，雷达和电子战的高效整合至关重要。例如，雷达系统不仅需要进行信号处理和数据处理，还需具备雷达管理功能。通过实时数据分析，系统能够迅速识别威胁并进行响应。 同样，在电子战模块中，信号处理与电子战管理的结合，能够在对抗敌方电子干扰时，保持自身信息的安全与完整。 通信导航的关键角色通信、导航和识别系统（CNI）的有效管理对于机载操作至关重要。这些系统需要进行实时信号处理和数据分析，以确保航行的准确性和安全性，包括： 前视红外探测器：实时监控与目标测向，帮助飞行员获得周边环境信息。 分布式红外传感器：提供全面的态势感知和导弹威胁告警。 天脉嵌入式实时操作系统的应用天脉系列嵌入式实时操作系统代表了当前机载操作系统的高水平发展，具备完全自主知识产权。天脉操作系统的特征包括： 高安全性与高可靠性：在军事任务中对于系统安全性的极高要求。 强实时性能：保证系统能够在极短时间内处理紧急情况。 天脉系列产品的多样化天脉系列操作系统根据不同的应用场景设计了多种版本： 天脉 1 操作系统：专注于实时多任务处理，已经进入定型阶段，适用于通用机载电子设备。 天脉 2 操作系统：提供多应用间的安全隔离，具备故障管理功能，确保系统稳定运行。 天脉 3 操作系统：为航空装备提供高性能的多核信息处理平台，支持 64 位设计，满足现代复杂任务的处理需求。 每个版本的设计特征都能满足不同的作战需求，为飞行器提供可靠的操作基础。 天脉 1 操作系统—实时多任务体系结构支持包板级支持包 任务管理提供多任务环境下的管理工具，可以灵活切换不同的任务，确保系统在多种情况下都能稳定运行。 高可靠文件系统设计用于存储和处理关键数据，具有容错能力，确保数据的安全性和有效性。比如，支持快速恢复上一状态，防止数据丢失。 天脉 API 接口提供了与 VxWorks 5.x 兼容的接口，便于应用的开发和迁移，确保应用程序的无缝移植。此外，还提供其他功能接口，使得用户能够更方便地进行开发。 任务间通信针对不同任务之间的通信需求，提供了高效的机制，以确保数据的及时传递和共享。 中断异常有效管理系统的中断和异常情况，支持系统快速响应外部事件。 存储管理通过高效的存储管理工具，有效优化内存使用，提高系统性能。 时间管理通过精确的时间控制，确保任务的按时执行。 网络协议栈 图形显示支持 OpenGL 等图形接口，允许在嵌入式系统中进行丰富的图形处理，增强用户体验。 嵌入式数据库提供嵌入式数据库功能，方便数据库的管理和操作，支持快速的数据查询和存储。 分布式管理支持在分布式环境中进行任务和资源的管理，提高系统的可扩展性。 基本核心模块支持层 功能组件提供多种功能组件，满足不同应用需求。用户可以根据自身的需求进行选择和配置。 用户扩展用户可以根据具体需求扩展系统功能，增强系统灵活性。 Cache 管理、设备管理、错误管理提供对缓存、设备及错误的有效管理，确保系统长期、稳定地运行。 支持机载常用组件 TCPIP提供完整的 TCPIP 协议支持，确保网络通信的可靠性。 数据库各类数据库的支持使得系统具有良好的数据处理能力。 高可靠文件系统确保文件的高可靠性，特别是在机载环境中，数据的完整性至关重要。 OpenGL通过 OpenGL 进行图形渲染，使得用户可以使用现代化的图形界面。 支持处理器系列 PowerPC 全系兼容各种 PowerPC 处理器，确保用户能够实现更高的性能。 X86广泛支持 X86 架构，满足不同应用场景的需求。 ARM（飞腾）提供 ARM 处理器的支持，尤其是国产飞腾处理器，适应国内的应用场景。 MIPS（龙芯）增强与多种龙芯处理器的兼容，确保了系统的可用性。 天脉 1 能力与 VxWorks 5.x 相当，接口兼容分层架构 提高重用性、可移植性采用分层架构设计，系统的各个模块可以独立开发和替换，从而自然提高了模块的重用性和整个系统的可移植性。 天脉 1—机载特性设计 时间粒度可配，默认 1ms提供灵活的时间粒度选择，以适应不同的应用需求。 周期任务支持支持定时任务，确保系统能够实时处理高频次的任务调度。 中断嵌套支持支持中断嵌套，有效提升系统响应外部事件的能力。 实时性与确定性 存储空间保护通过存储空间保护，确保重要数据不被非法访问或修改。 只读数据保护提供只读数据区的支持，增强数据的安全性。 函数接口调用限制对于函数接口的调用进行限制，确保系统安全性不受到威胁。 可靠安全 高可靠文件系统设计高可靠性文件系统，确保数据在各种条件下的安全。 图形支持：OpenGL、QT 多组件集成通过 OpenGL 和 QT 等工具集成，实现优秀的图形展示能力。 嵌入式数据库提供灵活可用的嵌入式数据库模块，支持各类数据操作。 多系列处理器平台支持多种处理器平台，提升了系统的适应性和应用范围。 支持多种国产处理器特别强调对国产处理器的支持，提高了自主可控的能力。 平台适应性 参数可配置，组件可剪裁根据具体需求进行灵活配置，用户可根据实际情况对组件进行裁剪，减少不必要的资源浪费。 周期任务接口：无需应用设计周期机制，简化开发过程。 空间保护：实现空指针检测和地址越界检测，确保系统安全。 安全信号量：防止任务优先级翻转，确保系统稳定运行。 VxWorks 兼容包：提高移植效率，让用户在不同系统间进行轻松切换。 可剪裁配置：各类组件可以根据用户的需求进行选配，确保代码规模小，提高系统效率。 处理器支持：支持 PPC、ARM、MIPS、X86 四个系列中的数十种处理器，带来广泛的配置灵活性。 国产硬件：确保支持飞腾、龙芯、锐华、国微等国产处理器，响应国内的发展需求。 天脉 2—安全分区时间空间隔离技术： 解决多应用共享资源带来的冲突，提高了系统的稳定性。 健康监控机制： 解决大规模复杂软件故障处理问题，确保系统的可靠运行。 应用层（AL） 应用分区、单元测试管理为各个应用提供独立的运行环境。 文件系统确保数据的有效管理。 模块支持层（MSL） ASP BIT 测试进行系统级的测试，确保每个模块的稳定性。 IM 管理高效的集成管理，保障系统整体运行顺畅。 模块支持层与核心操作系统接口各模块间的高效通信，支持系统的高性能运作。 C 运行时库提供丰富的运行时库支持，增强系统编程能力。 分区管理 任务管理提供全面的任务管理工具，确保每个任务都能高效执行。 任务间通信管理高效的通信管理机制，提高任务间的协作效率。 时间管理确保所有任务按照设定的时间进行调度。 设备管理有效管理系统中的各种设备。 定时器管理提供精确的定时器管理，实现时间的精确控制。 健康监控 分区内调试代理针对每个分区提供独立的调试支持，帮助开发人员快速发现和修复问题。 核心操作系统初始化确保核心操作系统的完整启动，保障整个系统的运行。 任务级通信代理实现任务间的高效通信，确保数据传输的及时性。 健康监控进行全面的健康监测，确保系统长期稳定运行。 配置数据管理便于用户对系统配置进行快速修改和管理。 调度表管理高效管理任务调度，确保系统资源的高效使用。 错误号管理、日志信息输出提供详细的错误报告，方便后续的维护和产品改进。 标准 APEX 服务 实现应用分区的平台无关性，便于快速迁移和验证，提升开发效率。 确定性配置 提高机载应用的安全性与可靠性，确保在复杂环境下仍能稳定运行。 天脉 3 操作系统—多核处理飞机能力提升 机载信息处理得益于更高处理效能的多核处理平台，增强了整体技术能力。 SWaP 不断追求 在体积、重量和功耗方面（SWaP）追求最佳平衡。 有效途径：多核处理器与多核操作系统 采用多核处理器进行高效数据处理，提升任务执行的并行性。 采用多核典型机载计算机 支持高并发、多流水的算法，针对不同的应用场景进行优化。 天脉 3—产品能力天脉 3 架构 硬件抽象层封装硬件细节，使得应用开发更为简便。 内核与虚拟化支持提供多核环境的虚拟化能力，确保应用的分离与安全。 ARINC653 支持模块符合多个国际标准，提高适配性。 实时进程模块支持实时进程的高效调度，实现实时响应。 服务接口库提供多种接口库支持，包括 ACoreOSVxWorks Posix，确保应用程序的灵活性。 非分区模式 支持任务调度、任务间通信、中断和异常管理。 支持实时进程（RTP）具备独立的任务隔离和时间表调度能力，确保高效运作。 支持 POSIX 接口和国外操作系统的兼容性提升了开发者的使用便利性。 分区模式 支持分区管理、健康监控、分区间通信等。 支持分区绑定处理核调度（BMP），符合 ARINC 653 标准。 支持 SMP 调度确保分区内进程的高效调度，允许更高的并发执行能力。 天脉 3—多核运行模式主流的多核模式与架构 非对称多处理（AMP）每个 CPU 核心运行独立的 OS 实例，适合处理不同任务。 对称多处理（SMP）一个 OS 实例同时管理所有 CPU 核心，使得资源利用率最大化。 绑定多处理（BMP）每个应用绑定特定处理核心，提高任务执行的专一性和稳定性。 ACoreIDE—天脉集成开发环境ACoreIDE 是一个综合性的集成开发环境，支持整个软件全生命周期的工具集合，从最初的人为协作模式逐渐发展到现代化的全生命周期工具集成。以下是其主要的工作流程和组成部分： 主要工作流程 设计：在这一阶段，开发团队会使用各种设计工具进行系统架构和模块设计，例如 UML 建模工具。 编码：程序员在编码环境中编写代码，支持多种编程语言，比如 CC++和 Python。 调试：使用调试工具对代码进行实时监控，查找 bug 并修复。 集成：将不同模块的代码集成到一起，通过自动化构建工具快速构建可执行文件。 测试：进行单元测试、集成测试和性能测试，以确保功能需求得到满足并检查系统稳定性。 部署：将经过测试的应用程序部署到目标环境中，可能涉及到多种平台和设备。 维护：定期监控系统表现，修复潜在问题，推送安全更新。 工具集成 工程管理：领导与协调项目，使用工具追踪软件开发进度和里程碑。 模型开发：用户可以创建和测试各种模型，进行系统仿真。 配置管理：用于软件版本控制，确保团队成员之间可以协同工作而不冲突。 环境设置 编辑环境与编译环境：提供友好的编辑界面，支持语法高亮、代码补全和即时编译反馈。 仿真环境：模拟设备和系统运行状态，帮助开发者理解代码行为。 信息浏览与重放调试：允许开发者查看过去的运行信息，并在重现错误时使用。 性能监控提供全面的监控工具，帮助开发者实时查看系统性能情况： 性能监视：监测 cpu 占用率、内存使用情况、端口和 IO 流量。 调度分析：对系统任务进行调度分析，以优化资源利用。 自动化工具 自动测试：集成各种自动化测试工具，减少人工干预，确保测试的可靠性与效率。 代码分析：静态代码分析工具帮助识别潜在的安全漏洞和性能瓶颈。 部署管理：通过脚本化的方式管理部署流程，确保一致性。 处理器支持情况天脉系统支持多种架构的处理器，确保可以满足多种类型项目的需求。 类型 型号（红色为国产处理器） 操作系统 PowerPC 440、HKSP6101、HKSP7101、860 系列 天脉 1 ARM V4 系列、V5 系列，ARM920T、ARM926E 天脉 1 x86 AtomCore i7 等 天脉 1天脉 2 MIPS 龙芯系列，LS2H、LS2K1000 天脉 1天脉 3 上述支持的处理器类型涵盖 PowerPC 的全系列，ARM 的主流型号，x86 架构和 MIPS 架构，有助于确保软件的广泛适用性。 能力扩展组件在 ACoreIDE 中，内置了丰富的能力扩展组件，支持不同的操作系统需求： 网络协议栈：自研的 TCPIP v4 和 v6 协议栈，确保网络通信的高效与可靠。 文件系统：包含 FAT 文件系统和网络文件系统，能够自如处理文件存储与共享。 系统中间件：如通用系统管理（GSM）和数据分发服务（DDS），提供核心服务。 生态建设天脉系统已经建成了满足航空装备应用需求的软件生态圈，能够支持复杂的航空系统和装备，同时确保系统的稳定性、安全性和可维护性。 通过这一系列的工具和功能的集成，ACoreIDE 不仅提升了软件开发的效率，也为开发者提供了丰富的资源和支持，使其能专注于实现创新与价值。","categories":["4.软件","航电"]},{"title":"ffmpeg-m3u8转mp4","path":"/2023/08/31/4-软件-音视频-ffmpeg-m3u8转mp4/","content":"FFmpeg 命令行工具将 m3u8 文件转换为 mp4 格式 下载并安装 FFmpeg可以从 官方网站 下载适合操作系统的版本。 打开命令行工具 在 Windows 上，可以按下 Win + R 键，然后输入 cmd 并按 Enter 键打开命令提示符。 在 Mac OS 或 Linux 上，可以打开终端应用程序。 转换 m3u8 文件在命令行中，导航到包含 m3u8 文件的目录，然后运行以下命令： ffmpeg -i input.m3u8 -c copy output.mp4 input.m3u8 是要转换的 m3u8 文件的名称，output.mp4 是转换后的 mp4 文件的名称。 该命令将使用 FFmpeg 将 m3u8 文件转换为 mp4 格式，并将其保存在相同的目录中。 请注意，此命令只能将 m3u8 文件转换为 mp4 格式，而不能将其中的视频文件下载到本地计算机。 如果需要下载 m3u8 文件中的视频文件，请使用其他工具或软件。 将分段式 m3u8 文件转换为 MP4 文件#!/bin/bashcd ./m3u8Movie #分段式m3u8文件所在文件夹for i in 1..2473 #轮询所有分段式文件数量do if [ -f $i ]; then #检测文件存在 mv $i $i.mp4 #重命名 fi echo file ./$i.mp4 list.txt #添加到列表中去done#调用ffmpeg进行视频连接操作ffmpeg -f concat -safe 0 -i list.txt -c copy ../movie.mp4#-f 指定输入格式为concat，表示要进行视频文件的连接操作#-safe 0 设置安全模式为0，允许使用不安全的文件名#-i 指定文本文件包含了要连接的视频文件的列表及其路径#-c 直接复制输入视频文件的音视频流，而不进行重新编码。这样可以加快处理速度而不损失质量。#指定输出文件路径和名称","categories":["4.软件","音视频"]},{"title":"TV BOX","path":"/2023/08/30/4-软件-音视频-TV-BOX/","content":"应用端TVBOXo0HalfLife0o 开源的 APK 可通过以下链接访问：TVBox APK。使用此应用程序前，首先需要配置其地址。前往应用的设置界面，找到”配置地址”选项，添加适合的视频源，确保能够顺利观看所需的内容。 ZY-PlayerZY-Player 是 another popular 应用程序，可以在 GitHub 上找到其源代码和安装包：ZY-Player。 视频源某些视频源因地址限制，可能无法直接访问。为了加速获取这些源，可以参考以下链接，帮助快速连接到视频内容。例如，可以使用 jsDelivr 和 Statically 提供的加速地址： jsDelivr 加速地址： ZY-Player-PC.json Statically 加速地址： ZY-Player-PC.json 集合以下是一些维护良好的 TVBox 接口项目，可以从中获取最新的视频源配置： YuanHsing 维护的 TVBOX 接口项目 另一个 TVBox 项目 备选项目 网站可以通过以下网站获取视频源配置，确保可以接入各类内容： 网站 地址 FongMi FongMi 配置 巧技 巧技 配置 俊于 俊于 配置 霜辉月明 霜辉月明 配置 小雅 小雅 配置 TVBox Cainisi 神器 神器每日推送 饭太硬 饭太硬 云星日记 云星日记 肥猫 肥猫 仓库以下是一些重要的开发者及其项目，可以在这些仓库中找到各类 TV 应用程序和接口： 唐三大佬的仓库：唐三仓库 巧技大佬的仓库：巧技仓库 俊于大佬、唐三大佬和影魔大佬的联合仓库：官方仓库 TV 猫盒：这个项目非常实用：猫盒项目 pluto-player：非开源项目，具备大量功能且支持在线升级，但目前不支持低版本安卓：pluto-player takagen99 项目：takagen99 o0HalfLife0o 项目：o0HalfLife0o AlphaTV 项目：AlphaTV clanTV 项目：clanTV FongMi-TV 项目：FongMi-TV BearTV：许多人提到的熊爱项目：BearTV 官方仓库，已于 2022 年 7 月 18 日封仓：官方仓库链接 多线路 TV 版本仓库：多线路 TV 版本 四角大神的仓库，部分内容已经被删除，但可以根据需要查看：四角大神仓库","categories":["4.软件","音视频"]},{"title":"音频播放","path":"/2023/08/29/4-软件-音视频-音频播放/","content":"Audio Control使用系统内置的播放功能调用系统的音频功能非常简单，使用以下命令可以直接播放音频文件： system(play wind.mp3) 该命令将调用本地系统的播放器以播放 wind.mp3 文件。确保文件路径正确且文件存在，以避免播放失败。 使用 FFMPEG 处理音频文件FFMPEG 是一个强大的音频和视频处理工具。可以使用简单的命令将不同格式的音频文件进行转换。以下是一些常用的转换命令： 将 MP3 转换为 WAV 格式将 MP3 文件转换为 WAV 格式，适合用在需要无损音质的场合。 ffmpeg -i input.mp3 -acodec pcm_s16le -ac 1 -ar 8000 output.wav 将 M4A 转换为 WAV 格式M4A 是一种常见的音频格式，此命令同样能够处理。 ffmpeg -i input.m4a -acodec pcm_s16le -ac 1 -ar 8000 output.wav WAV 与 PCM 的相互转换有时候需要在这两种格式之间进行转换，使用下列命令即可： ffmpeg -i input.wav -f s16le -ar 8000 -acodec pcm_s16le output.raw 将 PCM 数据转换为 WAV 格式将原始 PCM 数据文件转为更为通用的 WAV 格式： ffmpeg -f s16le -ar 8000 -ac 1 -acodec pcm_s16le -i input.raw output.wav 注释说明 -acodec pcm_s16le 选项指定使用 16 位 PCM 编码器，这是音频文件被广泛支持和使用的格式。 -f s16le 用于指定保存格式为 16 位 PCM 格式。 -ac 1 设置为单声道，通常在语音和简单音效中足够使用。 -ar 8000 指定了 8000Hz 的采样率，这样可以兼顾音质和文件大小。 使用 Qt 模块播放音频Qt 提供了多种模块用于音频播放，以下是使用 QSound 和 QMediaPlayer 模块的示例： 调用 QSound 模块确保在头文件中包含 QSound，并在项目文件中添加多媒体模块支持： #include QSound// 在 .pro 文件中QT += multimedia 播放音频文件的简单方法如下： QSound::play(./wind.mp3); 此命令将直接播放指定路径下的音频文件。 调用 QMediaPlayer 模块若需要更复杂的音频控制，则可使用 QMediaPlayer。示例代码如下： QString filePath = /home/forlinx/wind.mp3;if (!filePath.isEmpty()) player-setMedia(QUrl::fromLocalFile(filePath)); player-play(); 在这个示例中，如果给定的文件路径不为空，则设置媒体源，并开始播放。 考虑在需要更精细的音频控制时使用 QSoundEffect 或 QAudioOutput 类，这些类提供了更灵活的音效处理选项。 使用 GStreamer 工具GStreamer 是一个用于多媒体处理的框架，以下命令示例展示了如何使用其播放音频： system(gst-play-1.0 wind.mp3) 这条命令调用 GStreamer 的播放工具，播放指定的音频文件。确保 GStreamer 已安装，并且路径设置正确。 gst 源码/* * GStreamer命令行播放测试工具 */#include locale.h#include gst/gst.h#include stdlib.h#include stdio.h#include string.h#include math.h#include gst-play-kb.h#include gst/play/play.h// 定义音量步数，表示音量调节的细分程度#define VOLUME_STEPS 20// 定义调试分类GST_DEBUG_CATEGORY(play_debug);#define GST_CAT_DEFAULT play_debug// 定义播放器结构体，包含播放信息typedef struct gchar **uris; // 播放文件的 URI 列表 guint num_uris; // URI 的数量 gint cur_idx; // 当前播放的索引 GstPlay *player; // GStreamer 播放器实例 GstPlaySignalAdapter *signal_adapter; // 信号适配器 GstState desired_state; // 期望的状态 gboolean repeat; // 是否重复播放 GMainLoop *loop; // 主循环 Player;// 函数声明：播放下一个、上一个或重置播放static gboolean play_next(Player *play);static gboolean play_prev(Player *play);static void play_reset(Player *play);static void play_set_relative_volume(Player *play, gdouble volume_step);#include iostream// 输入输出流#include cstdint // 定义整数类型#include unistd.h// UNIX 标准函数#include fstream // 文件流操作// 使用结构体对 WAV 文件头进行对齐#pragma pack(1)struct WavHeader uint32_t id; // 文件标识符 uint32_t chunk_size; // 数据块大小 uint32_t form_type; // 文件格式类型 uint32_t fmt; // 格式标识符 uint32_t subchunk_size; // 子块大小 uint16_t audio_format; // 音频格式 uint16_t channel_nums; // 声道数 uint32_t sample_rate; // 采样率 uint32_t byte_rate; // 字节率 uint16_t block_align; // 数据块对齐 uint16_t bits_per_sample; // 每个样本的位数 uint32_t data; // 数据标识符 uint32_t data_size; // 数据大小;#pragma pack()// 设置主音量的函数void set_master_volume(long volume) long min, max; // 存储音量范围的变量 snd_mixer_t *handle; // 混音器句柄 snd_mixer_selem_id_t *sid; // 混音元素 ID const char *card = default; // 声卡类型 const char *selem_name = Master; // 声明名称 // 打开混音器 snd_mixer_open(handle, 0); snd_mixer_attach(handle, card); snd_mixer_selem_register(handle, NULL, NULL); snd_mixer_load(handle); // 分配并设置混音元素 ID snd_mixer_selem_id_alloca(sid); snd_mixer_selem_id_set_index(sid, 0); snd_mixer_selem_id_set_name(sid, selem_name); snd_mixer_elem_t *elem = snd_mixer_find_selem(handle, sid); // 查找混音元素 // 获取音量范围并设置主音量 snd_mixer_selem_get_playback_volume_range(elem, min, max); snd_mixer_selem_set_playback_volume_all(elem, volume * max / 100); // 将音量转换为实际值 // 关闭混音器 snd_mixer_close(handle);// 主函数：程序的入口int main(int argc, char **argv) // 检查是否提供了足够的命令行参数 if (argc 2) std::cout std::string(argv[0]) wav_file_path std::endl; // 提示如何使用程序 return -1; // 退出程序 std::string wav_file_name(argv[1]); // 获取 WAV 文件名 static voidend_of_stream_cb (GstPlaySignalAdapter * adapter, Player * play) gst_print ( ); /* and switch to next item in list */ if (!play_next (play)) gst_print (Reached end of play list. ); g_main_loop_quit (play-loop); static voiderror_cb (GstPlaySignalAdapter * adapter, GError * err, Player * play) gst_printerr (ERROR %s for %s , err-message, play-uris[play-cur_idx]); /* if looping is enabled, then disable it else will keep looping forever */ play-repeat = FALSE; /* try next item in list then */ if (!play_next (play)) gst_print (Reached end of play list. ); g_main_loop_quit (play-loop); static voidposition_updated_cb (GstPlaySignalAdapter * adapter, GstClockTime pos, Player * play) GstClockTime dur = -1; gchar status[64] = 0, ; g_object_get (play-player, duration, dur, NULL); memset (status, , sizeof (status) - 1); if (pos != -1 dur 0 dur != -1) gchar dstr[32], pstr[32]; /* FIXME: pretty print in nicer format */ g_snprintf (pstr, 32, % GST_TIME_FORMAT, GST_TIME_ARGS (pos)); pstr[9] = \\0; g_snprintf (dstr, 32, % GST_TIME_FORMAT, GST_TIME_ARGS (dur)); dstr[9] = \\0; gst_print (%s / %s %s\\r, pstr, dstr, status); static voidstate_changed_cb (GstPlaySignalAdapter * adapter, GstPlayState state, Player * play) gst_print (State changed: %s , gst_play_state_get_name (state));static voidbuffering_cb (GstPlaySignalAdapter * adapter, gint percent, Player * play) gst_print (Buffering: %d , percent);static voidprint_one_tag (const GstTagList * list, const gchar * tag, gpointer user_data) gint i, num; num = gst_tag_list_get_tag_size (list, tag); for (i = 0; i num; ++i) const GValue *val; val = gst_tag_list_get_value_index (list, tag, i); if (G_VALUE_HOLDS_STRING (val)) gst_print ( %s : %s , tag, g_value_get_string (val)); else if (G_VALUE_HOLDS_UINT (val)) gst_print ( %s : %u , tag, g_value_get_uint (val)); else if (G_VALUE_HOLDS_DOUBLE (val)) gst_print ( %s : %g , tag, g_value_get_double (val)); else if (G_VALUE_HOLDS_BOOLEAN (val)) gst_print ( %s : %s , tag, g_value_get_boolean (val) ? true : false); else if (GST_VALUE_HOLDS_DATE_TIME (val)) GstDateTime *dt = g_value_get_boxed (val); gchar *dt_str = gst_date_time_to_iso8601_string (dt); gst_print ( %s : %s , tag, dt_str); g_free (dt_str); else gst_print ( %s : tag of type %s , tag, G_VALUE_TYPE_NAME (val)); static voidprint_video_info (GstPlayVideoInfo * info) gint fps_n, fps_d; guint par_n, par_d; if (info == NULL) return; gst_print ( width : %d , gst_play_video_info_get_width (info)); gst_print ( height : %d , gst_play_video_info_get_height (info)); gst_print ( max_bitrate : %d , gst_play_video_info_get_max_bitrate (info)); gst_print ( bitrate : %d , gst_play_video_info_get_bitrate (info)); gst_play_video_info_get_framerate (info, fps_n, fps_d); gst_print ( framerate : %.2f , (gdouble) fps_n / fps_d); gst_play_video_info_get_pixel_aspect_ratio (info, par_n, par_d); gst_print ( pixel-aspect-ratio %u:%u , par_n, par_d);static voidprint_audio_info (GstPlayAudioInfo * info) if (info == NULL) return; gst_print ( sample rate : %d , gst_play_audio_info_get_sample_rate (info)); gst_print ( channels : %d , gst_play_audio_info_get_channels (info)); gst_print ( max_bitrate : %d , gst_play_audio_info_get_max_bitrate (info)); gst_print ( bitrate : %d , gst_play_audio_info_get_bitrate (info)); gst_print ( language : %s , gst_play_audio_info_get_language (info));static voidprint_subtitle_info (GstPlaySubtitleInfo * info) if (info == NULL) return; gst_print ( language : %s , gst_play_subtitle_info_get_language (info));static voidprint_all_stream_info (GstPlayMediaInfo * media_info) guint count = 0; GList *list, *l; gst_print (URI : %s , gst_play_media_info_get_uri (media_info)); gst_print (Duration: % GST_TIME_FORMAT , GST_TIME_ARGS (gst_play_media_info_get_duration (media_info))); gst_print (Global taglist: ); if (gst_play_media_info_get_tags (media_info)) gst_tag_list_foreach (gst_play_media_info_get_tags (media_info), print_one_tag, NULL); else gst_print ( (nil) ); list = gst_play_media_info_get_stream_list (media_info); if (!list) return; gst_print (All Stream information ); for (l = list; l != NULL; l = l-next) GstTagList *tags = NULL; GstPlayStreamInfo *stream = (GstPlayStreamInfo *) l-data; gst_print ( Stream # %u , count++); gst_print ( type : %s_%u , gst_play_stream_info_get_stream_type (stream), gst_play_stream_info_get_index (stream)); tags = gst_play_stream_info_get_tags (stream); gst_print ( taglist : ); if (tags) gst_tag_list_foreach (tags, print_one_tag, NULL); if (GST_IS_PLAY_VIDEO_INFO (stream)) print_video_info ((GstPlayVideoInfo *) stream); else if (GST_IS_PLAY_AUDIO_INFO (stream)) print_audio_info ((GstPlayAudioInfo *) stream); else print_subtitle_info ((GstPlaySubtitleInfo *) stream); static voidprint_all_video_stream (GstPlayMediaInfo * media_info) GList *list, *l; list = gst_play_media_info_get_video_streams (media_info); if (!list) return; gst_print (All video streams ); for (l = list; l != NULL; l = l-next) GstPlayVideoInfo *info = (GstPlayVideoInfo *) l-data; GstPlayStreamInfo *sinfo = (GstPlayStreamInfo *) info; gst_print ( %s_%d # , gst_play_stream_info_get_stream_type (sinfo), gst_play_stream_info_get_index (sinfo)); print_video_info (info); static voidprint_all_subtitle_stream (GstPlayMediaInfo * media_info) GList *list, *l; list = gst_play_media_info_get_subtitle_streams (media_info); if (!list) return; gst_print (All subtitle streams: ); for (l = list; l != NULL; l = l-next) GstPlaySubtitleInfo *info = (GstPlaySubtitleInfo *) l-data; GstPlayStreamInfo *sinfo = (GstPlayStreamInfo *) info; gst_print ( %s_%d # , gst_play_stream_info_get_stream_type (sinfo), gst_play_stream_info_get_index (sinfo)); print_subtitle_info (info); static voidprint_all_audio_stream (GstPlayMediaInfo * media_info) GList *list, *l; list = gst_play_media_info_get_audio_streams (media_info); if (!list) return; gst_print (All audio streams: ); for (l = list; l != NULL; l = l-next) GstPlayAudioInfo *info = (GstPlayAudioInfo *) l-data; GstPlayStreamInfo *sinfo = (GstPlayStreamInfo *) info; gst_print ( %s_%d # , gst_play_stream_info_get_stream_type (sinfo), gst_play_stream_info_get_index (sinfo)); print_audio_info (info); static voidprint_current_tracks (Player * play) GstPlayAudioInfo *audio = NULL; GstPlayVideoInfo *video = NULL; GstPlaySubtitleInfo *subtitle = NULL; gst_print (Current video track: ); video = gst_play_get_current_video_track (play-player); print_video_info (video); gst_print (Current audio track: ); audio = gst_play_get_current_audio_track (play-player); print_audio_info (audio); gst_print (Current subtitle track: ); subtitle = gst_play_get_current_subtitle_track (play-player); print_subtitle_info (subtitle); if (audio) g_object_unref (audio); if (video) g_object_unref (video); if (subtitle) g_object_unref (subtitle);static voidprint_media_info (GstPlayMediaInfo * media_info) print_all_stream_info (media_info); gst_print ( ); print_all_video_stream (media_info); gst_print ( ); print_all_audio_stream (media_info); gst_print ( ); print_all_subtitle_stream (media_info);static voidmedia_info_cb (GstPlaySignalAdapter * adapter, GstPlayMediaInfo * info, Player * play) static int once = 0; if (!once) print_media_info (info); print_current_tracks (play); once = 1; static Player *play_new (gchar ** uris, gdouble initial_volume) Player *play; play = g_new0 (Player, 1); play-uris = uris; play-num_uris = g_strv_length (uris); play-cur_idx = -1; play-player = gst_play_new (NULL); play-loop = g_main_loop_new (NULL, FALSE); play-desired_state = GST_STATE_PLAYING; play-signal_adapter = gst_play_signal_adapter_new_with_main_context (play-player, g_main_loop_get_context (play-loop)); g_signal_connect (play-signal_adapter, position-updated, G_CALLBACK (position_updated_cb), play); g_signal_connect (play-signal_adapter, state-changed, G_CALLBACK (state_changed_cb), play); g_signal_connect (play-signal_adapter, buffering, G_CALLBACK (buffering_cb), play); g_signal_connect (play-signal_adapter, end-of-stream, G_CALLBACK (end_of_stream_cb), play); g_signal_connect (play-signal_adapter, error, G_CALLBACK (error_cb), play); g_signal_connect (play-signal_adapter, media-info-updated, G_CALLBACK (media_info_cb), play); play_set_relative_volume (play, initial_volume - 1.0); return play;static voidplay_free (Player * play) play_reset (play); g_clear_object (play-signal_adapter); gst_object_unref (play-player); g_main_loop_unref (play-loop); g_strfreev (play-uris); g_free (play);/* reset for new file/stream */static voidplay_reset (Player * play)static voidplay_set_relative_volume (Player * play, gdouble volume_step) gdouble volume; g_object_get (play-player, volume, volume, NULL); volume = round ((volume + volume_step) * VOLUME_STEPS) / VOLUME_STEPS; volume = CLAMP (volume, 0.0, 10.0); g_object_set (play-player, volume, volume, NULL); gst_print (Volume: %.0f%% , volume * 100);static gchar *play_uri_get_display_name (Player * play, const gchar * uri) gchar *loc; if (gst_uri_has_protocol (uri, file)) loc = g_filename_from_uri (uri, NULL, NULL); else if (gst_uri_has_protocol (uri, pushfile)) loc = g_filename_from_uri (uri + 4, NULL, NULL); else loc = g_strdup (uri); /* Maybe additionally use glibs filename to display name function */ return loc;static voidplay_uri (Player * play, const gchar * next_uri) gchar *loc; play_reset (play); loc = play_uri_get_display_name (play, next_uri); gst_print (Now playing %s , loc); g_free (loc); g_object_set (play-player, uri, next_uri, NULL); gst_play_play (play-player);/* returns FALSE if we have reached the end of the playlist */static gbooleanplay_next (Player * play) if ((play-cur_idx + 1) = play-num_uris) if (play-repeat) gst_print (Looping playlist ); play-cur_idx = -1; else return FALSE; play_uri (play, play-uris[++play-cur_idx]); return TRUE;/* returns FALSE if we have reached the beginning of the playlist */static gbooleanplay_prev (Player * play) if (play-cur_idx == 0 || play-num_uris = 1) return FALSE; play_uri (play, play-uris[--play-cur_idx]); return TRUE;static voiddo_play (Player * play) gint i; /* dump playlist */ for (i = 0; i play-num_uris; ++i) GST_INFO (%4u : %s, i, play-uris[i]); if (!play_next (play)) return; g_main_loop_run (play-loop);static voidadd_to_playlist (GPtrArray * playlist, const gchar * filename) GDir *dir; gchar *uri; if (gst_uri_is_valid (filename)) g_ptr_array_add (playlist, g_strdup (filename)); return; if ((dir = g_dir_open (filename, 0, NULL))) const gchar *entry; /* FIXME: sort entries for each directory? */ while ((entry = g_dir_read_name (dir))) gchar *path; path = g_strconcat (filename, G_DIR_SEPARATOR_S, entry, NULL); add_to_playlist (playlist, path); g_free (path); g_dir_close (dir); return; uri = gst_filename_to_uri (filename, NULL); if (uri != NULL) g_ptr_array_add (playlist, uri); else g_warning (Could not make URI out of filename %s, filename);static voidshuffle_uris (gchar ** uris, guint num) gchar *tmp; guint i, j; if (num 2) return; for (i = 0; i num; i++) /* gets equally distributed random number in 0..num-1 [0;num[ */ j = g_random_int_range (0, num); tmp = uris[j]; uris[j] = uris[i]; uris[i] = tmp; static voidrestore_terminal (void) gst_play_kb_set_key_handler (NULL, NULL);static voidtoggle_paused (Player * play) if (play-desired_state == GST_STATE_PLAYING) play-desired_state = GST_STATE_PAUSED; gst_play_pause (play-player); else play-desired_state = GST_STATE_PLAYING; gst_play_play (play-player); static voidrelative_seek (Player * play, gdouble percent) gint64 dur = -1, pos = -1; g_return_if_fail (percent = -1.0 percent = 1.0); g_object_get (play-player, position, pos, duration, dur, NULL); if (dur = 0) gst_print ( Could not seek. ); return; pos = pos + dur * percent; if (pos 0) pos = 0; gst_play_seek (play-player, pos);static voidkeyboard_cb (const gchar * key_input, gpointer user_data) Player *play = (Player *) user_data; switch (g_ascii_tolower (key_input[0])) case i: GstPlayMediaInfo *media_info = gst_play_get_media_info (play-player); if (media_info) print_media_info (media_info); g_object_unref (media_info); print_current_tracks (play); break; case : toggle_paused (play); break; case q: case Q: g_main_loop_quit (play-loop); break; case : if (!play_next (play)) gst_print ( Reached end of play list. ); g_main_loop_quit (play-loop); break; case : play_prev (play); break; case 27: /* ESC */ if (key_input[1] == \\0) g_main_loop_quit (play-loop); break; /* fall through */ default: if (strcmp (key_input, GST_PLAY_KB_ARROW_RIGHT) == 0) relative_seek (play, +0.08); else if (strcmp (key_input, GST_PLAY_KB_ARROW_LEFT) == 0) relative_seek (play, -0.01); else if (strcmp (key_input, GST_PLAY_KB_ARROW_UP) == 0) play_set_relative_volume (play, +1.0 / VOLUME_STEPS); else if (strcmp (key_input, GST_PLAY_KB_ARROW_DOWN) == 0) play_set_relative_volume (play, -1.0 / VOLUME_STEPS); else GST_INFO (keyboard input:); for (; *key_input != \\0; ++key_input) GST_INFO ( code %3d, *key_input); break; intmain (int argc, char **argv) Player *play; GPtrArray *playlist; gboolean print_version = FALSE; gboolean interactive = FALSE; /* FIXME: maybe enable by default? */ gboolean shuffle = FALSE; gboolean repeat = FALSE; gdouble volume = 1.0; gchar **filenames = NULL; gchar **uris; guint num, i; GError *err = NULL; GOptionContext *ctx; gchar *playlist_file = NULL; GOptionEntry options[] = version, 0, 0, G_OPTION_ARG_NONE, print_version, Print version information and exit, NULL, shuffle, 0, 0, G_OPTION_ARG_NONE, shuffle, Shuffle playlist, NULL, interactive, 0, 0, G_OPTION_ARG_NONE, interactive, Interactive control via keyboard, NULL, volume, 0, 0, G_OPTION_ARG_DOUBLE, volume, Volume, NULL, playlist, 0, 0, G_OPTION_ARG_FILENAME, playlist_file, Playlist file containing input media files, NULL, loop, 0, 0, G_OPTION_ARG_NONE, repeat, Repeat all, NULL, G_OPTION_REMAINING, 0, 0, G_OPTION_ARG_FILENAME_ARRAY, filenames, NULL, NULL ; g_set_prgname (gst-play); ctx = g_option_context_new (FILE1|URI1 [FILE2|URI2] [FILE3|URI3] ...); g_option_context_add_main_entries (ctx, options, NULL); g_option_context_add_group (ctx, gst_init_get_option_group ()); if (!g_option_context_parse (ctx, argc, argv, err)) gst_print (Error initializing: %s , GST_STR_NULL (err-message)); g_clear_error (err); g_option_context_free (ctx); return 1; g_option_context_free (ctx); GST_DEBUG_CATEGORY_INIT (play_debug, play, 0, gst-play); if (print_version) gchar *version_str; version_str = gst_version_string (); gst_print (%s version %s , g_get_prgname (), 1.0); gst_print (%s , version_str); g_free (version_str); g_free (playlist_file); return 0; playlist = g_ptr_array_new (); if (playlist_file != NULL) gchar *playlist_contents = NULL; gchar **lines = NULL; if (g_file_get_contents (playlist_file, playlist_contents, NULL, err)) lines = g_strsplit (playlist_contents, , 0); num = g_strv_length (lines); for (i = 0; i num; i++) if (lines[i][0] != \\0) GST_LOG (Playlist[%d]: %s, i + 1, lines[i]); add_to_playlist (playlist, lines[i]); g_strfreev (lines); g_free (playlist_contents); else gst_printerr (Could not read playlist: %s , err-message); g_clear_error (err); g_free (playlist_file); playlist_file = NULL; if (playlist-len == 0 (filenames == NULL || *filenames == NULL)) gst_printerr (Usage: %s FILE1|URI1 [FILE2|URI2] [FILE3|URI3] ..., gst-play); gst_printerr ( ), gst_printerr (%s , You must provide at least one filename or URI to play.); /* No input provided. Free array */ g_ptr_array_free (playlist, TRUE); return 1; /* fill playlist */ if (filenames != NULL *filenames != NULL) num = g_strv_length (filenames); for (i = 0; i num; ++i) GST_LOG (command line argument: %s, filenames[i]); add_to_playlist (playlist, filenames[i]); g_strfreev (filenames); num = playlist-len; g_ptr_array_add (playlist, NULL); uris = (gchar **) g_ptr_array_free (playlist, FALSE); if (shuffle) shuffle_uris (uris, num); /* prepare */ play = play_new (uris, volume); play-repeat = repeat; if (interactive) if (gst_play_kb_set_key_handler (keyboard_cb, play)) atexit (restore_terminal); else gst_print (Interactive keyboard handling in terminal not available. ); /* play */ do_play (play); /* clean up */ play_free (play); gst_print ( ); gst_deinit (); return 0; 调用 ALSA 和 PCM 播放#include alsa/asoundlib.h#include iostream#include cstdint#include unistd.h#include fstream#pragma pack(1)struct WavHeader uint32_t id; uint32_t chunk_size; uint32_t form_type; uint32_t fmt; uint32_t subchunk_size; uint16_t audio_format; uint16_t channel_nums; uint32_t sample_rate; uint32_t byte_rate; uint16_t block_align; uint16_t bits_per_sample; uint32_t data; uint32_t data_size;;#pragma pack()void set_master_volume(long volume) long min, max; snd_mixer_t *handle; snd_mixer_selem_id_t *sid; const char *card = default; const char *selem_name = Master; snd_mixer_open(handle, 0); snd_mixer_attach(handle, card); snd_mixer_selem_register(handle, NULL, NULL); snd_mixer_load(handle); snd_mixer_selem_id_alloca(sid); snd_mixer_selem_id_set_index(sid, 0); snd_mixer_selem_id_set_name(sid, selem_name); snd_mixer_elem_t* elem = snd_mixer_find_selem(handle, sid); snd_mixer_selem_get_playback_volume_range(elem, min, max); snd_mixer_selem_set_playback_volume_all(elem, volume * max / 100); snd_mixer_close(handle);int main(int argc, char **argv) if(argc 2) std::cout std::string(argv[0]) wav_file_path std::endl; return -1; std::string wav_file_name(argv[1]); if(access(wav_file_name.c_str(), F_OK) != 0) std::cout File ( wav_file_name ) not exist! std::endl; return -1; // open wav file std::fstream wav(wav_file_name, std::ios_base::in|std::ios::binary ); if(wav.fail()) std::cout wav_file_name open failed! std::endl; return -1; // parse wav file WavHeader wav_header; wav.read((char*)wav_header, sizeof(wav_header)); if(wav.fail()) std::cout Read file failed! std::endl; return -1; if(wav_header.id != (uint32_t)0x46464952 or wav_header.fmt != (u_int32_t)0x20746d66 \\ or wav_header.audio_format != 1) std::cout std::hex wav_header.id std::endl; std::cout std::hex wav_header.fmt std::endl; std::cout std::hex wav_header.data std::endl; std::cout audio format: wav_header.audio_format std::endl; // audio format 为1 表示 std::cout File format error! std::endl; return -1; //summary std::cout sample_rate: wav_header.sample_rate std::endl; std::cout bit per sample: wav_header.bits_per_sample std::endl; std::cout channel nums: wav_header.channel_nums std::endl; set_master_volume(99); // 99% // play audio int err; unsigned int i; snd_pcm_t *handle; snd_pcm_sframes_t frames; std::string device(default); unsigned char buffer[512]; if ((err = snd_pcm_open(handle, device.c_str(), SND_PCM_STREAM_PLAYBACK, 0)) 0) printf(Playback open error: %s , snd_strerror(err)); exit(EXIT_FAILURE); snd_pcm_format_t pcm_format; switch (wav_header.bits_per_sample) case 8: pcm_format = SND_PCM_FORMAT_S8; break; case 16: pcm_format = SND_PCM_FORMAT_S16_LE; break; case 32: pcm_format = SND_PCM_FORMAT_S32_LE; break; default: break; if ((err = snd_pcm_set_params(handle, pcm_format, SND_PCM_ACCESS_RW_INTERLEAVED, wav_header.channel_nums, wav_header.sample_rate, 1, 500000)) 0) /* 0.5sec */ printf(Playback open error: %s , snd_strerror(err)); exit(EXIT_FAILURE); while (true) wav.read((char *)buffer, 512); if(wav.gcount() = 0) std::cout END std::endl; break; frames = snd_pcm_writei(handle, buffer, wav.gcount()/(wav_header.bits_per_sample * 2 / 8)); if (frames 0) frames = snd_pcm_recover(handle, frames, 0); if (frames 0) printf(snd_pcm_writei failed: %s , snd_strerror(frames)); break; if(wav.gcount() != 512) std::cout END std::endl; break; /* pass the remaining samples, otherwise theyre dropped in close */ err = snd_pcm_drain(handle); if (err 0) printf(snd_pcm_drain failed: %s , snd_strerror(err)); snd_pcm_close(handle);","categories":["4.软件","音视频"]},{"title":"健康","path":"/2023/08/28/5-生活-健康-健康/","content":"子时—胆经—23:00-1:00 丑时—肝经—1:00-3:00 寅时—肺经—3:00-5:00 卯时—大肠经—5:00-7:00 辰时—胃经—7:00-9:00 巳时—脾经—9:00-11:00 午时—心经—11:00-13:00 未时—小肠经—13:00-15:00 申时—膀胱经—15:00-17:00 酉时—肾经—17:00-19:00 戌时—心包经—19:00-21:00 亥时—三焦经—21:00-23:00","categories":["5.生活","健康"]},{"title":"阳台菜圃","path":"/2023/08/25/5-生活-健康-阳台菜圃/","content":"每天上街买菜确实令人感到烦躁，尤其是在繁忙的工作日或是烈日炎炎的夏天。如果不想再为这事操心，其实只需一个不用的垃圾桶，就能在家享用自己种的新鲜蔬菜。试想一下，那些香嫩的生菜、脆爽的芹菜，甚至大蒜，都能在阳台上生长，甚至可以畅想着，一年都不需要再上街买菜，享受自给自足的乐趣。 垃圾桶并不仅仅是用来装垃圾的，它其实是一个被错误用途耽误的种菜神器。相信，如果不信，可以亲自尝试！以下是具体的操作步骤： 准备垃圾桶种大蒜 选择工具：准备一个网状的垃圾桶和一个适合的垃圾袋。 装土：将垃圾袋稳妥地套在垃圾桶上，并在里面装满土壤。 处理大蒜： 取一盘剥好的大蒜。 用剪刀在垃圾桶的网口上扎几个小洞。 将大蒜小心地从洞口塞进去，确保大蒜尖向外。 浇水：在垃圾桶的四周和顶部喷洒适量的水，保持土壤湿润。 只需等待，随着时间的推移，将收获丰硕的大蒜。 替代方法：空油桶如果觉得用垃圾桶过于麻烦，可以用一个空油桶来种大蒜。将油桶的外侧标记出几个合适的位置，用刀轻轻划开，之后同样装土，把大蒜植入。喷些水，完成后就等着收成吧！ 更简单的方法如果觉得上述步骤太复杂，馆长推荐一种更简单的方法：用矿泉水瓶种大蒜。将矿泉水瓶剪开，把底部倒过来，装满水，然后将完整的大蒜放进瓶中，定期浇水，会看到大蒜一天天生长，甚至能收获新鲜的蒜苗。 水培其他蔬菜很多人认为只有大片土地才能种菜，实际上，有些蔬菜如芹菜、葱等，在家中也能轻松实现水培： 芹菜：切下芹菜根部，使用牙签支起根部，将其浸入水中。等根须生长后，可以移栽到土壤中，迅速成长。 葱：将葱根部切下，放在清水中浸泡，待根须发达后换个大杯，浇水并保持根须浸泡，葱叶长高了就可以随意剪取，方便又实用。 此外，生菜、胡萝卜、红薯、土豆、菠萝等都可以使用相同的方法来种植，想象一下，一年下来能够省下的买菜钱。 生姜生姜既可以盆栽，也可以水培，相对水培要简单一点，而且更直观，可以看到生姜的长势，当然，想要观察生姜的长势最好找一个透明的容器，在容器里装水，然后把发芽的生姜放在容器上，并且能够接触到水分就行。 水培的生姜不要晒大太阳，水容易浑浊，水会晒热，不利于生姜生长，因此，水培容器摆放在散光处即可，养护一段时间之后，生姜会长出根系，而且茎也会越来越粗壮，不亚于一盆水培观赏植物。 除了水培，生姜还可以盆栽种植，盆栽种植的时候，为了增加土壤的肥沃度，可以在土壤中混合适量的腐熟肥，更利于生姜的生长。 盆栽种植生姜的时候，记得要将生姜的芽点要朝上，这样有利于发芽，然后把生姜的三分之一埋进土壤里，适量浇水，摆放在散光、通风的地方。等到生姜生长 2 个月后，看到生姜的茎叶变黄，就能采收了。不过，采收的时候别都挖出来，留一些生姜，它还会继续生长。如此反复，就有新鲜的生姜吃啦！ 虽然生姜的种植比较容易，但是在养护过程中还是需要注意一些事项。首先是水分的管理，生姜喜欢湿润的环境，但也不要过于浇水，以免造成根部腐烂。 其次，是光照的管理，生姜比较喜欢散光的环境，避免暴晒或长时间处于阴暗潮湿的环境中。另外，在生长过程中需要适当施肥，可以选择一些有机肥料进行施用。 天然肥料 DIY在种植的过程中，肥料扮演着至关重要的角色。值得庆幸的是，们家中常见的物品也可以转变为优质的有机肥料，帮助们在保持土壤健康的同时，保护环境。自制肥料不仅给土壤提供了丰富的营养，还能有效预防害虫，实现废物利用，达到一举两得的效果。 鸡蛋壳把不用的鸡蛋壳收集起来，用勺子将鸡蛋壳碾碎，撒在种菜的盆里，最后用土将鸡蛋壳覆盖。 淘米水经常淘米的家庭，不妨将淘米水用于浇灌蔬菜。淘米水经过发酵后会转化为有机肥料，能够改善土壤结构，促使植物更加茁壮成长。制作方法非常简单： 收集淘米水：将淘米时产生的水收集在一个空坛子里。 发酵：将坛子密封好，放在阴凉处，静置约两周。这一过程让淘米水中的营养物质得以转化和浓缩。 稀释使用：发酵完成后，打开坛子，会发现淘米水的颜色变得更深了。接下来，向发酵的淘米水中添加大量清水，大约 70%~80 的水量进行稀释。此时，的有机肥料就制作完成了。 施肥方式：用稀释后的淘米水浇灌蔬菜时，建议将水顺着蔬菜的根部浇灌，避免直接浇在菜叶上，防止叶面受损。 香蕉皮吃完香蕉后，别急着扔掉香蕉皮。香蕉皮富含钾元素，能够有效促进植物开花和果实的生长，只需将其切小块后，直接埋入土壤中，便可快速腐烂并被根系吸收。实际上，除了香蕉皮，各种果皮（如橙子、苹果皮）、厨房剩菜、甚至树叶等都可以作为天然肥料，帮助提升土壤的营养价值。 茶叶茶叶在发酵过程中，能够显著增加土壤中的铵态氮和硝态氮含量，这两种养分对植物的生长至关重要。将发酵后的茶叶倒入土壤中，可以提升土壤肥力，改善土壤的结构，使其变得更为松软，利于植物的生长和根系的扩展。 这些自制肥料的制作过程简单易行，只需动手利用身边的废物，便能为的花园和菜园增添不少的生机与活力。在施肥的过程中，不仅可以体验到土壤改良的乐趣，还能为家里的植物带来健康成长的保障。","categories":["5.生活","健康"]},{"title":"MIUI下载","path":"/2023/08/24/5-生活-手机相机游戏机-MIUI下载/","content":"MIUI 镜像下载缓慢 将原来下载链接中的网址替换为 https://bkt-sgp-miui-ota-update-alisgp.oss-ap-southeast-1.aliyuncs.com/V14.0.8.0.TKKCNXM/haydn_images_V14.0.8.0.TKKCNXM_20231226.0000.00_13.0_cn_de34d63e97.tgz","categories":["5.生活","手机相机游戏机"]},{"title":"华为手机ADB","path":"/2023/08/23/5-生活-手机相机游戏机-华为手机ADB/","content":"设备连接//列出设备adb devices//列出第三方包名adb shell pm list package -3//列出系统包名adb shell pm list package -s 卸载Part 1 卸载REM 华为的蓝牙手写笔管理程序，适配华为旗下支持手写笔的设备 adb shell pm uninstall --user 0 com.huawei.hwbluetoothpencilmanagerREM 华为的便捷生活服务类应用，整合周边生活服务、出行服务等功能adb shell pm uninstall --user 0 com.huawei.easygoREM 鸿蒙系统的协作中心服务，推动鸿蒙生态设备协同作业adb shell pm uninstall --user 0 com.huawei.ohos.collaborationcenterREM 视频编辑adb shell pm uninstall --user 0 com.huawei.videoeditorREM 华为视频Appadb shell pm uninstall --user 0 com.huawei.himovieREM 华为视频App - 腾讯视频模块adb shell pm uninstall --user 0 com.tencent.qqlivehuaweiREM 华为视频App - 搜狐视频模块adb shell pm uninstall --user 0 com.sohu.sohuvideo.emplayerREM 手机克隆Appadb shell pm uninstall --user 0 com.hicloud.android.cloneREM 镜子Appadb shell pm uninstall --user 0 com.huawei.mirrorREM 智能提醒Appadb shell pm uninstall --user 0 com.huawei.tipsREM 玩机技巧Appadb shell pm uninstall --user 0 com.huawei.android.tipsREM 卸载竞品推荐,纯广告adb shell pm uninstall --user 0 com.huawei.hifolderREM 教育中心Appadb shell pm uninstall --user 0 com.huawei.educenterREM 天际通Appadb shell pm uninstall --user 0 com.huawei.hiskytoneREM 天际通服务adb shell pm uninstall --user 0 com.huawei.skytoneREM 华为的推荐系统服务，为用户个性化推荐应用、内容adb shell pm uninstall --user 0 com.huawei.recsysREM 游戏中心App,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.gameboxREM GameKit服务,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.game.kitserverREM 应用助手服务,其实就是游戏助手,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.gameassistantREM 运动健康Appadb shell pm uninstall --user 0 com.huawei.healthREM [HarmongOS]运动健康Appadb shell pm uninstall --user 0 com.huawei.ohos.healthREM 手写笔应用专区Appadb shell pm uninstall --user 0 com.huawei.stylus.mpenzoneREM 手写笔悬浮窗服务adb shell pm uninstall --user 0 com.huawei.stylus.floatmenuREM 华为钱包Appadb shell pm uninstall --user 0 com.huawei.walletREM 华为钱包的软件开发工具包，用于开发钱包相关应用adb shell pm uninstall --user 0 com.huawei.wallet.sdk.walletsdkREM 银联可信服务安全组件,给华为钱包调用的安全组件adb shell pm uninstall --user 0 com.unionpay.tsmserviceREM 华为浏览器Appadb shell pm uninstall --user 0 com.huawei.browserREM 智慧助手·今天服务,负一屏的垃圾广告adb shell pm uninstall --user 0 com.huawei.intelligentREM 杂志锁屏adb shell pm uninstall --user 0 com.huawei.magazineREM 华为快应用相关服务，无需安装，快速打开轻量化应用adb shell pm uninstall --user 0 com.huawei.fastappREM 华为的一款名为“paradise”的动态壁纸应用adb shell pm uninstall --user 0 com.huawei.livewallpaper.paradiseREM 华为音乐Appadb shell pm uninstall --user 0 com.android.mediacenterREM 旅行助手adb shell pm uninstall --user 0 com.huawei.scenepackREM K 歌特效adb shell pm uninstall --user 0 com.huawei.android.karaokeREM 安卓系统SIM卡应用相关弹窗服务，提示SIM卡相关信息adb shell pm uninstall --user 0 com.android.simappdialogREM SIM 卡应用Appadb shell pm uninstall --user 0 com.android.stk Part 2 保留@echo offREM 华为安全相关服务，可能涉及数据安全防护、风险检测的模块 ，助力保障手机系统安全adb shell pm uninstall --user 0 com.huawei.security.hsdrREM Android兼容性测试套件（CTS）的相关隐私模拟或适配组件用来检测系统隐私策略兼容性adb shell pm uninstall --user 0 com.android.cts.priv.ctsshimREM 华为手机原生相机应用，用于拍照、录像、专业摄影模式等各类影像捕捉功能adb shell pm uninstall --user 0 com.huawei.cameraREM 华为相机功能实现的底层工具包，辅助相机应用完成各类拍摄功能实现adb shell pm uninstall --user 0 com.huawei.camerakit.implREM 华为设备协同相关服务，让华为的不同终端之间实现互联互通、高效协作 adb shell pm uninstall --user 0 com.huawei.synergyREM 华为手机的桌面启动器，决定桌面布局、图标排列、快捷方式设定等外观与交互adb shell pm uninstall --user 0 com.huawei.android.launcherREM 华为移动服务（HMS）里的应用动态更新引擎，负责后台静默更新应用adb shell pm uninstall --user 0 com.huawei.hms.dupdateengineREM 安卓系统的电话信息存储与提供服务，管理联系人、通话记录等数据adb shell pm uninstall --user 0 com.android.providers.telephonyREM 银联可信服务管理模块（TSM）相关服务，关联银联卡支付、移动支付安全服务adb shell pm uninstall --user 0 com.unionpay.tsmserviceREM 鸿蒙操作系统的基础框架组件，支撑整个鸿蒙系统的底层运行逻辑adb shell pm uninstall --user 0 com.huawei.harmonyos.foundationREM 华为安卓系统下用于检测用户体验（UE）相关信息的工具，辅助优化系统adb shell pm uninstall --user 0 com.huawei.android.UEInfoCheckREM 华为的预览相关服务，比如图片、文档快速预览功能模块adb shell pm uninstall --user 0 com.huawei.hwpreviewREM 安卓系统的日历数据存储与提供服务，保存日程提醒等日历相关信息adb shell pm uninstall --user 0 com.android.providers.calendarREM 华为的特性分层框架，用来整合、管理各类特色功能模块adb shell pm uninstall --user 0 com.huawei.featurelayer.featureframeworkREM 华为智卡相关服务，集成电子身份证、交通卡等各类卡片模拟功能adb shell pm uninstall --user 0 com.huawei.hicardREM 华为的存储盘管理服务，管理手机内部存储、外接存储设备adb shell pm uninstall --user 0 com.huawei.hidiskREM 华为的视图管理相关服务，涉及系统界面显示、视觉呈现的底层逻辑adb shell pm uninstall --user 0 com.huawei.hiviewREM 华为设备诊断与维护相关程序，排查硬件、软件故障adb shell pm uninstall --user 0 com.huawei.hwddmpREM 华为智能感知相关服务，感知环境、用户操作习惯，智能调节系统adb shell pm uninstall --user 0 com.huawei.iawareREM 华为蓝牙相关功能模块，管理蓝牙配对、传输、设备连接adb shell pm uninstall --user 0 com.huawei.bluetoothREM 安卓系统的媒体文件存储与提供服务，负责图片、视频、音频存储管理adb shell pm uninstall --user 0 com.android.providers.mediaREM 华为本地备份服务，把手机数据备份到本地存储adb shell pm uninstall --user 0 com.huawei.localBackupREM 华为手机主题管理应用，更换桌面壁纸、图标风格、字体样式adb shell pm uninstall --user 0 com.huawei.android.thememanagerREM 鸿蒙系统下的录音机应用，用于录制音频adb shell pm uninstall --user 0 com.huawei.ohos.soundrecorderREM 安卓系统自带的壁纸裁剪工具，裁剪图片适配手机桌面adb shell pm uninstall --user 0 com.android.wallpapercropperREM 华为一键锁屏的相关服务，实现快速锁屏功能adb shell pm uninstall --user 0 com.huawei.onekeylock.hmserviceREM 华为的附近功能模块，发现周边的人和设备、服务信息adb shell pm uninstall --user 0 com.huawei.nearbyREM 华为文件管理器，管理手机存储里的文件、文件夹，支持复制、粘贴、删除等操作adb shell pm uninstall --user 0 com.huawei.filemanagerREM 华为的悬浮任务相关功能，实现多任务窗口以悬浮形式展现adb shell pm uninstall --user 0 com.huawei.android.FloatTasksREM 华为桌面系统UI相关服务，定制桌面系统视觉与交互效果adb shell pm uninstall --user 0 com.huawei.desktop.systemuiREM 华为相册应用，用于浏览、管理手机拍摄的图片、视频adb shell pm uninstall --user 0 com.huawei.photosREM 华为智能相关服务，整合AI智能助手、智能场景识别等功能adb shell pm uninstall --user 0 com.huawei.intelligentREM 华为的动作感知服务，识别手机的摇晃、翻转等动作adb shell pm uninstall --user 0 com.huawei.motionserviceREM 鸿蒙系统的系统管理器，管理系统资源、进程、权限adb shell pm uninstall --user 0 com.huawei.ohos.systemmanagerREM 华为的家长控制功能模块，限制儿童使用手机时长、访问内容adb shell pm uninstall --user 0 com.huawei.parentcontrolREM 华为搜索服务，在手机本地、网络搜索文件、信息、应用adb shell pm uninstall --user 0 com.huawei.searchREM 华为输入法相关安全服务，保障输入法使用安全adb shell pm uninstall --user 0 com.huawei.secimeREM 安卓系统的文档管理界面服务，呈现文件目录、文档预览adb shell pm uninstall --user 0 com.android.documentsuiREM 华为号码身份识别相关服务，识别陌生来电号码归属地、类型adb shell pm uninstall --user 0 com.huawei.numberidentityREM 安卓系统的外部存储管理服务，管理SD卡等外接存储设备adb shell pm uninstall --user 0 com.android.externalstorageREM 华为多媒体音频引擎，优化音频播放、录制效果adb shell pm uninstall --user 0 com.huawei.multimedia.audioengineREM 安卓系统自带的HTML网页查看器，浏览简单网页adb shell pm uninstall --user 0 com.android.htmlviewerREM 安卓系统的配套设备管理服务，连接、管理智能手表、手环等外设adb shell pm uninstall --user 0 com.android.companiondevicemanagerREM 华为注册服务，涉及华为账号注册、设备注册流程adb shell pm uninstall --user 0 com.huawei.regserviceREM 安卓系统的彩信服务，收发彩信功能的底层实现adb shell pm uninstall --user 0 com.android.mms.serviceREM 华为音频相关服务，优化音频输出、音效调节adb shell pm uninstall --user 0 com.huawei.waudioREM 安卓系统的下载管理服务，管理下载的文件、安装包adb shell pm uninstall --user 0 com.android.providers.downloadsREM 安卓系统网络栈相关的进程内服务，保障网络连接底层逻辑adb shell pm uninstall --user 0 com.android.networkstack.inprocessREM 华为硬件诊断服务，检测手机硬件是否存在故障adb shell pm uninstall --user 0 com.huawei.hwdiagnosisREM 华为的查找我的手机功能模块，定位丢失手机位置adb shell pm uninstall --user 0 com.huawei.android.findmyphoneREM 华为的信任环服务，构建安全可信的设备连接圈adb shell pm uninstall --user 0 com.huawei.trustcircleREM 华为的一跳服务主机相关程序，关联设备间快速交互服务adb shell pm uninstall --user 0 com.huawei.onehopsvchostREM 华为手机服务应用，整合客服、维修、设备信息查看等功能adb shell pm uninstall --user 0 com.huawei.phoneserviceREM 华为桌面的文件资源管理器，浏览手机存储文件adb shell pm uninstall --user 0 com.huawei.desktop.explorerREM 华为屏幕录制应用，录制手机屏幕操作adb shell pm uninstall --user 0 com.huawei.screenrecorderREM 华为增强现实（AR）引擎服务，支撑AR类应用开发运行adb shell pm uninstall --user 0 com.huawei.arengine.serviceREM 华为的无线连接相关服务，比如和华为设备的无线投屏、传文件adb shell pm uninstall --user 0 com.huawei.airlinkREM 华为安全管理器，统筹手机安全防护，如病毒查杀、权限管控adb shell pm uninstall --user 0 com.huawei.securitymgrREM 华为移动服务（HMS）里的5G工具包代理服务，适配5G功能adb shell pm uninstall --user 0 com.huawei.hms5gkit.agentserviceREM 华为移动设备管理（MDM）相关的覆盖层服务，用于定制系统界面adb shell pm uninstall --user 0 com.huawei.mdm.overlayREM 鸿蒙系统的输入法服务adb shell pm uninstall --user 0 com.huawei.ohos.inputmethodREM 华为连接相关服务，连接华为各类智能设备adb shell pm uninstall --user 0 com.huawei.iconnectREM 华为安卓系统下自动注册短信相关服务，辅助账号注册流程adb shell pm uninstall --user 0 com.huawei.android.AutoRegSmsREM 华为的SD卡管理服务，管理SD卡读写、格式化等操作adb shell pm uninstall --user 0 com.huawei.dsdscardmanagerREM 华为视图隧道相关服务，可能用于跨设备、跨进程的视图数据传输adb shell pm uninstall --user 0 com.huawei.hiviewtunnelREM 华为分布式剪贴板服务，实现不同设备间复制粘贴adb shell pm uninstall --user 0 com.huawei.distributedpasteboardREM 安卓下载管理的用户界面服务，呈现下载进度、管理下载任务adb shell pm uninstall --user 0 com.android.providers.downloads.uiREM 安卓系统UI的覆盖层服务，定制系统状态栏、通知栏外观adb shell pm uninstall --user 0 com.android.systemui.overlayREM 华为智能家居控制中心应用，连接、控制华为智能家居设备adb shell pm uninstall --user 0 com.huawei.smarthomeREM 华为智能拍摄相关服务，比如智能场景识别拍照adb shell pm uninstall --user 0 com.huawei.smartshotREM 安卓系统连接性相关的资源文件，保障网络、蓝牙连接adb shell pm uninstall --user 0 com.android.connectivity.resourcesREM 安卓系统华为扩展相关服务，给华为手机增添定制化功能adb shell pm uninstall --user 0 androidhwextREM 华为联系人应用，管理手机通讯录adb shell pm uninstall --user 0 com.huawei.contactsREM 安卓系统模块元数据管理服务，记录系统模块信息adb shell pm uninstall --user 0 com.android.modulemetadataREM 安卓系统证书安装服务，安装SSL等各类证书adb shell pm uninstall --user 0 com.android.certinstallerREM 华为手机通话录音应用，录制通话内容adb shell pm uninstall --user 0 com.huawei.phone.recorderREM 安卓系统运营商配置服务，适配不同运营商网络设置adb shell pm uninstall --user 0 com.android.carrierconfigREM 安卓系统基础包，提供底层系统运行框架adb shell pm uninstall --user 0 androidREM 华为多媒体相关的智能服务，优化多媒体体验adb shell pm uninstall --user 0 com.huawei.imedia.swsREM 华为的AI智能相关服务，赋能AI识别、AI运算adb shell pm uninstall --user 0 com.huawei.hiaiREM 华为设备标识相关服务，识别、管理设备唯一IDadb shell pm uninstall --user 0 com.huawei.hwidREM 华为内容感知服务，识别敏感内容，保护隐私adb shell pm uninstall --user 0 com.huawei.contentsensorREM 华为系统服务器相关服务，保障系统后台运行逻辑adb shell pm uninstall --user 0 com.huawei.systemserverREM 安卓系统彩信应用，收发彩信adb shell pm uninstall --user 0 com.android.mmsREM 安卓系统媒体传输协议相关服务，实现设备与电脑间媒体传输adb shell pm uninstall --user 0 com.android.mtpREM 安卓系统NFC近场通讯相关服务，支持NFC支付、门禁模拟adb shell pm uninstall --user 0 com.android.nfcREM 安卓系统备份确认服务，提示用户备份进度、结果adb shell pm uninstall --user 0 com.android.backupREM 智能检测adb shell pm uninstall --user 0 com.huawei.hwdetectrepairREM 的华为Appadb shell pm uninstall --user 0 com.huawei.phoneserviceREM 融合搜索服务adb shell pm uninstall --user 0 com.huawei.searchserviceREM 畅连Appadb shell pm uninstall --user 0 com.huawei.meetimeREM 畅连服务adb shell pm uninstall --user 0 com.huawei.hwvoipserviceREM 查找设备Appadb shell pm uninstall --user 0 com.huawei.android.findmyphoneREM XRKitadb shell pm uninstall --user 0 com.huawei.featurelayer.sharedfeature.xrkitREM 华为 AR 引擎服务adb shell pm uninstall --user 0 com.huawei.arengine.serviceREM 音频产品管家adb shell pm uninstall --user 0 com.huawei.audioaccessorymanagerREM 华为云空间adb shell pm uninstall --user 0 com.huawei.hidiskREM 华为云空间服务adb shell pm uninstall --user 0 com.huawei.hicloudREM 隐私空间adb shell pm uninstall --user 0 com.huawei.privatespaceREM 华为安全公共服务adb shell pm uninstall --user 0 com.huawei.securityserverREM 华为文件管理,推荐 MT管理器adb shell pm uninstall --user 0 com.huawei.filemanagerREM 华为的文件adb shell pm uninstall --user 0 com.huawei.desktop.explorerREM 下载管理adb shell pm uninstall --user 0 com.android.providers.downloadsREM 下载管理 UIadb shell pm uninstall --user 0 com.android.providers.downloads.uiREM 华为关键资产同步adb shell pm uninstall --user 0 com.huawei.assetsyncREM 华为关键资产同步服务adb shell pm uninstall --user 0 com.huawei.assetsyncserviceREM 华为联系人同步adb shell pm uninstall --user 0 com.huawei.contacts.syncREM 华为Air Linkadb shell pm uninstall --user 0 com.huawei.airlinkREM 华为 RCS 服务,同华为手机的免费短信adb shell pm uninstall --user 0 com.huawei.rcsserviceapplicationREM 华为通过蓝牙导入adb shell pm uninstall --user 0 com.huawei.bluetoothREM 华为智能解锁adb shell pm uninstall --user 0 com.huawei.trustagentREM 讯飞语音引擎adb shell pm uninstall --user 0 com.iflytek.speechsuiteREM [HarmongOS]华为服务中心adb shell pm uninstall --user 0 com.huawei.ohos.famanagerREM 共享存储备份adb shell pm uninstall --user 0 com.android.sharedstoragebackupREM 华为息屏支付adb shell pm uninstall --user 0 com.huawei.hwpanpayserviceREM 华为检测/诊断adb shell pm uninstall --user 0 com.huawei.hwdiagnosisREM 华为超级终端adb shell pm uninstall --user 0 com.huawei.controlcenterREM 华为视频开发引擎adb shell pm uninstall --user 0 com.huawei.multimedia.hivideoplayengineREM 华为注册服务adb shell pm uninstall --user 0 com.huawei.regserviceREM 华为可信认证跳过adb shell pm uninstall --user 0 com.huawei.trustedthingsauthREM 华为协同adb shell pm uninstall --user 0 com.huawei.synergyREM 华为联合认证adb shell pm uninstall --user 0 com.huawei.coauthservice 帧数优化关闭系统更新adb shell pm disable-user com.huawei.android.hwouc 动画缩放设置窗口动画缩放调整窗口动画缩放可以显著提升界面的响应速度，尤其在打开或关闭应用时，平滑度会有明显改善。使用以下命令可以设置窗口动画缩放： adb shell settings put global window_animation_scale 0.96 将此值调整低于 1 会加快窗口动画速度，使应用切换时的流畅度更高。 切换动画缩放切换动画缩放设定用于调整在不同屏幕间切换时的动画流畅性，此设置也应进行相应调整： adb shell settings put global transition_animation_scale 0.96 通过减小此数值，用户能够体验到更加迅速的跳转感受。 动画持续时间缩放对于动画持续时间的优化可以提升整个系统的流畅度，特别是在多任务处理时。在此设置中的有效增益会体现在动画的过渡上： adb shell settings put global animator_duration_scale 0.43 这一调整会大幅度压缩动画时间，从而增强应用之间的切换体验。 更改屏幕密度屏幕密度也会直接影响 UI 及其流畅性。通过修改屏幕密度，可以对显示效果和触控响应进行优化： adb shell wm density 520 将屏幕密度设置为 640dpi，可以让显示效果更加清晰，细节更加丰富，从而提升图形渲染质量和用户体验效率。默认 520","categories":["5.生活","手机相机游戏机"]},{"title":"串口终端软件picocom及putty的安装和配置","path":"/2023/08/22/3-协议-串口-串口终端软件picocom及putty的安装和配置/","content":"串口和终端软件什么是串口工具接收和发送分开，只有点击发送时，才将数据发送，一般用于串口数据调试 什么是终端工具终端工具的连接方式多种多样，包含串口，SSH，telnet 等方式，一般用于登录服务器，进行命令行操作 putty 在 Ubuntu 环境下的离线安装和配置由于本次安装 putty 需要在内网环境中安装，所以只能通过离线方式安装，如果可以通过在线方式安装时，只需要输入 sudo apt install putty 进行安装即可。 下载离线安装包，进入官网后选择 Download PuTTY，下拉找到 Unix source archive,当前最新的版本是 putty-0.78.tar.gz putty官方下载地址 从 0.77 版本开始官方改用 CMake 构建 从 0.78 版本开始增加 Github actions 自动编译脚本，方便直接在线编译 2.由于是离线配置，所以在本地编译，使用 CMake 进行构建即可 解压压缩包 tar xvf putty-0.78.tar.gz 进入目录 cd putty-0.78 执行 cmake cmake . 执行完成后显示 在执行以下命令进行构建 cmake --build . 执行完成后显示 安装 cmake --build . --target install 此处推荐一个 汉化putty 的开源仓库,有兴趣可以尝试 picocom 在 Ubuntu 环境下的离线安装和配置picocom下载地址1.切换到 piccocom 的源目录 make 2.进行瘦身（非必要） strip picocom 3.移动到 /usr/bin 目录下使得可以在任意处执行命令（非必要） 使用方式执行 picocom -b 115200 -f h /dev/ttyS0 指定波特率,串口，流控","categories":["3.协议","串口"]},{"title":"旧手机改造成web服务器","path":"/2023/08/21/5-生活-手机相机游戏机-旧手机改造成web服务器/","content":"前期准备需要的工具 旧安卓手机：必须能够获取 root 权限。这个权限能够让用户对手机系统进行更深层的操作，必要时进行系统配置修改。 联网的电脑：这台电脑需要安装 Git，以便进行版本控制和代码管理。 软件安装： Linux Deploy：用于在安卓设备上创建和管理 Linux 环境。 BusyBox：提供了许多常用的 Unix 工具，是 Linux 环境的基础。 JuiceSSH（可选）：一款 Android 上的 SSH 客户端，能够快速执行命令。 KSWEB（可选）：为 Android 设备提供的网页服务器，方便查看和管理内容。 配置 Linux 环境启动 BusyBox，点击安装以便将其功能扩展到安卓设备上。这项操作只在手机上执行，需要获得 root 权限。 接着，打开 Linux Deploy，点击右下方的配置图标。在这里，你需根据个人需求进行系统相关配置。选择容器类型为 chroot，发行版选择 CentOS。如果选择其他发行版，请务必确认手机 CPU 的架构与所选版本的兼容性，以避免安装出错。建议源地址切换为国内镜像源，比如中科大的镜像源：http://mirrors.ustc.edu.cn/centos-altarch/，清华源和阿里源也是不错的选择。 这个设置相当关键。确保启用 SSH 选项，因为后续步骤将依赖于 SSH 连接（SSH 的默认端口为 22）。返回主界面，点击左上角的设置，建议勾选前三个选项。往下滑，找到 PATH 变量，输入 /system/xbin。继续滚动，开启 调试模式 选项。 完成设置后，返回主界面，点击右上角的 开始安装。这个过程大约需要 30 分钟。 若在手机终端看到输出 deploy，则表示安装已完成。在启动之前，先单击停止按钮，待看到 stop 时再点击启动。成功启动时，控制台将显示相关内容。 之后，打开 KSWEB，查看当前手机的局域网 IP 地址，例如 192.168.101.10。通过电脑终端（可以使用 cmd、git 或 wsl），输入 ssh admin@192.168.101.10 并根据提示输入密码（密码在前面的 Linux Deploy 配置中设定）。如果在控制台看到预期的输出，则说明成功连接了手机。 在服务器上部署配置 Git在服务器端需要安装 Git 和 Node.js。执行以下命令： yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-develyum install -y gitcurl -sL https://rpm.nodesource.com/setup_12.x | bash -yum -y install nodejs 若下载未成功或显示 Exiting on user cancel，可尝试以下命令： yum clean metadatayum clean allyum upgrade 如果看到 Failed to set locale, defaulting to C.UTF-8，这意味着语言环境未正确设置，解决方法如下： echo export LC_ALL=en_US.UTF-8 /etc/profilesource /etc/profile 重新登录后再试安装，如果还有相同问题，可能需安装相应的语言包： 中文包： yum install glibc-langpack-zh 英文包： dnf install glibc-langpack-en 搭建 Nginx 服务器下载并安装 Nginx，需确保安装了编译环境，如 gcc、gdb、gcc-c++、make、wget。运行以下命令进行安装： cd /usr/local/srcwget http://nginx.org/download/nginx-1.15.2.tar.gztar xzvf nginx-1.15.2.tar.gzcd nginx-1.15.2./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-file-aio --with-http_realip_modulemake make install 为 Nginx 配置别名，方便后续操作： alias nginx=/usr/local/nginx/sbin/nginx 启动 Nginx 查看是否安装成功： nginx 使用浏览器访问 server_ip，查看是否能够正常展示页面。","categories":["5.生活","手机相机游戏机"]},{"title":"相机参数","path":"/2023/08/18/5-生活-手机相机游戏机-相机参数/","content":"光圈、快门、ISO、景深 光圈：光圈的大小直接影响镜头的光线进入量。光圈用 f 值表示，f 值越小，光圈越大。例如，f2.8 的光圈比 f8 的光圈大得多，这意味着在相同时间内，大光圈可以让更多光线进入相机，从而在低光环境中拍摄更加清晰明亮的照片。此外，大光圈还会产生更加柔和的背景虚化效果，这在拍摄人像时尤其受欢迎，能将主体突出。 快门：快门速度是影响运动物体拍摄效果的重要因素。如果快门速度过慢，比如设置在 1 秒，任何移动的物体都可能出现拖影或模糊现象。例如，在拍摄运动员奔跑的瞬间，快门速度应至少选择 1500 秒以上，以确保捕捉到清晰的动态瞬间。因此，快门速度对图像清晰度和动感的表现至关重要。 ISO：ISO 设置代表了相机传感器对光线的敏感程度。ISO 值越高，例如 ISO 1600，传感器对光线更加敏感，能在暗光环境下拍摄，但同时也会引入更多的噪点，使得画质下降。比如，在昏暗的酒吧里拍摄时提高 ISO 可以让捕捉到更多细节，但画面可能会出现明显的颗粒感，影响整体视觉效果。因此，选择合适的 ISO 是获得理想画质的关键。 景深：景深是指在照片中清晰的范围。一方面，深景深（如 f11）的光圈能够让前景和背景都清晰，适合拍摄风景照；另一方面，浅景深（如 f2.8）则使得背景模糊，适合专注表现主体，常用于人像摄影。通过合理控制景深，摄影师可以引导观众的注意力，创造出更具艺术感的作品。","categories":["5.生活","手机相机游戏机"]},{"title":"基金介绍","path":"/2023/08/17/5-生活-金融-基金介绍/","content":"基金介绍基金是一种集合投资工具，允许多个投资者将资金集中在一起，由专业的基金管理公司进行管理和投资。基金的主要目的是通过分散投资来降低风险，同时追求资本增值或收入。通过基金，投资者可以以较小的资金参与多种资产的投资，享受专业管理带来的便利。 基金的类型 股票基金股票基金主要投资于股票市场，目标是通过资本增值来实现投资回报。例如，某股票基金可能专注于科技行业，投资于如苹果、谷歌等公司的股票。此外，股票基金还可以分为： 成长型基金：投资于高成长潜力的公司，如科技初创企业。 价值型基金：投资于被市场低估的公司，等待其价值回归。 指数基金：跟踪特定指数，如标普 500，分散投资于多只股票。 ETF（交易所交易基金）：在交易所上市交易，兼具开放式和封闭式基金的特点。 债券基金债券基金主要投资于固定收益证券，如国债、企业债等。这类基金通常风险较低，适合寻求稳定收入的投资者。例如，某债券基金可能专注于投资于 AAA 级别的企业债券，以确保较低的违约风险。债券基金还可以分为： 短期债券基金：投资于到期日较短的债券，流动性高，风险低。 长期债券基金：投资于长期债券，收益较高，但利率风险较大。 可转换债券基金：投资于可以转换为股票的债券，兼具债券和股票的特性。 混合基金混合基金同时投资于股票和债券，旨在通过资产配置来平衡风险和收益。例如，某混合基金可能将 60%的资金投资于股票，40%投资于债券，以实现资本增值和稳定收入的双重目标。混合基金的资产配置策略可以分为： 保守型：以债券为主，股票比例较低，适合风险厌恶型投资者。 平衡型：股票和债券比例均衡，既追求收益又注重稳定。 激进型：以股票为主，追求较高的资本增值，风险相对较高。 货币市场基金货币市场基金投资于短期的、流动性强的金融工具，如国库券、商业票据和大额存单。这类基金通常风险极低，适合希望保持资金流动性并获得小额收益的投资者。例如，投资者可以在需要现金时随时赎回基金份额，流动性极高。 基金的运作方式基金的运作通常包括以下几个步骤： 募集资金基金通过向投资者发行份额来募集资金。投资者可以通过银行、证券公司或第三方销售平台购买基金份额。例如，投资者可以选择一次性认购或定期定额投资。基金管理公司将所有投资者的资金集中起来，形成一个共同的资产池。 投资决策基金经理根据市场分析和投资策略，选择合适的投资标的。例如，某基金经理可能会根据技术分析和基本面分析，决定在特定时机增持或减持某只股票。此外，基金经理还会参考宏观经济指标，如 GDP 增长率、利率变化和通货膨胀率，来制定投资策略。 收益分配基金的收益通常以分红或资本增值的形式分配给投资者。例如，某股票基金在年度结束时可能会将部分收益以现金分红的方式返还给投资者。另外，基金净值的升值也会使投资者的持有份额价值增加，投资者可以选择赎回份额以获取资本增值收益。 投资基金的优势 专业管理基金由经验丰富的专业人士管理，投资者可以借助他们的专业知识和市场洞察力，降低投资风险。基金经理和研究团队会不断研究市场动态，优化投资组合，帮助投资者实现投资目标。 分散投资基金通过投资于多种资产，降低了单一投资的风险。例如，投资于一个股票基金，投资者的资金将分散在多个公司股票上，而不是集中在一两只股票上。根据现代投资组合理论，分散投资可以有效降低非系统性风险。 流动性大多数基金允许投资者在特定时间内赎回份额，提供了较好的流动性。例如，开放式基金通常允许投资者在每个交易日结束时赎回份额。而封闭式基金则在交易所上市交易，投资者可以随时买卖基金份额。","categories":["5.生活","金融"]},{"title":"开户","path":"/2023/08/16/5-生活-金融-开户/","content":"赴港旅游、购物血拼、商业谈判，甚至为孩子汇学费或生活费，或是投资港股、美股，进行境外资产配置，购买海外理财保险，这些生活中的重要事项都离不开一张香港银行卡。然而，申请香港银行账户的过程却日益复杂，为此，针对香港的 10 大银行提供了一份详细的开户攻略，帮助简化这一流程。 一、香港汇丰银行（公户个户）01 公司账户开户资料： 香港公司全套资料：包括公司注册文件、商业登记证、最新报表等。 董事身份证及旅行证件：提供身份证、港澳通行证或护照的复印件，以及近三个月的个人银行流水。 合同和单据：提交最近三个月的采购合同、销售合同、发票、货运单和报关单各两份。 公司对账单：提供近半年的公司银行对账单。 大陆公司资料：包括营业执照复印件。 开户流程（过港）： 提交开户资料给银行经理进行预审。 开户经理将会电话联系董事进行 KYC 尽职调查（了解你的客户）。 审核完成后，通常会在 3-5 个工作日内安排面签。 按照约定时间到香港指定分行进行面签。 开户成功后，立即取得编码器和密码信以便后续使用。 02 个人账户开户资料： 有效身份证、港澳通行证或护照。 进入香港时的过港小票，海关会提供。 填写银行的 KYC 表格。 提供个人地址证明，如近一个月的水电费单。 开户方案：方案一： 年龄要求：22-55 岁。 存款要求：存入 50 万港币，需冻结三个月。 开户方式：可以选择在国内的汇丰柜台办理。 开户周期：预计为 4-6 周。 开户城市：全国汇丰分行均可办理。 方案二： 年龄要求：22-25 岁。 存款要求：最低存款 3.5 万港币，每月至少有 3.5 万港币的交易流水。 开户方式：在国内汇丰柜台办理。 开户城市：北京、上海、深圳、广州、天津。 03 开户流程： 内地见证： 将开户资料提交至机构进行初审。 机构将资料提交给银行审核并预约分行办理。 在指定分行办理内地汇丰账户并存入资金。 2-4 周内接到汇丰银行的电汇。 收到银行邮件并按指示操作。 接到银行的回访电话，确认开户信息。 收到实体卡后，只需激活即可使用。 过港开户： 准备好开户资料。 提前预约开户时间。 亲自前往香港指定汇丰网点办理开户。 在现场开立香港汇丰银行账户。 二、香港渣打银行（公户个户）01 公司账户开户资料： 香港公司资料：包括公司注册证书和最新商业登记证。 业务合同：准备两份业务合同。 提单和报关单：若有，需提供。 银行流水账单：最近三个月的流水账单。 董事和股东个人信息：包括身份证、港澳通行证或护照的复印件及三个月银行流水。 开户流程（过港）： 联系机构进行初审。 确认无误后，预约开户面签时间。 在约定的时间，亲自过港前往指定分行办理开户。 面签完成后的 2-3 周内即可完成开户。 开户后，账户激活可供正常使用。 02 个人账户开户资料： 身份证和旅行证件：有效期需在 6 个月以上。 过港小票：海关提供的证据。 银行 KYC 表格：填写必要的客户信息。 开户流程（过港）： 提交个人开户资料。 资料审核通过后，预约面签时间。 按照预约，亲自前往香港指定分行办理。 当场完成开户，在线激活账户后即可使用。 三、中国银行-香港（个户）01 公司账户开户资料： 各类注册文件：包括注册证书和商业登记证等。 相关身份证件：董事和股东的身份证及港澳通行证。 业务合同：两份业务合同，若有额外支持材料可提供。 银行 KYC 表格：用于了解客户背景信息。 开户流程（过港）： 确认需求，提交相关认证材料。 初审通过后与机构签署协议。 递交资料，3 个工作日内会有面签时间。 按时携带资料前往指定分行进行面签，预计 2-3 周完成开户。 四、香港东亚银行（公户个户）01 公司账户开户资料： 公司基本资料：如注册证书及商业登记证等。 业务合同：必须提供两份。 董事身份证与近半年银行流水：确保提供本人的相关财务记录。 银行 KYC 表格：用于客户身份的验证。 开户流程（过港）： 预先审核所有资料，确保完整。 审核完成后，预计 3 个工作日出面签时间。 亲自前往指定分行进行面签。 面签完成后，2-3 周内完成账户的正式开户。 02 个人账户开户资料： 有效身份证和旅行证件。 过港小票。 银行 KYC 表格和近三个月的银行流水证明。 地址证明材料。 开户流程（过港）： 提交资料进行预审。 预审合格后预约面签。 根据预约携带资料前往香港分行进行办理。 办理完成后当场可以开立账户。 五、香港集友银行（公户个户）01 公司账户开户资料： 董事个人身份证：港澳通行证或护照。 近半年的银行流水：可提供最新的财务状况。 香港公司完整资料：包括注册证书和商业登记证。 业务证明材料：如采购合同和销售合同。 国内公司资料：营业执照和业务证明材料。 开户流程（过港）： 资料进行预先审核。 确定出面签时间。 亲自过港到指定分行进行面签。 提交申请后，预计 2-3 周完成开户。 02 个人账户开户资料： 有效身份证和通行证。 过港小票。 开户流程（过港）： 提交资料后进行审查。 资料审核通过后预约面签。 按照预约时间前往指定分行办理开户。 当场完成手续，开立账户。 六、中国银行-香港（个户）01 个人账户开户资料： 身份证和通行证。 过港小票。 开户流程（过港）： 准备好开户资料。 提前预约面签时间。 按照预约时间亲自前往指定分行办理。 办理完成后可直接获取账户。 七、香港招商永隆银行（个户）01 个人账户开户资料： 身份证及通行证。 过港小票。 开户流程（过港）： 准备开户资料。 提前预约办理时间。 按照预约时间亲自前往指定分行办理。 办理完成，当场开立账户。 八、香港花旗银行（个户）01 个人账户开户资料： 身份证及通行证。 过港小票。 开户流程（过港）： 准备好相关资料。 提前预约办理时间。 按照约定时间亲自前往分行办理。 当场完成开户手续。 九、交通银行-香港（个户）01 个人账户开户资料： 身份证、通行证。 过港小票。 开户流程（过港）： 准备开户资料并进行审核。 提前预约时间进行面签。 亲自前往香港指定分行办理。 办理完成，当场下账户。 十、中国建设银行-亚洲（公户）01 公司账户开户资料： 香港公司基本资料，包括注册证书和商业登记证。 两套业务合同。 董事及股东身份证和通行证。 银行 KYC 表格。 国内公司营业执照及近半年流水。 开户流程（过港）： 提交资料进行预审。 确认资料完整后预约面签时间。 按时亲自过港至指定分行进行面签。 面签后 2-3 周内完成开户。 在香港，金融监管制度严格，银行在开户时常常会向申请者推荐理财产品或基金，这是因为开户经理有销售这些产品的任务。成功开户不仅是一项成就，更是一种生活的便利。希望每一步都能顺利进行，为未来的投资与生活提供更多可能。","categories":["5.生活","金融"]},{"title":"移动平均法的理论依据与计算方法","path":"/2023/08/15/5-生活-金融-移动平均法的理论依据与计算方法/","content":"移动平均法的理论依据与计算方法移动平均分析法是指用统计分析的方法，将一定时期内的证券价格（指数）加以平均，并把不同时间的平均值连接起来，形成一根移动平均线，用以观察证券价格变动趋势的一种技术分析方法。 移动平均法的理论依据移动平均的理论依据是道·琼斯理论的”平均成本”概念。该理论指出，证券市场的价格波动状况可分为：长期运动、中期运动和短期变动三种形式。其中长期运动和中期运动是两种主要的形式，其技术分析意义最大，而短期变动的影响相对较小。为了消除短期变动和其他偶然因素对证券价格变动所造成的影响，确认证券价格的变动趋势，可将一定时期内的价格或指数加以平均，即可得到一定时期的平均价格（指数）。它反映了在这一时期内购买该证券的平均成本。将证券的当前价格与平均价格进行比较，可以判断出证券价格的运动趋势。若证券价格在平均价格（指数）之上，则意味着市场的买力（需求）较大，其价格将会继续上升；反之当证券价格落到平均价格之下时，则意味着供过于求，市场卖压较重，其价格将会继续下跌。移动平均理论正是根据上述理论来对未来证券价格的变动趋势作出研判，以作出最佳的投资决策。 移动平均的计算方法移动平均理论是指通过将一段时期内的证券价格的平均价（或平均指数〕连成一条曲线，从曲线的波峰、谷底和转折之处研判证券价格运动方向，所以说，移动平均理论亦可称为移动平均线理论。 根据对数据统计处理方法的不同，移动平均可分为算术移动平均线（SMA）、加权移动平均线（WMA）和指数平滑移动平均线（EMA）三种，但不管是算术移动平均线还是加权移动平均线，均得储存大量的数据资料，且费时费力。因此，实际应用中常使用指数平滑移动平均线方法，这种方法可避免以上弊端。 指数平滑移动平均线（EMA）的计算公式如下： 其中： 为计算期中 t 日的收盘价；EMAt-1 为 t-1 日的移动平均数。 当指数平滑移动平均线起算基点不同时，起算基点较晚的计算结果，会与起算基点较早的数字有所差异。但这种差异经过稍长一段时间的平滑运算后会逐渐消失，两者趋向一致。 根据计算时期的长短，移动平均线又可分为短期、中期和长期移动平均线。通常以 5 日、10 日线观察证券市场的短期走势；以 10 日、20 日线观察中短期趋势；以 30 日、60 日线观察中期走势；以 13 周、26 周移动平均线，研判长期趋势。西方投资机构非常看重 200 天长期均线，并以此作为长期投资的依据；若行情价格在 200 天均线以下，属空头市场；反之，则为多头市场。 综合短、中、长期移动平均线，亦可研判市场多空属性。当短、中、长期均线由上而下依次排列时，可认为是多头市场（牛市）；反之，移动平均线的排列，由上而下依次为长、中、短期移动平均线时，则认为是在空头市场（熊市）。由于短期移动平均线较长期移动平均线易于反应行情价格的涨跌，所以一般又把短期移动平均线称之为”快速移动平均线”，长期移动平均线则称为”慢速移动平均线”。 移动平均线的特点移动平均线的基本思想是消除偶然因素的影响。它具有以下几个特点： 追踪趋势。移动平均线能够表示股价的趋势方向，并追踪这个趋势。如果从股价的图表中能够找出上升或下降趋势，那么，移动平均线将保持与趋势方向一致，能消除在这个过程中出现的起伏。 滞后性。在股价原有趋势发生反转时，由于移动平均线追踪趋势的特征，使其行动往往过于迟缓，调头速度落后于大趋势。 稳定性。根据移动平均线的计算方法，要想较大地改变移动平均的数值，必须当天的股价有很大的变化，因为移动平均线是几天变动的平均值。这个特点也决定了移动平均线对股价反映的滞后性。 助长助跌性。当股价突破移动平均线时，无论是向上还是向下突破，股价都有继续向突破方向发展的愿望，这就是移动平均线的助长助跌性。 支撑线和压力线的作用。移动平均线在股价走势中起支撑线和压力线的作用，即移动平均线被突破，实际上就是支撑线和压力线的被突破。 移动平均线的参数作用实际上是对上述几个特征的加强。参数选得越大，上述特征就越明显。 葛兰威尔法则与移动平均线的组合葛兰威尔法则在移动平均线的应用上，最著名的莫过于葛兰威尔的”移动平均线八大买卖法则”。此法则是以证券价格（或指数）与移动平均线之间的偏离关系来作为研判的依据。八大法则中有四条是买进法则，四条是卖出法则（见图 9-17）。 葛兰威尔八大买卖法则如下： 当平均线从下逐渐转为盘局或上升，面股价从平均线下方突破平均线，此为买进信号（见图 9-17①）。 当股价趋势线仍在平均线上方，股价下跌却并未跌破平均线且立刻反转上升，是买进信号（见图 9-17②）。 当股价虽跌破平均线，但又立刻回升到平均线上，此时平均线仍持续上升，为买进信号（见图 9-17③〕。 当股价突然暴跌，跌破且远离平均线，则极有可能止跌反弹，为买进时机（见图 9-17④）。 当股价突然暴涨，突破且远离平均线，则极有可能回档调整，为卖出时机（见图 9-17⑤）。 当平均线从上升逐渐转为盘局或下跌，而股价向下跌破平均线，为卖出信号（见图 9-17⑥）。 当股价趋势走在平均线之下，股价上升并未突破平均线且又开始下跌，是卖出信号（见图 9-17⑦）。 当股价虽然向上突破平均线，但又立刻回跌至平均线以下，此时平均线仍持续下降，为卖出信号（见图 9-17⑧）。 经过长时间的实践，葛兰威尔认为上述八法则中，第 3 条和第 8 条实际操作风险较大，为初学者所慎用；同时认为若将第 1 条和第 2 条、第 6 条和第 7 条合并使用，可捕捉最佳买进（卖出）时机；第 4 条和第 5 条可结合乖离率指标使用，以提高其适用性和可操作性。 移动平均线的组合长、短期移动平均线的配合作用投资者可利用快、慢两种移动平均线的交叉情况来决定买进和卖出的时机。当现在行情价位站稳在长期与短期移动平均线之上，短期移动平均线向上突破长期移动平均线时，为买进信号，此种交叉称为”黄金交叉”；反之，则为卖出信号，交叉称之为”死亡交叉”（如图 9-18）。 长、中、短期移动平均线的配合使用长期平均线（250 日），中期平均线（50 日），短期平均线（10 日）的移动方向有时趋于一致，有时不一致，可从两个方面来分析、研判。 ①方向一致 在空头市场中，经过长时间的下跌，股价与 10 日平均线、50 日平均线、250 日平均线的排列关系，从下到上依次为股价、10 日均线、50 日均线和 250 日均线。若股市出现转机，股价开始回升，反应最敏感的是 10 日平均线，首先跟着股价从下跌转为上升；随着股价继续攀升，50 日平均线才开始转为向上方移动。至于 250 日平均线的方向改变，则意味股市的基本趋势的转变，多头市场的来临。若股市仅出现次级移动，股价上升数星期或两三个月，使得短期均线和中期均线向上移动；当次级移动结束后，股价再朝原始方向运动，平均线则从短期均线、中期均线依次向下移动。 在多头市场中，情形则恰恰相反。 ②方向不一致 当股价进入整理盘旋后，短期平均线、中期平均线很容易与股价缠绕在一起，不能正确地指明运动方向。有时短期均线在中期均线之上或之下，此种情形表示整个股市缺乏弹性，静待多方或空方打破僵局，使行情再度上升或下跌。 另一种不协调的现象是中期平均线向上移动，股价和短期平均线向下移动，这表明股市上升趋势并未改变，暂时出现回档调整现象。只有当股价和短期均线相继跌破中期均线，并且中期均线亦有向下反转迹象，则上升趋势改变。或是中期平均线仍向下移动，股价与短期平均线却向上移动；这表明下跌趋势并未改变，中间出现一段反弹行情而已。只有当股价和短期均线都回到均线之上，并且中期均线亦有向上反转，则趋势才改变。 平滑异同移动平均线（MACD）平滑异同移动平均线（MACD），是运用快速与慢速移动平均线聚合和分离的征兆，加以双重平滑运算，用以研判证券买进与卖出时机的方法。 计算方法在应用 MACD 时，以 12 日 EMA 为快速移动平均线，26 日 EMA 为慢速移动平均线；首先计算出两条移动平均线数值间的离差值（DIF）作为研判行情的基础，然后再求 DIF 的 9 日平滑移动平均线，即 MACD 线，来作为买卖时机的判析。 （1）计算移动平均值（EMA） 快速平滑移动平均线的计算： 今日 EMA（12）＝213 今日收盘价 1113 昨日 EMA（12） 慢速平滑移动平均线的计算： 今日 EMA（26）＝227 今日收盘价+2527 昨日 EMA（26） （2）计算离差值（DIF） DIF＝EMA（12）-EMA（26） （3）计算 DIF 的 9 日 EMA 根据离差值计算其 9 日 EMA，即”离差平均值”，是所求的 MACD 值。为了不与指标原名相混淆，此值又名 DEM。 今日 DEM（MACD）＝210 今日 DIF+810 昨日 DEM 理论上，在持续的涨势中，12 日 EMA 线在 26 日 EMA 线之上，其间的正离差值（+DIF）会愈来愈大。反之在跌势中，离差值可能变负（-DIF），其绝对值也愈来愈大；如果行情开始回转，正或负离差值将会缩小。MACD 就是利用正负的离差值，与离差值的 9 日平均线的交叉信号，作为买卖行为的依据。 为了方便判断，亦可用 DIF 值减去 DEM 值，用以绘制柱状图。 运用法则MACD 在买卖交易的判断上，有以下几个信号功能。 （1）当 DIF 和 MACD 在 0 以上，属多头市场，DIF 向上突破 MACD 是买入信号；若 DIF 向下突破 MACD 只能认为是回档，作获利了结。 （2）当 DIF 和 MACD 在 0 以下，属空头市场。此时，若 DIF 向下突破 MACD，是卖出信号；若 DIF 向上突破 MACD，只能认为是反弹，可暂时补空。 （3）当 DIF 跌破 0 轴线时，此为卖出信号，即 12 日 EMA 与 26 日 EMA 发生死亡交叉的信号。当 DIF 上穿 0 轴线时，为买入信号，即 12 日 EMA 与 26 日 EMA 发生黄金交叉的信号。 （4）”背离信号”的判断。当股价走势出现二或三个近期低点时，而 DIF（MACD〕并不配合出现新低点，可买入；当股价走势出现二或三个近期高点时，而 DIF（MACD）并不配合出现新高点，可卖出。 MACD 的优点是除掉了移动平均线产生的频繁出现买入与卖出信号，避免一部分假信号的出现，用起来比移动平均线更有把握。MACD 的缺点与移动平均线相同，在股市没有明显趋势而进入盘整时，失误的时候较多。 乖离率（BIAS）乖离率（BIAS）是测算股价与移动平均线偏离程度的指标，从而得出股价在剧烈波动时因偏离移动平均趋势而造成的可能回档或反弹，以及股价在正常范围内移动而继续原有趋势的可信度。 乖离率的技术原理在于：如果股价偏离移动平均线太远，不管是在移动平均线上方或下方，都有可能趋向平均线。乖离率是表示股价偏离趋向指标的百分比值。 计算公式 其中：Ct 为当日指数或收盘价，MAn 为 N 日移动平均价。 应用法则一般说来，乖离率的研判要点如下： （1)乖离率分正乖离和负乖离。当股价在平均线之上，则为正乖离率，反之，则为负乖离率；当股价与平均线相交时，则乖离率为零。正的乖离率愈大，表示短期多头的获利愈大，获利回吐的可能性愈高；负的乖离率愈大，则空头回补的可能性也愈高。 （2）个别股因多空双方激战的影响，股价和各种平均线的乖离率容易出现异常现象（偏高或偏低），其操作策略也应随之而变。 （3）在大势上升市场中如遇负乖离率，可择机跌价买进；在大势下跌的走势中如遇正乖离率，可以等待回升高价时出脱持股。 对于乖离率达到何种程度方为正确的买入点或卖出点，目前并无统一的标准，投资者可凭经验和对行情强弱的判断得出综合的结论。","categories":["5.生活","金融"]},{"title":"移动平均法的理论依据与计算方法","path":"/2023/08/15/5-生活-金融-策略学习-移动平均法的理论依据与计算方法/","content":"移动平均法的理论依据与计算方法移动平均分析法是指用统计分析的方法，将一定时期内的证券价格（指数）加以平均，并把不同时间的平均值连接起来，形成一根移动平均线，用以观察证券价格变动趋势的一种技术分析方法。 移动平均法的理论依据移动平均的理论依据是道·琼斯理论的”平均成本”概念。该理论指出，证券市场的价格波动状况可分为：长期运动、中期运动和短期变动三种形式。其中长期运动和中期运动是两种主要的形式，其技术分析意义最大，而短期变动的影响相对较小。为了消除短期变动和其他偶然因素对证券价格变动所造成的影响，确认证券价格的变动趋势，可将一定时期内的价格或指数加以平均，即可得到一定时期的平均价格（指数）。它反映了在这一时期内购买该证券的平均成本。将证券的当前价格与平均价格进行比较，可以判断出证券价格的运动趋势。若证券价格在平均价格（指数）之上，则意味着市场的买力（需求）较大，其价格将会继续上升；反之当证券价格落到平均价格之下时，则意味着供过于求，市场卖压较重，其价格将会继续下跌。移动平均理论正是根据上述理论来对未来证券价格的变动趋势作出研判，以作出最佳的投资决策。 移动平均的计算方法移动平均理论是指通过将一段时期内的证券价格的平均价（或平均指数〕连成一条曲线，从曲线的波峰、谷底和转折之处研判证券价格运动方向，所以说，移动平均理论亦可称为移动平均线理论。 根据对数据统计处理方法的不同，移动平均可分为算术移动平均线（SMA）、加权移动平均线（WMA）和指数平滑移动平均线（EMA）三种，但不管是算术移动平均线还是加权移动平均线，均得储存大量的数据资料，且费时费力。因此，实际应用中常使用指数平滑移动平均线方法，这种方法可避免以上弊端。 指数平滑移动平均线（EMA）的计算公式如下： 其中： 为计算期中 t 日的收盘价；EMAt-1 为 t-1 日的移动平均数。 当指数平滑移动平均线起算基点不同时，起算基点较晚的计算结果，会与起算基点较早的数字有所差异。但这种差异经过稍长一段时间的平滑运算后会逐渐消失，两者趋向一致。 根据计算时期的长短，移动平均线又可分为短期、中期和长期移动平均线。通常以 5 日、10 日线观察证券市场的短期走势；以 10 日、20 日线观察中短期趋势；以 30 日、60 日线观察中期走势；以 13 周、26 周移动平均线，研判长期趋势。西方投资机构非常看重 200 天长期均线，并以此作为长期投资的依据；若行情价格在 200 天均线以下，属空头市场；反之，则为多头市场。 综合短、中、长期移动平均线，亦可研判市场多空属性。当短、中、长期均线由上而下依次排列时，可认为是多头市场（牛市）；反之，移动平均线的排列，由上而下依次为长、中、短期移动平均线时，则认为是在空头市场（熊市）。由于短期移动平均线较长期移动平均线易于反应行情价格的涨跌，所以一般又把短期移动平均线称之为”快速移动平均线”，长期移动平均线则称为”慢速移动平均线”。 移动平均线的特点移动平均线的基本思想是消除偶然因素的影响。它具有以下几个特点： 追踪趋势。移动平均线能够表示股价的趋势方向，并追踪这个趋势。如果从股价的图表中能够找出上升或下降趋势，那么，移动平均线将保持与趋势方向一致，能消除在这个过程中出现的起伏。 滞后性。在股价原有趋势发生反转时，由于移动平均线追踪趋势的特征，使其行动往往过于迟缓，调头速度落后于大趋势。 稳定性。根据移动平均线的计算方法，要想较大地改变移动平均的数值，必须当天的股价有很大的变化，因为移动平均线是几天变动的平均值。这个特点也决定了移动平均线对股价反映的滞后性。 助长助跌性。当股价突破移动平均线时，无论是向上还是向下突破，股价都有继续向突破方向发展的愿望，这就是移动平均线的助长助跌性。 支撑线和压力线的作用。移动平均线在股价走势中起支撑线和压力线的作用，即移动平均线被突破，实际上就是支撑线和压力线的被突破。 移动平均线的参数作用实际上是对上述几个特征的加强。参数选得越大，上述特征就越明显。 葛兰威尔法则与移动平均线的组合葛兰威尔法则在移动平均线的应用上，最著名的莫过于葛兰威尔的”移动平均线八大买卖法则”。此法则是以证券价格（或指数）与移动平均线之间的偏离关系来作为研判的依据。八大法则中有四条是买进法则，四条是卖出法则（见图 9-17）。 葛兰威尔八大买卖法则如下： 当平均线从下逐渐转为盘局或上升，面股价从平均线下方突破平均线，此为买进信号（见图 9-17①）。 当股价趋势线仍在平均线上方，股价下跌却并未跌破平均线且立刻反转上升，是买进信号（见图 9-17②）。 当股价虽跌破平均线，但又立刻回升到平均线上，此时平均线仍持续上升，为买进信号（见图 9-17③〕。 当股价突然暴跌，跌破且远离平均线，则极有可能止跌反弹，为买进时机（见图 9-17④）。 当股价突然暴涨，突破且远离平均线，则极有可能回档调整，为卖出时机（见图 9-17⑤）。 当平均线从上升逐渐转为盘局或下跌，而股价向下跌破平均线，为卖出信号（见图 9-17⑥）。 当股价趋势走在平均线之下，股价上升并未突破平均线且又开始下跌，是卖出信号（见图 9-17⑦）。 当股价虽然向上突破平均线，但又立刻回跌至平均线以下，此时平均线仍持续下降，为卖出信号（见图 9-17⑧）。 经过长时间的实践，葛兰威尔认为上述八法则中，第 3 条和第 8 条实际操作风险较大，为初学者所慎用；同时认为若将第 1 条和第 2 条、第 6 条和第 7 条合并使用，可捕捉最佳买进（卖出）时机；第 4 条和第 5 条可结合乖离率指标使用，以提高其适用性和可操作性。 移动平均线的组合长、短期移动平均线的配合作用投资者可利用快、慢两种移动平均线的交叉情况来决定买进和卖出的时机。当现在行情价位站稳在长期与短期移动平均线之上，短期移动平均线向上突破长期移动平均线时，为买进信号，此种交叉称为”黄金交叉”；反之，则为卖出信号，交叉称之为”死亡交叉”（如图 9-18）。 长、中、短期移动平均线的配合使用长期平均线（250 日），中期平均线（50 日），短期平均线（10 日）的移动方向有时趋于一致，有时不一致，可从两个方面来分析、研判。 ①方向一致 在空头市场中，经过长时间的下跌，股价与 10 日平均线、50 日平均线、250 日平均线的排列关系，从下到上依次为股价、10 日均线、50 日均线和 250 日均线。若股市出现转机，股价开始回升，反应最敏感的是 10 日平均线，首先跟着股价从下跌转为上升；随着股价继续攀升，50 日平均线才开始转为向上方移动。至于 250 日平均线的方向改变，则意味股市的基本趋势的转变，多头市场的来临。若股市仅出现次级移动，股价上升数星期或两三个月，使得短期均线和中期均线向上移动；当次级移动结束后，股价再朝原始方向运动，平均线则从短期均线、中期均线依次向下移动。 在多头市场中，情形则恰恰相反。 ②方向不一致 当股价进入整理盘旋后，短期平均线、中期平均线很容易与股价缠绕在一起，不能正确地指明运动方向。有时短期均线在中期均线之上或之下，此种情形表示整个股市缺乏弹性，静待多方或空方打破僵局，使行情再度上升或下跌。 另一种不协调的现象是中期平均线向上移动，股价和短期平均线向下移动，这表明股市上升趋势并未改变，暂时出现回档调整现象。只有当股价和短期均线相继跌破中期均线，并且中期均线亦有向下反转迹象，则上升趋势改变。或是中期平均线仍向下移动，股价与短期平均线却向上移动；这表明下跌趋势并未改变，中间出现一段反弹行情而已。只有当股价和短期均线都回到均线之上，并且中期均线亦有向上反转，则趋势才改变。 平滑异同移动平均线（MACD）平滑异同移动平均线（MACD），是运用快速与慢速移动平均线聚合和分离的征兆，加以双重平滑运算，用以研判证券买进与卖出时机的方法。 计算方法在应用 MACD 时，以 12 日 EMA 为快速移动平均线，26 日 EMA 为慢速移动平均线；首先计算出两条移动平均线数值间的离差值（DIF）作为研判行情的基础，然后再求 DIF 的 9 日平滑移动平均线，即 MACD 线，来作为买卖时机的判析。 （1）计算移动平均值（EMA） 快速平滑移动平均线的计算： 今日 EMA（12）＝213 今日收盘价 1113 昨日 EMA（12） 慢速平滑移动平均线的计算： 今日 EMA（26）＝227 今日收盘价+2527 昨日 EMA（26） （2）计算离差值（DIF） DIF＝EMA（12）-EMA（26） （3）计算 DIF 的 9 日 EMA 根据离差值计算其 9 日 EMA，即”离差平均值”，是所求的 MACD 值。为了不与指标原名相混淆，此值又名 DEM。 今日 DEM（MACD）＝210 今日 DIF+810 昨日 DEM 理论上，在持续的涨势中，12 日 EMA 线在 26 日 EMA 线之上，其间的正离差值（+DIF）会愈来愈大。反之在跌势中，离差值可能变负（-DIF），其绝对值也愈来愈大；如果行情开始回转，正或负离差值将会缩小。MACD 就是利用正负的离差值，与离差值的 9 日平均线的交叉信号，作为买卖行为的依据。 为了方便判断，亦可用 DIF 值减去 DEM 值，用以绘制柱状图。 运用法则MACD 在买卖交易的判断上，有以下几个信号功能。 （1）当 DIF 和 MACD 在 0 以上，属多头市场，DIF 向上突破 MACD 是买入信号；若 DIF 向下突破 MACD 只能认为是回档，作获利了结。 （2）当 DIF 和 MACD 在 0 以下，属空头市场。此时，若 DIF 向下突破 MACD，是卖出信号；若 DIF 向上突破 MACD，只能认为是反弹，可暂时补空。 （3）当 DIF 跌破 0 轴线时，此为卖出信号，即 12 日 EMA 与 26 日 EMA 发生死亡交叉的信号。当 DIF 上穿 0 轴线时，为买入信号，即 12 日 EMA 与 26 日 EMA 发生黄金交叉的信号。 （4）”背离信号”的判断。当股价走势出现二或三个近期低点时，而 DIF（MACD〕并不配合出现新低点，可买入；当股价走势出现二或三个近期高点时，而 DIF（MACD）并不配合出现新高点，可卖出。 MACD 的优点是除掉了移动平均线产生的频繁出现买入与卖出信号，避免一部分假信号的出现，用起来比移动平均线更有把握。MACD 的缺点与移动平均线相同，在股市没有明显趋势而进入盘整时，失误的时候较多。 乖离率（BIAS）乖离率（BIAS）是测算股价与移动平均线偏离程度的指标，从而得出股价在剧烈波动时因偏离移动平均趋势而造成的可能回档或反弹，以及股价在正常范围内移动而继续原有趋势的可信度。 乖离率的技术原理在于：如果股价偏离移动平均线太远，不管是在移动平均线上方或下方，都有可能趋向平均线。乖离率是表示股价偏离趋向指标的百分比值。 计算公式 其中：Ct 为当日指数或收盘价，MAn 为 N 日移动平均价。 应用法则一般说来，乖离率的研判要点如下： （1)乖离率分正乖离和负乖离。当股价在平均线之上，则为正乖离率，反之，则为负乖离率；当股价与平均线相交时，则乖离率为零。正的乖离率愈大，表示短期多头的获利愈大，获利回吐的可能性愈高；负的乖离率愈大，则空头回补的可能性也愈高。 （2）个别股因多空双方激战的影响，股价和各种平均线的乖离率容易出现异常现象（偏高或偏低），其操作策略也应随之而变。 （3）在大势上升市场中如遇负乖离率，可择机跌价买进；在大势下跌的走势中如遇正乖离率，可以等待回升高价时出脱持股。 对于乖离率达到何种程度方为正确的买入点或卖出点，目前并无统一的标准，投资者可凭经验和对行情强弱的判断得出综合的结论。","categories":["5.生活","金融","策略学习"]},{"title":"量化交易","path":"/2023/08/14/5-生活-金融-量化交易/","content":"Python 量化金融基础量化金融运用数学、统计学和计算机科学等工具，通过系统性的方法进行金融分析和交易。这一领域为复杂的市场行为提供了深入的分析框架，使得交易策略不再依赖直觉，而是建立在严格的数据分析和模型基础之上。 量化术语以下是一些与量化交易相关的基础概念和术语的详细解释： 策略（Strategy）量化交易的核心是交易策略，它定义了在何时、何地、以及以何种条件进行买卖的系统。策略可以基于技术指标，例如简单移动平均线（SMA）交叉策略，或使用统计模型，如回归分析。此外，现代量化交易还越来越多地采用机器学习方法，如强化学习，来不断优化策略。例如，一个基于机器学习的策略可以通过分析历史价格数据，自动调整其买入和卖出的时机以最大化收益。 因子（Factor）因子是用来衡量资产或市场特征的数值。在量化交易中，因子可以是任何与股价或交易量相关的变量，如价格、成交量、均线、公司市值、市盈率等。许多投资者会将这些因子组合起来进行多因子模型分析，优化其投资决策。例如，某投资者可能会同时考虑股价与市盈率（PE Ratio）来评估某只股票的投资价值。 信号（Signal）信号是基于交易策略和因子生成的指令，告诉投资者在何时进行买入或卖出。信号来自于对市场条件的定量分析。例如，当短期均线超过长期均线时，可能会生成买入信号，反之则产生卖出信号。 模型（Model）量化交易使用数学模型来表示市场行为。这些模型的复杂程度可以相差很大，从简单的线性回归模型到复杂的深度学习算法都在应用之中。比如，深度学习模型可以用来分析社交媒体情绪对股价波动的影响，进而帮助交易者做出决策。 回测（Backtesting）回测是在历史市场数据上模拟和评估一个交易策略的过程。通过回测，投资者可以获取有关策略表现的重要信息，例如一年中的某个特定月份是否表现良好。然而，在进行回测时需谨防过度拟合（overfitting），这发生在模型在历史数据上表现极好但在真实交易中却表现差劲的情况。 AlphaAlpha 是一个衡量策略相对于市场基准（通常是无风险收益率）的超额收益指标。正的 Alpha 意味着策略在风险调整后表现优于市场，比如一个策略的 Alpha 为 2%，意味着其收益高于基准的 2%。 BetaBeta 指标表示一个投资组合相对于市场的敏感性，通常用于评估风险。Beta 值大于 1 表示该投资组合比市场更敏感，这意味着在市场上涨时，投资组合可能有更大的上涨幅度，而在市场下跌时也可能经历更大的损失。反之，Beta 值小于 1 表示相对不敏感。 夏普比率（Sharpe Ratio）夏普比率在量化金融中广泛用于衡量投资组合风险调整后收益的指标。其计算公式为（策略收益率 - 无风险利率） 策略波动率。夏普比率越高，表明每单位风险带来的收益越大，是评估策略的重要指标。例如，年收益率为 12%、波动率为 8%的策略，若无风险利率为 2%，则夏普比率为 (12%-2%)8% 1.25，这表示投资者在承担风险时所获得的回报相对较高。 最大回撤（Maximum Drawdown）最大回撤描述的是策略在历史上任何时期内可能损失的最大百分比，通常用于评估风险水平。比如，一个投资策略在某段时间内经历的最大回撤为 15%，这表明投资者在最糟糕的情况下可能会损失 15%的资金。因此，了解最大回撤可以帮助投资者制定合适的风险管理策略。 资金管理（Money Management）资金管理是一种通过控制投资组合风险和保护本金的方法。其中包括投资组合的分散投资、仓位控制等技巧。例如，某投资者可能决定将资金的 60%投入蓝筹股，30%投入债券，10%保留为现金以保持流动性，这样的分配可以降低整体风险。 金融术语以下是一些量化金融的基本概念： 股票（Stocks）股票是公司的所有权证券，代表对公司部分资产和利润的所有权。购买股票意味着成为股东，享有分红权和投票权。例如，投资者购买某科技公司的股票，即成为该公司的股东，有权分享未来的利润增长。 投资组合（Portfolio）投资组合是由多种不同资产（如股票、债券、期货等）构成的一揽子投资。通过构建投资组合，投资者能够分散风险，提高收益潜力。例如，一个由 40%美国股票、30%国际股票和 30%债券组成的投资组合，可以降低单一市场波动对整体投资的影响。 风险管理（Risk Management）风险管理是一种识别、测量和控制投资中的潜在风险的方法。在量化金融中，使用统计学和数学模型来评估和管理投资组合的风险。例如，可以使用历史波动率、VaR（在险价值）等指标来衡量投资组合可能的损失。 收益（Return）收益是投资的盈利，通常以百分比表示。投资者在追求最大化收益的同时，必须合理考虑潜在的风险。例如，某投资策略的年度收益为 15%，但如果相应的风险水平也较高，投资者需要权衡这种收益的吸引力与承受的风险。 算法交易（Algorithmic Trading）算法交易是通过计算机程序执行的，由预定规则和数学模型引导的交易方法。这种方式能够实现高速和高效交易，例如在一秒钟内执行成千上万笔订单，以捕捉市场瞬息万变的机会。 量化模型（Quantitative Models）量化模型利用数学和统计学工具来分析和预测金融市场的行为。这些模型可能基于历史数据、技术分析或基本分析等多种方法。例如，通过建立一个基于时间序列分析的预测模型，投资者可以根据历史价格数据预测未来股价走势，从而做出买入或卖出的决策。 高频交易（High-Frequency Trading）高频交易指的是以极快的速度进行交易，通常依赖于复杂的计算机算法。这类交易能够在毫秒级别内执行，以捕捉市场微小的价格波动。高频交易机构利用市场流动性，试图在短时间内实现利润，例如机器人自动交易平台每天可能执行数十万笔交易。 套利（Arbitrage）套利是一种通过同时买入和卖出同一资产或相似资产来利用价格差异的交易策略。其核心目的在于法律允许的范围内，以无风险或低风险的手段获取利润。例如，若某商品在不同交易所的价格存在差异，交易者可先低价买入，再高价卖出，以实现套利收益。 蒙特卡洛模拟（Monte Carlo Simulation）蒙特卡洛模拟是一种用于模拟金融市场不确定性的数学技术。通过生成大量随机样本来评估投资组合的风险和收益，投资者可以看出在不同市场状况下可能的损失和赢利。这种方法在风险管理中尤为重要，能够帮助投资者量化潜在的风险。 夏普比率（Sharpe Ratio）夏普比率是衡量投资组合每承担一单位总风险所获得超额收益的指标，是量化金融中常用的性能指标之一。它使投资者能够比较不同投资策略的有效性，帮助选择出风险-adjusted 收益最高的投资方式。例如，一个策略在市场波动性很大时，若保持较高的夏普比率，意味着其有效性强，应引起投资者的重视。 量化交易基本策略量化交易依赖于数学模型、统计学原理和计算机算法，通过系统化的方法来识别和执行交易机会。这一领域的策略通常结合了科学和艺术，使交易者能够利用市场行为的规律进行盈利。以下是一些常见的量化交易基本策略及其实现方式。 1. 移动平均策略策略思想：该策略基于股价的历史平均值，目的是通过计算短期和长期移动平均线之间的差异来产生买卖信号。例如，在短期布林带上穿长期布林带时，交易者可能会选择买入，预期股价将继续上涨。 实现方式：交易者计算短期（如 50 日移动平均）和长期（如 200 日移动平均）移动平均。当短期均线上穿长期均线时，根据这一交叉信号产生买入信号；反之，当短期均线下穿长期均线时，产生卖出信号。这种方法简单易用，并且在趋势明显的市场环境中表现良好。 2. 均值回归策略策略思想：该策略基于价格的历史波动，认为价格在经历剧烈波动后，会逐渐回归其历史平均水平。例如，如果一家公司的股票价格因为市场情绪过度反应而短暂下跌，均值回归策略可能会在价格接近历史均值时产生买入信号。 实现方式：交易者通过计算当前价格与其历史均值之间的差异来识别信号。当价格偏离均值超过一定阈值时（例如标准差的两倍），就可以发出买入或卖出信号。这种策略在波动型市场中尤为有效。 3. 动量策略策略思想：动量策略基于一个假设，即价格趋势往往会延续一段时间。交易者通常在价格上涨时买入，而在价格下跌时卖出。例如，如果某只股票在过去一个月内涨幅显著，动量策略可能促使交易者继续持有该股票，期待涨势持续。 实现方式：通过计算价格的变化率、相对强弱指数（RSI）或牛市熊市信号，动量策略生成买入或卖出信号。这种策略在处于强趋势的市场中表现尤为突出。 4. 市场中性策略策略思想：市场中性策略试图通过同时进行买入和卖出，利用市场的相对强弱来获取利润。比如，交易者或许会选择买入一家公司的股票，同时卖空其同行业中的另一家公司，以减少整体市场风险。 实现方式：这种策略通常基于两个或多个相关资产之间的价差或相关性，生成交易信号。如果某两个相关资产的价格关系发生显著变化，可能会触发交易。例如，若某一股票相对其竞争对手的价格出现偏差，交易者可以采取相应的多头或空头策略。 5. 统计套利策略策略思想：统计套利策略依托统计学原理，寻找资产之间的临时不平衡来实现套利。例如，假设某两只股票的历史价格走势十分相似，但短期内出现了价格差异，交易者可以通过买入低估股票和卖空高估股票来获取利润。 实现方式：交易者通过寻找价格、波动性或其他统计指标出现的异常值，来发出交易信号。这种策略要求交易者具备稳定的模型和大量的数据支持，以供决策。 6. 事件驱动策略策略思想：事件驱动策略旨在利用一些特定事件或新闻的发生来产生交易信号。例如，企业财报发布后，一些交易者可能会依据利好或利空信息迅速调整持仓。 实现方式：交易者需监控相关的新闻动态、公司财报、经济指标等。一旦预测的事件发生，如商业并购、行业变革等，便会立即执行交易。这样的策略适合那些愿意快速反应并对新闻敏感的交易者。 7. 机器学习策略策略思想：这一策略运用机器学习算法，从海量数据中学习市场行为的模式，以预测未来价格的走势。 实现方式：交易者可以使用回归分析、分类算法或深度学习模型对市场行为进行训练。这些模型不仅能够分析历史数据，还能自动优化以适应不断变化的市场条件，提升预测的准确性。 8. 高频交易策略策略思想：高频交易策略通过快速执行大量交易，以利用微小价格差异进行盈利。例如，交易者在毫秒级别内执行交易，以捕捉瞬息万变的市场价格变化。 实现方式：这种策略通常涉及使用高效的算法和高性能计算系统，来支持交易者完成大量的短期交易。这要求极低的延迟和优越的市场进入策略，适合于从事流动性提供和市场制造的专业交易者。 这些策略仅是量化交易领域中的一小部分。实际上，量化交易策略的形成和实现多种多样，可以根据市场状况、资产类别和交易者的个人偏好进行灵活调整。设计有效的量化策略需要经过充分的历史数据回测，并考虑潜在的风险管理，以确保在不同市场环境下的有效性和可持续性。 交易策略在金融市场中，交易者和投资者经常使用均线指标来帮助他们做出决策。其中两个常用的均线是 50 天均线 和 200 天均线。 50 天均线50 天均线是过去 50 个交易日的平均价格。它可以帮助们判断一个资产的短期趋势。当价格在 50 天均线之上时，这表明资产处于上升趋势；而当价格在 50 天均线之下时，则表明资产处于下降趋势。例如，如果某只股票的价格连续几天都在 50 天均线之上，这可能意味着市场对该股票有较高的兴趣，并且可能继续上涨。假设某科技股的价格在 50 天均线之上，且成交量也在增加，这可能是一个买入信号，表明投资者对该股的未来表现持乐观态度。 200 天均线200 天均线则用来观察资产的长期趋势。它是过去 200 个交易日的平均价格。长期投资者通常会使用这个指标来判断一个资产的整体走势。如果价格在 200 天均线之上，这往往意味着资产处于长期上升趋势；而如果价格在 200 天均线之下，则可能表明资产正处于长期下降趋势。举个例子，如果某只股票的价格连续几个月都在 200 天均线之下，这可能意味着市场对该股票的兴趣较低，并且可能继续下跌。比如，某家公司的股票在经历了一段时间的下跌后，价格始终未能突破 200 天均线，这可能会促使投资者重新评估该公司的基本面。 交易者的选择不同的交易者和投资者会根据自己的交易策略和风险承受能力来选择使用哪个均线指标。短期交易者通常更关注短期趋势，因此会选择使用较短的均线指标，如 20 天均线。例如，日内交易者可能会利用 20 天均线来捕捉快速的价格波动。而长期投资者更关注资产的整体走势，因此会选择使用较长的均线指标，如 50 天和 200 天均线。 其他交易策略除了均线指标，交易者还可以考虑以下几种策略： 相对强弱指数（RSI）：RSI 是一种动量指标，用于评估资产的超买或超卖状态。当 RSI 超过 70 时，资产可能被视为超买，反之，当 RSI 低于 30 时，资产可能被视为超卖。 布林带：布林带由三条线组成，分别是中间的移动平均线和上下两条标准差线。价格触及上轨可能意味着超买，而触及下轨则可能意味着超卖。 MACD（移动平均收敛发散指标）：MACD 是一种趋势跟踪动量指标，通过两条移动平均线之间的关系来判断买入或卖出信号。 支撑与阻力：支撑位是价格下跌时可能遇到的底部，而阻力位是价格上涨时可能遇到的顶部。交易者可以利用这些水平来制定进出场策略。 趋势线：通过连接价格图表上的高点或低点，交易者可以识别出趋势的方向，并据此做出交易决策。 通过结合这些策略，交易者可以更全面地分析市场，制定出更有效的交易计划。","categories":["5.生活","金融"]},{"title":"量化交易","path":"/2023/08/14/5-生活-金融-策略学习-量化交易/","content":"Python 量化金融基础量化金融运用数学、统计学和计算机科学等工具，通过系统性的方法进行金融分析和交易。这一领域为复杂的市场行为提供了深入的分析框架，使得交易策略不再依赖直觉，而是建立在严格的数据分析和模型基础之上。 量化术语以下是一些与量化交易相关的基础概念和术语的详细解释： 策略（Strategy）量化交易的核心是交易策略，它定义了在何时、何地、以及以何种条件进行买卖的系统。策略可以基于技术指标，例如简单移动平均线（SMA）交叉策略，或使用统计模型，如回归分析。此外，现代量化交易还越来越多地采用机器学习方法，如强化学习，来不断优化策略。例如，一个基于机器学习的策略可以通过分析历史价格数据，自动调整其买入和卖出的时机以最大化收益。 因子（Factor）因子是用来衡量资产或市场特征的数值。在量化交易中，因子可以是任何与股价或交易量相关的变量，如价格、成交量、均线、公司市值、市盈率等。许多投资者会将这些因子组合起来进行多因子模型分析，优化其投资决策。例如，某投资者可能会同时考虑股价与市盈率（PE Ratio）来评估某只股票的投资价值。 信号（Signal）信号是基于交易策略和因子生成的指令，告诉投资者在何时进行买入或卖出。信号来自于对市场条件的定量分析。例如，当短期均线超过长期均线时，可能会生成买入信号，反之则产生卖出信号。 模型（Model）量化交易使用数学模型来表示市场行为。这些模型的复杂程度可以相差很大，从简单的线性回归模型到复杂的深度学习算法都在应用之中。比如，深度学习模型可以用来分析社交媒体情绪对股价波动的影响，进而帮助交易者做出决策。 回测（Backtesting）回测是在历史市场数据上模拟和评估一个交易策略的过程。通过回测，投资者可以获取有关策略表现的重要信息，例如一年中的某个特定月份是否表现良好。然而，在进行回测时需谨防过度拟合（overfitting），这发生在模型在历史数据上表现极好但在真实交易中却表现差劲的情况。 AlphaAlpha 是一个衡量策略相对于市场基准（通常是无风险收益率）的超额收益指标。正的 Alpha 意味着策略在风险调整后表现优于市场，比如一个策略的 Alpha 为 2%，意味着其收益高于基准的 2%。 BetaBeta 指标表示一个投资组合相对于市场的敏感性，通常用于评估风险。Beta 值大于 1 表示该投资组合比市场更敏感，这意味着在市场上涨时，投资组合可能有更大的上涨幅度，而在市场下跌时也可能经历更大的损失。反之，Beta 值小于 1 表示相对不敏感。 夏普比率（Sharpe Ratio）夏普比率在量化金融中广泛用于衡量投资组合风险调整后收益的指标。其计算公式为（策略收益率 - 无风险利率） 策略波动率。夏普比率越高，表明每单位风险带来的收益越大，是评估策略的重要指标。例如，年收益率为 12%、波动率为 8%的策略，若无风险利率为 2%，则夏普比率为 (12%-2%)8% 1.25，这表示投资者在承担风险时所获得的回报相对较高。 最大回撤（Maximum Drawdown）最大回撤描述的是策略在历史上任何时期内可能损失的最大百分比，通常用于评估风险水平。比如，一个投资策略在某段时间内经历的最大回撤为 15%，这表明投资者在最糟糕的情况下可能会损失 15%的资金。因此，了解最大回撤可以帮助投资者制定合适的风险管理策略。 资金管理（Money Management）资金管理是一种通过控制投资组合风险和保护本金的方法。其中包括投资组合的分散投资、仓位控制等技巧。例如，某投资者可能决定将资金的 60%投入蓝筹股，30%投入债券，10%保留为现金以保持流动性，这样的分配可以降低整体风险。 金融术语以下是一些量化金融的基本概念： 股票（Stocks）股票是公司的所有权证券，代表对公司部分资产和利润的所有权。购买股票意味着成为股东，享有分红权和投票权。例如，投资者购买某科技公司的股票，即成为该公司的股东，有权分享未来的利润增长。 投资组合（Portfolio）投资组合是由多种不同资产（如股票、债券、期货等）构成的一揽子投资。通过构建投资组合，投资者能够分散风险，提高收益潜力。例如，一个由 40%美国股票、30%国际股票和 30%债券组成的投资组合，可以降低单一市场波动对整体投资的影响。 风险管理（Risk Management）风险管理是一种识别、测量和控制投资中的潜在风险的方法。在量化金融中，使用统计学和数学模型来评估和管理投资组合的风险。例如，可以使用历史波动率、VaR（在险价值）等指标来衡量投资组合可能的损失。 收益（Return）收益是投资的盈利，通常以百分比表示。投资者在追求最大化收益的同时，必须合理考虑潜在的风险。例如，某投资策略的年度收益为 15%，但如果相应的风险水平也较高，投资者需要权衡这种收益的吸引力与承受的风险。 算法交易（Algorithmic Trading）算法交易是通过计算机程序执行的，由预定规则和数学模型引导的交易方法。这种方式能够实现高速和高效交易，例如在一秒钟内执行成千上万笔订单，以捕捉市场瞬息万变的机会。 量化模型（Quantitative Models）量化模型利用数学和统计学工具来分析和预测金融市场的行为。这些模型可能基于历史数据、技术分析或基本分析等多种方法。例如，通过建立一个基于时间序列分析的预测模型，投资者可以根据历史价格数据预测未来股价走势，从而做出买入或卖出的决策。 高频交易（High-Frequency Trading）高频交易指的是以极快的速度进行交易，通常依赖于复杂的计算机算法。这类交易能够在毫秒级别内执行，以捕捉市场微小的价格波动。高频交易机构利用市场流动性，试图在短时间内实现利润，例如机器人自动交易平台每天可能执行数十万笔交易。 套利（Arbitrage）套利是一种通过同时买入和卖出同一资产或相似资产来利用价格差异的交易策略。其核心目的在于法律允许的范围内，以无风险或低风险的手段获取利润。例如，若某商品在不同交易所的价格存在差异，交易者可先低价买入，再高价卖出，以实现套利收益。 蒙特卡洛模拟（Monte Carlo Simulation）蒙特卡洛模拟是一种用于模拟金融市场不确定性的数学技术。通过生成大量随机样本来评估投资组合的风险和收益，投资者可以看出在不同市场状况下可能的损失和赢利。这种方法在风险管理中尤为重要，能够帮助投资者量化潜在的风险。 夏普比率（Sharpe Ratio）夏普比率是衡量投资组合每承担一单位总风险所获得超额收益的指标，是量化金融中常用的性能指标之一。它使投资者能够比较不同投资策略的有效性，帮助选择出风险-adjusted 收益最高的投资方式。例如，一个策略在市场波动性很大时，若保持较高的夏普比率，意味着其有效性强，应引起投资者的重视。 量化交易基本策略量化交易依赖于数学模型、统计学原理和计算机算法，通过系统化的方法来识别和执行交易机会。这一领域的策略通常结合了科学和艺术，使交易者能够利用市场行为的规律进行盈利。以下是一些常见的量化交易基本策略及其实现方式。 1. 移动平均策略策略思想：该策略基于股价的历史平均值，目的是通过计算短期和长期移动平均线之间的差异来产生买卖信号。例如，在短期布林带上穿长期布林带时，交易者可能会选择买入，预期股价将继续上涨。 实现方式：交易者计算短期（如 50 日移动平均）和长期（如 200 日移动平均）移动平均。当短期均线上穿长期均线时，根据这一交叉信号产生买入信号；反之，当短期均线下穿长期均线时，产生卖出信号。这种方法简单易用，并且在趋势明显的市场环境中表现良好。 2. 均值回归策略策略思想：该策略基于价格的历史波动，认为价格在经历剧烈波动后，会逐渐回归其历史平均水平。例如，如果一家公司的股票价格因为市场情绪过度反应而短暂下跌，均值回归策略可能会在价格接近历史均值时产生买入信号。 实现方式：交易者通过计算当前价格与其历史均值之间的差异来识别信号。当价格偏离均值超过一定阈值时（例如标准差的两倍），就可以发出买入或卖出信号。这种策略在波动型市场中尤为有效。 3. 动量策略策略思想：动量策略基于一个假设，即价格趋势往往会延续一段时间。交易者通常在价格上涨时买入，而在价格下跌时卖出。例如，如果某只股票在过去一个月内涨幅显著，动量策略可能促使交易者继续持有该股票，期待涨势持续。 实现方式：通过计算价格的变化率、相对强弱指数（RSI）或牛市熊市信号，动量策略生成买入或卖出信号。这种策略在处于强趋势的市场中表现尤为突出。 4. 市场中性策略策略思想：市场中性策略试图通过同时进行买入和卖出，利用市场的相对强弱来获取利润。比如，交易者或许会选择买入一家公司的股票，同时卖空其同行业中的另一家公司，以减少整体市场风险。 实现方式：这种策略通常基于两个或多个相关资产之间的价差或相关性，生成交易信号。如果某两个相关资产的价格关系发生显著变化，可能会触发交易。例如，若某一股票相对其竞争对手的价格出现偏差，交易者可以采取相应的多头或空头策略。 5. 统计套利策略策略思想：统计套利策略依托统计学原理，寻找资产之间的临时不平衡来实现套利。例如，假设某两只股票的历史价格走势十分相似，但短期内出现了价格差异，交易者可以通过买入低估股票和卖空高估股票来获取利润。 实现方式：交易者通过寻找价格、波动性或其他统计指标出现的异常值，来发出交易信号。这种策略要求交易者具备稳定的模型和大量的数据支持，以供决策。 6. 事件驱动策略策略思想：事件驱动策略旨在利用一些特定事件或新闻的发生来产生交易信号。例如，企业财报发布后，一些交易者可能会依据利好或利空信息迅速调整持仓。 实现方式：交易者需监控相关的新闻动态、公司财报、经济指标等。一旦预测的事件发生，如商业并购、行业变革等，便会立即执行交易。这样的策略适合那些愿意快速反应并对新闻敏感的交易者。 7. 机器学习策略策略思想：这一策略运用机器学习算法，从海量数据中学习市场行为的模式，以预测未来价格的走势。 实现方式：交易者可以使用回归分析、分类算法或深度学习模型对市场行为进行训练。这些模型不仅能够分析历史数据，还能自动优化以适应不断变化的市场条件，提升预测的准确性。 8. 高频交易策略策略思想：高频交易策略通过快速执行大量交易，以利用微小价格差异进行盈利。例如，交易者在毫秒级别内执行交易，以捕捉瞬息万变的市场价格变化。 实现方式：这种策略通常涉及使用高效的算法和高性能计算系统，来支持交易者完成大量的短期交易。这要求极低的延迟和优越的市场进入策略，适合于从事流动性提供和市场制造的专业交易者。 这些策略仅是量化交易领域中的一小部分。实际上，量化交易策略的形成和实现多种多样，可以根据市场状况、资产类别和交易者的个人偏好进行灵活调整。设计有效的量化策略需要经过充分的历史数据回测，并考虑潜在的风险管理，以确保在不同市场环境下的有效性和可持续性。 交易策略在金融市场中，交易者和投资者经常使用均线指标来帮助他们做出决策。其中两个常用的均线是 50 天均线 和 200 天均线。 50 天均线50 天均线是过去 50 个交易日的平均价格。它可以帮助们判断一个资产的短期趋势。当价格在 50 天均线之上时，这表明资产处于上升趋势；而当价格在 50 天均线之下时，则表明资产处于下降趋势。例如，如果某只股票的价格连续几天都在 50 天均线之上，这可能意味着市场对该股票有较高的兴趣，并且可能继续上涨。假设某科技股的价格在 50 天均线之上，且成交量也在增加，这可能是一个买入信号，表明投资者对该股的未来表现持乐观态度。 200 天均线200 天均线则用来观察资产的长期趋势。它是过去 200 个交易日的平均价格。长期投资者通常会使用这个指标来判断一个资产的整体走势。如果价格在 200 天均线之上，这往往意味着资产处于长期上升趋势；而如果价格在 200 天均线之下，则可能表明资产正处于长期下降趋势。举个例子，如果某只股票的价格连续几个月都在 200 天均线之下，这可能意味着市场对该股票的兴趣较低，并且可能继续下跌。比如，某家公司的股票在经历了一段时间的下跌后，价格始终未能突破 200 天均线，这可能会促使投资者重新评估该公司的基本面。 交易者的选择不同的交易者和投资者会根据自己的交易策略和风险承受能力来选择使用哪个均线指标。短期交易者通常更关注短期趋势，因此会选择使用较短的均线指标，如 20 天均线。例如，日内交易者可能会利用 20 天均线来捕捉快速的价格波动。而长期投资者更关注资产的整体走势，因此会选择使用较长的均线指标，如 50 天和 200 天均线。 其他交易策略除了均线指标，交易者还可以考虑以下几种策略： 相对强弱指数（RSI）：RSI 是一种动量指标，用于评估资产的超买或超卖状态。当 RSI 超过 70 时，资产可能被视为超买，反之，当 RSI 低于 30 时，资产可能被视为超卖。 布林带：布林带由三条线组成，分别是中间的移动平均线和上下两条标准差线。价格触及上轨可能意味着超买，而触及下轨则可能意味着超卖。 MACD（移动平均收敛发散指标）：MACD 是一种趋势跟踪动量指标，通过两条移动平均线之间的关系来判断买入或卖出信号。 支撑与阻力：支撑位是价格下跌时可能遇到的底部，而阻力位是价格上涨时可能遇到的顶部。交易者可以利用这些水平来制定进出场策略。 趋势线：通过连接价格图表上的高点或低点，交易者可以识别出趋势的方向，并据此做出交易决策。 通过结合这些策略，交易者可以更全面地分析市场，制定出更有效的交易计划。","categories":["5.生活","金融","策略学习"]},{"title":"金融学","path":"/2023/08/11/5-生活-金融-金融学/","content":"金融学什么是金融和金融学金融是一个广泛的概念，涵盖了资金的获取、使用和管理。它不仅关乎个人的理财和企业的投资决策，还涉及国家整体经济的运作。例如，家庭通过贷款购房、企业通过融资扩展业务，以及政府通过发行债券筹集资金，都是金融活动的表现。金融学则是研究金融现象、行为及其机制的学科。它提供理论框架和实用工具，帮助理解和分析各种金融活动的动态。 金融体系概述金融体系是由金融市场、金融机构、金融工具和金融监管构成的复杂网络。金融市场是进行资金交易的场所，比如股票交易所和债券市场；金融机构包括银行、保险公司、投资公司等，负责资金的中介和管理；金融工具如股票、债券和衍生品，用于转移风险和实现投资回报；而金融监管则确保市场的稳定性和透明性。例如，证券监管委员会负责监管股票市场，以保护投资者的利益。 货币什么是货币货币是一种普遍接受的交换媒介，用于商品和服务的交易。它不仅共有价值，还能作为价值的储存手段和计量单位。值得注意的是，货币的定义与在日常生活中对它的感性认识密切相关。比如，在超市看到的一张纸币，正是货币作为交换媒介的重要体现。 货币的感性认识人们对货币的直观理解往往停留在纸币和硬币等实物形式上。然而，随着数字支付的普及，电子货币（如支付宝、微信支付）也成为了日常交易的重要组成部分。它们在便利性上大大超过了传统货币，体现了货币概念的不断演变。 货币的理论追溯 起源：货币的起源可以追溯到早期的物物交换。在这种交易中，双方需要找到彼此都想要的商品，这常常事倍功半。为了简化交易，社会逐渐引入了一些被广泛认可的物品（如贝壳、盐、金属）。最终，这些物品演化为今天的货币。 本质：货币本质上是一种社会合约，它的价值基于人们的信任和共识。即使在金本位制下，纸币的真正价值并不在于纸张本身，而在于它能够兑换成一定量的黄金或其他商品。 职能：货币主要具有以下几种职能：作为交换媒介（简化买卖过程），作为价值尺度（提供价格标准），以及作为价值存储（允许财富的积累）。 货币的实际测算 货币层次的划分：货币层次通常分为几个级别，如 M0、M1 和 M2。M0 指流通中的现金，M1 包括 M0 及活期存款，而 M2 则涵盖 M1 和各类定期存款。通过货币层次的划分，经济学家能够更好地分析货币供给和需求的变化。 货币制度货币制度是一个国家针对货币发行、流通及管理的一系列法律、制度和政策的总和。它直接影响着经济的稳定性与发展。 货币制度的构成要素主要构成要素包括： 货币发行机构：通常为中央银行，负责控制货币的供应量和利率。 货币政策工具：如利率调整、公开市场操作等，用于调控经济。 货币的种类：包括法定货币和数字货币等。 货币制度类型货币制度可以依据货币的性质、流通方式和管理方式分类，如： 金本位制：货币的价值与黄金挂钩，提供了稳定性，但对货币政策的灵活性限制较大。 纸币制：现代流通中的纸币，可以较为灵活地调节经济。 数字货币制度：随着科技的发展，数字货币作为一种新兴货币形式正在逐渐体验发展和应用。 利息和利率信用和信用形式信用是指在缺乏即时支付的情况下，借贷双方的信任基础。信用形式有很多，包括个人信用、企业信用和国家信用等。高信用的个体或机构通常能获得更低的借款利率示例：拥有良好信用评分的个人更容易获得银行的贷款批准。 利率体系利率体系是指在一个经济体中，借贷和投资的利率水平如何形成和变化。通常，利率由市场供需关系、中央银行的货币政策、通货膨胀预期等多重因素决定。不同类型的贷款和投资会有不同的利率，如房贷、车贷和消费贷。 货币的时间价值货币的时间价值是指，相同金额的货币在不同时间点上的价值不同，这主要体现在未来的收益和当前的消费。这一概念是金融决策的核心。 终值：终值是指未来某一时点的货币价值，考虑了投资的利息。比如，一个人投资 1000 元，假设年利率为 5%，经过一年后，其终值为 1050 元。 现值：现值则是将未来的货币价值折现回现在的价值。例如，若一年后将收到 1050 元，折现回现在以 5%的利率计算，现值约为 1000 元。 利率水平的决定利率水平受多种因素影响，包括经济增长率、通货膨胀、中央银行政策等。例如，当经济发展良好、就业率高时，消费者和企业借贷意向上升，利率可能上升；相反，经济放缓时，借贷需求下降，利率可降低。 利率结构理论利率结构理论使理解不同期限的贷款或投资利率如何变化。通常情况下，长期利率较高，因为较长时间的资金占用存在更大风险。同时，市场对基准利率的预期也会影响结构。例如，预期经济增长强劲时，长期利率可能上升。 利率的作用利率在经济中扮演着至关重要的角色。它不只影响个人的借贷成本和储蓄回报，也直接与企业的投资决策关联。高利率可能抑制消费和投资，进而影响经济增长，反之亦然。因此，中央银行需通过调整利率来实现经济稳定。例如，在经济衰退期间，降低利率可以激励消费和投资，从而促进经济复苏。 外汇与汇率外汇和汇率的基本概念外汇是指一个国家的货币在国际市场上和其他国家货币进行兑换的能力，通常涉及到贸易与投资的交易。学习外汇交易时，了解汇率的变化 、国际市场的走向以及政治经济因素至关重要。例如，如果在中国，有 1,000 元人民币，想要在海外旅行并兑换成美元，那么需要关注人民币对美元的汇率变动。 汇率则是两种货币之间的价格关系，通常表示为一种货币可兑换另一种货币的比率。例如，如果 1 美元等于 7 人民币，那么汇率就是 7。汇率的变化，可以受到多种因素的影响，包括经济数据、政治事件和市场情绪。 汇率标价方法汇率的标价方法主要有两种：直接标价法与间接标价法。直接标价法通常是将外币作为基准，比如在美元与人民币的关系中，1 美元7 人民币就是直接标价。而间接标价法则是将本国货币作为基准，比如在中国可以表述为 1 人民币0.14 美元。 主要类型汇率主要分为浮动汇率与固定汇率。浮动汇率是指市场力量自由调整下的汇率，比如欧元与美元间的汇率，就是随市场供求而变化的。而固定汇率则是由政府或中央银行设定并维持的，例如，香港自 1983 年以来将港元与美元固定在一个固定的汇率范围内。 基本计算计算汇率通常涉及两个主要货币的兑换率。假设想将 500 美元兑换成人民币，若当前汇率为 1 美元7 人民币，就可以简单计算：500 × 7 3500 人民币。计算对多个币种进行汇兑时，先查找相关汇率，再依次计算。 汇率制度汇率制度是一个国家或地区采取的管理其本国货币与外币之间汇率的政策及方式。常见的汇率制度包括： 浮动汇率制度：汇率由市场供求关系决定，波动较大，国家干预较少。 固定汇率制度：国家设定一个固定的汇率，并通过干预外汇市场保持这一汇率，通常是与主要外汇（如美元）挂钩。 管理浮动汇率制度：汇率在市场供需的基础上，由中央银行进行一定的干预，以防止汇率出现过大的波动。 以中国为例，自 1994 年以来实施的汇率制度，就在一定程度上管理汇率的浮动，为市场流动性和国际贸易提供一定保障。 汇率决定理论汇率的决定理论有几种主要的经济理论： 购买力平价理论（PPP）：这一理论认为不同国家的货币在购买相同商品时的能力应是一致的。例如，若一杯咖啡在美国售价 2 美元，在中国售价 14 元人民币，则理论上 1 美元应该等于 7 人民币。 国际费雪效应：根据这一理论，名义利率的差异影响汇率。如果美国的利率为 3%，而中国的利率为 1%，那么长期来看，应该会导致美元升值，人民币贬值。 资产市场理论：该理论强调汇率由市场投资者对两个国家货币的未来预期和信心决定，比如经济增长、政治稳定等因素都可能影响投资者的判断，从而影响汇率的波动。","categories":["5.生活","金融"]},{"title":"Nodejs和npm","path":"/2023/05/26/4-软件-Web-Nodejs和npm/","content":"更新 nodejs 到最新版本卸载自带的 nodejs sudo apt autoremove nodejs sudo apt purge nodejs 安装 20 版本的 nodejs curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - sudo apt-get install -y nodejs 查看版本是否更新，否则关闭命令行重新打开 nodejs -v 安装 nodejs 安装工具到全局 sudo npm install n -g 安装稳定版本 nodejs sudo n stable 安装 npmsudo apt install npm -y","categories":["4.软件","Web"]},{"title":"WireShark的安装","path":"/2023/05/25/4-软件-WireShark-WireShark的安装/","content":"WireShark重点演示： 如何选择网卡接口 如何设置过滤条件 如何查看抓取的报文 Linux 下安装和配置安装sudo apt-get install wireshark 设置运行权限如果在此阶段以非 root 用户身份运行 wireshark，将收到消息”没有接口可以用于在当前配置的系统中进行捕获。” 缺省在非 root 账号下运行会发现看不见 interface 信息 Create the wiresharkgroup. sudo groupadd wireshark Add your username to the wiresharkgroup sudo usermod -a -G wiresharkYOUR_USER_NAME Change the group ownership of file dumpcap to wireshark sudo chgrp wireshark/usr/bin/dumpcap Change the mode of the file dumpcap to allow execution bythe group wireshark sudo chmod 750 /usr/bin/dumpcap Grant capabilities with setcap, man capabilities(7), setcap(8), cap_from_text(3) for more info about what are “cap_net_raw”, “cap_net_admin” and “eip”. Anyway, after we grant the capabilities, the dump can perform various network-related operations, use RAW and PACKET sockets; bind to anyaddressfor transparent proxying. sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap Verifythe change sudo getcap /usr/bin/dumpcap Outputshould be like below: /usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip At this point, you will need to log out, then backinto ubuntu 简单介绍下这个软件的一些常用按钮，简单的说下最常用的按钮，打开软件后，下面红框中的按钮从左到右依次是： -1 列表显示所有网卡的网络包情况，一般用的很少； -2 显示抓包选项，一般都是点这个按钮开始抓包； -3 开始新的抓包，一般用的也很少； -4 停止抓包，当抓完包之后，就是点这个停止了； -5 清空当前已经抓到的数据包，可以防止抓包时间过长机器变卡； 而实际上，一般只要知道上面加粗部分的按钮功能，就可以完成抓包了，剩下的就是如何抓想要的数据包，如何分析的问题了。 接下来说下抓包选项界面，也就是点第二个按钮出来的界面，同样，这里也只介绍最常用的几个功能，首先下图中最上面的红框是选择需要抓的网卡，选择好网卡后会在下面显示这个网卡的 IP 地址。 然后 Capture Filter 中就是要写抓包规则的地方，也叫做”过滤规则”，下面要说的很多规则都是要写到这个框里的，规则写好后，点下 面的 Start 就开始抓包了。 当抓包结束之后，如果需要把抓到的数据包找其他人分析，那么可以点菜单上的 file，然后点 Save As 保存抓到的数据包 使用 Wireshark 时最常见的问题，是当使用默认设置时，会得到大量冗余信息，以至于很难找到自己需要的部分。这就是为什么过滤器会 如此重要。它们可以帮助在庞杂的结果中迅速找到需要的信息。 三次握手 Three-way Handshake一个虚拟连接的建立是通过三次握手来实现的 (Client) – [SYN] – (Server)假如 Client 和 Server 通讯. 当 Client 要和 Server 通信时，Client 首先向 Server 发一个 SYN (Synchronize) 标记的包，告诉 Server 请求建立连接.注意: 一个 SYN 包就是仅 SYN 标记设为 1 的 TCP 包 (参见 TCP 包头 Resources). 认识到这点很重要，只有当 Server 收到 Client 发来的 SYN 包，才可建立连接，除此之外别无他法。因此，如果的防火墙丢弃所有的发往外网接口的 SYN 包，那么将不 能让外部任何主机主动建立连接。 (Client) – [SYNACK] –(Server)接着，Server 收到来自 Client 发来的 SYN 包后，会发一个对 SYN 包的确认包 (SYNACK) 给 Client，表示对第一个 SYN 包的确认，并继续握手操作.注意: SYNACK 包是仅 SYN 和 ACK 标记为 1 的包. (Client) – [ACK] – (Server)Client 收到来自 Server 的 SYNACK 包,Client 会再向 Server 发一个确认包 (ACK)，通知 Server 连接已建立。至此，三次握手完成，一个 TCP 连接完成。Note: ACK 包就是仅 ACK 标记设为 1 的 TCP 包. 需要注意的是当三此握手完成、连接建立以后，TCP 连接的每个包都会设置 ACK 位。 这就是为何连接跟踪很重要的原因了. 没有连接跟踪,防火墙将无法判断收到的 ACK 包是否属于一个已经建立的连接.一般的包过滤 (Ipchains) 收到 ACK 包时,会让它通过 (这绝对不是个 好主意). 而当状态型防火墙收到此种包时，它会先在连接表中查找是否属于哪个已建连接，否则丢弃该包。 四次握手 Four-way Handshake 四次握手用来关闭已建立的 TCP 连接 (Client) – ACKFIN – (Server) (Client) – ACK – (Server) (Client) – ACKFIN – (Server) (Client) – ACK – (Server)注意: 由于 TCP 连接是双向连接, 因此关闭连接需要在两个方向上做。**ACKFIN 包 (ACK 和 FIN 标记设为 1) 通常被认为是 FIN(终结) 包.**然而, 由于连接还没有关闭, FIN 包总是打上 ACK 标记. 没有 ACK 标记而仅有 FIN 标记的包不是合法的包，并且通常被认为是恶意的。 连接复位 Resetting a connection四次握手不是关闭 TCP 连接的唯一方法. 有时,如果主机需要尽快关闭连接 (或连接超时,端口或主机不可达),RST(Reset) 包将被发送. 注意在，由于 RST 包不是 TCP 连接中的必须部分, 可以只发送 RST 包 (即不带 ACK 标记). 但在正常的 TCP 连接中 RST 包可以带 ACK 确认标记 请注意 RST 包是可以不要收到方确认的? 无效的 TCP 标记 Invalid TCP Flags 到目前为止，已经看到了 SYN, ACK, FIN, 和 RST 标记. 另外，还有 PSH (Push) 和 URG (Urgent) 标记. 最常见的非法组合是 SYNFIN 包. 注意: 由于 SYN 包是用来初始化连接的, 它不可能和 FIN 和 RST 标记一起出现. 这也是一个恶意攻击. 由于现在大多数防火墙已知 SYNFIN 包, 别的一些组合,例如 SYNFINPSH, SYNFINRST, SYNFINRSTPSH。很明显，当网络中出现这种包时，很的网络肯定受到攻击了。 别的已知的非法包有 FIN (无 ACK 标记) 和”NULL”包。如同早先讨论的，由于 ACKFIN 包的出现是为了关闭一个 TCP 连接，那么正常的 FIN 包总是带有 ACK 标记。”NULL”包就是没有任何 TCP 标记的包 (URG,ACK,PSH,RST,SYN,FIN 都为 0)。 到目前为止，正常的网络活动下，TCP 协议栈不可能产生带有上面提到的任何一种标记组合的 TCP 包。当发现这些不正常的包时，肯定有人对的网络不怀好意。 UDP (用户数据包协议 User DatagramProtocol)TCP 是面向连接的，而 UDP 是非连接的协议。UDP 没有对接受进行确认的标记和确认机制。对丢包的处理是在应用层来完成的。(or accidentalarrival).此处需要重点注意的事情是：在正常情况下，当 UDP 包到达一个关闭的端口时，会返回一个 UDP 复位包。由于 UDP 是非面向连接的, 因此没有任何确认信息来确认包是否正确到达目的地。因此如果的防火墙丢弃 UDP 包，它会开放所有的 UDP 端口 (?)。 由于 Internet 上正常情况下一些包将被丢弃，甚至某些发往已关闭端口 (非防火墙的) 的 UDP 包将不会到达目的，它们将返回一个复位 UDP 包。 因为这个原因，UDP 端口扫描总是不精确、不可靠的。 看起来大 UDP 包的碎片是常见的 DOS(Denial ofService) 攻击的常见形式 (这里有个 DOS 攻击的例子，http://grc.com/dos/grcdos.htm ). ICMP (网间控制消息协议 Internet ControlMessage Protocol)如同名字一样， ICMP 用来在主机路由器之间传递控制信息的协议。 ICMP 包可以包含诊断信息 (ping, traceroute - 注意目前 unix 系统中的 traceroute 用 UDP 包而不是 ICMP)，错误信息 (网络主机端口 不可达 networkhostport unreachable), 信息 (时间戳 timestamp, 地址掩码 addressmaskrequest, etc.)，或控制信息 (source quench, redirect, etc.) 。 可以在 http://www.iana.org/assignments/icmp-parameters 中找到 ICMP 包的类型。 尽管 ICMP 通常是无害的，还是有些类型的 ICMP 信息需要丢弃。 Redirect (5), Alternate Host Address(6), Router Advertisement (9) 能用来转发通讯。 Echo (8), Timestamp (13)and AddressMask Request (17) 能用来分别判断主机是否起来，本地时间 和地址掩码。注意它们是和返回的信息类别有关的。 它们自己本身是不能被利用的，但它们泄露出的信息对攻击者是有用的。 ICMP 消息有时也被用来作为 DOS 攻击的一部分 (例如：洪水 ping flood ping,死 ping ?呵呵，有趣 ping of death)?p 包碎片注意 A Note About Packet Fragmentation 如果一个包的大小超过了 TCP 的最大段长度 MSS(Maximum Segment Size) 或 MTU (Maximum Transmission Unit)，能够把此包发往目的的唯一 方法是把此包分片。由于包分片是正常的，它可以被利用来做恶意的攻击。 因为分片的包的第一个分片包含一个包头，若没有包分片的重组功能，包过滤器不可能检测附加的包分片。典型的攻击 Typicalattacks involve in overlapping the packet data in which packet header is 典型的攻击 Typicalattacksinvolve in overlapping the packet data in which packet header isnormal until isit overwritten with different destination IP (or port) thereby bypassing firewall rules。包分片能作为 DOS 攻击的一部分，它 可以 crash older IP stacks 或涨死 CPU 连接能力。 NetfilterIptables 中的连接跟踪代码能自动做分片重组。它仍有弱点，可能受到饱和连接攻击，可以把 CPU 资源耗光。 OK，到此为止，关于 Wireshark 抓包工具的一些小教程已经写完了，而导致想写这么一个纠结的教程的原因是，前几天通过这个抓包解决了梦幻西游在网维大师无盘上容易掉线的问题，当时捕捉到梦幻西游掉线时的数据包是这样的。 注意下图中的红色数据，123.58.184.241 是梦幻西游的服务器，而 192.168.1.41 是玩梦幻西游的客户机，在掉线时，发现是先有梦幻西游的服务器向客户机发送一个 [FIN,ACK] 数据包，根据上面的解释，FIN 标记的数据包是代表要断开连接的意思，而接着客户机又回给服务器一个确认断 开链接包。当看到这个抓包数据时，就意识到，大家说的在网维大师系统虚拟盘上梦幻爱掉线的问题，并非普通的网络问题，因为通过数据包的信息来看，是梦幻服 务器主动要求断开链接，产生这个情况无非是以下几个原因： 服务器发现客户端非法，比如有外挂什么的，踢掉了客户机； 服务器压力大，踢掉了客户机； 总之不是客户端问题导致的掉线； 那么既然结论是如此，为什么会有在网维大师系统虚拟盘上容易出现梦幻掉线问题呢？原因是由于网维大师系统虚拟盘是模拟真实硬盘方式来实现的，而在模拟过程 中，将硬盘的序列号设置为固定过的 OSDIY888 了，而梦幻西游刚好后识别客户机硬盘信息，发现大量客户端的硬盘序列号都是一样的，就认为是作弊或者使 用挂机外挂了，结果就导致随机被服务器踢下线的情况发生，后来将硬盘序列号设置为空，则没再出现该问题。这个问题在未来的新版本中会解决掉。 说这个案例的目的并不是为了说明抓包多有用，而是想说明一些解决问题的思路和方法，有些人是有思路，但是缺方法，比如不会用工具，而有些人收集了很多工具 却不会用，而其实就属于后者，几年前就收集了 n 多工具，但是用到的没几个。慢慢的学会用这些工具后，发现思维 + 工具，解决问题是效率暴增，接下来的几天 里，会陆续介绍写小工具给大家，也希望大家有空学习下，有问题先百度，再自己摸索，而不是一味的求助，毕竟求人不如求己！自己能直接搞定，是皆大欢喜的事情 注意：由于某些系统为了防止 ARP 攻击，都免疫掉了一个 Npptools.dll 文件，这会导致该软件无法正常安装，打下这个补丁就可以了","categories":["4.软件","WireShark"]},{"title":"WireShark过滤器","path":"/2023/05/22/4-软件-WireShark-WireShark过滤器/","content":"什么是 WiresharkWireshark 是一款功能强大的开源网络封包分析软件，广泛应用于网络管理和网络安全领域。这款软件能够实时捕获、分析和展示计算机网络中的数据包，为网络专业人员提供深入了解网络流量的工具。 功能与支持的协议Wireshark 支持多种网络协议，包括但不限于： 以太网：用于局域网的基本传输协议。 无线网络：分析 Wi-Fi 网络流量，了解数据的传输情况。 互联网协议（IP）：处理互联网上的地址和路由信息。 传输控制协议（TCP）：确保数据的可靠传输，提供流量控制和错误校验。 用户数据报协议（UDP）：用于速度要求高但不需要可靠性的应用，如视频流和在线游戏。 捕获数据包使用 Wireshark 时，用户只需通过连接到目标计算机网络的接口（如以太网口或无线网卡）来捕获网络数据包。捕获的数据包将以直观的方式在软件界面中显示。每个数据包的详细信息一目了然，包括： 源 IP 地址：数据包发送方的地址。 目标 IP 地址：数据包接收方的地址。 协议类型：指示使用的协议（如 TCP、UDP）。 数据长度：整个数据包的字节数。 用户可以通过简单的点击操作，深入查看每个数据包的字段及其内容，帮助分析流量中可能存在的问题。 过滤与分析工具Wireshark 提供强大的过滤功能，允许用户根据特定条件筛选数据包。例如，可以根据源 IP 地址、目标 IP 地址、协议类型等过滤数据，从而集中注意力于感兴趣的流量。此外，Wireshark 还提供了一系列分析工具和统计功能： 流量图表：可视化展示网络流量的变化趋势，便于识别流量高峰或异常情况。 协议分层显示：直观显示各种协议的分层结构，帮助用户理清数据交互的逻辑。 数据包重组：将分散的多个数据包重新组合，便于分析完整的通信内容。 应用场景Wireshark 在多个领域得到了广泛应用，如： 网络管理：网络管理员使用 Wireshark 来诊断网络故障，如延迟、丢包和连接问题，帮助确保网络正常运行。 网络安全：通过分析数据包，安全专业人员可以检测潜在的网络攻击和异常活动，从而采取适当的安全措施。 协议开发与调试：开发者利用 Wireshark 检查自定义协议的实现，调试网络通信，提高软件的健壮性。 总的来说，Wireshark 凭借其强大的功能、用户友好的界面和开放源代码的特性，已经成为网络分析领域的标准工具之一，深受业界专业人士的喜爱。 过滤器在 Wireshark 中，过滤器（Filter）是一种强大的工具，用于选择和筛选特定的网络数据包以供深入分析。通过过滤器，用户能够有针对性地显示感兴趣的数据包，从而有效减少分析的数据量，并专注于与特定问题、事件或协议相关的信息，提升整体的分析效率。 Wireshark 采用一种称为”显示过滤器”（Display Filter）的语法来定义过滤条件。用户可以根据多个参数来创建精细的过滤器规则，例如源 IP 地址、目标 IP 地址、协议类型（如 TCP 或 UDP）、端口号、数据包长度，以及特定字段的值等。当这些过滤器应用于网络数据包捕获或已保存的数据包时，只有符合这些条件的数据包会被显示，其他不相关的数据包则会被自动隐藏。 例如，若希望分析来自特定服务器（源 IP 地址）到客户端的所有 TCP 通信流量，可以使用类似 ip.src == 192.168.1.1 tcp 的过滤器。这种方式不但缩小了需要查看的数据包范围，还能让分析人员更快速地评估这些数据包的内容和状态。 Wireshark 提供了丰富的过滤器语法和功能，使用户能够根据不同需求创建复杂的过滤标准。用户可以使用比较运算符（如 ==, !=, , 等）、逻辑运算符（如 , ||, !）和通配符，构建更精确的过滤规则。同时，可以通过组合多个条件，定义出更为复杂的过滤器，以便更好地获取相关数据。 在网络分析和故障排除过程中，过滤器极为重要。它们不仅帮助分析人员有效集中注意力于特定数据包，还提供了更清晰、有针对性的分析视角。这对于处理复杂网络问题和优化网络性能，有着不可或缺的作用。 过滤器的区别Wireshark 中存在两种主要的过滤器：捕捉过滤器（Capture Filters）和显示过滤器（Display Filters），它们的作用和语法截然不同。 捕捉过滤器捕捉过滤器用于决定在进行数据捕捉时，哪些信息应该被记录在捕捉结果中。这些过滤器必须在捕捉过程开始之前设置。例如，如果仅需捕捉 TCP 流量，可以设置过滤器为 tcp，这样就只会记录 TCP 协议的数据包，而忽略其他类型的流量。捕捉过滤器作为数据捕捉的第一层过滤，目的是控制捕捉数据的数量，从而避免生成过大的日志文件，这对于存储和后续分析都有显著的益处。 显示过滤器显示过滤器则是在捕捉结果中进行详细查找的工具。在捕捉完成后，它可以随时被修改，以便帮助用户快速定位所需的记录。例如，如果在捕捉过程中记录了大量的数据包，用户可以之后应用显示过滤器 http，迅速找到其中的 HTTP 请求与响应。这种灵活性使得显示过滤器成为一种更为强大和复杂的过滤手段。 总结而言，捕捉过滤器与显示过滤器的目的和使用场景完全不同。捕捉过滤器是在数据捕捉之初进行的第一道防线，而显示过滤器则是后续分析时用于精确查找的高级工具，它们共同构成了 Wireshark 强大的分析能力，帮助用户有效解析和理解网络流量。 捕捉过滤器Protocol（协议）:可能的值：ether、fddi、ip、arp、rarp、decnet、lat、sca、moprc、mopdl、tcp 和 udp。 如果没有特别指明协议，过滤器将默认使用所有支持的协议。例如，捕捉所有通过网络传输的数据时，可以简单地省略协议参数，系统会自动获取所有可用的传输协议数据。 Direction（方向）:可能的值：src（来源）、dst（目的地）、src and dst（来源和目的地）、src or dst（来源或目的地）。 若未特别指定，则默认值为 src or dst。举个例子，表达式 host 10.2.2.2 与 src or dst host 10.2.2.2 是相同的，皆可捕捉目的地或来源为 10.2.2.2 的封包。 Host(s):可能的值：net（网络）、port（端口）、host（主机）、portrange（端口范围）。 若未指定，此值默认为 host。例如，表达式 src 10.1.1.1 和 src host 10.1.1.1 是等效的，会捕捉所有来源地址为 10.1.1.1 的封包。 Logical Operations（逻辑运算）:可能的值：not（否）、and（与）、or（或）。 运算时，not 优先级最高，and 和 or 优先级相同，并按顺序从左至右进行。例如，表达式 not tcp port 3128 and tcp port 23 与 (not tcp port 3128) and tcp port 23 是等效的，而 not tcp port 3128 and tcp port 23 与 not (tcp port 3128 and tcp port 23) 不同。 示例： tcp dst port 3128捕捉目的 TCP 端口为 3128 的封包，这通常用于代理服务。 ip src host 10.1.1.1捕捉来源 IP 地址为 10.1.1.1 的封包，适用于监控特定设备的流量。 host 10.1.2.3捕捉目的或来源 IP 地址为 10.1.2.3 的封包，这确保了与该地址的所有数据包都不被遗漏。 ether host e0-05-c5-44-b1-3c捕捉目的或来源 MAC 地址为 e0-05-c5-44-b1-3c 的封包。如果需要监控本机与外部网络之间的数据流，可以替换为路由器的 MAC 地址以捕捉相应流量。 src portrange 2000-2500捕捉来源端口为 2000 至 2500 范围内的 UDP 或 TCP 封包，这常用于特定服务如游戏或文件传输协议。 not icmp显示除了 ICMP 封包以外的所有封包，方便分析除 ping 以外的网络行为。 src host 10.7.2.12 and not dst net 10.200.0.0/16显示来源 IP 为 10.7.2.12，但目的地不是 10.200.0.0/16 的封包，适用于特定的流量监控和安全策略。 (src host 10.4.1.12 or src net 10.6.0.0/16) and tcp dst portrange 200-10000 and dst net 10.0.0.0/8捕捉来源 IP 为 10.4.1.12 或来源网络为 10.6.0.0/16，同时目的地 TCP 端口号在 200 至 10000 之间，并且目的地位于网络 10.0.0.0/8 内的所有封包，用于广泛的数据分析。 src net 192.168.0.0/24捕捉源地址为 192.168.0.0 网络内的所有封包，适用于内部网络监控。 src net 192.168.0.0 mask 255.255.255.0同样捕捉源地址为 192.168.0.0 网络内的所有封包，可用于网络管理和问题排查。 注意事项： 使用关键字作为值时，需在关键字前加上反斜杠 \\。 示例：ether proto \\ip（与关键字 ip 相同）。这样的表达方式会使得过滤器关注 IP 协议。 另一种写法：ip proto \\icmp（与关键字 icmp 相同）。该写法表示需要捕捉与 ping 工具通信用的 ICMP 协议相关的数据包。 可以在 ip 或 ether 后面使用 multicast 及 broadcast 关键字。例如，当想要排除广播请求时使用 no broadcast 关键字时非常有效。 Protocol（协议）:使用 OSI 模型第 2 至 7 层的多种协议。点击 “Expression…” 按钮将显示可用协议，如 IP、TCP、DNS、SSH 等，便于用户选择。 String1, String2 (可选项):提供更详细的匹配条件。 协议的子类:点击相关父类旁的 “+” 号，然后选择其子类，能够进一步精细化数据包的捕捉条件。 使用此捕捉过滤器可以高效管理和监控网络流量，帮助排查潜在的安全问题或网络故障。 显示过滤器过滤器用于捕获和显示特定类型的数据包。以下是一些常见的过滤条件及其解释： 例子 snmp || dns || icmp这个过滤器用于显示 SNMP、DNS 或 ICMP 封包。使用这个过滤器时，任何一个满足条件的封包都会被显示。 ip.addr == 10.1.1.1用于显示所有来源或目的 IP 地址为 10.1.1.1 的封包。这意味着无论是发起连接的设备，还是接收连接的设备，任一方为这个 IP 地址的封包都会被过滤出来。 ip.src != 10.1.2.3 or ip.dst != 10.4.5.6该过滤器会显示来源不为 10.1.2.3 或者目的不为 10.4.5.6 的封包。换句话说，显示封包的条件为： 来源 IP：任意 IP，但不是 10.1.2.3 目的 IP：任意 IP，但不是 10.4.5.6 ip.src != 10.1.2.3 and ip.dst != 10.4.5.6这个过滤器用于显示来源 IP 不为 10.1.2.3 且目的 IP 不为 10.4.5.6 的封包。要求同时满足来源和目的 IP 的条件，准确取出更为特定的封包。 来源 IP：任意 IP，但不是 10.1.2.3 目的 IP：任意 IP，但不是 10.4.5.6 tcp.port == 25此过滤器显示来源或目的 TCP 端口号为 25 的封包，通常用于识别和分析与电子邮件相关的流量，因为端口 25 是邮件传输代理（MTA）使用的标准端口。 tcp.dstport == 25显示目的 TCP 端口号为 25 的封包，只关注那些发往特定端口的流量，适合用来监控邮箱服务器的流量。 tcp.flags此过滤器显示所有包含 TCP 标志的封包。此时可以深入分析 TCP 连接的控制信息，如 SYN、ACK 和 FIN 等。 tcp.flags.syn == 0x02用于显示包含 TCP SYN 标志的封包，常用于建立新连接时的初始请求。TCP 三次握手的第一步就是发送 SYN 包以请求建立连接。 一旦设置了过滤器，软件界面会根据过滤器的语法对表达式进行颜色编码。正确的过滤器背景呈绿色，指示没有语法错误；而错误的过滤器背景呈红色，提示用户进行修正。 更多详细信息，请访问 Wireshark 过滤器指南。 数据包的分析以上仅介绍了基本的抓取和过滤方法，但若想深入分析网络包，还需了解常见的协议标记和操作过程。例如，TCP 的三次握手，由三个主要步骤组成： SYN：客户端向服务器发送一个带有 SYN 标志的数据包，表示请求建立连接。 SYN-ACK：服务器回应客户端，发送一个同时带有 SYN 和 ACK 标志的数据包，确认接收到的请求。 ACK：客户端向服务器发送 ACK 数据包，确认连接成功。 理解这些步骤有助于分析网络通信过程，识别连接是否成功以及存在的潜在问题。","categories":["4.软件","WireShark"]}]