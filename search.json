[{"title":"Qt的条件编译","path":"/2024/06/12/语言-Qt-Qt的条件编译/","content":"通过 DEFINES 定义宏可以在 pro 文件中使用 DEFINES += 宏名来定义宏。然后在 pro 文件或源码中使用 contains(DEFINES,宏名) 来判断该宏是否被定义,从而实现条件编译。 123456789101112DEFINES += MY_MACRO # 定义宏 MY_MACROcontains(DEFINES, MY_MACRO) &#123; message(&quot;MY_MACRO defined&quot;)\t# 做一些操作&#125; else &#123; message(&quot;MY_MACRO not defined&quot;) # 做其他操作&#125;contains(QMAKE_HOST.os, Unix) &#123; # 针对unix平台做一些操作&#125; 在源码中也可以使用 #ifdef MY_MACRO...#endif 来根据宏定义进行条件编译。 通过 CONFIG 配置CONFIG 变量用于指定工程配置和编译器选项,每个选项值都可用于条件判断。 1234567CONFIG += MY_CONFIGMY_CONFIG &#123; LIBS += -lmydll # 链接某库&#125; else &#123; LIBS += -lxxxdll # 链接其他库&#125; 通过平台判断QMake 提供了一些内置变量来判断当前平台,如 win32、macx、android 等,可以根据这些变量进行条件编译。 12345678910win32 &#123; LIBS += -lwindowslib&#125;macx &#123; LIBS += -lmaclib &#125;!macx:!win32 &#123; # 针对unix平台做一些操作 &#125;","categories":["语言","Qt"]},{"title":"文件IO","path":"/2024/06/07/平台Platform-Linux-IO-文件IO/","content":"文件 IO 文件描述符 进程的概念 从硬盘到内存到cpu的的动态过程 进程内唯一，每个打开的文件都对应内核中的一块区域，被内核管理 内核给用户一个整型值用来通知内核要操作的文件 缺省默认当前可用的最小值 012 缺省文件描述符 分别映射一个硬件设备 由系统默认打开 文件 IO API 编程接口,就是函数名 fp = open(pathname, flag); fp = open(pathname, flag, mode); ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); close(fd); lseek(); 空洞文件。 文件和目录 文件属性: stat(&quot;pathname&quot;, struct stat p); fstat(int fd, ....); lstat(&quot;..&quot;, ....); getpwuid(); //根据uid获取用户信息 getgrgid(); // gid 组信息 localtime(); struct stat &#123;&#125;; 文件信息结构体 struct passwd &#123;&#125;; 用户信息结构体 pw = getpwuid(sb.st_uid); struct group &#123;&#125;; 组信息结构体 struct tm&#123;&#125;; 时间结构体 文件夹: DIR *opendir(); struct dirent * readdir(); closedir(); struct dirent &#123;&#125;; 拓展: getopt(); 获取短参函数 ls -la access(); 检查文件文件是否存在和文件权限函数 chdir();","categories":["平台Platform","Linux","IO"]},{"title":"Shell脚本","path":"/2024/06/07/语言-Shell脚本/","content":"Shell 脚本的本质: shell命令的有序集合 #!&#x2F;bin&#x2F;bash chmod u+x test.sh.&#x2F;test.sh &#x3D;&#x3D; &#x2F;home&#x2F;fs&#x2F;Temp&#x2F;test.sh &#x2F;bin&#x2F;bash test.sh chmod u+x test.shPATH+&#x3D;:&#x2F;home&#x2F;fs&#x2F;Temptest.sh 任意目录运行 chmod u+x test.sh sudo mv test.sh &#x2F;bin&#x2F; Shell 变量 自定义变量: 1.不区分数据类型,全部识别为字符串 2.命名符合标识符规定, 3.引用 $Var $&#123;&#125; 边界识别 4. 只读变量 readonly 变量名 5. 删除变量 unset 变量名 set 显示本地的所有变量 位置变量: $# 参数的个数 $? 命令执行结果,函数返回结果, $$ 进程id $1,$2..$9,$&#123;10&#125;, $&#123;11&#125; $@ &quot;&quot; $* &quot;$*&quot; 当做整体处理 环境变量 (全局可以访问的变量) env export 变量名 将局部变量变为全局变量 PS: 脚本中定义的变量只在本脚本有效 功能语句 read -p &quot;提示内容&quot; -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 read -n 5 AA BB CC read AA BB CC hello xiaoming, mingtian you kong expr expr $AA + $BB sum=`expr $AA +　$BB` sum=$(expr $AA + $BB) sum=$(($AA + $BB)) sum=$[$AA + $BB] let &quot;sum=$AA + $BB&quot; let sum=$AA+$BB test 字符串 test str1 = str2 != 整数\t-eq -ne -gt -ge -lt -le 文件属性 -d -f -r -w 结构语句 switch case if for while untill if [ ] then\tfi if [ ]then else fi case case var in 1) ... ;; 2|3|4) ... ;; esac for 变量 in 单词表 do .. done for ((i=0; i&lt;N; i++)) do done for var in `ls` for var in $(ls) for var\t#单词表的内容是位置参数变量时，可以省略in ... while 表达式 do 。。 done while (($i &lt; $loop)) do ... done 函数 定义： 函数返回值用$? 输出给了变量 var&#x3D;$(add_fun) 返回值范围 0-255 传参: add_fun str1 str2 str3 gcc 编译流程 step1:预处理 头文件加载,宏定义替换,条件编译,注释 生成预处理文件.i &lt;有效文件&gt; gcc -E name.c -o name.i gcc -o name.i -E name.c step2:编译 检查代码的语法错误,如果有错误，报错，结束编译。否则，生成汇编代码.s gcc -S name.i -o name.s\tgcc -o name.s -S name.i step3:汇编 将汇编源码编译生成机器码(目标文件).o gcc -c name.s -o name.o gcc -o name.o -c name.s step4:链接 将目标文件(&gt;=个)链接生成可执行文件 gcc name.o -o name gcc -o name name.o gdb","categories":["语言"]},{"title":"函数笔记","path":"/2024/06/07/平台Platform-Linux-其他-函数笔记/","content":"timetime() 获取当前的系统时间，从一个标准时间点到此时的时间经过的秒数 localtime() 返回以 tm 结构表达的时间 asctime() 参数所指的 tm 结构中的信息转换成真实世界所使用的时间日期表示方法，然后将结果以字符串形态返回。","categories":["平台Platform","Linux","其他"]},{"title":"基于FreeGPT35的GPT-3.5 API本地化部署","path":"/2024/06/05/AI-基于FreeGPT35的GPT-3-5-API本地化部署/","content":"项目地址 https://github.com/missuo/FreeGPT35?tab=readme-ov-file 关联项目说明： ChatGPT Next Web 提供跨平台私人 ChatGPT 应用&#x2F;网页 lobe-chat免费拥有你自己的 ChatGPT&#x2F;Gemini&#x2F;Claude&#x2F;Ollama 应用","categories":["AI"]},{"title":"博客部署各端口功能分布","path":"/2024/06/02/博客-博客部署各端口功能分布/","content":"9050：Hexo 博客部署端口 9080：FRP 映射对接端口 9081：FRP 的 DashBoard 9082：NAS 映射端口 9083：Alist 映射端口 9090：1Panel 服务器运维管理面板 PDF 处理工具搭建到云服务器 圈小猫，游戏搭建到云服务器 freedns42 如何利用微信小号自动剪藏，稍后阅读","categories":["博客"]},{"title":"一些在用的软件","path":"/2024/05/31/软件-一些在用的软件/","content":"工具软件：utools 图床：PicGo 终端：MobaXterm RSS 阅读：Lettura 磁盘空间分析：SpaceSniffer 重复文件清除：Duplicate Cleaner Pro 5 笔记软件：Obsidian 搜索软件： Archivarius 3000 设置索引目录，支持 txt／pdf／word／xls／ppt &#x2F;azw3／epub／mobi／md 等常见文档 &amp; 压缩包内文档的搜索 Everything PDF 翻译：彩云小译（网页） https://fanyi.caiyunapp.com 翻译软件：deepL 视频播放软件 VLC 项目地址： https://github.com/videolan/vlc CuteMarkEd 基于 Qt5 开发,一款开源免费的 Markdown 编辑器，项目地址 https://github.com/cloose/CuteMarkEd 每日菜单 项目地址 https://github.com/YunYouJun/cook 下载软件 Aria2 和 AriaNG AriaNG 是 mayswind 大神做的一个前端界面 aria2 是命令行下载工具 下载一个 bt 任务或者磁力链手动增加 tracker 列表，列表地址 https://github.com/ngosang/trackerslist","categories":["软件"]},{"title":"Alist个人网盘搭建","path":"/2024/05/31/其他-NAS-Alist个人网盘搭建/","content":"Alist 搭建方案 方案一：云服务器直接搭建及存储 方案二：云服务搭建页面，NAS 需要搭建 webdav，同时需要提供 NAS 穿透方案 方案三：云服务器提供穿透方案 frp&#x2F;Cloudflared，NAS 搭建页面和存储 本地搭建 Alist仓库地址 https://github.com/alist-org/alist Relaes 地址 https://github.com/alist-org/alist/releases 下载对应版本的 alist 使用，直接解压后按照下述方式运行即可 123456789101112131415# 解压下载的文件，得到可执行文件：unzip alist-xxxx.zip# 运行程序.\\alist.exe server# 获得管理员信息 以下两个不同版本，新版本也有随机生成和手动设置# 低于v3.25.0版本.\\alist.exe admin# 高于v3.25.0版本# 随机生成一个密码.\\alist.exe admin random# 手动设置一个密码 `NEW_PASSWORD`是指你需要设置的密码.\\alist.exe admin set NEW_PASSWORD 之后访问本地 http://127.0.0.1:5244/ 即可打开 Alist 页面。 配置Alist 配置存储直接按照 Alist 官方文档配置即可，配置完成后，NAS 利用 CloudSync 套件，添加 WebDav 站点后即可访问。 WebDav 配置如果没有单独留路径选项那正常就是在 站点后面添加 /dav 选项，如下所示： 其他 搭建 NAS，192.168.2.100:5000 搭建 Alist，192.168.2.100:5244 Alist 添加夸克网盘&#x2F;移动云盘&#x2F;百度网盘 NAS 中安装 CloudSync，链接到 Alist 的 WebDav，双向同步方案 通过 FRP 透传 NAS 的端口和 WebDav 的端口到外网 如何让 Alist 网盘内不同的文件夹同步","categories":["其他","NAS"]},{"title":"NAS相关配置","path":"/2024/05/31/其他-NAS-NAS相关配置/","content":"控制面板-网络-设置，设置 DNS 为 223.5.5.5 或者 114.114.114.114 或者 119.29.29.29 配置时间服务器控制面板-高级模式-区域选项，与 NTP 服务器同步：打字填入 ntp1.aliyun.com 或者 time.apple.com 配置 SSH 服务 打开控制面板 选择终端机和 SNMP，启动 SSH 功能，设置端口号 打开 mobaxterm 连接 NAS 的 IP 加上设置的 SSH 端口号 进入终端后输入用户名和密码登录，之后输入 sudo -i 进入 root 用户但是默认 22 端口要改掉，最好在 9000 以上 配置自启动编辑 rc.local 添加自启动脚本 1234#!/bin/shcd /home/ubuntu/frpServer/frp_0.52.3_linux_amd64#按照配置文件启动服务器端./frps -c ./frps.toml 在 NAS 中添加脚本到任务计划 进入控制面板，选择任务计划，选择新增 - 触发的任务 - 用户定义的脚本 编辑任务名称，选择账号为 root，事件为开机，勾选已启动 编辑任务设置，编辑运行命令中的内容为 bash /root/start.sh 确定保存后在该任务上右击，选择运行 猫盘考虑下大猫盘接入 USB 接口 配置 FRP，同步至云服务器 配置 SYNC，同步至夸克&#x2F;移动&#x2F;百度 frp 方案依赖服务器带宽，比较卡","categories":["其他","NAS"]},{"title":"CAN Open Linux代码分析","path":"/2024/05/28/通讯协议-CAN-CAN-Open-Linux代码分析/","content":"主文件 CO_main_basic.c进入 Main 函数中运行，最开始都是一些关于存储&#x2F;多线程&#x2F;功能启用部分的配置代码，后面我们会根据宏定义来讲解。实际的第一行初始化代码从以下开始。 123uint32_t heapMemoryUsed = 0;CO_config_t *config_ptr = NULL;CO = CO_new(config_ptr, &amp;heapMemoryUsed); 该函数的作用是创建一个 CAN open 对象，在单个 OD 的情况下，config 应为 NULL，参数从默认的 “OD.h “文件中获取。如果定义了 CO_USE_GLOBALS，那么函数将为所有 CANopenNode 对象使用全局静态变量。否则，它将从堆中分配所有对象。 12CO_epoll_t epMain;err = CO_epoll_create(&amp;epMain, MAIN_THREAD_INTERVAL_US); 该函数创建 Linux epoll 监控 timerfd 和 eventfd。创建并配置多个 Linux 通知，以触发任务的执行。CO_epoll_create 中实现了 epoll 拦截并监控多个文件描述符，其中 timerfd 以恒定的定时器间隔触发，eventfd 则根据外部信号触发。 123CO_CANptrSocketCan_t CANptr = &#123;0&#125;;CANptr.can_ifindex = if_nametoindex(&quot;can0&quot;);CANptr.epoll_fd = epMain.epoll_fd; 设置用于 CO_CANinit 的指针参数，主要传入 CAN 设备名和监控的 epoll 描述符。 之后进入 CAN open 通讯初始化阶段，注意该阶段是可以通过 0x82 命令，即 CANopen communication reset 重置的。 12CO_CANsetConfigurationMode((void *)&amp;CANptr);CO_CANmodule_disable(CO-&gt;CANmodule); 进入 CAN 配置，主要还是在通过 0x82 命令重启后，禁用 CANmodule 模块。 1err = CO_CANinit(CO, (void *)&amp;CANptr, 0 /* bit rate not used */); 初始化 CAN 驱动，如果是通过 0x82 命令重启的通讯，也必须重新初始化。其中的波特率参数在 Linux 部分中还不被支持。之后是 LSS 部分的初始化，该部分内容属于 CiA 305，先略过，之后有时间在分析实现。 123456789101112131415161718#define NMT_CONTROL \\ CO_NMT_STARTUP_TO_OPERATIONAL \\ | CO_NMT_ERR_ON_ERR_REG \\ | CO_ERR_REG_GENERIC_ERR \\ | CO_ERR_REG_COMMUNICATION err = CO_CANopenInit(CO, /* CANopen object */ NULL, /* alternate NMT */ NULL, /* alternate em */ OD, /* Object dictionary */ NULL, /* Optional OD_statusBits */ NMT_CONTROL, /* CO_NMT_control_t */ 500, /* firstHBTime_ms */ 1000, /* SDOserverTimeoutTime_ms */ 500, /* SDOclientTimeoutTime_ms */ false, /* SDOclientBlockTransfer */ CO_activeNodeId, //Node ID &amp;errInfo); 初始化除 PDO 对象外的 CAN open 通讯协议（同样也必须在 0x82 命令后调用）。 CO CANopen 对象。 em 紧急对象，用于不同的 CANopen 对象内部，通常用于错误报告。如果为空，则使用 co-&gt;em。如果为空，且 co-&gt;CNT_EM 为 0，则函数错误返回。 NMT 如果 co-&gt;CNT_NMT 为 0，则必须指定该对象；如果 co-&gt;CNT_NMT 为 1，则该对象将被忽略，可以为 NULL。NMT 对象用于 NMT 对象用于在 CO_process()内部检索 NMT 内部状态。 od CANopen 对象字典。之前有提到的 ODxyz.h 中定义。 OD_statusBits 传递给 CO_EM_init() 的参数。可以为空。 NMTcontrol 传递给 CO_NMT_init() 的参数。 firstHBTime_ms 传递给 CO_NMT_init() 的参数。 SDOserverTimeoutTime_ms 传递给 CO_SDOserver_init() 的参数。 SDOclientTimeoutTime_ms SDO 客户端的默认超时时间毫秒，一般为 500。 SDOclientBlockTransfer 如果为 “true”，则默认在 SDO 客户端设置块传输。 nodeId CANopen 节点 ID（1 … 127）或 0xFF（未配置）。在 CANopen 初始化中，它与 CO_LSSinit() 中的 pendingBitRate 相同。如果为未配置，则某些 CANopen 对象将不会被初始化或处理。 errInfo 也可以在函数返回 CO_ERROR_NO 的非关键错误中设置。 成功时返回 CO_ERROR_NO。 1CO_epoll_initCANopenMain(&amp;epMain, CO); 该函数用于配置 CAN 接收后的自定义回调。自定义回调函数可由应用程序选择性注册，并在操作系统中配置线程。回调函数会在高优先级线程预处理完某些内容后调用，并且必须由低优先级线程进一步处理。例如，当接收到 CAN 报文并进行预处理后，回调应唤醒主线程处理函数。 123CO_EM_initCallbackRx(CO-&gt;em, EmergencyRxCallback);CO_NMT_initCallbackChanged(CO-&gt;NMT, NmtChangedCallback);CO_HBconsumer_initCallbackNmtChanged(CO-&gt;HBcons, 0, NULL, HeartbeatNmtChangedCallback); CO_EM_initCallbackRx，初始化 Emergency 接收回调函数。该函数在收到错误条件后执行。 CO_NMT_initCallbackChanged，初始化 NMT 状态变化回调函数。该函数在 NMT 状态发生变化后被调用。该函数可能会唤醒处理 NMT 事件的外部任务。第一次调用会立即向消费者提供 当前的 NMT 状态。 CO_HBconsumer_initCallbackNmtChanged，初始化心跳消费者 NMT 更改回调函数，当 NMT 状态发生变化时调用的回调函数。 1CO_TIME_set(CO-&gt;TIME, time_ms, time_days, TIME_STAMP_INTERVAL_MS); 设置当前时间，并设置生产者的间隔时间为 TIME_STAMP_INTERVAL_MS，以毫秒为单位，此处设置为 10000ms。 12345err = CO_CANopenInitPDO(CO, /* CANopen object */ CO-&gt;em, /* emergency object */ OD, /* Object dictionary */ CO_activeNodeId, &amp;errInfo); 必须在通信重置 0x82 部分的末尾调用该函数，否则某些 OD 变量将无法正确映射到 PDO 中。函数参数就是 CAN Open 对象，EM 对象，OD 对象，NodeID 以及错误信息这些。 1CO_CANsetNormalMode(CO-&gt;CANmodule); 已完成所有对象初始化，设置状态，准备进入主循环函数。在主循环函数中，通过 epoll 监控多个文件描述符。 1234CO_epoll_wait(&amp;epMain);CO_epoll_processRT(&amp;epMain, CO, false);CO_epoll_processMain(&amp;epMain, CO, GATEWAY_ENABLE, &amp;reset);CO_epoll_processLast(&amp;epMain); CO_epoll_wait 函数会阻塞，直到 epoll 上注册了以下事件：timerfd、eventfd 或应用程序指定的事件。函数还会计算自上次调用以来的 timeDifference_us 并准备 timerNext_us。 CO_epoll_processLast，epoll 事件的关闭函数，此函数必须在 CO_epoll_wait() 之后调用。在它们之间是应用程序指定的处理函数，可以检查自己的事件并进行处理。应用程序还可以降低 timerNext_us 变量的值。如果将 timerNext_us 变量调低，则将重新配置间隔定时器，并提前触发 CO_epoll_wait()。 CO_epoll_processRT 和 CO_epoll_processMain 指定了处理函数，接下来先说明 CO_epoll_processRT 处理函数。 123456//CO_CANrxFromEpoll 如果 epoll 事件与任何 CAN 接口匹配，则返回 True。CO_CANrxFromEpoll(co-&gt;CANmodule, &amp;ep-&gt;ev, NULL, NULL);syncWas = CO_process_SYNC(co, ep-&gt;timeDifference_us,pTimerNext_us);CO_process_RPDO(co, syncWas, ep-&gt;timeDifference_us,pTimerNext_us);CO_process_TPDO(co, syncWas, ep-&gt;timeDifference_us,pTimerNext_us); 在 CO_epoll_processRT 中处理以上的 SYNC&#x2F;TPDO&#x2F;RPDO 协议。 1234567891011CO_CANmodule_process(co-&gt;CANmodule);CO_EM_process(co-&gt;em, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_NMT_process(co-&gt;NMT,&amp;NMTstate,timeDifference_us,timerNext_us);CO_SDOserver_process(&amp;co-&gt;SDOserver[i], NMTisPreOrOperational, timeDifference_us,timerNext_us);CO_HBconsumer_process(co-&gt;HBcons, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_TIME_process(co-&gt;TIME, NMTisPreOrOperational, timeDifference_us); 在 CO_epoll_processMain 中处理了以上的 EM&#x2F;NMT&#x2F;SDOServer&#x2F;HB&#x2F;TIME 协议。 CO_SINGLE_THREAD该参数在 Makefile 中通过-D 参数指定，作用是配置程序在单线程中运行。单线程运行时不同的事件（例如 CAN 接收或计时器到期）会触发循环通过堆栈（所有代码都是非阻塞的）。它需要较少的系统资源。 在多线程操作中，除了主线线程外，还建立了一个实时线程。RT 线程每毫秒运行一次，并使用外围设备读&#x2F;写、控制程序或类似程序处理 PDO 和可选应用程序代码。使用此配置必须考虑竞争条件，例如，从主线线程运行的应用程序代码在访问 OD 变量时必须使用 CO_(UN)LOCK_OD 宏。 CO_CONFIG_STORAGE该参数由 CO_CONFIG_STORAGE_ENABLE 在 CO_config.h 中使能，主要作用是依据 CiA 301 标准对控制数据进行存储和恢复。数据源通常是对象字典中的一组变量，但并不局限于 OD。在生成对象字典（OD.h 和 OD.c 文件）时，会根据 “存储组 “参数将 OD 变量分组为结构。 OD 对象 0x1010 - 存储参数OD 对象 0x1010 - 存储参数： 子索引 0：支持的最高子索引 子索引 1：保存所有参数，UNSIGNED32 子索引 2：保存通信参数，UNSIGNED32 子索引 3：保存应用参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其存储功能的信息： 位 0：如果设置，CANopen 设备根据命令保存参数 位 1：如果设置，CANopen 设备自主保存参数 写入值 0x65766173（’s’、’a’、’v’、’e’，从 LSB 到 MSB）可存储相应数据。相应数据。 OD 对象 0x1011 - 恢复默认参数 子索引 0：支持的最高子索引 子索引 1：恢复所有默认参数，UNSIGNED32 子索引 2：恢复通信默认参数，UNSIGNED32 子索引 3：恢复应用程序默认参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其恢复能力的信息： 位 0：如果设置，CANopen 设备恢复参数 写入值 0x64616F6C（’l’、’o’、’a’、’d’从 LSB 到 MSB）可恢复相应数据。相应数据。 CO_CONFIG_GTW网关对象由标准 CiA 309 - CANopen 从其他网络访问涵盖。它可以将 NMT 主站、SDO 客户端和 LSS 主站用作网关设备。 本次使用中不支持该形式，直接在 CO_config.h 中注释掉该模块即可。 数据字典 OD 操纵CANopen 数据字典 OD 基本上是一个 XML 文件，其中包含 CANopen 设备的所有信息。文件的大部分是所有对象字典变量的列表，其中包含所有必要的属性和文档。该文件可使用 OD 编辑器应用程序进行编辑，并可用作数据源，从中生成 CANopenNode 的对象字典。该文件还可用于 CANopen 配置工具，在运行的 CANopen 网络上与 CANopen 设备进行交互。 CANopen 还为 CANopen 设备描述指定了另一种类型的文件。它们是 INI 格式的 EDS 文件。可以在这两种格式之间进行转换。设备描述文件的扩展名为 “XDD”。该文件的名称应包含 CANopen 设备的供应商 ID，以 8 位十六进制数字的形式出现在名称的任意位置，并用下划线分隔。例如 “name1_12345678_name2.XDD”。CANopenNode 包含多个配置文件定义文件，每个 CANopen 对象一个。这些文件的扩展名为 “XPD”。它们采用与 XDD 文件相同的 XML 格式。XML 编辑工具可以使用 XPD 文件将准备好的数据插入正在编辑的设备描述文件 (XDD)。还有扩展名为 “XDC “的设备配置文件。这些文件描述了已配置的 CANopen 设备，并包含其他元素，如默认值、分母和设备调试元素。类似于 INI 格式的 “dcf “文件。 使用OD object是指对象字典中位于特定 16 位索引的对象。CANopen 中有不同类型的 OD 对象：变量、数组和记录（结构）。每个 OD 对象都包含指向实际数据、数据长度和属性的指针。在 OD_objectTypes_t 中被定义。 OD variable 是指定类型的基本变量。例如：int8_t、uint32_t、float64_t……或数据长度已知或未知的二进制数据序列。每个 OD 变量都以指定的 16 位索引和 8 位子索引存在于对象字典中。 OD entry指的是结构元素，其中包含 OD 对象的一些基本属性、OD 对象的类型指示以及指向 OD 对象所有必要数据的指针。OD 条目数组以及 OD 条目总数信息代表 CANopenNode 内部定义的对象字典。参见 OD_entry_t 和 OD_t。 应用程序和堆栈可通过通用的 OD_t 对象和 OD_find() 函数访问 OD 对象。无需直接访问定义对象字典的自定义结构。特定 OD 变量的属性可通过 OD_getSub()函数获取。通过 read 和 write 函数访问实际变量。 OD_getSub() 可以获取这两个函数的指针。参见 OD_stream_t。另请参见快捷方式： CO_ODgetSetters 用于访问不同类型的数据。 可以从不同的线程访问 OD 变量。CANopenNode 基本上在两个线程中运行：快速实时线程（PDO 处理等）和非关键时间主线程（SDO 等）。两个线程都可以访问 OD 变量，因此必须小心谨慎。CANopenNode 使用锁定机制，SDO 服务器在读取或写入 OD 变量时会阻止实时线程的执行。在 CO_storage 中也需要对 OD 变量进行同样的保护。更多信息请参见 CO_driver.h 中的 CO_critical_sections。 OD 文件-ODxyz.c&#x2F;.h一个 CANopen 设备的实际对象字典由一对 OD_xyz.h 和 ODxyz.c 文件定义。 后缀 “xyz “是对象字典的唯一名称。如果使用单个默认对象字典，则省略后缀。这样就可以配置多个对象字典。 用于定义 OD 的数据安排在多个结构中。不同的 OD 配置有不同的结构。用这些结构创建的数据对象可以是常量，也可以是变量。 实际的 OD 变量位于多个结构（即存储组）中。选定的组可以选择存储到非易失性存储器中。 手动编辑 ODxyz.h&#x2F;.c 文件非常容易出错。 OD 编辑工具可生成成对的 ODxyz.h&#x2F;.c 文件。该工具可以编辑 xml 格式的标准 CANopen 设备描述文件。Xml 文件可能还包括一些 CANopenNode 特有的非标准元素。然后，Xml 文件将用于自动生成 ODxyz.h&#x2F;.c 文件。 1234567891011121314151617181920212223242526272829303132/* OD data declaration of all groups ******************************************/typedef struct &#123; uint32_t x1000_deviceType; struct &#123; uint8_t maxSubIndex; uint32_t vendorID; uint32_t productCode; uint32_t revisionNumber; uint32_t serialNumber; &#125; x1018_identity;&#125; ODxyz_PERSIST_COMM_t;typedef struct &#123; uint8_t x1001_errorRegister; uint8_t x1003_preDefinedErrorField_sub0; uint32_t x1003_preDefinedErrorField[8];&#125; ODxyz_RAM_t;extern ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM;extern ODxyz_RAM_t ODxyz_RAM;extern OD_t *ODxyz;/* Object dictionary entries - shortcuts **************************************/#define ODxyz_ENTRY_H1000 &amp;ODxyz-&gt;list[0]#define ODxyz_ENTRY_H1001 &amp;ODxyz-&gt;list[1]#define ODxyz_ENTRY_H1003 &amp;ODxyz-&gt;list[2]#define ODxyz_ENTRY_H1018 &amp;ODxyz-&gt;list[3]#define ODxyz_ENTRY_H1000_deviceType &amp;ODxyz-&gt;list[0]#define ODxyz_ENTRY_H1001_errorRegister &amp;ODxyz-&gt;list[1]#define ODxyz_ENTRY_H1003_preDefinedErrorField &amp;ODxyz-&gt;list[2]#define ODxyz_ENTRY_H1018_identity &amp;ODxyz-&gt;list[3] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#define OD_DEFINITION#include &quot;301/CO_ODinterface.h&quot;#include &quot;ODxyz.h&quot;/* OD data initialization of all groups ***************************************/ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM = &#123; .x1000_deviceType = 0, .x1018_identity = &#123; .maxSubIndex = 4, .vendorID = 0, .productCode = 0, .revisionNumber = 0, .serialNumber = 0 &#125;&#125;;ODxyz_RAM_t ODxyz_RAM = &#123; .x1001_errorRegister = 0, .x1003_preDefinedErrorField_sub0 = 0, .x1003_preDefinedErrorField = &#123;0, 0, 0, 0, 0, 0, 0, 0&#125;&#125;;/* All OD objects (constant) **************************************************/typedef struct &#123; OD_obj_var_t o_1000_deviceType; OD_obj_var_t o_1001_errorRegister; OD_obj_array_t o_1003_preDefinedErrorField; OD_obj_record_t o_1018_identity[5];&#125; ODxyzObjs_t;static CO_PROGMEM ODxyzObjs_t ODxyzObjs = &#123; .o_1000_deviceType = &#123; .dataOrig = &amp;ODxyz_PERSIST_COMM.x1000_deviceType, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, .o_1001_errorRegister = &#123; .dataOrig = &amp;ODxyz_RAM.x1001_errorRegister, .attribute = ODA_SDO_R, .dataLength = 1 &#125;, .o_1003_preDefinedErrorField = &#123; .dataOrig0 = &amp;ODxyz_RAM.x1003_preDefinedErrorField_sub0, .dataOrig = &amp;ODxyz_RAM.x1003_preDefinedErrorField[0], .attribute0 = ODA_SDO_RW, .attribute = ODA_SDO_R | ODA_MB, .dataElementLength = 4, .dataElementSizeof = sizeof(uint32_t) &#125;, .o_1018_identity = &#123; &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.maxSubIndex, .subIndex = 0, .attribute = ODA_SDO_R, .dataLength = 1 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.vendorID, .subIndex = 1, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.productCode, .subIndex = 2, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.revisionNumber, .subIndex = 3, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.serialNumber, .subIndex = 4, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125; &#125;&#125;;/* Object dictionary **********************************************************/static OD_entry_t ODxyzList[] = &#123; &#123;0x1000, 0x01, ODT_VAR, &amp;ODxyzObjs.o_1000_deviceType, NULL&#125;, &#123;0x1001, 0x01, ODT_VAR, &amp;ODxyzObjs.o_1001_errorRegister, NULL&#125;, &#123;0x1003, 0x09, ODT_VAR, &amp;ODxyzObjs.o_1003_preDefinedErrorField, NULL&#125;, &#123;0x1018, 0x05, ODT_REC, &amp;ODxyzObjs.o_1018_identity, NULL&#125;, &#123;0x0000, 0x00, 0, NULL, NULL&#125;&#125;;OD_t _ODxyz = &#123; (sizeof(ODxyzList) / sizeof(ODxyzList[0])) - 1, &amp;ODxyzList[0]&#125;;OD_t *ODxyz = &amp;_ODxyz; OD_find 查找指定对象123456789101112131415161718192021222324252627282930313233extern OD_t *ODxyz;void myFunc(OD_t *od) &#123; ODR_t odRet;//保存对象字典操作的返回值。 OD_entry_t *entry;//指向对象字典条目的指针。 OD_IO_t io1008;//用于对象字典I/O操作的结构体。 char buf[50]; OD_size_t bytesRd;//存储读取的字节数。 int error = 0; // 查找并初始化0x1008条目和其子索引0x00的IO结构体 entry = OD_find(od, 0x1008);//查找对象字典中的条目。 odRet = OD_getSub(entry, 0x00, &amp;io1008, false);//获取对象字典条目的子索引。 // 读取制造商设备名称 if (odRet == ODR_OK) &#123; /* Locking is necessary from mainline thread, but must not be used from * timer interval (real-time) thread. Locking is not necessary in the * CANoopen initialization section. Locking is also not necessary, if * OD variable is not mappable to PDO and not accessed from RT thread.*/ CO_LOCK_OD(CANmodule); odRet = io1008.read(&amp;io1008.stream, &amp;buf[0], sizeof(buf), &amp;bytesRd);//读取子索引的数据。 CO_UNLOCK_OD(CANmodule); &#125; if (odRet != ODR_OK) error++; /* Use helper and set &quot;Producer heartbeat time&quot; at index 0x1017, sub 0x00 */ // 设置生产者心跳时间 CO_LOCK_OD(CANmodule); /* may not be necessary, see comment above */ odRet = OD_set_u16(OD_find(od, 0x1017), 0x00, 500, false);//设置对象字典条目的子索引值。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++;&#125; 直接根据结构体查找 OD 对象如何直接访问和操作 CANopen 对象字典（Object Dictionary）中的条目，而不是通过查找函数 OD_find 来间接访问。直接访问对象字典条目和变量比通过函数查找要快，因为它避免了函数调用和查找过程。 对象字典的头文件 ODxyz.h，其中定义了对象字典的所有条目和相关结构。 123456789#include &quot;ODxyz.h&quot;void myFuncGlob(void) &#123; // Direct address instead of OD_find() OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; // Direct access to OD variable uint32_t devType = ODxyz_0.x1000_deviceType; ODxyz_0.x1018_identity.serialNumber = 0x12345678; &#125; OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; 直接获取对象字典中 0x1001 索引（错误寄存器）的条目指针 entry_errReg。这里使用的是直接声明的指针 ODxyz_1001_errorRegister，而不是通过 OD_find 函数查找。 uint32_t devType = ODxyz_0.x1000_deviceType; 直接读取对象字典中 0x1000 索引（设备类型）的变量 ODxyz_0.x1000_deviceType，并将其存储到本地变量 devType 中。ODxyz_0.x1018_identity.serialNumber = 0x12345678; 直接修改对象字典中 0x1018 索引（设备标识）的 serialNumber 字段，将其设置为 0x12345678。 如果 OD 对象已启用 OD 扩展，则不得直接访问其 OD 变量。只有通过读、写或辅助函数访问才有效。 修改 PDO 固定长度在 PDO 协议中，数据的接收是严格按照 PDO 中映射的数据长度来读取的，当数据不足时，该数据帧会被丢弃，当数据过长时，该数据帧会被截断。 在此次的应用程序中，由于该设备配置的 PDO 存在两种长度数据，所以需要将 PDO 的数据长度更改为兼容自定义的两种数据长度。 在 CO_PDO.c 文件中，有 RPDO 处理函数 CO_RPDO_process，其中的 for 循环，当小于 PDO-&gt;mappedObjectsCount 数量时，执行 1byte 的拷贝，所以此处我们需要修改为当 i&lt;CO_PDO_MAX_SIZE 时执行拷贝，即对 PDO 中所有的数据进行拷贝，不管该字节是否有数据。","categories":["通讯协议","CAN"]},{"title":"博客部署相关服务","path":"/2024/05/25/博客-博客部署相关服务/","content":"Github 托管服务Github 是一个著名的互联网托管服务，用于软件开发和使用 Git 的版本控制。一直拥有各种奇怪的用途，被发掘出来当图床也见怪不怪了。 你可以上传各种类型的文件，只要 github 接受它们。当你在笔记中提到一个共享的文件时，比如图片&#x2F;脚本、配置文件或任何东西时， 能很好地将其嵌入到 markdown 文件中。 文件链接是否能在 Obsidian 中呈现，取决于 obsidian 本身的支持情况。没关系，即使它们不能被渲染，它们仍然可以作为链接使用。只要去掉开头的感叹号就可以了。 速度：国内可以接受，海外速度很快 CDN：Fastly CDN，几个节点在国内都解禁了的 HTTPS：支持（似乎不支持 HTTP2） 域名：user-images.githubusercontent.com 上传方式是新建一个 Repo，然后在 Issue 中传图（直接将图片拖动到 issue 输入框即可），GitHub 会将你的图片分发到 GitHub 用的 CDN 中。 这和使用 GitHub Raw 需要 GitHub 的服务器动态生成文件不同，user-image 这个子域名是 GitHub 专门为静态文件准备的，不会让当年某某抢票助手 CC GitHub 的事情重现的。 当然，这个接口不是公开的。善待 GitHub。 ⚠️注意， github 目标仓库必须为 public，这意味着上传的所有文件都是公开。github 也更应该是为乐于共享者而服务的。请确保对你来说分享你上传的文件是无害的。我个人更期待着有一天你的某次上传就是为了无私共享。🌻 不要上传空文件。在这里是没有意义的，是错误的。 建议勾选面板中的随机文件名。重复的文件名会引起错误。随机文件名将大大避免重复的文件名。 一般来说，Github 足够慷慨。但你需要掌握分寸，不要太滥用 Github 的服务。放轻松，正常使用，比如在 Github pages 中使用，当然是可以接受的。但如果你需要大量使用图片，请使用专业的图床服务（现在该项服务已经集成到了本插件中）超出正常范围（如在单个资源库中存储超过 1GB 的文件），滥用 Github，上传不良文件，造成不良影响，可能会导致你的 Github 库甚至账户受到影响。 我在这里使用到了 jsdelivr。它是免费的。就像上面关于 GitHub 的一样，不要滥用它。 NetlifyRailwayhttps://railway.app/ Railway 提供免费容器服务。支持主流语言 python、nodejs 等直接运行，支持 Dockerfile 在线构建 docker 镜像。支持使用 CLI 部署。此外，还提供大量模板直接构建。例如 code server（vscode 网页版）等。 不自动休眠，不自动删数据（手动重新部署当然会删），支持自定义域名，自动 SSL 加密。 提供数据库支持，部署完成之后添加数据库插件即可。 按量付费，每个月 5 美元免费额度，跑个小程序够用。具体可以参考定价。 部署railway 支持三种部署方式： 通过 Github repo 进行部署，需要连接到你自己的特定仓库。如果你的仓库中有 Dockerfile 文件，则会自动解析。参见：Dockerfiles | Railway Docs 使用它们的 CLI，这个我试用了下感觉体验不是很好。不太推荐。 通过自带的模板进行部署，例如 code server。选择 Deploy Starter 即可 Vercelhttps://vercel.com/ Vercel 是一个云服务平台，支持静态网站和动态网站的应用部署、预览和上线。如果你用过 GitHub Pages ，那么心里可能不会太陌生，但你也能通过 vercel 集成 GitHub 后后，在 GitHub 项目进行代码推送，PR 合并自动部署的目的，且你不需要考虑服务器问题。 Vercel 它是一个免费的网站托管平台，也是我目前用过最好的网站托管平台，不仅仅可以部署静态网站，而且还可以部署动态网站，所以我们可以拿 vercel 充当你免费的服务器，主要有以下好处。 关联 github，只需要往 github 提交代码，它会自动获取最新的提交，然后自动部署 提供了免费的域名，省去了申请域名的问题，如果有自己的域名，还可以做个域名解析到这个平台上 提供了免费的 Https 证书，如果证书到期了，它会自动替换，完全不需要操心 傻瓜式的部署方式，它的操作非常简单，Vercel 提供了两种方式：通过命令行部署、通过 Vercel 提供管理后台部署，这期视频我们主要介绍通过命令行部署，因为命令行的部署方式更加简单 Cloudflare","categories":["博客"]},{"title":"博客部署相关文件","path":"/2024/05/25/博客-博客部署相关文件/","content":"部署涉及到的各项关键配置文件有以下，各文件路径基于 Hexo&#x2F;Github&#x2F;Obsidian 的仓库根目录 文件所属 文件名 文件路径 文件用途 GitHub Actions blogPublish.yml .github/workflows 用于仓库同步到 github 之后，自动将源码生成静态页面，同步到发布仓库进行发布 GitHub .gitignore ./ 用于忽略 Hexo 和 Obsidian 中不需要同步到 Git 的文件(有些文件体积过大，占用仓库体积) Hexo _config.yml ./ Hexo 站点配置文件 Hexo package.json ./ npm 安装包及命令文件，部署站点时所需的和 hexo 相关的依赖包都在此文件中 Hexo-Stellar _config.yml themes/stellar/_config.yml Hexo 主题配置文件 Hexo-Stellar widgets.yml themes/stellar/_data/widgets.yml Stellar 主题中的控件配置文件 更换主题 修改 .github/workflows/blogPublish.yml 该文件中指定了主题仓库和主题配置文件，修改主题仓库 修改 _config.theme.yml 该文件中默认为 stellar 的主题配置文件，需要修改为指定的主题配置文件 修改站点配置文件 _config.yml 需要在站点配置文件中修改指定的主题 Qexo管理后端建设 拉取仓库并本地部署脚本 123456789101112rm -rf ./BlogDeploygit clone git@github.com:liuluhua/BlogDeploy.gitcd ./BlogDeploymkdir themescd themesgit clone git@github.com:xaoxuu/hexo-theme-stellar.gitgit clone git@github.com:next-theme/hexo-theme-next.gitcd ..npm installhexo cleanhexo ghexo s -p 9050","categories":["博客"]},{"title":"AI应用软件了解","path":"/2024/05/24/AI-AI应用软件了解/","content":"文本生成 AI ChatGPT-4： 理论上最强的大模型 Poe：市面上所有的头部大模型都集成在了一起 Claude3： 长文本整理那些海量信息 非常好用 Gemini：对语音，图片理解能力可以，前两个月免费 NewBing: 通义千问：1kw 长文本处理 豆包：陪伴型 AI 天工：可生成音乐 扣子：创建智能体 图片生成 AI Stable Diffusion：文生图，免费 Midjourney：收费 DALL-E3：集成在 chat gpt 中 dreamina：字节 通义万象：集成在通义千问 混元助手：腾讯 akuma https://akuma.ai/ 视频生成 AI： Sora：以文本描述生成视频 Stable Video Diffusion runway pika haiper dreamina：字节 pixverse vidu：清华 Money print turbo：全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频 音频生成 AI： suno：ai 创作音乐，登录就可以使用了，免费版本每日送 50 积分，可以生成 10 Stable Audio： 天工音乐 网易天音 AI 浏览器： perplexity AI 编程 gpt github-copilot 照片说话： emo：阿里 sadtalk： 音频模仿 gpt-sovits： 音频 AI 生成 Openvoice 剪映 魔音工坊 PPT 讯飞智文 gamma wps AI 视频编辑 腾讯智影 剪映 其他说明：PyTorch 2.0.1 CUDA 11 conda FastGPT+ollama 订阅号对接 ollma 模型—云服务器资源不足 微软 E5 开发者订阅 huggingface.coHugging Face Transformers 是一个开源 Python 库，其提供了数以千计的预训练 transformer 模型，可广泛用于自然语言处理 (NLP) 、计算机视觉、音频等各种任务。 Hugging Face Hub 是一个协作平台，其中托管了大量的用于机器学习的开源模型和数据集，你可以将其视为 ML 的 Github。 Hugging Face Spaces 是 Hugging Face Hub 上提供的一项服务，它提供了一个易于使用的 GUI，用于构建和部署 Web 托管的 ML 演示及应用。该服务使得用户可以快速构建 ML 演示、上传要托管的自有应用，甚至即时部署多个预配置的 ML 应用。","categories":["AI"]},{"title":"CAN Open Linux 调试","path":"/2024/05/24/通讯协议-CAN-CAN-Open-Linux-调试/","content":"作为 CAN Open 总线上的数据抓取设备，要求程序具有以下功能 能够作为总线上的从机设备，要求具有以下功能： HeartBeat 本设备 SDO 配置项 PDO 数据配置 如何通过主机 ASK 某一设备的数据 能够作为总线上的主机设备，要求具有以下功能： 从机设备的状态管理 PDO 数据采集 例如，预配置的过程数据对象 (PDO) 由生产者传输。每个 PDO 可能由多个节点使用。每个 CANopen 设备的其他有用的 CANopen 功能还包括：心跳生产者和消费者、紧急生产者、同步生产者或消费者、时间生产者或消费者、SDO 服务器（服务数据对象 - 从对象字典中提供变量）、NMT 从属（网络管理 - 启动或停止通信部分）、LSS 从属（节点 ID 和比特率的配置）。 CANopen 网络通常有一个具有命令功能的设备用于网络配置，例如：NMT 主站、LSS 主站、SDO 客户端、紧急消费者。CANopenNode 中的命令功能根据标准 CiA309-3 使用 Ascii 命令行接口实现。 使能 CAN Open 网络利用 modprobe 创建 Linux 下 CAN 设备 modprobe 是 Linux 系统中的一个命令行工具，用于管理内核模块。内核模块是可以动态加载或卸载的可扩展组件，允许 Linux 内核在运行时添加或删除功能而不需要重启系统。常见的内核模块包括设备驱动程序、文件系统支持以及网络协议等。 创建一个虚拟 CAN 设备，并启用 123sudo modprobe vcansudo ip link add dev can0 type vcansudo ip link set up can0 安装 CAN 监测调试工具，can-utils 项目地址 https://github.com/linux-can/can-utils 12sudo apt-get install can-utilscandump -td can0 #显示can消息 *rk3568 的 can 使用时 ip link set can0 up 启用失败报错：can0: incorrect missing data bit-timing驱动问题，设备树中的节点配置，需要将 kernel&#x2F;arch&#x2F;arm64&#x2F;boot&#x2F;dts&#x2F;rockchip&#x2F;rk3568.dtsi 中的 can0 节点中的 compatible &#x3D; “rockchip,canfd-1.0”修改为 compatible &#x3D; “rockchip,can-1.0”，重新编译后下载 启动 3568 的 CAN 1234567891011121314151617181920212223242526272829303132333435363738394041424344ifconfig can0 downip link set can0 up type can bitrate 500000ifconfig can0 upifconfig can1 downip link set can1 up type can bitrate 500000ifconfig can1 upip link set can0 downip link set can1 downip link set can0 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd onip link set can1 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd on#查询当前网络设备:ifconfig -a#关闭CAN:ip link set can0 down#设置比特率500KHz:ip link set can0 type can bitrate 500000#打印can0信息:ip -details -statistics link show can0#启动CAN:ip link set can0 up#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123#DEADBEEF#发送（标准帧,远程帧,ID:123）:cansend can0 123#R#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123#12345678#发送（扩展帧,远程帧,ID:00000123）:cansend can0 00000123#R#开启打印，等待接收:candump can0###########################################设置can fd#设置仲裁段1M波特率，数据段3M波特率:ip link set can0 type can bitrate 1000000 dbitrate 3000000 fd on#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123##1DEADBEEF#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123##1DEADBEEF CAN 通信测试工具canutils 是常用的 CAN 通信测试工具包，内含 5 个独立的程序：canconfig、candump、canecho、cansend、cansequence。 这几个程序的功能简述如下： canconfig 用于配置 CAN 总线接口的参数，主要是波特率和模式。 candump 从 CAN 总线接口接收数据并以十六进制形式打印到标准输出，也可以输出到指定文件。 canecho 把从 CAN 总线接口接收到的所有数据重新发送到 CAN 总线接口。 cansend 往指定的 CAN 总线接口发送指定的数据。 cansequence 往指定的 CAN 总线接口自动重复递增数字，也可以指定接收模式并校验检查接收的递增数字。 ip CAN 波特率、功能等配置。 注意：busybox 里也有集成了 ip 工具，但 busybox 里的是阉割版本。不支持 CAN 的操作。故使用前请先确定 ip 命令的版本（iproute2）。上面工具包，网络上都有详细的编译说明。如果是自己编译 buildroot，直接开启宏就可以支持上述工具包。 12BR2_PACKAGE_CAN_UTILS=yBR2_PACKAGE_IPROUTE2=y CAN 比特率和采样点计算目前 CAN 架构根据输入频率和比特率自动计算。采样点的规则按照 CIA 标准协议： 1234567891011/* Use CiA recommended sample points */if (bt-&gt;sample_point) &#123;\tsample_point_nominal = bt-&gt;sample_point;&#125; else &#123;\tif (bt-&gt;bitrate &gt; 800000) sample_point_nominal = 750;\telse if (bt-&gt;bitrate &gt; 500000) sample_point_nominal = 800;\telse sample_point_nominal = 875;&#125; 比特率计算公式（详细原理可以百度，这里只介绍芯片配置相关）： BitRate = clk_can / (2 *(brq + 1) / ((tseg2 + 1) + (tseg1 + 1) + 1) Sample = (1 + (tseg1 + 1)) / (1 + (tseg1 + 1) + (tseg2 + 1)) brq、tseg1、tseg2 见 CAN 的 TRM 中 BITTIMING 寄存器。 用例分析状态恢复和存储紧急信息、错误寄存器和 NMT 运行前状态在未初始化的非易失性存储器中都有数据源。对象 0x1010 和 0x1011 用于存储和恢复数据，通常来自 CANopen 对象字典。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不为零，则可能禁止节点进入 NMT 操作状态，并且无法与其交换 PDO。 恢复所有非易失性存储器： CAN ID：0x600 + 节点 ID（表示从主机到从节点的 SDO 请求）。0x600 + 4 &#x3D; 0x604。 命令字节：表示写入命令和数据长度。0x23 表示写入 4 字节数据（visible string）。 索引：对象字典索引。0x1011（字节顺序为低字节在前）。 子索引：对象字典子索引。0x01 数据：load：ASCII 码 l、o、a、d 分别为 0x6C、0x6F、0x61、0x64。 构建数据恢复 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x11 0x10），子索引（0x01），数据（0x6C 0x6F 0x61 0x64）。 can0 604 [8] 23 11 10 01 6C 6F 61 64 save：ASCII 码 s、a、v、e 分别为 0x73、0x61、0x76、0x65。 构建数据存储 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x10 0x10），子索引（0x01），数据（0x73 0x61 0x76 0x65）。 can0 604 [8] 23 10 10 01 73 61 76 65 设置 NMT 状态报文可以发送给特定节点或所有节点。它们可以重置设备、通信或将远程设备的内部状态设置为运行、预运行（禁用 PDO）或停止（仅启用心跳生产者和 NMT 消费者）。 当出现了设置错误寄存器的紧急状况时，start 不起作用。 设置 Node ID 为 4 的设备状态为 reset。 000 82 04 Byte 0 取值（命令） 状态 01 start_remote_node 02 stop_remote_node 80 enter_pre-operational 81 reset_node 82 reset_communication 设置心跳包读取心跳时间设置CAN0 604 [8] 40 17 10 00 00 00 00 00 写入心跳时间设置 CAN ID：0x600 + 节点 ID（4）&#x3D; 0x604。 命令字节：0x2B 表示写入 2 字节（u16）。 索引：0x1017（字节顺序为 17 10）。 子索引：0x00。 数据：1000ms&#x3D;0x03E8，字节顺序为 E8 03。10000ms&#x3D;0x2710 can0 604 [8] 2B 17 10 00 E8 03 00 00 PDO 配置按以下步骤通过写入 OD 变量配置 PDO： 将 PDO 通信参数 COB-ID 中的第 31 位设置为 1，禁用 PDO。 只有禁用 PDO 时才能配置 Node-Id。 将 PDO 映射参数，子索引 0 设置为 0，禁用映射。 配置映射 通过设置 PDO 映射参数，子索引 0 至映射对象数启用映射 通过将 PDO 通信参数 COB-ID 中的第 31 位设置为 0 来启用 PDO 其他配置同步传输信号配置全局同步周期 SYNC 设置值保存在对象 1006h 中。 心跳CANopen 主站的对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 对象 1017h 的值(发生器心跳时间)被此处设置的值重写。适用于所有从站对象的对象 1017h(发生器心跳时间)的值被此处设置的值重写，对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 CAN Open 总线建设假定在一个 can open 网络中，node1 为主节点，node2 和 node3 为从节点，需要配置 node2，让 node2 接收 node3 的 TPDO 消息。 设备配置 设备名 节点地址 类型 Node 1 0x01 主节点（NMT Master） Node 2 0x02 从节点（NMT Slave） Node 3 0x03 从节点（NMT Slave） 其中 Node3 作为 TPDO 消息发出（生产者），期望 Node2 接收 Node3 消息。 PDO 参数配置配置所需信息配置 Node 3 的 TPDO： 确定 Node 3 的 TPDO 消息的 COB-ID 和映射对象。 在 Node 3 的对象字典中设置 TPDO 通信参数和映射参数。 配置 Node 2 的 RPDO： 设置 Node 2 的 RPDO 通信参数，使其接收 Node 3 的 TPDO 消息。 配置 Node 2 的 RPDO 映射参数，以处理从 Node 3 接收到的数据。 通讯参数和映射参数（OD）Node 3 的配置： TPDO 通信参数（0x1802）： 子索引 0x01: COB-ID &#x3D; 0x183 子索引 0x02: 传输类型（例如 0xFF，事件触发） TPDO 映射参数（0x1A02）： 子索引 0x00: 映射对象数量 &#x3D; 2 子索引 0x01: 0x60000208（对象 0x6000，子索引 0x02，8 位） 子索引 0x02: 0x64010110（对象 0x6401，子索引 0x01，16 位） Node 2 的配置： RPDO 通信参数（0x1400）： 子索引 0x01: COB-ID &#x3D; 0x183（与 Node 3 的 TPDO COB-ID 一致） 子索引 0x02: 传输类型（例如 0xFF，事件触发） RPDO 映射参数（0x1600）： 子索引 0x00: 映射对象数量 &#x3D; 2 子索引 0x01: 0x60000208（与 Node 3 的 TPDO 映射一致） 子索引 0x02: 0x64010110（与 Node 3 的 TPDO 映射一致） 配置过程设置 Node 3 的 TPDO 通信参数： 1234CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 83 01 00 00] # 设置 COB-ID 为 0x183（启用）CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 3 的 TPDO 映射参数： 12345678CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 00 00 00 00] # 禁用 TPDO 映射CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 02 00 00 00] # 启用 TPDO 映射 设置 Node 2 的 RPDO 通信参数： 1234CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 00 83 01 00 00] # 设置 COB-ID 为 0x183CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 2 的 RPDO 映射参数： 12345678CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 00 00 00 00] # 禁用 RPDO 映射CAN ID: 0x602 (SDO 请求)Data: [23 00 16 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x602 (SDO 请求)Data: [23 00 16 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 02 00 00 00] # 启用 RPDO 映射 通过上述步骤配置 Node 2 的 RPDO 通信参数和映射参数，使其能够接收和处理来自 Node 3 的 TPDO 消息。这种配置确保了 Node 2 能够正确接收和解析 Node 3 发送的 TPDO 数据，完成数据的有效传输和处理。 调试命令控制 NMT 状态 CAN0 000 [2] 01 04&#x2F;CAN0 000 [2] 02 04 控制节点 4 CAN0 000 [2] 01 00&#x2F;CAN0 000 [2] 02 00 控制所有节点 发送 SYNC 信号 CAN0 080 [0] 发送 ERROR 信号 CAN0 084 [8] 数据区根据实际错误定义 恢复参数，在 1011 的 01 写入 load CAN0 604 [8] 2F 11 10 01 6C 6F 61 64 读取 1005 信息（SYNC 的 COB-ID） CAN0 604 [8] 40 05 10 00 00 00 00 00 配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值）。 &#96;CAN0 604 [8] 23 05 10 00 80 00 00 00 读取 1006 信息(SYNC 通信周期) &#96;CAN0 604 [8] 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms &#x3D; 100000us）。 CAN0 604 [8] 23 06 10 00 A0 86 01 00 读取心跳时间设置 CAN0 604 [8] 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 CAN0 604 [8] 2B 17 10 00 E8 03 00 00 设置一个 TPDO配置 1800 的上报方式为异步，读取的话改 2F 为 40 CAN0 604 [8] 2F 00 18 02 FF 00 00 00 配置 1800 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 604 [8] 2B 00 18 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 604 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 604 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 604 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 604 [8] 2F 00 1A 00 02 00 00 00 设置 RPDO配置 1400 接收来自 181 的数据 CAN0 601 [8] 23 00 14 01 81 01 00 00 配置 1400 的上报方式为异步，读取的话改 2F 为 40 CAN0 601 [8] 2F 00 14 02 FF 00 00 00 配置 1400 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 601 [8] 2B 00 14 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 601 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 601 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 601 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 601 [8] 2F 00 1A 00 02 00 00 00","categories":["通讯协议","CAN"]},{"title":"文件夹双向同步软件设计","path":"/2024/05/22/其他-软件设计-文件夹双向同步软件设计/","content":"","categories":["其他","软件设计"]},{"title":"网络超时检测的三种方法","path":"/2024/05/22/平台Platform-Linux-网络-网络超时检测的三种方法/","content":"网络超时检测的三种方法 网络通信中，很多操作会使得进程阻塞，这时我们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 这里我们总结一下网络超时检测的三种方法： 一、通过 setsockopt 设置套接字属性 SO_RCVTIMEO 1234567891011121314struct timeval t = &#123;5, 0&#125; if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, &amp;t, sizeof(t)) == -1) &#123; perror(&quot;setsockopt&quot;); return -1; &#125; memset(&amp;peeraddr, 0, sizeof(peeraddr)); len = sizeof(peeraddr); if ((connfd = accept(listenfd, (struct sockaddr *)&amp;peeraddr, &amp;len)) == -1) &#123; printf(&quot;errno=%d: %s &quot;, errno, strerror(errno)); if (errno == EAGAIN) &#123; printf(&quot;timeout &quot;); return -1; &#125; &#125; 二、设定 select 函数的一个参数实现超时处理 1234567891011struct timeval t= &#123;3, 0&#125;; while (1) &#123; 。。。。。。 t.tv_sec = 3; t.tv_usec = 0; if ((ret = select(maxfd+1, &amp;rdfs, NULL, NULL, &amp;t)) == -1) &#123; perror(&quot;select&quot;); return -1; &#125; 。。。。。。 &#125; 三、设定一个定时器捕捉 SIGALRM 信号做超时控制 123456789101112struct sigaction act; sigaction(SIGALRM, NULL, &amp;act); //获取SIGALRM信号的属性 act.sa_handler = handler; // 设置SIGALRM信号的处理函数 sigaction(SIGALRM, &amp;act, NULL); // 设置SIGALRM信号的属性 alarm(3); // 定时器设置3秒钟 while (1) &#123; if ((connfd = accept(listenfd, (struct sockaddr *)&amp;peeraddr, &amp;len)) == -1) &#123; if (errno == EINTR) &#123; printf(&quot;timeout &quot;); return -1; &#125; &#125; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。我们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["平台Platform","Linux","网络"]},{"title":"Docker下将已部署的wordpress备份及迁移","path":"/2024/05/22/平台Platform-Docker-Docker下将已部署的wordpress备份及迁移/","content":"# Docker 镜像备份 在已经部署好 wordpress 的机器上，使用 docker save 命令将 Docker 镜像保存到本地文件中。 使用以下命令将名为 wordpress 和 mysql 的 Docker 镜像分别保存到名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中： docker save wordpress &gt; wordpress_image.tar #保存wordpress docker save mysql &gt; mysql_image.tar #保存mysql # Docker 镜像读取 将 wordpress_image.tar 和 mysql_image.tar 文件复制到目标机器上。在目标机器上，使用 docker load 命令将本地文件中的 Docker 镜像加载到 Docker 中。 使用以下命令将名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中的 Docker 镜像加载到 Docker 中： docker load &lt; wordpress_image.tar docker load &lt; mysql_image.tar Docker 文件系统备份要将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方，可以使用 Docker 的导入和导出功能，具体步骤如下： 在运行 WordPress 应用程序的 Docker 容器上执行以下命令，将容器中的 WordPress 应用程序导出为 tar 文件： docker export &lt;container_id&gt; &gt; wordpress.tar 这将在当前目录下创建一个名为 wordpress.tar 的文件，其中包含 Docker 容器中的整个 WordPress 应用程序。 Docker 文件系统读取将 wordpress.tar 文件传输到要部署 WordPress 应用程序的目标服务器上。 在目标服务器上执行以下命令，将 wordpress.tar 文件导入到 Docker 中： cat wordpress.tar | docker import - &lt;image_name&gt;:&lt;tag&gt; 其中，&lt;image_name&gt; 是你为导入的 Docker 镜像指定的名称，&lt;tag&gt; 是你为该镜像指定的标签。 运行导入的 Docker 镜像，启动 WordPress 应用程序的容器： docker run -p &lt;host_port&gt;:&lt;container_port&gt; -d &lt;image_name&gt;:&lt;tag&gt; 其中，&lt;host_port&gt; 是你要将容器的端口映射到主机上的端口号，&lt;container_port&gt; 是容器内运行 WordPress 应用程序的端口号。 这样，你就可以将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方了。 启动 Docker 按照之前的 docker-compose 的方法启动 dokcer 使用 docker ps -a --no-trunc 需要修改并添加 command wordpress 是 docker-entrypoint.sh apache2-foreground mysql 是 docker-entrypoint.sh mysqld 使用 docker run 命令在目标机器上启动该 Docker 镜像。例如，使用以下命令在目标机器上启动名为 wordpress 的 Docker 镜像： #启动mysql docker run -d –name mysql -v mysql_data:&#x2F;var&#x2F;lib&#x2F;mysql -e MYSQL_ROOT_PASSWORD&#x3D;liuluhua -e MYSQL_DATABASE&#x3D;wordpress -e MYSQL_USER&#x3D;liuluhua -e MYSQL_PASSWORD&#x3D;liuluhua mysql:latest docker-entrypoint.sh mysqld #启动wordpress docker run -d –name wordpress –link mysql -p 80:80 -e WORDPRESS_DB_HOST&#x3D;mysql:3306 -e WORDPRESS_DB_USER&#x3D;liuluhua -e WORDPRESS_DB_PASSWORD&#x3D;liuluhua -e WORDPRESS_DB_NAME&#x3D;wordpress -v .&#x2F;wp-content:&#x2F;var&#x2F;www&#x2F;html&#x2F;wp-content -v .&#x2F;uploads.ini:&#x2F;usr&#x2F;local&#x2F;etc&#x2F;php&#x2F;conf.d&#x2F;uploads.ini wordpress:latest docker-entrypoint.sh apache2-foreground 启动参数： **-d**：表示以“后台模式”运行容器，即使容器的主进程退出也不会停止容器。 **--name**：表示为容器指定一个名称，这样可以方便地对容器进行管理。 **-v**：表示将主机的目录或文件与容器内的目录或文件进行挂载，即数据卷。例如，-v mysql_data:/var/lib/mysql 表示将主机的 mysql_data 目录挂载到容器内的 /var/lib/mysql 目录，这样容器内的 MySQL 数据就可以持久化存储在主机上。 **-e**：表示设置容器内的环境变量。例如，-e MYSQL_ROOT_PASSWORD=liuluhua 表示设置容器内的 MYSQL_ROOT_PASSWORD 环境变量为 liuluhua。 **--link**：表示将一个容器链接到另一个容器，使得容器之间可以进行通信。例如，--link mysql 表示将容器链接到名为 mysql 的容器。 **-p**：表示将容器的端口映射到主机的端口。例如，-p 80:80 表示将容器的 80 端口映射到主机的 80 端口，使得可以通过主机的 IP 地址访问容器内的服务。 **wordpress:latest 和 mysql:latest**：表示使用 wordpress 和 mysql 镜像的最新版本来创建容器。 **./wp-content:/var/www/html/wp-content 和 ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini**：表示将主机上的 wp-content 目录和 uploads.ini 文件挂载到容器内的 /var/www/html/wp-content 目录和 /usr/local/etc/php/conf.d/uploads.ini 文件，使得容器内的 WordPress 网站可以访问这些文件。","categories":["平台Platform","Docker"]},{"title":"程序内存","path":"/2024/05/22/平台Platform-Linux-程序-程序内存/","content":"linux 的 ELF 可执行文件内存分布可执行文件 4G 内存分布，在 32bit 的 OS 中 用户空间 app+C 库\t3G 内核空间 驱动 1G 硬件 elf 分布.heap 堆: 用户自定义空间，用完释放.stack 栈: 局部变量，函数参数.bss 未初始化的全局，静态变量.data 数据段: 初始化的全局，静态变量.text 代码段: 存放二进制可执行代码 1234567891011121314151617181920#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;/*C语言中数据的内存分配*/int a=0;char *p1;int main()&#123;\tint b; /*b在栈 */\tchar s[] =&quot;abc&quot;; /*s在栈，&quot;abc&quot;在常量区*/\tchar *p2; /*p2在栈*/\tchar *p3=“123456&quot;; /*&quot;123456&quot;在常量区，p3 在栈*/\tstatic int c=0; /*可读可写数据段*/\tp1 = (char *)malloc(10);\t/*分配得来的 10个字节的区域在堆区*/\tp2 = (char *)malloc(20);\t/*分配得来的 20个字节的区域在堆区*/ /* 从常量区的“Hello world”字符串复制到刚分配到的堆区 */\tstrcpy(p1，“Hello World&quot;);\treturn 0;&#125; 基本数据类型Char:1B Int:4B Short:2B Long:4B long long :8B Float:4B double:8B long double:16B 位的使用和对齐操作字节对齐：在 32 位操作系统中，大多数计算机体系结构要求数据按照特定的字节边界对齐。常见的对齐边界是 4 字节（32 位）或 8 字节（64 位）。这是为了优化内存访问和数据传输的效率。如果数据没有按照正确的字节对齐方式存储，可能会导致额外的开销和性能下降。 结构体成员对齐：在结构体中，结构体成员的对齐方式可能会影响整个结构体的对齐方式。编译器通常会自动对结构体成员进行对齐，以满足所使用的编译器和平台的要求。默认情况下，大多数编译器会使用最大对齐方式，即按照结构体中最大成员的字节大小进行对齐。 指令对齐：在代码中，指令的对齐方式也是重要的。大多数处理器要求指令按照特定的字节边界对齐。指令对齐可以提高指令的执行速度和整体性能。 对于字节对齐，编译器通常会自动处理，但也可以通过编译器的指令或属性进行手动控制。在 C 语言中，可以使用特定的编译指令来控制结构体成员的对齐方式，例如使用#pragma pack 指令。 以下是一个示例，展示了如何使用#pragma pack 指令来设置结构体成员的对齐方式： 1234567891011121314151617181920#include &lt;stdio.h&gt;#pragma pack(push, 1) // 以1字节对齐方式压栈struct Example &#123; char a; int b; short c;&#125;;#pragma pack(pop) // 弹出对齐方式int main() &#123; struct Example ex; printf(&quot;Size of struct Example: %zu &quot;, sizeof(ex)); // 输出结构体的大小 return 0;&#125; 在上述示例中，通过使用#pragma pack(push, 1) 指令将对齐方式设置为 1 字节，然后定义了一个名为 Example 的结构体，包含了 char、int 和 short 类型的成员变量。最后使用#pragma pack(pop) 指令将对齐方式还原为默认值。 在运行示例程序后，可以观察到结构体 Example 的大小可能会受到对齐方式的影响。如果不进行任何对齐操作，默认情况下编译器可能会根据平台和编译器的要求进行对齐，大小会大于 1 字节。 总结来说，在 32 位的操作系统中，位的使用和对齐操作是为了优化内存访问和数据传输的效率。字节对齐、结构体成员对齐和指令对齐是常见的对齐方式，可以通过编译器的指令或属性进行手动控制，以满足特定的需求和平台要求。","categories":["平台Platform","Linux","程序"]},{"title":"vim安装","path":"/2024/05/22/软件-VIM-vim安装/","content":"配置文件 地址 安装环境 12sudo apt install git cscopewget -qO - https://raw.github.com/ma6174/vim/master/setup.sh | sh -x wget 是一个用于从网络下载文件的命令行工具。-q 表示静默模式，不显示下载进度和其他信息。-O - 指定输出到标准输出（stdout），而不是保存到文件。这样下载的文件内容就会直接输出到终端。https://raw.github.com/ma6174/vim/master/setup.sh 是要下载的文件的 URL 地址。| 是管道符号，用于将前一个命令的输出作为后一个命令的输入。sh 是一个用于执行 Shell 脚本的命令。-x 表示在执行脚本时显示详细的调试信息。 setup.sh 内容 123456789101112131415161718192021222324252627282930#!/bin/bashecho &quot;安装将花费一定时间，请耐心等待直到安装完成~~&quot;if which apt-get &gt;/dev/null; then\tsudo apt-get install -y vim vim-gnome ctags xclip astyle python-setuptools python-dev gitelif which yum &gt;/dev/null; then\tsudo yum install -y gcc vim git ctags xclip astyle python-setuptools python-develfi##Add HomeBrew support on Mac OSif which brew &gt;/dev/null;then\techo &quot;You are using HomeBrew tool&quot;\tbrew install vim ctags git astylefisudo easy_install -ZU autopep8sudo ln -s /usr/bin/ctags /usr/local/bin/ctagsmv -f ~/vim ~/vim oldcd ~/ &amp;&amp; git clone https://github.com/ma6174/vim.gitmv -f ~/.vim ~/.vim_old mv -f ~/vim ~/.vimmv -f ~/.vimrc ~/.vimrc_oldmv -f ~/.vim/.vimrc ~/ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundleecho &quot;ma6174正在努力为您安装bundle程序&quot; &gt; ma6174echo &quot;安装完毕将自动退出&quot; &gt;&gt; ma6174echo &quot;请耐心等待&quot; &gt;&gt; ma6174vim ma6174 -c &quot;BundleInstall&quot; -c &quot;q&quot; -c &quot;q&quot;rm ma6174echo &quot;安装完成&quot; 配置 1234cd /usr/includesudo ctags -Rcd -vim .vimrc 修改最后一行 1set tags=/usr/include/tags 安装 zshZsh 是一种替代默认的命令行 Shell（如 Bash）的 Shell。Zsh（Z Shell）是一种强大的命令行 Shell，它具有许多增强的功能和可定制选项。相较于传统的 Bash Shell，Zsh 提供了更好的自动补全、历史记录管理、拼写修正、主题定制等功能。它还支持丰富的插件和扩展，可以根据用户的需求进行定制和配置。 接下来，chsh -s /bin/zsh 是一个用于更改当前用户的默认 Shell 的命令。chsh 是 “change shell” 的缩写，-s 选项指定要更改为的新 Shell，/bin/zsh 是指要更改为 Zsh 的路径。 12sudo apt install zshchsh -s /bin/zsh","categories":["软件","VIM"]},{"title":"Sqlie使用","path":"/2024/05/22/软件-数据库-Sqlie使用/","content":"数据库基础安装数据库 1sudo apt-get install sqlite3 数据库指令操作打开一个数据库 1sqlite3 my.db 常用查询: `.table` 查看数据库中的表 `.schema tablename` 查看相应表的结构 `.database` 查看当前打开的数据库 `.quit` 退出当前数据库 `.help` 列出帮助信息 创建表: create table movies (id int, name text, time int, auth text);删除表: drop table tablename;\t添加信息: insert into movies values (.....); insert into movies values (.....);查询信息: select * from movies ;删除信息: delete from movies where id=1;更新信息: update tablename set name=&#39;&#39; where id=2;添加字段: alter table tablename add column sex char ; 1234567891011121314151617181920212223242526//创建名字为tong.db的数据库sqlite3 tong.db//创建一个叫user的table,里面有name, agecreate table user(name, age integer);//name的默认类型是字符串，用“taotao”//age的类型相当于int//删除一个tabledrop table user;//向user中存储数据insert into user values（“taotao”, 18）;//增加一个column叫num,类型是 integeralter table user add column num integer;//更新数据update user set name=&quot;taotao&quot;,age=18 where num=110;//打印所有信息select * from user;//打印某一个信息select * from user where name=&quot;taotao&quot;;//删除一个叫taotao的人delete from user where name=&quot;taotao&quot;;//查看有哪几个表.tables//查看某一个表的属性.schema user//退出.q","categories":["软件","数据库"]},{"title":"机器大小端校验","path":"/2024/05/22/平台Platform-Linux-其他-机器大小端校验/","content":"大小端字节序大端字节序（Big-Endian）和小端字节序（Little-Endian）是两种不同的字节存储顺序方式，用于在多字节数据类型（如整数、浮点数）在内存中的表示。 在大端字节序中，较高字节（最高有效字节）保存在较低的存储地址，而较低字节（最低有效字节）保存在较高的存储地址。换句话说，数据的高位字节存储在低地址位置，低位字节存储在高地址位置。 例如，整数值 0x12345678 在大端字节序中的存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 相比之下，在小端字节序中，较低字节保存在较低的存储地址，而较高字节保存在较高的存储地址。数据的低位字节存储在低地址位置，高位字节存储在高地址位置。 使用同样的示例值 0x12345678，小端字节序的存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 64 位和 32 位的不同64 位和 32 位的大小端情况是类似的，但存在一些细微差异。 在 64 位系统中，数据被划分为 8 字节（64 位），而在 32 位系统中，数据被划分为 4 字节（32 位）。因此，字节的顺序和对齐方式在这两种情况下可能会有所不同。 例如，考虑一个 64 位整数值 0x1122334455667788。 在大端字节序中，存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 而在小端字节序中，存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x88 0x77 0x66 0x55 0x44 0x33 0x22 0x11 尽管在 64 位和 32 位系统上字节顺序的原理相同，但具体的存储布局和访问方式可能有所不同。因此，在跨平台开发或数据交换中，需要注意字节序的差异，并采取适当的转换方法以确保数据的正确解释和传输。 影响字节序的选择对于不同的计算机体系结构和通信协议至关重要。它主要影响以下方面： 数据传输：在网络通信和数据交换中，如果通信双方使用不同的字节序，就需要进行字节序的转换，以确保正确解释和传输数据。 文件格式：某些文件格式（如图像、音频、视频）可能使用特定的字节序来存储数据，因此读取和解析这些文件时需要考虑字节序。 处理器架构：不同的处理器架构可能采用不同的字节序。例如，x86 架构使用小端字节序，而 PowerPC 架构使用大端字节序。在开发软件时，需要根据目标处理器架构的字节序选择适当的数据处理方式。 正确地处理字节序是确保跨平台兼容性和数据一致性的重要方面，特别是在网络通信和数据交换的情况下。 比较整数值 0x12345678 在 64 位和 32 位系统上，以大端字节序和小端字节序存储的示例： 64 位系统大端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x12 0x34 0x56 0x78 0x00 0x00 0x00 0x00 64 位系统小端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x00 0x00 0x00 0x00 0x78 0x56 0x34 0x12 32 位系统大端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 32 位系统小端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 校验方法123456789101112131415#include &lt;stdio.h&gt;int main() &#123; unsigned int num = 0x01020304; unsigned char *ptr = (unsigned char*)&amp;num; if (*ptr == 0x01) &#123; printf(&quot;大端字节序 &quot;); &#125; else &#123; printf(&quot;小端字节序 &quot;); &#125; return 0;&#125;","categories":["平台Platform","Linux","其他"]},{"title":"Linux网络配置","path":"/2024/05/22/平台Platform-Linux-网络-Linux网络配置/","content":"配置网卡信息IP、网关、掩码 1/etc/network/interfaces DNS 1/etc/resolv.conf &#x3D;&#x3D;》重启网卡 sudo service networking restart 123/etc/sysconfig/network-scripts/ifcfg-eno16777736TYPE=Ethernet(设备类型） BOOTPROTO=static（地址分配模式） NAME=eno16777736 ONBOOT=yes（是否启用）IPADDR=192.168.10.10 NETMASK=255.255.255.0 GATEWAY=192.168.10.1 DNS1=192.168.10.1 &#x3D;&#x3D;》重启网卡 systemctl restart network","categories":["平台Platform","Linux","网络"]},{"title":"linux下网络配置命令","path":"/2024/05/22/平台Platform-Linux-网络-linux下网络配置命令/","content":"TCP&#x2F;IP 网络相关概念 配置以太网络接口 配置 ppp 网络接口 Linux 环境下的网络配置 检测网络配置 TCP&#x2F;IP 网络相关概念 TCP&#x2F;IP 协议 IP 地址、子网掩码和域名 路由选择和网关地址 端到端连接 Linux 的网络应用 Linux 的网络接口设备 在网络中使用的每一个外围设备的网络接口，在 Linux 的核心（kernel）中都有相应的名字。 网络接口设备和相关的设备接口名：lo 本地回送接口。用于网络软件测试以及本地机进程间通信，无论什么程序一旦使用回送地址发送数据，协议软件立即将其返回，不进行任何网络传输。在 Linux 系统中，回送设备是默认设置好的。ethn 第 n 个以太网卡接口 (n 为 0 表示第一块，以此类推)，eth 是大多数网卡的接口设备名。pppn 第 n 个 ppp 接口。PPP 接口按照与它们有关的 PPP 配置顺序连接在串口上。 网络配置命令 hostnameLinux– 查看或配置计算机的主机名 ifconfig– 查看或配置网络接口 ifup– 启用指定的网络接口 ifdown– 禁用指定的网络接口 route– 查看或配置内核路由表的配置情况 配置以太网络－使用命令 配置 IP 地址– # ifconfig [interface] [ip-address] [netmask …] [broadcast … ] [up] [down] 配置默认网关– # route add default gw IP 地址 – #route add 0.0.0.0 netmask 0.0.0.0 eth0 配置 DNS 客户– # vi &#x2F;etc&#x2F;resolv.conf TCP&#x2F;IP 配置文件&#x2F;etc&#x2F;sysconfig&#x2F;network 主机最基本网络信息，用于系统启动 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts 系统启动初始化网络信息 &#x2F;etc&#x2F;xinetd.conf 定义由超级进程 xinetd 启动的网络服务 &#x2F;etc&#x2F;hosts 主机和 ip 映射 &#x2F;etc&#x2F;host.conf DNS 客户端搜索顺序 &#x2F;etc&#x2F;resoly.conf 指定 DNS 地址 &#x2F;etc&#x2F;serveices 编辑&#x2F;etc&#x2F;sysconfig&#x2F;entwork-script&#x2F;ifcfg-eth0 文件 Linux 支持一块网卡绑定多 IP，编辑子接口配置文件 ifcfg-eth0:1 Netconfig 调用菜单 配置 ADSL 网络接口 安装 pppoerpm –qa |grep pppoe 配置 pppoeadsl-setup&#x2F;etc&#x2F;sysconfig&#x2F;network-script&#x2F;ifcfg-ppp0adsl-status 启用和挂断 ADSL 网络连接adsl-start (或 ifup ppp0)adsl-stop (或 ifdown ppp0) 网络测试一般方法 排除非自身因素 查看本机 IP 地址 检测与网关的连接 监测与互联网的连接 测试域名解析 测试与特定站点的连接 检测网络状态 Ifconfig– 检测网络接口 ping– 检测网络连通性 netstat– 查看网络状态 traceroute– 检测到目的主机所经过的路由器 tcpdump– 显示本机网络流量的状态","categories":["平台Platform","Linux","网络"]},{"title":"管理员口令丢失","path":"/2024/05/22/平台Platform-Linux-其他-管理员口令丢失/","content":"管理员口令丢失解决办法 开机从 LILO 或 GRUB 中选择进入单用户模式（运行级别 1） 使用 passwd 命令修改 root 口令 重新切换为运行级别 3 或 5 切换到 root 用户，但是不切换用户环境sudo –s","categories":["平台Platform","Linux","其他"]},{"title":"Linux命令","path":"/2024/05/22/平台Platform-Linux-其他-Linux命令/","content":"嵌入式开发中常常需要确认开发板的系统版本，CPU，各种外部设备，内寸占用情况等数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138sudo –s # 切换到root用户，但是不切换用户环境# 操作系统uname -a #查看内核head -n 1 /etc/issue #查看操作系统版本cat /proc/cpuinfo #查看CPU信息hostname #查看计算机名lspci -tv #列出所有PCI设备lsusb -tv #列出所有USB设备lsmod #列出加载的内核模块env #查看环境变量# 资源free -m #查看内存使用量和交换区使用量df -h #查看各分区使用情况du -sh &lt;目录名&gt; #查看指定目录的大小grep MemTotal /proc/meminfo #查看内存总量grep MemFree /proc/meminfo #查看空闲内存量uptime #查看系统运行时间、用户数、负载cat /proc/loadavg #查看系统负载# 磁盘和分区mount | column -t #查看挂接的分区状态fdisk -l #查看所有分区swapon -s #查看所有交换分区hdparm -i /dev/hda #查看磁盘参数(仅适用于IDE设备)dmesg | grep IDE #查看启动时IDE设备检测状况# 网络ifconfig #查看所有网络接口的属性iptables -L #查看防火墙设置route -n #查看路由表netstat -lntp #查看所有监听端口netstat -antp #查看所有已经建立的连接netstat -s #查看网络统计信息# 进程ps -ef #查看所有进程top #实时显示进程状态# 用户w #查看活动用户id &lt;用户名&gt; #查看指定用户信息last #查看用户登录日志cut -d: -f1 /etc/passwd #查看系统所有用户cut -d: -f1 /etc/group #查看系统所有组crontab -l #查看当前用户的计划任务# 服务chkconfig --list #列出所有系统服务chkconfig --list | grep on #列出所有启动的系统服务# 程序rpm -qa #查看所有安装的软件包文件命令lsls -lacd dircdpwdmkdir dirrm filerm -r dirrm -f filerm -rf dircp file1 file2cp -r dir1 dir2mv file1 file2ln -s file linktouch filecat &gt; filemore filehead filetail filetail -f fileSSHssh user@hostssh -p port user@hostssh-copy-id user@host压缩tar cf file.tar filestar xf file.tartar czf file.tar.gz filestar xzf file.tar.gz tar cjf file.tar.bz2tar xjf file.tar.bz2gzip filegzip -d file.gz文件权限chmod otcal filechown搜索grep pattern filesgrep -r pattern dircommand | grep patternfind -name file网络ping hostwhois domaindig domiandig -x hostwget filewget -c file进程管理pstopkill pidkillall procbgfgfg n系统信息datecaluptimewwhoamifinger useruname -acat /proc/cpuinfocat /proc/meminfoman commanddfdufreefile [filename]\t# 可查看可执行文件是ARM架构还是X86架构uname -a\t# 显示电脑以及操作系统的相关信息df\t# 查看磁盘mount\t# 挂载umount\t# 卸载sync\t# 卸载之前同步数据scp test.c root@192.168.7.1:/home/root\t# SCP拷贝数据cat /sys/kernel/debug/usb/devices\t# 查看USB类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445cat # 把档案串连接后传到基本输出（萤幕或加 &gt; fileName 到另一个档案） cd chmod a+x filename # 对文件增加权限chown -R dirname # 对目前目录下的所有档案与子目录进行相同的拥有者变更cp -r dest source # 将目录下之档案亦皆依序拷贝至目的地cutfind path -name &quot;filename*&quot; # 在path路径下查找所有以filename开头的文件less filename # 浏览文字档案的内容ln -s yy zz # 将档案 yy 产生一个 symbolic link:zz ,不加s为硬链接locate chdrv # 寻找所有叫 chdrv 的档案ls -alrtFR filename #more -s testfile # 逐页显示 testfile 之档案内容,如有连续两行以上空白行则以一行空白行显示。 more +20 testfile # 从第 20 行开始显示 testfile 之档案内容。mv [options] source dest rm -r Finished rmdir -p BBB/Test split -b 1m filename filename.dump. # 将filename分割为1M大小，分割后的文件名为filename.dump.aa，filename.dump.ab...touch filename#将档案的时候记录改为现在的时间。若档案不存在,系统会建立新的档案。 at 5pm + 3 days /bin/ls # 三天后的下午 5 点执行 /bin/ls:cal # 显示本月的月历crontab 0 6-12/3 * 12 * /usr/bin/backup # 在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backupdate # 显示或设定系统的日期与时间sleep # 用来将目前动作延迟一段时间 time # 测量特定指令执行时所需消耗的时间及系统资源等资讯。uptime # 显示开机时间等信息last # 显示系统开机以来获是从每月初登入者的讯息loginpasswdwho # 显示系统中有那些使用者正在上面kill # 送出一个特定的信号 (signal) 给行程 id 为 pid 的行程根据该信号而做特定的动作, 若没有指定, 预设是送出终止 (TERM) 的信号 ps -aux # 显示瞬间行程 (process) 的动态 pstree # 将所有行程 (process) 以树状图显示top # 即时显示 process 的动态 skill # 送个讯号给正在执行的程序,预设的讯息为 TERM (中断) expr #字串长度/从位置处抓取字串/出现次数trclear compress -f source.dat # 将 source.dat 压缩成 source.dat.Z，解压-dtcpdumprenice +1 987 -u daemon root -p 32 # 将行程 id 为 987 及 32 的行程与行程拥有者为 daemon 及 root 的优先序号码加 1nice -n 1 ls # 将 ls 的优先序加 1 并执行diff -u a.patch oldfile newfile # 可以完成比较功能，生成补丁文件patch -i a.patch filname # 命令用于打补丁，补丁文件是使用diff产生的 time使用方式： 1time [options] COMMAND [arguments] 使用说明： time 指令的用途,在于等等。需要特别注意的是,部分资讯在 Linux 上显示不出来。这是因为在 Linux 上部分资源的分配函式与 time 指令所预设的方式并不相同,以致于 time 指令无法取得这些资料。 -o or –output&#x3D;FILE 设定结果输出档。这个选项会将 time 的输出写入 所指定的档案中。如果档案已经存在,系统将覆写其内容。 -a or –append 配合 -o 使用,会将结果写到档案的末端,而不会覆盖掉原来的内容。 -f FORMAT or –format&#x3D;FORMAT 以 FORMAT 字串设定显示方式。当这个选项没有被设定的时候,会用系统预设的格式。不过你可以用环境变数 time 来设定这个格式,如此一来就不必每次登入系统都要设定一次。 一般设定上,你可以用 \\t 表示跳栏,或者是用 表示换行。 每一项资料要用 % 做为前导。如果要在字串中使用百分比符号,就用.（学过 C 语言的人大概会觉得很熟悉） time 指令可以显示的资源有四大项,分别是： 1234Time resources Memory resources IO resources Command info 详细的内容如下： 1234567891011121314151617181920212223242526272829303132Time Resources E 执行指令所花费的时间,格式是：[hour]:minute:second。请注意这个数字并不代表实际的 CPU 时间。 e 执行指令所花费的时间,单位是秒。请注意这个数字并不代表实际的 CPU 时间。 S 指令执行时在核心模式（kernel mode）所花费的时间,单位是秒。 U 指令执行时在使用者模式（user mode）所花费的时间,单位是秒。 P 执行指令时 CPU 的占用比例。其实这个数字就是核心模式加上使用者模式的 CPU 时间除以总时间。 Memory Resources M 执行时所占用的实体记忆体的最大值。单位是 KB t 执行时所占用的实体记忆体的平均值,单位是 KB K 执行程序所占用的记忆体总量（stack+data+text）的平均大小,单位是 KB D 执行程序的自有资料区（unshared data area）的平均大小,单位是 KB p 执行程序的自有堆叠（unshared stack）的平均大小,单位是 KB X 执行程序间共享内容（shared text）的平均值,单位是 KB Z 系统记忆体页的大小,单位是 byte。对同一个系统来说这是个常数 IO Resources F 此程序的主要记忆体页错误发生次数。所谓的主要记忆体页错误是指某一记忆体页已经置换到置换档（swap file)中,而且已经分配给其他程序。此时该页的内容必须从置换档里再读出来。 R 此程序的次要记忆体页错误发生次数。所谓的次要记忆体页错误是指某一记忆体页虽然已经置换到置换档中,但尚未分配给其他程序。此时该页的内容并未被破坏,不必从置换档里读出来 W 此程序被交换到置换档的次数 c 此程序被强迫中断（像是分配到的 CPU 时间耗尽）的次数 w 此程序自愿中断（像是在等待某一个 I/O 执行完毕,像是磁碟读取等等）的次数 I 此程序所输入的档案数 O 此程序所输出的档案数 r 此程序所收到的 Socket Message s 此程序所送出的 Socket Message k 此程序所收到的信号 ( Signal )数量 Command Info C 执行时的参数以及指令名称 x 指令的结束代码 ( Exit Status ) -p or –portability 这个选项会自动把显示格式设定成为： 123real %e user %U sys %S 这么做的目的是为了与 POSIX 规格相容。 -v or –verbose 这个选项会把所有程式中用到的资源通通列出来,不但如一般英文语句,还有说明。对不想花时间去熟习格式设定或是刚刚开始接触这个指令的人相当有用。 范例： 利用下面的指令 1time -v ps -aux 我们可以获得执行 ps -aux 的结果和所花费的系统资源。如下面所列的资料： 123456789101112131415161718192021222324252627282930USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.4 1096 472 ? S Apr19 0:04 init root 2 0.0 0.0 0 0 ? SW Apr19 0:00 [kflushd] root 3 0.0 0.0 0 0 ? SW Apr19 0:00 [kpiod] ...... root 24269 0.0 1.0 2692 996 pts/3 R 12:16 0:00 ps -aux Command being timed: &quot;ps -aux&quot; User time (seconds): 0.05 System time (seconds): 0.06 Percent of CPU this job got: 68% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 0 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 238 Minor (reclaiming a frame) page faults: 46 Voluntary context switches: 0 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 mail使用方式： 1mail [-iInv] [-s subject] [-c cc-addr] [-b bcc-addr] user1 [user 2 ...] 使用说明： mail 不仅只是一个指令, mail 还是一个电子邮件程式,不过利用 mail 来读信的人应该很少吧！对于系统管理者来说 mail 就很有用,因为管理者可以用 mail 写成 script ,定期寄一些备忘录提醒系统的使用者。 i 忽略 tty 的中断讯号。 (interrupt) I 强迫设成互动模式。 (Interactive) v 列印出讯息,例如送信的地点,状态等等。 (verbose) n 不读入 mail.rc 设定档。 s 邮件标题。 c cc 邮件地址。 b bcc 邮件地址。 范例： 将信件送给一个或以上的电子邮件地址,由于没有加入其他的选项,使用者必须输入标题与信件的内容等。而 user2 没有主机位置,就会送给邮件伺服器的 user2 使用者。 12mail user1@email.address mail user1@email.address user2 将 mail.txt 的内容寄给 user2 同时 cc 给 user1 。如果将这一行指令设成 cronjob 就可以定时将备忘录寄给系统使用者。 1mail -s 标题 -c user1 user2 &lt; mail.txt","categories":["平台Platform","Linux","其他"]},{"title":"时间编程","path":"/2024/05/22/平台Platform-Linux-其他-时间编程/","content":"时间类型Coordinated Unicersal Time（UTC）：世界标准时间，也就是大家所熟知的格林威治标准时间（Greenwich Mean Time 吗 GMT） Calendar Time：日历时间，是用“从一个标准时间点（如：1970 年 1 月 1 日 0 点）到此时经过的秒数”来表示时间 时间获取获取日历时间，即从 1970 年 1 月 1 日 0 点到现在所经历的秒数 12#include &lt;time.h&gt;time_t time(time_t*tloc); 将日历时间转化为格林威治标准时间，并保存至 TM 结构 1struct tm *gmtime(const time_t*timep); 将日历时间转化为本地时间，并保存至 TM 结构 1struct tm *localtime(const time_t*timep); 1234567891011struct tm &#123;int tm_sec; /* Seconds(0-60) */int tm_min; /* Minutes(0-59) */int tm_hour; /* Hours(0-23) */int tm_mday; /* Day of the month (1-31) */int tm_mon; /* Month (0-11) */int tm_year; /* Year - 1900 */int tm_wday; /* Day of the week (0-6, Sunday = 0) */int tm_yday; /* Dayin the year (0-365, 1 Jan = 0) */int tm_isdst; /* Daylightsaving time */&#125;; 将 tm 格式的时间转化为字符串，如：Sat Jul 30 08：43：03：2005 1char*asctime(conststruct tm *tm); 将日历时间转化为本地时间的字符串形式 1char*ctime(const time_t*timep); 获取从今日凌晨到现在的时间差，常用于计算事件耗时 12#include &lt;sys/time.h&gt;int gettimeofday(struct timeval *tv,struct timezone *tz); 1234struct timeval &#123;time_t tv_sec; /*seconds*/ 秒数suseconds_t tv_usec; /* microseconds*/ 微秒&#125;; 延时执行使程序睡眠 seconds 12#include &lt;unistd.h&gt;unsigned intsleep(unsigned intseconds); 使程序睡眠 usec 微秒 12#include &lt;unistd.h&gt;int usleep(useconds_t usec);","categories":["平台Platform","Linux","其他"]},{"title":"Markdown语法","path":"/2024/05/22/语言-Markdown语法/","content":"Markdown 基础介绍Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 Markdown 能被使用来撰写电子书，如：Gitbook。 标题Markdown 标题有两种格式。 使用 &#x3D; 和 - 标记一级和二级标题 1234一级标题=================二级标题----------------- 使用 # 号可表示 1-6 级标题，一级标题对应一个 # 号。 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 段落Markdown 段落的换行有两种格式。 使用两个以上空格加上回车 在段落后面使用一个空行 字体123456*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ 分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 12345**** * ******- - ----------- 删除线如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线 ~~ 即可 1~~这是要删除的文本~~ 下划线利用 html 的 &lt;u&gt; 标签 1&lt;u&gt;带下划线文本&lt;/u&gt; 脚注脚注是对文本的补充说明。 Markdown 脚注的格式如下: [^要注明的文本] 列表Markdown 支持有序列表和无序列表。 无序列表使用星号 (*)、加号 (+) 或是减号 (-) 作为列表标记，这些标记后面要添加一个空格，然后再填写内容 123456789* 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项 有序列表使用数字并加上 . 号来表示 1231. 第一项2. 第二项3. 第三项 列表嵌套只需在子列表中的选项前面添加两个或四个空格即可 1234561. 第一项：- 第一项嵌套的第一个元素- 第一项嵌套的第二个元素2. 第二项：- 第二项嵌套的第一个元素- 第二项嵌套的第二个元素 区块 Markdown 区块引用是在段落开头使用 &gt; 符号 ，然后后面紧跟一个空格符号 区块是可以嵌套的，一个 &gt; 符号是最外层，两个 &gt; 符号是第一层嵌套 区块中也可以使用列表 列表中也可以使用区块，需要在 &gt; 前添加四个空格的缩进 1234567891011&gt; 区块&gt;&gt; 区块嵌套&gt;&gt;&gt; 区块嵌套&gt; 1. 区块列表1&gt; 2. 区块列表2&gt; + 区块列表1&gt; + 区块列表2* 列表1&gt; 列表区块1&gt; 列表区块2* 列表2 代码段落上的一个函数或片段的代码可以用反引号把它包起来（&#96;） 1`printf()` 代码块 四个空格 tab 制表符 用 ``&#96; 包裹一段代码，并指定一种语言 链接12[链接名称](baidu.com)&lt;baidu.com&gt; 高级链接 123这个链接用 1 作为网址变量 [Google][1]然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ 图片12![alt 属性文本](图片地址)![alt 属性文本](图片地址 &quot;可选标题&quot;) 也可以按照高级链接的方式，将图片地址放在文档结尾图片大小如果要修改图片大小，采用 html 的 &lt;img&gt; 标签 表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行 1234| 表头 | 表头 || ---- | ---- || 单元格 | 单元格 || 单元格 | 单元格 | 对齐 -: 设置内容和标题栏居右对齐。 :- 设置内容和标题栏居左对齐。 :-: 设置内容和标题栏居中对齐。 Markdown 技巧 不同的 markdown 编辑器支持的语法略有不同，下方介绍的相关技巧不一定支持 Github Flavored Markdown (GFM) 的工作清单语法 显示效果 KaTeX 数学公式排版语法语法 显示效果 SVG 向量流程图语法 显示效果 向量 UML 顺序图表语法 显示效果","categories":["语言"]},{"title":"WireShark的安装","path":"/2024/05/22/软件-WireShark-WireShark的安装/","content":"WireShark重点演示： 如何选择网卡接口 如何设置过滤条件 如何查看抓取的报文 Linux 下安装和配置安装1sudo apt-get install wireshark 设置运行权限如果您在此阶段以非 root 用户身份运行 wireshark，您将收到消息“没有接口可以用于在当前配置的系统中进行捕获。” 缺省在非 root 账号下运行会发现看不见 interface 信息 Create the wiresharkgroup. 1sudo groupadd wireshark Add your username to the wiresharkgroup 1sudo usermod -a -G wiresharkYOUR_USER_NAME Change the group ownership of file dumpcap to wireshark 1sudo chgrp wireshark/usr/bin/dumpcap Change the mode of the file dumpcap to allow execution bythe group wireshark 1sudo chmod 750 /usr/bin/dumpcap Grant capabilities with setcap, man capabilities(7), setcap(8), cap_from_text(3) for more info about what are “cap_net_raw”, “cap_net_admin” and “eip”. Anyway, after we grant the capabilities, the dump can perform various network-related operations, use RAW and PACKET sockets; bind to anyaddressfor transparent proxying. 1sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap Verifythe change 1sudo getcap /usr/bin/dumpcap Outputshould be like below: 1/usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip At this point, you will need to log out, then backinto ubuntu 简单介绍下这个软件的一些常用按钮，简单的说下最常用的按钮，打开软件后，下面红框中的按钮从左到右依次是： -1 列表显示所有网卡的网络包情况，一般用的很少； -2 显示抓包选项，一般都是点这个按钮开始抓包； -3 开始新的抓包，一般用的也很少； -4 停止抓包，当你抓完包之后，就是点这个停止了； -5 清空当前已经抓到的数据包，可以防止抓包时间过长机器变卡； 而实际上，一般我们只要知道上面加粗部分的按钮功能，就可以完成抓包了，剩下的就是如何抓你想要的数据包，如何分析的问题了。 接下来说下抓包选项界面，也就是点第二个按钮出来的界面，同样，这里也只介绍最常用的几个功能，首先下图中最上面的红框是选择需要抓的网卡，选择好网卡后会在下面显示这个网卡的 IP 地址。 然后 Capture Filter 中就是要写抓包规则的地方，也叫做“过滤规则”，我们下面要说的很多规则都是要写到这个框里的，规则写好后，点下 面的 Start 就开始抓包了。 当抓包结束之后，如果你需要把抓到的数据包找其他人分析，那么可以点菜单上的 file，然后点 Save As 保存抓到的数据包 使用 Wireshark 时最常见的问题，是当您使用默认设置时，会得到大量冗余信息，以至于很难找到自己需要的部分。这就是为什么过滤器会 如此重要。它们可以帮助我们在庞杂的结果中迅速找到我们需要的信息。 三次握手 Three-way Handshake一个虚拟连接的建立是通过三次握手来实现的 (Client) –&gt; [SYN] –&gt; (Server)假如 Client 和 Server 通讯. 当 Client 要和 Server 通信时，Client 首先向 Server 发一个 SYN (Synchronize) 标记的包，告诉 Server 请求建立连接.注意: 一个 SYN 包就是仅 SYN 标记设为 1 的 TCP 包 (参见 TCP 包头 Resources). 认识到这点很重要，只有当 Server 收到 Client 发来的 SYN 包，才可建立连接，除此之外别无他法。因此，如果你的防火墙丢弃所有的发往外网接口的 SYN 包，那么你将不 能让外部任何主机主动建立连接。 (Client) &lt;– [SYN&#x2F;ACK] &lt;–(Server)接着，Server 收到来自 Client 发来的 SYN 包后，会发一个对 SYN 包的确认包 (SYN&#x2F;ACK) 给 Client，表示对第一个 SYN 包的确认，并继续握手操作.注意: SYN&#x2F;ACK 包是仅 SYN 和 ACK 标记为 1 的包. (Client) –&gt; [ACK] –&gt; (Server)Client 收到来自 Server 的 SYN&#x2F;ACK 包,Client 会再向 Server 发一个确认包 (ACK)，通知 Server 连接已建立。至此，三次握手完成，一个 TCP 连接完成。Note: ACK 包就是仅 ACK 标记设为 1 的 TCP 包. 需要注意的是当三此握手完成、连接建立以后，TCP 连接的每个包都会设置 ACK 位。 这就是为何连接跟踪很重要的原因了. 没有连接跟踪,防火墙将无法判断收到的 ACK 包是否属于一个已经建立的连接.一般的包过滤 (Ipchains) 收到 ACK 包时,会让它通过 (这绝对不是个 好主意). 而当状态型防火墙收到此种包时，它会先在连接表中查找是否属于哪个已建连接，否则丢弃该包。 四次握手 Four-way Handshake 四次握手用来关闭已建立的 TCP 连接 (Client) –&gt; ACK&#x2F;FIN –&gt; (Server) (Client) &lt;– ACK &lt;– (Server) (Client) &lt;– ACK&#x2F;FIN &lt;– (Server) (Client) –&gt; ACK –&gt; (Server)注意: 由于 TCP 连接是双向连接, 因此关闭连接需要在两个方向上做。**ACK&#x2F;FIN 包 (ACK 和 FIN 标记设为 1) 通常被认为是 FIN(终结) 包.**然而, 由于连接还没有关闭, FIN 包总是打上 ACK 标记. 没有 ACK 标记而仅有 FIN 标记的包不是合法的包，并且通常被认为是恶意的。 连接复位 Resetting a connection四次握手不是关闭 TCP 连接的唯一方法. 有时,如果主机需要尽快关闭连接 (或连接超时,端口或主机不可达),RST(Reset) 包将被发送. 注意在，由于 RST 包不是 TCP 连接中的必须部分, 可以只发送 RST 包 (即不带 ACK 标记). 但在正常的 TCP 连接中 RST 包可以带 ACK 确认标记 请注意 RST 包是可以不要收到方确认的? 无效的 TCP 标记 Invalid TCP Flags 到目前为止，你已经看到了 SYN, ACK, FIN, 和 RST 标记. 另外，还有 PSH (Push) 和 URG (Urgent) 标记. 最常见的非法组合是 SYN&#x2F;FIN 包. 注意: 由于 SYN 包是用来初始化连接的, 它不可能和 FIN 和 RST 标记一起出现. 这也是一个恶意攻击. 由于现在大多数防火墙已知 SYN&#x2F;FIN 包, 别的一些组合,例如 SYN&#x2F;FIN&#x2F;PSH, SYN&#x2F;FIN&#x2F;RST, SYN&#x2F;FIN&#x2F;RST&#x2F;PSH。很明显，当网络中出现这种包时，很你的网络肯定受到攻击了。 别的已知的非法包有 FIN (无 ACK 标记) 和”NULL”包。如同早先讨论的，由于 ACK&#x2F;FIN 包的出现是为了关闭一个 TCP 连接，那么正常的 FIN 包总是带有 ACK 标记。”NULL”包就是没有任何 TCP 标记的包 (URG,ACK,PSH,RST,SYN,FIN 都为 0)。 到目前为止，正常的网络活动下，TCP 协议栈不可能产生带有上面提到的任何一种标记组合的 TCP 包。当你发现这些不正常的包时，肯定有人对你的网络不怀好意。 UDP (用户数据包协议 User DatagramProtocol)TCP 是面向连接的，而 UDP 是非连接的协议。UDP 没有对接受进行确认的标记和确认机制。对丢包的处理是在应用层来完成的。(or accidentalarrival).此处需要重点注意的事情是：在正常情况下，当 UDP 包到达一个关闭的端口时，会返回一个 UDP 复位包。由于 UDP 是非面向连接的, 因此没有任何确认信息来确认包是否正确到达目的地。因此如果你的防火墙丢弃 UDP 包，它会开放所有的 UDP 端口 (?)。 由于 Internet 上正常情况下一些包将被丢弃，甚至某些发往已关闭端口 (非防火墙的) 的 UDP 包将不会到达目的，它们将返回一个复位 UDP 包。 因为这个原因，UDP 端口扫描总是不精确、不可靠的。 看起来大 UDP 包的碎片是常见的 DOS(Denial ofService) 攻击的常见形式 (这里有个 DOS 攻击的例子，http://grc.com/dos/grcdos.htm ). ICMP (网间控制消息协议 Internet ControlMessage Protocol)如同名字一样， ICMP 用来在主机&#x2F;路由器之间传递控制信息的协议。 ICMP 包可以包含诊断信息 (ping, traceroute - 注意目前 unix 系统中的 traceroute 用 UDP 包而不是 ICMP)，错误信息 (网络&#x2F;主机&#x2F;端口 不可达 network&#x2F;host&#x2F;port unreachable), 信息 (时间戳 timestamp, 地址掩码 addressmaskrequest, etc.)，或控制信息 (source quench, redirect, etc.) 。 你可以在 http://www.iana.org/assignments/icmp-parameters 中找到 ICMP 包的类型。 尽管 ICMP 通常是无害的，还是有些类型的 ICMP 信息需要丢弃。 Redirect (5), Alternate Host Address(6), Router Advertisement (9) 能用来转发通讯。 Echo (8), Timestamp (13)and AddressMask Request (17) 能用来分别判断主机是否起来，本地时间 和地址掩码。注意它们是和返回的信息类别有关的。 它们自己本身是不能被利用的，但它们泄露出的信息对攻击者是有用的。 ICMP 消息有时也被用来作为 DOS 攻击的一部分 (例如：洪水 ping flood ping,死 ping ?呵呵，有趣 ping of death)?&#x2F;p&gt; 包碎片注意 A Note About Packet Fragmentation 如果一个包的大小超过了 TCP 的最大段长度 MSS(Maximum Segment Size) 或 MTU (Maximum Transmission Unit)，能够把此包发往目的的唯一 方法是把此包分片。由于包分片是正常的，它可以被利用来做恶意的攻击。 因为分片的包的第一个分片包含一个包头，若没有包分片的重组功能，包过滤器不可能检测附加的包分片。典型的攻击 Typicalattacks involve in overlapping the packet data in which packet header is 典型的攻击 Typicalattacksinvolve in overlapping the packet data in which packet header isnormal until isit overwritten with different destination IP (or port) thereby bypassing firewall rules。包分片能作为 DOS 攻击的一部分，它 可以 crash older IP stacks 或涨死 CPU 连接能力。 Netfilter&#x2F;Iptables 中的连接跟踪代码能自动做分片重组。它仍有弱点，可能受到饱和连接攻击，可以把 CPU 资源耗光。 OK，到此为止，关于 Wireshark 抓包工具的一些小教程已经写完了，而导致我想写这么一个纠结的教程的原因是，前几天通过这个抓包解决了梦幻西游在网维大师无盘上容易掉线的问题，当时捕捉到梦幻西游掉线时的数据包是这样的。 注意下图中的红色数据，123.58.184.241 是梦幻西游的服务器，而 192.168.1.41 是玩梦幻西游的客户机，在掉线时，发现是先有梦幻西游的服务器向客户机发送一个 [FIN,ACK] 数据包，根据上面的解释，FIN 标记的数据包是代表要断开连接的意思，而接着客户机又回给服务器一个确认断 开链接包。当看到这个抓包数据时，就意识到，大家说的在网维大师系统虚拟盘上梦幻爱掉线的问题，并非普通的网络问题，因为通过数据包的信息来看，是梦幻服 务器主动要求断开链接，产生这个情况无非是以下几个原因： 服务器发现客户端非法，比如有外挂什么的，踢掉了客户机； 服务器压力大，踢掉了客户机； 总之不是客户端问题导致的掉线； 那么既然结论是如此，为什么会有在网维大师系统虚拟盘上容易出现梦幻掉线问题呢？原因是由于网维大师系统虚拟盘是模拟真实硬盘方式来实现的，而在模拟过程 中，将硬盘的序列号设置为固定过的 OSDIY888 了，而梦幻西游刚好后识别客户机硬盘信息，发现大量客户端的硬盘序列号都是一样的，就认为是作弊或者使 用挂机外挂了，结果就导致随机被服务器踢下线的情况发生，后来我们将硬盘序列号设置为空，则没再出现该问题。这个问题在未来的新版本中会解决掉。 说这个案例的目的并不是为了说明抓包多有用，而是想说明一些解决问题的思路和方法，有些人是有思路，但是缺方法，比如不会用工具，而有些人收集了很多工具 却不会用，而我其实就属于后者，几年前就收集了 n 多工具，但是用到的没几个。慢慢的学会用这些工具后，发现思维 + 工具，解决问题是效率暴增，接下来的几天 里，会陆续介绍写小工具给大家，也希望大家有空学习下，有问题先百度，再自己摸索，而不是一味的求助，毕竟求人不如求己！自己能直接搞定，是皆大欢喜的事情 注意：由于某些系统为了防止 ARP 攻击，都免疫掉了一个 Npptools.dll 文件，这会导致该软件无法正常安装，打下这个补丁就可以了","categories":["软件","WireShark"]},{"title":"WireShark过滤器","path":"/2024/05/22/软件-WireShark-WireShark过滤器/","content":"什么是 wiresharkWireshark 是一款开源的网络封包分析软件。它可以捕获、分析和展示计算机网络中的数据包。Wireshark 支持多种网络协议，包括以太网、无线网络、Internet 协议（IP）、传输控制协议（TCP）、用户数据报协议（UDP）等等。 使用 Wireshark，您可以通过连接到计算机网络上的一个接口来捕获网络数据包。捕获的数据包将被 Wireshark 以可视化的方式显示出来，您可以查看每个数据包的详细信息，例如源 IP 地址、目标 IP 地址、协议类型、数据长度等等。 Wireshark 提供了强大的过滤功能，使您能够根据特定的条件过滤数据包，以便更好地分析网络流量。它还提供了许多分析工具和统计功能，如流量图表、协议分层显示、数据包重组等，帮助用户深入了解网络通信并发现潜在的问题。 Wireshark 是一个广泛应用于网络管理、网络安全和网络协议开发的工具。它能够帮助网络管理员诊断和解决网络故障，分析网络性能问题，检测网络安全事件，以及进行协议开发和调试等任务。由于其功能强大且易于使用，Wireshark 成为了网络分析领域的标准工具之一。 过滤器在 Wireshark 中，过滤器（Filter）是一种机制，用于选择和筛选特定的网络数据包以供分析。过滤器允许您根据特定的条件仅显示感兴趣的数据包，从而减少分析的数据量并集中精力于关注的内容。 Wireshark 使用一种称为 “ 显示过滤器 “（Display Filter）的语法来定义过滤条件。您可以根据多个参数，如源&#x2F;目标 IP 地址、协议类型、端口号、数据包长度、特定字段的值等等，创建过滤器规则。当过滤器应用于数据包捕获或已保存的数据包时，只有符合过滤条件的数据包会被显示，而其他数据包将被隐藏。 通过使用过滤器，您可以根据您的需求来选择显示的数据包，使得分析更加高效和专注。例如，您可以创建一个过滤器来只显示特定源 IP 地址的数据包，或者只显示某个协议类型的数据包，以便更好地关注您感兴趣的通信流量。 Wireshark 提供了广泛的过滤器语法和功能，使您能够根据不同的需求创建复杂的过滤条件。您可以使用比较运算符、逻辑运算符、通配符等来构建更精确的过滤规则，并根据需要组合多个条件来定义更复杂的过滤器。 过滤器在网络分析和故障排除中非常有用，可以帮助您集中注意力于感兴趣的数据包，提供更清晰和有针对性的分析。 过滤器的区别捕捉过滤器（CaptureFilters）：用于决定将什么样的信息记录在捕捉结果中。需要在开始捕捉前设置。 显示过滤器（DisplayFilters）：在捕捉结果中进行详细查找。他们可以在得到捕捉结果后随意修改。 两种过滤器的目的是不同的。 捕捉过滤器是数据经过的第一层过滤器，它用于控制捕捉数据的数量，以避免产生过大的日志文件。 显示过滤器是一种更为强大（复杂）的过滤器。它允许您在日志文件中迅速准确地找到所需要的记录。 两种过滤器使用的语法是完全不同的。 捕捉过滤器Protocol（协议）: 可能的值: ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp. 如果没有特别指明是什么协议，则默认使用所有支持的协议。 Direction（方向）: 可能的值: src, dst, src and dst, src or dst 如果没有特别指明来源或目的地，则默认使用 “src or dst” 作为关键字。 例如，”host 10.2.2.2″与”src or dst host 10.2.2.2″是一样的。 Host(s): 可能的值： net, port, host, portrange. 如果没有指定此值，则默认使用”host”关键字。 例如，”src 10.1.1.1″与”src host 10.1.1.1″相同。 Logical Operations（逻辑运算）: 可能的值：not, and, or. 否 (“not”) 具有最高的优先级。或 (“or”) 和与 (“and”) 具有相同的优先级，运算时从左至右进行。 例如， “not tcp port 3128 and tcp port 23″与”(not tcp port 3128) and tcp port 23″相同。 “not tcp port 3128 and tcp port 23″与”not (tcp port 3128 and tcp port 23)”不同。 例子： tcp dst port 3128 &#x2F;&#x2F;捕捉目的 TCP 端口为 3128 的封包。 ip src host 10.1.1.1 &#x2F;&#x2F;捕捉来源 IP 地址为 10.1.1.1 的封包。 host 10.1.2.3 &#x2F;&#x2F;捕捉目的或来源 IP 地址为 10.1.2.3 的封包。 ether host e0-05-c5-44-b1-3c &#x2F;&#x2F;捕捉目的或来源 MAC 地址为 e0-05-c5-44-b1-3c 的封包。如果你想抓本机与所有外网通讯的数据包时，可以将这里的 mac 地址换成路由的 mac 地址即可。 src portrange 2000-2500 &#x2F;&#x2F;捕捉来源为 UDP 或 TCP，并且端口号在 2000 至 2500 范围内的封包。 not imcp &#x2F;&#x2F;显示除了 icmp 以外的所有封包。（icmp 通常被 ping 工具使用） src host 10.7.2.12 and not dst net 10.200.0.0&#x2F;16 &#x2F;&#x2F;显示来源 IP 地址为 10.7.2.12，但目的地不是 10.200.0.0&#x2F;16 的封包。 (src host 10.4.1.12 or src net 10.6.0.0&#x2F;16) and tcp dst portrange 200-10000 and dst net 10.0.0.0&#x2F;8 &#x2F;&#x2F;捕捉来源 IP 为 10.4.1.12 或者来源网络为 10.6.0.0&#x2F;16，目的地 TCP 端口号在 200 至 10000 之间，并且目的位于网络 10.0.0.0&#x2F;8 内的所有封包。 src net 192.168.0.0&#x2F;24 src net 192.168.0.0 mask 255.255.255.0 &#x2F;&#x2F;捕捉源地址为 192.168.0.0 网络内的所有封包。 注意事项： 当使用关键字作为值时，需使用反斜杠“\\”。“ether proto \\ip” (与关键字”ip”相同). Ether proto 0x0800这样写将会以 IP 协议作为目标。 “ip proto \\icmp” (与关键字”icmp”相同).这样写将会以 ping 工具常用的 icmp 作为目标。 可以在”ip”或”ether”后面使用”multicast”及”broadcast”关键字。当您想排除广播请求时，”no broadcast”就会非常有用。 Protocol（协议）:您可以使用大量位于 OSI 模型第 2 至 7 层的协议。点击”Expression…”按钮后，您可以看到它们。比如：IP，TCP，DNS，SSH String1, String2 (可选项): 协议的子类。点击相关父类旁的”+”号，然后选择其子类。 显示过滤器例子： snmp || dns || icmp &#x2F;&#x2F;显示 SNMP 或 DNS 或 ICMP 封包。 ip.addr &#x3D;&#x3D; 10.1.1.1 &#x2F;&#x2F;显示来源或目的 IP 地址为 10.1.1.1 的封包。 ip.src !&#x3D; 10.1.2.3 or ip.dst !&#x3D; 10.4.5.6 &#x2F;&#x2F;显示来源不为 10.1.2.3 或者目的不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；目的 IP：任意 以及 来源 IP：任意；目的 IP：除了 10.4.5.6 以外任意 ip.src !&#x3D; 10.1.2.3 and ip.dst !&#x3D; 10.4.5.6 &#x2F;&#x2F;显示来源不为 10.1.2.3 并且目的 IP 不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；同时须满足，目的 IP：除了 10.4.5.6 以外任意 tcp.port &#x3D;&#x3D; 25 &#x2F;&#x2F;显示来源或目的 TCP 端口号为 25 的封包。 tcp.dstport &#x3D;&#x3D; 25 &#x2F;&#x2F;显示目的 TCP 端口号为 25 的封包。 tcp.flags &#x2F;&#x2F;显示包含 TCP 标志的封包。 tcp.flags.syn &#x3D;&#x3D; 0×02 &#x2F;&#x2F;显示包含 TCP SYN 标志的封包。 如果过滤器的语法是正确的，表达式的背景呈绿色。如果呈红色，说明表达式有误。 更为详细的说明请见：http://openmaniak.com/cn/wireshark_filters.php 以上只是抓包和简单的过滤，那么其实如果你要想达到能够分析这些网络包的要求时，还需要了解下一些数据包的标记，比如我们常说的 TCP 三次握手是怎么回事？","categories":["软件","WireShark"]},{"title":"Qt操作Sqlite3","path":"/2024/05/22/语言-Qt-Qt操作Sqlite3/","content":"创建数据库1234567891011121314void SqliteOperator::CreatDb()&#123; if(QSqlDatabase::contains(&quot;qt_sql_default_connection&quot;)) &#123; db = QSqlDatabase::database(&quot;qt_sql_default_connection&quot;); &#125; else &#123; db = QSqlDatabase::addDatabase(&quot;QSQLITE&quot;); db.setDatabaseName(&quot;test.db&quot;); db.setUserName(&quot;test&quot;); db.setPassword(&quot;test&quot;); &#125;&#125; 打开及关闭数据库1234567891011121314bool SqliteOperator::OpenDb()&#123; if(!db.open()) &#123; qDebug() &lt;&lt; &quot;Error: Failed to connect database.&quot; &lt;&lt; db.lastError(); return false; &#125; return true;&#125;void SqliteOperator::CloseDb()&#123; db.close();&#125; 创建数据表1234567891011121314void SqliteOperator::CreateTable()&#123; QSqlQuery sql_query; QString creat_sql = &quot;create table student (id int primary key, name varchar(30), age int)&quot;; sql_query.prepare(creat_sql); if(!sql_query.exec()) &#123; qDebug() &lt;&lt; &quot;Error: Fail to create table.&quot; &lt;&lt; sql_query.lastError(); &#125; else &#123; qDebug() &lt;&lt; &quot;Table created!&quot;; &#125;&#125; 插入数据123456789101112131415161718void SqliteOperator::InsertData()&#123; QString insert_sql = &quot;insert into student values (?, ?, ?)&quot;; QSqlQuery sql_query; sql_query.prepare(insert_sql);sql_query.addBindValue(GetMaxId() +1); sql_query.addBindValue(&quot;Wang&quot;); sql_query.addBindValue(25); if(!sql_query.exec()) &#123; qDebug() &lt;&lt; sql_query.lastError(); &#125; else &#123; qDebug() &lt;&lt; &quot;inserted Wang!&quot;; &#125;&#125; 查询数据1234567891011121314151617181920void SqliteOperator::QueryAllData()&#123; QString select_all_sql = &quot;select * from student&quot;; QSqlQuery sql_query; sql_query.prepare(select_all_sql); if(!sql_query.exec()) &#123; qDebug()&lt;&lt;sql_query.lastError(); &#125; else &#123; while(sql_query.next()) &#123; int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); int age = sql_query.value(2).toInt(); qDebug()&lt;&lt;QString(&quot;id:%1 name:%2 age:%3&quot;).arg(id).arg(name).arg(age); &#125; &#125;&#125; 条件查询123456789101112131415161718192021void SqliteOperator::QueryData()&#123; QString select_sql = QString(&quot;select * from student where name = &#x27;%1&#x27; and (age = &#x27;%2&#x27; or age = &#x27;%3&#x27;)&quot;) .arg(&quot;Wang&quot;) .arg(30) .arg(25); QSqlQuery sql_query; if(!sql_query.exec(select_sql)) &#123; qDebug()&lt;&lt;sql_query.lastError(); &#125; else &#123; while(sql_query.next()) &#123; int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); qDebug()&lt;&lt;QString(&quot;id:%1 name:%2&quot;).arg(id).arg(name); &#125; &#125;&#125;","categories":["语言","Qt"]},{"title":"JavaScript学习笔记","path":"/2024/05/22/语言-JavaScript学习笔记/","content":"JavaScript 用法HTML 中的 Javascript 脚本代码必须位于 &lt;script&gt; 与 &lt;/script&gt; 标签之间。 通常，我们需要在某个事件发生时执行代码，比如当用户点击按钮时。 如果我们把 JavaScript 代码放入函数中，就可以在事件发生时调用该函数。 Javascript 脚本代码可被放置在 HTML 页面的 &lt;body&gt; 和 &lt;head&gt; 部分中。 通常的做法是把函数放入 &lt;head&gt; 部分中，或者放在页面底部。这样就可以把它们安置到同一处位置，不会干扰页面的内容。 外部的 JavaScript也可以把脚本保存到外部文件中。外部文件通常包含被多个网页使用的代码。 外部 JavaScript 文件的文件扩展名是 .js。 如需使用外部文件，请在 &lt;script&gt; 标签的 “src” 属性中设置该 .js 文件： 12345&lt;button type=&quot;button&quot; onclick=&quot;myFunction()&quot;&gt;点击这里&lt;/button&gt;&lt;p&gt;&lt;b&gt;注释：&lt;/b&gt;myFunction 保存在名为 &quot;myScript.js&quot; 的外部文件中。&lt;/p&gt;&lt;script src=&quot;myScript.js&quot;&gt;&lt;/script&gt;\t&lt;/body&gt; js 代码如下： 1234function myFunction()&#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;我的第一个 JavaScript 函数&quot;;&#125; 外部脚本不能包含 &lt;script&gt; 标签。在标签中填写 onclick 事件调用函数时，不是 onclick&#x3D;函数名， 而是 onclick&#x3D;函数名 +() JavaScript JSONJSON 英文全称 JavaScript Object Notation JSON 是用于存储和传输数据的格式。 JSON 通常用于服务端向网页传递数据 。 数据为 键&#x2F;值 对。 数据由逗号分隔。 大括号保存对象 方括号保存数组 JSON 是 JS 对象的字符串表示法。它使用文本表示一个 JS 对象的信息，（JSON）本质是一个字符串。 JSON 字符串转换为 JavaScript 对象 1234567 var text = &#x27;&#123; &quot;sites&quot; : [&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Runoob&quot; , &quot;url&quot;:&quot;www.runoob.com&quot; &#125;,&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Google&quot; , &quot;url&quot;:&quot;www.google.com&quot; &#125;,&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Taobao&quot; , &quot;url&quot;:&quot;www.taobao.com&quot; &#125; ]&#125;&#x27;; obj = JSON.parse(text);document.getElementById(&quot;demo&quot;).innerHTML = obj.sites[1].name + &quot; &quot; + obj.sites[1].url; JSON.parse()\t用于将一个 JSON 字符串转换为 JavaScript 对象。 JSON.stringify()\t用于将 JavaScript 值转换为 JSON 字符串。 运行与调试在 Chrome 浏览器中可以通过按下 F12 按钮或者右击页面，选择 “ 检查 “ 来开启开发者工具 或者在右上角菜单栏选择 “ 更多工具 “&#x3D;》” 开发者工具 “ 来开启 Console 窗口调试 JavaScript 代码我们在 &gt; 符号后输入我们要执行的代码 console.log(“runoob”)，按回车后执行 清空 Console 窗口到内容 Chrome snippets 小脚本我们也可以在 Chrome 浏览器中创建一个脚本来执行，在开发者工具中点击 Sources 面板，选择 Snippets 选项卡，在导航器中右击鼠标，然后选择 Create new snippet 来新建一个脚本文件 点击 Create new snippet 后，会自动创建一个文件，你只需在右侧窗口输入以下代码，然后按 Ctrl+S 保存更改即可。 保存后，右击文件名，选择 “Run” 执行代码 设置断点debugger 关键字 JavaScript 输出 使用 window.alert() 弹出警告框。 使用 document.write() 方法将内容写到 HTML 文档中。 使用 innerHTML 写入到 HTML 元素。 使用 console.log() 写入到浏览器的控制台。 数据类型JavaScript 字面量 数字（Number）字面量 可以是整数或者是小数，或者是科学计数 (e)。 字符串（String）字面量 可以使用单引号或双引号: 表达式字面量 用于计算： 5 + 6 数组（Array）字面量 定义一个数组：[40, 100, 1, 5, 25, 10] 对象（Object）字面量 定义一个对象：{firstName:”John”, lastName:”Doe”, age:50, eyeColor:”blue”} 函数（Function）字面量 定义一个函数：function myFunction(a, b) { return a * b;} 变量 var 关键词来声明变量 当您声明新变量时，可以使用关键词 “new” 来声明其类型： 12345var carname=new String;var x= new Number;var y= new Boolean;var cars= new Array;var person= new Object; 变量的数据类型可以使用 typeof 操作符来查看： 值类型 (基本类型)： 字符串（String） var x &#x3D; “John”; 数字 (Number) var x &#x3D; 5; 布尔 (Boolean) var x&#x3D;true; 空（Null） 未定义（Undefined）\tvar x; Symbol。 引用数据类型（对象类型）： 对象 (Object) 123456789 var person = &#123; firstName: &quot;John&quot;, lastName : &quot;Doe&quot;, id : 5566, fullName : function() &#123; return this.firstName + &quot; &quot; + this.lastName; &#125;&#125;; 对象属性有两种寻址方式：name&#x3D;person.lastname;name&#x3D;person[“lastname”]; 数组 (Array) 1var cars=[&quot;Saab&quot;,&quot;Volvo&quot;,&quot;BMW&quot;]; var cars&#x3D;new Array();cars[0]&#x3D;”Saab”;cars[1]&#x3D;”Volvo”;cars[2]&#x3D;”BMW”;或者 (condensed array):var cars&#x3D;new Array(“Saab”,”Volvo”,”BMW”);或者 (literal array):var cars&#x3D;[“Saab”,”Volvo”,”BMW”]; 函数 (Function) 12345678 &lt;button onclick=&quot;myFunction(&#x27;Harry Potter&#x27;,&#x27;Wizard&#x27;)&quot;&gt;点击这里&lt;/button&gt;&lt;button onclick=&quot;myFunction(&#x27;Bob&#x27;,&#x27;Builder&#x27;)&quot;&gt;点击这里&lt;/button&gt;&lt;script&gt;function myFunction(name,job)&#123;\talert(&quot;Welcome &quot; + name + &quot;, the &quot; + job);&#125;&lt;/script&gt; 带有返回值的函数 123456 function myFunction()&#123; var x=5; return x;&#125;var myVar=myFunction(); 函数表达式 1var x = function (a, b) &#123;return a * b&#125;; 还有两个特殊的对象： 正则（RegExp） &#x2F;正则表达式主体&#x2F;修饰符 (可选) 1234 var patt = /runoob/i //字符串 var n = str.search(/Runoob/i); var patt = /e/; //正则patt.test(&quot;The best things in life are free!&quot;); &#x2F;runoob&#x2F;i 是一个正则表达式。runoob 是一个正则表达式主体 (用于检索)。i 是一个修饰符 (搜索不区分大小写)。 在 JavaScript 中，正则表达式通常用于两个字符串方法 : search() 和 replace()。 search() 方法用于检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串，并返回子串的起始位置。 replace() 方法用于在字符串中用一些字符串替换另一些字符串，或替换一个与正则表达式匹配的子串。 test() 方法用于检测一个字符串是否匹配某个模式，如果字符串中含有匹配的文本，则返回 true，否则返回 false。 exec() 方法用于检索字符串中的正则表达式的匹配。 日期（Date） 生存周期 局部变量 在 JavaScript 函数内部声明的变量（使用 var）是局部变量，所以只能在函数内部访问它。（该变量的作用域是局部的）。 全局变量函数外声明的变量是全局变量，网页上的所有脚本和函数都能访问它。 事件HTML 事件可以是浏览器行为，也可以是用户行为。 HTML 页面完成加载 HTML input 字段改变时 HTML 按钮被点击 |事件 |描述 | |:–: |:–: | |onchange |HTML 元素改变 | |onclick |用户点击 HTML 元素 | |onmouseover\t|鼠标指针移动到指定的元素上时发生 | |onmouseout |用户从一个 HTML 元素上移开鼠标时发生\t| |onkeydown |用户按下键盘按键 | |onload |浏览器已完成页面的加载 | 语句条件语句if-else 1234567if (condition1)&#123; 当条件 1 为 true 时执行的代码&#125;else if (condition2)&#123; 当条件 2 为 true 时执行的代码&#125;else&#123; 当条件 1 和 条件 2 都不为 true 时执行的代码&#125; switch 1234567891011switch(n)&#123; case 1: 执行代码块 1 break; case 2: 执行代码块 2 break; default: 与 case 1 和 case 2 不同时执行的代码&#125; 循环语句for 1234for (var i=0,len=cars.length; i&lt;len; i++)&#123; document.write(cars[i] + &quot;&lt;br&gt;&quot;);&#125; 123456var person=&#123;fname:&quot;Bill&quot;,lname:&quot;Gates&quot;,age:56&#125;; for (x in person) // x 为属性名&#123; txt=txt + person[x];&#125; while 1234while (条件)&#123; 需要执行的代码&#125; 12345do&#123; 需要执行的代码&#125;while (条件); 其他breakcontinuetypeof检测变量的数据类型nullnull 是一个只有一个值的特殊类型。表示一个空对象引用。undefinedundefined 是一个没有设置值的变量 null 和 undefined 的值相等，但类型不等 错误处理 try 语句测试代码块的错误。 catch 语句处理错误。 throw 语句创建自定义错误。 finally 语句在 try 和 catch 语句之后，无论是否有触发异常，该语句都会执行。 异步编程回调函数这段程序中的 setTimeout 就是一个消耗时间较长（3 秒）的过程，它的第一个参数是个回调函数，第二个参数是毫秒数，这个函数执行之后会产生一个子线程，子线程会等待 3 秒，然后执行回调函数 “print”，在命令行输出 “RUNOOB!”。 1234function print() &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;setTimeout(print, 3000); 123setTimeout(function () &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;, 3000); JavaScript Promise类JavaScript HTML DOMHTML DOM (文档对象模型)（Document Object Model） 通过 id 找到 HTML 元素 1var x=document.getElementById(&quot;intro&quot;); 通过标签名找到 HTML 元素 12var x=document.getElementById(&quot;main&quot;);var y=x.getElementsByTagName(&quot;p&quot;); 通过类名找到 HTML 元素 1var x=document.getElementsByClassName(&quot;intro&quot;); JavaScript HTML DOM - 改变 HTML内容 12345678&lt;html&gt;&lt;body&gt;&lt;p id=&quot;p1&quot;&gt;Hello World!&lt;/p&gt;&lt;script&gt;document.getElementById(&quot;p1&quot;).innerHTML=&quot;新文本!&quot;;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 属性 12345678&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;img id=&quot;image&quot; src=&quot;smiley.gif&quot;&gt;&lt;script&gt;document.getElementById(&quot;image&quot;).src=&quot;landscape.jpg&quot;;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; JavaScript HTML DOM - 改变 CSS12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p id=&quot;p1&quot;&gt;Hello World!&lt;/p&gt;&lt;p id=&quot;p2&quot;&gt;Hello World!&lt;/p&gt;&lt;script&gt;document.getElementById(&quot;p2&quot;).style.color=&quot;blue&quot;;document.getElementById(&quot;p2&quot;).style.fontFamily=&quot;Arial&quot;;document.getElementById(&quot;p2&quot;).style.fontSize=&quot;larger&quot;;&lt;/script&gt;&lt;p&gt;以上段落通过脚本修改。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; JavaScript HTML DOM 事件123&lt;script&gt;document.getElementById(&quot;myBtn&quot;).onclick=function()&#123;displayDate()&#125;;&lt;/script&gt; onload 和 onunload 事件会在用户进入或离开页面时被触发。 onchange 事件常结合对输入字段的验证来使用。 onmouseover 和 onmouseout 事件可用于在用户的鼠标移至 HTML 元素上方或移出元素时触发函数。 onmousedown, onmouseup 以及 onclick 构成了鼠标点击事件的所有部分。首先当点击鼠标按钮时，会触发 onmousedown 事件，当释放鼠标按钮时，会触发 onmouseup 事件，最后，当完成鼠标点击时，会触发 onclick 事件。 总结JavaScript：直接写入 HTML 输出流12document.write(&quot;&lt;h1&gt;这是一个标题&lt;/h1&gt;&quot;);document.write(&quot;&lt;p&gt;这是一个段落。&lt;/p&gt;&quot;); 您只能在 HTML 输出流中使用 document.write。 如果您在文档已加载后使用它（比如在函数中），会覆盖整个文档。 JavaScript：对事件的反应1&lt;button type=&quot;button&quot; onclick=&quot;alert(&#x27;欢迎!&#x27;)&quot;&gt;点我!&lt;/button&gt; JavaScript：改变 HTML 内容12x=document.getElementById(&quot;demo&quot;); //查找元素x.innerHTML=&quot;Hello JavaScript&quot;; //改变内容 DOM (Document Object Model)（文档对象模型）是用于访问 HTML 元素的正式 W3C 标准。 JavaScript：改变 HTML 图像123456789101112131415&lt;script&gt;function changeImage()&#123; element=document.getElementById(&#x27;myimage&#x27;) if (element.src.match(&quot;bulbon&quot;)) &#123; element.src=&quot;/images/pic_bulboff.gif&quot;; &#125; else &#123; element.src=&quot;/images/pic_bulbon.gif&quot;; &#125;&#125;&lt;/script&gt;&lt;img decoding=&quot;async&quot; loading=&quot;lazy&quot; id=&quot;myimage&quot; onclick=&quot;changeImage()&quot; src=&quot;/images/pic_bulboff.gif&quot; width=&quot;100&quot; height=&quot;180&quot;&gt; JavaScript：改变 HTML 样式12x=document.getElementById(&quot;demo&quot;) //找到元素 x.style.color=&quot;#ff0000&quot;; //改变样式 JavaScript：验证输入1234567891011&lt;input id=&quot;demo&quot; type=&quot;text&quot;&gt;&lt;script&gt;function myFunction()&#123;\tvar x=document.getElementById(&quot;demo&quot;).value;\tif(isNaN(x)||x.replace(/(^\\s*)|(\\s*$)/g,&quot;&quot;)==&quot;&quot;)&#123; alert(&quot;不是数字&quot;);\t&#125;&#125;&lt;/script&gt;&lt;button type=&quot;button&quot; onclick=&quot;myFunction()&quot;&gt;点击这里&lt;/button&gt;","categories":["语言"]},{"title":"Ubuntu22.04 jammy更换源","path":"/2024/05/22/平台Platform-Linux-Ubuntu-Ubuntu22-04-jammy更换源/","content":"源文件所在位置备份源文件 /etc/apt/sources.list Ubuntu22.04 jammy 源清华源# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse 阿里云源deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse 中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse 网易 163 源deb http://mirrors.163.com/ubuntu/ jammy main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ jammy-security main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ jammy-updates main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ jammy-proposed main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ jammy-backports main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ jammy main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ jammy-security main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ jammy-updates main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ jammy-proposed main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ jammy-backports main restricted universe multiverse","categories":["平台Platform","Linux","Ubuntu"]},{"title":"虚拟机磁盘收缩","path":"/2024/05/22/平台Platform-VMware-虚拟机磁盘收缩/","content":"1. 删除快照打开 VMware，选择工具栏的虚拟机，选择快照，选择快照管理器，删除不用的快照 2.1 删除缓存文件打开虚拟机，删除虚拟机中的缓存文件目录： /home/xxxx/.cache/vmware/drag_and_drop df -h 指令可查找到磁盘真实占据的磁盘空间 2.2 压缩磁盘空间当虚拟机安装盘所剩余的空间大于.vmdk 文件的大小时，强烈推荐使用以下方式 在你的终端输入 sudo /usr/bin/vmware-toolbox-cmd disk list 一般会有 &quot;/&quot; 目录 再输入 sudo /usr/bin/vmware-toolbox-cmd disk shrink / 即压缩根目录 &quot;/&quot; 3. 导出 OVF 重新建立新 vmdk有时候删除虚拟机快照出现错误，但快照图标已消失，导致无法再次删除，造成文件残留，就这样越堆越多，无法清理。 优点是可以释放大量空间，缺点是只能保留 VMware 虚拟机当前的状态和文件，丢失其他快照（可以按需先转到某个快照再导出 OVF，这样就可以保留快照时的状态了。同样，会丢失其他状态）。步骤如下： 点击要清理的虚拟机，然后左上角点击文件，导出为 OVF（只存了虚拟机当前的状态，大概有十几个 G），存到其他空闲的磁盘下。 将上述步骤导出的 ovf 再部署出来，看看虚拟机是否正常。 如果正常可用，就可以把虚拟机原来占用的磁盘清空了，快速释放大量空间。","categories":["平台Platform","VMware"]},{"title":"pythonWeb部署方案","path":"/2024/05/22/语言-Python-pythonWeb部署方案/","content":"搭建开发环境首先，确认系统安装的 Python 版本是 3.7.x： 12$ python3 --versionPython 3.7.0 然后，用 pip 安装开发 Web App 需要的第三方库： 异步框架 aiohttp： 1$pip3 install aiohttp 前端模板引擎 jinja2： 1$ pip3 install jinja2 MySQL 5.x 数据库，从 官方网站 下载并安装，安装完毕后，请务必牢记 root 口令。为避免遗忘口令，建议直接把 root 口令设置为 password； MySQL 的 Python 异步驱动程序 aiomysql： 1$ pip3 install aiomysql 项目结构选择一个工作目录，然后，我们建立如下的目录结构： 1234567891011121314151617awesome-python3-webapp/ &lt;-- 根目录|+- backup/ &lt;-- 备份目录|+- conf/ &lt;-- 配置文件|+- dist/ &lt;-- 打包目录|+- www/ &lt;-- Web目录，存放.py文件| || +- static/ &lt;-- 存放静态文件| || +- templates/ &lt;-- 存放模板文件|+- ios/ &lt;-- 存放iOS App工程|+- LICENSE &lt;-- 代码LICENSE 创建好项目的目录结构后，建议同时建立 git 仓库并同步至 GitHub，保证代码修改的安全。 Web 骨架由于我们的 Web App 建立在 asyncio 的基础上，因此用 aiohttp 写一个基本的 app.py： 12345678910111213141516import logging; logging.basicConfig(level=logging.INFO)import asyncio, os, json, timefrom datetime import datetimefrom aiohttp import webdef index(request): return web.Response(body=b&#x27;&lt;h1&gt;Awesome&lt;/h1&gt;&#x27;)@asyncio.coroutinedef init(loop): app = web.Application(loop=loop) app.router.add_route(&#x27;GET&#x27;, &#x27;/&#x27;, index) srv = yield from loop.create_server(app.make_handler(), &#x27;127.0.0.1&#x27;, 9000) logging.info(&#x27;server started at http://127.0.0.1:9000...&#x27;) return srvloop = asyncio.get_event_loop()loop.run_until_complete(init(loop))loop.run_forever() 运行 python app.py，Web App 将在 9000 端口监听 HTTP 请求，并且对首页 / 进行响应： 12$ python3 app.pyINFO:root:server started at http://127.0.0.1:9000... 这里我们简单地返回一个 Awesome 字符串，在浏览器中可以看到效果 这说明我们的 Web App 骨架已经搭好了，可以进一步往里面添加更多的东西。 ORMORM 全称是：Object Relational Mapping(对象关系映射)，其主要作用是在编程中，把面向对象的概念跟数据库中表的概念对应起来。举例来说就是，我定义一个对象，那就对应着一张表，这个对象的实例，就对应着表中的一条记录。 在一个 Web App 中，所有数据，包括用户信息、发布的日志、评论等，都存储在数据库中。在 awesome-python3-webapp 中，我们选择 MySQL 作为数据库。 Web App 里面有很多地方都要访问数据库。访问数据库需要创建数据库连接、游标对象，然后执行 SQL 语句，最后处理异常，清理资源。这些访问数据库的代码如果分散到各个函数中，势必无法维护，也不利于代码复用。 所以，我们要首先把常用的 SELECT、INSERT、UPDATE 和 DELETE 操作用函数封装起来。 由于 Web 框架使用了基于 asyncio 的 aiohttp，这是基于协程的异步模型。在协程中，不能调用普通的同步 IO 操作，因为所有用户都是由一个线程服务的，协程的执行速度必须非常快，才能处理大量用户的请求。而耗时的 IO 操作不能在协程中以同步的方式调用，否则，等待一个 IO 操作时，系统无法响应任何其他用户。 这就是异步编程的一个原则：一旦决定使用异步，则系统每一层都必须是异步，“开弓没有回头箭”。 幸运的是 aiomysql 为 MySQL 数据库提供了异步 IO 的驱动。 创建连接池我们需要创建一个全局的连接池，每个 HTTP 请求都可以从连接池中直接获取数据库连接。使用连接池的好处是不必频繁地打开和关闭数据库连接，而是能复用就尽量复用。 连接池由全局变量 __pool 存储，缺省情况下将编码设置为 utf8，自动提交事务： 12345678910111213141516@asyncio.coroutinedef create_pool(loop, **kw): logging.info(&#x27;create database connection pool...&#x27;) global __pool __pool = yield from aiomysql.create_pool( host=kw.get(&#x27;host&#x27;, &#x27;localhost&#x27;), port=kw.get(&#x27;port&#x27;, 3306), user=kw[&#x27;user&#x27;], password=kw[&#x27;password&#x27;], db=kw[&#x27;db&#x27;], charset=kw.get(&#x27;charset&#x27;, &#x27;utf8&#x27;), autocommit=kw.get(&#x27;autocommit&#x27;, True), maxsize=kw.get(&#x27;maxsize&#x27;, 10), minsize=kw.get(&#x27;minsize&#x27;, 1), loop=loop ) Select要执行 SELECT 语句，我们用 select 函数执行，需要传入 SQL 语句和 SQL 参数： 1234567891011121314@asyncio.coroutinedef select(sql, args, size=None): log(sql, args) global __pool with (yield from __pool) as conn: cur = yield from conn.cursor(aiomysql.DictCursor) yield from cur.execute(sql.replace(&#x27;?&#x27;, &#x27;%s&#x27;), args or ()) if size: rs = yield from cur.fetchmany(size) else: rs = yield from cur.fetchall() yield from cur.close() logging.info(&#x27;rows returned: %s&#x27; % len(rs)) return rs SQL 语句的占位符是 ?，而 MySQL 的占位符是 %s，select() 函数在内部自动替换。注意要始终坚持使用带参数的 SQL，而不是自己拼接 SQL 字符串，这样可以防止 SQL 注入攻击。 注意到 yield from 将调用一个子协程（也就是在一个协程中调用另一个协程）并直接获得子协程的返回结果。 如果传入 size 参数，就通过 fetchmany() 获取最多指定数量的记录，否则，通过 fetchall() 获取所有记录。 Insert, Update, Delete要执行 INSERT、UPDATE、DELETE 语句，可以定义一个通用的 execute() 函数，因为这 3 种 SQL 的执行都需要相同的参数，以及返回一个整数表示影响的行数： 123456789101112@asyncio.coroutinedef execute(sql, args): log(sql) with (yield from __pool) as conn: try: cur = yield from conn.cursor() yield from cur.execute(sql.replace(&#x27;?&#x27;, &#x27;%s&#x27;), args) affected = cur.rowcount yield from cur.close() except BaseException as e: raise return affected execute() 函数和 select() 函数所不同的是，cursor 对象不返回结果集，而是通过 rowcount 返回结果数。 ORM有了基本的 select() 和 execute() 函数，我们就可以开始编写一个简单的 ORM 了。 设计 ORM 需要从上层调用者角度来设计。 我们先考虑如何定义一个 User 对象，然后把数据库表 users 和它关联起来。 12345from orm import Model, StringField, IntegerFieldclass User(Model): __table__ = &#x27;users&#x27; id = IntegerField(primary_key=True) name = StringField() 注意到定义在 User 类中的 __table__、id 和 name 是类的属性，不是实例的属性。所以，在类级别上定义的属性用来描述 User 对象和表的映射关系，而实例属性必须通过 __init__() 方法去初始化，所以两者互不干扰： 123456# 创建实例:user = User(id=123, name=&#x27;Michael&#x27;)# 存入数据库:user.insert()# 查询所有User对象:users = User.findAll() 定义 Model首先要定义的是所有 ORM 映射的基类 Model： 123456789101112131415161718192021class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&#x27;Model&#x27; object has no attribute &#x27;%s&#x27;&quot; % key) def __setattr__(self, key, value): self[key] = value def getValue(self, key): return getattr(self, key, None) def getValueOrDefault(self, key): value = getattr(self, key, None) if value is None: field = self.__mappings__[key] if field.default is not None: value = field.default() if callable(field.default) else field.default logging.debug(&#x27;using default value for %s: %s&#x27; % (key, str(value))) setattr(self, key, value) return value Model 从 dict 继承，所以具备所有 dict 的功能，同时又实现了特殊方法 __getattr__() 和 __setattr__()，因此又可以像引用普通字段那样写： 1234&gt;&gt;&gt; user[&#x27;id&#x27;]123&gt;&gt;&gt; user.id123 以及 Field 和各种 Field 子类： 12345678class Field(object): def __init__(self, name, column_type, primary_key, default): self.name = name self.column_type = column_type self.primary_key = primary_key self.default = default def __str__(self): return &#x27;&lt;%s, %s:%s&gt;&#x27; % (self.__class__.__name__, self.column_type, self.name) 映射 varchar 的 StringField： 123class StringField(Field): def __init__(self, name=None, primary_key=False, default=None, ddl=&#x27;varchar(100)&#x27;): super().__init__(name, ddl, primary_key, default) 注意到 Model 只是一个基类，如何将具体的子类如 User 的映射信息读取出来呢？答案就是通过 metaclass：ModelMetaclass： 1234567891011121314151617181920212223242526272829303132333435363738class ModelMetaclass(type): def __new__(cls, name, bases, attrs): # 排除Model类本身: if name==&#x27;Model&#x27;: return type.__new__(cls, name, bases, attrs) # 获取table名称: tableName = attrs.get(&#x27;__table__&#x27;, None) or name logging.info(&#x27;found model: %s (table: %s)&#x27; % (name, tableName)) # 获取所有的Field和主键名: mappings = dict() fields = [] primaryKey = None for k, v in attrs.items(): if isinstance(v, Field): logging.info(&#x27; found mapping: %s ==&gt; %s&#x27; % (k, v)) mappings[k] = v if v.primary_key: # 找到主键: if primaryKey: raise RuntimeError(&#x27;Duplicate primary key for field: %s&#x27; % k) primaryKey = k else: fields.append(k) if not primaryKey: raise RuntimeError(&#x27;Primary key not found.&#x27;) for k in mappings.keys(): attrs.pop(k) escaped_fields = list(map(lambda f: &#x27;`%s`&#x27; % f, fields)) attrs[&#x27;__mappings__&#x27;] = mappings # 保存属性和列的映射关系 attrs[&#x27;__table__&#x27;] = tableName attrs[&#x27;__primary_key__&#x27;] = primaryKey # 主键属性名 attrs[&#x27;__fields__&#x27;] = fields # 除主键外的属性名 # 构造默认的SELECT, INSERT, UPDATE和DELETE语句: attrs[&#x27;__select__&#x27;] = &#x27;select `%s`, %s from `%s`&#x27; % (primaryKey, &#x27;, &#x27;.join(escaped_fields), tableName) attrs[&#x27;__insert__&#x27;] = &#x27;insert into `%s` (%s, `%s`) values (%s)&#x27; % (tableName, &#x27;, &#x27;.join(escaped_fields), primaryKey, create_args_string(len(escaped_fields) + 1)) attrs[&#x27;__update__&#x27;] = &#x27;update `%s` set %s where `%s`=?&#x27; % (tableName, &#x27;, &#x27;.join(map(lambda f: &#x27;`%s`=?&#x27; % (mappings.get(f).name or f), fields)), primaryKey) attrs[&#x27;__delete__&#x27;] = &#x27;delete from `%s` where `%s`=?&#x27; % (tableName, primaryKey) return type.__new__(cls, name, bases, attrs) 这样，任何继承自 Model 的类（比如 User），会自动通过 ModelMetaclass 扫描映射关系，并存储到自身的类属性如 __table__、__mappings__ 中。 然后，我们往 Model 类添加 class 方法，就可以让所有子类调用 class 方法： 12345678910class Model(dict): ... @classmethod @asyncio.coroutine def find(cls, pk): &#x27; find object by primary key. &#x27; rs = yield from select(&#x27;%s where `%s`=?&#x27; % (cls.__select__, cls.__primary_key__), [pk], 1) if len(rs) == 0: return None return cls(**rs[0]) User 类现在就可以通过类方法实现主键查找： 1user = yield from User.find(&#x27;123&#x27;) 往 Model 类添加实例方法，就可以让所有子类调用实例方法： 123456789class Model(dict): ... @asyncio.coroutine def save(self): args = list(map(self.getValueOrDefault, self.__fields__)) args.append(self.getValueOrDefault(self.__primary_key__)) rows = yield from execute(self.__insert__, args) if rows != 1: logging.warn(&#x27;failed to insert record: affected rows: %s&#x27; % rows) 这样，就可以把一个 User 实例存入数据库： 12user = User(id=123, name=&#x27;Michael&#x27;)yield from user.save() 最后一步是完善 ORM，对于查找，我们可以实现以下方法： findAll() - 根据 WHERE 条件查找； findNumber() - 根据 WHERE 条件查找，但返回的是整数，适用于 select count(*) 类型的 SQL。以及 update() 和 remove() 方法。所有这些方法都必须用 @asyncio.coroutine 装饰，变成一个协程。调用时需要特别注意： 1user.save() 没有任何效果，因为调用 save() 仅仅是创建了一个协程，并没有执行它。一定要用： 1yield from user.save() 才真正执行了 INSERT 操作。 编写 Model有了 ORM，我们就可以把 Web App 需要的 3 个表用 Model 表示出来： 1234567891011121314151617181920212223242526272829303132import time, uuidfrom orm import Model, StringField, BooleanField, FloatField, TextFielddef next_id(): return &#x27;%015d%s000&#x27; % (int(time.time() * 1000), uuid.uuid4().hex)class User(Model): __table__ = &#x27;users&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) email = StringField(ddl=&#x27;varchar(50)&#x27;) passwd = StringField(ddl=&#x27;varchar(50)&#x27;) admin = BooleanField() name = StringField(ddl=&#x27;varchar(50)&#x27;) image = StringField(ddl=&#x27;varchar(500)&#x27;) created_at = FloatField(default=time.time)class Blog(Model): __table__ = &#x27;blogs&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) user_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_name = StringField(ddl=&#x27;varchar(50)&#x27;) user_image = StringField(ddl=&#x27;varchar(500)&#x27;) name = StringField(ddl=&#x27;varchar(50)&#x27;) summary = StringField(ddl=&#x27;varchar(200)&#x27;) content = TextField() created_at = FloatField(default=time.time)class Comment(Model): __table__ = &#x27;comments&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) blog_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_name = StringField(ddl=&#x27;varchar(50)&#x27;) user_image = StringField(ddl=&#x27;varchar(500)&#x27;) content = TextField() created_at = FloatField(default=time.time) 在编写 ORM 时，给一个 Field 增加一个 default 参数可以让 ORM 自己填入缺省值，非常方便。并且，缺省值可以作为函数对象传入，在调用 save() 时自动计算。 例如，主键 id 的缺省值是函数 next_id，创建时间 created_at 的缺省值是函数 time.time，可以自动设置当前日期和时间。 日期和时间用 float 类型存储在数据库中，而不是 datetime 类型，这么做的好处是不必关心数据库的时区以及时区转换问题，排序非常简单，显示的时候，只需要做一个 float 到 str 的转换，也非常容易。 初始化数据库表如果表的数量很少，可以手写创建表的 SQL 脚本： 12345678910111213141516171819202122232425262728293031323334353637383940-- schema.sqldrop database if exists awesome;create database awesome;use awesome;grant select, insert, update, delete on awesome.* to &#x27;www-data&#x27;@&#x27;localhost&#x27; identified by &#x27;www-data&#x27;;create table users ( `id` varchar(50) not null, `email` varchar(50) not null, `passwd` varchar(50) not null, `admin` bool not null, `name` varchar(50) not null, `image` varchar(500) not null, `created_at` real not null, unique key `idx_email` (`email`), key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table blogs ( `id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `name` varchar(50) not null, `summary` varchar(200) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table comments ( `id` varchar(50) not null, `blog_id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8; 如果表的数量很多，可以从 Model 对象直接通过脚本自动生成 SQL 脚本，使用更简单。 把 SQL 脚本放到 MySQL 命令行里执行： 1$ mysql -u root -p &lt; schema.sql 我们就完成了数据库表的初始化。 编写数据访问代码接下来，就可以真正开始编写代码操作对象了。比如，对于 User 对象，我们就可以做如下操作： 12345678import ormfrom models import User, Blog, Commentdef test(): yield from orm.create_pool(user=&#x27;www-data&#x27;, password=&#x27;www-data&#x27;, database=&#x27;awesome&#x27;) u = User(name=&#x27;Test&#x27;, email=&#x27;test@example.com&#x27;, passwd=&#x27;1234567890&#x27;, image=&#x27;about:blank&#x27;) yield from u.save()for x in test(): pass 可以在 MySQL 客户端命令行查询，看看数据是不是正常存储到 MySQL 里面了。 Web 框架在正式开始 Web 开发前，我们需要编写一个 Web 框架。 aiohttp 已经是一个 Web 框架了，为什么我们还需要自己封装一个？ 原因是从使用者的角度来说，aiohttp 相对比较底层，编写一个 URL 的处理函数需要这么几步： 第一步，编写一个用 @asyncio.coroutine 装饰的函数： 123@asyncio.coroutinedef handle_url_xxx(request): pass 第二步，传入的参数需要自己从 request 中获取： 12url_param = request.match_info[&#x27;key&#x27;]query_params = parse_qs(request.query_string) 最后，需要自己构造 Response 对象： 12text = render(&#x27;template&#x27;, data)return web.Response(text.encode(&#x27;utf-8&#x27;)) 这些重复的工作可以由框架完成。例如，处理带参数的 URL/blog/&#123;id&#125; 可以这么写： 123@get(&#x27;/blog/&#123;id&#125;&#x27;)def get_blog(id): pass 处理 query_string 参数可以通过关键字参数 **kw 或者命名关键字参数接收： 123@get(&#x27;/api/comments&#x27;)def api_comments(*, page=&#x27;1&#x27;): pass 对于函数的返回值，不一定是 web.Response 对象，可以是 str、bytes 或 dict。 如果希望渲染模板，我们可以这么返回一个 dict： 1234return &#123; &#x27;__template__&#x27;: &#x27;index.html&#x27;, &#x27;data&#x27;: &#x27;...&#x27;&#125; 因此，Web 框架的设计是完全从使用者出发，目的是让使用者编写尽可能少的代码。 编写简单的函数而非引入 request 和 web.Response 还有一个额外的好处，就是可以单独测试，否则，需要模拟一个 request 才能测试。 @get 和@post要把一个函数映射为一个 URL 处理函数，我们先定义 @get()： 123456789101112def get(path): &#x27;&#x27;&#x27; Define decorator @get(&#x27;/path&#x27;) &#x27;&#x27;&#x27; def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): return func(*args, **kw) wrapper.__method__ = &#x27;GET&#x27; wrapper.__route__ = path return wrapper return decorator 这样，一个函数通过 @get() 的装饰就附带了 URL 信息。 @post 与 @get 定义类似。 定义 RequestHandlerURL 处理函数不一定是一个 coroutine，因此我们用 RequestHandler() 来封装一个 URL 处理函数。 RequestHandler 是一个类，由于定义了 __call__() 方法，因此可以将其实例视为函数。 RequestHandler 目的就是从 URL 函数中分析其需要接收的参数，从 request 中获取必要的参数，调用 URL 函数，然后把结果转换为 web.Response 对象，这样，就完全符合 aiohttp 框架的要求： 12345678910class RequestHandler(object): def __init__(self, app, fn): self._app = app self._func = fn ... @asyncio.coroutine def __call__(self, request): kw = ... 获取参数 r = yield from self._func(**kw) return r 再编写一个 add_route 函数，用来注册一个 URL 处理函数： 123456789def add_route(app, fn): method = getattr(fn, &#x27;__method__&#x27;, None) path = getattr(fn, &#x27;__route__&#x27;, None) if path is None or method is None: raise ValueError(&#x27;@get or @post not defined in %s.&#x27; % str(fn)) if not asyncio.iscoroutinefunction(fn) and not inspect.isgeneratorfunction(fn): fn = asyncio.coroutine(fn) logging.info(&#x27;add route %s %s =&gt; %s(%s)&#x27; % (method, path, fn.__name__, &#x27;, &#x27;.join(inspect.signature(fn).parameters.keys()))) app.router.add_route(method, path, RequestHandler(app, fn)) 最后一步，把很多次 add_route() 注册的调用： 1234add_route(app, handles.index)add_route(app, handles.blog)add_route(app, handles.create_comment)... 变成自动扫描： 12# 自动把handler模块的所有符合条件的函数注册了:add_routes(app, &#x27;handlers&#x27;) add_routes() 定义如下： 12345678910111213141516def add_routes(app, module_name): n = module_name.rfind(&#x27;.&#x27;) if n == (-1): mod = __import__(module_name, globals(), locals()) else: name = module_name[n+1:] mod = getattr(__import__(module_name[:n], globals(), locals(), [name]), name) for attr in dir(mod): if attr.startswith(&#x27;_&#x27;): continue fn = getattr(mod, attr) if callable(fn): method = getattr(fn, &#x27;__method__&#x27;, None) path = getattr(fn, &#x27;__route__&#x27;, None) if method and path: add_route(app, fn) 最后，在 app.py 中加入 middleware、jinja2 模板和自注册的支持： 123456app = web.Application(loop=loop, middlewares=[ logger_factory, response_factory])init_jinja2(app, filters=dict(datetime=datetime_filter))add_routes(app, &#x27;handlers&#x27;)add_static(app) middlewaremiddleware 是一种拦截器，一个 URL 在被某个函数处理前，可以经过一系列的 middleware 的处理。 一个 middleware 可以改变 URL 的输入、输出，甚至可以决定不继续处理而直接返回。middleware 的用处就在于把通用的功能从每个 URL 处理函数中拿出来，集中放到一个地方。例如，一个记录 URL 日志的 logger 可以简单定义如下： 123456789@asyncio.coroutinedef logger_factory(app, handler): @asyncio.coroutine def logger(request): # 记录日志: logging.info(&#x27;Request: %s %s&#x27; % (request.method, request.path)) # 继续处理请求: return (yield from handler(request)) return logger 而 response 这个 middleware 把返回值转换为 web.Response 对象再返回，以保证满足 aiohttp 的要求： 123456789101112131415161718@asyncio.coroutinedef response_factory(app, handler): @asyncio.coroutine def response(request): # 结果: r = yield from handler(request) if isinstance(r, web.StreamResponse): return r if isinstance(r, bytes): resp = web.Response(body=r) resp.content_type = &#x27;application/octet-stream&#x27; return resp if isinstance(r, str): resp = web.Response(body=r.encode(&#x27;utf-8&#x27;)) resp.content_type = &#x27;text/html;charset=utf-8&#x27; return resp if isinstance(r, dict): ... 有了这些基础设施，我们就可以专注地往 handlers 模块不断添加 URL 处理函数了，可以极大地提高开发效率。 配置文件有了 Web 框架和 ORM 框架，我们就可以开始装配 App 了。 通常，一个 Web App 在运行时都需要读取配置文件，比如数据库的用户名、口令等，在不同的环境中运行时，Web App 可以通过读取不同的配置文件来获得正确的配置。 由于 Python 本身语法简单，完全可以直接用 Python 源代码来实现配置，而不需要再解析一个单独的 .properties 或者 .yaml 等配置文件。 默认的配置文件应该完全符合本地开发环境，这样，无需任何设置，就可以立刻启动服务器。 我们把默认的配置文件命名为 config_default.py： 12345678910111213# config_default.pyconfigs = &#123; &#x27;db&#x27;: &#123; &#x27;host&#x27;: &#x27;127.0.0.1&#x27;, &#x27;port&#x27;: 3306, &#x27;user&#x27;: &#x27;www-data&#x27;, &#x27;password&#x27;: &#x27;www-data&#x27;, &#x27;database&#x27;: &#x27;awesome&#x27; &#125;, &#x27;session&#x27;: &#123; &#x27;secret&#x27;: &#x27;AwEsOmE&#x27; &#125;&#125; 上述配置文件简单明了。但是，如果要部署到服务器时，通常需要修改数据库的 host 等信息，直接修改 config_default.py 不是一个好办法，更好的方法是编写一个 config_override.py，用来覆盖某些默认设置： 123456# config_override.pyconfigs = &#123; &#x27;db&#x27;: &#123; &#x27;host&#x27;: &#x27;192.168.0.100&#x27; &#125;&#125; 把 config_default.py 作为开发环境的标准配置，把 config_override.py 作为生产环境的标准配置，我们就可以既方便地在本地开发，又可以随时把应用部署到服务器上。 应用程序读取配置文件需要优先从 config_override.py 读取。为了简化读取配置文件，可以把所有配置读取到统一的 config.py 中： 1234567# config.pyconfigs = config_default.configstry: import config_override configs = merge(configs, config_override.configs)except ImportError: pass 这样，我们就完成了 App 的配置。 MVC现在，ORM 框架、Web 框架和配置都已就绪，我们可以开始编写一个最简单的 MVC，把它们全部启动起来。 通过 Web 框架的 @get 和 ORM 框架的 Model 支持，可以很容易地编写一个处理首页 URL 的函数： 1234567@get(&#x27;/&#x27;)def index(request): users = yield from User.findAll() return &#123; &#x27;__template__&#x27;: &#x27;test.html&#x27;, &#x27;users&#x27;: users &#125; &#39;__template__&#39; 指定的模板文件是 test.html，其他参数是传递给模板的数据，所以我们在模板的根目录 templates 下创建 test.html： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Test users - Awesome Python Webapp&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;All users&lt;/h1&gt; &#123;% for u in users %&#125; &lt;p&gt;&#123;&#123; u.name &#125;&#125; / &#123;&#123; u.email &#125;&#125;&lt;/p&gt; &#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 接下来，如果一切顺利，可以用命令行启动 Web 服务器： 1$ python3 app.py 然后，在浏览器中访问 http://localhost:9000/。 如果数据库的 users 表什么内容也没有，你就无法在浏览器中看到循环输出的内容。可以自己在 MySQL 的命令行里给 users 表添加几条记录，然后再访问 构建前端对于复杂的 HTML 前端页面来说，我们需要一套基础的 CSS 框架来完成页面布局和基本样式。另外，jQuery 作为操作 DOM 的 JavaScript 库也必不可少。 从零开始写 CSS 不如直接从一个已有的功能完善的 CSS 框架开始。有很多 CSS 框架可供选择。我们这次选择 uikit 这个强大的 CSS 框架。它具备完善的响应式布局，漂亮的 UI，以及丰富的 HTML 组件，让我们能轻松设计出美观而简洁的页面。 可以从 uikit首页 下载打包的资源文件。 所有的静态资源文件我们统一放到 www/static 目录下，并按照类别归类： 1234567891011121314151617181920static/+- css/| +- addons/| | +- uikit.addons.min.css| | +- uikit.almost-flat.addons.min.css| | +- uikit.gradient.addons.min.css| +- awesome.css| +- uikit.almost-flat.addons.min.css| +- uikit.gradient.addons.min.css| +- uikit.min.css+- fonts/| +- fontawesome-webfont.eot| +- fontawesome-webfont.ttf| +- fontawesome-webfont.woff| +- FontAwesome.otf+- js/ +- awesome.js +- html5.js +- jquery.min.js +- uikit.min.js 由于前端页面肯定不止首页一个页面，每个页面都有相同的页眉和页脚。如果每个页面都是独立的 HTML 模板，那么我们在修改页眉和页脚的时候，就需要把每个模板都改一遍，这显然是没有效率的。 常见的模板引擎已经考虑到了页面上重复的 HTML 部分的复用问题。有的模板通过 include 把页面拆成三部分： 12345&lt;html&gt; &lt;% include file=&quot;inc_header.html&quot; %&gt; &lt;% include file=&quot;index_body.html&quot; %&gt; &lt;% include file=&quot;inc_footer.html&quot; %&gt;&lt;/html&gt; 这样，相同的部分 inc_header.html 和 inc_footer.html 就可以共享。 但是 include 方法不利于页面整体结构的维护。jinjia2 的模板还有另一种“继承”方式，实现模板的复用更简单。 “继承”模板的方式是通过编写一个“父模板”，在父模板中定义一些可替换的 block（块）。然后，编写多个“子模板”，每个子模板都可以只替换父模板定义的 block。比如，定义一个最简单的父模板： 123456789&lt;!-- base.html --&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;&#123;% block title%&#125; 这里定义了一个名为title的block &#123;% endblock %&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &#123;% block content %&#125; 这里定义了一个名为content的block &#123;% endblock %&#125; &lt;/body&gt;&lt;/html&gt; 对于子模板 a.html，只需要把父模板的 title 和 content 替换掉： 123456&#123;% extends &#x27;base.html&#x27; %&#125;&#123;% block title %&#125; A &#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt;Chapter A&lt;/h1&gt; &lt;p&gt;blablabla...&lt;/p&gt;&#123;% endblock %&#125; 对于子模板 b.html，如法炮制： 123456789&#123;% extends &#x27;base.html&#x27; %&#125;&#123;% block title %&#125; B &#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt;Chapter B&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;list 1&lt;/li&gt; &lt;li&gt;list 2&lt;/li&gt; &lt;/ul&gt;&#123;% endblock %&#125; 这样，一旦定义好父模板的整体布局和 CSS 样式，编写子模板就会非常容易。 让我们通过 uikit 这个 CSS 框架来完成父模板 __base__.html 的编写： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &#123;% block meta %&#125;&lt;!-- block meta --&gt;&#123;% endblock %&#125; &lt;title&gt;&#123;% block title %&#125; ? &#123;% endblock %&#125; - Awesome Python Webapp&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/uikit.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/uikit.gradient.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/awesome.css&quot; /&gt; &lt;script src=&quot;/static/js/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/md5.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/uikit.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/awesome.js&quot;&gt;&lt;/script&gt; &#123;% block beforehead %&#125;&lt;!-- before head --&gt;&#123;% endblock %&#125;&lt;/head&gt;&lt;body&gt; &lt;nav class=&quot;uk-navbar uk-navbar-attached uk-margin-bottom&quot;&gt; &lt;div class=&quot;uk-container uk-container-center&quot;&gt; &lt;a href=&quot;/&quot; class=&quot;uk-navbar-brand&quot;&gt;Awesome&lt;/a&gt; &lt;ul class=&quot;uk-navbar-nav&quot;&gt; &lt;li data-url=&quot;blogs&quot;&gt;&lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;uk-icon-home&quot;&gt;&lt;/i&gt; 日志&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-book&quot;&gt;&lt;/i&gt; 教程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-code&quot;&gt;&lt;/i&gt; 源码&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&quot;uk-navbar-flip&quot;&gt; &lt;ul class=&quot;uk-navbar-nav&quot;&gt; &#123;% if user %&#125; &lt;li class=&quot;uk-parent&quot; data-uk-dropdown&gt; &lt;a href=&quot;#0&quot;&gt;&lt;i class=&quot;uk-icon-user&quot;&gt;&lt;/i&gt; &#123;&#123; user.name &#125;&#125;&lt;/a&gt; &lt;div class=&quot;uk-dropdown uk-dropdown-navbar&quot;&gt; &lt;ul class=&quot;uk-nav uk-nav-navbar&quot;&gt; &lt;li&gt;&lt;a href=&quot;/signout&quot;&gt;&lt;i class=&quot;uk-icon-sign-out&quot;&gt;&lt;/i&gt; 登出&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &#123;% else %&#125; &lt;li&gt;&lt;a href=&quot;/signin&quot;&gt;&lt;i class=&quot;uk-icon-sign-in&quot;&gt;&lt;/i&gt; 登陆&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/register&quot;&gt;&lt;i class=&quot;uk-icon-edit&quot;&gt;&lt;/i&gt; 注册&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/nav&gt; &lt;div class=&quot;uk-container uk-container-center&quot;&gt; &lt;div class=&quot;uk-grid&quot;&gt; &lt;!-- content --&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;!-- // content --&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-margin-large-top&quot; style=&quot;background-color:#eee; border-top:1px solid #ccc;&quot;&gt; &lt;div class=&quot;uk-container uk-container-center uk-text-center&quot;&gt; &lt;div class=&quot;uk-panel uk-margin-top uk-margin-bottom&quot;&gt; &lt;p&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-weibo&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-github&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-linkedin-square&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-twitter&quot;&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Powered by &lt;a href=&quot;#&quot;&gt;Awesome Python Webapp&lt;/a&gt;. Copyright &amp;copy; 2014. [&lt;a href=&quot;/manage/&quot; target=&quot;_blank&quot;&gt;Manage&lt;/a&gt;]&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://www.liaoxuefeng.com/&quot; target=&quot;_blank&quot;&gt;www.liaoxuefeng.com&lt;/a&gt;. All rights reserved.&lt;/p&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-html5&quot; style=&quot;font-size:64px; color: #444;&quot;&gt;&lt;/i&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; __base__.html 定义的几个 block 作用如下： 用于子页面定义一些 meta，例如 rss feed： 1&#123;% block meta %&#125; ... &#123;% endblock %&#125; 覆盖页面的标题： 1&#123;% block title %&#125; ... &#123;% endblock %&#125; 子页面可以在 &lt;head&gt; 标签关闭前插入 JavaScript 代码： 1&#123;% block beforehead %&#125; ... &#123;% endblock %&#125; 子页面的 content 布局和内容： 123&#123;% block content %&#125; ...&#123;% endblock %&#125; 我们把首页改造一下，从 __base__.html 继承一个 blogs.html： 1234567891011121314151617181920212223242526&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;日志&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-medium-3-4&quot;&gt; &#123;% for blog in blogs %&#125; &lt;article class=&quot;uk-article&quot;&gt; &lt;h2&gt;&lt;a href=&quot;/blog/&#123;&#123; blog.id &#125;&#125;&quot;&gt;&#123;&#123; blog.name &#125;&#125;&lt;/a&gt;&lt;/h2&gt; &lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; blog.summary &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/blog/&#123;&#123; blog.id &#125;&#125;&quot;&gt;继续阅读 &lt;i class=&quot;uk-icon-angle-double-right&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt; &lt;/article&gt; &lt;hr class=&quot;uk-article-divider&quot;&gt; &#123;% endfor %&#125; &lt;/div&gt; &lt;div class=&quot;uk-width-medium-1-4&quot;&gt; &lt;div class=&quot;uk-panel uk-panel-header&quot;&gt; &lt;h3 class=&quot;uk-panel-title&quot;&gt;友情链接&lt;/h3&gt; &lt;ul class=&quot;uk-list uk-list-line&quot;&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;编程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;读书&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;Python教程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;Git教程&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&#123;% endblock %&#125; 相应地，首页 URL 的处理函数更新如下： 123456789101112@get(&#x27;/&#x27;)def index(request): summary = &#x27;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.&#x27; blogs = [ Blog(id=&#x27;1&#x27;, name=&#x27;Test Blog&#x27;, summary=summary, created_at=time.time()-120), Blog(id=&#x27;2&#x27;, name=&#x27;Something New&#x27;, summary=summary, created_at=time.time()-3600), Blog(id=&#x27;3&#x27;, name=&#x27;Learn Swift&#x27;, summary=summary, created_at=time.time()-7200) ] return &#123; &#x27;__template__&#x27;: &#x27;blogs.html&#x27;, &#x27;blogs&#x27;: blogs &#125; Blog 的创建日期显示的是一个浮点数，因为它是由这段模板渲染出来的： 1&lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at &#125;&#125;&lt;/p&gt; 解决方法是通过 jinja2 的 filter（过滤器），把一个浮点数转换成日期字符串。我们来编写一个 datetime 的 filter，在模板里用法如下： 1&lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at|datetime &#125;&#125;&lt;/p&gt; filter 需要在初始化 jinja2 时设置。相关代码如下： 123456789101112131415def datetime_filter(t): delta = int(time.time() - t) if delta &lt; 60: return &#x27;1分钟前&#x27; if delta &lt; 3600: return &#x27;%s分钟前&#x27; % (delta // 60) if delta &lt; 86400: return &#x27;%s小时前&#x27; % (delta // 3600) if delta &lt; 604800: return &#x27;%s天前&#x27; % (delta // 86400) dt = datetime.fromtimestamp(t) return &#x27;%s年%s月%s日&#x27; % (dt.year, dt.month, dt.day)...init_jinja2(app, filters=dict(datetime=datetime_filter))... 现在，完善的首页显示如下 编写 API什么是 Web API 呢？ 如果我们想要获取一篇 Blog，输入 http://localhost:9000/blog/123，就可以看到 id 为 123 的 Blog 页面，但这个结果是 HTML 页面，它同时混合包含了 Blog 的数据和 Blog 的展示两个部分。对于用户来说，阅读起来没有问题，但是，如果机器读取，就很难从 HTML 中解析出 Blog 的数据。 如果一个 URL 返回的不是 HTML，而是机器能直接解析的数据，这个 URL 就可以看成是一个 Web API。比如，读取 http://localhost:9000/api/blogs/123，如果能直接返回 Blog 的数据，那么机器就可以直接读取。 REST 就是一种设计 API 的模式。最常用的数据格式是 JSON。由于 JSON 能直接被 JavaScript 读取，所以，以 JSON 格式编写的 REST 风格的 API 具有简单、易读、易用的特点。 编写 API 有什么好处呢？由于 API 就是把 Web App 的功能全部封装了，所以，通过 API 操作数据，可以极大地把前端和后端的代码隔离，使得后端代码易于测试，前端代码编写更简单。 一个 API 也是一个 URL 的处理函数，我们希望能直接通过一个 @api 来把函数变成 JSON 格式的 REST API，这样，获取注册用户可以用一个 API 实现如下： 1234567891011@get(&#x27;/api/users&#x27;)def api_get_users(*, page=&#x27;1&#x27;): page_index = get_page_index(page) num = yield from User.findNumber(&#x27;count(id)&#x27;) p = Page(num, page_index) if num == 0: return dict(page=p, users=()) users = yield from User.findAll(orderBy=&#x27;created_at desc&#x27;, limit=(p.offset, p.limit)) for u in users: u.passwd = &#x27;******&#x27; return dict(page=p, users=users) 只要返回一个 dict，后续的 response 这个 middleware 就可以把结果序列化为 JSON 并返回。 我们需要对 Error 进行处理，因此定义一个 APIError，这种 Error 是指 API 调用时发生了逻辑错误（比如用户不存在），其他的 Error 视为 Bug，返回的错误代码为 internalerror。 客户端调用 API 时，必须通过错误代码来区分 API 调用是否成功。错误代码是用来告诉调用者出错的原因。很多 API 用一个整数表示错误码，这种方式很难维护错误码，客户端拿到错误码还需要查表得知错误信息。更好的方式是用字符串表示错误代码，不需要看文档也能猜到错误原因。 可以在浏览器直接测试 API，例如，输入 http://localhost:9000/api/users，就可以看到返回的 JSON： 功能注册和登录用户管理是绝大部分 Web 网站都需要解决的问题。用户管理涉及到用户注册和登录。 用户注册相对简单，我们可以先通过 API 把用户注册这个功能实现了： 123456789101112131415161718192021222324_RE_EMAIL = re.compile(r&#x27;^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)&#123;1,4&#125;$&#x27;)_RE_SHA1 = re.compile(r&#x27;^[0-9a-f]&#123;40&#125;$&#x27;)@post(&#x27;/api/users&#x27;)def api_register_user(*, email, name, passwd): if not name or not name.strip(): raise APIValueError(&#x27;name&#x27;) if not email or not _RE_EMAIL.match(email): raise APIValueError(&#x27;email&#x27;) if not passwd or not _RE_SHA1.match(passwd): raise APIValueError(&#x27;passwd&#x27;) users = yield from User.findAll(&#x27;email=?&#x27;, [email]) if len(users) &gt; 0: raise APIError(&#x27;register:failed&#x27;, &#x27;email&#x27;, &#x27;Email is already in use.&#x27;) uid = next_id() sha1_passwd = &#x27;%s:%s&#x27; % (uid, passwd) user = User(id=uid, name=name.strip(), email=email, passwd=hashlib.sha1(sha1_passwd.encode(&#x27;utf-8&#x27;)).hexdigest(), image=&#x27;http://www.gravatar.com/avatar/%s?d=mm&amp;s=120&#x27; % hashlib.md5(email.encode(&#x27;utf-8&#x27;)).hexdigest()) yield from user.save() # make session cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = &#x27;******&#x27; r.content_type = &#x27;application/json&#x27; r.body = json.dumps(user, ensure_ascii=False).encode(&#x27;utf-8&#x27;) return r 注意用户口令是客户端传递的经过 SHA1 计算后的 40 位 Hash 字符串，所以服务器端并不知道用户的原始口令。 接下来可以创建一个注册页面，让用户填写注册表单，然后，提交数据到注册用户的 API： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;注册&#123;% endblock %&#125;&#123;% block beforehead %&#125;&lt;script&gt;function validateEmail(email) &#123; var re = /^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)&#123;1,4&#125;$/; return re.test(email.toLowerCase());&#125;$(function () &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: &#123; name: &#x27;&#x27;, email: &#x27;&#x27;, password1: &#x27;&#x27;, password2: &#x27;&#x27; &#125;, methods: &#123; submit: function (event) &#123; event.preventDefault(); var $form = $(&#x27;#vm&#x27;); if (! this.name.trim()) &#123; return $form.showFormError(&#x27;请输入名字&#x27;); &#125; if (! validateEmail(this.email.trim().toLowerCase())) &#123; return $form.showFormError(&#x27;请输入正确的Email地址&#x27;); &#125; if (this.password1.length &lt; 6) &#123; return $form.showFormError(&#x27;口令长度至少为6个字符&#x27;); &#125; if (this.password1 !== this.password2) &#123; return $form.showFormError(&#x27;两次输入的口令不一致&#x27;); &#125; var email = this.email.trim().toLowerCase(); $form.postJSON(&#x27;/api/users&#x27;, &#123; name: this.name.trim(), email: email, passwd: CryptoJS.SHA1(email + &#x27;:&#x27; + this.password1).toString() &#125;, function (err, r) &#123; if (err) &#123; return $form.showFormError(err); &#125; return location.assign(&#x27;/&#x27;); &#125;); &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;);&lt;/script&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-2-3&quot;&gt; &lt;h1&gt;欢迎注册！&lt;/h1&gt; &lt;form id=&quot;vm&quot; v-on=&quot;submit: submit&quot; class=&quot;uk-form uk-form-stacked&quot;&gt; &lt;div class=&quot;uk-alert uk-alert-danger uk-hidden&quot;&gt;&lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;名字:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;name&quot; type=&quot;text&quot; maxlength=&quot;50&quot; placeholder=&quot;名字&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;电子邮件:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;email&quot; type=&quot;text&quot; maxlength=&quot;50&quot; placeholder=&quot;your-name@example.com&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;输入口令:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;password1&quot; type=&quot;password&quot; maxlength=&quot;50&quot; placeholder=&quot;输入口令&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;重复口令:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;password2&quot; type=&quot;password&quot; maxlength=&quot;50&quot; placeholder=&quot;重复口令&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-user&quot;&gt;&lt;/i&gt; 注册&lt;/button&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&#123;% endblock %&#125; 这样我们就把用户注册的功能完成了 用户登录比用户注册复杂。由于 HTTP 协议是一种无状态协议，而服务器要跟踪用户状态，就只能通过 cookie 实现。大多数 Web 框架提供了 Session 功能来封装保存用户状态的 cookie。 Session 的优点是简单易用，可以直接从 Session 中取出用户登录信息。 Session 的缺点是服务器需要在内存中维护一个映射表来存储用户登录信息，如果有两台以上服务器，就需要对 Session 做集群，因此，使用 Session 的 Web App 很难扩展。 我们采用直接读取 cookie 的方式来验证用户登录，每次用户访问任意 URL，都会对 cookie 进行验证，这种方式的好处是保证服务器处理任意的 URL 都是无状态的，可以扩展到多台服务器。 由于登录成功后是由服务器生成一个 cookie 发送给浏览器，所以，要保证这个 cookie 不会被客户端伪造出来。 实现防伪造 cookie 的关键是通过一个单向算法（例如 SHA1），举例如下： 当用户输入了正确的口令登录成功后，服务器可以从数据库取到用户的 id，并按照如下方式计算出一个字符串： 1&quot;用户id&quot; + &quot;过期时间&quot; + SHA1(&quot;用户id&quot; + &quot;用户口令&quot; + &quot;过期时间&quot; + &quot;SecretKey&quot;) 当浏览器发送 cookie 到服务器端后，服务器可以拿到的信息包括： 用户 id 过期时间 SHA1 值如果未到过期时间，服务器就根据用户 id 查找用户口令，并计算： 1SHA1(&quot;用户id&quot; + &quot;用户口令&quot; + &quot;过期时间&quot; + &quot;SecretKey&quot;) 并与浏览器 cookie 中的哈希进行比较，如果相等，则说明用户已登录，否则，cookie 就是伪造的。 这个算法的关键在于 SHA1 是一种单向算法，即可以通过原始字符串计算出 SHA1 结果，但无法通过 SHA1 结果反推出原始字符串。 所以登录 API 可以实现如下： 1234567891011121314151617181920212223242526272829303132@post(&#x27;/api/authenticate&#x27;)def authenticate(*, email, passwd): if not email: raise APIValueError(&#x27;email&#x27;, &#x27;Invalid email.&#x27;) if not passwd: raise APIValueError(&#x27;passwd&#x27;, &#x27;Invalid password.&#x27;) users = yield from User.findAll(&#x27;email=?&#x27;, [email]) if len(users) == 0: raise APIValueError(&#x27;email&#x27;, &#x27;Email not exist.&#x27;) user = users[0] # check passwd: sha1 = hashlib.sha1() sha1.update(user.id.encode(&#x27;utf-8&#x27;)) sha1.update(b&#x27;:&#x27;) sha1.update(passwd.encode(&#x27;utf-8&#x27;)) if user.passwd != sha1.hexdigest(): raise APIValueError(&#x27;passwd&#x27;, &#x27;Invalid password.&#x27;) # authenticate ok, set cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = &#x27;******&#x27; r.content_type = &#x27;application/json&#x27; r.body = json.dumps(user, ensure_ascii=False).encode(&#x27;utf-8&#x27;) return r # 计算加密cookie:def user2cookie(user, max_age): # build cookie string by: id-expires-sha1 expires = str(int(time.time() + max_age)) s = &#x27;%s-%s-%s-%s&#x27; % (user.id, user.passwd, expires, _COOKIE_KEY) L = [user.id, expires, hashlib.sha1(s.encode(&#x27;utf-8&#x27;)).hexdigest()] return &#x27;-&#x27;.join(L) 对于每个 URL 处理函数，如果我们都去写解析 cookie 的代码，那会导致代码重复很多次。 利用 middle 在处理 URL 之前，把 cookie 解析出来，并将登录用户绑定到 request 对象上，这样，后续的 URL 处理函数就可以直接拿到登录用户： 123456789101112131415161718192021222324252627282930313233343536373839404142@asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(&#x27;check user: %s %s&#x27; % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(&#x27;set current user: %s&#x27; % user.email) request.__user__ = user return (yield from handler(request)) return auth # 解密cookie:@asyncio.coroutinedef cookie2user(cookie_str): &#x27;&#x27;&#x27; Parse cookie and load user if cookie is valid. &#x27;&#x27;&#x27; if not cookie_str: return None try: L = cookie_str.split(&#x27;-&#x27;) if len(L) != 3: return None uid, expires, sha1 = L if int(expires) &lt; time.time(): return None user = yield from User.find(uid) if user is None: return None s = &#x27;%s-%s-%s-%s&#x27; % (uid, user.passwd, expires, _COOKIE_KEY) if sha1 != hashlib.sha1(s.encode(&#x27;utf-8&#x27;)).hexdigest(): logging.info(&#x27;invalid sha1&#x27;) return None user.passwd = &#x27;******&#x27; return user except Exception as e: logging.exception(e) return None 这样，我们就完成了用户注册和登录的功能。 编写日志创建页在 Web 开发中，后端代码写起来其实是相当容易的。 例如，我们编写一个 REST API，用于创建一个 Blog： 123456789101112@post(&#x27;/api/blogs&#x27;)def api_create_blog(request, *, name, summary, content): check_admin(request) if not name or not name.strip(): raise APIValueError(&#x27;name&#x27;, &#x27;name cannot be empty.&#x27;) if not summary or not summary.strip(): raise APIValueError(&#x27;summary&#x27;, &#x27;summary cannot be empty.&#x27;) if not content or not content.strip(): raise APIValueError(&#x27;content&#x27;, &#x27;content cannot be empty.&#x27;) blog = Blog(user_id=request.__user__.id, user_name=request.__user__.name, user_image=request.__user__.image, name=name.strip(), summary=summary.strip(), content=content.strip()) yield from blog.save() return blog 编写后端 Python 代码不但很简单，而且非常容易测试，上面的 API：api_create_blog() 本身只是一个普通函数。 Web 开发真正困难的地方在于编写前端页面。前端页面需要混合 HTML、CSS 和 JavaScript，如果对这三者没有深入地掌握，编写的前端页面将很快难以维护。 更大的问题在于，前端页面通常是动态页面，也就是说，前端页面往往是由后端代码生成的。 生成前端页面最早的方式是拼接字符串： 12345s = &#x27;&lt;html&gt;&lt;head&gt;&lt;title&gt;&#x27; + title + &#x27;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#x27; + body + &#x27;&lt;/body&gt;&lt;/html&gt;&#x27; 显然这种方式完全不具备可维护性。所以有第二种模板方式： 12345678&lt;html&gt;&lt;head&gt; &lt;title&gt;&#123;&#123; title &#125;&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;&#123; body &#125;&#125;&lt;/body&gt;&lt;/html&gt; ASP、JSP、PHP 等都是用这种模板方式生成前端页面。 如果在页面上大量使用 JavaScript（事实上大部分页面都会），模板方式仍然会导致 JavaScript 代码与后端代码绑得非常紧密，以至于难以维护。其根本原因在于负责显示的 HTML DOM 模型与负责数据和交互的 JavaScript 代码没有分割清楚。 要编写可维护的前端代码绝非易事。和后端结合的 MVC 模式已经无法满足复杂页面逻辑的需要了，所以，新的 MVVM：Model View ViewModel 模式应运而生。 MVVM 最早由微软提出来，它借鉴了桌面应用程序的 MVC 思想，在前端页面中，把 Model 用纯 JavaScript 对象表示： 1234567&lt;script&gt; var blog = &#123; name: &#x27;hello&#x27;, summary: &#x27;this is summary&#x27;, content: &#x27;this is content...&#x27; &#125;;&lt;/script&gt; View 是纯 HTML： 123456&lt;form action=&quot;/api/blogs&quot; method=&quot;post&quot;&gt; &lt;input name=&quot;name&quot;&gt; &lt;input name=&quot;summary&quot;&gt; &lt;textarea name=&quot;content&quot;&gt;&lt;/textarea&gt; &lt;button type=&quot;submit&quot;&gt;OK&lt;/button&gt;&lt;/form&gt; 由于 Model 表示数据，View 负责显示，两者做到了最大限度的分离。 把 Model 和 View 关联起来的就是 ViewModel。ViewModel 负责把 Model 的数据同步到 View 显示出来，还负责把 View 的修改同步回 Model。 ViewModel 如何编写？需要用 JavaScript 编写一个通用的 ViewModel，这样，就可以复用整个 MVVM 模型了。 好消息是已有许多成熟的 MVVM 框架，例如 AngularJS，KnockoutJS 等。我们选择 Vue 这个简单易用的 MVVM 框架来实现创建 Blog 的页面 templates/manage_blog_edit.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;编辑日志&#123;% endblock %&#125;&#123;% block beforehead %&#125;&lt;script&gt;var ID = &#x27;&#123;&#123; id &#125;&#125;&#x27;, action = &#x27;&#123;&#123; action &#125;&#125;&#x27;;function initVM(blog) &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: blog, methods: &#123; submit: function (event) &#123; event.preventDefault(); var $form = $(&#x27;#vm&#x27;).find(&#x27;form&#x27;); $form.postJSON(action, this.$data, function (err, r) &#123; if (err) &#123; $form.showFormError(err); &#125; else &#123; return location.assign(&#x27;/api/blogs/&#x27; + r.id); &#125; &#125;); &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;$(function () &#123; if (ID) &#123; getJSON(&#x27;/api/blogs/&#x27; + ID, function (err, blog) &#123; if (err) &#123; return fatal(err); &#125; $(&#x27;#loading&#x27;).hide(); initVM(blog); &#125;); &#125; else &#123; $(&#x27;#loading&#x27;).hide(); initVM(&#123; name: &#x27;&#x27;, summary: &#x27;&#x27;, content: &#x27;&#x27; &#125;); &#125;&#125;);&lt;/script&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-1-1 uk-margin-bottom&quot;&gt; &lt;div class=&quot;uk-panel uk-panel-box&quot;&gt; &lt;ul class=&quot;uk-breadcrumb&quot;&gt; &lt;li&gt;&lt;a href=&quot;/manage/comments&quot;&gt;评论&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/manage/blogs&quot;&gt;日志&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/manage/users&quot;&gt;用户&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=&quot;error&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;div id=&quot;loading&quot; class=&quot;uk-width-1-1 uk-text-center&quot;&gt; &lt;span&gt;&lt;i class=&quot;uk-icon-spinner uk-icon-medium uk-icon-spin&quot;&gt;&lt;/i&gt; 正在加载...&lt;/span&gt; &lt;/div&gt; &lt;div id=&quot;vm&quot; class=&quot;uk-width-2-3&quot;&gt; &lt;form v-on=&quot;submit: submit&quot; class=&quot;uk-form uk-form-stacked&quot;&gt; &lt;div class=&quot;uk-alert uk-alert-danger uk-hidden&quot;&gt;&lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;标题:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;name&quot; name=&quot;name&quot; type=&quot;text&quot; placeholder=&quot;标题&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;摘要:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;textarea v-model=&quot;summary&quot; rows=&quot;4&quot; name=&quot;summary&quot; placeholder=&quot;摘要&quot; class=&quot;uk-width-1-1&quot; style=&quot;resize:none;&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;内容:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;textarea v-model=&quot;content&quot; rows=&quot;16&quot; name=&quot;content&quot; placeholder=&quot;内容&quot; class=&quot;uk-width-1-1&quot; style=&quot;resize:none;&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-save&quot;&gt;&lt;/i&gt; 保存&lt;/button&gt; &lt;a href=&quot;/manage/blogs&quot; class=&quot;uk-button&quot;&gt;&lt;i class=&quot;uk-icon-times&quot;&gt;&lt;/i&gt; 取消&lt;/a&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&#123;% endblock %&#125; 初始化 Vue 时，我们指定 3 个参数： el：根据选择器查找绑定的 View，这里是 #vm，就是 id 为 vm 的 DOM，对应的是一个 &lt;div&gt; 标签； data：JavaScript 对象表示的 Model，我们初始化为 &#123; name: &#39;&#39;, summary: &#39;&#39;, content: &#39;&#39;&#125;； methods：View 可以触发的 JavaScript 函数，submit 就是提交表单时触发的函数。 接下来，我们在 &lt;form&gt; 标签中，用几个简单的 v-model，就可以让 Vue 把 Model 和 View 关联起来： 12&lt;!-- input的value和Model的name关联起来了 --&gt;&lt;input v-model=&quot;name&quot; class=&quot;uk-width-1-1&quot;&gt; Form 表单通过 &lt;form v-on=&quot;submit: submit&quot;&gt; 把提交表单的事件关联到 submit 方法。 需要特别注意的是，在 MVVM 中，Model 和 View 是双向绑定的。如果我们在 Form 中修改了文本框的值，可以在 Model 中立刻拿到新的值。试试在表单中输入文本，然后在 Chrome 浏览器中打开 JavaScript 控制台，可以通过 vm.name 访问单个属性，或者通过 vm.$data 访问整个 Model 如果我们在 JavaScript 逻辑中修改了 Model，这个修改会立刻反映到 View 上。试试在 JavaScript 控制台输入 vm.name = &#39;MVVM简介&#39;，可以看到文本框的内容自动被同步了 双向绑定是 MVVM 框架最大的作用。借助于 MVVM，我们把复杂的显示逻辑交给框架完成。由于后端编写了独立的 REST API，所以，前端用 AJAX 提交表单非常容易，前后端分离得非常彻底。 日志列表页MVVM 模式不但可用于 Form 表单，在复杂的管理页面中也能大显身手。例如，分页显示 Blog 的功能，我们先把后端代码写出来： 在 apis.py 中定义一个 Page 类用于存储分页信息： 123456789101112131415161718class Page(object): def __init__(self, item_count, page_index=1, page_size=10): self.item_count = item_count self.page_size = page_size self.page_count = item_count // page_size + (1 if item_count % page_size &gt; 0 else 0) if (item_count == 0) or (page_index &gt; self.page_count): self.offset = 0 self.limit = 0 self.page_index = 1 else: self.page_index = page_index self.offset = self.page_size * (page_index - 1) self.limit = self.page_size self.has_next = self.page_index &lt; self.page_count self.has_previous = self.page_index &gt; 1 def __str__(self): return &#x27;item_count: %s, page_count: %s, page_index: %s, page_size: %s, offset: %s, limit: %s&#x27; % (self.item_count, self.page_count, self.page_index, self.page_size, self.offset, self.limit) __repr__ = __str__ 在 handlers.py 中实现 API： 123456789@get(&#x27;/api/blogs&#x27;)def api_blogs(*, page=&#x27;1&#x27;): page_index = get_page_index(page) num = yield from Blog.findNumber(&#x27;count(id)&#x27;) p = Page(num, page_index) if num == 0: return dict(page=p, blogs=()) blogs = yield from Blog.findAll(orderBy=&#x27;created_at desc&#x27;, limit=(p.offset, p.limit)) return dict(page=p, blogs=blogs) 管理页面： 123456@get(&#x27;/manage/blogs&#x27;)def manage_blogs(*, page=&#x27;1&#x27;): return &#123; &#x27;__template__&#x27;: &#x27;manage_blogs.html&#x27;, &#x27;page_index&#x27;: get_page_index(page) &#125; 模板页面首先通过 API：GET /api/blogs?page=? 拿到 Model： 12345678910&#123; &quot;page&quot;: &#123; &quot;has_next&quot;: true, &quot;page_index&quot;: 1, &quot;page_count&quot;: 2, &quot;has_previous&quot;: false, &quot;item_count&quot;: 12 &#125;, &quot;blogs&quot;: [...]&#125; 然后，通过 Vue 初始化 MVVM： 1234567891011121314151617181920212223242526272829303132333435363738&lt;script&gt;function initVM(data) &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: &#123; blogs: data.blogs, page: data.page &#125;, methods: &#123; edit_blog: function (blog) &#123; location.assign(&#x27;/manage/blogs/edit?id=&#x27; + blog.id); &#125;, delete_blog: function (blog) &#123; if (confirm(&#x27;确认要删除“&#x27; + blog.name + &#x27;”？删除后不可恢复！&#x27;)) &#123; postJSON(&#x27;/api/blogs/&#x27; + blog.id + &#x27;/delete&#x27;, function (err, r) &#123; if (err) &#123; return alert(err.message || err.error || err); &#125; refresh(); &#125;); &#125; &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;$(function() &#123; getJSON(&#x27;/api/blogs&#x27;, &#123; page: &#123;&#123; page_index &#125;&#125; &#125;, function (err, results) &#123; if (err) &#123; return fatal(err); &#125; $(&#x27;#loading&#x27;).hide(); initVM(results); &#125;);&#125;);&lt;/script&gt; View 的容器是 #vm，包含一个 table，我们用 v-repeat 可以把 Model 的数组 blogs 直接变成多行的 &lt;tr&gt;： 12345678910111213141516171819202122232425262728293031&lt;div id=&quot;vm&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;a href=&quot;/manage/blogs/create&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-plus&quot;&gt;&lt;/i&gt; 新日志&lt;/a&gt; &lt;table class=&quot;uk-table uk-table-hover&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=&quot;uk-width-5-10&quot;&gt;标题 / 摘要&lt;/th&gt; &lt;th class=&quot;uk-width-2-10&quot;&gt;作者&lt;/th&gt; &lt;th class=&quot;uk-width-2-10&quot;&gt;创建时间&lt;/th&gt; &lt;th class=&quot;uk-width-1-10&quot;&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr v-repeat=&quot;blog: blogs&quot; &gt; &lt;td&gt; &lt;a target=&quot;_blank&quot; v-attr=&quot;href: &#x27;/blog/&#x27;+blog.id&quot; v-text=&quot;blog.name&quot;&gt;&lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;a target=&quot;_blank&quot; v-attr=&quot;href: &#x27;/user/&#x27;+blog.user_id&quot; v-text=&quot;blog.user_name&quot;&gt;&lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;span v-text=&quot;blog.created_at.toDateTime()&quot;&gt;&lt;/span&gt; &lt;/td&gt; &lt;td&gt; &lt;a href=&quot;#0&quot; v-on=&quot;click: edit_blog(blog)&quot;&gt;&lt;i class=&quot;uk-icon-edit&quot;&gt;&lt;/i&gt; &lt;a href=&quot;#0&quot; v-on=&quot;click: delete_blog(blog)&quot;&gt;&lt;i class=&quot;uk-icon-trash-o&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div v-component=&quot;pagination&quot; v-with=&quot;page&quot;&gt;&lt;/div&gt;&lt;/div&gt; 往 Model 的 blogs 数组中增加一个 Blog 元素，table 就神奇地增加了一行；把 blogs 数组的某个元素删除，table 就神奇地减少了一行。所有复杂的 Model-View 的映射逻辑全部由 MVVM 框架完成，我们只需要在 HTML 中写上 v-repeat 指令，就什么都不用管了。 可以把 v-repeat=&quot;blog: blogs&quot; 看成循环代码，所以，可以在一个 &lt;tr&gt; 内部引用循环变量 blog。v-text 和 v-attr 指令分别用于生成文本和 DOM 节点属性。 效率现在，我们已经把一个 Web App 的框架完全搭建好了，从后端的 API 到前端的 MVVM，流程已经跑通了。 在继续工作前，注意到每次修改 Python 代码，都必须在命令行先 Ctrl-C 停止服务器，再重启，改动才能生效。 在开发阶段，每天都要修改、保存几十次代码，每次保存都手动来这么一下非常麻烦，严重地降低了我们的开发效率。有没有办法让服务器检测到代码修改后自动重新加载呢？ Django 的开发环境在 Debug 模式下就可以做到自动重新加载，如果我们编写的服务器也能实现这个功能，就能大大提升开发效率。 可惜的是，Django 没把这个功能独立出来，不用 Django 就享受不到，怎么办？ 其实 Python 本身提供了重新载入模块的功能，但不是所有模块都能被重新载入。另一种思路是检测 www 目录下的代码改动，一旦有改动，就自动重启服务器。 按照这个思路，我们可以编写一个辅助程序 pymonitor.py，让它启动 wsgiapp.py，并时刻监控 www 目录下的代码改动，有改动时，先把当前 wsgiapp.py 进程杀掉，再重启，就完成了服务器进程的自动重启。 要监控目录文件的变化，我们也无需自己手动定时扫描，Python 的第三方库 watchdog 可以利用操作系统的 API 来监控目录文件的变化，并发送通知。我们先用 pip 安装： 1$ pip3 install watchdog 利用 watchdog 接收文件变化的通知，如果是 .py 文件，就自动重启 wsgiapp.py 进程。 利用 Python 自带的 subprocess 实现进程的启动和终止，并把输入输出重定向到当前进程的输入输出中： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python3# -*- coding: utf-8 -*-__author__ = &#x27;Michael Liao&#x27;import os, sys, time, subprocessfrom watchdog.observers import Observerfrom watchdog.events import FileSystemEventHandlerdef log(s): print(&#x27;[Monitor] %s&#x27; % s)class MyFileSystemEventHander(FileSystemEventHandler): def __init__(self, fn): super(MyFileSystemEventHander, self).__init__() self.restart = fn def on_any_event(self, event): if event.src_path.endswith(&#x27;.py&#x27;): log(&#x27;Python source file changed: %s&#x27; % event.src_path) self.restart()command = [&#x27;echo&#x27;, &#x27;ok&#x27;]process = Nonedef kill_process(): global process if process: log(&#x27;Kill process [%s]...&#x27; % process.pid) process.kill() process.wait() log(&#x27;Process ended with code %s.&#x27; % process.returncode) process = Nonedef start_process(): global process, command log(&#x27;Start process %s...&#x27; % &#x27; &#x27;.join(command)) process = subprocess.Popen(command, stdin=sys.stdin, stdout=sys.stdout, stderr=sys.stderr)def restart_process(): kill_process() start_process()def start_watch(path, callback): observer = Observer() observer.schedule(MyFileSystemEventHander(restart_process), path, recursive=True) observer.start() log(&#x27;Watching directory %s...&#x27; % path) start_process() try: while True: time.sleep(0.5) except KeyboardInterrupt: observer.stop() observer.join()if __name__ == &#x27;__main__&#x27;: argv = sys.argv[1:] if not argv: print(&#x27;Usage: ./pymonitor your-script.py&#x27;) exit(0) if argv[0] != &#x27;python3&#x27;: argv.insert(0, &#x27;python3&#x27;) command = argv path = os.path.abspath(&#x27;.&#x27;) start_watch(path, None) 一共 70 行左右的代码，就实现了 Debug 模式的自动重新加载。用下面的命令启动服务器： 1$ python3 pymonitor.py wsgiapp.py 或者给 pymonitor.py 加上可执行权限，启动服务器： 1$ ./pymonitor.py app.py 在编辑器中打开一个 .py 文件，修改后保存，看看命令行输出，是不是自动重启了服务器： 1234567891011$ ./pymonitor.py app.py [Monitor] Watching directory /Users/michael/Github/awesome-python3-webapp/www...[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000...[Monitor] Python source file changed: /Users/michael/Github/awesome-python-webapp/www/handlers.py[Monitor] Kill process [2747]...[Monitor] Process ended with code -9.[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000... 现在，只要一保存代码，就可以刷新浏览器看到效果，大大提升了开发效率。 完善在 Web App 框架和基本流程跑通后，剩下的工作全部是体力活了：在 Debug 开发模式下完成后端所有 API、前端所有页面。我们需要做的事情包括： 把当前用户绑定到 request 上，并对 URL/manage/ 进行拦截，检查当前用户是否是管理员身份： 12345678910111213141516@asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(&#x27;check user: %s %s&#x27; % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(&#x27;set current user: %s&#x27; % user.email) request.__user__ = user if request.path.startswith(&#x27;/manage/&#x27;) and (request.__user__ is None or not request.__user__.admin): return web.HTTPFound(&#x27;/signin&#x27;) return (yield from handler(request)) return auth 后端 API 包括： 获取日志：GET &#x2F;api&#x2F;blogs 创建日志：POST &#x2F;api&#x2F;blogs 修改日志：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id 删除日志：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id&#x2F;delete 获取评论：GET &#x2F;api&#x2F;comments 创建评论：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id&#x2F;comments 删除评论：POST &#x2F;api&#x2F;comments&#x2F;:comment_id&#x2F;delete 创建新用户：POST &#x2F;api&#x2F;users 获取用户：GET &#x2F;api&#x2F;users管理页面包括： 评论列表页：GET &#x2F;manage&#x2F;comments 日志列表页：GET &#x2F;manage&#x2F;blogs 创建日志页：GET &#x2F;manage&#x2F;blogs&#x2F;create 修改日志页：GET &#x2F;manage&#x2F;blogs&#x2F; 用户列表页：GET &#x2F;manage&#x2F;users用户浏览页面包括： 注册页：GET &#x2F;register 登录页：GET &#x2F;signin 注销页：GET &#x2F;signout 首页：GET &#x2F; 日志详情页：GET &#x2F;blog&#x2F;:blog_id把所有的功能实现，我们第一个 Web App 就宣告完成！ 部署很多做开发的同学把部署这件事情看成是运维同学的工作，这种看法是完全错误的。首先，最近流行 DevOps 理念，就是说，开发和运维要变成一个整体。其次，运维的难度，其实跟开发质量有很大的关系。代码写得垃圾，运维再好也架不住天天挂掉。最后，DevOps 理念需要把运维、监控等功能融入到开发中。你想服务器升级时不中断用户服务？那就得在开发时考虑到这一点。 下面，我们就来把 awesome-python3-webapp 部署到 Linux 服务器。 搭建 Linux 服务器要部署到 Linux，首先得有一台 Linux 服务器。要在公网上体验的同学，可以在 Amazon 的 AWS 申请一台 EC2 虚拟机（免费使用 1 年），或者使用国内的一些云服务器，一般都提供 Ubuntu Server 的镜像。想在本地部署的同学，请安装虚拟机，推荐使用 VirtualBox。 我们选择的 Linux 服务器版本是 Ubuntu Server 14.04 LTS，原因是 apt 太简单了。如果你准备使用其他 Linux 版本，也没有问题。 Linux 安装完成后，请确保 ssh 服务正在运行，否则，需要通过 apt 安装： 1$ sudo apt-get install openssh-server 有了 ssh 服务，就可以从本地连接到服务器上。建议把公钥复制到服务器端用户的 .ssh/authorized_keys 中，这样，就可以通过证书实现无密码连接。 部署方式利用 Python 自带的 asyncio，我们已经编写了一个异步高性能服务器。但是，我们还需要一个高性能的 Web 服务器，这里选择 Nginx，它可以处理静态资源，同时作为反向代理把动态请求交给 Python 代码处理。这个模型如下 Nginx 负责分发请求 在服务器端，我们需要定义好部署的目录结构： 123456/+- srv/ +- awesome/ &lt;-- Web App根目录 +- www/ &lt;-- 存放Python源码 | +- static/ &lt;-- 存放静态资源文件 +- log/ &lt;-- 存放log 在服务器上部署，要考虑到新版本如果运行不正常，需要回退到旧版本时怎么办。每次用新的代码覆盖掉旧的文件是不行的，需要一个类似版本控制的机制。由于 Linux 系统提供了软链接功能，所以，我们把 www 作为一个软链接，它指向哪个目录，哪个目录就是当前运行的版本 而 Nginx 和 python 代码的配置文件只需要指向 www 目录即可。 Nginx 可以作为服务进程直接启动，但 app.py 还不行，所以，Supervisor 登场！Supervisor 是一个管理进程的工具，可以随系统启动而启动服务，它还时刻监控服务进程，如果服务进程意外退出，Supervisor 可以自动重启服务。 总结一下我们需要用到的服务有： Nginx：高性能 Web 服务器 + 负责反向代理； Supervisor：监控服务进程的工具； MySQL：数据库服务。在 Linux 服务器上用 apt 可以直接安装上述服务： 1$ sudo apt-get install nginx supervisor python3 mysql-server 然后，再把我们自己的 Web App 用到的 Python 库安装了： 1$ sudo pip3 install jinja2 aiomysql aiohttp 在服务器上创建目录 /srv/awesome/ 以及相应的子目录。 在服务器上初始化 MySQL 数据库，把数据库初始化脚本 schema.sql 复制到服务器上执行： 1$ mysql -u root -p &lt; schema.sql 服务器端准备就绪。 部署用 FTP 还是 SCP 还是 rsync 复制文件？如果你需要手动复制，用一次两次还行，一天如果部署 50 次不但慢、效率低，而且容易出错。 正确的部署方式是使用工具配合脚本完成自动化部署。Fabric 就是一个自动化部署工具。由于 Fabric 是用 Python 2.x 开发的，所以，部署脚本要用 Python 2.7 来编写，本机还必须安装 Python 2.7 版本。 要用 Fabric 部署，需要在本机（是开发机器，不是 Linux 服务器）安装 Fabric： 1$ easy_install fabric Linux 服务器上不需要安装 Fabric，Fabric 使用 SSH 直接登录服务器并执行部署命令。 下一步是编写部署脚本。Fabric 的部署脚本叫 fabfile.py，我们把它放到 awesome-python-webapp 的目录下，与 www 目录平级： 1234awesome-python-webapp/+- fabfile.py+- www/+- ... Fabric 的脚本编写很简单，首先导入 Fabric 的 API，设置部署时的变量： 1234567891011121314# fabfile.pyimport os, refrom datetime import datetime# 导入Fabric API:from fabric.api import *# 服务器登录用户名:env.user = &#x27;michael&#x27;# sudo用户为root:env.sudo_user = &#x27;root&#x27;# 服务器地址，可以有多个，依次部署:env.hosts = [&#x27;192.168.0.3&#x27;]# 服务器MySQL用户名和口令:db_user = &#x27;www-data&#x27;db_password = &#x27;www-data&#x27; 然后，每个 Python 函数都是一个任务。我们先编写一个打包的任务： 12345678910_TAR_FILE = &#x27;dist-awesome.tar.gz&#x27;def build(): includes = [&#x27;static&#x27;, &#x27;templates&#x27;, &#x27;transwarp&#x27;, &#x27;favicon.ico&#x27;, &#x27;*.py&#x27;] excludes = [&#x27;test&#x27;, &#x27;.*&#x27;, &#x27;*.pyc&#x27;, &#x27;*.pyo&#x27;] local(&#x27;rm -f dist/%s&#x27; % _TAR_FILE) with lcd(os.path.join(os.path.abspath(&#x27;.&#x27;), &#x27;www&#x27;)): cmd = [&#x27;tar&#x27;, &#x27;--dereference&#x27;, &#x27;-czvf&#x27;, &#x27;../dist/%s&#x27; % _TAR_FILE] cmd.extend([&#x27;--exclude=\\&#x27;%s\\&#x27;&#x27; % ex for ex in excludes]) cmd.extend(includes) local(&#x27; &#x27;.join(cmd)) Fabric 提供 local(&#39;...&#39;) 来运行本地命令，with lcd(path) 可以把当前命令的目录设定为 lcd() 指定的目录，注意 Fabric 只能运行命令行命令，Windows 下可能需要 Cgywin 环境。 在 awesome-python-webapp 目录下运行： 1$ fab build 看看是否在 dist 目录下创建了 dist-awesome.tar.gz 的文件。 打包后，我们就可以继续编写 deploy 任务，把打包文件上传至服务器，解压，重置 www 软链接，重启相关服务： 12345678910111213141516171819202122232425_REMOTE_TMP_TAR = &#x27;/tmp/%s&#x27; % _TAR_FILE_REMOTE_BASE_DIR = &#x27;/srv/awesome&#x27;def deploy(): newdir = &#x27;www-%s&#x27; % datetime.now().strftime(&#x27;%y-%m-%d_%H.%M.%S&#x27;) # 删除已有的tar文件: run(&#x27;rm -f %s&#x27; % _REMOTE_TMP_TAR) # 上传新的tar文件: put(&#x27;dist/%s&#x27; % _TAR_FILE, _REMOTE_TMP_TAR) # 创建新目录: with cd(_REMOTE_BASE_DIR): sudo(&#x27;mkdir %s&#x27; % newdir) # 解压到新目录: with cd(&#x27;%s/%s&#x27; % (_REMOTE_BASE_DIR, newdir)): sudo(&#x27;tar -xzvf %s&#x27; % _REMOTE_TMP_TAR) # 重置软链接: with cd(_REMOTE_BASE_DIR): sudo(&#x27;rm -f www&#x27;) sudo(&#x27;ln -s %s www&#x27; % newdir) sudo(&#x27;chown www-data:www-data www&#x27;) sudo(&#x27;chown -R www-data:www-data %s&#x27; % newdir) # 重启Python服务和nginx服务器: with settings(warn_only=True): sudo(&#x27;supervisorctl stop awesome&#x27;) sudo(&#x27;supervisorctl start awesome&#x27;) sudo(&#x27;/etc/init.d/nginx reload&#x27;) 注意 run() 函数执行的命令是在服务器上运行，with cd(path) 和 with lcd(path) 类似，把当前目录在服务器端设置为 cd() 指定的目录。如果一个命令需要 sudo 权限，就不能用 run()，而是用 sudo() 来执行。 配置 Supervisor上面让 Supervisor 重启 awesome 的命令会失败，因为我们还没有配置 Supervisor 呢。 编写一个 Supervisor 的配置文件 awesome.conf，存放到 /etc/supervisor/conf.d/ 目录下： 123456789[program:awesome]command = /srv/awesome/www/app.pydirectory = /srv/awesome/wwwuser = www-datastartsecs = 3redirect_stderr = truestdout_logfile_maxbytes = 50MBstdout_logfile_backups = 10stdout_logfile = /srv/awesome/log/app.log 配置文件通过 [program:awesome] 指定服务名为 awesome，command 指定启动 app.py。 然后重启 Supervisor 后，就可以随时启动和停止 Supervisor 管理的服务了： 1234$ sudo supervisorctl reload$ sudo supervisorctl start awesome$ sudo supervisorctl statusawesome RUNNING pid 1401, uptime 5:01:34 配置 NginxSupervisor 只负责运行 app.py，我们还需要配置 Nginx。把配置文件 awesome 放到 /etc/nginx/sites-available/ 目录下： 12345678910111213141516171819202122server &#123; listen 80; # 监听80端口 root /srv/awesome/www; access_log /srv/awesome/log/access_log; error_log /srv/awesome/log/error_log; # server_name awesome.liaoxuefeng.com; # 配置域名 # 处理静态文件/favicon.ico: location /favicon.ico &#123; root /srv/awesome/www; &#125; # 处理静态资源: location ~ ^\\/static\\/.*$ &#123; root /srv/awesome/www; &#125; # 动态请求转发到9000端口: location / &#123; proxy_pass http://127.0.0.1:9000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 然后在 /etc/nginx/sites-enabled/ 目录下创建软链接： 123$ pwd/etc/nginx/sites-enabled$ sudo ln -s /etc/nginx/sites-available/awesome . 让 Nginx 重新加载配置文件，不出意外，我们的 awesome-python3-webapp 应该正常运行： 1$ sudo /etc/init.d/nginx reload 如果有任何错误，都可以在 /srv/awesome/log 下查找 Nginx 和 App 本身的 log。如果 Supervisor 启动时报错，可以在 /var/log/supervisor 下查看 Supervisor 的 log。 如果一切顺利，你可以在浏览器中访问 Linux 服务器上的 awesome-python3-webapp 了 如果在开发环境更新了代码，只需要在命令行执行： 12$ fab build$ fab deploy 自动部署完成！刷新浏览器就可以看到服务器代码更新后的效果。","categories":["语言","Python"]},{"title":"JavaScript","path":"/2024/05/22/语言-JavaScript/","content":"示例分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384//在当前页面重新载入页面function reloadPageContent(reloadPage)&#123; window.location.replace(reloadPage);&#125;//按钮点击展开或隐藏function updateClick()&#123; $(document).ready((function() &#123;\t//ready函数来确保文档加载完毕后再执行代码(jquery库代码)\t$(&quot;a&quot;).click((function() &#123;\t//为文档中的所有&lt;a&gt;标签绑定点击事件 $(this).next(&quot;.menu&quot;).toggle()//找到当前被点击的&lt;a&gt;标签的下一个.menu类的元素，切换它的可见性\t&#125;)) &#125;))&#125;//获取并更新innerHTML中的内容function getInnerHTML(filePos)&#123; var xhr = new XMLHttpRequest(); xhr.open(&quot;GET&quot;, filePos, true); xhr.onreadystatechange = function() &#123;\tif (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; var htmlContent = xhr.responseText; document.getElementById(&quot;mainmenu&quot;).innerHTML = htmlContent; updateClick();\t&#125; &#125;; xhr.send();&#125;function showPicture()&#123; fetch(&#x27;http://124.222.246.202/get_picture?id=1&#x27;, &#123;method: &#x27;GET&#x27;,headers: &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;,&#125;) .then(response =&gt; response.text()) .then(data =&gt; &#123;document.getElementById(&quot;mainmenu&quot;).innerHTML=data&#125;)&#125;function openFile(filePos)&#123; var xhr = new XMLHttpRequest(); xhr.open(&quot;POST&quot;, &quot;http://124.222.246.202/getFileContent&quot;, true); xhr.setRequestHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); var message = &#123; filePos &#125;; var jsonMessage = JSON.stringify(message); xhr.onreadystatechange = function () &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; var responseContainer = document.getElementById(&quot;mainmenu&quot;); responseContainer.innerHTML = &#x27;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;2.css/github-markdown-css/github-markdown.css&quot;&gt;&lt;style&gt;.markdown-body &#123;box-sizing: border-box;min-width: 200px;max-width: 980px;margin: 0 auto;padding: 45px;&#125;@media (max-width: 767px) &#123;.markdown-body &#123;padding: 15px;&#125;&#125;&lt;/style&gt;&lt;article class=&quot;markdown-body&quot;&gt;&#x27;+marked.parse(xhr.responseText)+&#x27;&lt;/article&gt;&#x27;; &#125; &#125;; xhr.send(jsonMessage);&#125;function blogList() &#123; // 创建XMLHttpRequest对象 var xhr = new XMLHttpRequest(); // 配置请求，将消息发送到后端Python服务器 xhr.open(&quot;POST&quot;, &quot;http://124.222.246.202/getFileList&quot;, true); // 设置请求头，告诉服务器发送的是JSON数据 xhr.setRequestHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); // 创建要发送的消息对象 var message = &#123; &quot;message&quot;: &quot;Hello, backend!&quot; &#125;; // 将消息对象转换为JSON格式 var jsonMessage = JSON.stringify(message); // 处理响应 xhr.onreadystatechange = function () &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; // 在页面上显示后端返回的消息 var responseContainer = document.getElementById(&quot;mainmenu&quot;); responseContainer.innerHTML = &quot;后端返回的消息: &quot; + xhr.responseText; &#125; &#125;; // 发送请求 xhr.send(jsonMessage);&#125;","categories":["语言"]},{"title":"Python返回前端请求IP地址","path":"/2024/05/22/语言-Python-Python返回前端请求IP地址/","content":"前端 js 代码123456&lt;script&gt;\tfetch(&#x27;/get_ip&#x27;, &#123;method: &#x27;GET&#x27;,headers: &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;,&#125;) .then(response =&gt; response.text()) .then(data =&gt; &#123;document.getElementById(&quot;ip_addr&quot;).innerHTML=data&#125;)&lt;/script&gt;","categories":["语言","Python"]},{"title":"LNMP环境部署wordpress","path":"/2024/05/22/平台Platform-云服务器-LNMP环境部署wordpress/","content":"前言由于在利用 Docker 部署 wordpress 时发现，很多需要修改的文件都需要通过 docker-compose 的脚本映射到本地，不好修改，另外由于 docker 的属性，导致 docker 在关闭并重启后，数据会丢失，必须利用 volume 或者“data container”来实现数据持久化 在容器关闭之后可以利用“-v”或者“–volumes-from”重新使用以前的数据，docker 也可挂载宿主机磁盘目录，用来永久存储数据。 所以还是通过自己配置 LNMP 的基础运行环境，能够看到并修改所有文件的方式才比较放心。 目前 LNMP 环境的配置，可以通过多种方法： 通过宝塔面板，可视化配置 通过脚本，一键配置所有软件 各软件环境自己手动安装，手动配置 这次我们通过脚本配置，之后导入原来的 docker 中搭建的 wordpress 的所有数据。 LNMP 介绍LNMP 只是 wordpress 运行的基础环境，LNMP 是一种常用的 Web 服务器架构，它的名字代表了其中的四个组件：Linux、Nginx、MySQL&#x2F;MariaDB 和 PHP。这些组件分别扮演了不同的角色： Linux：操作系统，提供了基本的系统服务和资源管理； Nginx：Web 服务器，处理客户端请求并将其转发给后端的应用程序； MySQL&#x2F;MariaDB：关系型数据库，用于存储和管理应用程序的数据； PHP：服务器端编程语言，用于编写应用程序的业务逻辑。LNMP 架构的优点在于：高性能：Nginx 是一个高性能的 Web 服务器，能够处理大量并发请求；稳定可靠：Linux 是一个稳定可靠的操作系统，能够提供良好的系统服务和资源管理；易于扩展：MySQL&#x2F;MariaDB 是一个成熟的关系型数据库，支持高可用和分布式架构；灵活可定制：PHP 是一种灵活可定制的服务器端编程语言，能够满足不同的业务需求。 LNMP 架构被广泛应用于 Web 开发和运维领域，特别是在高并发和大数据场景下，具有良好的性能表现和可扩展性。 还有其余的诸如： LAMP 的全称是 Linux + Apache + MySQL + PHP LNAMP 的全称是 Linux + Nginx + Apache + MySQL + PHP 其中 Apache 是世界使用排名第一的 Web 服务器软件。 它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的 Web 服务器端软件之一。 安装 LNMP源项目地址 下载 LNMP 安装脚本（指定版本为 1.5） wget http://soft.vpser.net/lnmp/lnmp1.9.tar.gz 解压并执行 123tar zxf lnmp1.9.tar.gzcd lnmp1.9./install.sh lnmp 运行脚本后，首先会让你选择数据库的版本： MYSQL&#x2F;MariaDB 选好数据库，会让你设置数据库 root 用户的密码: 如果输入有错误需要删除，需要按住 Ctrl 再%","categories":["平台Platform","云服务器"]},{"title":"16-8禁食软件架构设计","path":"/2024/05/22/其他-软件设计-16-8禁食软件架构设计/","content":"介绍用于记录每日的禁食时间，保证不间断禁食时间保持十六个小时 如何提供奖励机制 功能记录 - 点击按钮开始计时 - 再次点击按钮结束计时 - 期间中途如果 APP 有退出情况，应记录中途退出情况，并能够续写禁食时间 程序启动时，开始时读取上次的计时状态和禁食日志 如果之前的禁食状态未为结束，根据中间经过的时间间隔继续计时，接着开始禁食 否则进入正常流程，等待重新开始计时 点击开始计时后 判断日志中是否已经有今日的禁食时间，是否覆盖？ 如果否，则不启动计时 如果是，则清除文件中已保存的禁食时间，启动定时器 定时器启动，实时写入当前的禁食数值及禁食状态 - 2023-07-26-10-10-10-1 点击结束计时后， 停止计时器 覆写当前时间和禁食时间以及禁食状态 - 2023-07-26-10-10-30-0 写入当前当前日期和禁食时间 - 2023-07-26-0-0-20 查询能够查询到每日的禁食时间 - 保存每日的禁食数据，如果有重复的禁食数据，弹窗提示，让用户选择哪条禁食数据有效 - 查询每日禁食数据，根据点击的日期显示禁食时长 - 表格显示禁食进度完成情况，绿色代表完成，红色代表未完成 目标建立每日目标及目标达成情况 - 表格显示每日目标及目标达成情况 设置 - 能够设置每日禁食时长 - 能够手动设立目标","categories":["其他","软件设计"]},{"title":"影视APP","path":"/2024/05/22/软件-音视频-影视APP/","content":"影视 APP 采用的都是用「套壳＋视频源」的模式，将壳体和视频源分开，接口也有逐渐发展为他人专门提供的趋势 TVBOXGithub 开源了一个名为 TVBox 的项目： o0HalfLife0o 最新测试版 APK https://github.com/o0HalfLife0o/TVBoxOSC/releases/ APP 设置 » 配置地址，我们需要在这里给 APP 添加视频源之后才能使用 YuanHsingYuanHsing 维护的 TVBOX接口项目 如果以上地址失效，你可以到原项目上找到 json 文件获取文件的 raw 地址进行添加，不过由于现在墙的存在，我们不能直接订阅 Github 原生文件地址，需要将链接稍作修改，改成经过 CDN 加速后的地址，才可以使用： jsDelivr 加速地址： https://gcore.jsdelivr.net/gh/YuanHsing/freed@master/TVBox/meow.json Statically 加速地址： https://cdn.staticaly.com/gh/YuanHsing/freed/master/TVBox/meow.json jsDelivr、Statically 这俩个加速服务还是挺稳的，不过具体文件名可能以后会有变化，如果文件名变化了，自行修改上面两个链接末尾的 meow.json 就行了 导入之后，返回一下首页，等待 jar 文件加载成功，再到设置 » 首页数据源 在代码托管平台上找视频源在 Github 上其实有很多程序员在维护自用的 TVBOX 接口，而 Github 上的代码多数都是公开的，搜索方法也很简单，在 github.com 上搜索关键词：TVBOX，然后再右上角 Sort 筛选这里，选择 Recently upload 最近更新 然一般我们只需要找到项目里面的 json 文件，然后点进去看一下 json 文件的具体代码，看看代码里面有没有关键词 TVBOX，有的话，就基本上就可以断定这是一个可用的 TVBOX 接口了，如果你有安装相关的 Github 加速油猴脚本，那直接从上面直接复制 json 文件的加速地址，添加到 TVBOX 就行了，如果没安装相关脚本的话，可以参照本文 1.1 节，将文件链接格式修改为 jsDelivr、Statically 等的加速链接即可使用，同理在 Gitee 上也能找到一些 TVBOX 相关的接口分享项目，虽然相关项目比较少，但优点是 Gitee.com 在国内可以直接访问，接口文件也是直接添加即可（注意是添加原始数据链接） TVBox 软件接口大全来源 某公众号在线TVBox软件接口大全 来源于导航站 风向标导航 海阔视界官方 Github海阔视界的 官方规则 Github 分享地址 你能在这里找到很多由官方维护与更新的规则文件，这里注意一下最后的更新时间，这里我们找一个最近不久才更新的规则，还是一样的：如果你有安装相关的 Github 加速油猴脚本，那直接从上面直接复制 json 文件的加速地址，如果没安装相关脚本的话，可以参照本文 1.1 节，先将文件链接格式修改为 jsDelivr、Statically 等的加速链接，比如这个规则的加速地址之一是： https://cdn.staticaly.com/gh/qiusunshine/hiker-rules/master/rules/2022-8-2.txt 但注意我们还不能直接就这样导入到海阔海阔视界，你需要在规则文件的链接前再加上一个前缀：海阔视界￥home_rule_url￥ 即我们将链接拼接成： 海阔视界￥home_rule_url￥https://cdn.staticaly.com/gh/qiusunshine/hiker-rules/master/rules/2022-8-2.txt 这样就可以将其导入到海阔视界了（如果导入后没反应，可以尝试多导入几次） 导入成功后，再回到 APP 主页，你就会发现上面多出了各种合集，而在这里就能轻松进行聚合影视搜索了 虽然他其实就是网页聚合搜索，但搭配上海阔影视不错的广告拦截效果，观看体验还是很不错的 微信公众号直接关注 APP 的官方公众号：新方圆小棉袄、海阔视界小棉袄这俩个公众号都时不时会分享海阔视界的规则，并且可以从公众号上一键复制 ZY-Player内置源已经全部失效，APP 下载链接： https://github.com/cuiocean/ZY-Player-APP YuanHsinghttps://github.com/YuanHsing/freed/tree/master/ZY-Player 虽然你可以到视频源文件写了 PC 两个字，但实际上是通用的，安卓端也可以使用还是一样的，由于现在墙的存在，我们不能直接订阅 Github 原生文件地址，需要将链接稍作修改，改成经过 CDN 加速后的地址，才可以使用： jsDelivr 加速地址： https://gcore.jsdelivr.net/gh/YuanHsing/freed@master/ZY-Player/ZY-Player-PC.json Statically 加速地址： https://cdn.staticaly.com/gh/YuanHsing/freed/master/ZY-Player/ZY-Player-PC.json 在代码托管平台上找视频源在代码托管平台上找 ZY-Player 的公开视频源，但 ZY-Player 就比较推荐到 Gitee 上找视频源了，相关的仓库会多一点，方法还是一样的很简单，在 Gitee.com 上搜索 ZY-Player，并按最近更新排序，随便点进一个项目，发现在根目录并没有找到 json 文件，没关系，看到有一个名为 resources（资源）的文件夹，点进去，果然里面有一个最近不久才更新的 json 文件，这个就是视频源，然后我们在源代码这里，点击原始数据，获取文件直链，将这个直链添加进 ZY-Player，然后就能在首页切换网站查看","categories":["软件","音视频"]},{"title":"TV Box源","path":"/2024/05/22/软件-音视频-TV-Box源/","content":"FongMi https://ghproxy.com/raw.githubusercontent.com/FongMi/CatVodSpider/main/json/config.json 巧技 (需关注公众号) http://pandown.pro/tvbox/tvbox.json 俊于 http://home.jundie.top:81/top98.json 霜辉月明 (py) https://ghproxy.com/raw.githubusercontent.com/lm317379829/PyramidStore/pyramid/py.json 小雅 (js) http://drpy.site/js1 菜妮丝 xBPQ https://tvbox.cainisi.cf 神器 https:&#x2F;&#x2F;神器每日推送.tk&#x2F;pz.json 饭太硬 http:&#x2F;&#x2F;饭太硬.ga&#x2F;x&#x2F;o.json 云星日记 https://maoyingshi.cc/tvbox/云星日记/1.m3u8 肥猫 http:&#x2F;&#x2F;肥猫.love","categories":["软件","音视频"]},{"title":"Docker介绍","path":"/2024/05/22/平台Platform-Docker-Docker介绍/","content":"介绍Docker 是一种流行的容器化平台，它可以帮助开发人员和运维人员更轻松地构建、交付和运行应用程序。 Docker 架构Docker 的架构包括以下组件： Docker 守护进程：运行在主机上的后台进程，负责管理 Docker 对象，如镜像、容器、网络和数据卷。 Docker 客户端：通过 Docker API 与 Docker 守护进程通信。 Docker 镜像：包含应用程序和其依赖项的只读文件系统。 Docker 容器：Docker 镜像的可运行实例。 Docker 仓库：用于存储 Docker 镜像的地方。 主要需要注意的是镜像IMAGE和容器CONTAINER 可以将镜像视为虚拟机的一个快照，镜像是容器的基础，定义了容器的基本配置和内容 容器，即为镜像的实例化内容，当启动一个容器时，Docker 会从镜像创建一个只读的文件系统层，并在其上添加一个可写层，容器中的所有更改和数据都存储在这个可写层上。 Docker 基本命令Docker 提供了一系列命令行工具，用于管理 Docker 容器和镜像，以及执行与容器相关的操作 以下是一些常用的 Docker 命令： docker images：列出本地所有的镜像。 docker rmi &lt;image&gt;：删除一个镜像。 docker pull &lt;image&gt;：从仓库中拉取一个镜像。 docker build -t &lt;image_name&gt; &lt;path_to_dockerfile&gt;：根据 Dockerfile 构建新的自定义镜像。 docker push &lt;image&gt;：将一个镜像推送到仓库中。 docker run &lt;image&gt;：根据指定的镜像创建并启动一个新的容器。 docker ps：列出当前正在运行的容器。加 -a 列出所有，包括运行中的和已经停止的 docker start &lt;container_id/container_name&gt;：启动已停止的容器。 docker stop &lt;container_id/container_name&gt;：停止运行中的容器。 docker restart &lt;container_id/container_name&gt;：重启容器。 docker rm &lt;container_id/container_name&gt;：删除指定容器。 docker logs &lt;container_id/container_name&gt;：查看容器的日志输出。 docker exec -it &lt;container_id/container_name&gt; &lt;command&gt;：在正在运行的容器中执行特定命令。 docker exec -it container /bin/bash 进入 container 容器中的命令行 docker inspect &lt;container_id/container_name&gt;：查看容器的详细信息，包括 IP 地址、端口映射等。 docker network ls：列出所有 Docker 网络。 docker volume ls：列出所有 Docker 卷。 DockerfileDockerfile 是一种文本文件，用于定义如何构建 Docker 镜像。包含了一系列的指令和参数，用于指导 Docker 引擎在基础镜像上添加应用程序代码、运行时环境、依赖项和配置文件等，最终生成一个新的 Docker 镜像。 以下是一个简单的 Dockerfile 示例： 123 FROM ubuntu:latest RUN apt-get update &amp;&amp; apt-get install -y nginx CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 该 Dockerfile 使用最新版本的 Ubuntu 镜像作为基础镜像，并在其中安装了 nginx。 一些 dockerfile 中的指令： FROM： 指定基础镜像。每个 Docker 镜像都是基于一个基础镜像构建的，这个指令用于设置构建的起点。 MAINTAINER： 设置镜像的作者信息，通常是作者的名字和电子邮件。 RUN： 在镜像构建过程中执行的命令。可以用于安装软件包、更新系统、设置环境等操作。 CMD： 设置容器启动时要执行的命令。如果在运行镜像时没有指定要执行的命令，则将执行这里设置的默认命令。 ENTRYPOINT： 设置容器启动时要执行的固定命令。与 CMD 类似，但可以将参数传递给 ENTRYPOINT 指定的命令。 COPY： 将本地文件复制到镜像中。 ADD： 类似于 COPY，但它还支持复制网络资源和自动解压缩压缩文件。 WORKDIR： 设置容器的工作目录，后续的指令将在这个目录下执行。 EXPOSE： 指定容器运行时监听的端口号，但并不会自动将端口映射到宿主机。 ENV： 设置环境变量，可以在容器内部访问。 ARG： 声明构建时的参数，构建时可以通过 –build-arg 参数传递。 VOLUME： 创建一个可以从宿主机或其他容器挂载的挂载点。 USER： 设置运行镜像的用户。 ONBUILD： 定义一个触发器，在子镜像构建时执行特定的操作。 Docker Compose（重点）Docker Compose 是一个工具，用于定义和运行多个 Docker 容器的应用程序。 docker-compose 需要编写 yml 脚本，定义配置以及多个容器之间的依赖关系和网络连接 * 注意：yml 文件对缩进有严格要求 通过命令控制 docker-compose以下是一个简单的 docker-compose.yml 文件示例： 123456789101112131415161718192021222324252627282930version: &quot;3.9&quot;services: db: image: mysql:5.7 volumes: - ./db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - ./wordpress_data:/var/www/html ports: - &quot;80:80&quot; - &quot;443:443&quot; restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: &#123;&#125; wordpress_data: &#123;&#125; 这里用到了 mysql:5.7 和 wordpress:latest 两个 Docker 镜像，WordPress 镜像依赖 depends_on 于 MySQL 镜像。 restart: always 参数表明容器服务宕机后会自动重启。 MYSQL_ROOT_PASSWORD 为数据库的 root 密码，MYSQL_PASSWORD 为数据库的普通用户密码，请自行修改，对应的 WORDPRESS_DB_PASSWORD 也要同时修改。MYSQL_USER 为数据库普通用户的用户名，如果有需要也可以修改，对应的 WORDPRESS_DB_USER 也要同时修改。 80:80 的意思是把宿主机的 80 端口映射到容器内部的 80 端口。如需通过其他端口访问，只需修改前面的 80。比如，我要通过 8080 端口访问 WordPress，填写 8080:80 即可。 volumes 会将主机中指定的目录 ./wordpress_data 和容器中的指定目录 /var/www/html 共享，类似于虚拟机中的共享文件夹。并且在容器销毁后目录中的文件依旧存在。 在 Docker Compose 版本 3 及以上的配置中，不再使用 links 字段来定义容器之间的连接。取而代之的是使用 Docker 网络来实现容器之间的通信。现在，Docker Compose 默认创建一个项目级别的默认网络，其中每个服务（service）都可以使用它。 只需保证 db 和 wordpress 属于同一个项目（即在同一个 docker-compose.yml 文件中定义），它们将自动连接到默认网络，并可以通过服务名称（db 和 wordpress）相互访问。 docker-compose 脚本Docker Compose官方文档 docker-compose 命令docker-compose up -d：根据当前目录的 yml 文件配置启动容器，-d 参数代表在后台运行 docker-compose ps：查看运行状态 docker-compose stop：停止运行 docker-compose restart：重启 docker-compose restart service-name：重启单个服务 docker-compose exec service-name sh：进入容器命令行 docker-compose logs [service-name]：查看容器运行 log -f指定文件名 Docker 安装及使用利用 docker 配置 wordpress 个人博客安装在安装 docker 时，发现 docker 有多个版本： docker.io：debian&#x2F;ubuntu 官方基于 docker 社区源码封装的版本，将 docker 的依赖直接转接到主系统上 docker-ce：docker.com 放出来的社区版，使用 golang 将依赖封装在一个包中 docker-ee：docker.com 维护的商业版一般使用docker.io 安装 docker.io： 1sudo apt install docker.io 安装 docker-compose： 1sudo apt install docker-compose 使用 创建一个文件夹用于存储 volume 以及 yml 文件： 1mkdir wordpress &amp;&amp; cd wordpress 编辑 yml 文件（yml 文件内容参照 Docker介绍）： 1vi myBlog.yml 启动容器（初次启动时会下载镜像，速度较慢）： 1sudo docker-compose up -d 如果有错误，查看启动日志： 1sudo docker-compose logs 如果需要进入容器内命令行： 1sudo docker-compose exec -it &lt;容器名称&gt; /bin/bash 停止并删除容器 1sudo docker-compose down Docker 镜像和容器的构建、导出docker build、docker export、docker save 和 docker commit 是 Docker 的一些常用命令，它们在 Docker 镜像和容器的构建、导出和保存等方面有不同的作用。 docker build作用：使用 Dockerfile 定义构建规则，构建一个新的 Docker 镜像。 描述：docker build 命令是用于根据 Dockerfile 创建一个新的 Docker 镜像。 Dockerfile 中包含了构建镜像所需的指令，例如安装软件、配置环境等。 docker build 命令会根据 Dockerfile 的指令逐步构建镜像的不同层，最终生成一个可执行的镜像。 docker export作用：导出 Docker 容器的文件系统作为一个 tar 归档文件。 docker export 命令将 Docker 容器导出为一个 tar 文件，其中包含容器中的文件系统和元数据，但不包括镜像的元数据和层。这意味着，使用 docker export 命令导出的文件无法用作 Docker 镜像的源文件，只能用于将容器迁移到另一个 Docker 主机或将容器中的文件系统导出到本地。 例如，如果你想要将一个正在运行的 WordPress 容器迁移到另一个 Docker 主机，可以使用 docker export 命令将容器导出为一个 tar 文件，然后将该文件传输到目标主机并使用 docker import 命令导入为一个新的 Docker 镜像。 1docker export &lt;container_id&gt; &gt; wordpress.tar docker save作用：将 Docker 镜像保存为 tar 归档文件。 docker save 命令将 Docker 镜像导出为一个 tar 文件，其中包含镜像的元数据和层，可以用作 Docker 镜像的源文件。这意味着，使用 docker save 命令导出的文件可以用于在不同的 Docker 主机之间共享镜像，或者将镜像备份到本地。 例如，如果你想要将一个名为 wordpress:latest 的 Docker 镜像备份到本地，可以使用 docker save 命令将镜像导出为一个 tar 文件。 docker save -o wordpress.tar wordpress:latest 总之，docker export 命令导出的文件只包含容器中的文件系统和元数据，而 docker save 命令导出的文件包含完整的镜像元数据和层，可以用于在不同的 Docker 主机之间共享镜像或备份到本地。 docker commit作用：将容器的变更保存为新的 Docker 镜像。 描述：docker commit 命令允许你将一个正在运行的容器的变更保存为一个新的 Docker 镜像。它会创建一个新的镜像层，将容器中的变更添加到这个层中，最终生成一个新的镜像。 例如：遇到了一个 docker 环境，需要带回来自己调试，打包正在运行的容器，快速拖环境跑路 1234docker ps //获取正在运行的容器,找到IDdocker commit -a &quot;test&quot; -m &quot;wordpress&quot; &lt;容器名称或ID&gt; //将容器打包成镜像docker save -o ./wordpress.tar &lt;容器名称或ID&gt; //拖到本地docker load -i hackgod-demo.tar //导入镜像 Docker 将容器打包成镜像以及导入导出可以使用 docker commit 命令来完成，docker commit 可以从容器创建一个新的镜像。 语法格式docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 参数说明-a : 提交的镜像作者；-c : 使用 Dockerfile 指令来创建镜像；-m : 提交时的说明文字；-p : 在 commit 时，将容器暂停 容器打包成镜像：将容器 a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。 12docker stop 2a2a11e2c043docker commit -a &quot;alway.com&quot; -m &quot;socks5&quot; 2a2a11e2c043 alway.com/wangwei/socks5:v1 导入在镜像包所在的文件夹下操作docker load --input uu.tar(也可以使用docker load -i uu.tar或者 docker load &lt; uu.tar) 或 docker load &lt; uu.tar 导出（镜像打包） docker save &gt; /root/docker_images/uu.tar ubuntu:latest 或 docker save /root/docker_images/ubuntu:latest &gt; uu.tar 或 docker save -o /root/docker_images/[镜像名].tar [镜像名]:latest 启动镜像 docker run -it -d --name container-name -pp1:p1-pp2:p2new-image-name docker run -it -d --name qinglong -p 5700:5700 alway.com/wangwei/qinglong:v1 联系和区别docker build 和 docker commit 都用于构建 Docker 镜像，但它们的方式不同。 *docker build 是通过 Dockerfile 定义构建规则，逐步构建镜像，而 docker commit 是将容器的变更直接保存为新的镜像。 docker export 和 docker save 都用于导出 Docker 镜像或容器的文件系统，但它们导出的内容不同。 *docker export 导出容器的文件系统作为归档文件，但不包含镜像的元数据和历史记录，不能用于还原容器。而 docker save 导出完整的 Docker 镜像，包含了元数据和文件系统，可以用于还原镜像。 docker build 和 docker save 都用于创建 Docker 镜像 docker export 用于导出容器的文件系统，而 docker commit 用于将容器的变更保存为新的镜像。","categories":["平台Platform","Docker"]},{"title":"微信公众号后端配置","path":"/2024/05/22/平台Platform-云服务器-微信公众号后端配置/","content":"12345678910111213141516@app.route(&#x27;/wechat&#x27;, methods=[&#x27;GET&#x27;])def wechat_signature(): data = request.args echostr = data.get(&#x27;echostr&#x27;) signature = data.get(&#x27;signature&#x27;) timestamp = data.get(&#x27;timestamp&#x27;) nonce = data.get(&quot;nonce&quot;) if not signature or not timestamp or not nonce: return False tmp_str = &quot;&quot;.join(sorted([&#x27;liuluhua&#x27;, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(&#x27;UTF-8&#x27;)).hexdigest() if tmp_str == signature: return echostr else: print(&quot;Failed&quot;) return &quot;Failed&quot; 12345678910111213141516171819202122232425262728293031@app.route(&#x27;/wechat&#x27;, methods=[&#x27;POST&#x27;])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值​ req = xmltodict.parse(xml)[&#x27;xml&#x27;] # 判断post过来的数据中数据类型是不是文本​ if &#x27;text&#x27; == req.get(&#x27;MsgType&#x27;): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式​ resp = &#123;​ &#x27;ToUserName&#x27;:req.get(&#x27;FromUserName&#x27;),​ &#x27;FromUserName&#x27;:req.get(&#x27;ToUserName&#x27;),​ &#x27;CreateTime&#x27;:int(time.time()),​ &#x27;MsgType&#x27;:&#x27;text&#x27;,​ &#x27;Content&#x27;:req.get(&#x27;Content&#x27;)​ &#125; # 把构造的字典转换成xml格式​ xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) # print(req.get(&#x27;Content&#x27;)) # 返回数据​ return xml​ else:​ resp = &#123;​ &#x27;ToUserName&#x27;: req.get(&#x27;FromUserName&#x27;, &#x27;&#x27;),​ &#x27;FromUserName&#x27;: req.get(&#x27;ToUserName&#x27;, &#x27;&#x27;),​ &#x27;CreateTime&#x27;: int(time.time()),​ &#x27;MsgType&#x27;: &#x27;text&#x27;,​ &#x27;Content&#x27;: &#x27;I LOVE ITCAST&#x27;​ &#125;​ xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;)​ return xml","categories":["平台Platform","云服务器"]},{"title":"植物大战僵尸游戏架构","path":"/2024/05/22/其他-软件设计-植物大战僵尸游戏架构/","content":"","categories":["其他","软件设计"]},{"title":"远程访问方案","path":"/2024/05/22/软件-内网穿透-远程访问方案/","content":"获取公网 IP+DDNS 解析什么是 DDNSDDNS 的意思是动态域名解析。是解决有公网 IP ，但是公网 IP 不固定的问题，用固定的域名代替动态变化的公网 IP。 无公网 IP 网络环境用内网穿透方案，即类似如 nat123 内网映射方式，将内网 IP 映射成域名（自动生成二级域名或用自己域名）地址，然后通过域名来访问。 DDNS (Dynamic Domain Name System) 是一种可以动态更新域名解析的服务，它可以让您的域名指向一个动态 IP 地址，而不是一个固定的 IP 地址。它可以让您的域名跟随您的设备，而不需要您每次更改 IP 地址时都去更新域名解析。 适用情况： 路由器是公网 IP，但是公网 IP 不固定 检测方法： 用百度搜索 IP，百度会显示当前的 IP 地址，把这个 IP 地址和路由器的 IP 地址作比较，如果一致，说明是公网 IP，如果不一致，说明是运营商用一个 IP 然后经过多层 NAT 之后分配的内网 IP。 隧道穿透 —frp 前提：需求公网服务器，将内网端口映射到公网服务器，通过公网服务器 + 端口的形式访问内网端口。需要了解配置 frps 和 frpc 的配置文件如何配置，针对特定端口进行开放 下载 frp 文件，根据实际要部署的环境的架构利用 wget 下载相应版本 项目地址 https://github.com/fatedier/frp 安卓版本仓库地址 https://github.com/FrpcCluster/frpc-Android 下载完成后 tar -xvf 解压，进入目录，修改 fps.toml 配置文件 文档地址 https://gofrp.org/zh-cn/docs/ frps 服务端配置安装前需 uname -a 查看云服务器的外网处理器架构,根据不同的架构下载不同 frp 版本，x86_64 的 下载 后缀带 amd 的即可 wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz 解压后编辑 frps.toml 文件 12345678910111213141516171819202122#bindAddr = &quot;0.0.0.0&quot;bindPort = 9085 //内网设备绑定的端口# auth tokenauth.token = &quot;******&quot; //接入验证码，需要和设备端保持一致# Configure the web server to enable the dashboard for frps.# 使能dashboard(非必要)# 使能控制面板# 控制面板必须配置port# dashboard is available only if webServer.port is set.webServer.addr = &quot;0.0.0.0&quot;webServer.port = 9086webServer.user = &quot;lemonade&quot;webServer.password = &quot;lemonade&quot;# console or real logFile path like ./frps.log # 使能log(非必要)# 输入的日志文件log.to = &quot;./frps.log&quot; //日志存储位置# trace, debug, info, warn, errorlog.level = &quot;info&quot; //存储等级log.maxDays = 3 //时间 netstat -ntlp 查看端口占用情况 启动 frps 服务 ./frps -c ./frps.toml， 需要注意服务器开通指定端口的防火墙 frpc 客户端配置123456789101112131415161718192021222324 //具有公网IP的服务器地址serverAddr = &quot;124.222.246.***&quot; //接入端口serverPort = 9085//接入tokenauth.token=&quot;******&quot;[[proxies]]//将本设备的5000端口映射到服务器的9087端口name = &quot;frp-nas&quot;//类型type = &quot;tcp&quot; localIP = &quot;0.0.0.0&quot;//本地端口localPort = 5000//公网端口remotePort = 9087[[proxies]]name = &quot;frp-nas-ssh&quot;type = &quot;tcp&quot;localIP = &quot;0.0.0.0&quot;localPort = 9090remotePort = 9088 启动脚本 VBS1234567Dim ws_alistDim ws_frpSet ws_alist = Wscript.CreateObject(&quot;Wscript.Shell&quot;)ws_alist.run &quot;alist.exe server&quot;,vbhideSet ws_frp = Wscript.CreateObject(&quot;Wscript.Shell&quot;)ws_frp.run &quot;.\\frpc.exe -c .\\frpc.toml&quot;,vbhideWscript.quit 微软的 devtunalcloudflare控制台页面 https://dash.cloudflare.com Tailscale免费版 构建虚拟局域网 —ZeroTier、Tailscale 以及蒲公英 在 zerotier 创建虚拟局域网，客户端安装后复制虚拟局域网 ID 加入即可实现访问，但是连接速度不稳定 进阶方式可以自己搭建 moon 服务器和 planet 服务器，但是也需要公网服务器 私有部署zerotier-planet服务 一分钟自建zerotier-planet 学习文档内网穿透 - Jonnyan的原创笔记 - 亖亖亖 (mrdoc.fun)","categories":["软件","内网穿透"]},{"title":"RSS","path":"/2024/05/22/语言-RSS/","content":"Rsshub 的 docker 部署下载 docker-compose.yml wget https://raw.githubusercontent.com/DIYgod/RSSHub/master/docker-compose.yml 检查是否有需要修改的配置 vi docker-compose.yml # or your favorite editor 创建 redis 卷 Create a docker volume to persist Redis caches docker volume create redis-data 启动 docker-compose up -d Channel1234567891011121314151617&lt;channel&gt; 参考手册 元素 描述&lt;category&gt; 可选的。为 feed 定义所属的一个或多个种类。&lt;cloud&gt; 可选的。注册进程，以获得 feed 更新的立即通知。&lt;copyright&gt; 可选。告知版权资料。&lt;description&gt; 必需的。描述频道。&lt;docs&gt; 可选的。规定指向当前 RSS 文件所用格式说明的 URL。&lt;generator&gt; 可选的。规定用于生成 feed 的程序。&lt;image&gt; 可选的。在聚合器呈现某个 feed 时，显示一个图像。&lt;language&gt; 可选的。规定编写 feed 所用的语言。&lt;lastBuildDate&gt; 可选的。定义 feed 内容的最后修改日期。&lt;link&gt; 必需的。定义指向频道的超链接。&lt;managingEditor&gt; 可选的。定义 feed 内容编辑的电子邮件地址。&lt;pubDate&gt; 可选的。为 feed 的内容定义最后发布日期。&lt;rating&gt; 可选的。feed 的 PICS 级别。&lt;skipDays&gt; 可选的。规定忽略 feed 更新的天。&lt;skipHours&gt; 可选的。规定忽略 feed 更新的小时。&lt;textInput&gt; 可选的。规定应当与 feed 一同显示的文本输入域。 Item12345678910&lt;item&gt; 参考手册 元素 描述&lt;author&gt; 可选的。规定项目作者的电子邮件地址。&lt;category&gt; 可选的。定义项目所属的一个或多个类别。&lt;comments&gt; 可选的。允许项目连接到有关此项目的注释（文件）。&lt;description&gt; 必需的。描述此项目。&lt;enclosure&gt; 可选的。允许将一个媒体文件导入一个项中。&lt;guid&gt; 可选的。为项目定义一个唯一的标识符。&lt;link&gt; 必需的。定义指向此项目的超链接。&lt;pubDate&gt; 可选的。定义此项目的最后发布日期。&lt;source&gt; 可选的。为此项目指定一个第三方来源。 验证可以在 http://www.feedvalidator.org 找到很好的验证器。 RSS 阅读器功能文字 字体 字号 背景 翻页 图片 缩放 移动 下载 视频 播放&#x2F;暂停 快进 进度条 音量 下载 设置 订阅 自动&#x2F;手动同步 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式eg. https://rsshub.app/6v123/latestMovies &#x3D;&#x3D;&#x3D;&gt;&#96;6v123_latestMovies eg. https://rsshub.app/t66y/20/2 &#x3D;&#x3D;&#x3D;&gt;&#96;t66y_20_2 页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["语言"]},{"title":"设置flask后端CORS跨域访问","path":"/2024/05/22/语言-Python-设置flask后端CORS跨域访问/","content":"设置前后端分离 环境搭建flask 项目地址 https://tutorial.helloflask.com/ 安装 flask 和 flask-cors cors 用于允许服务器进行跨域访问 12pip install flaskpip install flask-cors 浏览器 js 前端代码123456789101112131415161718192021function SendUrlToServer(url, method)&#123;\tlet requestUrl = &#x27;http://124.222.246.202:8081/fetch-sub-url?url=&#x27;+url;\t/*let requestUrl = ?url=&#x27;http://127.0.0.1:8081/fetch-sub-url*/\tfetch(requestUrl, &#123;\tmethod: method,\theaders: &#123;\t&#x27;Content-Type&#x27;: &#x27;application/json&#x27;\t&#125;,\t/*body: JSON.stringify(&#123; url: url &#125;)*/\t&#125;).then(response =&gt; response.text()).then(data =&gt; &#123;\tconsole.log(&#x27;Response from server:&#x27;);&#125;).catch(error =&gt; &#123;\tconsole.error(&#x27;Error sending data:&#x27;, error);&#125;);&#125;function RSS() &#123;\tSendUrlToServer(&quot;https://rsshub.app/bilibili/ranking/0/3/1&quot;, &#x27;GET&#x27;);&#125; 服务器端 python 代码12345678910111213141516171819202122232425262728293031323334353637from flask import Flask, request, jsonifyfrom flask_cors import CORSimport requestsimport feedparser##get python pathimport ospython_path = os.environ.get(&quot;PYTHONPATH&quot;)print(&quot;PYTHONPATH:&quot;, python_path)##get endapp = Flask(__name__)#CORS(app, resources=&#123;r&quot;/*&quot;: &#123;&quot;origins&quot;: &quot;http://127.0.0.1:80&quot;&#125;&#125;) # 允许指定的来源访问CORS(app)@app.route(&#x27;/fetch-sub-url&#x27;, methods=[&#x27;GET&#x27;,&#x27;POST&#x27;])def fetch_sub_url(): #data = request.get_json() #url = data.get(&#x27;url&#x27;) #url = &#x27;https://www.baidu.com&#x27; url = request.args.get(&#x27;url&#x27;) print (&quot;current url is ===&gt;&quot;+url) try: response = requests.get(url) response_text = response.text return response_text except requests.exceptions.RequestException as e: return jsonify(&#123;&#x27;error&#x27;: str(e)&#125;) # 解析RSS feed #feed = feedparser.parse(url) # 打印feed的标题 #print(&quot;Feed Title:&quot;, feed.feed.title) # 打印feed中的条目 #for entry in feed.entries: # print(&quot; Title:&quot;, entry.title) # print(&quot;Link:&quot;, entry.link) # print(&quot;description:&quot;, entry.description) #return feedif __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=8081) 后端服务开机自启 systemd&#x2F;etc&#x2F;systemd&#x2F;system 启动 12345678910111213[Unit]Description=Start Python BackEnd With HtmlAfter=multi-user.target[Service]WorkingDirectory=/home/ubuntuType=idle#ExecStart=/home/ubuntu/html/BackEnd/start_backend.shExecStart=/usr/bin/python3 /home/ubuntu/html/BackEnd/main.pyUser=ubuntuGroup=ubuntuEnvironment=&quot;PYTHONPATH=/home/ubuntu/.local/lib/python3.10/site-packages&quot;[Install]WantedBy=multi-user.target 将服务单元文件复制到 systemd 目录： 将您的服务单元文件复制到&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;目录下。您可以使用 sudo 命令进行拷贝，确保文件的权限设置正确。 sudo cp your-service-name.service /etc/systemd/system/ 重新加载 systemd 配置： 您需要重新加载 systemd 配置以使更改生效。 sudo systemctl daemon-reload 启用服务： 要启用服务，使其在系统启动时自动启动，可以运行以下命令： sudo systemctl enable your-service-name.service 这将会在适当的运行级别下创建符号链接，以便服务在系统启动时自动启动。 启动服务： 如果您想立即启动服务，可以运行以下命令： sudo systemctl start your-service-name.service 这将启动您的服务。 完整后端处理代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonimport socketimport asynciofrom aiohttp import web# root_dir = &#x27;/home/ubuntu/html/&#x27;# pic_dir = &#x27;0.res/Picture/&#x27;# name = &#x27;1&#x27;#request.args.get(&#x27;id&#x27;)# act_addr = os.path.join(root_dir,pic_dir,name);# fileNameList = &#x27;&#x27;# for file_name in os.listdir(act_addr):# fileNameList += pic_dir+name+&quot;/&quot;+file_name# print(fileNameList)app = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[&quot;http://124.222.246.202&quot;,&quot;http://127.0.0.1&quot;])HOME_PATH = &quot;/home/ubuntu/BlogData/&quot;#@app.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])#def home_index():# index_html = open(&quot;/home/ubuntu/liuluhua.github.io/index.html&quot;, &quot;r&quot;)# print (&quot;文件名: &quot;, index_html.name)# print (&quot;是否已关闭 : &quot;, index_html.closed)# print (&quot;访问模式 : &quot;, index_html.mode)# return index_html.read()@app.route(&#x27;/get_ip&#x27;, methods=[&#x27;GET&#x27;])def ip_addr(): ip_addr = request.remote_addr api_url = f&#x27;https://ipinfo.io/&#123;ip_addr&#125;/json&#x27; response = requests.get(api_url) data = response.json() ret_data = &quot;来自&quot;+data.get(&#x27;country&#x27;)+&quot; &quot;+data.get(&#x27;region&#x27;)+&quot;的&quot;+data.get(&#x27;ip&#x27;)+&quot;朋友&quot;; return ret_data@app.route(&#x27;/get_picture&#x27;, methods=[&#x27;GET&#x27;])def picture_show(): pic_dir = &#x27;0.res/Picture/&#x27; name = request.args.get(&#x27;id&#x27;) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = &#x27;&#x27; for file_name in os.listdir(act_addr): fileNameList += f&#x27;&lt;img src=&quot;&#123;pic_dir&#125;&#123;name&#125;/&#123;file_name&#125;&quot; alt=&quot;&#123;file_name&#125;&quot;&gt;&#x27; print(file_name) print (fileNameList) return (fileNameList)@app.route(&#x27;/getFileContent&#x27;, methods=[&#x27;POST&#x27;])def getFileContent(): filePath = request.get_json().get(&#x27;filePos&#x27;) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(&#x27;/getFileList&#x27;, methods=[&#x27;POST&#x27;])def getFileList(): #return json.dumps(request.get_json()) + getDirList(HOME_PATH+&quot;Python&quot;); return getDirList(HOME_PATH+&quot;Python&quot;);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(&#x27;&lt;details&gt;&lt;summary&gt;&lt;span class=&quot;tree-item&quot;&gt;&#x27;) ret_list.append(entry.name+&#x27;&lt;/span&gt;&lt;/summary&gt;&#x27;) getDirList(entry.path, ret_list, depth+1) ret_list.append(&#x27;&lt;/details&gt;&#x27;) else: file_pos = dir_path.replace(&quot;/home/ubuntu/html&quot;,&quot;&quot;) ret_list.append(f&#x27;&lt;details&gt;&lt;summary&gt; \\ &lt;span class=&quot;tree-item&quot; onclick=&quot;openFile(\\&#x27;&#123;file_pos&#125;/&#123;entry.name&#125;\\&#x27;)&quot;&gt;&#x27; + entry.name+&#x27;&lt;/summary&gt;&lt;/details&gt;&#x27;) return &quot; &quot;.join(ret_list)@app.route(&#x27;/signin&#x27;, methods=[&#x27;POST&#x27;])def signin(): print(&quot;post signin&quot;) username = request.form.get(&#x27;username&#x27;) password = request.form.get(&#x27;password&#x27;) button_clicked = request.form.get(&#x27;signin&#x27;) # 或者使用 &#x27;signup&#x27; #jsonify(&#123;&quot;response&quot;: &quot;test&quot;&#125;) # 确定哪个按钮被点击了 if button_clicked == &#x27;signin&#x27;: # 处理登录操作 return f&#x27;Login: Username=&#123;username&#125;, Password=&#123;password&#125;&#x27; elif button_clicked == &#x27;signup&#x27;: # 处理注册操作 return f&#x27;Signup: Username=&#123;username&#125;, Password=&#123;password&#125;&#x27; else: # 没有按钮被点击或者未知按钮名称 return &#x27;Unknown button pressed&#x27;@app.route(&#x27;/wechat&#x27;, methods=[&#x27;GET&#x27;])def wechat_signature(): data = request.args echostr = data.get(&#x27;echostr&#x27;) signature = data.get(&#x27;signature&#x27;) timestamp = data.get(&#x27;timestamp&#x27;) nonce = data.get(&quot;nonce&quot;) if not signature or not timestamp or not nonce: return False tmp_str = &quot;&quot;.join(sorted([&#x27;******&#x27;, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(&#x27;UTF-8&#x27;)).hexdigest() if tmp_str == signature: return echostr else: print(&quot;Failed&quot;) return &quot;Failed&quot;@app.route(&#x27;/wechat&#x27;, methods=[&#x27;POST&#x27;])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[&#x27;xml&#x27;] # 判断post过来的数据中数据类型是不是文本 if &#x27;text&#x27; == req.get(&#x27;MsgType&#x27;): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = &#123; &#x27;ToUserName&#x27;:req.get(&#x27;FromUserName&#x27;), &#x27;FromUserName&#x27;:req.get(&#x27;ToUserName&#x27;), &#x27;CreateTime&#x27;:int(time.time()), &#x27;MsgType&#x27;:&#x27;text&#x27;, &#x27;Content&#x27;:req.get(&#x27;Content&#x27;) &#125; # 把构造的字典转换成xml格式 xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) # print(req.get(&#x27;Content&#x27;)) # 返回数据 return xml else: resp = &#123; &#x27;ToUserName&#x27;: req.get(&#x27;FromUserName&#x27;, &#x27;&#x27;), &#x27;FromUserName&#x27;: req.get(&#x27;ToUserName&#x27;, &#x27;&#x27;), &#x27;CreateTime&#x27;: int(time.time()), &#x27;MsgType&#x27;: &#x27;text&#x27;, &#x27;Content&#x27;: &#x27;I LOVE ITCAST&#x27; &#125; xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) return xmlif __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;127.0.0.1&#x27;, port=9080)","categories":["语言","Python"]},{"title":"Obsidian笔记建设","path":"/2024/05/22/博客-Obsidian笔记建设/","content":"Obsidian 配置Ctrl+Shift+I 在控制台里可以查看详细日志，所有插件的日志都可以在这里看到 Hexo 忽略文件和文件夹由于 hexo 的文章只存在于 source 目录下，我们需要让 Obsidian 忽略其他文件的内容以优化性能以及减少不必要的搜索结果。具体的操作是在 设置-文件与链接-Exclude Files，将需要忽略的文件添加进去（尤其是 node_modules）。 Templater模板配置说明文档 https://silentvoid13.github.io/Templater/introduction.html 首先我们要创建模板，我们可以在 source 目录下创建 _obsidian 文件夹，并创建一篇 Post Template 的文章（md 文件），我们再创建新文章的时候，只需要点击侧边栏的『插入模板』按钮就可以快速生成 Front-matter 信息： 123456789101112131415161718---title: &lt;% tp.file.title %&gt;date: &lt;% tp.file.creation_date(format=&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;update: &lt;% tp.file.last_modified_date(&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;comments: truetags:categories:dg-publish: true---定义脚本function generateTimestampUrl() &#123; var timestamp = Math.round(new Date() / 1000); var url = timestamp.toString(36) return url; &#125; module.exports = generateTimestampUrl; osidian-git快捷键 Ctrl + P 打开命令面板，输入 open source control view 启用可视化操作面板 obsidian-pangu已用 Linter 替代 中英文之间加空格 Hidden Folder目录隐藏插件 FileTree左侧菜单出现了一个 File Tree 的 Tab 页，点击后就可以看到文件以树形的结构呈现，我们展开 source 文件夹，并右键 _post 文件夹，选择 Focuse on Folder 后，左侧的文件列表中就只会显示 _post 文件夹中的内容了 Github Publisher已使用整个仓库进行同步发布，不采用这种单页面发布形式 将 Obsidian 中的文章和本地附件上传到 Github 仓库，上传前可以指定文件目录、自定义内容替换等操作。 能将 Obsidian 仓库里的任意笔记自动或者手动同步到 GitHub 代码仓库的任意位置。首先设置好 Github 相关信息，包括 Github repository，用户名，token 以及 Branch。当然也可以在单个笔记文件里，通过文档属性（frontmatter），单独设置接收笔记上传的 Github 仓库信息（可以选择同一用户下的不同仓库，同一仓库下的不同位置）。 上传设置 设定上传的笔记存储在 Github 仓库的位置。因为我的 hexo 博客日志文件保存在 source&#x2F;posts 目录下，故选择 Fixed Folder，设定好默认上传到的目录。 文章发布 在文章文档属性添加一个 share 属性（可以根据需要在插件设置里改成其他任意名称），赋予值 true。文章写好后，share: true 右键发布。 ShellCommand可以解决 obsidian 无法打开 . 开头的默认文件的问题 再介绍个终极优化方案，之前我们执行命令是通过运行 bat 文件，而 Shell commands 可以在 Obsidian 中设置好命令，并通过 Obsidian 的命令面板或快捷键快速运行。 在插件设置面板中添加命令 运行博客： Shell commands 没有显示终端窗口的功能，所以需要我们启动 powershell 再传入命令 有了终端窗口我们才可以在窗口中按 Ctrl + C 关闭 Hexo 服务，否则它会一直占用端口 1start powershell &#x27;-NoExit -Command start http://localhost:4000 ; cd Blog ; hexo s&#x27; 打开站点和主题配置文件： 12start Blog/_config.ymlstart Blog/themes/butterfly4.3.1/_config.yml 然后修改默认执行环境为 PowerShell 5，可以为每个命令设置下别名，就是在命令面板显示的名字 Emo 插件用 PicGo 支持更多自定义设置 用于自托管图片 image auto upload plugin也是用于自托管图片 Linter 插件用户在保存笔记时按照一定的格式，格式化笔记，这里用到的功能： 保存笔记时自动插入 front-matter 进入 Linter 的设置，选择 YAML 设置，找到其中的插入 YAML 设置（ Insert YAML attributes），打开开关后，输入要插入的 front-matter 自动更新文件修改时间戳 进入 Linter 的设置，选择 YAML 设置，找到其中的 YAML 时间戳（ yaml-timestamp），设置为 Hexo 识别的 date 和 update 格式化笔记 主要的是一个不同语言中间的空格自动添加，进入 Linter 的设置，选择空格，找到其中的 Space between Chinese Japanese or Korean and English or numbers，打开即可 其他插件 Image Converter 转化图片格式，我统一转为 webp，并设置了图片分辨率大小。 Unique attachments 用于将附件的文件名统一为 “字母 + 数字”的格式,记着在配置里加入 webp 图片格式 Image Inserter 用于找图片，我用于设置文章封面，即设置 cover.image 属性。","categories":["博客"]},{"title":"ELF文件分析","path":"/2024/05/22/平台Platform-Linux-程序-ELF文件分析/","content":"","categories":["平台Platform","Linux","程序"]},{"title":"Qexo管理后端建设","path":"/2024/05/21/博客-Qexo管理后端建设/","content":"安装克隆 qexo 项目到本地 git clone https://github.com/Qexo/Qexo.git 编辑配置，以使用 Mysql 为例, 确认好安装相关依赖后在 manage.py 的同级目录下创建并修改 configs.py 12345678910111213141516import pymysql pymysql.install_as_MySQLdb() DOMAINS = [&quot;127.0.0.1&quot;, &quot;124.222.246.202&quot;] DATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;NAME&#x27;: &#x27;数据库表&#x27;, &#x27;USER&#x27;: &#x27;数据库用户名&#x27;, &#x27;PASSWORD&#x27;: &#x27;数据库密码&#x27;, &#x27;HOST&#x27;: &#x27;127.0.0.1&#x27;, &#x27;PORT&#x27;: &#x27;3306&#x27;, &#x27;OPTIONS&#x27;: &#123; &quot;init_command&quot;: &quot;SET sql_mode=&#x27;STRICT_TRANS_TABLES&#x27;&quot; &#125; &#125; &#125; 安装依赖 123pip3 install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate 启动 Qexo 博客管理后端 python3 manage.py runserver 0.0.0.0:9051 --noreload 访问公网 IP+ 端口即可打开管理页面 配置在 vercel 上配置","categories":["博客"]},{"title":"USB设备连接到WSL","path":"/2024/05/21/平台Platform-WSL-USB设备连接到WSL/","content":"在 WSL2 中连接 3D 打印机的 USB 端口，须将该设备从 windows 中挂载至 Linux 中，需要在 windows 环境中安装 usbipd usbipd GitHub 地址 https://github.com/dorssel/usbipd-win 安装 usbipd 12#在win命令行中执行winget install usbipd 安装环境 123##在你的wsl中执行sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 *usbipd: error: WSL ‘usbip’ client not correctly installed.重新执行此步骤 列出并挂载 win 中的设备到 linux 环境下 123# 在win终端中执行usbipd wsl listusbipd wsl attach --busid=4-1","categories":["平台Platform","WSL"]},{"title":"Vmware共享文件夹","path":"/2024/05/21/平台Platform-VMware-Vmware共享文件夹/","content":"查看共享的文件夹使用 vmware-hgfsclient 命令 输入 vmware-hgfsclient 显示共享文件夹名称 挂载共享文件夹使用 vmhgfs-fuse 命令 vmhgfs-fuse .host:/ShareDir /home/forlinx/ShareDir -o subtype=vmhgfs-fuse,allow_other 将主机下的 ShareDir 挂载到虚拟机的&#x2F;home&#x2F;forlinx&#x2F;ShareDir 文件夹下 在虚拟机中设置共享文件夹完成后，发现共享文件夹没有出现，执行 vmhgfs-fuse .host:/ /home/forlinx/ShareDir文件夹下 如果没有其他显示报错，就可以认为挂载成功了。 注意：&#x2F;mnt 文件夹下的 hgfs 是自己创建的，如果没有，可以用 mkdir /mnt/hgfs 命令创建。 直接用 ls 命令查看 ls /home/forlinx/ShareDir 显示挂载的共享文件夹内的文件内容已经同步，表示成功挂载。 自动挂载脚本创建一个 startShare.sh 写入 vmhgfs-fuse .host:/ /home/forlinx/ShareDir 加权限 chmod a+x startShare.sh 添加该脚本到自启中 启动文件另：如果不想每次重启后都挂载一遍的话，建议直接把挂载放入启动文件 首先，备份 /etc/fstab 文件 cp fstab fstab_bak 其次，编辑 fstab``vim fstab 在最后一句添加 12# mount hgfs.host:/kali_share /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0 然后就能够不用每次重启挂载一遍。","categories":["平台Platform","VMware"]},{"title":"3D打印控制命令","path":"/2024/05/21/其他-3D打印机-3D打印控制命令/","content":"G-Code 协议指令 https://marlinfw.org/meta/gcode/ 限位开关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令： QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确，如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） 123[stepper_X]endstop_pin: ^PE5 #修改前endstop_pin: ^!PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令 PID_CALIBRATE HEATER=heater_bed TARGET=100 它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速 M106 S64 ，然后发送命令 PID_CALIBRATE HEATER=extruder TARGET=245 它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。 其他使 Klipper 进入 “shutdown”（关闭）状态 M112 重新加载配置文件并重启 FIRMWARE_RESTART 保存配置文件 SAVE_CONFIG 查看使用的 printer.cfg 文件位置 ps -ef | grep klippy 获取位置 GET_POSITION 调平 QUAD_GANTRY_LEVEL GCode 协议指令Klipper 支持的 G-Codes 命令官方文档 https://www.klipper3d.org/G-Codes.html 部分我使用到的命令 命令 用途 M112 使 Klipper 进入 “shutdown”（关闭）状态 FIRMWARE_RESTART 重新加载配置文件并重启 SAVE_CONFIG 保存配置文件 GET_POSITION 获取位置 限位开关测试相关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令：QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确 如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） 123456 [stepper_X] endstop_pin: ^PE5 #修改前 endstop_pin: ^!PE5 #修改后 或 endstop_pin: PE5 #修改前 endstop_pin: ^PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令PID_CALIBRATE HEATER=heater_bed TARGET=100它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速（ M106 S64 ），然后发送命令PID_CALIBRATE HEATER=extruder TARGET=245它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。","categories":["其他","3D打印机"]},{"title":"3D打印相关软件","path":"/2024/05/21/其他-3D打印机-3D打印相关软件/","content":"系统固件KlipperKlipper 是一个高性能、灵活的 3D 打印机固件，它通过将一些计算工作转移到更强大的主机（如 Raspberry Pi）上来提高打印质量和速度。 MarlinMarlin 是目前最流行的 3D 打印机固件之一，支持广泛的硬件平台和 3D 打印机模型，具有丰富的功能和高度的可定制性。 控制软件fluiddFluidd 是一个基于网页的控制界面，用于管理和监控运行 Klipper 固件的 3D 打印机。它提供了用户友好的界面和实时监控功能。GitHub 地址: https://github.com/fluidd-core/fluidd安装手册: https://github.com/dw-0/kiauh Make-meMake-me 是一个通过 WiFi 控制 Replicator 2 打印机的开源项目，使用 GitHub 的聊天机器人 Hubot 来监控和完成打印任务。目前只支持 Mac 的 OS X。 Pepeteir-ServerPepeteir-Server 是一个新型的 Repeteir 产品，可以在 Raspberry Pi 上运行，支持控制多台打印机，内存消耗极小。它的网页操作界面简单，但不支持 Mac 和 PC。 OctoprintOctoprint 是一个完全基于网页的 3D 打印机控制程序，可以远程控制打印机，并通过网络摄像头监控打印过程。支持 Raspberry Pi。 BotqueueBotqueue 是一个开源的远程打印机控制软件，可以控制多台打印机。用户上传 .stl 文件后，软件会完成切片和打印工作。它支持为每台打印机设置独立的切片特性。 切片软件切片软件用于将 3D 模型按层切片，并生成用于打印的 G 代码。 CuraCura 由 Ultimaker 开发，兼容多种 3D 打印机。它不仅可以切片，还提供 3D 打印机控制界面，尤其适用于 Ultimaker 的 3D 打印机。 Slic3rSlic3r 是开源且免费的切片软件，因其快捷性和高度可定制化而广受欢迎。许多 3D 打印机制造商提供默认的 Slic3r 配置文件（.INI 文件），可以用作初始设置。 Skeinforge另一款非常流行的切片软件。同样开源，免费。 kisslicerKISSlicer 是一款跨平台的切片软件，名称源自 “Keep It Simple”（保持简单），目标是提供一个简单易用的界面。 PrintrunPrintrun 既是控制软件，也是切片软件，可以独立完成从切片到打印的整个过程。支持 Mac、Linux 和 PC 操作平台。 Repetier-HostRepetier-Host 与 Printrun 类似，是一款综合性软件，具有切片、零件定位和机器控制功能。用户界面相对更复杂但更直观，同样支持 Mac、Linux 和 PC 操作平台。 3D 建模软件BlenderBlender 是一款开源的 3D 建模软件，功能强大且完全免费。它不仅可以用于 3D 建模，还支持动画、渲染、雕刻等多种功能，适用于各种复杂的 3D 设计和制作。 TinkercadTinkercad 是一个由 Autodesk 开发的在线 3D 建模工具，适合初学者使用。它基于浏览器，无需下载软件，界面友好且易于使用。 Fusion 360Fusion 360 同样由 Autodesk 开发，是一款功能强大的云端 3D CAD、CAM 和 CAE 工具。它适用于从初学者到专业人士的各个层级，提供了全面的建模、仿真和制造功能。 SketchUpSketchUp 是一款广受欢迎的 3D 建模软件，以其直观的用户界面和易用性著称。它有免费版本（SketchUp Free）和专业版本（SketchUp Pro），适用于建筑、工程、游戏开发等多个领域。 FreeCADFreeCAD 是一款开源的 3D CAD 建模软件，适合于产品设计、机械工程以及建筑设计。它具有模块化的架构，可以通过插件扩展其功能。 SolidWorksSolidWorks 是一款由 Dassault Systèmes 开发的专业 3D CAD 软件，广泛应用于工程设计、产品设计和制造业。它功能强大，但价格较高，通常用于工业级应用。 OnshapeOnshape 是一个基于云的 3D CAD 建模软件，适用于团队协作和设计项目。它无需安装，直接在浏览器中运行，支持实时协作和版本控制。 OpenSCADOpenSCAD 是一款开源的 3D CAD 建模软件，适用于创建精确的 3D 模型。它使用编程语言来定义模型，适合那些有编程经验的用户。","categories":["其他","3D打印机"]},{"title":"Python","path":"/2024/05/21/语言-Python-Python/","content":"源码安装打开终端，使用以下命令更新软件包列表： 1sudo apt update 安装编译 Python 3.10 所需的依赖项： 1sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： 1wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码并进入解压后的目录： 12tar -xf Python-3.10.0.tgzcd Python-3.10.0 配置 Python 3.10 的编译选项： 1./configure --enable-optimizations 编译并安装 Python 3.10： 12make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： 1python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。","categories":["语言","Python"]},{"title":"pip下载网络问题","path":"/2024/05/21/语言-Python-pip下载网络问题/","content":"在使用 Python 安装包工具 pip 时经常会出现下载很慢的情况，这其中有很大一部分原因和 pip 的源有关，在我们安装 python 后，通常 python 解释器自带 pip 这个工具，但是这里 pip 是设置的默认源，也就是官方源：https://pypi.org/simple，这个源在国内的下载速度是很慢的，所以我们为了提高包的下载速度我们可以通过换源来实现。 临时使用参数可以在使用 pip 的时候加参数 -i https://pypi.tuna.tsinghua.edu.cn/simple 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple markdown 这样就会从清华这边的镜像去安装 markdown。 12345678910# 清华源pip install markdown -i https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip install markdown -i https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip install markdown -i http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip install markdown -i http://pypi.douban.com/simple/# 中国科学技术大学pip install markdown -i http://pypi.mirrors.ustc.edu.cn/simple/ 报错未添加信任源pip install beautifulsoup4 --trusted-host mirrors.aliyun.com 永久修改命令行12345678910# 清华源pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip config set global.index-url http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip config set global.index-url http://pypi.douban.com/simple/# 换回默认源pip config unset global.index-url 配置文件 Linux 下 ~/.pip/pip.conf Windows 下 &#96;&#96;%HOMEPATH%\\pip\\pip.ini&#96;内容如下： 12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 报错未添加信任源12[install]trusted-host=pypi.douban.com","categories":["语言","Python"]},{"title":"Linux下的CH34x串口识别","path":"/2024/05/21/通讯协议-串口-Linux下的CH34x串口识别/","content":"判断是否识别使用 lsusb 命令可以看到有 Bus 001 Device 005: ID 1a86:7523 QinHeng Electronics CH340 serial converter 是能识别出 ch34x 设备 检查串口是否被驱动加载输入指令 ls /dev/ttyUSB* 将会列出 USB 的加载情况。如果提示 No such file or directory 则是没有被驱动加载。 占用情况因报文件不存在错误，采用 dmesg|grep tty 命令检查发现，被 brltty 进程占用。 brltty 是一个后台进程（守护进程），为盲人提供对 Linux&#x2F;Unix 控制台的访问（当处于文本模式时），使用可刷新盲文显示。 移除该 apt remove brltty。 权限chmod a+rw /dev/ttyUSB0 即可 重装驱动下载最新的驱动 CH341SER_LINUXhttps://github.com/WCHSoftGroup/ch341ser_linux 解压后进入 “driver” 目录下 输入 make 命令编译驱动，正常编译完成后，将会看到生成了 ch341.ko 模块 输入 sudo make load 或者 sudo insmod ch341.ko 动态加载驱动（重启需要再次加载），或者输入 sudo make install 安装驱动（重启不丢失） 输入 sudo make unload 或者 sudo rmmod ch341.ko 或者 sudo make uninstall 卸载驱动 如果编译失败，可能是 ch34x.c 和实际内核版本不匹配，uname -r 可查看操作系统的发行版号，之后在 https://elixir.bootlin.com/linux/latest/source 中查找对应内核版本的源代码文件，一般位于 /drivers/usb/serial/ch341.c，替换后重新编译 如果 insmod 失败，查看 /lib/modules/$(uname -r)/kernel/drivers/usb/serial 目录下是否已经有了 ko 模块，将目录中生成 ko 文件复制到此处，使用 lsmod 查看模块","categories":["通讯协议","串口"]},{"title":"自启动","path":"/2024/05/21/平台Platform-Linux-其他-自启动/","content":"自启动服务在 /etc/systemd/system/my_startup.service 或 /usr/lib/systemd/system/startmyapp.service 编辑或创建一个服务文件 123456789101112131415[Unit] #服务的说明Description=nginx #描述服务After=network.target #描述服务类别[Service] #服务运行参数的设置Type=forking #是后台运行的形式PIDFile=/var/run/nginx.pidExecStartPre=/usr/bin/nginx -t -c ./nginx.confExecStart=/usr/bin/nginx -c ./nginx.conf #服务的具体运行命令ExecReload=/bin/kill -s HUP $MAINPID #重启命令ExecStop=/bin/kill -s QUIT $MAINPID #停止命令PrivateTmp=true #给服务分配独立的临时空间[Install] #运行级别下服务安装的相关设置WantedBy=multi-user.target #设置为多用户，系统运行级别为3 加载服务到自启动中 12sudo systemctl daemon-reloadsudo systemctl enable my_startup 操作服务 12345678910111213141516171819# 设置开机自启动systemctl enable startmyapp.service# 停止开机自启动systemctl disable startmyapp.service# 启动服务systemctl start startmyapp.service# 关闭服务systemctl stop startmyapp.service# 重新启动服务systemctl restart startmyapp.service# 重新加载服务配置文件systemctl reload startmyapp.service# 查看服务当前状态systemctl status startmyapp.service# 查看所有已启动的服务systemctl list-units --type=services# 查询服务是否开机启动systemctl is-enabled startmyapp.service 设置脚本1234567vi /etc/rc.local# 添加启动脚本/usr/bin/nginx startchmod +x /etc/rc.d/rc.local# /etc/rc.d/rc.local是/etc/rc.local的软连接","categories":["平台Platform","Linux","其他"]},{"title":"CAN和CANFD","path":"/2024/05/20/通讯协议-CAN-CAN和CANFD/","content":"CAN 和 CANFDCAN 与 CAN-FD 主要区别： 传输速率不同 CAN：最大传输速率 1Mbps。 CAN-FD：速率可变，仲裁比特率最高 1Mbps（与 CAN 相同），数据比特率最高 8Mbps。 数据长度不同 CAN：一帧数据最长 8 字节 CAN-FD：一帧数据最长 64 字节。 帧格式不同和 ID 长度不同。 CANFD 不存在远程帧，CAN 报文中的 RTR（用于区别标准帧与远程帧）被替换为 RRS（远程请求替代位，默认值为 0） CANFD 报文的标准帧和扩展帧—IDE 为 1 表示为扩展帧、为 0 表示标准帧 FDF 用于传统 CAN 报文和 CANFD 报文，FDF 位为 0 时为传统报文，FDF 为 1 时为 CANFD 报文 BRS 位速率切换为，BRS 位为 0 时 CANFD 速率保持恒定速率、BRS 位为 1 时 CANFD 的数据段会被切换到高速率。 ESI 错误状态指示位：CAN 报文中发送节点的错误状态只有该节点自己知道，CANFD 报文中可以通过 ESI 标志位来告诉其他节点该节点的错误状态，当 ESI 为 1 时表示发送节点处于被动错误状态、当 ESI 为 0 时表示发送节点处于主动错误状态 CRC：随着数据场的扩大，为了保证信息发送的质量，CAN FD 的 CRC 计算不仅要包括数据段的位，还包括来自 SOF 的 Stuff Count 和填充位。通过比较 CRC 的计算结果，可以判断接收节点是否能够正常接收。 在 CAN 中，CRC 的位数是 15 位，而在 CAN FD 中，CRC 场扩展到了 21 位。 当传输报文为 15 字节时：CRC 15 位 当传输数据为 16 字节或更少时：CRC 17 位 当传输数据超过 16 字节时：CRC 21 位","categories":["通讯协议","CAN"]},{"title":"CAN Open 笔记","path":"/2024/05/20/通讯协议-CAN-CAN-Open-笔记/","content":"项目地址 CANopenNode https://github.com/CANopenNode/CANopenNode CANopenLinux https://github.com/CANopenNode/CANopenLinux CANopenDemo https://github.com/CANopenNode/CANopenDemo CANopenEditor https://github.com/CANopenNode/CANopenEditor 帮助文档 CANopenLinux https://canopennode.github.io/CANopenLinux CANopenDemo https://canopennode.github.io/index.html CANopenCANopen 是一种基于 CAN（Controller Area Network）通信协议的高层协议和设备协议，定义了网络管理、设备配置、通信对象和应用对象等方面的标准，以确保不同设备之间的互操作性和通信的一致性。 协议CiA 通过一系列文件维护保持 CANopen 设备和通讯协议规定。基本配置由 CiA 301 规范定义。它被命名为“CANopen 应用层和通信配置”，并规定了 CANopen 应用层。这些规范包括： CANopen 对象字典中的数据类型、编码规则和对象 CANopen 通信服务和协议 CANopen 网络管理服务和协议 CANopen 通讯配置 – 物理层 预定义的通信对象标识符连接数集、与紧急事件相关的对象、时间标识和同步通信对象 此基本 CiA 301 配置规定由其他 CiA 文件进行了补充和扩展，为一些具体领域的设备和功能规定了设备、应用程序和接口配置。具体有以下几个部分，按照自身应用程序的实际情况引入。 CiA 302 – CANopen 附加应用层功能 CiA 303-1 – 布线和接头管脚分配 CiA 303-3 – 指示器规范 CiA 306 – CANopen 电子数据表规范 CiA 309 – 从其他网络接入 CANopen CiA 315 – CANopen 通用框架 CiA 401 – 通用 I&#x2F;O 模块的 CANopen 设备配置 CiA 402 – 驱动和运动控制的 CANopen 设备配置 OSI 模型CANopen 的 OSI 模型，Data link 和 Physical 是由 CAN 进行实现的，Presentation 和 Session 是由 CANopen 进行实现的。 物理层（Physical Layer）定义了物理介质、电气特性、传输速率和编码规范等。 数据链路层（Data Link Layer）划分数据帧、错误检测与纠正、流量控制。 网络层（Network Layer）提供路径选择、逻辑寻址、路由选择等功能。 传输层（Transport Layer）提供端到端的传输控制和错误恢复。 会话层（Session Layer）建立、维护、同步和恢复会话。 表示层（Presentation Layer）数据的加密、压缩、格式转换等。 应用层（Application Layer）用户数据交互和应用支持。 设备模型每个 CANopen 设备都遵循一个通用的设备模型，因此不同的设备能依据同样的 CANopen 标准。CANopen 设备模型的三个组成部分是： 通讯接口 对象字典 应用程序一个 CANopen 设备必须支持一定数量的网络管理服务 NMT，需要至少一个 SDO。每个生产或消费过程数据的设备需要至少一个 PDO。所有其它的通讯对象是可选的。 核心概念通讯模式 设备&#x2F;节点通信有 3 种模型：主设备&#x2F;从设备、客户端&#x2F;服务器和生产者&#x2F;消费者 通讯协议 协议用于通信，例如配置节点（SDO）或传输实时数据（PDO） 定义了设备之间通信的机制和方式，包括对象字典、服务数据对象（SDO）、过程数据对象（PDO）、网络管理（NMT）等。 设备状态 设备支持不同的状态。“主”节点可以更改“从”节点的状态，例如将其重置。 对象字典（Object Dictionary，OD） 每个 CANopen 设备都有一个对象字典，OD 带有指定设备配置的条目，类似于一个查找表，列出了设备中的所有参数和数据。对象字典包括通信对象和应用对象，使用 16 位索引和 8 位子索引进行标识。可以通过 SDO 访问。 EDS（Electronic Data Sheet） EDS 是用于 OD 的标准文件格式，允许更新设备的服务 通讯模式CANopen 通过不同的通讯模式在节点之间传输报文: 生产&#x2F;消费模式: 它是一个广播连接，以推送模式工作（信号生产节点向消费节点发送无任何特定要求的信息）和引入模式（消费节点向信号生产节点要求特定信息）。 用户机&#x2F;服务器模式: 通过 SDO 协议，用户节点向服务器节点要求数据（对象字典索引），然后服务器节点通过发送在指定索引处的对象内容来响应。 主机&#x2F;从机模式: 主机节点可在任何时候向从机节点发送或要求数据。例如：NMT 协议通信。 数据帧数据帧由帧头 + 数据区组成，帧头由功能 ID+NodeID+RTR(远程传输请求)构成。 11 位的 CAN ID 称为通信对象标识符（COB-ID），分为两个部分： 前 4 位等于功能代码 Function Code（代表一个 CANopen 通信对象） 后 7 位包含节点 IDNode ID CANopen 网络中使用的 COB-ID 标识符的预定义分配 数据区部分的定义就要通过 CANopen 中的重要概念，对象字典 OD 来实现。 对象字典 OD对象字典（OD）是 CANopen 协议的核心概念。它是一组预定义的 CANopen 对象，使用索引和子索引访问对象。对象字典提供了应用程序和设备之间的沟通方式，提供了配置该设备的途径，和与设备通信的方法。 所有 CANopen 节点必须具有对象字典（OD），对象字典是指含有描述的 CANopen 节点的 行为 的所有 参数 的 标准化结构。 设备（例如从设备）的 OD 条目可以由其他设备（例如主机）使用 SDO 通过 CAN 进行访问。例如，通过 SDO 可以使应用程序主机更改从属发送心跳的频率。 作为对象索引存储在对象字典中的信息包括： 通信和应用程序配置参数 标准化设备配置参数 制造商特定设备配置文件参数 设备配置静态数据类型 设备配置复杂数据类型 复杂和静态数据类型 制造商特定数据类型 其他 可以按照 CANopen 标准的指导，以预定义的方式添加自己特定的制造商配置和数据类型。制造商还可以通过扩展由标准设备配置和数据类型规范要求的标准设备功能，来增强其设备的功能。 主索引索引值低于 0x0FFF 的是一些数据类型定义。一个节点的对象字典的有关范围在 0x1000 到 0x9FFF 之间，该范围内定义了一系列称为子协议的文档，用于定义节点的通讯行为。 通讯子协议区域详细划分 通用通讯对象 OD 示例配置下图是一个 TPDO 的定义示例，该 TPDO 在主索引 0x1800 的子索引中定义该 TPDO 相关的通信参数，主要是 TPDO 的发送类型和触发事件等设置，同时在和 0x1800 地址对应的 0x1A00 中定义了映射参数，在该参数的子索引中，定义了具体的映射地址和对象。并给出了该 TPDO 消息在发送时数据区内容。 电子数据表（EDS）一个节点的对象字典是在电子数据文档（EDS：Electronic Data Sheet）中描述。 实际上，将使用适当的软件工具来配置&#x2F;管理复杂的 CANopen 网络。 一个电子数据表（EDS）是一个标准化的电子文件，描述为 CANopen 设备定义的通信功能和对象。此供应方生成的文件有 3 个区域： 关于 EDS 文件的信息 一般设备信息 具有默认变量的对象字典 EDS 文件可用作 CANopen 设备的配置和网络设置工具。 通讯协议通信对象CANopen 通信单元由必要的通信接口和协议软件组成，通过总线在节点之间进行通信对象的发送和接收。各种 CANopen 通信对象用于实现各种类型的通信，CANopen 协议定义了几种不同类型的通信对象，每种对象都用于特定的通信目的： 过程数据对象（PDO）：用于实时数据传输，具有高优先级和低延迟。PDO 传输的数据量小，但传输速度快，适用于传感器数据和控制命令等实时性要求高的场景。 服务数据对象（SDO）：用于非实时数据传输，如配置参数和大数据块的传输。SDO 传输的灵活性更大，但优先级较低，适用于设备配置和诊断等场景。 网络管理对象（NMT）：用于控制设备状态和网络操作模式，如启动、停止和复位设备。 同步对象（SYNC）：用于网络同步，确保所有节点在同一时间点进行操作。 时间戳对象（TIME）：提供时间参考，用于时间相关的操作。 紧急情况对象 (EMCY) ： 指定状态下可用的通讯对象及状态转换说明： 中括号内的字母表示处于不同状态那些通讯对象可以使用。 123456a. NMTb. Node Guard c. SDO d. Emergencye. PDO f. Boot-up 网络管理（NMT）所有的 CANopen 节点都有自己专属的 NMT 状态，而主站可以通过 NMT 去控制从站的状态。CANopen 的网络管理采取主机&#x2F;从机通信模式。整个网络被设置为一个“状态机”，其中一个设备被指定为 NMT 主机，其余设备被指定为 NMT 从机。NMT 主机控制和监控 NMT 从机的状态。通过 NMT 主机触发，NMT 从机进行状态转换，实现 CANopen 网络的各个阶段。 NMT 服务用于通过 NMT 命令来控制 CANopen 设备的状态。只有 NMT-Master 节点能够传送 NMT Module Control 报文。所有从设备必须支持 NMT 模块控制服务。NMT Module Control 消息不需要应答。为了更改状态，NMT 主设备发送 COBID+2 字节的消息。 COB-ID 为 0（function code&#x3D;0 和 node ID&#x3D;0），优先级为最高。 第一个 CAN 数据字节 Requested State 包含请求的状态 第二个 CAN 数据字节包含目标节点的节点 ID。节点 ID 0 表示广播命令。所有从节点都处理此消息。 通过具体的 NMT 协议，如启动协议、模块控制协议、心跳协议（Heartbeat Protocol）和节点监测，主机向从机发出状态更改命令，进行这些状态转换。NMT 主机向特定节点或所有节点发送 NMT 命令代码以改变状态。 在预运行状态下，应用程序配置工具可以使用SDO 通信，配置 NMT 从机和设置参数。由于设备尚未开始运行，因此在此状态下不能使用 PDO 通信。 一旦状态从预运行变为运行状态，节点中的所有通信对象都将变为活跃状态，并且运行节点之间均可进行 PDO 和 SDO 通信。在此阶段，也可以通过 SDO 访问对象字典。当节点状态更改为停止时，PDO 和 SDO 通信都将停止。 实际状态取值 步骤 Byte 0 取值（命令） 状态 （2） 01 operation （3） 02 stop （4） 80 pre-operation （5） 81 reset app （6） 82 reset communication 示例1234# node 0x6 进入 `operational` 模式000 01 06# 所有节点进入 `pre-operational` 模式000 80 00 服务数据对象（SDO）SDO 提供了直接访问 CANopen 设备对象字典的入口，入口条件包括数据类型及大小。 访问者被称作客户端(client)，对象字典被访问且提供所请求服务的 CANopen 设备别称作服务器(server)。任何类型的 SDO 传输都由客户端发起，数据字典 OD 持有者是服务端，客户端和服务端都可以主动中止传输。通常情况下 CAN 总线网络中只有一个客户端。 客户的 CAN 报文和服务器的应答 CAN 报文总是包含 8 字节数据（尽管不是所有的数据字节都一定有意义）。一个客户的请求一定有来自服务器的应答。如果超时没有确认，则客户端节点将会重新发送原报文。 SDO 服务用于访问&#x2F;更改 CANopen 设备的对象字典中的值。允许 CANopen 节点通过 CAN 网络读取另一个节点的对象字典&#x2F;编辑值。下载（Download）是指对对象字典进行写操作，上传（Upload）指对对象字典进行读操作。 客户端节点可以通过以下 CAN 帧广播来启动 SDO 下载到节点 5，这将触发节点 5（并被其他节点忽略）。SDO 客户端的“接收”（即请求）CAN 帧如下所示： SDO 消息变量数据区 Byte 说明： Byte0 命令字节，主要定义了以下内容： CCS（客户端命令说明符，Client Command Specifier）描述传输类型（下载 download&#x2F;上载 upload） n 是数据字节 4-7 中不包含数据的 bytes （如果设置了 e＆s 则有效） 如果设置，e 表示 快速传输(所有数据在单个 CAN 帧中)&#x2F;分段传输 如果设置，s 表示数据大小显示在 n 中 Byte1+Byte2 主索引字节（16 位）确认 OD 主索引 Byte3 子索引字节（8 位）确认 OD 子索引 Byte4-7 包含实际的数据内容 一旦节点（客户端）发送了 CAN 帧，从节点 5（服务端）便会通过 RSDO 进行响应，并带有 COB-ID585。该响应包含索引&#x2F;子索引和 4 个空数据字节。自然地，如果客户端节点请求上传（即从节点 5 OD 读取数据），则节点 5 将以字节 4-7 中包含的相关数据进行响应。 SDO 灵活，但会带来大量输出，使其不适用于实时操作数据。同时数据只能包含在后续 4 个字节中，对于较大的数据方案，无法一次传输完毕。因此 SDO 中实现了 2 种传送机制，两种传送机制实际包含 4 个请求&#x2F;应答协议，共有 5 个协议如下： 快速传送（Expedited transfer） ： 最多传输 4 字节数据 启动域下载 （Initiate Domain Download） 启动域上传 （Initiate Domain Upload） 分段传送（Segmented transfer） ： 传输数据长度大于 4 字节 域分段下载（Download Domain Segment） 域分段上传 （Upload Domain Segment） 域传送中止（Abort Domain Transfer）。 快速 SDOCommand specifier(CS)命令符: 0x40 读取命令 0x2F 写一个字节 0x4F 返回值响应一个字节 0x2B 写两个字节 0x4B 返回值响应两个字节 0x27 写三个字节 0x47 返回值响应三个字节 0x23 写四个字节 0x43 返回值响应四个字节 0x60 写成功应答 0x80 异常响应 启动域下载（Initiate Domain Download） Bit 7 6 5 4 3 2 1 0 客户端 0 0 1 - n n e s 服务器 0 1 1 - - - - n ： 如果 e=1 且 s=1，则有效，否则为 0；表示数据部分中无意义数据的字节数（字节 8－n 到 7 数据无意义）。 e ： 0 &#x3D; 正常传送，1 &#x3D; 加速传送（数据在一个帧中）。 s ： 是否指明数据长度，0 &#x3D; 数据长度未指明，1 &#x3D; 数据长度指明。 e &#x3D; 0， s &#x3D; 0： 由 CiA 保留。 e &#x3D; 0， s &#x3D; 1 ： 数据字节为字节计数器，byte 4 是数据低位部分（LSB），byte 7 是数据高位部分（MSB）。 e &#x3D; 1 ： 数据字节为将要下载（download）的数据。 启动域上传（Initiate Domain Upload） Bit 7 6 5 4 3 2 1 0 客户端 0 1 0 - - - - - 服务器 0 1 0 - n n e s n，e，s： 与启动域下载相同。 分段 SDO域分段下载（Download Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 0 0 t n n n c 服务器 0 0 1 t - - - - n ：无意义的数据字节数。如果没有指明段长度，则为 0。 c ： 0 &#x3D; 有后续分段需要 download，1 &#x3D; 最后一个段。 t ： 触发位，后续每个分段交替清零和置位（第一次传送为 0，等效于 request&#x2F;response）。 域分段上传（Upload Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 1 1 t - - - - 服务器 0 0 0 t n n n c n，c，t ： 与域分段下载相同。 示例通讯示例 -upload 数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 40 00 14 02 00 00 00 00 若成功，应答： 585 4F 00 14 02 FE 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 40 02 18 01 00 00 00 00 若成功，应答：585 60 02 18 01 08 02 12 60 通讯示例 -download数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 2F 00 14 02 FE 00 00 00 若成功，应答： 585 60 00 14 02 00 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 23 02 18 01 08 02 12 60 若成功，应答：585 60 02 18 01 00 00 00 00 过程数据对象（PDO）PDO 属于过程数据，即单向传输，无需接收节点回应 CAN 报文来确认，从通讯术语上来说是属于“生产消费”模型。、生产者“生产数据”，并使用 Transmit PDO（TPDO）将其传输到“消费者”（主用户）。相反，它可以通过 Receive PDO（RPDO）从使用者接收数据。 PDO 服务用于在设备之间传输实时数据，例如来自温度传感器的温度数据。PDO 承载大量信息，被视为最重要的 CANopen 协议。PDO 消息可以包含 8 个完整字节的数据，并且它可以在单个帧中包含多个对象参数值。因此在 PDO 服务中用 1 帧完成 SDO 至少需要 4 帧的操作。 带有特定 11 位 CAN 标识符的 TPDO 由一个设备发送，并作为 RPDO 由零个或多个设备接收。每个 PDO 在对象字典中用 2 个对象描述： PDO 通讯参数：包含哪个 COB-ID 将被 PDO 使用，传输类型，禁止时间和定时器周期。在索引 0x1400+ 和 0x1800+ 的对象字典中。 PDO 映射参数：包含一个对象字典中对象的列表，这些对象映射到 PDO 里，包括它们的数据长度（in bits）。生产者和消费者必须知道这个映射，以解释 PDO 内容。在索引 0x1600+ 和 0x1A00+ 的对象字典中。 生产者节点可以被配置为每 100ms 响应消费者所广播的 SYNC 触发。然后，节点 5 可以例如在下面广播，以 COB-ID 185 的 TPDO： 注意数据区部分 3 个参数值的打包方式，这些值是由数据字典中对应的映射结构决定了一个 PDO 的数据类型和映射关系。 通信参数定义了该设备所使用的 COB-ID、传输类型、定时周期等。RPDO 通讯参数位于对象字典索引的 0x1400 to 0x15FF，TPDO 通讯参数位于对象字典索引的 0x1800 to 0x19FF。每条索引代表一个 PDO 的通信参数集，其中的子索引分别指向具体的各种参数。PDO 消息的内容是预定义的（或者在网络启动时配置的）。 Number of entries 参数条目数量：即本索引中有几条参数； COB-ID：即这个 PDO 发出或者接收的对应 CAN 帧 ID； 发送类型：即这个 PDO 发送或者接收的传输形式，通常使用循环同步和异步制造商特定事件较多； Inhibit time 生产禁止约束时间(1&#x2F;10ms)：约束 PDO 发送的最小间隔，避免导致总线负载剧烈增加，比如数字量输入过快，导致状态改变发送的 TPDO 频繁发送，总线负载加大，所以需要一个约束时间来进行“滤波”，这个时间单位为 0.1ms； Event timer 事件定时器触发的时间(单位 ms)：定时发送的 PDO，它的定时时间，如果这个时间为 0，则这个 PDO 为事件改变发送。 SYNC start value 同步起始值：同步传输的 PDO，收到诺干个同步包后，才进行发送，这个同步起始值就是同步包数量。比如设置为 2，即收到 2 个同步包后才进行发送。 发送类型PDO 可以有多种发送类型： 同步（通过接收 SYNC 对象实现同步） 非周期：远程帧预触发传送或设备子协议中规定的对象特定事件预触发传送。 周期：传送在每 1 到 240 个 SYNC 消息后触发。 异步 远程帧触发传送。通过发送与 PDO 的 COB-ID 相同的远程帧来触发 PDO 发送 由设备子协议中规定的对象特定事件触发传送。（基本采用这种，例如定时传输，数据变化传输等） 由传输类型定义的不同 PDO 传输模式，传输类型为 PDO 通讯参数对象的一部分，由 8 位无符号整数定义。 间隔时间一个 PDO 可以指定一个禁止时间，即定义两个连续 PDO 传输的最小间隔时间，避免由于高优先级信息的数据量太大，始终占据总线，而使其它优先级较低的数据无力竞争总线的问题。禁止时间由 16 位无符号整数定义，单位 100us。 定时周期一个 PDO 可以指定一个事件定时周期，当超过定时时间后，一个 PDO 传输可以被触发（不需要触发位）。事件定时周期由 16 位无符号整数定义，单位 1ms。 映射参数RPDO 通讯参数 1400h to 15FFh，映射参数 1600h to 17FFh，数据存放为 2000h 之后厂商自定义区域； TPDO 通讯参数 1800h to 19FFh，映射参数 1A00h to 1BFFh，数据存放为 2000h 之后厂商自定义区域。 包含了一个对象字典中的对象列表，这些对象映射到相应的 PDO，其中包括数据的长度（单位，位），对于生产者和消费者都必须要知道这个映射参数，才能够正确的解释 PDO 内容。就是将通信参数、应用数据和具体 CAN 报文中数据联系起来。 子索引 0：PDO 中映射应用程序对象的数量： 值 0：映射被禁用。 值 1：子索引 0x01 有效。 值 2-8: 子索引 0x01 至 (0x02 至 0x08) 有效。 子索引 1-8： 应用对象 1-8： 位 16-31：索引 位 8-15：子索引 位 0-7：数据长度（位） 示例示例设备配置 节点 ID: 0x01 第二个 Transmit PDO (TPDO2): TPDO2 的 COB-ID: 0x280 + Node_ID &#x3D; 0x281 对象字典（Object Dictionary）定义： 0x1801: TPDO2 通信参数 子索引 0x00: 0x02 (表示有 2 个子索引) 子索引 0x01: 0x00000281 (TPDO2 的 COB-ID, 使能) 子索引 0x02: 0x00 (传输类型，假设为 0x00 表示同步传输) 0x1A01: TPDO2 映射参数 子索引 0x00: 0x02 (映射对象数量，表示有两个对象映射到这个 TPDO) 子索引 0x01: 0x60000208 (映射对象 0x6000，子索引 0x02，8 位) 子索引 0x02: 0x64010110 (映射对象 0x6401，子索引 0x01，16 位) 假设当前设备中的数据如下： 对象 0x6000，子索引 0x02: 0xAB 对象 0x6401，子索引 0x01: 0x1234 TPDO2 实际发送的 CANopen 数据帧报文由以下 3 个字节组成： Byte 0: 0xAB Byte 1: 0x34 (低 8 位) Byte 2: 0x12 (高 8 位) 实际的 CANopen 数据帧：CAN ID: 0x281 Data: [0xAB, 0x34, 0x12] 设置一个 TPDO Index 1800 + n，subindex 01 ，COB_ID（通讯对象的标识符）：包含 CAN-ID 和附加控制位的标识符 Index 1800 + n，subindex 02， 写传输类型 t， t &#x3D; 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t &#x3D; FD ：收到 PDO 请求后 t &#x3D; FE ：事件驱动（制造商指定） t &#x3D; FF ：事件传输，节点自发传输 PDO Index 1800 + n， subindex 03，抑制时间。 如果传输类型设置为 FE 和 FF，它是最小的 PDO 传输间隔，单位 100us，值为 0 禁用抑制时间。PDO 报文需要延时 t × 100us 的时间才发出，以此避免在多 PDO 报文同时发出时，引起的时间冲突 。 Index 1800 + n， subindex 05，时间定时器。 如果传输类型设置为 FE 和 FF，它是 PDO 传输间隔，单位 ms，值为 0 禁用。t &#x3D;0xC8，200ms。 Index 1A00 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 18 02 FF 00 00 00 设置索引 Index 1800，事件传输 605 2F 00 18 05 C8 00 00 00 设置索引 Index 1800，时间间隔 200ms 605 2F 00 1A 00 00 00 00 00 设置子索引禁用 605 23 00 1A 01 10 00 30 400x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 23 00 1A 02 20 00 10 200x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） 605 2F 00 1A 00 02 00 00 00 设置映射数量，用多少设多少，这里用了 2 个 设置一个 RPDO Index 1400 + n, subindex 01 ，COB_ID（通讯对象的标识符） Index 1400 + n, subindex 02，写传输类型 t， t &#x3D; 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t &#x3D; FD ：收到 PDO 请求后 t &#x3D; FE ：事件驱动（制造商指定） t &#x3D; FF ：事件传输，节点自发传输 PDO Index 1600 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 14 02 FF 00 00 00 设置索引 Index 1400，事件传输 605 2F 00 16 00 00 00 00 00 设置子索引禁用 605 23 00 16 01 10 00 30 40 设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 2F 00 16 00 01 00 00 00 设置映射数量，用多少设多少，这里用了 01 定义映射时，先设置子索引禁用；再设置相应映射；然后设置映射数量对于 TPDO 来说，其通信参数中的 COB-ID 是自身的 COB-ID，当发送 TPDO 时用来表明这个 TPDO 是谁发出的。对于 RPDO 来说，其通信参数的 COB-ID 是发送方的 COB-ID，用来表示自己只接受某个 CAN 节点发过来的 TPDO。 同步（SYNC）SYNC 消息通常由应用程序主机触发。每个节点都以该同步报文作为 PDO 触发参数，因此该同步报文的 COB-ID 具有比较高的优先级以及最短的传输时间。一般选用 0x80 作为同步报文的 CAN-ID，将 SYNC 消息（COB-ID 080）发送到 CANopen 网络。 在网络范围内同步（尤其在驱动应用中）：在整个网络范围内当前输入值准同时保存，随后传送（如果需要），根据前一个 SYNC 后接收到的报文更新输出值。 主从模式：SYNC 主节点定时发送 SYNC 对象，SYNC 从节点收到后同步执行任务。 在 SYNC 报文传送后，在给定的时间窗口内传送一个同步 PDO。 用 CAL 中基本变量类型的 CMS 对象实现。 CANopen 建议用一个最高优先级的 COB-ID 以保证同步信号正常传送。SYNC 报文可以不传送数据以使报文尽可能短。 一般同步报文由 NMT 主机发出，CAN 报文的数据为 0 字节。但如果一个网络内有 2 个同步机制，就需要设置不同的同步节拍，比如某些节点按 1 个同步帧发送 1 次 PDO，其他的节点收到 2 个同步帧才发送 1 次 PDO，所以这里 PDO 参数中的同步起始值就起了作用。 在同步协议中，有 3 个约束条件： 同步命令：0x1005 中规定了同步帧的命令为 0x80； 通讯循环周期：索引 0x1006 规定了同步帧的循环周期； 同步窗口时间：索引 0x1007 约束了同步帧发送后，从节点发送 PDO 的时效，即在这个时间内发送的 PDO 才有效，超过时间的 PDO 将被丢弃。 示例配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值） 23 05 10 00 80 00 00 00 读取 1006 信息 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms &#x3D; 100000us） 23 06 10 00 A0 86 01 00 时间戳（TIME-stamp）时间标记对象（Time Stamp），NMT 主机发送自身的时钟，为网络各个节点提供公共的时间参考，即网络对时，这在故障诊断中非常需要。 时间戳协议采用广播方式，无需节点应答，CAN-ID 为 0x100，数据长度为 6，数据为当前时刻与 1984 年 1 月 1 日 0 时的时间差。节点将此时间存储在对象字典 1012h 的索引中。 主机发出带有 CAN ID 100 的 TIME 消息，TIME 服务包含一个 6 字节的日期和时间信息。其中最初的 4 个数据字节包含午夜之后的毫秒数，随后的 2 个字节包含自 1984 年 1 月 1 日以来的天数。 紧急情况（EMCY）紧急报文协议（Emergency protocol）用于设备发生致命错误（例如传感器故障）的情况，从而使其可以向网络的其余部分指示此错误。 受影响的节点以高优先级向网络发送发送设备内部错误代码，提示 NMT 主站。紧急报文属于诊断性报文，一般不会影响 CANopen 通讯，其 CAN-ID 存储在 0x1014 的索引中，一般会定义为 0x080 + node-ID，数据包含 8 个字节，例如，节点 5 具有 COB-ID 085 + 数据字节，数据字节包含有关错误的信息，可以查找厂商定义的错误代码。 紧急信息的内容如下 Bytes 0…1： CO_EM_errorCode_t，在本例中为 0x5000（设备硬件） Bytes 2：CO_errorRegister_t，本例中为 0x01（通用错误） Bytes 3：CO_EM_errorStatusBits_t 中的错误条件索引，本例中为 0x2F（CO_EM_NON_VOLATILE_MEMORY - 访问非易失性设备内存时出错） Bytes 4…7：附加信息参数，本例中为 0x00000014 或 0x00000074 紧急信息由 CO_errorReport() 函数内部触发。您可以在 CO_EM_NON_VOLATILE_MEMORY 的源代码中查找紧急信息的来源。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不等于零，则禁止节点进入 NMT 运行状态，并且不能与其交换 PDO。 节点监测NMT 主机定期使用远程帧询问从机的当前状态，并将其与网络数据库中记录的早期状态相比较。任何不匹配和缺少 PDO 传输的状态都会以适当的错误代码表示，然后应用程序将采取适当的操作，如设备重置或错误标识。这称为节点监测，是通过使用节点监测协议得以实现。 NMT 从机使用一种称为生命监测的技术，通过在预定义的时间间隔里，内部检查节点监测帧的接收，来检测 NMT 主机的缺失。 现代设备设计使用 Heartbeat 协议进行节点监视，其中 NMT 从设备（Heartbeat Producer 心跳发出者）将周期性地向 NMT 主设备（Heartbeat Consumer 心跳使用者）发送 Heartbeat 报文。 这些报文之间的间隔是可配置的，并在主、从两个设备的对象字典中 Heartbeat producer time（心跳产生时间）对象上都进行设置。如果心跳报文在此时间限制内未到达，则发出者将被视为关机，使用者将采取补救措施，如设备重置或错误显示。 当一个 Heartbeat 节点启动后它的 Boot-up 报文是其第一个 Heartbeat 报文。Heartbeat 消费者通常是 NMT-Master 节点，它为每个 Heartbeat 节点设定一个超时值，当超时发生时采取相应动作。 示例读取心跳时间设置 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 2B 17 10 00 E8 03 00 00 Master 节点发送远程帧（无数据）NMT-Master -&gt; NMT-Slave COB-ID &#x3D; 0x700 + Node_ID NMT-Slave 节点发送如下报文应答 NMT-Master &lt;- NMT-Slave COB-ID &#x3D; 0x700 + Node_ID Byte0 &#x3D; Bit 7-0 : 状态 LSSLSS（Layer Setting Services）是一个用于配置和管理 CANopen 设备的一种服务。它提供了一些特定的功能，主要用于设备的初始化和配置，例如设置节点 ID 和波特率。LSS 对于在生产、调试和运行过程中配置 CANopen 设备非常有用。 LSS 的主要功能 设置节点 ID： 在 CANopen 网络中，每个节点都有一个唯一的节点 ID，范围为 1 到 127。LSS 允许动态设置或修改节点 ID，而不需要物理访问设备。这在设备初始安装和替换时特别有用。 设置波特率： CANopen 网络中的所有节点必须使用相同的波特率进行通信。LSS 允许动态修改设备的波特率，以便在不同的网络条件下进行适应和优化。 设备识别： LSS 可以用于识别网络中的设备。通过 LSS 服务，可以查询设备的唯一标识符（例如制造商代码、产品代码、序列号等），从而实现设备的识别和管理。 LSS 服务的主要操作 Switch Mode Global： 切换所有节点到配置模式或操作模式。 Switch Mode Selective： 选择性地切换特定节点到配置模式或操作模式。 Configure Node-ID： 设置节点 ID。 Configure Bit Timing Parameters： 设置 CAN 总线的波特率参数。 Identify Remote Slave： 识别网络中的设备，读取其唯一标识符。 LSS 协议的示例假设我们需要将一个设备的节点 ID 设置为 0x02，并将波特率设置为 250 kbps。以下是使用 LSS 的步骤： 切换到配置模式： 发送 LSS Switch Mode Selective 命令，将目标设备切换到配置模式。 设置节点 ID： 使用 LSS Configure Node-ID 命令，设置设备的节点 ID。 设置波特率： 使用 LSS Configure Bit Timing Parameters 命令，设置设备的波特率。 切换到操作模式： 发送 LSS Switch Mode Global 命令，将所有设备切换到操作模式。 LSS 消息格式LSS 消息使用特定的 CAN 标识符和数据格式。以下是 LSS Switch Mode Selective 命令的示例： CAN ID：0x7E5（LSS 主站到从站） 数据：0x04 0x00 0x00 0x00 0x00 0x00 0x00 0x00（切换到配置模式） 设置节点 ID 的命令： CAN ID：0x7E5 数据：0x11 0x02 0x00 0x00 0x00 0x00 0x00 0x00（设置节点 ID 为 0x02） 设置波特率的命令： CAN ID：0x7E5 数据：0x13 0x03 0x00 0x00 0x00 0x00 0x00 0x00（设置波特率为 250 kbps，假设 0x03 表示 250 kbps）","categories":["通讯协议","CAN"]},{"title":"USB权限设置","path":"/2024/05/20/通讯协议-USB-USB权限设置/","content":"因 Linux 系统下将涉及到 usb 底层驱动的调用，运行时，一定要加 sudo 获取权限运行，否则 USB 设备没有权限操作。 现通过创建 UDEV 规则，配置 USB 权限后，可以调用指定设备不加权限运行。 输入 lsusb，查看当前的 USB 设备的 ID，确定需要配置的 USB。 创建一个新的 udev 规则。名称取为：99-myusb.rules sudo vi /etc/udev/rules.d/99-myusb.rules 在 99-myusb.rules 文件中，输入以下内容 12##ACTION==&quot;add&quot;,SUBSYSTEMS==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;04d8&quot;, ATTRS&#123;idProduct&#125;==&quot;0053&quot;, GROUP=&quot;users&quot;, MODE=&quot;0777&quot; 这条 udev 规则的作用是，当供应商 ID 为 04d8 且产品 ID 为 0053 的 USB 设备插入系统时，将该设备的用户组设置为 users，并赋予所有用户读、写、执行的全部权限。 插拔一下 USBCAN 设备或重启一下电脑后，即可不加 sudo 权限运行程序了 对某个特定 USB 设备设置权限。每当这个设备插入系统时，规则会自动应用。 ACTION==&quot;add&quot;：这表示规则在设备添加（插入）时生效。udev 可以根据不同的动作（如添加、移除等）触发规则，add 动作指设备插入时。 SUBSYSTEMS==&quot;usb&quot;：表示规则适用于 USB 子系统的设备。udev 管理系统中的设备，子系统用于分类，USB 是其中一种。 ATTRS&#123;idVendor&#125;==&quot;04d8&quot;：表示设备的供应商 ID（Vendor ID）为 04d8。每个 USB 设备都有唯一的供应商 ID，用于标识设备的制造商。 ATTRS&#123;idProduct&#125;==&quot;0053&quot;：表示设备的产品 ID（Product ID）为 0053。每个供应商的不同产品有不同的产品 ID，用于区分供应商的各个设备。 GROUP=&quot;users&quot;：表示设备的用户组被设置为 users。这决定了哪些用户组的成员有权访问该设备。 MODE=&quot;0777&quot;：表示设备的权限模式被设置为 0777，即所有用户对该设备都有读、写、执行权限。","categories":["通讯协议","USB"]},{"title":"Socket套接字","path":"/2024/05/20/通讯协议-网络-Socket套接字/","content":"Socket 最初是作为网络上不同主机之间进程的通信接口，后来应用越来越广，在同一主机上的不同进程之间通信也可以用 Socket。 简单来说，当网络上不同主机之间的两个进程（A、B）采用 Socket 进行通信时，那么它们之间需要建立一个通信端点，即创建 Socket，创建 Socket 时就分配端口号和网络地址。当进程 A 向进程 B 发送数据时，那么进程 A 必须要知道进程 B 的网络地址及端口号。 Socket 采用 C&#x2F;S 模型进行设计的，即 Client&#x2F;Server，面向客户端—服务器模型。 每一个 Socket 都用一个半相关描述： {协议，本地地址，本地端口} 一个完整的 Socket 则用一个相关描述: {协议，本地地址，本地端口，远程地址，远程端口} 类型字节流套接字（SOCK_STREAM）字节流的套接字可以提供可靠的数据传输、面向连接的通讯流。数据按何种顺序发送，就按何种顺序接收。例如，当我们按顺序发送 A-B-C，那么在数据到达接收端时，它的顺序也是 A-B-C。字节流套接字采用的是 TCP（Transmission Control Protocol）协议。保证了数据传输的可靠性。 数据报套接字（SOCK_DGRAM）数据报套接字定义了一种无连接的服务。所谓无连接服务，简单来说，即在发送数据时，无需在收发两端建立类似 TCP 那样的握手连接，在发送时，将数据打包，然后加上远程 IP 地址，即可把该数据包发送出去。 数据通过相互独立的报文进行传输。并且是无序的、不可靠的传输。 原始套接字（SOCK_ROW）先启动服务器，通过调用 socket() 函数建立一个套接字，然后调用 bind() 函数将该套接字和本地网络地址联系在一起，再调用 listen() 函数使套接字做好侦听的准备，并规定它的请求队列的长度，之后就调用 accept() 函数来接收连接。 客户端在建立套接字之后就可调用 connect() 和服务器建立连接。 连接一旦建立，客户端和服务器之间就可以通过调用 recv()&#x2F;recvfrom() 函数和 send()&#x2F;sendto 函数来进行发收数据。 最后，待数据传送结束后，双方调用 close() 函数关闭套接字。","categories":["通讯协议","网络"]},{"title":"CAN学习笔记","path":"/2024/05/17/通讯协议-CAN-CAN学习笔记/","content":"概述介绍CAN 总线是一种串行通信协议，使用的是两条差分信号线，只能表达一个信号。 简洁的物理层决定了 CAN 必然要配上一套复杂的协议。 根据不同的距离、不同的网络，可配置不同的速度，最高速度为 1MBit&#x2F;s。 CAN 2.0A 为标准格式，CAN 2.0B 为扩展格式。 优点： 可以多主方式工作，网络上的任意节点均可以在任意时刻主动地向网络上的其他节点发送信息，而不分主从，通信方式灵活。 网络上的节点 (信息) 可分成不同的优先级，可以满足不同的实时要求。 采用非破坏性位仲裁总线结构机制，当两个节点同时向网络上传送信息时，优先级低的节点主动停止数据发送，而优先级高的节点可不受影响地继续传输数据。 工作原理当 CAN 总线上的节点发送数据时，以报文形式广播给网络中的所有节点，总线上的所有节点都不使用节点地址等系统配置信息，只根据每组报文开头的 11 位标识符 (CAN 2.0A 规范) 解释数据的含义来决定是否接收。这种数据收发方式称为面向内容的编址方案。 当某个节点要向其他节点发送数据时，这个节点的处理器将要发送的数据和自己的标识符传送给该节点的 CAN 总线接口控制器，并处于准备状态；当收到总线分配时，转为发送报文状态。数据根据协议组织成一定的报文格式后发出，此时网络上的其他节点处于接收状态。处于接收状态的每个节点对接收到的报文进行检 测，判断这些报文是否是发给自己的以确定是否接收。 层次结构CAN 被细分为三个层次： （1）CAN 对象层（the object layer）； （2）CAN 传输层（the transfer layer）； （3）CAN 物理层（the phyical layer）； 对象层和传输层包括所有由 ISO&#x2F;OSI 模型定义的数据链路层的服务和功能。 对象层的作用范围包括： （1）查找被发送的报文。 （2）确定由实际要使用的传输层接收哪一个报文。 （3）为应用层相关硬件提供接口。 传输层的作用主要： （1）传送规则，也就是控制帧结构、执行仲裁、错误检测、出错标定、故障界定。 （2）总线上什么时候开始发送新报文及什么时候开始接收报文，均在传输层里确定。 （3）位定时的一些普通功能也可以看作是传输层的一部分。 （4）传输层的修改是受到限制的。 物理层的作用： 在不同节点之间根据所有的电气属性进行位信息的实际传输。当然，同一网络内，物理层对于所有的节点必须是相同的。 编程在对象层进行，这一层直接与应用层交互，并且提供了管理和处理 CAN 消息的接口。通过对象层，应用程序可以发送和接收 CAN 的打包消息。打包的过程就是在原始数据的基础上再加上帧起始段、仲裁段、控制段、CRC 校验、应答和帧结束，把这些内容按特定的格式打包好，就可以用一个通道表达各种信号了，当数据包被发送时，只要接收方按约定格式去解读，就能还原出原始数据。 传输层的功能主要由 CAN 控制器硬件和驱动程序实现。通常，程序员不直接操作传输层，而是通过对象层的 API 间接利用传输层的功能。 传输层负责处理 CAN 协议的低级细节，如位级传输、错误处理和仲裁。 位填充（BitStuffing） 位填充是为了防止突发错误而设定的功能。位填充的规则如下： （1）5 位连续相同电平之后，必须填充一位反向位，即不允许有 6 个连续相同位； （2）SOF 之前为总线空闲状态，不需要同步，因此不需要位填充； （3）CRC 之后为固定格式，不允许填充； （4）由 CAN 控制器自动实现； 物理层通常由 CAN 收发器硬件和相关电气接口组成。 CAN 属性CAN 具有以下的属性： （1）报文（Messages）：CAN 协议对数据、操作命令 (如读&#x2F;写) 以及同步信号进行打包，打包后的这些内容称为报文，简单来说就是具有固定格式的数据包。 （2）信息路由（Information Routing）：即，报文寻找结点的方式。 （3）位速率（Bit rate）：数据位的传输速度。 （4）优先权（Priorities）：即报文发送的优先权。 （5）远程数据请求（Remote Data Request）：通过发送远程帧，需要数据的节点可以请求另一节点发送相应的数据帧。 （6）多主机（Multimaster）：总线空闲时，任何结点都可以开始传送报文。 （7）仲裁（Arbitration）：当 2 个及以上的单元同时开始传送报文，那么就会有总线访问冲突。仲裁是确定哪个单元的具有发送优先权。 （8）安全性（Safety）：CAN 的每一个节点均采取了强有力的措施以进行错误检测、错误标定及错误自检。 （9）错误检测（Error Detection）：包括监视、循环冗余检查、位填充、报文格式检查。 （10）错误检测的执行（Performance of Error Detection） （11）错误标定和恢复时间（Error Sinalling and Recovery Time）：任何检测到错误的结点会标志出已损坏的报文。此报文会失效并将自动地开始重新传送。如果不再出现新的错误，从检测到错误到下一报文的传送开始为止，恢复时间最多为 29 个位的时间。 （12）故障界定（Fault Confinement）：CAN 结点能够把永久故障和短暂扰动区分开来。永久故障的结点会被关闭。 （13）连接（Connections）：CAN 串行通讯链路是可以连接许多结点的总线。理论上，可连接无数多的结点。但由于实际上受延迟时间或者总线线路上电气负载的影响，连接结点的数量是有限的。 （14）单通道（Single Channel）：总线是由单一进行双向位信号传送的通道组成。 （15）总线值（Bus value）：总线可以具有两种互补的逻辑值之一：“显性”（可表示为逻辑 0）或“隐性”（可表示为逻辑 1）。 （16）应答（Acknowledgment）：所有的接收器检查报文的连贯性。对于连贯的报文，接收器应答；对于不连贯的报文，接收器作出标志。 （17） 睡眠模式／唤醒（Sleep Mode &#x2F; Wake-up）：为了减少系统电源的功率消耗，可以将 CAN 器件设为睡眠模式以便停止内部活动及断开与总线驱动器的连接。CAN 器件可由总线激活，或系统内部状态而被唤醒。 仲裁方式在总线空闲态，最先开始发送消息的单元获得发送权。多个单元同时开始发送时，各发送单元从仲裁段的第一位开始进行仲裁。连续输出显性电平最多的单元可继续发送。即逐位地对比 各个结点发出的报文 ID。 由于线与的关系，显示位“0”可以覆盖隐性位“1”，因此 ID 最小的节点赢得仲裁，总线上表现为该结点的报文，其他结点失去仲裁，退出发送，转为接收状态。 标准格式 ID 与具有相同 ID 的远程帧或者扩展格式的数据帧在总线上竞争时，标准格式的 RTR 位为显性位的具有优先权，可继续发送。 位时序由发送单元在非同步的情况下发送的每秒钟的位数称为位速率。一个位可分为 4 段。 同步段（SS） 传播时间段（PTS） 相位缓冲段 1（PBS1） 相位缓冲段 2（PBS2） 这些段又由可称为 Time Quantum（以下称为 Tq）的最小时间单位构成。 1 位分为 4 个段，每个段又由若干个 Tq 构成，这称为位时序。 1 位由多少个 Tq 构成、每个段又由多少个 Tq 构成等，可以任意设定位时序。通过设定位时序，多个单元可 同时采样，也可任意设定采样点。 Linux 下设置位时序的方式 ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1 同步段（Sync Segment）: 固定为 1 TQ，用于同步位定时器。 传播时间段（Propagation Segment, prop-seg）: 用于补偿信号在总线上传播的时间延迟。 相位缓冲段 1（Phase Buffer Segment 1, phase-seg1）: 用于提高抗干扰能力，允许时间调整。 相位缓冲段 2（Phase Buffer Segment 2, phase-seg2）: 也用于提高抗干扰能力，允许时间调整。 *ip link set can0 type can: 设置名为 can0 的网络接口的类型为 CAN。tq 125: 设置时间量化（Time Quantum，TQ）为 125 ns。TQ 是 CAN 控制器内部的基本时间单位，用于划分整个位时间。prop-seg 6: 设置传播时间段（Propagation Segment）为 6 TQ。传播时间段用于补偿信号在 CAN 总线上传播的延迟。phase-seg1 7: 设置相位缓冲段 1（Phase Buffer Segment 1）为 7 TQ。这个时间段用于调整边沿相位，通常包括采样点之前的时间。phase-seg2 2: 设置相位缓冲段 2（Phase Buffer Segment 2）为 2 TQ。这个时间段用于调整边沿相位，通常包括采样点之后的时间。sjw 1: 设置同步跳跃宽度（Synchronization Jump Width，SJW）为 1 TQ。SJW 用于重新同步时可以跳跃的最大时间量。 具体计算tq 125: 时间量化为 125 ns。prop-seg 6: 传播时间段为 6 个时间量化，6 * 125 ns &#x3D; 750 ns。phase-seg1 7: 相位缓冲段 1 为 7 个时间量化，7 * 125 ns &#x3D; 875 ns。phase-seg2 2: 相位缓冲段 2 为 2 个时间量化，2 * 125 ns &#x3D; 250 ns。sjw 1: 同步跳跃宽度为 1 个时间量化，1 * 125 ns &#x3D; 125 ns。计算位时间总位时间是所有段的时间总和：Sync Segment: 1 TQPropagation Segment: 6 TQPhase Buffer Segment 1: 7 TQPhase Buffer Segment 2: 2 TQ总时间量化数 &#x3D; 1 + 6 + 7 + 2 &#x3D; 16 TQ总位时间 &#x3D; 16 * 125 ns &#x3D; 2000 ns &#x3D; 2 μs位速率（Bit Rate） &#x3D; 1 &#x2F; 总位时间 &#x3D; 1 &#x2F; 2 μs &#x3D; 500 kbps 数据帧帧类型为了更有效地控制通讯，CAN 一共规定了 5 种类型的帧 数据帧：发送单元向接收单元传送数据的帧。 远程帧：接收单元向发送单元请求数据的帧。 错误帧：检测出错误时向其它单元通知错误的帧。 过载帧：接收单元通知其尚未就绪的帧。 间隔帧：将数据帧及遥控帧与前面的帧分离开来的帧。 数据帧和遥控帧有标准帧和扩展帧两种帧，标准帧有 11 个位的标识符 ID，扩展帧有 29 个位的 ID 标准 CAN 帧定义数据帧由帧起始、仲裁段、控制段、数据段、CRC、ACK、帧结束共 7 个段构成 隐形=1 显性=0 帧起始 (Start Of Frame,SOF)，1bit 表示帧开始的段，设置为 0。 仲裁段（Identifier，ID），11bits&#x2F;29bits 表示数据帧优先级的段标准帧与扩展帧的构成有所不同，均禁止高 7 位为隐性 (ID&#x3D;1111111XXXX…) 仲裁段的内容主要为本数据帧的 ID，标准帧的 ID 有 11 个位，扩展帧的 ID 有 29 个位，在 CAN 协议中，ID 决定着数据帧发送的优先级，也决定着其它节点是否会接收这个数据帧。CAN 总线不对挂载在它之上的节点分配优先级和地址，对总线的占有权是由信息的 ID 决定的，即对于重要的信息，优先级高的 ID，能够优先发送出去 RTR 位 (Remote Transmission Request Bit)远程传输请求位，用于区分数据帧和遥控帧的，为 0 表示数据帧，1 表示遥控帧。 控制段 控制段由 6 个位构成，表示数据段的字节数 IDE 位 (Identifier Extension Bit)标识符扩展位，用于区分标准帧与扩展帧，为 0 表示标准帧，1 表示扩展帧 SRR 位 (Substitute Remote Request Bit)只存在于扩展帧，它用于替代标准帧中的 RTR 位，扩展帧中的 SRR 位固定为 1，RTR 在数据帧中为 0，所以两个 ID 相同的标准帧与扩展帧，标准帧的优先级较高 DLC 数据长度码（Data Length Code）数据的字节数必须为 0～8 字节 数据段（Data Field） 数据段可包含 0～8 个字节的数据 CRC 段 CRC 段是检查帧传输错误的段，由 15 个位的 CRC 值和 1 个位的 CRC 界定符 (隐性分隔位) 构成 CRC 是根据多项式生成的 CRC 值，CRC 的计算范围包括帧起始、仲裁段、控制段、数据段 接收方以同样的方式计算 CRC 值并进行比较，不一致时利用错误帧请求重新发送 ACK 段 ACK 段包括 ACK 槽位、ACK 界定符位 2 个位 发送单元的 ACK 段：发送单元在 ACK 段发送 2 个位的隐性位接收单元的 ACK 段：接收到正确消息的单元在 ACK 槽发送显性位，通知发送单元正常接收结束，这称作“发送 ACK”或者“返回 ACK” 帧结束 (End Of Frame，EOF) 帧结束是表示该帧结束的段，由发送节点发送 7 个位的隐性位构成 *CAN 数据帧的结束符长度并不是完全不定的，而是根据数据位速率（Data Bit Rate，DBR）而定。CAN 总线协议规定，对于数据位速率低于等于 125kbps 的网络，CAN 数据帧的结束符长度为 7 个位；对于数据位速率大于 125kbps 的网络，CAN 数据帧的结束符长度为 3 个位。这是因为在高速网络中，由于数据传输速率更快，所以 CAN 控制器可以更快地检测到结束位，因此可以减少结束符的长度，从而提高网络的传输效率。而在低速网络中，由于数据传输速率较慢，所以 CAN 控制器需要更长的时间来检测结束位，因此需要一个更长的结束符来确保数据帧传输的正确性和完整性。因此，CAN 数据帧的结束符长度是根据数据位速率而定的，并不是完全不定的。 Linux 下的 Socket CAN 帧定义 帧头，canid_t 定义了一个无符号的 32 位整形数，按位确定功能 0-28 位为标识符，如果是扩展帧，则高 11 位为标准 ID 29 位标识是数据帧还是错误消息 30 位说明是否是远程帧 31 位说明是标准帧还是扩展帧。 帧长，8 位无符号表示数据区长度 数据区，定义 CAN_MAX_DLEN 个 8 位无符号数，按照数组的形式申请*__attribute__((aligned(8))) 告诉编译器，将变量 data 放在一个地址是 8 的倍数的内存位置上。 1234567891011121314151617181920/* CAN payload length and DLC definitions according to ISO 11898-1 */#define CAN_MAX_DLC 8#define CAN_MAX_DLEN 8struct can_frame &#123; canid_t can_id; /* 32 bit CAN_ID + EFF/RTR/ERR flags */ __u8 can_dlc; /* frame payload length in byte */ __u8 data[CAN_MAX_DLEN] __attribute__((aligned(8)));&#125;;/** Controller Area Network Identifier structure** bit 0-28 : CAN identifier (11/29 bit)* bit 29 : error message frame flag (0 = data frame, 1 = error message)* bit 30 : remote transmission request flag (1 = rtr frame)* bit 31 : frame format flag (0 = standard 11 bit, 1 = extended 29 bit)*/typedef __u32 canid_t;typedef unsigned char __u8; Linux 处理 can_frame 时用到的掩码和标识符： 123456789/* special address description flags for the CAN_ID */#define CAN_EFF_FLAG 0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG 0x40000000U /* remote transmission request */#define CAN_ERR_FLAG 0x20000000U /* error message frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK 0x000007FFU /* standard frame format (SFF) */#define CAN_EFF_MASK 0x1FFFFFFFU /* extended frame format (EFF) */#define CAN_ERR_MASK 0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 实际对 can_frame 的处理是在 mcp251x_hw_tx&#x2F;mcp251x_hw_rx_frame 中进行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static void mcp251x_hw_tx(struct spi_device *spi, struct can_frame *frame,int tx_buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);u32 sid, eid, exide, rtr;u8 buf[SPI_TRANSFER_BUF_LEN];//取can_id的31位，判断是标准帧还是扩展帧exide = (frame-&gt;can_id &amp; CAN_EFF_FLAG) ? 1 : 0; if (exide)//如果是扩展帧，can_id的0-28位为ID，其中高11位为标准IDsid = (frame-&gt;can_id &amp; CAN_EFF_MASK) &gt;&gt; 18;elsesid = frame-&gt;can_id &amp; CAN_SFF_MASK; /* Standard ID */eid = frame-&gt;can_id &amp; CAN_EFF_MASK; /* Extended ID */rtr = (frame-&gt;can_id &amp; CAN_RTR_FLAG) ? 1 : 0; /* 是否是远程帧*/buf[TXBCTRL_OFF] = INSTRUCTION_LOAD_TXB(tx_buf_idx); //发送缓冲器控制寄存器地址buf[TXBSIDH_OFF] = sid &gt;&gt; SIDH_SHIFT; //发送缓冲器标准ID高8位//5-7位存放发送缓冲器低3位,3位存放帧格式，0-1位存放扩展标识符低18位的高两位（16-17）buf[TXBSIDL_OFF] = ((sid &amp; SIDL_SID_MASK) &lt;&lt; SIDL_SID_SHIFT) | (exide &lt;&lt;SIDL_EXIDE_SHIFT) | ((eid &gt;&gt; SIDL_EID_SHIFT) &amp; SIDL_EID_MASK);buf[TXBEID8_OFF] = GET_BYTE(eid, 1); //存放扩展标识符低18位的8-15位buf[TXBEID0_OFF] = GET_BYTE(eid, 0); //扩展标识符低18位的低8位（0-7）buf[TXBDLC_OFF] = (rtr &lt;&lt; DLC_RTR_SHIFT) | frame-&gt;can_dlc; //6位存放远程帧标识符，0-3存放数据长度码memcpy(buf + TXBDAT_OFF, frame-&gt;data, frame-&gt;can_dlc);//拷贝要发送的数据mcp251x_hw_tx_frame(spi, buf, frame-&gt;can_dlc, tx_buf_idx);/* use INSTRUCTION_RTS, to avoid &quot;repeated frame problem&quot; */priv-&gt;spi_tx_buf[0] = INSTRUCTION_RTS(1 &lt;&lt; tx_buf_idx);mcp251x_spi_trans(priv-&gt;spi, 1);&#125;static void mcp251x_hw_rx_frame(struct spi_device *spi, u8 *buf,int buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);if (mcp251x_is_2510(spi)) &#123;int i, len;for (i = 1; i &lt; RXBDAT_OFF; i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);\tlen = get_can_dlc(buf[RXBDLC_OFF] &amp; RXBDLC_LEN_MASK);\tfor (; i &lt; (RXBDAT_OFF + len); i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);&#125; else &#123;\tpriv-&gt;spi_tx_buf[RXBCTRL_OFF] = INSTRUCTION_READ_RXB(buf_idx);\tmcp251x_spi_trans(spi, SPI_TRANSFER_BUF_LEN);\tmemcpy(buf, priv-&gt;spi_rx_buf, SPI_TRANSFER_BUF_LEN);&#125;&#125; Linux CAN 功能分析一个标准的 CAN 功能包括： CAN 接口号指定 CAN 接口号 can0 指定 CAN 通讯波特率，单位 Kbps，默认为 500 Kbps 指定 CAN 发送帧 ID 指定 CAN 发送帧数据 需要包含数据的大小端模式转换 指定 CAN 帧发送间隔，单位 ms， 默认为 250ms, 最小值为 1ms 指定 CAN 帧发送次数 指定 CAN 发送帧为标准帧&#x2F;扩展帧 发送数据时错误判断，本地环回功能基于 LINUX SOCKET 机制实现的 CAN 接口，其基本的流程如下所示： 设置套接字 socket 指定 CAN 设备 ioctl 绑定套接字与设备 bind 设置过滤规则 setsockopt 发送&#x2F;接受报文 read/write 关闭套接字 close以下介绍各部分如何实现。 Linux 应用层 SocketCAN 实例初始化SocketCAN 中大部分的数据结构和函数在头文件 linux&#x2F;can.h 中进行了定义。 CAN 总线套接字的创建采用标准的网络套接字操作来完成。网络套接字在头文件 sys&#x2F;socket.h 中定义。 套接字的初始化方法如下： 123456789int s;struct sockaddr_can addr;struct ifreq ifr;s = socket(PF_CAN, SOCK_RAW, CAN_RAW);//创建SocketCAN 套接字strcpy(ifr.ifr_name, &quot;can0&quot;);ioctl(s, SIOCGIFINDEX, &amp;ifr);//指定 can0 设备addr.can_family = AF_CAN;addr.can_ifindex = ifr.ifr_ifindex;bind(s, (structsockaddr *)&amp;addr,sizeof(addr)); //将套接字与 can0 绑定 数据发送在数据收发的内容方面， CAN 总线与标准套接字通信稍有不同，每一次通信都采用 can_ frame 结构体将数据封装成帧。 结构体定义如下： 12345structcan_frame &#123;canid_t can_id;//CAN 标识符__u8 can_dlc;//数据场的长度__u8 data[8];//数据&#125;; can_id 为帧的标识符， 如果发出的是标准帧， 就使用 can_id 的低 11 位； 如果为扩展帧， 就使用 0～ 28 位。 can_id 的第 29、 30、 31 位是帧的标志位，用来定义帧的类型，定义如下： 123#define CAN_EFF_FLAG 0x80000000U //扩展帧的标识#define CAN_RTR_FLAG 0x40000000U //远程帧的标识#define CAN_ERR_FLAG 0x20000000U //错误帧的标识，用于错误检查 数据发送使用 write 函数来实现。 如果发送的数据帧 (标识符为 0x123) 包含单个字节 (0xAB) 的数据，可采用如下方法进行发送： 123456789struct can_frame frame;//如果为扩展帧，那么frame.can_id = CAN_EFF_FLAG | 0x123;frame.can_id = 0x123;frame.can_dlc = 1; //数据长度为 1frame.data[0] = 0xAB; //数据内容为 0xABint nbytes = write(s, &amp;frame, sizeof(frame));//发送数据if(nbytes != sizeof(frame)) //如果 nbytes 不等于帧长度，就说明发送失败printf(&quot;Error !&quot;); 如果要发送远程帧 (标识符为 0x123)，可采用如下方法进行发送： 123struct can_frame frame;frame.can_id = CAN_RTR_FLAG | 0x123;write(s, &amp;frame, sizeof(frame)); 数据接收数据接收使用 read 函数来完成，实现如下： 12struct can_frame frame;int nbytes = read(s, &amp;frame, sizeof(frame)); 套接字数据收发时常用的 send、 sendto、 sendmsg 以及对应的 recv 函数也都可以用于 CAN 总线数据的收发。 错误处理当帧接收后，可以通过判断 can_id 中的 CAN_ERR_FLAG 位来判断接收的帧是否为错误帧。 如果为错误帧，可以通过 can_id 的其他符号位来判断错误的具体原因。 错误帧的符号位在头文件 linux&#x2F;can&#x2F;error.h 中定义。 过滤规则设置在数据接收时，系统可以根据预先设置的过滤规则，实现对报文的过滤。过滤规则使用 can_filter 结构体来实现，定义如下： 1234struct can_filter &#123;canid_t can_id;canid_t can_mask;&#125;; 过滤的规则为：接收到的数据帧的 can_id &amp; mask == can_id &amp; mask 通过这条规则可以在系统中过滤掉所有不符合规则的报文，使得应用程序不需要对无关的报文进行处理。在 can_filter 结构的 can_id 中，符号位 CAN_INV_FILTER 在置位时可以实现 can_id 在执行过滤前的位反转。 用户可以为每个打开的套接字设置多条独立的过滤规则，使用方法如下： 12345678structcan_filter rfilter[2];rfilter[0].can_id = 0x123;rfilter[0].can_mask = CAN_SFF_MASK;//#define CAN_SFF_MASK 0x000007FFUrfilter[1].can_id = 0x200;rfilter[1].can_mask = 0x700;//设置规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER,&amp;rfilter, sizeof(rfilter)); 在极端情况下，如果应用程序不需要接收报文，可以禁用过滤规则。这样的话，原始套接字就会忽略所有接收到的报文。在这种仅仅发送数据的应用中，可以在内核中省略接收队列，以此减少 CPU 资源的消耗。禁用方法如下： 1setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER, NULL, 0); //禁用过滤规则 通过错误掩码可以实现对错误帧的过滤， 例如： 12can_err_mask_t err_mask = (CAN_ERR_TX_TIMEOUT | CAN_ERR_BUSOFF );setsockopt(s, SOL_CAN_RAW,CAN_RAW_ERR_FILTER, err_mask,sizeof(err_mask)); 回环功能设置在默认情况下， 本地回环功能是开启的，可以使用下面的方法关闭回环&#x2F;开启功能： 12int loopback = 0; // 0 表示关闭, 1 表示开启( 默认)setsockopt(s, SOL_CAN_RAW, CAN_RAW_LOOPBACK,&amp;loopback, sizeof(loopback)); 在本地回环功能开启的情况下，所有的发送帧都会被回环到与 CAN 总线接口对应的套接字上。 默认情况下，发送 CAN 报文的套接字不想接收自己发送的报文，因此发送套接字上的回环功能是关闭的。 可以在需要的时候改变这一默认行为： 12int ro = 1; // 0 表示关闭( 默认), 1 表示开启setsockopt(s, SOL_CAN_RAW, CAN_RAW_RECV_OWN_MSGS, &amp;ro, sizeof(ro)); 如何在 ARM 上实现 CAN 通讯硬件ARM 需要有 CAN 控制器和 CAN 收发器 CAN 控制器（CAN Controller）是负责实现 CAN 协议的逻辑部分的组件 CAN 收发器（CAN Transceiver）是负责 CAN 总线电平信号和 CAN 控制器之间的电信号转换的组件 CAN 控制器示例： 内置于微控制器中的 CAN 模块（例如 STM32 系列微控制器的内置 CAN 控制器）。 独立的 CAN 控制器芯片（例如 MCP2515）。CAN 收发器示例： 常见的独立 CAN 收发器芯片（例如 MCP2551、TJA1050 等）。 先选择 CAN 控制器芯片，一般的 PC 和 ARM 都没有 CAN 控制器，一般是 MCP2515 和 SJA1000，主要区别是 MCP2515 是 SPI 接口，SJA1000 是 I&#x2F;O 接口。所以 MCP2515 占用资源少，5-6 个管脚就可以控制，SJA1000 占用的管脚就多。 软件需要支持 CAN 控制器驱动，控制 CAN 控制器发送 CAN 帧 对于一般的 CAN 控制器，进行初始化时，最关键的是以下两步： 配置 CAN 的位时序； 配置 CAN 的消息报文； 内核Linux 中有对 CAN（Controller Area Network）总线的支持，主要通过 SocketCAN 子系统实现。内核编译时选择响应的支持芯片。 1234567891011$ make linux-menuconfigNetworking support ---&gt;CAN bus subsystem support ---&gt;--- CAN bus subsystem supportRaw CAN Protocol (raw access with CAN-ID filtering)Broadcast Manager CAN Protocol (with content filtering)CAN Device Drivers ---&gt;Virtual Local CAN Interface (vcan)Platform CAN drivers with Netlink support[*] CAN bit-timing calculationMicrochip 251x series SPI CAN Controller SocketCAN 支持多种 CAN 控制器硬件，通过不同的内核驱动程序实现对具体硬件的支持。例如，以下是一些常见的 CAN 控制器驱动程序： sja1000：Philips&#x2F;NXP SJA1000 CAN 控制器 mcp251x：Microchip MCP251x SPI CAN 控制器系列（如 MCP2515） flexcan：Freescale&#x2F;NXP FlexCAN 模块这些驱动程序通常位于内核源代码树的 drivers/net/can 目录下。 CAN 数据发送跟踪当我们在用户层通过 socket 进行 CAN 数据的发送时，需要进行以下操作： 创建一个套接字 socket，采用 AF_CAN 协议。 将创建的套接字返回描述符 sockfd，绑定到本地的地址。 通过 sendto 系统调用函数进行发送，sendto 的系统调用会发送一帧数据报到指定的地址，在 CAN 协议调用之前把该地址移到内核空间和检查用户空间数据域是否可读。 在 net/socket.c 源文件中，在 sendto 的系统调用 （sys_sendto） 里，会调用到 sock_sendmsg() 函数，接下来调用 __sock_sendmsg() 函数。 再往下一步就是 __sock_sendmsg_nosec 函数。在 __sock_sendmsg_nosec() 函数中会返回一个 sendmsg 函数指针。 在 /net/can/raw.c 源文件中，将 raw_sendmsg 函数地址赋给 sendmsg 函数指针，即在函数 __sock_sendmsg_nosec() 中 return sock-&gt;ops-&gt;sendmsg(iocb,sock, msg, size)，返回的函数指针将指向 raw_sendmsg() 函数。 在 net/can/af_can.c 源文件中，can_send 函数负责 CAN 协议层的数据传输，即传输一帧 CAN 报文（可选本地回环）。参数 skb 指针指向套接字缓冲区和在数据段的 CAN 帧。loop 参数是在本地 CAN 套接字上为监听者提供回环。 以下开始进行到 CAN 的底层驱动代码了，由于 CAN 驱动是编译进内核中，所以在系统启动时会注册 CAN 驱动。 注册 CAN 驱动过程中会初始化 d_can_netdev_ops 结构体变量。 在这个过程中，d_can_netdev_ops 结构体变量定义了 3 个函数指针，其中 (*ndo_start_xmit) 函数指针指向 d_can_start_xmit 函数的入口地址。 在 d_can_start_xmit() 函数中，会调用 d_can_write_msg_object() 函数准备消息报文进行传输。 CAN 数据接收跟踪对于网络设备，数据接收大体上采用中断 +NAPI 机制进行数据的接收。同样，我们现在的 CAN 模块也是采用同样的方式进行数据的接收。由于我们只针对 CAN 总线接收数据这条主线进行分析。因些，会忽略一些针对 CAN 协议的设置及初始化等相关代码。 *NAPI（New API）是一种改进的网络数据接收机制，它通过减少中断处理的次数来提高性能。NAPI 的基本思想是延迟数据包的处理，使得多个数据包可以一次性地在中断处理程序中进行处理，从而减少了中断的数量，提高了系统的处理效率。 中断 +NAPI 机制的工作原理大致如下： 当网络数据包到达时，网络接口卡会生成一个中断通知操作系统。 中断服务程序会执行一些必要的处理，然后调用 NAPI 机制。 NAPI 机制会检查网络接口缓冲区中是否有足够的数据需要处理。 如果有足够的数据，NAPI 会立即开始处理这些数据，而不会再次触发中断。如果数据量不足，NAPI 会退出，并要求在将来的某个时候再次调用。 处理完数据后，系统可以选择性地决定是否重新启用中断服务程序。 通过将数据包的处理延迟到一组数据包到达时再进行，中断 +NAPI 机制能够大大减少中断的数量，提高系统的处理效率，特别是在高负载情况下。 在初始化 CAN 设备时，我们需要给 CAN 设备分配 NAPI 功能。我们通过 netif_napi_add() 函数将 CAN 设备添加到 NAPI 机制列表中。 将 CAN 设备添加到 NAPI 机制列表中后，在中断处理函数 d_can_isr 中，我们通过 napi_schedule() 函数调度已经在 NAPI 机制列表中的 d_can_poll() 函数。该函数会通过轮询的方式接收数据。而根据 NAPI 机制，当中断产生后，会调度轮询机制同时关闭所有的中断。 当中断产生时，会调用函数 d_can_poll()，该函数即采用轮询的方式进行数据的接收。由于 CAN 总线状态中断具有最高优先权，在接收数据之前，需要对 CAN 总线的状态进行判断。而对于 CAN 总线错误状态有三种：主动&#x2F;被动&#x2F;关闭。 当总线状态数据状态正常时，从 CAN 模块的接收寄存器中接收数据。 文件系统要在 linux 下面配置和测试 CAN，需要安装以下三个组件。 iproute2 （配置 CAN 接口时需要） libsocketcan（使用 CAN 必须） can-utils https://github.com/linux-can/can-utils (CAN 的测试小工具，linux 下测试 CAN 比较好用应用程序) 可以直接通过命令行形式控制 CAN 12345678910111213141516171819202122# 配置CAN接口（假设设备名为`can0`）：ip link set can0 up type can bitrate 500000# 启动CAN接口ip link set up can0# 查看CAN接口状态ip -details link show can0# CAN 2.0 linkupip link set can0 up type can bitrate 100000# CAN 2.0 FD linkupip link set can0 up type can bitrate 500000 dbitrate 2000000 fd on# 命令来配置 CAN 总线的位速率：ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1# 可以使用 ip 命令直接设定位速率500kbps：ip link set can0 type can bitrate 500000# 当设置完成后，可以通过下面的命令查询 can0 设备的参数设置：ip -details link show can0# 当设置完成后，可以使用下面的命令使能 can0 设备：ifconfig can0 up# 使用下面的命令取消 can0 设备使能：ifconfig can0 down# 在设备工作中，可以使用下面的命令来查询工作状态：ip -details -statistics link show can0 Qt 中使用 SocketCAN需要编译安装 socketCAN 插件， https://doc.qt.io/qt-5/qtserialbus-socketcan-overview.html ，关键字【Using SocketCAN Plugin】 pro 文件中添加 QT += serialbus 12345QString errorString;const QList&lt;QCanBusDeviceInfo&gt; devices = QCanBus::instance()-&gt;availableDevices(\tQStringLiteral(&quot;socketcan&quot;), &amp;errorString);if (!errorString.isEmpty())\tqDebug() &lt;&lt; errorString; 在 Qt 中利用线程权限进行高速的 CAN 通信用 PC 里能达到的 CAN 通信（使用 USBCAN-II）速度是 1ms 使用 3 个线程类：1 个用来接收，1 个用来发送，1 个用来解析 接收线程使用最高线程权限：QThread::HighestPriority，其余线程用 QThread::HighPriority 如何循环发送报文：在发送线程里再多加一个定时器，timeout 时间为需要循环发送的时间（可达到 1ms）； 用户在主界面设置需要发送的报文为 OBJ 结构体数组，然后通过构造函数的方式传到发送线程，最后发送就行了。 解析过程：接收函数循环接收报文，每接收到 n 帧就发送到解析线程，然后根据 ID 解析，将解析数据发送主界面显示（不要 append）","categories":["通讯协议","CAN"]},{"title":"数字花园建设","path":"/2024/05/17/博客-数字花园建设/","content":"页面部署打开 github 下方仓库 https://github.com/oleeskild/digitalgarden fork 到自己仓库 直接点击 deploy，部署到 vercel Obsidian 插件配置搜索 digital garden 插件，配置 Github 仓库即可 写文章时，需要在文章属性中添加 1dg-publish: true 搜索 publish single note，发布文章","categories":["博客"]},{"title":"RAG检索知识体系","path":"/2024/05/17/AI-RAG检索知识体系/","content":"Windows 本地部署 Ollama + AnythingLLM 解读本地文档 构建私有知识库现阶段切入大模型应用落地最合适的方案依然是结合大模型基于 RAG 检索增强来实现知识库的检索和生存。从而构建个人或者企业私有化的本地知识库。 你只需要将本地私有的 PDF、Word 文档和文本文件嵌入到本地向量库，连接上 LLM，然后就可以通过对话、搜索的方式进行回答问题、提供见解，甚至生成摘要。 Ollama 下载地址 https://ollama.com/download Ollama 配置文档 ollama笔记 AnythingLLM 下载地址 https://useanything.com/download AnythingLLM 配置文档 AnythingLLM笔记 AnythingLLM 是 Mintplex Labs Inc. 开发的一个基于 RAG（Retrieval-Augmented Generation）方案构建的开源、高效、可定制的私有知识库解决方案，一款开源 ChatGPT 等效工具，用于在安全的环境中与文档等进行聊天，专为想要使用现有文档进行智能聊天或构建知识库的任何人而构建。 AnythingLLM 能够把各种文档、资料或者内容转换成一种格式，让 LLM（如 ChatGPT）在聊天时可以引用这些内容。然后你就可以用它来和各种文档、内容、资料聊天，支持多个用户同时使用，还可以设置谁能看或改哪些内容。 支持多种 LLM、嵌入器和向量数据库。 Open WebUI 安装地址 https://github.com/v1cc0/open-webui 安装 Ollama 工具后，在命令行输入 ollama pull qwen:4b 下载模型 千问 4b 的模型，也可以下载其他模型 ，支持的模型列表：https://ollama.com/library。 要开始运行 Ollama 的话，只需要在命令行输入 ollama run qwen:4b 就可以使用并访问这个模型了。 接下来我们需要安装向量模型和数据库，在 https://ollama.com/里面搜索 nomic-embed-text ，这个模型可以将文本内容转换成向量数据，里面是模型介绍。 安装模型可以在命令行输入 ollama pull nomic-embed-text 进行下载和安装。 安装 AnythingLLM 工具后打开初始化界面，会进入到配置页面，在 LLM Preference 选项卡中，选择 Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 qwen:4b ，token 填 8192 下一步是配置 Embedding Preference 选项卡中，一样选择 Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 nomic-embed-text ，length 填 512 下一步是配置 Vector Database ，选择默认的 LanceDB ，这是内置的向量数据库，如果想用云端数据库，可以选择 Pinecone 进行云端配置。 后面就是按提示下一步下一步，如果是要加新的工作空间，可以点 new workspace 来增加不同场景下的工作空间。如果需要更换模型，可以点左下角的配置按钮，重新执行上面三步完成配置。 到这里环境已经部署了，这时你已经可以跟大模型进行对话了。 接下来的步骤是对私有知识库的内容进行分析和获取。需要将文档上传到 AnythinLLM，通过 nomic-embed-text 模型进行向量转换，然后存在向量数据库中。最后通过提问，去向量数据库获取内容并分析回答。 Data Connectors 是一种工具，它允许用户将外部数据源无缝集成到他们的 AnythingLLM 工作空间中，而无需编写任何自定义代码或处理复杂的配置。这些经过验证的数据连接器确保与你的 AnythingLLM 实例兼容，提供了一种简单且直接的方式来扩展你的工作空间功能。 以下是一些可用的数据连接器及其功能： GitHub Repo: - 通过这个连接器，你可以一键导入整个公共或私有的 GitHub 仓库到你的 AnythingLLM 工作空间中。 - 访问 GitHub 来获取你想要导入的仓库的链接。 - 这个功能对于开发者和团队来说非常有用，因为它允许他们直接在 AnythingLLM 中管理和查看代码库，跟踪问题和特性请求，以及审查代码。 YouTube Transcript: - 这个连接器允许你从 YouTube 视频链接导入整个视频的转录文本。 - 只需提供 YouTube 视频的链接，就可以轻松获取视频的文字内容。 - 这对于需要分析视频内容、创建视频摘要或者进行视频内容相关的研究的用户来说非常有用。 使用这些数据连接器，你可以快速地将外部数据集成到你的工作流程中，从而提高效率和生产力。例如，如果你正在研究一个特定的编程问题，你可以直接导入相关的 GitHub 仓库来查看代码和文档；或者，如果你需要分析一个教育视频的内容，你可以导入视频的转录文本来进行文本分析。 这些连接器的使用通常涉及到在 AnythingLLM 工作空间中选择相应的连接器，然后按照提示输入必要的信息，如仓库链接或视频链接，之后就可以开始导入数据了。整个过程简单直观，无需专业的编程知识，使得用户可以专注于数据分析和决策，而不是技术细节。 在工作空间页面上有一个上传文档的按钮，点击可以上传我们的文档内容。上传后选中文档，点击 Save and Embed ，等待一段时间，让模型进行向量转换和保存。 然后回到主界面点击工作空间的设置，选择 Chat Setting 选项卡，这里对话模式选择 Query ，这个模式是指只从提供的文档内容进行查找分析，而不要求大语言模型里面提供的信息作答。最后点击 Update workspace 进行更新。 然后就可以进行提问了，以上是本地部署应用的地方，如果你的电脑不太行，可以装 Ollama 部署在云端 GPU 服务器，然后本地安装 AnythingLLM，在选择 URL 上填写云端 Ollama 的地址即可。 配置 LLM这里选择 Ollama 作为后台的服务，URL 这里填写 http://127.0.0.1:11434，也就是前面 Ollama 启动的服务端口，填写后 LLM 模型选择 gemma:2b 配置 Embedding Model这里同样选择 Ollama 作为后台的服务，URL 这里同样填写 http://127.0.0.1:11434，填写后 Embedding Model 选择 nomic-embed-text:latest 配置 Vector DatabaseVector Database 选择默认的第一个 LanceDB 以上三个关键配置完成后，就可以开始使用 AnythingLLM 了。 创建文档库点击 New Workspace 新建文档库，并填写名称点击按钮开始添加文档我们使用的文档是 paul_graham_essay.txt，这个文档也可以从 github 上下载：https://github.com/xinsblog/try-llama-index/blob/master/data/paul_graham_essay.txt 。 添加文档后还要将文档 Move to Workspace然后点击 Save and Embed出现 Workspace updated successfully 就表示配置已经完成 开始测试回到主页面，输入问题 What did the author do in 9th grade?几秒钟后就可以看到 AnythingLLM 给出的回答 第三个工具就是 Open WebUI，此工具可以支持云端部署 web 界面，在浏览器上访问大模型。 前置需要安装 Docker，具体安装步骤可以看 https://github.com/v1cc0/open-webui 上面的安装步骤，这里就不再赘述。 安装完后输入 github 上的指令即可连通 Ollama，并进行使用。","categories":["AI"]},{"title":"ollama笔记","path":"/2024/05/17/AI-ollama笔记/","content":"支持的模型 https://ollama.com/library 在用的 ollama 模型ollama.exe list ollama run llama3:8b ollama run codellama:7b ollama run qwen:14b ollama run starcoder2:7b ollama run nomic-embed-text NAME SIZE FEATURES codellama:latest 3.8 GB llama3:latest 4.7 GB starcoder2:3b 1.7 GB qwen:4b nomic-embed-text 新建系统环境变量，变量名：OLLAMA_MODELS，变量值中指定模型位置 https://huggingface.co/ https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file Ollama on Linux安装1curl -fsSL https://ollama.com/install.sh | sh Ollama 使用Ollama 大模型联网Python 及库123import requestsimport jsonimport time 定义联网函数需要定义一个联网函数，用于与互联网上的服务器进行通信。这个函数可以发送 HTTP 请求，接收服务器的响应，并返回结果。以下是一个示例： 12345678def connect_to_server(url, data): headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; response = requests.post(url, data=json.dumps(data), headers=headers) if response.status_code == 200: return response.json() else: print(&quot;Error connecting to server:&quot;, response.status_code) return None 配置 Ollama在联网之前，我们需要对 Ollama 大模型进行一些配置。这包括设置模型的参数、训练数据和测试数据等。具体的配置方法取决于你所使用的 Ollama 大模型。以下是一个示例： 12345678910# 设置模型参数model_params = &#123; &quot;learning_rate&quot;: 0.001, &quot;num_epochs&quot;: 100, &quot;batch_size&quot;: 32&#125;# 加载训练数据和测试数据train_data = load_train_data()test_data = load_test_data() 训练模型在配置好 Ollama 大模型后，我们可以开始训练模型。训练过程中，我们可以使用之前定义的联网函数将模型的中间结果上传到服务器上。以下是一个示例： for epoch in range(model_params[&quot;num_epochs&quot;]): # 训练模型 train_model(train_data, model_params) # 将中间结果上传到服务器 url = &quot;http://example.com/upload&quot; data = &#123; &quot;epoch&quot;: epoch, &quot;loss&quot;: get_current_loss(), &quot;accuracy&quot;: get_current_accuracy() &#125; connect_to_server(url, data) 测试模型训练完成后，我们可以使用测试数据对模型进行测试。同样，我们可以使用联网函数将测试结果上传到服务器上。以下是一个示例： 1234567891011# 测试模型test_model(test_data)# 将测试结果上传到服务器url = &quot;http://example.com/upload&quot;data = &#123; &quot;test_loss&quot;: get_test_loss(), &quot;test_accuracy&quot;: get_test_accuracy()&#125;connect_to_server(url, data) 通过以上步骤，我们已经成功地让 Ollama 大模型联网了。在实际应用中，你可能需要根据具体的需求和环境进行调整和优化。希望本文能够帮助你更好地理解和应用 Ollama 大模型的联网功能。","categories":["AI"]},{"title":"博客部署相关环境","path":"/2024/05/17/博客-博客部署相关环境/","content":"更新软件包sudo apt update 更新 nodejs 到最新版本卸载自带的 nodejs sudo apt autoremove nodejs sudo apt purge nodejs 安装 20 版本的 nodejs curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp; sudo apt-get install -y nodejs 查看版本是否更新，否则关闭命令行重新打开 nodejs -v 安装 nodejs 安装工具到全局 sudo npm install n -g 安装稳定版本 nodejs sudo n stable 安装 npmsudo apt install npm -y FTP 配置 - 用于图床安装 ftp 服务端 sudo apt install vsftpd -y 修改配置文件 sudo vi &#x2F;etc&#x2F;vsftpd.conf #禁止匿名访问anonymous_enable&#x3D;NO#接受本地用户local_enable&#x3D;YES#允许上传write_enable&#x3D;YES #更改创建文件权限 local_umask&#x3D;022 重启服务 sudo service vsftpd restart 创建 FTP 用户 sudo useradd -d &#x2F;home&#x2F;lemonade -M lemonade sudo passwd lemonade Mysql 环境搭建安装 mysql sudo apt install mysql-server -y sudo service mysql status # 查看服务状态sudo service mysql start # 启动服务sudo service mysql stop # 停止服务sudo service mysql restart # 重启服务 查看并更新密码 sudo cat /etc/mysql/debian.cnf 采用默认用户名密码登录 mysql -u *** -p 更新 root 用户密码 ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;newpasswd&#39;; 退出后，用 root 用户确认正常登录 mysql -u root -p newpasswd 创建 Qexo 要使用表 create database qexo; Python 环境安装安装编译 Python 3.10 所需的依赖项： sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码： tar -xf Python-3.10.0.tgz 进入解压后的目录： cd Python-3.10.0 配置 Python 3.10 的编译选项： ./configure --enable-optimizations 编译并安装 Python 3.10： make -j 8 sudo make altinstall 确认 Python 3.10 是否安装成功： python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。 安装时网络问题见 pip下载网络问题 nginx 环境安装安装 nginx sudo apt install nginx 访问公网 IP，发现 nginx 页面安装成功 修改 nginx 配置文件 sudo vi /etc/nginx/sites-enabled/default 修改完成后重启 nginx 服务 sudo service nginx restart","tags":["博客"],"categories":["博客"]},{"title":"shell","path":"/2024/05/17/语言-shell/","content":"什么是 shellshell 是一个编程语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支； 也是一个命令行解释器，交互式地解释和执行用户输入的命令； 还是内核的保护工具，它调用了系统核心的大部分功能来执行程序、建立文件并以并行的方式协调各个程序的运行。 Shell 有两种执行命令的方式：交互式（Interactive）：解释执行用户的命令，用户输入一条命令，Shell 就解释执行一条。批处理（Batch）：用户事先写一个 Shell 脚本 (Script)，shell 脚本是 shell 命令的有限序列，将各类命令预先放入其中，方便一次性执行的一个程序文件，主要用于方便管理员进行设置或者管理，而不必一条一条地敲命令。 *Shell 脚本是解释执行的，不需要编译，Shell 程序从脚本中一行一行读取并执行这些命令，相当于一个用户把脚本中的命令一行一行敲到 Shell 提示符下执行 Linux 的 Shell 种类众多，常见的有：Bourne Shell（&#x2F;usr&#x2F;bin&#x2F;sh 或&#x2F;bin&#x2F;sh）、Bourne Again Shell（&#x2F;bin&#x2F;bash）、C Shell（&#x2F;usr&#x2F;bin&#x2F;csh）、K Shell（&#x2F;usr&#x2F;bin&#x2F;ksh）、Shell for Root（&#x2F;sbin&#x2F;sh）等等。 不同的 Shell 语言的语法有所不同，所以不能交换使用。我们关注的重点是 Bash，Bash 也是大多数 Linux 系统默认的 Shell。在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，在下面的文字中，我们可以看到#!&#x2F;bin&#x2F;sh，它同样也可以改为#!&#x2F;bin&#x2F;bash。 编写 Shell 脚本的格式是固定的，一个简单的 shell 脚本如下： 1234#!/bin/sh#print hello world in the console windowa = &quot;hello world&quot;echo $a 首行中的符号**#!告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序**。 如果首行没有这句话，在执行脚本文件的时候，将会出现错误。 后续的部分就是主程序，Shell 脚本像高级语言一样，也有变量赋值，也有控制语句。 除第一行外，以#开头的行就是注释行，直到此行的结束。 如果一行未完成，可以在行尾加上 “，这个符号表明下一行与此行会合并为同一行。 编辑完毕，将脚本存盘为 filename.sh，文件名后缀 sh 表明这是一个 Bash 脚本文件。 执行方式： 1234567891011121.加可执行权限 chmod u+x filename.sh ./filename.sh2.执行通过bash运行 /bin/bash filename.sh3.将路径添加到环境变量 chmod u+x filename.sh PATH+=:/home/fs/Temp filename.sh //任意目录运行4.添加到bin文件夹 chmod u+x filename.sh sudo mv filename.sh /bin/ 注意，一定要写成.&#x2F;filename.sh，而不是 filename.sh。运行其它二进制的程序也一样，直接写 filename.sh，linux 系统会去 PATH 里寻找有没有叫 filename.sh 的，而只有&#x2F;bin, &#x2F;sbin, &#x2F;usr&#x2F;bin，&#x2F;usr&#x2F;sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 filename.sh 是会找不到命令的，要用.&#x2F;filename.sh 告诉系统说，就在当前目录找。 速查表 命令 含义 %!xxd 将二进制文件转换为 16 进制和 ASCII 表形式查看 * 代表通配符，可代表任意长度的任意字符； ？ 可代表单个长度的任意字符 [] 通配括号中的元素 [^……] 除去括号中的元素，其他通配 &gt;file 将输出重定向到 file 中去（新建） &gt;&gt;file 将输出重定向到 file 中去（追加模式） &lt;file 将 file 作为标准输入 2&gt; 或 &amp;&gt; –&gt;标准错误 pipe 管道,将第一个命令的输出作为第二个命令的输入 shell 命令使用 tab 补齐：命令 文件名 路径 history ：查看命令历史 通配符 *：匹配任意长度任意字符串 管道 |：第一个指令的输出作为第二个指令的输入：ls /usr/bin | wc -l 重定向 : 命令置换：反撇号 1 ls `pwd` 常用命令 用户管理命令 进程管理命令 通配符1234567*?[...][-][^...][a-z, ABC] // 表示匹配a到z和A,B,C中任意一个字符ls file[3-4][5-9].c /*表示名匹配文件名含[3-4]中的一个字符和[5-9]中的一个字符，两个字符的共两个字符的文件名都符合规则。*/ 管道| 将第一个命令的正确输出内容 通过管道输出给 第二个命令作为输入. 要求第一个命令有输出，第二个命令有输入功能。 重定向echo &quot;hello world&quot; &gt; test &#x2F;&#x2F;将内容输出到文件 test 中。 echo &quot;hello Eric&quot; &gt;&gt; test &#x2F;&#x2F;将字符串内容追加到 test 中,在 test 原有的内容上添加 2&gt; 2&gt;&gt; &#x2F;&#x2F;将报错信息重定向或追加到指定文件. &amp;&gt; &amp;&gt;&gt; &#x2F;&#x2F;将正确信息和错误信息一起重定向或追加到指定文件。 0 标准输入 stdin 1 标准输出 stdout ‘ ’ main() return ; fflush(stdout); 2 标准出错 stderr /dev/null 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 12cat /dev/null &gt; ~/.bash_history // 利用/dev/null清空指定文件。/dev/zero command &gt; file 将输出重定向到 file。 command &lt; file 将输入重定向到 file。 command &gt;&gt; file 将输出以追加的方式重定向到 file。 n &gt; file 将文件描述符为 n 的文件重定向到 file。 n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n &gt;&amp; m 将输出文件 m 和 n 合并。 n &lt;&amp; m 将输入文件 m 和 n 合并。 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 管道和重定向的比较command1 | command2 左输出 | 右输入 command &gt; file 左输出 &gt; 右文件 command &lt; file 左输入 &lt; 右文件 管道的命令同时执行,command2 等待 command1 的输出 (阻塞) 重定向是有优先级的,由进程优先级决定. 常用命令less/more alias 定义别名 12alias md=&#x27;mkdir&#x27;md dir1 dir2 //md就是mkdir了,这里创建了两个目录(文件夹)dir1和dir2. head/tail sort 排序命令 12345cat /etc/passwd | sort -t: -k 4 -n //-t指定分隔符 -k 4 指定分隔后的段, -n 完整比较。manman 1 可执行程序或Shell命令man 2 ?man 3 ? 用户管理命令12345678910adduserdeluser --remove-home //删除用户的同时，删除其工作目录chownchown xiaomeng jielun //将文件jielun的所有者改为xiaomeng.su 切换用户passwd 修改密码sudo //用超级用户权限执行一次命令；sudo passwd //普通用户修改root用户密码;usermodusermod -l Ez xiaoming //更改用户名xiaoming为Ez,要保证用户不在登陆状态; 相关文件: 123456789101112/etc/passwd/etc/shadow/etc/skel//etc/group/etc/gshadowchmod 改变文件读写执行权限rw- r-- r--110 100 1006 4 4| | |其他用户| |组用户权限|所属者的权限Xm 进程管理信息进程的概念:程是指正在执行的程序的实例。每个运行的程序都在系统中作为一个进程存在。进程是操作系统进行任务调度和资源管理的基本单位，它拥有自己的内存空间、执行代码、数据和资源。进程之间相互独立，彼此隔离，这样可以确保一个进程的异常不会影响其他进程的正常运行。进程与程序的区别:程序是一组静态的指令和数据的集合，它们存储在磁盘上；而进程是程序的实例，是程序在内存中的执行过程。程序只是静态的代码和数据的集合，而进程是具有动态特性、在系统中运行的实体。 &#x2F; 进程 程序 定义 进程是正在运行的程序的实例。在操作系统中，进程代表了一个独立的执行单元，拥有自己的内存空间、程序代码、数据和资源。每个运行的程序都以进程的形式存在。 程序是一组指令和数据的集合，它是静态的、存储在磁盘上的文件，描述了如何执行特定任务。程序本身并不占用系统资源，只有在被加载到内存并运行时，才成为一个进程。 特性 进程是一个动态的实体，具有生命周期，可以处于运行、就绪、阻塞、挂起等不同状态，而且进程之间相互独立，彼此隔离。 程序是一个静态的实体，只是存储在磁盘上的文件，并不具有自己的执行状态和资源。 生命周期 进程从创建、运行到终止，进程有一个明确的生命周期。当进程终止时，它占用的资源会被操作系统回收。 程序本身没有生命周期，只有在被加载到内存并执行为进程后，才会有生命周期。 进程和程序之间是一种从程序到进程的实例化关系。当运行一个程序时，操作系统会为该程序创建一个对应的进程，使得程序在内存中得以执行。 进程的查看: 12ps -auxps -elf 进程的几种状态: 运行（Running）：表示进程正在运行或正在执行。 就绪（Ready）：表示进程已经准备好运行，但由于系统资源限制或其他进程的运行，它暂时还没有得到处理器的分配。 阻塞（Blocked）：也称为等待（Waiting），表示进程由于等待某个事件的发生（如 I&#x2F;O 操作完成、信号等）而暂停执行，直到事件发生才能继续运行。 挂起（Suspended）：表示进程被暂时挂起，不占用 CPU 资源，并且可能被放置在磁盘上。这种状态通常用于系统中的一些特殊情况，如进程被调试或由于内存不足而被置换出来。 shell 命令行下查找在当前目录下所有文件中查找内容包含 string 的文件并列出字符所在的文件,所在行及所在行的内容: 1find ./ -name &quot;*&quot; -exec grep -n &quot;string&quot; ./ &#123;&#125; \\; 使用 find 查找时希望忽略某个目录 (-prune): 如果希望在&#x2F;app 目录下查找文件，但不希望在&#x2F;app&#x2F;bin 目录下查找: 1find /app -name &quot;/app/bin&quot; -prune -o -print 使用 type 选项: 如果要在&#x2F;etc 目录下查找所有的目录: 1find /etc -type d -print 如果要在&#x2F;etc 目录下查找.svn 的目录: 1find /etc -name .svn -type d -print 为了在当前目录下查找除目录以外的所有类型的文件: 1find . ! -type d -print 为了在当前目录下查找所有的符号链接文件，可以用: 1find . -type | -print 为了用 ls -l 命令列出所匹配到的文件，可以把 ls -l 命令放在 find 命令的 -exec 选项中: 1find . -type f -exec ls -l &#123;&#125; \\; 注：f 表示普通文件 shell 脚本各种执行方式source ./*.sh . ./*.sh ./*.sh 的区别 ./*.sh 的执行方式等价于 sh ./*.sh 或者 bash ./*.sh， 此三种执行脚本的方式都是重新启动一个子 shell,在子 shell 中执行此脚本。 .source ./*.sh 和 . ./*.sh 的执行方式是等价的，即两种执行方式都是在当前 shell 进程中执行此脚本，而不是重新启动一个 shell 而在子 shell 进程中执行此脚本。验证依据：没有被 export 导出的变量（即非环境变量）是不能被子 shell 继承的验证结果： 12345678910111213141516[root@localhost ~]#name=dangxu //定义一般变量[root@localhost ~]# echo $&#123;name&#125;dangxu[root@localhost ~]# cat test.sh //验证脚本，实例化标题中的./*.sh#!/bin/shecho $&#123;name&#125;[root@localhost ~]# ls -l test.sh //验证脚本可执行-rwxr-xr-x 1 root root 23 Feb 611:09 test.sh[root@localhost ~]# ./test.sh //以下三个命令证明了结论一[root@localhost ~]# sh ./test.sh[root@localhost ~]# bash ./test.sh[root@localhost ~]# . ./test.sh //以下两个命令证明了结论二dangxu[root@localhost ~]# source ./test.shdangxu[root@localhost ~]# 变量定义Shell 支持自定义变量，不区分数据类型,全部识别为字符串 定义变量时，命名符合标识符规定，变量名不加 $ 符号 varName=&quot;value&quot; 注意变量名和等号之间不能有空格，同时变量名的命令遵循以下规则 首个字符必须为字母 中间不能有空格，支持下划线 不能使用标点符号，不能使用 bash 里的关键字 使用使用一个定义过的变量，只要在变量名前面加 $ 符号即可 12echo $varNameecho $&#123;varName&#125; //&#123;&#125;帮助进行边界识别 变量名外的花括号时可选的，可以用于帮助解释器识别变量，比如下面这种情况 1234for skill in Adado\techo &quot;i am good at $&#123;skill&#125;Script&quot;done 如果不给 skill 变量加{}，解释器会把 $skillScript 当成一个变量 重新定义已定义的变量可以被重新定义 1234myUrl=&quot;http://see.xidian.edu.cn/cpp/linux/&quot;echo $&#123;myUrl&#125;myUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;echo $&#123;myUrl&#125; 第二次赋值的时候不能写 $myUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;，只有使用变量时才加 $ 符号 只读变量使用 readonly 可以将变量定义为只读变变量，只读变量的值不能被改变 1234#!/bin/bashmyUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;readonly myUrlmyUrl=&quot;http://see.xidian.edu.cn/cpp/danpianji/&quot; 运行脚本，会报如下错误： /bin/sh: NAME: This variable is read only. 删除变量使用 unset 可以删除变量，unset 不能删除只读变量 12unset 变量名set 显示本地的所有变量 变量类型位置变量接收用户参数 $0 表示当前脚本名称 $1 表示接收的第一个命令行参数 $2 表示第二个命令行参数，以此类推 123456$# 参数的个数$? 命令执行结果,函数返回结果,$$ 进程id$1,$2..$9,$&#123;10&#125;, $&#123;11&#125;$@ &quot;&quot;$* &quot;$*&quot; 当做整体处理 环境变量 (全局可以访问的变量)脚本中定义的变量只在本脚本有效 12envexport 变量名 //将局部变量变为全局变量 特殊变量 $0 当前脚本的文件名 $n 传递给脚本或函数的参数，$1,$2 $# 传递给脚本或函数的参数个数 $* 传递给脚本或函数的所有参数 $@ $? 上个命令的退出状态或函数的返回值 $$ 当前 shell 进程 ID $* 和 $@ 的区别 12345678910111213141516171819202122232425#!/bin/bashecho &quot;\\$*=&quot; $*echo &quot;\\&quot;\\$*\\&quot;=&quot;&quot;$*&quot;echo &quot;\\$@=&quot; $@echo &quot;\\&quot;\\$@\\&quot;=&quot;&quot;$@&quot;echo &quot;print each param from \\$*&quot;for var in $*do\techo &quot;$var&quot;doneecho &quot;print each param from \\$@&quot;for var in $@do\techo &quot;$var&quot;doneecho &quot;print each param from \\&quot;\\$*\\&quot;&quot;for var in &quot;$*&quot;do\techo &quot;$var&quot;doneecho &quot;print each param from \\&quot;\\$@\\&quot;&quot;for var in &quot;$@&quot;do\techo &quot;$var&quot;done 运行 .&#x2F;test.sh “a” “b” “c” “d”，看到下面的结果： 12345678$*= a b c d&quot;$*&quot;= a b c d$@= a b c d&quot;$@&quot;= a b c dprint each param from $*abcdprint each param from $@abcdprint each param from &quot;$*&quot;a b c dprint each param from &quot;$@&quot;abcd 替换，运算符，字符串，数组替换如果表达式中包含特殊字符，Shell 将会进行替换。例如，在双引号中使用变量就是一种替换，转义字符也是一种替换。 123#!/bin/basha=10echo -e &quot;Value of a is $a &quot; 这里 -e 表示对转义字符进行替换。如果不使用 -e 选项，将会原样输出 1Value of a is 10 命令替换命令替换是将一个命令的输出作为另一个命令的参数。命令格式如下所示。 1command1 `command2` 其中，命令 command2 的输出将作为命令 command1 的参数。 1ls `pwd` //这里是反引号,和~是同一个按键 pwd 命令用于显示当前目录的绝对路径。在上面的命令行中，使用命令置换符，将 pwd 的运行结果作为 ls 命令的参数。最终，命令执行结果是显示当前目录的文件内容。 需要注意命令置换和管道 pipe 的区别 变量替换变量替换可以根据变量的状态（是否为空、是否定义等）来改变它的值可以使用的变量替换形式 形式 说明 ${var} 变量本来的值 ${var:-word} 如果变量 var 为空或已被删除 (unset)，那么返回 word，但不改变 var 的值。 ${var:&#x3D;word} 如果变量 var 为空或已被删除(unset)，那么返回word，并将 var 的值设置为 word。 ${var:?message} 如果变量 var 为空或已被删除 (unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值。若此替换出现在 Shell 脚本中，那么脚本将停止运行。 ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值。 运算符Bash 支持很多运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符算数运算符awk 和 expr，expr 12345#!/bin/bashval=`expr 2 + 2`echo &quot;value : $val&quot;val=`expr 2 \\* 2`echo &quot;value : $val&quot; 输出 value : 4 value : 4 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2 完整的表达式要被 &#96;&#96; 包含，注意这个字符不是常用的单引号，在 Esc 键下边 乘号 * 前边必须加反斜杠 \\ 才能实现乘法运算 12345678`+``-``*``/``%`取余`=`赋值`==`相等`!=`不等 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字-eq 相等-ne 不等-gt 左侧大于右侧，返回 true-lt 小于-ge 大于等于-le 小于等于布尔运算符! 非-a 与-o 或字符串运算符 1[ -z $String ] echo $? 12345`=` 检测两个字符串是否相等，相等返回 true。`!=` 不等`-z` 检测字符串长度是否为0，为0返回 true`-n` 检测字符串长度是否为0，不为0返回 true`str` 检测字符串是否为空，不为空返回 true。 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性 1[ -d /etc/fstab ] echo $? 操作符 作用 -b file 检测文件是否是块设备文件 -c file 检测文件是否是字符设备文件 -d file 检测文件是否是目录 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件） -g file 检测文件是否设置了 SGID 位 -k file 检测文件是否设置了粘着位 (Sticky Bit) -p file 检测文件是否是具名管道 -u file 检测文件是否设置了 SUID 位 -r file 检测文件是否可读 -w file 检测文件是否可写 -x file 检测文件是否可执行 -s file 检测文件是否为空（文件大小是否大于 0） -e file 检测文件（包括目录）是否存在 字符串字符串可以用单引号，也可以用双引号，也可以不用引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号里可以有变量 双引号里可以出现转义字符 数组bash 支持一维数组（不支持多维数组），并且没有限定数组的大小。类似与 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组 在 Shell 中，用括号来表示数组，数组元素用“空格”符号分割开。定义数组的一般形式为： 1array_name=(value1 ... valuen) 还可以单独定义数组的各个分量： 123array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组读取数组元素值的一般格式是： 1$&#123;array_name[index]&#125; 使用 @ 或 * 可以获取数组中的所有元素 12$&#123;array_name[*]&#125;$&#123;array_name[@]&#125; 获取数组长度或取数组长度的方法与获取字符串长度的方法相同，例如： 123456# 取得数组元素的个数length=$&#123;#array_name[@]&#125;# 或者length=$&#123;#array_name[*]&#125;# 取得数组单个元素的长度lengthn=$&#123;#array_name[n] 逻辑语句功能语句read 是用来读取用户输入信息的命令，能够把接收到的用户输入信息赋值给后面的指定变量，-p 参数用于向用户显示一定的提示信息。 操作符 作用 -p “ 提示内容 “ -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 1234read -n 5 AA BB CCread AA BB CChello xiaoming, mingtian you kongread -p &quot;Enter your score（0-100）：&quot; GRADE 判断语句判断语句格式： 1[ 条件表达式 ] 对应两边应均有一个空格 逻辑测试语句： &amp;&amp; 与 (当前面的命令执行成功后才会执行它后面的命令) 或（当前面的命令执行失败后才会执行它后面的命令） ！ 非（把条件测试中的判断结果取相反值） 得到当前内存剩余量： 12FreeMem=`free -m | grep Mem: | awk &#x27;&#123;print $4&#125;&#x27;`[ $FreeMem -lt 1024 ] &amp;&amp; echo &quot;Insufficient Memory&quot; break 语句break 命令允许跳出所有循环（终止执行后面的所有循环）。在嵌套循环中，break 命令后面还可以跟一个整数，表示跳出第几层循环。例如： 1break n //表示跳出第 n 层循环。 continue 语句continue 命令与 break 命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。同样，continue 后面也可以跟一个数字，表示跳出第几层循环。 结构语句case 123456789casecase var in1)...;;2|3|4)...;;esac case 工作方式如上所示。取值后面必须为关键字 in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。;; 与其他语言中的 break 类似，意思是跳到整个 case 语句的最后。 demo: 123456789101112#!/bin/bashread -p &quot;请输入一个字符，并按Enter键确认：&quot; KEYcase &quot;$KEY&quot; in[a-z]|[A-Z]) echo &quot;您输入的是 字母。&quot; ;;[0-9]) echo &quot;您输入的是 数字。&quot; ;;*) echo &quot;您输入的是 空格、功能键或其他控制字符。&quot;esac 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 if 1234567if [ ] thenelsefiif [ ] thenelif [ ] thenelsefi demo: 1234567891011121314#!/bin/bashread -p &quot;Enter The Users Password : &quot; PASSWDfor UNAME in `cat users.txt`doid $UNAME &amp;&gt; /dev/null （&amp;&gt;就是&quot;&gt;&quot;和&quot;2&gt;&quot;这两个的结合体）if [ $? -eq 0 ] then echo &quot;Already exists&quot;else useradd $UNAME &amp;&gt; /dev/null echo &quot;$PASSWD&quot; | passwd --stdin $UNAME &amp;&gt; /dev/null if [ $? -eq 0 ] then echo &quot;$UNAME , Create success&quot; else echo &quot;$UNAME , Create failure&quot; fifidone 循环语句for 12345678910for 变量 in 列表do..donefor ((i=0; i&lt;N; i++))dodonefor var in `ls`for var in $(ls)for var #列表的内容是位置参数变量时，可以省略in ... 列表是一组值（数字、字符串等）组成的序列，每个值通过空格分隔。每循环一次，就将列表中的下一个值赋给变量。 demo: 12345678910HLIST=`echo www.baidu.com`for IP in $HLISTdo ping -c 3 -i 0.2 -W 3 $IP &amp;&gt; /dev/nullif [ $? -eq 0 ] then echo &quot;baidu is online&quot;else echo &quot;baidu is offline&quot;fidone while 12345678while 表达式do..donewhile (($i &lt; $loop))do...done while 循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。 demo: 12345678910111213141516PRICE=$(expr $RANDOM % 1000)TIMES=0echo &quot;商品实际价格为0-999之间，猜猜看是多少？&quot;while truedo read -p &quot;请输入您猜测的价格数目：&quot; INT let TIMES++ if [ $INT -eq $PRICE ] ; then echo &quot;恭喜您答对了，实际价格是 $PRICE&quot; echo &quot;您总共猜测了 $TIMES 次&quot; exit 0 elif [ $INT -gt $PRICE] ; then echo &quot;太高了！&quot; else echo &quot;太低了！&quot; fidone untilluntil 循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。一般 while 循环优于 until 循环。 123456a=0until [ ! $a -lt 10 ]doecho $aa=`expr $a + 1`done 函数函数定义 12345678function_name () &#123; list of commands [ return value ]&#125;function function_name () &#123; list of commands [ return value ]&#125; 如果你希望直接从终端调用函数，可以将函数定义在主目录下的 .profile 文件，这样每次登录后，在命令提示符后面输入函数名字就可以立即调用。返回值函数返回值，可以显式增加 return 语句；如果不加，会将最后一条命令运行结果作为返回值。接收函数返回值用 $?。Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0 表示成功，其他值表示失败。（返回值范围 0-255）如果 return 其他数据，比如一个字符串，往往会得到错误提示：“numeric argument required”。如果一定要让函数返回字符串，那么可以先定义一个变量，用来接收函数的计算结果，脚本在需要的时候访问这个变量来获得函数返回值。调用调用函数只需要给出函数名，不需要加括号。 12345678910Hello() &#123;echo &quot;hello, world&quot;&#125;HelloHello2() &#123;echo &quot;hello2, world&quot;return 1&#125;Hello2ret=$? 输出给了变量 1var=$(Hello2) 删除像删除变量一样，删除函数也可以使用 unset 命令，不过要加上 .f 选项，如下所示： 1unset .f function_name 参数在 Shell 中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1 表示第一个参数，$2 表示第二个参数 获取第十个参数需要 $&#123;10&#125;。当 n&gt;&#x3D;10 时，需要使用 $&#123;n&#125; 来获取参数。 $# 传递给函数的参数个数。 $* 显示所有传递给函数的参数。 $@ 与 $* 相同，但是略有区别 $? 函数的返回值。 传参: 123function add_fun () &#123;&#125;add_fun str1 str2 str3 文件包含Shell 也可以包含外部脚本，将外部脚本的内容合并到当前脚本。 12. filenamesource filename 两种方式的效果相同，简单起见，一般使用点号 (.)，但是注意点号 (.) 和文件名中间有一空格 被包含脚本不需要有执行权限 补充环境变量环境变量一般是指在操作系统中用来指定操作系统运行环境的一些参数，比如临时文件夹位置和系统文件夹位置等等。 变量种类 按变量的生存周期来划分，Linux 变量可分为两类： 永久的：需要修改配置文件，变量永久生效。 临时的：使用 export 命令声明即可，变量在关闭 shell 时失效。设置环境变量 在&#x2F;etc&#x2F;profile 文件中添加变量【对所有用户生效（永久的）】 用 VI 在文件&#x2F;etc&#x2F;profile 文件中增加变量，该变量将会对 Linux 下所有用户有效，并且是“永久的”。例如：编辑&#x2F;etc&#x2F;profile 文件，添加 PATH 变量 1 export PATH=/home/fs : $PATH &gt; 注：修改文件后要想马上生效还要运行# source &#x2F;etc&#x2F;profile 不然只能在下次重进此用户时生效。 在用户目录下的.bash_profile 文件中增加变量【对单一用户生效（永久的）】 用 VI 在用户目录下的.bash_profile 文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。 例如：编辑 guok 用户目录（&#x2F;home&#x2F;guok）下的.bash_profile，添加如下内容： 1 export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &gt; 注：修改文件后要想马上生效还要运行 $ source &#x2F;home&#x2F;guok&#x2F;.bash_profile 不然只能在下次重进此用户时生效。 直接运行 export 命令定义变量【只对当前 shell（BASH）有效（临时的）】 在 shell 的命令行下直接使用 [export 变量名&#x3D;变量值] 定义变量，该变量只在当前的 shell（BASH）或其子 shell（BASH）下是有效的，shell 关闭了，变量也就失效了，再打开新 shell 时就没有这个变量，需要使用的话还需要重新定义。PATH 声明其格式为：PATH=$PATH: 你可以自己加上指定的路径，中间用冒号隔开。环境变量更改后，在用户下次登陆时生效。如果想立刻生效，则可执行下面的语句：$source .bash_profile需要注意的是，最好不要把当前路径 ./ 放到 PATH 里，这样可能会受到意想不到的攻击。完成后，可以通过 $ echo $PATH 查看当前的搜索路径。这样定制后，就可以避免频繁的启动位于 shell 搜索的路径之外的程序了。常用的环境变量 变量名 内容 PATH 决定了 shell 将到哪些目录中寻找命令或程序 HOME 当前用户主目录 HISTSIZE 历史记录数 LOGNAME 当前用户的登录名 HOSTNAME 指主机的名称 SHELL 当前用户 Shell 类型 LANGUGE 语言相关的环境变量，多语言可以修改此环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符，对于 root 用户是#，对于普通用户是 $ 常用的环境变量相关命令 设置一个新的环境变量 hello 1234 fs@ubuntu:~$ export HELLO=&quot;Hello&quot; fs@ubuntu:~$ echo $HELLO Hello fs@ubuntu:~$ 使用 env 命令显示所有的环境变量 12 fs@ubuntu:~$ env .... 使用 set 命令显示所有本地定义的 Shell 变量，set 可以设置某个环境变量的值。 12 fs@ubuntu:~$ set ... 使用 unset 命令来清除环境变量，清除环境变量的值用 unset 命令。如果未指定值，则该变量值将被设为 NULL。示例如下： 12345 fs@ubuntu:~$ export TEST=&quot;Test&quot; \\\\增加一个环境变量TEST fs@ubuntu:~$ env | grep TEST \\\\此命令有输出，证明环境变量TEST已存在 TEST=Test fs@ubuntu:~$ unset $TEST \\\\删除环境变量TEST fs@ubuntu:~$ env | grep TEST \\\\此命令没输出，证明环境变量TEST已经存在 使用 readonly 命令设置只读变量，如果使用了 readonly 命令的话，变量就不可以被修改或清除了。示例如下： 1234567 fs@ubuntu:~$ export TEST=&quot;Test&quot; \\\\增加一个环境变量TEST fs@ubuntu:~$ readonly TEST \\\\将环境变量TEST设为只读 fs@ubuntu:~$ unset TEST \\\\此变量无法删除 bash: unset: TEST: cannot unset: readonly variable fs@ubuntu:~$ TEST=&quot;NEW&quot; \\\\此变量不可更改 bash: TEST: readonly variable fs@ubuntu:~$ 计划任务服务程序一次性计划任务“at 时间 “ 是一个命令行工具，用于在指定的时间执行一次性任务。通过使用该命令，您可以安排计划在将来的某个时间运行的命令或脚本。时间参数可以采用多种格式，如 HH:MM，HH:MM AM&#x2F;PM 或者明天的日期。例如，以下命令将在下午 2 点运行一个脚本： 1at 2pm &lt;脚本路径&gt; 查看计划任务“at -l” 命令用于列出当前计划的 at 任务列表，显示已经被安排的任务及其相关信息，如任务序号、执行时间等。例如，以下命令将列出当前计划的 at 任务列表： 1at -l 取消计划任务“atrm 任务序号 “ 命令用于取消一个已经计划的 at 任务，其中任务序号是通过 “at -l” 命令列出的任务的序号。例如，以下命令将取消任务序号为 1 的 at 任务： 1atrm 1 长期性计划任务crontab -e 创建、编辑计划任务crontab -l 查看当前计划任务crontab -r 删除某条计划任务crontab -u 编辑他人的计划任务demo: 1234crontab -ecrontab -l&gt;25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar /home/wwwrootwhereis rm 时间周期设置： 125 3 * * 1,3,5 依次对应 分钟，小时，日期，月份，星期 任务内容: 要运行的命令 1/usr/bin/tar -czvf backup.tar /home/wwwroot 终端和控制台终端 (terminal，或者叫物理终端）：是一种设备，不是一个程序，一般说的就是能提供命令行用户界面的设备，典型的是屏幕和键盘，或其他的一些物理终端。 虚拟终端：屏幕和键盘只是一个终端，可能不够用，又不想增加设备投入，就产生了虚拟终端。gnome-terminal,urxvt，mlterm，xterm 等等是一个程序，职责是模拟终端设备，和虚拟终端的区别表面上在于它以 GUI 形式的窗口出现，内部则是程序结构和系统控制结构有所不同，但本质上差不多。控制台（console):显示系统消息的终端就叫控制台，Linux 默认所有虚拟终端都是控制台，都能显示系统消息。有时专指 CLI 下的模拟终端设备的一个程序，和 gnome-terminal,urxvt，mlterm，xterm 等相同，只是 CLI 和 GUI 界面的区别。一般 console 有 6 个，tty1-6，CTRL+ALT+f1-6 切换。shell：shell 是一个抽象概念，shell 的一切操作都在计算机内部，负责处理人机交互，执行脚本等，是操作系统能正常运行的重要组成部分,bash，ash，zsh，tcsh 等是 shell 这个抽象概念的一种具体的实现，都是一个程序，都能生成一个进程对象如果想换 shell 的程序，可以修改&#x2F;etc&#x2F;passwd，把里面的&#x2F;bin&#x2F;bash 换成你想要的 shell，或者用 chsh 命令来切换shell 与终端的关系：shell 把一些信息适当的输送到终端设备，同时还接收来自终端设备的输入。一般每个 shell 进程都会有一个终端关联，也可以没有。 12字符程序 &lt;---&gt; 虚拟终端 &lt;---&gt; 图像显示shell &lt;---&gt; xterm &lt;---&gt; X11 控制台和终端的历史遗留区别计算机最初由于价格昂贵，因此，一台计算机一般是由多个人同时使用的。在这种情况下一台计算机需要连接上许多套键盘和显示器来供多个人使用。 在以前专门有这种可以连上一台电脑的设备，只有显示器和键盘，还有简单的处理电路，本身不具有处理计算机信息的能力，他是负责连接到一台正常的计算机上（通常是通过串口） ，然后登陆计算机，并对该计算机进行操作。 当然，那时候的计算机操作系统都是多任务多用户的操作系统。 这样一台只有显示器和键盘能够通过串口连接到计算机 的设备就叫做终端。 而控制台又是什么回事呢？ 学机电的人应该知道，一台机床，或者数控设备的控制箱，通常会被称为控制台，顾名思义，控制台就是一个直接控制设备的台面（一个面板，上面有很多控制按钮）。 在计算机里，把那套直接连接在电脑上的键盘和显示器就叫做控制台。 请注意它和终端的区别，终端是通过串口连接上的，不是计算机本身就有的设备，而控制台是计算机本身就有的设备，一个计算机只有一个控制台。 计算机启动的时候，所有的信息都会显示到控制台上，而不会显示到终端上。 也就是说，控制台是计算机的基 本设备，而终端是附加设备。 当然，由于控制台也有终端一样的功能，控制台有时候也被模糊的统称为终端。 计算机操作系统中，与终端不相关的信息，比如内核消息，后台服务消息，都可以显示到控制台上，但不会显示到终端上。 现在普通用户可以简单的把终端和控制台理解为：可以输入命令行并显示程序运行过程中的信息以及程序运行结果的窗口。 不必要严格区分这两者的差别。 现在由于计算机硬件越来越便宜，通常都是一个人独占一台计算机超做，不再连接以前那种真正意义上的“终端设备了”，因此，终端和控制台的概念也慢慢演化了。 终端和控制台由硬件的概念，演化成了软件的概念。 现在说的终端，比如 linux 中的虚拟终端，都是软件的概念，他用计算机的软件来模拟以前硬件的方式。 比如在 linux 中，你用 alt+f1 ~ f6 可以切换六个虚拟终端，就好比是以前多人公用的计算机中的六个终端设备，这就是为什么这个叫“虚拟终端”的原因。 当然，现在的 linux 也可以通过串口 线，连接一个真正的终端，现在这种终端设备已经非常罕见了，但是还存在，只是一般人很难见到。 也有人利用以前的老电脑（386，486）装上一个串口通信软件，连上一台计算机，来模拟一个终端来用。这样可以达到一台电脑多人使用的目的。 简单的说，能直接显示系统消息的那个终端称为控制台，其他的则称为终端。 但是在 linux 系统中，这个概念也已经模糊化了。 比如下面这条命令： 1echo &quot;hello,world&quot; &gt; /dev/console 这条命令的目的是将 “hello,world” 显示到控制台上&#x2F;dev&#x2F;console 是控制台设备的设备名。 在 linux 中，在字符模式下，你无论在哪个虚拟终端下执行这条命令，字符 hello,world 都会显示在当前的虚拟终端下。也就是说，linux 把当前的终端当作控制台来看待。可见，linux 中已经完全淡化了控制台和终端的区别。 但是在其他的 UNIX 类系统中，却很明显的有虚拟终端和控制台的区别。比如 freeBSD 系统。在 freebsd 中，只有第一个“终端”才是真正的控制台。（就是说按 alt+f1 得到的那个虚拟终端），你无论在哪个虚拟终端上执行上面的那条命令（哪怕是通过网络连接的伪终端上执行这条命令）。hello,world 字符总会显示到第一个“终端”也就是 真正的控制台上。 另外，其他的一些系统内部信息，比如哪个用户在哪个终端登陆，系统有何严重错误警告等信息，全都显示在这个真正的控制台上。在这里，就明显的区分了终端和控制台的概念。其他 UNIX 中也是这样的。 比如 Tru64 unix 在 X 下有一个控制台模拟软件，你无论在哪里输入 echo &quot;hello,world&quot; &gt; /dev/console 命令，hello,world 总会显示在这个控制台模拟器中。 我们在 X 界面下用的那些输入命令的软件，比如 xterm ,rxvt, gnome-terminal 等等，都应该被称为终端模拟软件。 请注意它和控制台模拟软件的区别。 linux 中好象没有控制台模拟软件。 在 X 中的终端模拟 软件中输入的 echo &quot;hello,world&quot;&gt;/dev/console 命令的输出信息，都会输出到启动该 X 服务器的虚拟终端上。 比如，你用字符方式登陆系统。进入第一个虚拟终端，然后 startx 启动 X 服务器。 再打开 xterm 来输入 echo &quot;hello,world&quot;&gt;/dev/console 命令，那么字符串 hello,world 就显示在第一个虚拟终端上。 你按 ctrl+alt+f1，回到那个启动 X 服务器的终端，就可以看到 hello, world 字符串。 现在该明白终端和控制台的区别了吧。 再简单的说，控制台是直接和计算机相连接的原生设备，终端是通过电缆、网络等等和主机连接的设备。在以前的硬件终端设备中，由于生产厂家不同，所遵循的标准不同，因此有不同的型号标准。 比如 vt100 等。这里的 vt100 就是一个标准，那么现在我 们所说的终端，往往不是真正的硬件终端了，而是终端模拟软件了，因此不同的终端模拟软件可能符合不同的标准，还有一些终端模拟软件符合很多种不同终端的标准。 比如 gnome 的终端模拟软件 gnome-terminal，他提供好几中标准可供用户选择。 用户只要设置一下就可以了。现在，由于原先的这些设备在我们的视线中渐渐淡出，控制台和终端的概念也慢慢谈化。","tags":["语言"],"categories":["语言"]},{"title":"正则表达式笔记","path":"/2024/05/17/语言-正则表达式笔记/","content":"正则表达式什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。 正则表达式就是记录文本规则的代码，用于模式匹配和搜索文本的工具。 正则表达式的模式 字面值字符：普通字符按照字面意义进行匹配,例如字母、数字、空格等，可以直接匹配它们自身。 特殊字符：例如点号 .、星号 *、加号 +、问号 ? 等，它们具有特殊的含义和功能。 字符类：用方括号 [ ] 包围的字符集合，用于匹配方括号内的任意一个字符。[^ ] 匹配除了括号内的字符以外的任意一个字符 元字符：例如 \\d、\\w、\\s 等，用于匹配特定类型的字符，如数字、字母、空白字符等。 量词：例如 &#123;n&#125;、&#123;n,&#125;、&#123;n,m&#125; 等，用于指定匹配的次数或范围。 边界符号：例如 ^、$、\\b、\\B 等，用于匹配字符串的开头、结尾或单词边界与非边界位置。 分组和捕获：( )：用于分组和捕获子表达式。(?: )：用于分组但不捕获子表达式。 字符字符匹配直接在方括号里列出： [aeiou] 就匹配任何一个英文元音字母 [.?!] 匹配标点符号 (.或?或!) 也可以指定一个字符范围： [0-9] 代表的含意与\\d 就是完全一致的：一位数字 [a-z0-9A-Z_] 也完全等同于\\w。 普通字符 字符 含义 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（ 、\\r）之外的任何单个字符，相等于 [^ \\r]。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] 非打印字符 字符 含义 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 特殊字符 字符 含义 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则$ 也匹配 ‘ ’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。 * 匹配前面的子表达式零次或多次。要匹配 * 字符，请使用*。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。 . 匹配除换行符 之外的任何单字符。要匹配 . ，请使用 . 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 [。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’ ’ 匹配换行符。序列 ‘&#39; 匹配 “&quot;，而 ‘(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用^。 { 标记限定符表达式的开始。要匹配 {，请使用 {。 | 指明两项之间的一个选择。要匹配|，请使用 |。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。例如 IP 地址表达式:((2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?).)&#123;3&#125;(2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?) 限定符 字符 含义 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于 {0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 “do” 、 “does”、 “doxy” 中的 “do” 和 “does”。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 含义 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 或 \\r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 或 \\r 之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 不能将限定符与定位符一起使用。由于在紧靠换行或者单词边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式 转义字符与反义字符 在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。 反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法 (?#comment) 来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。 如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。 前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样 .*? 就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 现在看看懒惰版的例子吧： a.*?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?&#x3D;), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，” 或 “ 操作,字符具有高于替换运算符的优先级，使得&#96;m 反向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本 (也就是此分组捕获的内容) 可以在表达式或其它程序中作进一步的处理。 反向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b 可以用来匹配重复的单词，像 go go, 或者 kitty kitty。 总结 确定需要匹配的基本字符或字符类别&#x2F;集合等 确定匹配的字符或字符集合的数量 特殊字符和转义字符的处理 边界和位置的匹配 使用捕获组 () 进行多组匹配 使用反向引用 使用逻辑操作符进行判定 正则表达式字符含义表 字符 含义 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 “n”。\\ 匹配一个换行符。序列 \\\\ 匹配 “\\ 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \\ 或 \\\\r 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 \\ 或 \\\\r 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o&#123;2&#125; 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o&#123;2,&#125; 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o&#123;1,&#125; 等价于 o+。o&#123;0,&#125; 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。o&#123;0,1&#125; 等价于 o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，o+? 将匹配单个 “o”，而 o+ 将匹配所有 o。 . 匹配除换行符（ 、\\r）之外的任何单个字符。要匹配包括 \\ 在内的任何字符，请使用像 &#96;(. )&#96; 的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在 VBScript 中使用 SubMatches 集合，在 JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ( 或 )。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “ 或 “ 字符 (&#96; ) 来组合一个模式的各个部分是很有用。例如， industr(?:y (?&#x3D;pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，&#96;Windows(?&#x3D;95 98 (?!pattern) 正向否定预查 (negative assert)，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如 &#96;Windows(?!95 98 (?&lt;&#x3D;pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，&#96;(?&lt;&#x3D;95 98 (? 反向否定预查，与正向否定预查类似，只是方向相反。例如 “(?” 能匹配 “3.1Windows” 中的 “Windows”，但不能匹配 “2000Windows” 中的 “Windows”。 &#96;x y&#96; 匹配 x 或 y。例如，&#96;z [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 “plain” 中的 a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，[^abc] 可以匹配 “plain” 中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\\\\b 可以匹配”never” 中的 er，但不能匹配 “verb” 中的 er。 \\B 匹配非单词边界。er\\\\B 能匹配 “verb” 中的 er，但不能匹配 “never” 中的 er。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的c 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\\\x41 匹配 “A”。\\\\x041 则等价于 \\\\x04 &amp; “1”。正则表达式中可以使用 ASCII 编码。 um 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)\\\\1 匹配两个连续的相同字符。 标识一个八进制转义值或一个向后引用。如果 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 m 标识一个八进制转义值或一个向后引用。如果 m 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 m 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 m 将匹配八进制转义值 nm。 ml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。 &#96;","tags":["语言"],"categories":["语言"]},{"title":"3D打印机介绍及环境配置","path":"/2024/05/17/其他-3D打印机-3D打印机介绍及环境配置/","content":"3D 打印机3D 打印（3D printing）是一种快速成型技术，也被称为添加制造（Additive Manufacturing，AM）。它是一种通过将材料逐层叠加以构建三维实体物体的过程。与传统的制造方法不同，3D 打印不需要模具或切削工具，而是通过从计算机辅助设计（CAD）模型中生成的数字模型直接创建物体。 FDM（熔融沉积成型）：FDM 是目前最常见的 3D 打印技术，它使用热塑性材料通过打印头喷出的方式逐层堆积，最终形成所需的物体。FDM 打印机的结构和控制系统比较简单，价格也比较实惠，因此广泛应用于家庭、办公室和教育等领域。 SLA（光固化成型）：SLA 使用紫外线激光器或 LED 光源照射光敏树脂，使其逐层固化成为所需的物体。SLA 打印机的精度和表面光滑度比 FDM 更高，但价格也更贵。 SLS（选择性激光烧结）：SLS 使用激光束将热塑性粉末烧结在一起，逐层堆积形成所需的物体。SLS 打印机可以使用多种材料，可以打印出更复杂的结构，但价格也更昂贵。 DLP（数字光处理）：DLP 使用光敏树脂和数字投影仪，通过投影仪将光固化在涂层的树脂上，逐层堆积形成所需的物体。DLP 打印机的速度和精度都比较高，但价格也较贵。 FDM通过将加热的材料挤出打印头，逐层堆积形成打印件 打印头 打印床&#x2F;热床 控制系统（主板、电机、传感器和用户界面） 打印材料 G-Code 一种用于控制数控机床（包括 3D 打印机、数控铣床、数控车床等）运动和操作的编程语言。 结构结构主要分为两部分： 一个负责三维空间的移动的组件 (三维移动部分) 一个负责进料、融化材料和挤出材料的组件（挤出部分） 打印时材料会一层又一层地堆积在之前已经「挤出来」的材料上，所以在这两个组件共同协作下就能打印出一个完成的 3D 物体了。 结构 - 三维移动部分打印机在 3D 的空间运动的传动方式有很多种，一般较为便宜的打印机会选择笛卡尔结构。笛卡尔结构指的是 X Y Z 方向上的运动是独立的，这种方式比较直观，结构也比较简单。常用的 3D 打印机的结构有以下几种： Prusa i3 型：控制 X&#x2F;Z 轴，Y 轴通过工作台的移动来实现。CoreXY 型：CoreXY 最大的特别之处在于其 X、Y 电机是协同运作的，并且它的同步带在不同同步轮的摆放下能够形成多种不一样的缠绕方法。由于两个电机的协同运动，电机带动的力比单一电机的力要大，且会减少在 XY 方向面上的一个电机重量，提高精准性。**CoreXY 结构：CoreXY 结构采用的是两个电机通过传动带和滑块来实现打印头的运动，其中 X 和 Y 轴的传动带交叉布置，使得打印头的运动方向可以在 X 和 Y 轴上独立控制。CoreXY 结构的优点是打印速度快，同时打印头的重量对定位精度的影响较小，同时可以实现较大的打印范围。缺点是结构复杂，需要更多的零件和更高的制造精度，同时维护和升级也较为困难。 Um &#x2F;Ultimaker 型：X 轴、Y 轴的电机都在静止的框架上，但挤出头在两个互相垂直的光轴的交叉处。**UM 结构（Ultimaker 结构）：UM 结构采用的是直线轴承和滑块来实现运动，其中 X 和 Y 轴分别由两个电机驱动，通过传动带和滑块来实现打印头的运动。UM 结构的优点是定位精度高，速度快，同时结构简单，易于维护和升级。缺点是打印头的质量和稳定性对定位精度有较大影响，同时打印头的重量也会影响打印速度。 MB：主要体现在挤出电机一般都装在喷头旁，近程进丝，双光轴承载挤出组件，X 方向的运动一般是通过电机带动同步带，通过带传动使两边一起运动。 delta 三角洲（并联臂）型 结构 - 挤出部分挤出部分分为以下： 挤出头 送料步进电机 送料步进电机驱动板 FDM 3D 打印机除了怎么动的很关键以外，怎么取料、融化材料、挤出材料也非常重要。 其中取料和挤出材料是由挤出机处理的，融化材料则是由热端处理的。 挤出机从材料盘中将材料拉出来，送进去热端融化。 并持续往热端送更多的料让融化的材料从喷嘴中挤出来。 其中挤出机的精度和挤出的速度决定了打印质量和速度。精度高意味着可以更好的控制挤出的量。挤出的材料太多或者太少对打印的质量影响都非常大。挤出的速度快就很直接的决定了你能打印多快。 而影响挤出机的精度和速度的两个关键因素就是： 挤出机的类型 挤出机的齿轮数量 FDM 挤出机分为两个大类： 远端挤出机 远端挤出机在于挤出机不需要跟着喷嘴一块移动，减轻了需要移动的零件的重量 远端挤出机由于从喷嘴挤出压力的是通过材料本身传递的，所以远端挤出机的反应时间较长，并且对打印的材料比较敏感，例如 TPU 之类的软质材料就没法很好的打印出来 近端挤出机 近程挤出机由于距离热端非常近，所以需要的挤出力量也比较小，这样挤出精度就会更高 近程挤出机是和热端是集成在一起的，因此 X Y 轴上移动的部件的重量增加了，震动也会相对的增加 另外一个影响挤出机精度的就是挤出机的齿轮了。较低端的机器一般都是配备都是单齿轮，虽然对比双齿轮的挤出机，无论是对材料的咬合能力还是挤出精度都表现更差，但它便宜而且工作，对于预算相对比较紧张的朋友是一个不错的选择。 传动系统传动系统分为以下几个部分： Xyz 步进电机 限位开关 步进电机驱动板 同步带 传动系统是 3D 打印机中负责移动打印头（或喷嘴）和打印平台的机械组件。它在 3D 打印过程中发挥以下作用： 控制位置：传动系统通过精确的运动控制，将打印头定位在正确的位置，以便在每个层次上精确地添加材料。 三维定位：传动系统的运动控制使得打印头可以在 X、Y、Z 三个方向上精确移动，从而实现三维打印。 打印速度：传动系统的运动控制还影响到打印速度。更快的传动系统能够加快打印速度，但需要保持精确性和稳定性，以确保打印质量不受影响。 自动校准：一些高级的传动系统具备自动校准功能，能够自动检测打印平台和打印头的位置，从而保持打印的准确性和稳定性。 加热部分加热部分分为以下： 热床 MOS 管打印机的床就是用来承载挤出机挤出来的材料。是 3D 打印机上的一个移动平台，用于支撑正在打印的物体。其主要作用如下： 粘附和稳定：打印平台上的特殊表面或涂层（例如热床、胶水、胶带等）可以提供粘附性，确保打印的第一层材料牢固地附着在平台上，并防止其在打印过程中发生位移或变形。 * 塑料在不同的温度下粘性不一样，控制床的温度可以让不同的塑料在保持形状的同时达到最大的粘性。如果温度太高则有可让打印的形状变形，温度太低则有可能让打印的材料不粘床。床的温度和热端的温度共同决定了可以打印什么材料。如果能顺利融化材料，但是他并不能稳定的黏在床上，打印也会有非常大几率失败。 平整度：打印平台的调平性（平整度）对于打印质量至关重要。如果平台不平整，可能导致打印的物体底部出现变形或不平整的表面。 防止翘曲：特定类型的 3D 打印材料，例如 ABS（丙烯腈 - 丁二烯 - 苯乙烯）等，有时容易在冷却过程中产生翘曲。热床可以在打印过程中加热，有助于减少材料翘曲，提高打印的成功率。 电气系统电气系统分为以下几个模块： 电源 主板（需要烧录固件代码如 Marlin） 显示屏 传感器&#x2F;加热模块等 了解各模块的所需电源电压，功耗等信息选取合适电源了解打印机的所需功能，进行针对性选择主板 其他扩展模块Octoprint 远程监控模块3d 打印的成功率和模型文件、材料、切片 gcode 代码、天气、机器等关联，然后只有在打印中才能知道模型有没有出问题，octoprint 连接 Wifi，通过网页端远程摄像头监控进度，同时能够开始和停止打印机的操作。 自动调平通常机器在几天内调平过一次之后很大几率不用重新调平，但是你对机器的一举一动包括机器自己的老化都会影响热床的位置移动和变形，自动调平模块 3D touch（也有别的）能够让完全手动的调平变成半自动调平。 双 Z 结构顾名思义就是有两根 Z 轴。 单一的 Z 轴由于在一边容易导致 Z 轴变形造成模型垂直方向变形。同时也可能会让 XY 平面在变形的 Z 轴运动受阻。 双 Z 结构不仅能够减少变形，同时增强 Z 轴的稳定性。 硬件硬件选型硬件采用 MKS Gen L v2.1，固件采用 Klipper pin 口图 硬件相关主要考虑因素: 驱动电机数量（根据 3D 打印机的结构方案确定） 限位开关 风扇控制 挤出头控制 热敏电阻（热床&#x2F;加热棒&#x2F;挤出头） 单下位机方案需要支持屏幕接口 上位机方案需要支持 USB 连接 控制架构目前 3D 打印机的主流架构一般情况下，有以下两种方式： 上位机（运行 fluidd 控制软件）+ 下位机（运行 kilpper 固件）+Web 显示 * 由于手头上正好有一块 Linux 开发板，所以准备采用上位机方案，局域网部署（OctoPrint 和 Fluidd 二选一安装配置即可。） 下位机（运行 marlin 固件）+ 串口屏显示 * 优点：只需要一块控制板加上串口屏，不需要上位机控制软件，节约成本 缺点：屏幕小，显示的信息少 固件本次机器组装选择的方案是 klipper，可以很方便的直接在上位机修改打印机参数，不需要每次修改参数后重新烧写固件 在 3D 打印机中，固件是一种运行在单片机上的软件，它控制着 3D 打印机的运动和操作。固件负责将 G 代码转换为实际的运动和操作，例如将 G 代码中的坐标转换为电机的运动，控制加热器的温度等。 固件还负责处理传感器的输入，例如温度传感器、限位开关等，并根据这些输入控制 3D 打印机的运动和操作。 3D 打印机的固件通常是预装在单片机上的，但用户也可以根据需要进行更新和修改，以实现更好的性能和功能。 在 3D 打印领域，主流的固件有以下几种： Marlin：Marlin 是一款开源固件，它是 3D 打印领域最流行的固件之一，具有广泛的硬件支持和强大的功能。 Repetier：Repetier 是另一款流行的开源固件，它具有类似于 Marlin 的功能和支持。 Smoothie：Smoothie 是一款基于 ARM 处理器的开源固件，它支持多个独立的电机和传感器，并具有良好的可扩展性。 Klipper：Klipper 是一款比较新的开源固件，它具有更高的计算能力，可以实现更快的运动和更高的精度。 KlipperKlipper 是一种用于 3D 打印的固件软件，它可以在单片机上运行，控制 3D 打印机的运动。与其他 3D 打印机固件相比，Klipper 具有更高的计算能力，因此可以实现更快的运动和更高的精度。Klipper 还支持多种硬件平台，包括树莓派和 BeagleBone Black 等。使用 Klipper 可以提高 3D 打印机的性能，并且可以通过配置文件进行高度自定义。 MarlinMarlin 是一种用于 3D 打印的开源固件软件，它可以在单片机上运行，控制 3D 打印机的运动。Marlin 是 3D 打印机领域最流行的固件之一，因为它具有广泛的硬件支持和强大的功能。Marlin 支持多种传感器和功能，如自动床平衡、断电续打、LCD 屏幕等。Marlin 还提供了一套易于使用的配置文件，可以通过修改这些文件来对 3D 打印机进行高度自定义。由于 Marlin 是开源软件，因此用户可以根据自己的需要进行修改和定制，以实现更好的性能和功能。 Klipper 固件配置及烧写Klipper 官方文档 https://www.klipper3d.org/zh/Overview.html 建议详细阅读，很多参数和问题都有说明 获取 klipper 源码 1git clone https://github.com/Klipper3d/klipper.git 执行脚本安装一些系统依赖、设置 安装很慢时，可以更换下 pip 的源 pip下载网络问题 1./klipper/scripts/install-octopi.sh 然后配置和构建 123cd ~/klipper/make menuconfigmake 需要确定连接到微控制器的串行端口， 12ls /dev/serial/by-id/*ls /dev/ttyUSB* 可以用类似以下的方法来刷写固件： 123sudo service klipper stopmake flash FLASH_DEVICE=/dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0sudo service klipper start 刷写时要确保 端口没有被占用 控制软件上位机主板采用一块手头空余的 Linux 主板，软件采用 Fluidd，如果是上位机的形式，则由运行在上位机的 3D 打印机控制软件来控制 3D 打印机，主要考虑因素: ARM 架构，功耗低（需要长时间工作） USB 接口，连接下位机 网口，局域网 Web 显示打印机控制 显示屏，本地显示打印机控制 WIFI，可以无线打印 先在 WSL 环境下搭建调试 Fluidd， 适用于 3D 打印机的 Klipper 固件，提供 WEB 页面和控制。Fluidd 项目地址 安装手册 KIAUH (Klipper Installation And Update Helper)安装安装方式采用推荐的安装脚本安装，该脚本不仅可以安装 fluidd，界面如下所示： 执行脚本前需要安装 git sudo apt-get update &amp;&amp; sudo apt-get install git -y 下载 KIAUH 到本地： 1git clone https://github.com/dw-0/kiauh.git 执行脚本 1./kiauh/kiauh.sh KIAUH 的主菜单中。您将看到多个操作可供选择，具体取决于您想要执行的操作。要选择操作，只需在“执行操作”提示中输入相应的数字，然后按 ENTER 确认即可。 通过 kiauh 安装 Klipper 的方式需要下载约 500MB 数据，对连接 GitHub 的网络要求较高，否则会持续安装失败。 moonraker选择 1 Install,需要输入密码，之后选择 2 moonrarker，安装完成后进入浏览器输入 http://127.0.0.1:7125/server/info 测试 moonrarker 是否正常安装。 moonraker 的作用： Moonraker is the API that fluidd communicates with, which in turn communicates with Klipper. All three components are required for a healthy printer. 如果出现 pip 下载速度太慢导致的失败，修改 kiauh&#x2F;scripts&#x2F;moonrarker.sh 在所有的 pip install 后追加 -i https://pypi.tuna.tsinghua.edu.cn/simple/ 或修改 ~/.pip/pip.conf(没有就创建一个)，内容如下： 12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple fluidd选择 1 Install 之后选择 4 Fluidd 进行安装，安装完成后访问 http://127.0.0.1/#/ 正常打开 fluidd 页面 手动安装Fluidd 附带一个 build 脚本，可在项目地址 https://github.com/fluidd-core/fluidd/releases 的 fluidd.zip 中找到。 需要安装 NodeJS (v16.x) 和 Git 克隆 Fluidd 源代码 git clone https://github.com/fluidd-core/fluidd.git 导航到 Fluidd 源代码目录 cd fluidd 安装依赖 npm ci 构建并捆绑 Fluidd npm run build 构建的文件将写入该 dist 目录。您可以使用您首选的 HTTP 服务器来提供这些服务，例如 NGINX。 要出于开发目的构建 Fluidd，请运行 npm run serve 而不是 npm run build 启用热重载。 配置打印机配置文件，一般在用户主目录中名为 printer.cfg 的文件 配置文件示例 /home/linux/printer.cfg。 刷写 Klipper 后，名称可能会改变，检查 USB 节点名称： 123ls /dev/serial/by-id/*或者ls /dev/ttyUSB* 确认节点名称并写入配置文件中去。 123/dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0或者/dev/ttyUSB0 用这个唯一的名字更新配置文件。更新 [mcu] 部分，类似于： 12[mcu]serial: /dev/ttyUSB0 在编辑该文件后，发出 restart 或 FIREWARE_RESTART 命令以重新加载配置（命令根据实际上位机）。如果 Klipper 配置文件被成功读取，并且成功找到并配置了微控制器，那么 “status” 命令将报告打印机已准备就绪。 默认的 Klipper 启动脚本也在 /tmp/klippy.log 中放置一个日志，提供更详细的信息。 问题解决由于本次安装是在 WSL 中的 Ubuntu 进行安装的，所以有以下两个问题需要解决 1）systemd 中的服务无法启动导致的 moonrarker.service 无法运行 Windows 版本要求 (已验证 Win11 22H2) 启动 windows Power Shell，更新 wsl 1wsl --update 进入 Ubuntu 1wsl ~ 编辑配置 1sudo vi /etc/wsl.conf 添加以下内容 12[boot]systemd=true 保存并退出 ubuntu 1exit 在 windows power shell 中关闭 ubuntu 1wsl --shutdown 然后重新进入 ubuntu 1wsl ~ 查询 systemd 服务 1sudo systemctl status 2）在 WSL 中无法打开 Windows 的 USB 端口 WSL2 内核要求 &gt;&#x3D; 5.10.60.1 进入 Ubuntu 1wsl ~ 查询内核版本 1uname -a 退出 Ubuntu 1exit 安装 usbipd-win 1winget install usbipd 进入 Ubuntu，安装客户端工具 12sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 退出 Ubuntu，添加 USB 设备到 WSL 中去 1234usbipd wsl list //列出所有连接到Windows的USB设备。usbipd wsl attach --busid //添加USB设备进入Ubuntu，需要管理员权限usbipd wsl detach --busid //停止USB设备共享usbipd wsl attach -a --busid 2-7 // -a 自动绑定 进入 Ubuntu，查看已经连接的 USB 设备 1lsusb 配置 udev，允许非 root 用户访问 USB 设备,需要在设备连接前完成该操作 需要将根据自己 USB 设备编写的 60-myusb.rules 文件复制到&#x2F;etc&#x2F;udev&#x2F;rules.d 远程监控模块 Obico for Remote AccessObico for Klipper is an open-source solution to let you monitor and access your printer while you are not on the same local network. Obico sends status messages as well as webcam snapshots to mobile push notification, Email, Telegram, Discord, and more. You can get the real-time webcam feed and printer control using Obico’s mobile app or in the browser. Obico also uses AI to detect print failures. Follow this guide to set up Obico for Klipper. 切片软件设置打印机 配置 Cura 设置可见性可以根据自己在切片时实际需要调整的相关参数进行显示 移动和缩放模型长按鼠标滚轮中键，可平移视角 长按鼠标右键，可旋转视角 滚动鼠标滚轮，可放大缩小视角 选中模型后，在 Cura 的左侧，依次功能为 移动 缩放 旋转 镜像 单一模型设置 支撑拦截器 在相应位置添加方块减少支撑应用右击模型，可进行“复制”、“清空平台”、“居中模型等设置 设置打印参数点击右侧的打印参数设置栏，选择多种模式 质量即层高：数值越小，打印物体表面效果越好，打印时间越长。默认选择 0.15mm 填充打印模型内部的模型密度，默认以网格状的形式填充。默认选择 20% 如果填充率过低，也会有一定程度导致翘边，不同的内部填充图案也可以有效减少翘边。 材料主要设置打印时喷嘴和热床的温度。一般耗材上会写有打印温度。也可通过打印温度塔测试出每种最耗材品牌最佳的打印温度。建议首层温度用 230°C，容易粘床。 打印 PLA，热床的温度建议在 50-60°C。 速度PLA 建议打印速度为 60mm&#x2F;s，±20 也在常用速度。 过快步进电机会丢步，按实际情况设置 移动当喷嘴移动到非打印区域上方时回抽耗材 当打印出现拉丝情况，可调整回抽设置。建议回抽距离用 2.0mm，回抽速度用 50mm&#x2F;s，加大数值可减少拉丝情况。如果打印过程中喷嘴有碰到打印物的情况，可勾选 Z 轴抬升。 附着加大模型第一层与打印平台的接触面积，增加附着力，让模型在打印过程中更稳固。当打印模型的高度较高，接触面积较小时使用。 skirt 裙边 在打印模型前，在模型外围打印一圈，让喷头里面的出丝比较顺滑,主要用于擦净喷头 brim 在模型的边缘处加上薄薄的一层，防止翘边，适用于打印较高的物体且接触面较小，容易倒塌的时候 raft 底座，在底座上在打印模型，适用于接触面多且复杂的情况 支撑在模型的悬垂部分生成支撑结构，防止模型倒塌。作为入门最难的一个设置。通常角度过大，打印过程中悬空部位则需要添加支撑，否则容易下垂。支撑与模型接触面往往很粗糙，影响模型质量。 支撑悬垂角度越大，需要支撑部位（红色部分）则越小。建议 45-50 间。 添加支撑的最小悬垂角度，当角度为 0 时，将支撑所有悬垂，当角度为 90 度时，不提供任何支持 Cura 提供普通支撑和树型支撑两种选择。 树型支撑对模型影响更小，也节省材料。注意，它只适合于非平面的悬空，如鼻尖，指尖或拱形。对于平面的悬空，树形支撑无法提供足够的稳定性。 正常支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：0支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。支撑 X&#x2F;Y 距离：1-1.5mm 树形支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：1连接支撑锯齿形: 勾选支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。支撑 X&#x2F;Y 距离：1-1.5 保存和预览点击右下角的切片，等待切片完毕后，可在预览界面预览打印效果、耗材用量及预计用时。拉动最右边进度条，可查看每层打印情况。点击右下角保存 gcode 文件准备打印。 特殊操作 偏好设置”—“基本”—“自动下降模型到打印平台” 假如只想打印一半模型，可解除 Z 轴限制，可使模型下降至负数。切片后只会打印平台上方部分。 3D 打印机问题总结平台上的蓝色纸有什么用处，用到什么程度需要更换？美纹纸，它的作用一是防止刮坏喷嘴，二让模型与平台粘接更稳。 由于打印材料的热胀冷缩效应，当打印大体积模型时，可能会发生翘边现象，建议打印前先贴上蓝色美纹纸，才开始打印。该纸可反复使用，直到破损或者明显粘不住模型为止。 大部分人都在用 PEI 喷涂的钢板作为底面。PEI 的特性是冷的时候不粘，热的时候具有一定的粘性。 新的 PEI 床和旧的自带的床。更换 PEI 后打印 PETG 就非常好用了。等床凉了以后轻轻一拿就可以从床上拿起来了，不像是原来那张床用铲子翘半天。 不过新床目前也是遇到了一些问题，就是打 PLA 没有原来粘了。所以用 PLA 打印第一层得时候需要压得更低一点，才能获得最佳得粘性。 哪些模型要加支撑？如何判断？ 红色位置是需要加支撑的位置，Cura 右侧可以设置支撑的相关参数 调平台这个步骤怎么确保距离调的 ok 呢？喷嘴距离平台距离太远或太近有什么区别？为什么模型打印过程中直接被拖走？ 首先在调节平台之前我们需要先保证 X 轴在丝杆上移动是水平的 喷嘴和平台的距离标准为一张 A4 纸的距离，如果不好判断，塞张纸在平台和喷嘴之间，以正常抽拉并附带阻力为标准； 在不会刮伤平台的前提下，调的越近模型粘的越牢固！ 我们还可以通过模型打印第一层的状态来判断距离是否调好，有以下三种情况： 1、正确的距离：扁平，无间隙，铺在平台上面很平整无毛刺,喷头与热床是最佳距离能保证打印出的耗材被紧压在热床上成平整的带状（扁皮状）。如图所示： 2、不正确的距离：细圆的，粘上去时铺的不均匀，有空隙和翘起，说明距离太远,耗材是靠重力作用垂到热床，形成圆润的条状，其黏附效果不佳，模型容易移动，打印效果非常不理想。如图所示： 3、不正确的距离：出丝时，压在平台上会出现中间薄两边有不规则突起（有毛刺）的，说明贴的太紧，或者可能造成无法出丝以及喷头移动时会刮带到之前打印的地方，相关形状如图所示： 以上情况均可以通过调节热床下方的弹簧来调整。 调节平台需要注意什么？而且每次打印前都需要检查平台吗？ 调节弹簧螺丝时，请注意按住下方的羊角螺母，不然在拧的过程中也会一起转动； 每次调完或检查平台操作后，都必须移动喷嘴在平台上走一圈，确保不会刮伤平台才能进行下一步操作； 虽然不需要您每次在打印前调节平台，但需要以 1 天 1 次作为周期性检查，平台距离合适； 为什么预热后上料？为何我感觉插到底了，下方喷嘴却不出丝？换料的时候需要注意哪些情况？ 上料时，如果喷头没有加热，耗材插到底也不会吐丝，客户就无法判断是否已正常上料，所以必须先预热，再上料！ 在上料时，插入进料口后一段距离感觉已经无法插入，但是喷头下方并没有出丝，因为在耗材在进入进料口后需要穿过挤出轮和压料轮中间后再进入下方喷嘴导料管，在上耗材的时候没有把耗材前段剪尖和捋直，导致耗材插入时没能直接进入下方导料口而被旁边阻挡，如图： 正确上料步骤：预热—剪尖并捋直耗材—下压螺丝—笔直插入耗材—出丝 每次打模型前都需要预热吗？提前预热的情况只有在进行换料前才需要提前预热，正常打印时，您只需要选择打印的模型文件即可自动加热； 模型打印过程中停电了能否继续打印？如果停电了模型直接终止打印，下次开机无法延续打印（但可以通过测量已打印高度，仅将未打印的部分切片进行打印，再粘上，仅适合非精密零件模型） 那中途可以暂停再继续打吗？看机器是否有设计暂停打印功能 在打印时暂停喷嘴依旧处于加热状态，耗材因重力作用会下垂流出，影响模型外观； 中途耗材用完怎么办？ 首先模型在软件进行切片转换格式的时候就会显示所需打印的时间，耗材长度以及重量，那您需要判断机器上余下的耗材能否支持本次打印完成，避免中途打印耗材用完； 若碰到耗材中途快用完，请在耗材还没进入进料口的时候及时的进行暂停，并迅速拔出剩余耗材，将新的耗材插入至喉管的深度即可 每次打完需要将耗材取出来做排空处理吗？不是，距离下次打印超过 72 小时，则需要排空处理； 喷头需要定期清理吗？需要！ 挤出头加热到指定温度后用最小号的内六角螺丝刀，压下进料弹簧，插入进料口，往下挤压，挤压的时候扳手插慢慢插到底时，来回挤压三次，扳手回抽不要过急或过长，插进去后小幅度的在里面挤压三次即可，再迅速拔出，空烧 1 分钟左右注意观察下方是否有东西流出，流完或没东西流出一分钟后请用我们配送的小捅针，从下方喷嘴插入，抽拉三次没东西流出即可；最后一步，请弄根新耗材，插入到底向下挤压出丝后猛的迅速拔出，尽量带出内壁附着物即可； 模型刚开始打印第一层就不出丝，怎么回事？如果这种情况发生在您刚才有换过耗材的情况下，那您需要确定耗材已上到底，并出丝；确保喷嘴是否顶到平台，导致无间隙空间吐丝； 打出来的模型很脆，外壁像网丝状，很脆，一捏就瘪了？此情况属于出丝量很小，需要检查以下几点： 拉料正常，料盘上的耗材没有打结等缠住现象； 耗材在进入导料管与喷嘴（加热管&#x2F;喉管）之前，要穿过一个 u 型轮和挤出电机齿轮中间，u 型轮压住耗材让齿轮把耗材往下挤送，u 型轮压住耗材的力量是由旁边的六角螺钉顶着弹簧的力度来决定的，螺丝扭紧弹簧弹性越大，u 型轮压料就越紧，反之越松， 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 齿轮本身带动耗材挤压也有许多因素，耗材从上往下经过齿轮的时候是否有在齿轮的中间，如果齿轮脱位，耗材在齿轮的牙边下去的，可能出现带不动耗材往下的情况而出丝不顺 模型打印时，突然在某一层高处整体向 X（左右）&#x2F;Y（前后）方向偏移？首先需要确定机器传动系统问题，再来排除软件参数和主板固件问题，排除方法如下： 首先需要判断你的模型摆放在平台上时，偏移的方向是 x（横向）还是 y（纵向），然后我们需要检查对应的 xy 轴的传动系统是否正常，第一先检查皮带是否松动脱落；第二检查同步轮固定螺丝是否松动 ① 带松动加紧： 首先，如果是 X 轴皮带松动，必须拉紧至绷紧状态，切平行； ②同步轮松动：Y 轴传动系统同步轮和 X 轴同步轮都需要检查到； 排除完机器问题，建议看下软件参数是否存在问题 例如检查是否是电机运动速度过快或出现阻碍导致的丢步 以上两点排除完毕，需要对主板固件程序进行重新烧录来解决问题 打印模型过程中中间断了几层，但是上面打印还可以？为什么模型突然中途就不出丝，喷嘴一直在空走打印不出丝？这几种问题都属于前期能正常打，但是中途不出丝的情况，这种情况需要从以下几点判断： 挤出电机接线口处四针排线松动，导致电机挤出齿轮来回正反转，耗材送不下去； 打印不出丝时，可以从电机右侧方弹簧方向往里面看到齿轮转到情况，如果齿轮来回摆动不定，说明接线出有问题，将接线拔掉重新插入尝试即可； 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 耗材在料盘上缠住，导致进料不顺,检查料盘的耗材缠绕是否有拉扯住 喷嘴可能有残料堵塞,可以把喷头首先预热 230，一手按住进料口旁螺丝，一手快速挤压耗材（多送点丝），再迅速拔出，然后让喷嘴空烧一会儿，直到有黑色物质从喷嘴里流出，然后用钢丝从喷嘴端插入，抽拉，拔出，让里面剩余的耗材掉出，重复抽拉动作，直到喷嘴没料自然流出为止，最后上料，重新打印； 为什么打印模型在中途过程中，喷嘴周边缠着很多耗材，模型变成一团乱丝，不成形？这种情况分两种： 刚开始打印阶段，此情况一般是喷嘴和平台之间的距离过远，喷嘴出丝无法粘住平台，就会被喷嘴带走并一直出丝形成一坨； 打印过程中出丝不均匀，有断层现象，打印模型比实际高度低，超过一定间隙距离后出料正常是没附着下面的模型上面就会缠成一坨； 打印过程中喷嘴突然停止在打印模型上方不打印，并未回原点，怎么回事？ 切片问题,重新切片打印测试 内存卡松及读取问题 主板固件问题 为什么把模型保存在卡里是显示 ok，但插入机器后选择模型打印后不加热也没反应？为什么 SD 卡在电脑读取正常放入机器缺显示无卡？一般由于保存文件时的文件名上，切片完成后进行保存时文件名请使用英文字母或数字. 为什么 SD 卡在电脑读取正常放入机器缺显示无卡？这种问题首先要排除卡和卡槽是否正常配合，保证卡和卡槽读取正常，如果重新插入还是无法读取，可用您身边的内存卡保存文件插入机器是否能正常读取 为什么选择模型打印，机器没任何反应？或者加热了很久但是不打印？这种情况可能喷嘴冷却风扇提前开启，导致实际温度和设置温度总有 1-2 度差距，导致无法打印，请您选择停止打印并关掉风扇开关后，重新选择打印模型即可； 宽度 5mm 高度 6mm 的字体打得出来不,类似这种小模型需要修改哪些参数呢？小模型打印需要将速度和挤出量降低，模型可以打得更好看。比如打 5mm 左右的字体，可以采用 22 左右的速度配合 85 的挤出量来进行切片打印，温度采用 190 左右的即溶温度即可，这适合小模型打印哦； 为什么在打印模型时，某个位置会剧烈振动，机器声音很大？这种位置一般是模型实体部分的填充，特别是交窄的壁厚，填充为波浪形，打印速度很快的时候 xy 配合产生共振引起的 为什么在打印很大模型例如 190*190*180 和平台尺寸相近的模型时，喷头移动到某个方向极限值时，会有振动然后再改方向进行移动呢？打印前，喷嘴会在模型周围打一圈进行排空出料的操作，这样的话就实际增加了大模型的成型空间，导致直接碰到机箱，可以把此设置关掉即可 查看切片时是否有裙边设置 打印模型经常翘边问题怎么解决？PLA 与 ABS 通用原因： 喷嘴距离与平台太远，没能充分贴紧平台 模型与热床接触面积太小，导致附着力不够 解决办法：可增加 brim 或者 raft 垫子 ；打印 ABS 的话 Brim 效果更理想； 打印 ABS 时开了散热风扇。 解决办法：在打印是进入主界面的控制 – 温度 – 风扇速度 Bed 中由最高转速 255 改成 100 减少冷却效果，直接关闭风扇开关效果更理想； - 挤出头或热床温度不合适，挤出头温度不够可能导致挤出的材料流动性不够，无法完美的平铺在热床上，影响其粘滞力。热床温度过高也可能导致翘边，原因是材料受热流动性变大，不能稳固黏在热床上。 - 热床表面不干净。手的汗与油粘在胶带上，表面上看不见，但也导致表面打滑，影响黏附效果。这种情况在湿度大的南方比较常见。 ABS 材料很特殊因为它有一定的收缩率，打印较大的物体时，效果更佳明显，整体收缩导致底面翘起。最好能配合洞洞板。 显示屏下方显示 Err 报错，挤出头&#x2F;热床温度温度显示不正常？喷头上热敏电阻的接触不良或者损坏了 拆下热敏电阻，若是接触不良，则重新拔插接好；若是线的焊点脱落，用电烙铁焊好否则易损坏电阻；若是损坏，则更换新的热敏电阻。注：固定线时螺丝不宜拧过紧 这个黑色螺丝拧松，热敏电阻取出来，同时热敏电阻线也从主板上拔下来，用万用表测一下阻值，80-100K 正常 打完第一层，打印头在左边，要打上面一层的时候，打印头不是要回到右边的吗，回去的时候就会刮在之前打印的第一层上并留下一条线呢？那是距离平台过近，会刮到上一层打印的耗材 平台距离喷嘴近有利于粘住平台，不会翘边; 会轻微刮到上一层打印模型，但不影响模型成型过程，最多挂点料在喷嘴上挂着，然后在掉下来 模型平面上字体打出来效果不好怎么办？如果字写在模型上，此情况可以将模型竖起来打，层厚 0.1 能更为细腻的打出字体； 为什么从绘图软件里导出来的模型放在 cura 里显示不规整，弧面都是棱面组成的？在绘图软件里导出 stl 的时候会有二进制和 ASCⅡ，通常选择二进制并将角度和弦值设置默认最小值，但在 maya 等一些软件里，文件导出的时候 stl 格式是默认设置的，这是软件的特性，但是这个默认数值会随着你文件的建模时的网格细腻程度增加，也就是说文件平滑原本是一倍的，现在加到三倍导出来的 STL 就会比一倍的细腻很多 调试机器时选择自动丝出来都不是直的，是弯曲的?如果出丝是弯曲的 挤出量有关；挤出量一般由温度以及进料口旁边的螺丝松紧度有关，需要检查进料口旁边的螺丝 温度原因，1.风扇吹的 2.温度可以适当加高到 200 度左右 温度总是上不去或者不稳定？ 挤出头的热敏感应件没固定好在铝块里，打印的时候易松，导致探温不准； 导风嘴冷却风扇的风是吹到喷嘴下方的模型，如果没有调好就会吹到 喷嘴，导致温度下降； 如果出现以下情况是怎么导致？ 挤出齿轮底部缠料，一般是由此部位温度过高引起耗材变软，送丝过程中导致齿轮下部耗材折断而缠住； 遇到此情况首先需检查电机前方的方形冷却风扇是否工作以及叶片是否完整，避免冷却不够而导致堵料； 请检查耗材是否长时间未密封保存而变脆，取一段从中间这段，若折后显白痕且有韧性即正常，若折后直接啪的应声而断即已变脆； X 轴架构在 Z 轴电机丝杆控制上下过程中，会导致一边高一边低，每次都需要重新调节平台高度呢？ x 轴本身没有平衡，在移动过程中反应更明显； 请解决 X 轴调平问题； 黄色 T 型螺母太紧，导致 T 型螺母与丝杆紧配受力不均匀，移动不顺畅； 将固定 T 型螺母上的螺丝不要拧紧，留半个螺纹的缝隙，给予缓冲，再将 x 轴调至平衡，移动 z 轴电机调试！ x 轴光杆太长，没有完全捅到底去，顶住丝杆，导致移动不顺 检查光杆插入深度； 将 Z 轴两边的两个光杆去掉，控制电机上升是否正常，排除光杆弯曲配合滑动轴承配合不顺问题（可以单独将光杆插入滑动轴承，上下移动是否顺滑） 更换光杆或者滑动轴承 以上问题都检查后就可能: 移动不顺畅的丝杆部分弯曲或者螺纹损伤，更换丝杆 在更新固件后，挤出电机齿轮检测出反转，无法正常下料 固件中电机引脚配置反了 拔出挤出电机后端电机线接口，按照现在正常 1234 线序，把其中‘一组’12 对调或者 34 对掉即可 如果模型摆放在软件里为中心点，但在实际打印过程中并不在平台中间；因为机器喷嘴回原点的时候并不在热床平台上方而是在外面，而 cura 软件的机器设置里原点就在平台某个角的正上方，为了补偿原点所在误差，需要将软件的平台设置扩大，才能让模型打印在正中间，如图操作更改即可： 加热后拔料感觉扯不出来，也无法下压了铝块融化处剩余耗材口径较大，加热后直接上拉耗材，易堵在口径较小的喉管处，并迅速冷却，以至堵塞喉管 预热达到温度后，一只手按住进料口旁边的螺丝，另一只手将耗材往下挤压，让前端耗材挤出一段距离后，再迅速拔出耗材即可避免堵塞喉管 选择自动回原点时，当喷头移动至限位开关的时候，电机一直不停的往前走，撞击限位开关并抖动，这是怎么回事？ 您需要检查在部件回原点触碰到限位开关之前是否有东西挡住它前进才无法触碰到限位开关而不停止运动； - 可能是限位开关坏了导致的，检查方法是将每个轴的移动部件移至轴中部，选择自动回原点，在部件向原点限位开关移动的过程中，请按住限位开关，观察部件是否停止移动，如果没有停止，请马上切断电源，基本上可以确定限位开关问题 为什么 X 轴上的喷头在移动过程中，一顿一顿的，特别是在回原点的时候，移动时几乎在抖动很不顺畅？ 排除下电机线与电机的问题：拆卸底板：需要用万用表检查 x 轴四根电机线是否都是通路，如果正常就是电机本身问题； 可以断电后手动运动下挤出头，是否丝杆或滑块中的钢珠生锈导致运动不流畅 超出打印范围安装软件的时候初始设置选择错误机型导致的，重新设置机型即可 不粘床，找平 自动找平后，但有的时候打印出来的第一层还是和床粘的不紧密 Z Offset 设置也会影响粘不粘床。 其中白色部分为压力传感器（BLTouch），右边蓝色硅胶罩下面的为喷头 可以看到左边白色的压力传感器的高度和右边蓝色硅胶套下面的喷嘴是不在一个高度的。设置喷嘴和床之前的距离是以压力传感器的反馈为准的。但是压力传感器测到的距离是传感器本身到床的距离，并不是喷嘴到床的距离。所以压力传感器到喷嘴之间的高度差就是 Z Offset，需要通过调整它来设置合适的喷嘴高度。 手动调平 需要用到一张纸，一般打印用的 A4 即可。 然后在床的中点进行 Z Offset 调整，在四个角落（螺丝位置）手动调整床的高低。具体步骤如下： 中点 Z-Offset 调整 首先通过控制面板将喷嘴移动到床的中间的正上方，接下来将纸放喷嘴下方的床上，紧接着慢慢将 Z 轴的高度降低到 0（如果降不下去不要硬来），喷嘴可能会压住纸或者没碰到纸；尝试前后不停的移动纸张。 如果纸张能移动并且刚好有一点阻力就是合适的喷嘴高度不需要调节，通常而言不会那么顺利；如果如果喷嘴完全没碰到纸张，或者纸张移动完全没有任何阻力，可以尝试通过调整 Z-Offset ，一点点降低喷嘴高度。直到达到上述的移动纸张有一点点阻力的状态；如果纸张被压的很死无法动弹，则先将 Z 轴升高到 5mm 然后尝试调整 Z-Offset 升高喷嘴，然后再继续尝试慢慢降低 Z 轴到 0mm，反复调整直到移动纸张有一点点阻力的状态。 使用一张纸来手动找到喷头合适高度的方法。但是这个能移动但是有一点点阻力状态有点模糊，它并不是一个固定的点，是一段区间内都可以感觉到能移动但是有摩擦力。我建议是选摩擦力稍微轻一点的力度的点，这样喷嘴高度较高，后面调整的时候不容易刮伤床上的底板。 四周螺丝调整 在中间确定了最基本的 Z 轴的高度之后则需要物理调整四周的螺丝了，调整四周的螺丝需要按照顺序一个一个的调整，并且需要多次调整和确认，具体步骤如下： 首先抬起 Z 轴让喷嘴距离床大概 5mm 的距离，再移动到任意一个距离调整螺母的正上方，将纸放在喷嘴正下方的床上，紧接着一点点尝试往下移动 Z 轴到 0mm，和上面一样如果降不下去不要硬来；接下来就和上面一样，尝试移动不停的前后移动纸张，如果处于能移动但是有摩擦力的状态则是合适的，如果完全没碰到纸张，在移动纸张的同时旋转下方的螺丝来物理调节这个角落的高度，直到纸张处于能移动但是有摩擦力的状态。最后将 Z 抬起到 5mm 左右，顺&#x2F;逆时针移动到下一个调节螺母的上方，重复以上步骤。 上面步骤是单个角落手动物理调整床高度的方法，完成四个点（上图的床只有四个螺丝，有几个螺丝就校准几个点）为一个循环。因为打印机的床是一个固体，所以当你上下移动某一个角落的高度的时候另外三个角落的高低也是会受到影响的，尤其是相邻的两个角落。所以这里需要多个循环来拧螺丝调整各个角落的高度，直到四个角落的高度都合适的情况，即为纸张能移动但是有阻力的状态。 在拧玩螺丝校准完四个角落的高度后，需要再次通过 Z-Offset 校准中间喷嘴的高度。因为在调整四角的螺丝的时候可能会整体抬高或者降低了床的高度，所以中间的喷嘴高度需要再一次校准。重复上面中点 Z-Offset 校准即可。 如果固件自带自动找平还是比较简单的，选择自动找平等就好了。虽然手动找平完之后床基本上是处于可以用的状态了，但是便宜的桌面打印机的床它本身可能就是凹凸不平的，所以需要自动找平来弥补床本身的凹凸起伏的部分。如果没有自动找平的打印机就没有太好的办法避免这个了。只能通过稍微压低一点点喷嘴来做到尽量都粘到床。 测试调平是否成功 在做完上述的调整后就可以进行最终的调整了。这一步是通过打印一些模型来确认喷嘴的高度是否合适。 虽然用纸调整好了喷嘴的高度，但是纸有薄有厚，调整出来的喷嘴高度并不一定是最好的打印高度，所以最终还是需要通过打印来调整。 打印测试时尽量选择有颜色的材料，透明透明材料会看不清楚第一层有没有打好，在打印模型的时候，手需要在电源附近随时待命。在喷嘴高度设置错误或者床不平的时能及时停止打印机降低损失。 打印出来的模型主要是用来检查喷嘴的高度和床是否倾斜的，四周的圆柱和绕场一周的线条用来检查床的倾斜度。 外围线条如果高低不平均，薄的那边就是较高的地方，厚的那边则是较低的地方。四角的圆柱则可以和上述的 Raise 3D 的示意图来比较确认喷头的高度是否合适。如果不合适可能需要重新手动找平。中间的圆形是确认喷嘴高度用的。同样通过对比来观察高度是否合适，如果床并没有很严重的倾斜，则只需要调整 Z-Offset 来移动喷嘴。然后重新打印确认。如果确认床有倾斜，就要重新走一遍手动找平的流程的了，然后重新打印确认。 当然找平也不是一定完美的。但是有自动找平后，整个过程还是比较简单的。但是也有无论怎么调整，都觉得床有倾斜或者高度不对的时候。这里就要分两种情况讨论了。如果能正常打印不想折腾了就选一个能调整到的最好的状态直接用吧。如果严重到了无法打印的程度，则需要检查打印的装配是不是有问题了。 过度挤出 打印出来的东西都有奇怪的纹理。而且质量也参差不齐。 检查之后是 klipper 配置里面的挤出机的「roration_distance」配错了。导致挤出机往外挤的时候给了远比正常情况多的料，进而溢出到边缘产生了神奇的纹理。 Klipper 配置里面的挤出机转一圈挤多少料这些东西都需要自己配置。所以配置挤出参数时是需要校准的，当你给指令让他挤 100mm 的材料的时候，他应该就挤出来 100mm 左右的材料。没有校准所以导致了非常严重的过度挤出，配置正确后打印的东西表面的问题就漂亮多了。 正常挤出打印的零件的表面质感 材料与环境湿度由于 FDM 3D 打印件一般都需要将材料加热到 200 摄氏度或以上的温度才能打印，所以当材料通过热端的时候，其中的水蒸气会蒸发出来，造成喷嘴里面的材料有间隙，这些现象还会造成打印件在物理特性上的改变： 水汽膨胀造成挤出原料不均匀导致的表面粗糙 水汽膨胀造成材料之间有很多空隙导致的强度下降 水汽膨胀喷嘴中黏在一块的材料有缝隙，导致拉丝。 材料均需要密封干燥保存！买干燥盒 主要成分简称 推荐打印喷嘴温度 推荐打印床温度 特点 PLA 190˚C – 230˚C 25˚C-60˚C 易受潮 TPU 200˚C – 210˚C 50˚C 易拉丝 PETG 230˚C – 240˚C 70˚C – 80˚C ABS 245˚C – 265˚C 90˚C – 100˚C 有毒 ASA 240˚C – 260˚C 75˚C – 95˚C PC 250˚C – 270˚C 90˚C – 105˚C PA6 250˚C – 270˚C 25˚C – 50˚C PA6-CF 280˚C – 300˚C 25˚C – 50˚C","tags":["3D打印机"],"categories":["其他","3D打印机"]},{"title":"Git介绍和基本命令","path":"/2024/05/17/软件-Git-Git介绍和基本命令/","content":"版本控制版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 Git 是免费、开源的分布式版本控制系统。 集中式版本控制系统集中管理的中央服务器，保存着所有文件的修改历史版本。 协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。 分布式版本控制系统远程仓库同步所有版本信息到本地的每个用户 本地可以查看所有的历史版本信息，偶尔远程更新，查看其他用户修改提交到远程 用户即使离线也可以本地提交，push 推送到远程服务器才需要联网 每个用户都保存了历史版本 工作区域Workspace：电脑本地看到的文件和目录，在 Git 的版本控制下，构成了工作区。 Index&#x2F;Stage：暂存区，一般存放在.git 目录下，即.git&#x2F;index,它又叫待提交更新区，用于临时存放你未提交的改动。执行 git add，这些改动就添加到这个区域。 Repository：本地仓库，你执行 git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 HEAD 指向最新放入仓库的版本。当你执行 git commit，文件改动就到本地仓库。 Remote：远程仓库，云端版本库 文件状态Untracked: 文件未加入到 git 库，未参与版本控制，处于未跟踪状态。通过 git add，可以变为 Staged 状态 Unmodified：文件已经加入 git 库，版本库中的文件快照内容与文件夹中还完全一致。 Unmodified 的文件如果被修改, 就会变为 Modified。如果使用 git remove 移出版本库，则成为 Untracked 文件。 Modified：文件被修改进入 modified 状态，文件这个状态通过 stage 命令可以进入 staged 状态 staged：暂存状态. 执行 git commit 则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为 Unmodified 状态。 正向工作流git 的正向工作流程一般就这样： 从远程仓库拉取文件代码回来；git pull 在工作目录，增删改文件； 把改动的文件放入暂存区；git add 将暂存区的文件提交本地仓库；git commit 将本地仓库的文件推送到远程仓库；git push 常用命令123456789101112131415161718192021222324git clone [url] #克隆远程仓库git add [dir/file]#添加目录/文件到暂存区git commit [--amend] -m [msg] #提交暂存区到仓库区,msg为说明信息(amend用新的commit覆盖提交)git log [--oneline] [-p [file]]#查看提交历史(online精简模式)(p指定文件)git blame #列表方式查看指定文件的提交历史git diff #显示暂存区和工作区的差异git diff #显示暂存区和工作区的差异git diff filepath #filepath路径文件中，工作区与暂存区的比较差异git diff HEAD filepath #工作区与HEAD ( 当前工作分支)的比较差异git diff branchName filepath #当前分支文件与branchName分支的文件的比较差异git diff commitId filepath #与某一次提交的比较差异git status [-s] [--show-stash] #查看当前工作区暂存区变动(-s概要信息)（show-stash显示暂存文件）git pull/fetch #拉取远端代码#git pull = git fetch+ git merge。pull的话，拉取远程分支并与本地分支合并#fetch只是拉远程分支，怎么合并，可以自己再做选择。git pull #拉取远程仓库所有分支更新并合并到本地分支。git pull origin master #将远程master分支合并到当前本地master分支git pull origin master:master #将远程master分支合并到当前本地master分支，冒号后面表示本地分支git fetch --all #拉取所有远端的最新代码git fetch origin master #拉取远程最新master分支代码git push #推送到远端git push origin master #将本地分支的更新全部推送到远程仓库master分支。git push origin -d #删除远程branchname分支git push --tags #推送所有标签 123456789101112131415161718192021222324252627# git rebase`rebase`又称为衍合，是合并的另外一种选择。 `rebase`好处是： 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：`git pull --rebase`# git stash`stash`命令可用于临时保存和恢复修改git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作git stash list 显示保存的工作进度列表git stash pop stash@&#123;num&#125; 恢复工作进度到工作区git stash show ：显示做了哪些改动git stash drop stash@&#123;num&#125; ：删除一条保存的工作进度git stash clear 删除所有缓存的stash。# git reflog显示当前分支的最近几次提交# git blame`git blame filepath`记录了某个文件的更改历史和更改人# git remotegit remote 查看关联的远程仓库的名称git remote add url 添加一个远程仓库git remote show [remote] 显示某个远程仓库的信息","tags":["Git"],"categories":["软件","Git"]},{"title":"Git常用操作","path":"/2024/05/17/软件-Git-Git常用操作/","content":"项目创建对于网络项目git clone [url] 将 GitHub 中的网络项目复制到本地，只需在修改完之后 commit 即可，然后更新仓库代码，就可同步修改。 对于本地项目首先要创建一个文件夹用以存放文件，然后使用 git init 对进行初始化操作 git status 得到 git 中文件的状态 git add filename 将 filename 文件加入到 git 本地仓库中去（git rm -cached 可移除） git commit -m ‘status’ 表示提交信息（status 表示附加信息） 之后对本地项目进行关联 git remote add origin [url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 关联之后可以向远程仓库提交代码（更新仓库代码） 日常 push git status #获取状态 git add . #添加文件到暂存区 git commit -m &quot;20191121 push&quot; #提交文件 git push origin master #推送 日常 pull git diff 比较工作目录和 Index 中的代码。 git fetch 当于从远程获取最新版本到本地，不会自动 merge ，比 Git pull 更安全些 git checkout app/model/user.rb 将 user.rb 文件从上一个已提交的版本中更新回来，未提交的工作目录中的内容全部会被覆盖 首次使用配置 ssh ssh-keygen -t rsa ssh -T &lt;git@github.com&gt; 首次使用设置用户 git config (--global) user.name &quot;username&quot; git config (--global) user.email &quot;&lt;username@gmail.com&gt;&quot; 上传&#x2F;下载常用命令 git push origin（仓库名） master（分支） 更新仓库代码（上传） git pull origin（仓库名） master（分支） 更新本地代码（下载） 回退历史版本 git log git reset --hard \\[commit\\_id] git revert \\[commit\\_id] 网络项目 git clone \\[url] git remote add origin \\[url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 版本情况 git tag 查看版本情况 git tag V1.0 新建版本 git checkout V1.0 切换至版本 V1.0 分支情况 git branch 查看当前分支情况 git checkout a 切换到分支 a git checkout -b a 新建分支 a 并切换到分支 a git branch -d a 删除 a 分支 git merge a 将 a 分支的代码合并到 master 分支上 撤销或回退在 Git 中，撤销和回退是指撤销或回退先前的提交或更改。 简单介绍下 Git 中的撤销和回退操作，以及如何使用它们来管理代码库。 #可以把版本库上的提交回退到暂存区，修改记录保留 git reset –-soft [] #可以把版本库上的提交回退到工作区，修改记录保留 git reset –-mixed [] #可以把版本库上的提交彻底回退，修改的记录全部revert。 git reset –-hard reset 和 revert 的区别git reset 和 git revert 的主要区别在于它们对历史记录的处理方式。git reset 会删除历史记录并永久删除更改，而 git revert 会创建一个新的提交来撤销更改并保留历史记录。 git reset 命令会将 HEAD 指针指向指定的 commit，并将暂存区和工作目录恢复到该 commit 的状态。这意味着在执行 git reset 后，之前的更改将不再存在于工作目录和暂存区中。如果您希望永久删除一些更改并且不再需要它们，可以使用 git reset。 git revert 命令会创建一个新的提交来撤销指定的提交。这意味着在执行 git revert 后，之前的更改仍然存在于工作目录和暂存区中，并且您需要提交一个新的撤销提交。如果您想要保留更改历史记录并且不想永久删除更改，可以使用 git revert。 获取 IDgit log 获取到想要回退的 commit_id 撤销&#x2F;回退未提交的更改**(add 之后，commit 之前)** 要撤销未提交的更改，请使用以下命令： git checkout &lt;file-name&gt; 将名为 file-name 的文件恢复到上一个提交的状态。 本地本次的更改也不再保存，恢复到上一个提交 (commit) 的状态 git reset HEAD --file 回退暂存区里的某个文件，回退到当前版本工作区状态 保存工作区的更改，只是撤销 git add 这一步操作 git checkout . 将所有文件恢复到最新提交的状态。请注意，此操作将删除所有未提交的更改。 撤销&#x2F;回退上一个提交**(commit 之后，push 之前)** 撤销上一个提交 git reset HEAD~1 将 HEAD 指针移动到上一个提交。 工作区保留先前的更改，需要重新添加到暂存区 (git add) 回退到上一个提交 git reset --hard HEAD~1 将 HEAD 指针和工作树都重置为上一个提交的状态。 请注意，此操作将删除所有未提交 (commit) 的更改。 撤销&#x2F;回退到特定的提交**(push 之后)** 撤销到特定版本 git revert &lt;commit_id&gt; 这将创建一个新的提交，该提交撤销名为 commit-hash 的提交所做的更改。 本次撤销操作也会作为一次提交 (push) 进行保存 回退到特定版本 git reset --hard &lt;commit_id&gt; 将 HEAD 指针和工作树都重置为名为 commit-hash 的提交的状态。 请注意，此操作将删除所有未提交的更改。 回退完成后，git push -f 强制提交 分支Git 是一个流行的分布式版本控制系统，一般都是存在多个分支的，开发分支，回归测试分支以及主干分支等 在 Git 中，分支是指指向 Git 提交历史中某个特定提交的指针。 每个分支都包含在 Git 提交历史中的一系列提交，这些提交构成了分支的历史记录。 分支在 Git 中非常重要，因为它们允许多个开发人员同时在同一个代码库中工作，而不会相互干扰。 通过创建分支，每个开发人员都可以在自己的分支上进行工作，而不会影响其他人的工作。 这样，开发人员可以在不干扰其他人的情况下，独立地开发和测试新功能，最终将这些更改合并到主分支中。 在 Git 中，分支操作非常简单。以下是一些常用的 Git 分支操作： 创建分支要创建一个新分支，请使用以下命令： git branch &lt;branch-name&gt; 这将创建一个名为 branch-name 的新分支。 注意，此时仍然在当前分支上工作。 git checkout -b &lt;branch-name&gt; 新建一个分支，并且切换到新的分支 branch-name 查看分支要查看所有分支，请使用以下命令： git branch 这将列出所有分支，当前分支将用一个星号标记。 git branch -r 查看所有远程的分支 git branch -a 查看所有远程分支和本地分支 删除分支要删除一个分支，请使用以下命令： git branch -d &lt;branch-name&gt; 这将删除名为的分支。 注意，如果该分支包含未合并的更改，则必须使用 -D 选项而不是 -d 选项来强制删除该分支。 切换分支要切换到另一个分支，请使用以下命令： git checkout &lt;branch-name&gt; 这将使您从当前分支切换到名为 branch-name 的分支。 注意，需要在切换分支之前将所有更改提交或保存。 合并分支要将一个分支合并到另一个分支，请使用以下命令： git merge &lt;branch-name&gt; 将名为 branch-name 的分支合并到当前分支中。 注意，如果两个分支上都有对同一文件的更改，则可能会发生冲突。在这种情况下，需要手动解决冲突并提交更改。 git merge –no-ff origin&#x2F;dev 在当前分支上合并远程分支 dev git merge –abort 终止本次 merge，并回到 merge 前的状态 以上是一些常用的 Git 分支操作。使用这些操作，您可以轻松地创建、切换、合并和删除分支。这些操作使多人协作变得更加容易，因为每个开发人员都可以在自己的分支上进行工作，并将更改合并到主分支中。在实际开发中，分支操作是非常重要的，最好能够熟练掌握并运用这些操作 标签在 Git 中，tag 是用于标记某个特定提交的名称。它类似于一个快照，可以用于标记版本、发布或重要的里程碑。Git 中有两种类型的 tag：轻量级标签和附注标签。 轻量级标签是一个简单的指向某个特定提交的引用，类似于一个分支，但不会随着新的提交而移动。创建轻量级标签的方法很简单，只需在命令行中输入 git tag &lt;tag-name&gt; 即可。例如，git tag v1.0 将创建一个名为 v1.0 的轻量级标签。 附注标签是一个包含标签名称、标签创建者、标签创建日期和标签说明的 Git 对象。它们是 Git 中最常用的标签类型，可以用于发布版本、重要的里程碑和其他重要的提交。创建附注标签的方法是使用 -a 标志和标签名称，然后输入标签说明。例如，git tag -a v1.0 -m &quot;Release version 1.0&quot; 将创建一个名为 v1.0 的附注标签，并将其说明设置为 “Release version 1.0”。 标签可以使用 git push 命令推送到远程存储库中，以便在其他计算机上使用。例如，要将名为 v1.0 的标签推送到远程存储库，可以使用 git push origin v1.0 命令。 1234567git tag #列出所有taggit tag [tag] #新建一个tag在当前commitgit tag [tag] [commit] #新建一个tag在指定commitgit tag -d [tag] #删除本地taggit push origin [tag] #推送tag到远程git show [tag] #查看特定taggit checkout -b [branch] [tag] #新建一个分支，指向某个tag","tags":["Git"],"categories":["软件","Git"]},{"title":"Git服务器环境搭建和客户端使用","path":"/2024/05/17/软件-Git-Git服务器环境搭建和客户端使用/","content":"服务端安装 git 和 ssh sudo apt-get install git sudo apt-get install openssh-server openssh-client 增加 git 用户并生成文件夹 sudo adduser git sudo mkdir /home/git 创建 ssh 证书认证文件 sudo mkdir /home/git/.ssh sudo touch /home/git/.ssh/authorized_keys 临时修改 authorized_keys 文件的权限 sudo chmod 777 /home/git/.ssh/authorized_keys 把需要访问 git 服务器的客户端公钥 id_rsa.pub的内容复制到 authorized_keys 文件 修改 authorized_keys 文件的权限 1234567sudo chmod 700 /home/gitsudo chmod 700 /home/git/.sshsudo chmod 600 /home/git/authorized_keyssudo chown -R git:git /home/gitsudo chown -R git:git /home/git/.sshsudo chown -R git:git /home/git/.ssh/authorized_keys``` 为了安全考虑禁止登录 git 服务器的 shell，修改 git 的 shell 用 /usr/bin/git-shell 把 /etc/passwd 的 git:x:1004:1004:,,,:/home/git:/bin/bash 改成： git:x:1004:1004:,,,:/home/git:/usr/bin/git-shell 保存 建代码仓库 sudo mkdir /home/Repo #创建仓库的目录 sudo git init --bare /home/Repo/test.git #创建仓库 sudo chown -R git:git /home/Repo/test.git #修改权限为git 以后每创建一个新的仓库，记得最后一步操作: 修改仓库所属用户为 git。 客户端安装 git Linux 环境下 sudo apt-get install git Windows 环境下直接安装 Git安装包 配置连接 通过密钥方式 ssh-keygen -t rsa [-C &quot;你的邮箱地址&quot;] 会生成 id_rsa.pub 文件 添加该公钥到到服务器 Linux 环境下，密钥默认位于 /home/ubuntu/.ssh/id\\_rsa Windows 环境下密钥位于 C:\\Users\\xxx.ssh\\id\\_rsa.pub 通过用户名&#x2F;密码 12git config –global user.name “username”git config –global user.email “username@gmail.com” 在连接 git 时，会需要输入账号密码，直接输入即可 附注：增量备份 -Git 服务器备份使用 crontab 建立每天凌晨 3 点定时触发的任务crontab -e 0 3 * * * * rsync -av -e &quot;ssh -i /path/to/id_rsa&quot; /homt/git/ remote_user@X.X.X.X:~/backup","tags":["Git"],"categories":["软件","Git"]},{"title":"版本控制方案","path":"/2024/05/17/软件-Git-版本控制方案/","content":"Git 方案1. 仓库创建 仓库创建基于当前的项目，例如备份仪表项目仓库，LSA 项目等 2. 分支创建 项目主分支保存项目代码及文档，负责发布代码 项目开发分支保存项目源码，分支仅管理员可见 项目运行分支保存项目头文件及库文件代码，分支所有人可见 项目人员开发分支基于运行分支创建，仅该人员有权限，该人员开发任务基于该分支进行修改代码 3. 代码提交 各人员代码仅提交在单独分支，提交完成后，由管理员审核后，同步源代码至开发分支 4. 版本回退 SVN 方案","categories":["软件","Git"]},{"title":"USB挂载监测","path":"/2024/05/17/通讯协议-USB-USB挂载监测/","content":"功能程序监测到插入U盘后，自动执行执行U盘内和本地指定文件夹双向同步功能 要点 Linux 下如何用 QT 检测到 U 盘已经插入，并实现 mount 与 umount 实现方式使用 qt 自带的 QDBus 可以实现，下面为连接代码，当系统有设备插入时，可以调用 slotDeviceAdded(QString udi) 函数。 在 pro 文件中应该加入 QT +=dbus 12345678910111213141516#include &lt;QtDBus/QDBusConnection&gt;#include &lt;QDbusInterface&gt;//以下为检测设备的插入 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceAdded&quot;, this, SLOT(slotDeviceAdded(QString )));//以下为检查设备的拨出 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceRemoved&quot;, this, SLOT(slotDeviceRemoved(QString ))); 在 slotDeviceAdded(QString udi) 函数中，要使用到 1QDBusInterface device(&quot;org.freedesktop.Hal&quot;, udi, &quot;org.freedesktop.Hal.Device&quot; , QDBusConnection::systemBus()); 通过 HAL 可以查询到设备为 volume 的设备，然后通过判断是否为&#x2F;dev&#x2F;sd 的设备，就可以判断出是否为 U 盘，然后调用 mount 就可以了。 这时记录下 U 盘的 UDI，在检测到设备拨出时，再查询一下 U 盘的 UDI 是否还在，就知道 U 盘是否被拨出了。","categories":["通讯协议","USB"]},{"title":"DRM+GBM+EGL显示","path":"/2024/05/17/平台Platform-Linux-Linux-Graphics-DRM-GBM-EGL显示/","content":"DRM (Direct Rendering Manager)、GBM (Generic Buffer Manager) 和 EGL (Embedded-System Graphics Library) 组合在一起，是在 Linux 平台上进行图形渲染和硬件加速的常见方式。这些组件一起提供了一个完整的图形渲染栈，允许应用程序直接与图形硬件进行交互。 DRM（Direct Rendering Manager）：DRM 是 Linux 内核中的一个子系统，用于管理图形硬件的驱动程序。它提供了一种通用的接口，允许用户空间程序直接与硬件交互，通过设备文件 /dev/dri/cardX 访问。DRM 提供了诸如模式设置、显示控制、渲染加速等功能。 GBM（Generic Buffer Manager）：GBM 是一个用于管理图形缓冲区的库，通常与 DRM 配合使用。它提供了一种标准的接口，用于分配、管理和操作图形内存。GBM 还提供了与 EGL 和 OpenGL ES 兼容的接口，使应用程序能够使用硬件加速进行渲染。 EGL（Embedded-System Graphics Library）：EGL 是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。EGL 通常与 GBM 和 DRM 一起使用，通过 GBM 提供的接口来创建图形表面，并将其与 OpenGL 或 OpenGL ES 上下文关联起来，实现硬件加速的图形渲染。","categories":["平台Platform","Linux","Linux Graphics"]},{"title":"Mesa","path":"/2024/05/17/平台Platform-Linux-Linux-Graphics-Mesa/","content":"","categories":["平台Platform","Linux","Linux Graphics"]},{"title":"OpenGL显示","path":"/2024/05/17/平台Platform-Linux-Linux-Graphics-OpenGL显示/","content":"GLUGLU（OpenGL Utility Library）是 OpenGL 的一个辅助库，提供了一些更高级的几何计算和对象构造函数，如曲面和体的生成、平移、旋转等，这些函数在处理复杂的几何操作时非常有用。 GLFWGLFW 是一个流行的开源库，主要用于创建和管理图形应用程序中的窗口、OpenGL 或 Vulkan 上下文，以及处理用户输入、定时器等功能。适用于各种图形应用程序的开发，提供了窗口管理、上下文管理、输入处理等功能，使开发者能够专注于图形渲染和应用逻辑的实现。 主要功能： 窗口管理： GLFW 允许开发者创建窗口并对其进行管理，包括调整大小、最小化、最大化、关闭等操作。 上下文管理： 它提供了创建 OpenGL 或 Vulkan 上下文的功能，使得图形渲染程序可以在窗口中绘制图形。 输入处理： GLFW 支持处理用户输入，包括键盘输入、鼠标移动和点击、游戏手柄等。 事件处理： 它允许开发者监听和响应各种事件，如窗口大小改变、键盘按键、鼠标移动等。 监视器管理： GLFW 支持多个显示器的管理，可以获取显示器的分辨率、刷新率等信息。 使用步骤： 初始化： 在程序启动时，调用 GLFW 的初始化函数来初始化库。 创建窗口： 使用 GLFW 的窗口创建函数来创建一个窗口并指定其属性，如大小、标题等。 创建上下文： 使用 GLFW 的上下文创建函数来创建一个 OpenGL 或 Vulkan 上下文。 主循环： 在主循环中轮询事件，并根据事件类型做出相应的处理。 渲染： 在渲染阶段，使用 OpenGL 或 Vulkan 等图形 API 绘制场景。 清理： 在程序结束时，调用 GLFW 的清理函数来释放资源并关闭库。 利用 glfw 监视器 Demo 1234567891011121314151617181920212223242526272829#include &lt;GLFW/glfw3.h&gt; int main() &#123; // 初始化 GLFW if (!glfwInit()) &#123; return -1; &#125; // 获取监视器（显示器）列表 int count; GLFWmonitor** monitors = glfwGetMonitors(&amp;count); // 指定要使用的显示设备索引 int monitor_index = 0; // 设置为你想要的显示设备索引 // 获取指定索引的显示设备 GLFWmonitor* monitor = (monitor_index &lt; count) ? monitors[monitor_index] : NULL; // 获取显示设备的视频模式 const GLFWvidmode* mode = glfwGetVideoMode(monitor); // 创建窗口并指定显示设备 GLFWwindow* window = glfwCreateWindow(mode-&gt;width, mode-&gt;height, &quot;OpenGL Window&quot;, monitor, NULL); if (!window) &#123; glfwTerminate(); return -1; &#125; // 进入主循环 while (!glfwWindowShouldClose(window)) &#123; // 渲染代码 glClear(GL_COLOR_BUFFER_BIT); // ... glfwSwapBuffers(window); glfwPollEvents(); &#125; // 清理资源 glfwDestroyWindow(window); glfwTerminate(); return 0; &#125; GLUT（OpenGL Utility Toolkit） GLUT 是一个跨平台的工具包，用于创建和管理 OpenGL 窗口、处理用户输入等。它提供了一组简单的 API，使得编写基本的 OpenGL 程序变得更加容易。 - GLUT 支持多种操作系统，包括 Windows、Linux 和 macOS。 - 使用 GLUT，你可以很快地编写出一个可以在不同平台上运行的简单 OpenGL 程序，而不必担心平台特定的细节。 - 但是，GLUT 对于创建复杂的图形用户界面（GUI）可能不够灵活，因为它的功能相对有限。 GLUT 是一个跨平台的工具包，用于简化 OpenGL 应用程序的开发。它提供了一组函数，用于创建窗口、处理输入事件、进行基本的图形绘制等，使开发者可以更轻松地编写 OpenGL 应用程序，而无需处理底层的窗口系统的细节。 GLUT 提供了一个相对简单的接口，适用于快速原型设计和简单的图形应用程序。它通常用于学习 OpenGL、编写小型游戏、演示程序等。 GLX（OpenGL Extension to the X Window System） GLX 是 OpenGL 在 X Window System 上的扩展，它允许 OpenGL 应用程序与 X 服务器通信，并在 X 窗口系统中创建 OpenGL 上下文。GLX 提供了一组函数，用于在 X 窗口系统中创建 OpenGL 渲染上下文、管理 OpenGL 窗口和图形渲染等。 GLX 允许 OpenGL 应用程序直接与 X 服务器通信，而不需要借助其他库或工具。它提供了对 OpenGL 的完整支持，可以实现高性能的图形渲染和交互。 GLX 则是 OpenGL 在 X 窗口系统上的扩展，提供了与 X 服务器通信和在 X 窗口系统中创建 OpenGL 渲染上下文的功能。 EGL（Embedded Graphics Library）EGL 是一个用于管理图形渲染上下文的接口，通常用于嵌入式系统和移动设备上。 - EGL 是 OpenGL ES 和 OpenVG 的标准的本地显示系统接口，它提供了与底层窗口系统交互的能力。 - 在 Linux 上，EGL 通常与 GBM（Generic Buffer Manager）或其他图形系统配合使用，如 Wayland。 - 使用 EGL，你可以在嵌入式系统上更好地控制 OpenGL 上下文的创建和管理，以及与窗口系统的交互。","categories":["平台Platform","Linux","Linux Graphics"]},{"title":"Ubuntu18.04更换国内源","path":"/2024/05/17/平台Platform-Linux-Ubuntu-Ubuntu18-04更换国内源/","content":"Ubuntu18.04 更换国内源Ubuntu 本身的源使用的是国内的源，下载速度比较慢，不像 CentOS 一样 yum 安装的时候对镜像站点进项选择， 所以选择了更换成国内的源。 bionic 代表 ubuntu18 备份&#x2F;etc&#x2F;apt&#x2F;sources.list 文件1mv /etc/apt/sources.list /etc/apt/sourses.list.backup 新建&#x2F;etc&#x2F;apt&#x2F;sources.list 文件并添加以下内容1234567891011#163源deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 更改完成之后执行以下命令12# apt update# apt upgrade 其他的一些 apt 命令12345678910111213141516sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 其他几个国内的源：1234567891011121314151617181920212223242526272829303132333435#中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse#阿里云源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse#清华源deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse","categories":["平台Platform","Linux","Ubuntu"]},{"title":"终端","path":"/2024/05/17/平台Platform-Linux-其他-终端/","content":"终端一个基于文本的交互界面 快捷键 打开命令行终端 Ctrl+Alt+t 放大终端 Ctrl Shirft + 缩小终端 Ctrl - 终端提示符含义lemonade@ubuntu:~$ 对应用户名 (lemonade)@主机名 (ubuntu): 工作目录 (~) 提示符 ($) ~：家目录 $: 普通用户#: 超级用户 (root) 命令— 在终端中用于告诉计算机去执行一个动作 参数— 选项— 选项通常用一个连接号（-）或两个连接号（--）来划分 常用 ls: 列出当前目录内容 cd ~: 进入当前用户的家目录 ./ 当前目录 (可省略) ../ 上一层目录 ../../ 上一层的上一层 文件操作指令 mkdir 创建文件夹 mkdir mydir touch 创建空文件 touch myfile rmdir 删除一个空文件夹 rm 删除一个文件或文件夹,默认删除文件 rm -r 删除文件夹 打印定向指令 echo 打印一串字符 echo hello world &gt; 输出重定向&#x2F;指定输出的目标文件 &gt;&gt; 向指定文件中追加内容 cat 读文件内容并打印 cat readme root&amp;sudo sudo passwd 通过普通用户修改超级用户 (root) 的密码. su root 切换用户为 root 用户 (超级用户) su lemonade 切换为 lemonade 用户. sudo 用普通用户权限执行 root 的功能 普通用户权限执行 root 的功能需注意用户环境下的环境变量和 root 用户环境的下环境变量是否一致 移动拷贝指令 mv 移动命令 mv source dest``mv source dir cp 拷贝命令 man 用户帮助手册 man ls ls [options]... [file]... options 选项或参数 file 目标文件或文件夹 [] 可选标志 ... 多参机制 改变权值的命令 chmod 777 readme.sh 所有用户可读可写可执行 文件类型: - ：普通文件d : 文件夹&#x2F;目录l : 链接 (快捷方式)s : 网络套接字p: 管道b : 块设备, 磁盘 c : 字符设备, 键盘 关机 halt 关机 reboot 重启 sudo shutdown -h now 加上关机时间 sudo shutdown -h +1 &quot;See You la la&quot; 加上关机备注","tags":["Linux"],"categories":["平台Platform","Linux","其他"]},{"title":"linux-crypto","path":"/2024/05/17/平台Platform-Linux-加密-linux-crypto/","content":"加密技术通常分为两大类“对称式”和“非对称式”","categories":["平台Platform","Linux","加密"]},{"title":"Hexo博客建设","path":"/2024/05/17/博客-Hexo博客建设/","content":"√ 博客框架采用 Hexo √ 部署到 GitHubPages（） √ 部署到 Vercel（GitHub Publish） × 通过 Netlify 部署和构建 √ 利用 Obsidian Digital Garden&#x2F;Flowershow 插件在 Vercel 上将笔记内容部署为 Obsidian 数字花园 部署流程 创建 GitHub 发布仓库 GitHub仓库部署 创建 GitHub 源码仓库，并在仓库中部署 Hexo 在源码仓库中创建工作流，工作流主要完成任务是在接收到同步后，完成以下几个动作 GitHub Actions 构建静态页面生成 public 文件夹，在构建之前需要调用 hexo 插件自动生成 category 信息 将 public 文件夹拷贝至发布仓库 确定 Hexo 仓库部署在 GitHub 还是本地如果部署在 GitHub则需要整个仓库拉取到 obsidian，主要显示 post 下文件，需要通过 github actions 进行发布管理 优点：本地不需要 Hexo 环境，直接提交后自动构建页面 缺点：所有源码都在 Github 且仓库必须公开 如果部署在本地需要在本地生成静态网页，之后将静态网页通过 publisher 发布 public 文件夹到 github 仓库 优点：仓库可以不开源 缺点：本地需要具有 Hexo 环境，且需要在本地生成静态网页 两个仓库都在 Github是否可以实现，编辑完成后，github 从源码仓库复制到发布仓库？ 源码仓库闭源，同步笔记到源码仓库后，源码仓库通过 actions 时触发同步到发布仓库，更新发布仓库页面 扩展：三仓库管理，Markdown 仓库只用于编辑 Markdown 文件，同步后触发 actions，同步到源码仓库中的 post，源码仓库接受到 push 后，触发 actions 生成静态页面 public，public 生成完成后拷贝 public 到发布仓库利用 actions，可以实现，感觉没啥必要，太过复杂了，源码仓库 + 发布仓库基本就可以了 两仓库实现步骤可以实现两个仓库都在 GitHub，并通过 GitHub Actions 在源码仓库进行编译，编译完成后自动将源码仓库的静态页面内容复制到发布仓库，实现自动化的发布管理。 将 Hexo 的源码仓库设置在 GitHub 上，你可以在这个仓库中编辑和管理 Hexo 的源代码、主题和文章。 创建另一个 GitHub 仓库作为发布仓库，用于存放生成的静态网页。你可以将 Hexo 生成的 public 文件夹的内容推送到这个仓库中。该仓库利用 GitHub Pages，直接通过.github.io 进行访问 在 Hexo 源码仓库中设置一个 GitHub Actions workflow，以便在每次提交或推送时自动将更新的内容复制到发布仓库。 需要配置 GitHub 的 ssh，可以有权限访问两个仓库 需要配置发布仓库的 deploy key，可以有权限写入发布仓库 域名获取 GitHub 二级域名 GitHubPages liuluhua.github.io 二级域名 https://freedomain.one/ linglu.work.gd 二级可穿透域名 解析包括添加三条解析记录 192.30.252.153 是 GitHub 的地址，你也可以 ping 你的 http:&#x2F;&#x2F;你的用户名.github.io 的 ip 地址，填入进去。 第三个记录类型是 CNAME，CNAME 的记录值是：http:&#x2F;&#x2F;你的用户名.github.io 这里千万别弄错了。 绑定 Github 域名，登录 GitHub，进入之前创建的仓库，点击 settings，设置 Custom domain，输入你的域名 图床GitHub 图床 创建一个 public 仓库 进入 Settings-Developer Settings-Personal access tokens (classic) 生成 token PicGo介绍PicGo 是一个开源的图片上传工具，主要用于将本地图片上传到各种图片托管服务，并生成图片链接。它提供了图形界面和命令行两种方式来使用。 用途图片托管：将本地图片上传到图片托管服务，如 GitHub 等。图片压缩：在上传图片之前，可以选择对图片进行压缩以减小图片文件大小，节省存储空间和加快图片加载速度。图片管理：通过 PicGo 上传的图片可以在相应的托管服务上进行管理，包括查看、删除等操作。图片链接生成：上传成功后，PicGo 会生成图片链接，方便在博客、论坛等地方直接使用图片。 配置 Github 图床图床设计选择 GitHub，输入在 GitHub 的仓库名，分支名和 token 即可 设置 GitHub 为默认图床 设置图床参数 设定存储路径 插件 super-prefix安装 super prefix 插件，将图片存储时按照时间分类存储 配置文件路径插件 需要在 PicGo 设置中关闭时间戳重命名 /img/2019/11/18/20191118005858.jpeg 参数 建议值 说明 prefixFormat YYYY/MM/DD/ 文件名个性前缀格式 (以&#x2F;结尾) fileFormat YYYYMMDDHHmmss 文件名个性格式 GitHubGithub Pages 部署GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。 创建 GitHub 账号，并创建一个基于用户名.github.io 的仓库 使用 GitHub Pages 进行部署，所建仓库必须取名为“GitHub 用户名.github.io” 勾选“Add a README file”，不然后面会看不到 GitHub Pages 域名和部署分支 仓库需要创建为公有仓库，即 public 仓库大小限制为 创建完成后 GitHub Pages 给我们提供了一个格式为 https://GitHub用户名.github.io 的免费域名，并且相应的网站是从该仓库的 main&#x2F;master 分支构建得到的 自定义域名，在 GitHub 仓库 Settings-Pages-Custom domain 添加自己的域名 Git HookGit hook 是一种机制，允许在特定的 Git 事件发生时触发自定义的脚本或命令。这些事件可以包括提交 (commit)、推送 (push)、合并 (merge) 等。使用 Git hook，你可以在这些事件发生时执行自定义的操作，比如运行测试、格式化代码、触发构建等。Git 提供了一系列的预定义钩子，你可以将自己的脚本绑定到这些钩子上，或者创建自定义的钩子。 GitHub ActionsGitHub Actions 是 GitHub 提供的一项持续集成（CI）和持续部署（CD）服务，允许开发者自动化软件开发工作流程。通过 GitHub Actions，你可以在 GitHub 上运行自定义的代码（称为动作），以响应存储库中的事件，例如推送代码、创建拉取请求等。 一个 GitHub Actions 的核心概念是 workflow（工作流），它是一系列由动作组成的自定义任务，这些任务可以在特定的事件触发时自动执行。每个 workflow 都定义了一系列步骤，每个步骤又包含一个或多个动作。workflow 可以用 YAML 格式定义，并存储在存储库的 .github/workflows 目录中。 通过 GitHub Actions，实现将代码同步 GitHub 之后，由 GitHub Actions 执行页面的发布。 执行 GitHub Actions，在需要执行的储存库中前往 Settings &gt; Pages &gt; Source，并将 Source 改为 GitHub Actions。 在储存库中建立 .github/workflows/blogPublish.yml 并写入内容 环境变量配置在 Settings –&gt; Secrets and Variables –&gt; Actions 里面,配置后，可以在 actions 里面通过 $&#123;&#123; secrets.dingtalk_secret &#125;&#125; 调用到对应的数据 文章更新时间问题使用 Github Actions 造成的文章更新时间问题参考原文： https://mrseawave.github.io/blogs/articles/2021/01/07/ci-hexo-update-time/ 当使用 Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。对于 Github Actions 可以使用命令在构建之前进行处理 123456jobs: deploy_gh_pages: steps: - name: Restore file modification time run: | git ls-files -z | while read -d &#x27;&#x27; path; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$path&quot;)&quot; &quot;$path&quot;; done 如果 git 命令不好用， 也可以使用 find 命令 1find source/_posts -name &#x27;*.md&#x27; | while read file; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$file&quot;)&quot; &quot;$file&quot;; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果 github actions 中使用 actions&#x2F;checkout@v2，请设定它的参数 fetch-depth: 0，因为 0 表示获取所有分支和标签的所有历史记录。默认值为 1 gitignore在 Git 仓库的根目录下编辑有.gitignore 文件，该文件中定义了一些不需要上传至 GitHub 的内容，列在该文件中的文件或文件夹将会被忽略，不在上传 Hexo 忽略文件12345678.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_multiconfig.yml Obsidian 忽略文件1.obsidian/workspace .obsidian 文件本身是可以同步的，当前存储库的插件以及相关的配置都会下载在这个文件夹中，因此将其同步到 git 记录中也是非常有用的，假如你切换设备就不需要重新为当前的存储库重新配置 Obsidian 了。 GitHub 仓库部署源码仓库部署 创建一个私有仓库，此处我创建一个 BlogDeploy 仓库，仓库拉取到本地后，在仓库中部署 Hexo使用 创建 gitignore 文件，排除 Hexo 不用上传的文件 同步仓库到远端 发布仓库部署 创建一个 GitHub 仓库，仓库必须取名为“GitHub 用户名.github.io” 仓库需要创建为公有仓库，即 public 创建一个分支，分支名为 ImageBed，用于做图床上传 获取 Token，选择用户 Settings-&gt;Developer settings-&gt;Personal access tokens，token 的权限获取，勾上 workflow 即可 图床分支创建用于存储图片，图床分支的相关信息部署完成后，需要在 PicGo 中进行配置 1234git checkout -b my-test //在当前分支下创建my-test的本地分支分支git push origin my-test //将my-test分支推送到远程git branch --set-upstream-to=origin/my-test //将本地分支my-test关联到远程分支my-test上 git branch -a //查看远程分支 Hexo 部署Hexo 是一个基于 Node.js 的静态网站生成器，主要用于快速、简单地搭建个人博客或静态网站。它采用 Markdown 格式来撰写内容，并提供了丰富的主题和插件生态系统，可以轻松扩展和定制网站功能和外观。 适用于个人博客、项目文档、个人简历等各种静态网站的搭建和管理。 目录架构12345678_config.yml #网站的配置信息package.json #应用程序的信息scaffolds #模版文件夹source #存放用户资源，Markdown 文档\t_drafts\t_poststhemes #主题文件夹public #网站文件 Hexo 使用使用流程 安装 hexosudo npm install -g hexo-cli 查看版本，确认安装成功 hexo -v 创建一个新文件夹 Hexo，并初始化该文件夹 hexo init Hexo 清除缓存 hexo clean 生成静态文件 hexo g 开启本地服务器并修改端口为 80hexo s -p 9050 常用命令 12345678910111213141516171819202122npm install -g hexo-cli #安装Hexo npm update hexo -g #升级 hexo init #初始化博客 命令简写 hexo n &quot;我的博客&quot;hexo new &quot;我的博客&quot; #新建文章 hexo ghexo generate #生成 hexo shexo server #启动服务预览 hexo dhexo deploy #部署 hexo server #Hexo会监视文件变动并自动更新，无须重启服务器 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令端口修改 node_modules\\hexo-server\\index.js 临时启动 hexo s -p 9050 hexo generate 将 Hexo 源码目录中已有的源码编译生成为静态网页文件，生成以下： db.json 文件：编译过程中产生的中间文件，不用关心； public 文件夹：新生成的静态网页文件就存放在这个目录下。 hexo deploy 将静态网页文件推送到 GitHub Pages Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容 配置文件配置快捷打开 站点配置文件和主题配置文件是我们 DIY 博客经常要编辑的两个文件，在 Obsidian 中没法编辑 yml 文件，可以通过 URL 来打开 yml 文件，会自动调用默认的编辑器打开。创建一个专门用于编辑配置的文件，写入我们两个配置文件所在的相对路径： 12345[打开站点配置文件](Blog/_config.yml)[打开主题配置文件](Blog/themes/stellar/_config.yml)# 或者通过shellcommand形式打开.开头的隐藏文件[Github 同步忽略文件配置](obsidian://shell-commands/?vault=BlogDeploy&amp;execute=f4b02rlcvr) 站点配置文件在 blog 根目录里的 _config.yml 文件称为站点配置文件 主题修改：theme 网站标题:title 副标题:subtitle 网站描述:description 作者:author 网站头像外部链接:avatar 网站语言:language:zh-Hans 时区:timezone:Asia&#x2F;Shanghai 自定义域名：url: 忽略文件： 12345skip_render: # 排除一些obsidian编辑器的文件和一些脚本/模板文件 - &#x27;_posts/.obsidian/*&#x27; - &#x27;_posts/Scripts/*&#x27; - &#x27;_posts/Templates/*&#x27; 主题配置文件使用的主题：stellar 或者 Next，二选其一 进入根目录 themes 文件夹，里面有个 _config.yml 文件，为主题配置文件 社交外链的设置，即在侧栏展示你的个人社交网站信息。(插件 jiathis) 插入网易云，进入网页版的网易云音乐，选择喜欢的音乐，点击生成外链播放器，在侧栏插入这首歌的音乐播放器，修改 blog/themes/next/layout/_macro 的 sidebar.swig 文件，添加刚刚复制的外链代码 设置背景，在 blog/themes/next/source/css/_custom 文件的 custom.styl 首部添加 body &#123; background:url(./background.jpg); background-attachment: fixed; &#125;，fixed 固定背景图片 增加侧栏菜单条目，默认的侧栏菜单条目有：首页、归档、标签、关于、搜索等。如果你想要增加其他的菜单条目，修改主题配置文件 _config.yml 里的 Menu Settings 中的 menu 和 menu_icons 两个地方 域名配置文件进入 blog/source 目录下，创建一个文件，文件名 CNAME，写入你的自定义域名即可 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 扩展：abbrlink&#x3D;文章永久链接 category123456789并列分类，了解一下： categories: - [Linux] - [Tools]并列+子分类，再了解一下： categories: - [Linux, Hexo] - [Tools, PHP] 自定义文章标签生成标签页面 hexo new page tags 修改 blog&#x2F;source&#x2F;tags&#x2F;index.md，添加 type: “tags” 123title: tagsdate: 2023-01-08 11:27:57type: &quot;tags&quot; 以后就可以在文章文件头添加标签了，如下 123456title: Hexo + GitHub 搭建个人博客date: 2023-01-07 13:15:00tags:- Hexo- Next- 博客 手动生成和添加是十分繁琐的，后续利用插件形式按照目录格式为文章自动生成标签。 评论系统 Waline Waline评论系统的配置 前往 Waline 官网 根据指引到 Vercel 进行 Waline 服务端部署 安装 @waline&#x2F;hexo-nextnpm install @waline/hexo-next 为了不使用魔法也能正常评论，我们需要有自己的域名解析到 Waline 服务端，可以在域名控制台给自己的博客域名添加二级域名，添加 CNAME 解析到 cname-china.vercel-dns.com 或添加 A 解析到 76.223.126.88（也可以前往 Vercel All IP 自行挑选合适的节点），接着进入 Vercel 的 Waline 应用的控制台，在 Settings-Domains 里添加上文提到的二级域名，这样在主题配置文件添加配置后就可以正常评论了 主题配置文件添加配置 配置完评论后及时到 Waline 服务端登录，以便管理评论 可选择开启评论邮件提醒功能， Waline 官网 有详细的说明 设置字体更改站点配置文件，增加如下字段 1234inject: head: &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/satouriko/LxgwWenKai_Webfonts@v1.101/dist/LXGWWenKaiMono-Bold.css&quot; /&gt; 更改主题配置文件，找到 style 字段在 font-family 中增加字体名称： 123456style: font-family: logo: &#x27;LXGWWenKaiMono&#x27; body: &#x27;LXGWWenKaiMono&#x27; code: &#x27;LXGWWenKaiMono&#x27; codeblock: &#x27;LXGWWenKaiMono&#x27; 设置背景音乐在 stellar 主题的 _data/widgets.yml 文件中找到 welcome 字段，在其中的 content 部分添加： 12345welcome: layout: markdown title: 哈喽~ 旅人： content: |&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=224 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=512983678&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt; 插件部署插件 hexo-deployer-git 编辑 Hexo 顶层目录下的 _config.yml 文件，文件最后可以看到 deployment 相关内容 1234deploy： type: git repo: git@github.com:liuluhua/liuluhua.github.io.git branch: main repo 填写仓库 ssh 地址 branch 的填写需要和 GitHub Pages部分指定的Branch保持一致 搜索插件 hexo-generator-searchdbstellar 自带了搜索插件，故未配置该插件 安装 hexo-generator-searchdbnpm install hexo-generator-searchdb 修改主题配置文件 12local_search:\tenable: true 自动标签插件 hexo-auto-category该插件在 Hexo 进行 build 的时候会去自动根据文章目录情况来自动修改文章的 categories 信息 安装插件 npm install hexo-auto-category --save 修改站点配置文件 _config.yml，使文章链接清晰 12345678910111213# Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the max_depth of directory-tree you want to generate, should &gt; 0# multiple: multiple category hierarchiesauto_category: enable: true multiple: true depth: 5# 修改 permalink 让你的文章链接更加友好，并且有益于 SEO permalink: :year/:month/:hash.html# 规定你的新文章在 _post 目录下是以 cateory new_post_name: :category/:title| 该插件需要每次手动构建执行 hexo g 时才会更新 categories 信息。 1.仓库部署在本地，上传时使用 git hook，在我们每次执行 commit 前都自动运行 npx hexo generate 触发自动生成 categories 的行为，并将生成后的变更自动添加到本次提交中，然后一同 push 到 github 上去。这里可以使用 husky 来很方便的设置这样一个 git hook1. 安装 huksy：npm install husky --save-dev2. 执行 huksy 初始化指令：npx husky install*3. 在 package.json 中的 scripts 中写入：&quot;prepare&quot;: &quot;husky install&quot;4. 在生成的 .husky 目录创建 pre-commit 文件（chmod a+x pre-commit），并写入以下内容，之后提交代码时，检查有无 categories 的生成信息。 1234#!/usr/bin/env sh . &quot;$(dirname -- &quot;$0&quot;)/_/husky.sh&quot; npx hexo generate &amp;&amp; git add . 2. 仓库部署在 GitHub 时直接利用 GitHub Actions 自动生成 百度数据分析进入 https://tongji.baidu.com/ 申请账号后，输入网址获取统计代码，之后在 stellar 主题的配置文件 _config.yml 的扩展插件部分插入以下代码： 1234 baiduanalytics: enable: true # 使能百度分析接口 inject: | ...扩展插件代码 阅读量统计用于 next 主题 Leancloud（https://console.leancloud.cn/） 创建应用，进入该应用的 设置-&gt;应用凭证，找到 AppID 和 AppKey，记录下来后面配置要用 配置 _config.yml 启用网页访问统计，配置 leancloud 的 app_id 和 app_key，打开计数功能，统计来源改为 leancloud 123456789101112131415161718#网页访问统计#Analysis of website visitorsweb analytics:\tenable:trueleancloud:\tapp id: app key: # 浏览量计数# Number of visitsviews:\tenable:true\t#统计数据来源\t#Data Source\t#Options:busuanzi | leancloud\tsource:&quot;leancloud&quot;\tformat:&quot;&#123;&#125;次&quot; 页面底部展示网站的 PV、UV 统计数用于 next 主题显示页面的访问量和访客数量 123456789101112# 展示网站的 pv、w 统计数# Display website pv and uv statisticsstatistics:\tenable:true\t#统计数据来源，使用leancloud 需要设置&#x27;web analytics:leancloud&#x27;中的参数;busuanzi 显示统计数据很大属于正常现象，部署后会正常\t# Data source.If use leancloud,you need to set the parameter in&#x27;web analytics:leancloud\t# Options:busuanzian | leancloud\tsource:&quot;leancloud&#x27;\t#页面显示的文本，&#123;&#125;是数字的占位符(必须包含)，下同\t# Displayed text, &#123;&#125;is a placeholder for numbers (must be included), the same below\tpv format:&quot;总访问量 &#123;&#125;次&quot;\tuv format:&quot;总访客数 &#123;&#125;人&quot; Canvas nest 背景动画 在 blog/source/_data 文件夹下新建 footer.njk 并编辑 1&lt;script color=&quot;0,255,255&quot; opacity=&quot;1&quot; zIndex=&quot;-1&quot; count=&quot;70&quot; src=&quot;https://cdn.staticfile.org/canvas-nest.js/1.0.1/canvas-nest.js&quot;&gt;&lt;/script&gt; 修改主题配置文件 12custom_file_path: footer: source/_data/footer.njk stellar 主题中直接添加在主题配置文件 _config.yml footer 的 content 中 MathJax 安装 hexo-filter-mathjax 修改主题配置文件 123math: mathjax: enable: true 此后可在文章文件开头添加参数 mathjax: true 以使用 MathJax CDN 修改主题配置文件 123vendors: plugins: custom custom_cdn_url: https://cdn.staticfile.org/$&#123;cdnjs_name&#125;/$&#123;version&#125;/$&#123;cdnjs_file&#125; 字数统计 安装 hexo-word-counter 运行时间next 主题在 /blog/themes/next/layout/_partials/footer.njk 中添加 stellar 主题在主题配置文件 _config.yml 中找到 footer: 中的 content: |，在其后添加 1234567891011121314151617181920&lt;div&gt; &lt;span id=&quot;timeDate&quot;&gt;载入天数...&lt;/span&gt; &lt;span id=&quot;times&quot;&gt;载入时分秒...&lt;/span&gt;&lt;/div&gt;&lt;script&gt; var now = new Date(); function createtime() &#123; var grt= new Date(&quot;05/20/2024 05:20:00&quot;);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125; document.getElementById(&quot;timeDate&quot;).innerHTML = &quot;本站已安全运行 &quot;+dnum+&quot; 天 &quot;; document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; 小时 &quot; + mnum + &quot; 分 &quot; + snum + &quot; 秒&quot;; &#125;setInterval(&quot;createtime()&quot;,250);&lt;/script&gt; 站点地图 安装 hexo-generator-sitemap 修改主题配置文件 12menu: sitemap: /sitemap.xml || fa fa-sitemap 执行 hexo cl &amp;&amp; hexo g 生成 sitemap.xml 此时可以在 blog/public 文件夹下看到 sitemap.xml 验证，进入 Google Search Console ，选择网址前缀，输入网址时记得加上 https:&#x2F;&#x2F;，选择 HTML 标记，你会得到元标记 &lt;meta name=&quot;google-site-verification&quot; content=&quot;xxxxxxxx&quot; /&gt;，将 content 后的内容加入到主题配置文件中 google_site_verification: &quot;xxxxxxxx&quot;，执行 hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 点击前往资源页面 添加站点地图，成功提交 静态资源压缩 安装 hexo-neat 主题配置文件添加配置 123456789101112131415161718neat_enable: trueneat_html: enable: true exclude:neat_css: enable: true exclude: - &#x27;**/*.min.css&#x27;neat_js: enable: true mangle: true output: compress: exclude: - &#x27;**/*.min.js&#x27; 文章页眉显示标签用于 next 主题 在 blog/source/_data 文件夹下新建 post-meta.njk 并编辑 12345678910&lt;span class=&quot;post-meta-item&quot;&gt; &#123;%- if post.tags and post.tags.length %&#125; &#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27; if theme.tag_icon else &#x27;#&#x27; %&#125; &lt;span class=&quot;post-tags&quot;&gt; &#123;%- for tag in post.tags.toArray() %&#125; &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&#123;&#123; tag_indicate &#125;&#125; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;%- endfor %&#125; &lt;/span&gt; &#123;%- endif %&#125;&lt;/span&gt; 修改主题配置文件 12custom_file_path: postMeta: source/_data/post-meta.njk","categories":["博客"]},{"title":"Markdown笔记","path":"/2024/05/16/语言-Markdown笔记/","content":"Markdown 笔记语法表格 &amp; 文本样式 样式 语法 示例 加粗 前后 ** 或 __ 加粗 1 加粗 2 斜体 前后 * 或 _ 斜体 1 斜体 2 删除线 前后 ~~ 删除线 内联代码 前后 &#96; code 下划线 前&lt;u&gt; 后 &lt;/u&gt; 下划线 高亮 前后== &#x3D;&#x3D;高亮文本&#x3D;&#x3D; 引用 此内容为引用内容 链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接 Blog网址 图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中 图片可拖动为文件到任意窗口使用 无序列表 项目 项目 1 项目 A 项目 B 项目 2 有序列表 项目 1 项目 A 项目 B 项目 2 任务列表 A 计划 A1 计划 A2 计划 B 计划 代码块代码块支持 168 种编程语言 12345678910111213141516// javascript 冒泡排序function bubbleSort(array) &#123; let swapped = true; do &#123; swapped = false; for (let j = 0; j &lt; array.length; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; let temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; swapped = true; &#125; &#125; &#125; while (swapped); return array;&#125; KaTeX 数学公式内联公式质能方程 $E&#x3D;mc^2$ 公式块$$\\displaystyle \\left( \\sum_{k&#x3D;1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k&#x3D;1}^n a_k^2 \\right) \\left( \\sum_{k&#x3D;1}^n b_k^2 \\right)$$","tags":["语言"],"categories":["语言"]},{"title":"ffmpeg-m3u8转mp4","path":"/2024/05/16/软件-Ffmpeg-ffmpeg-m3u8转mp4/","content":"FFmpeg 命令行工具将 m3u8 文件转换为 mp4 格式 下载并安装 FFmpeg您可以从 官方网站 下载适合您操作系统的版本。 打开命令行工具 在 Windows 上，您可以按下 Win + R 键，然后输入 cmd 并按 Enter 键打开命令提示符。 在 Mac OS 或 Linux 上，您可以打开终端应用程序。 转换 m3u8 文件在命令行中，导航到包含 m3u8 文件的目录，然后运行以下命令： 1ffmpeg -i input.m3u8 -c copy output.mp4 input.m3u8 是要转换的 m3u8 文件的名称，output.mp4 是转换后的 mp4 文件的名称。 该命令将使用 FFmpeg 将 m3u8 文件转换为 mp4 格式，并将其保存在相同的目录中。 请注意，此命令只能将 m3u8 文件转换为 mp4 格式，而不能将其中的视频文件下载到本地计算机。 如果您需要下载 m3u8 文件中的视频文件，请使用其他工具或软件。 将分段式 m3u8 文件转换为 MP4 文件1234567891011121314151617#!/bin/bashcd ./m3u8Movie #分段式m3u8文件所在文件夹for i in &#123;1..2473&#125; #轮询所有分段式文件数量do if [ -f &quot;$i&quot; ]; then #检测文件存在 mv &quot;$i&quot; &quot;$i.mp4&quot; #重命名 fi echo &quot;file &#x27;./$i.mp4&#x27;&quot; &gt;&gt; list.txt #添加到列表中去done#调用ffmpeg进行视频连接操作ffmpeg -f concat -safe 0 -i list.txt -c copy ../movie.mp4#-f 指定输入格式为concat，表示要进行视频文件的连接操作#-safe 0 设置安全模式为0，允许使用不安全的文件名#-i 指定文本文件包含了要连接的视频文件的列表及其路径#-c 直接复制输入视频文件的音视频流，而不进行重新编码。这样可以加快处理速度而不损失质量。#指定输出文件路径和名称","tags":["其他"],"categories":["软件","Ffmpeg"]},{"title":"Nginx学习笔记","path":"/2024/05/16/软件-Nginx-Nginx学习笔记/","content":"Nginx功能： Web 服务器 负载均衡 API 网关 DDoS 防御 反向代理 Web 应用防火墙 缓存 下载sudo apt install nginx -y 配置 nginxnginx 的配置文件位于 /etc/nginx/ 根据配置文件中的 root 确定根目录位置 /var/www/html 链接网页根目录到指定位置 ln -s /var/www/html ~/html 配置文件cd /etc/nginx/sites-enable 原来的配置为 default（链接到 sites-avaliable），删除并添加自己的页面 输入下列内容 12345678910111213141516171819202122232425server &#123; listen 8080 default_server;# 注意这里，要把默认的那个default_server去掉,因为我们在下面要单独配置域名访问，所以这里不要留default_server，不然会报错。 #server_name mytest.com; //这里写你想设置的域名，可以写多个，与名之间用空格隔开 root /home/ubuntu/html;# //这里是你虚拟机的根目录，写绝对路径 # Load configuration files for the default server block. location / &#123; index index.php index.html index.htm;# //这里配置默认访问的页面 &#125; #location ~* \\.php$ &#123; //这里配置php解析.php文件 # fastcgi_index index.php; # fastcgi_pass 127.0.0.1:9000; # include fastcgi_params; # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param SCRIPT_NAME $fastcgi_script_name; #&#125; #error_page 404 /404.html; //默认的错误页面 # location = /40x.html &#123; #&#125; #error_page 500 502 503 504 /50x.html; # location = /50x.html &#123; #&#125;&#125; 输入 nginx -t 检查配置文件 之后重新启动 nginx 并访问 sudo systemctl start nginx sudo systemctl enable nginx 直接输入 IP 地址即可访问，根据设置的端口进行访问 修改页面，重载页面sudo nginx -s reload 命令查看 nginx 版本 nginx -v 配置文件所在位置 /etc/nginx，文件名 nginx.conf 检查配置文件是否有问题 nginx -t 重新加载 nginx 配置文件 nginx -s reload 关闭 nginx nginx -s quit 或 nginx -s stop eventshttpserverincludelistenserver_nameroot 根目录节点index 指定页面returnlocation &#x3D;(完全匹配) ~(启用正则表达式)rewrite 重写proxy_pass curl 命令是一个功能强大的命令行传输工具，用于发送请求和下载文件。它支持多种协议，如 HTTP、HTTPS、FTP 等，可以设置请求头、请求参数等 -i 参数 打印出服务器回应的 HTTP 标头","categories":["软件","Nginx"]},{"title":"Qt多项目管理","path":"/2024/03/03/语言-Qt-Qt多项目管理/","content":"Qt 工程过大或需要将工程分模块编译成库的形式加载时,需要将整体的 Qt 项目拆分各个小模块进行编译。 1.条件编译文件123456789unix&#123; //执行unix环境下的配置选项&#125;win32&#123; //执行Windows环境下的配置选项&#125;contains(QT_ARCH, arm64)&#123; //执行在架构为arm64的环境下的配置选项&#125; 2. 子项目 lib子项目工程文件为 12345678QT -= guiTARGET = printHelloCONFIG += staticlibTEMPLATE = libDEFINES += printHello_LIBRARYCONFIG -= debug_and_releaseSOURCES += printHello. cppHEADERS += printHello. h 3. 子项目 dll1234567QT -= guiTARGET = printNiceTEMPLATE = libDEFINES += printNice_LIBRARYCONFIG -= debug_and_releaseSOURCES += printNice. cppHEADERS += printNice. h 4.可执行程序项目 exe1234567QT += core gui widgetsTARGET = printTEMPLATE = appSOURCES += main. cpp printwindow. cppLIBS += -LprintHello -lprintHello -LprintNice -lprintNiceFORMS += printwindow. uiHEADERS += printwindow. h 5.管理项 Dirs123TEMPLATE = subdirsSUBDIRS += printHello/printHello.pro printNice/printNice.pro print.proCONFIG += ordered","categories":["语言","Qt"]},{"title":"about","path":"/about.html","content":"个人信息 姓名： 刘璐华 学历： 本科 出生年月: 1995.09 性别： 男 联系方式： 15756000566 英语： 四级 邮箱： &#108;&#105;&#x75;&#108;&#x75;&#x68;&#117;&#x61;&#55;&#64;&#x67;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#109; 教育经历： 2013-2017 铜陵学院 电气工程及其自动化 工作经历 时间 公司 职位 工作内容 2017.02-2019.10 上海华之邦科技股份有限公司 嵌入式 Linux 软件工程师 嵌入式 Linux 环境搭建，数据库，触摸库，USB 库等的移植工作，Linux 环境下的 Qt 编程，开发文档，设计文档，API 文档，操作手册等文档的编写 2019.10-2020.07 上海金标生物科技有限公司 Linux Qt 高级工程师 嵌入式 Linux 开发板的选型及环境搭建，相关库的移植工作，Linux 环境下软件代码的编写&#x2F;重构&#x2F;测试，通信协议的制定，相关文档的编写 2020.07-2021.10 无锡百泰克生物有限公司（上海分公司） 软件开发负责人 NAS 部署与管理，redmine 的部署与项目进度控制，PCR 上位机架构设计，第三方设备的选型及环境搭建使用，上位机代码编写，相关文档的编写 2021.10- 至今 安徽华明航空电子系统有限公司 Linux 嵌入式软件工程师 Windows 环境下的 C++ 代码的开发工作，Linux 平台环境的搭建，Windows 平台向 Linux 平台下的迁移工作，窗口的重绘工作，相关设计&#x2F;测试文档的编写工作 奖项荣誉奖学金，优秀社团干部，优秀新人，优秀员工，优秀团队 专业技能 熟练使用 Linux ，熟悉 Linux 环境配置及平台搭建（网络配置，内核配置，文件系统配置等） 熟练掌握 Linux 环境下的 C++ 程序设计和 Qt 程序设计 熟练掌握多项外设的移植使用，如 4G 终端&#x2F;相机&#x2F;扫描模块等 熟练掌握 Linux 下的串口通讯、MODBUS 通讯、TCP/IP 通信、USB 通信编程 熟悉 Shell，会编写脚本用于辅助编译工作 了解 Python，会利用 Python 进行相关的辅助工作 了解 Docker 及 docker-compose，能够编写 docker-compose 脚本并运行 docker 服务 项目经历基于嵌入式 Linux 环境下的烟气在线监测系统（CEMS）&#x2F;水质在线检测设备功能：系统主要通过控制设备采集污染气体&#x2F;水质，在腔体内对污染气体&#x2F;的光学数据通过程序中的 Matlab 算法进行分析，得到污染物实时浓度，进行监测及上报给环保局。模块：软件系统分为 PC 端（数据存储与上报），ARM 端（数据处理及程序控制），STM32 端（动作执行），主要负责的职责涉及以下方面： 环境搭建：嵌入式 Linux 环境的交叉编译、裁剪 外部库移植：libusb&#x2F;libmodbus&#x2F;MQTT 协议等通讯库向 linux 环境下的移植使用 代码编写：基于 Qt4 完成 ARM 端的代码编写及 PC 端上位机的后期维护工作 设备测试及文档：完成模块及系统测试，输出设计文档，开发文档，测试文档，操作文档等手册 现场调试：对于初始型号在现场调试并根据反馈结果迭代程序 难点： 移植工作，根据实际嵌入式环境编译脚本及编译选项 根据国产的**A3352(基于 TI AM3352)**开发板进行嵌入式程序开发、调试 通过 libusb 等外部库实现 USB 协议和上位机通讯 实际现场问题的排查，影响设备运行的原因多种多样，包含电磁兼容性，信号屏蔽，电源&#x2F;地线稳定性，从硬件到外设的各方面原因 基于 Windows&#x2F;Linux 环境下的光谱仪的 SDK 开发功能：设备主要通过控制氙灯的闪烁频率，并采集 CCD 的相关数据用于 CEMS 中的光谱监测分析。模块：设备分为 PC 端（数据存储与分析），STM32 端（动作执行），主要负责的模块涉及以下几个方面： 多平台开发：Windows 及 Linux 环境下 PC 端代码开发 多通讯协议开发：TCP&#x2F;串口&#x2F;USB 三种方式连接设备，并对设备进行操作 代码编写：基于 Qt5 完成 PC 端多平台代码的编写 基于 Linux 环境下的 PCR 设备&#x2F;心室辅助装置 VAD 的开发功能：PCR 设备主要用于通过控制 TEC 升降温进行扩增及溶解，通过 Basler 相机采集荧光数据，通过 Matlab 算法进行分析，依据在每个循环的荧光数据通过阈值基线计算判断样品的阴阳性。功能：VAD 设备主要用于压力传感器进行 ms 级监测血压并显示，通过手动设置泵的速度，帮助血液泵送到身体其他部位。 环境搭建：Matlab 算法移植，相机支持库的配置及使用 通信协议：制定通讯协议，熟悉 CAN 协议，使用 socketCAN 进行通讯 代码编写：包括架构涉及，功能配置，业务逻辑 难点： 设计设备的升降温、电机旋转角度、相机数据采集和多线程处理的同步控制 针对不同设备间算法的兼容性及普适性测试及参数微调 根据国产的 OK3568(基于 RK3568) 开发板进行嵌入式程序开发、调试 eVTOL 航电模拟器系统的平台迁移工作和备份仪表的模块开发功能：系统主要用于飞机的六大仪表显示，飞行路径规划，机体相关信息显示。系统分为 Windows 和 Linux 双平台进行开发，其中 Windows 主要适用于模拟器，Linux 主要适用于真机。主要涉及以下几个方面： 环境搭建：Linux 环境部署及内核文件系统裁剪，内核实时性 xenomai 的方案学习 通讯协议：熟悉原来基于 socket 中间件的通信协议，并基于串口和 CAN 进行分解 代码迁移：将原来的 Windows 环境下的系统代码迁移到 Linux 环境下，并调试程序直至正常运行 窗口系统：为迁移后的程序在 Qt 环境下设计新的窗口系统 MES 系统项目上线 完成 MES 项目一阶段验收 完成 SAP 对接测试上线工作 完成立库的一阶段上线 负责光伏项目整体进度推进，未完成项任务计划沟通制定、实施及变更控制 负责组件试运行期间问题清单需求收集、评审和进度跟进 负责组件 MES 系统迭代升级和测试验证 负责 MES 项目与各外围系统对接的相关测试及推进工作 负责向项目干系人工作进展和阶段性成果沟通汇报 负责组件 MES 项目风险识别、分析、反馈风险策略实施 负责组件 MES 项目用户支持、培训和运维保障 自我介绍 学习了解一些 python 相关的内容，比较基础，通过 BeautifulSoup 爬取一些自己想要的信息 在局域网内搭建了一台 NAS，利用 docker 部署了一些 nextcloud 等应用，用于管理自己的所有资料 基于个人私有的云服务器，利用 docker 部署了自己的 wordpress 博客，记录一些学习内容和资料 完成一台 3D 打印机的 DIY 工作，搭建了 web 端的 fluidd 上位机，连接 klipper 固件的主板，调试完成 3D 打印"},{"title":"aboutWork","path":"/aboutWork.html","content":"知识结构知识结构会涉及到知识技能的深度和广度，一门语言，知识技能构成如下： 数据结构 + 算法（不论在哪门语言下，其理论基础是一致的） 语法 + 基础库 常用框架的掌握 模式和最佳实践 性能调优、Debugging、Troubleshooting 等 可以对语言深入吐槽，比如 python 为什么搞 GIL，.net 的 GC 线程怎么就不同呢学习框架源码可以让你规范自己的代码、提高代码质量。学习多个框架可以开阔自己的视野，了解方案的差异化，就很容易找到适合自己项目的方法。 C&#x2F;C++ 语言C 数据类型 C&#x2F;C++ 关键字 流程控制 数组 函数 指针 内存布局 结构体、共用体 二级指针 指针函数 函数指针和回调函数 文件操作 动态库的封装和设计C++ 命名空间 引用 C&#x2F;C++ 混合编程，extern &quot;C&quot; 函数拓展 面向对象编程思想 -OOP 类的封装 构造和析构 静态成员 对象管理 友元函数与友元类 操作符重载 继承与多继承 多态 虚函数与抽象类 函数模板与类模板 输入输出流 异常处理C++ 序列式容器 堆栈容器 双向链表容器 关联式容器 对组 STL 算法详解 其他LinuxPythonshellJavaScriptHadoopVxWorks汇编 数据结构 顺序存储 链式存储 - 链表 循环链表 双向链表 栈 队列 哈希表 树基本概念&amp;遍历 二叉树 图 设计模式和 UML 设计模式概念 面向对象设计原则 单例模式 工厂模式 UML 应用 中间件 XML 网络安全 C&#x2F;S 计算机组成原理&#x2F;系统结构 B&#x2F;S MVC MVP 算法 排序 查找 操作系统 操作系统原理 基础操作 linux 操作系统介绍，UNIX，POSIX linux 基本命令 linux 运维操作 linux 目录和路径 linux 文件权限 文件系统剖析 启动过程分析 网络服务配置 Linux 后台程序 - 服务 环境变量 vim 编辑 Shell 编程 Makefile 编程 系统编程 系统调用 时间编程 文件 IO&#x2F;标准 IO 进程控制原理 进程间关系 多进程程序 fork( ) 守护进程 进程间通信 管道 - 有名&#x2F;无名 信号 信号灯 消息队列 共享内存 Linux 任务 任务管理 任务调度 任务间同步与通信 线程控制原理 多线程编程方法 线程间同步 - 互斥锁，条件变量，信号量 网络编程 网络基础知识&#x2F;体系结构 -OSI 参考模型 TCP&#x2F;IP 网络结构 -TCP&#x2F;IP 参考模型 网络协议编程 socket 套接字原理 socket 编程 常用 API 函数 Ping 命令 高并发服务器 异步 IO libevent 许可证服务器 UDP PPP GPRS 代理服务器 路由器 TCP&#x2F;IP socket HTTP RTP SIP RTMP RTSP HLS FreeSwitch P2P VoIP Asterisk WebService SDN openssl dpi Opensips thrift DarwinStreamingServer RTCP WebSocket async IO Soap 数据库 关系型&#x2F;非关系型数据库 SQL 语言编程 关系型数据库 MySQL Oracle SQL Server DB2 Sybase PostgreSQL 非关系型数据库&#x2F;缓存技术 redis mongodb nosql memcached HBase Cassandra 框架 -GUI 程序开发 GUI 基础&#x2F;类型 QT STL&#x2F;模板库 MFC boost C++11 TBB libcurl wxwidgets 文件系统 虚拟文件系统 文件系统的建立 ramfs 内存文件系统 proc 文件系统 devfs 文件系统 MTD 技术 MTD 块设备初始化 MTD 块设备的读写操作 JFFS2 文件系统 cramfs 文件系统 Windows 技术 MFC C# COM&#x2F;DCOM&#x2F;COM+ ATL .NET DLL ActiveX GDI&#x2F;GDI++ Windows API WTL Windows 桌面 WinSocket DUILib WinDbg Windows SDK WinInet WPF WinForm DirectUI ui 控件 其他 wince ucos 风河 编译调试 编译原理 Shell 脚本的编写 gcc 使用方法 gdb 调试技术 Autoconf Automake Makefile CMake Meason 代码优化 lib 库的制作和使用 通信 串行 I&#x2F;O 的基本概念 MiniCOM 系统移植 交叉编译 TFTP 服务 NFS 服务 Bootloader 内核 工具链 U-boot Linux 内核 平台相关代码分析 ARM 平台介绍 内核 内核配置与裁剪 内核模块开发 文件系统制作 进程子系统创建调用进程 进程调度算法 内存子系统分配回收内存 proc 文件系统 系统调用 内核定时器 内核异常分析 驱动 设备驱动程序基础知识 Linux 系统的模块 字符设备驱动程序 总线设备驱动模型 硬件访问技术 中断处理 字符设备驱动分析 fs_operation 结构 键盘驱动 I&#x2F;O 驱动 看门狗驱动程序 块设备驱动程序 块设备驱动程序工作原理 块设备驱动程序分析 块设备的读写请求队列 块设备驱动程序结构 字符设备与块设备的异同 MMC 卡驱动程序 驱动程序 Input 设备 platform PCI USB 网卡 串口 触摸屏 底层核心 ARM 处理器编程 ARM 硬件接口编程 图形&#x2F;游戏相关 OpenGL opencv Cocos2d-x DirectX Unity3D UE4 u3d OSG 流媒体&#x2F;多媒体&#x2F;视频&#x2F;音频 流媒体 MPEG ffmpeg H.264 vlc AAC FLV X264 live555 openSIPS MP4 H.265 MP3 librtmp openfire vp8 驱动&#x2F;插件 USB SD FIPS MCU CSP openstack PKCS11 NPAPI SATA 工具 VS(Visual Studio) Cmake SVN git github wireshark strace MSDN 应用领域 服务器&#x2F;服务端&#x2F;后端 客户端&#x2F;界面开发&#x2F;界面编程 图形&#x2F;图像 游戏 视音频 银行 嵌入式 引擎 大数据 内核 流媒体 驱动程序 组件 IM 即时通信 直播 人工智能 搜索技术 监控系统 串口 浏览器 深度学习 P2P 呼叫中心 三维开发 物联网 处理器 机器人 编译器 芯片 仿真 IVR 服务器 麦克风 传感器 Web 服务器 (运维管理) Nginx LVS Apache IIS LNMP docker 程序员证书 系统分析师 系统架构设计师 信息系统项目管理师 网络规划设计师 系统规划与管理师 软件设计师 数据库系统工程师 软件评测师 信息系统管理工程师 嵌入式系统工程师 信息安全工程师 电子商务师 系统集成项目管理工程师 网络工程师 信息系统监理师 信息处理技术员 程序员 网络管理员 运行管理员"}]