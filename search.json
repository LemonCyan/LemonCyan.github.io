[{"path":"/2024/05/21/操作系统-VMware-Vmware共享文件夹/","content":"在虚拟机中设置共享文件夹完成后，发现共享文件夹没有出现，执行vmhgfs-fuse .host:/ /home/forlinx/3568Share将共享文件夹挂载到&#x2F;home&#x2F;forlinx&#x2F;3568Share 创建一个startShare.sh写入vmhgfs-fuse .host:/ /home/forlinx/3568Share加权限chmod a+x startShare.sh添加该脚本到自启中","categories":["操作系统","VMware"]},{"path":"/2024/05/21/操作系统-WSL-USB设备连接到WSL/","content":"在WSL2中连接3D打印机的USB端口，须将该设备从windows中挂载至Linux中，需要在windows环境中安装usbipd usbipd GitHub地址 https://github.com/dorssel/usbipd-win 安装usbipd 12#在win命令行中执行winget install usbipd 安装环境 123##在你的wsl中执行sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 *usbipd: error: WSL ‘usbip’ client not correctly installed.重新执行此步骤 列出并挂载win中的设备到linux环境下 123# 在win终端中执行usbipd wsl listusbipd wsl attach --busid=4-1","categories":["操作系统","WSL"]},{"title":"Qexo管理Hexo博客","path":"/2024/05/21/博客-Qexo管理Hexo博客/","content":"安装克隆qexo项目到本地git clone https://github.com/Qexo/Qexo.git编辑配置，以使用 Mysql 为例, 确认好安装相关依赖后在manage.py的同级目录下创建并修改 configs.py 12345678910111213141516import pymysql pymysql.install_as_MySQLdb() DOMAINS = [&quot;127.0.0.1&quot;, &quot;124.222.246.202&quot;] DATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;NAME&#x27;: &#x27;数据库表&#x27;, &#x27;USER&#x27;: &#x27;数据库用户名&#x27;, &#x27;PASSWORD&#x27;: &#x27;数据库密码&#x27;, &#x27;HOST&#x27;: &#x27;127.0.0.1&#x27;, &#x27;PORT&#x27;: &#x27;3306&#x27;, &#x27;OPTIONS&#x27;: &#123; &quot;init_command&quot;: &quot;SET sql_mode=&#x27;STRICT_TRANS_TABLES&#x27;&quot; &#125; &#125; &#125; 安装依赖 123pip3 install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate 启动Qexo博客管理后端python3 manage.py runserver 0.0.0.0:9051 --noreload访问公网IP+端口即可打开管理页面 配置","categories":["博客"]},{"title":"3D打印控制命令","path":"/2024/05/21/其他-3D打印机-3D打印控制命令/","content":"限位开关确保X、Y和Z轴的限位开关都没有被触发，然后通过控制台发送命令：QUERY_ENDSTOPS返回值是open打开，则限位触发电平类型设置正确，如果是triggered（触发），则需要修改限位的电平类型（以X轴为例） 123[stepper_X]endstop_pin: ^PE5 #修改前endstop_pin: ^!PE5 #修改后 热床PID校正G28归零后，将喷嘴移至热床中心，高出床面约5-10mm，然后发送命令PID_CALIBRATE HEATER=heater_bed TARGET=100它将执行一个PID校准程序，将持续约10分钟，完成后控制台将会返回PID数值，将其复制到热床的PID设置即可。 挤出头PID校正先将模型冷却风扇设置为25%的转速 M106 S64 ，然后发送命令PID_CALIBRATE HEATER=extruder TARGET=245它将执行一个PID校准程序，将持续约5分钟，完成后控制台将返回PID数值，将其复制到配置文件即可。 其他使 Klipper 进入 “shutdown”（关闭）状态M112 重新加载配置文件并重启FIRMWARE_RESTART 保存配置文件SAVE_CONFIG 查看使用的printer.cfg文件位置ps -ef | grep klippy 获取位置GET_POSITION QUAD_GANTRY_LEVEL","categories":["其他","3D打印机"]},{"title":"3D打印相关软件","path":"/2024/05/21/其他-3D打印机-3D打印相关软件/","content":"系统固件KlipperKlipper 是一个高性能、灵活的3D打印机固件，它通过将一些计算工作转移到更强大的主机（如Raspberry Pi）上来提高打印质量和速度。 MarlinMarlin 是目前最流行的3D打印机固件之一，支持广泛的硬件平台和3D打印机模型，具有丰富的功能和高度的可定制性。 控制软件fluiddFluidd 是一个基于网页的控制界面，用于管理和监控运行 Klipper 固件的3D打印机。它提供了用户友好的界面和实时监控功能。GitHub地址: https://github.com/fluidd-core/fluidd安装手册: https://github.com/dw-0/kiauh Make-meMake-me 是一个通过 WiFi 控制 Replicator 2 打印机的开源项目，使用 GitHub 的聊天机器人 Hubot 来监控和完成打印任务。目前只支持 Mac 的 OS X。 Pepeteir-ServerPepeteir-Server 是一个新型的 Repeteir 产品，可以在 Raspberry Pi 上运行，支持控制多台打印机，内存消耗极小。它的网页操作界面简单，但不支持 Mac 和 PC。 OctoprintOctoprint 是一个完全基于网页的3D打印机控制程序，可以远程控制打印机，并通过网络摄像头监控打印过程。支持 Raspberry Pi。 BotqueueBotqueue 是一个开源的远程打印机控制软件，可以控制多台打印机。用户上传 .stl 文件后，软件会完成切片和打印工作。它支持为每台打印机设置独立的切片特性。 切片软件切片软件用于将3D模型按层切片，并生成用于打印的G代码。 CuraCura 由 Ultimaker 开发，兼容多种3D打印机。它不仅可以切片，还提供3D打印机控制界面，尤其适用于 Ultimaker 的3D打印机。 Slic3rSlic3r 是开源且免费的切片软件，因其快捷性和高度可定制化而广受欢迎。许多3D打印机制造商提供默认的 Slic3r 配置文件（.INI 文件），可以用作初始设置。 Skeinforge另一款非常流行的切片软件。同样开源，免费。 kisslicerKISSlicer 是一款跨平台的切片软件，名称源自 “Keep It Simple”（保持简单），目标是提供一个简单易用的界面。 PrintrunPrintrun 既是控制软件，也是切片软件，可以独立完成从切片到打印的整个过程。支持 Mac、Linux 和 PC 操作平台。 Repetier-HostRepetier-Host 与 Printrun 类似，是一款综合性软件，具有切片、零件定位和机器控制功能。用户界面相对更复杂但更直观，同样支持 Mac、Linux 和 PC 操作平台。 3D建模软件BlenderBlender 是一款开源的3D建模软件，功能强大且完全免费。它不仅可以用于3D建模，还支持动画、渲染、雕刻等多种功能，适用于各种复杂的3D设计和制作。 TinkercadTinkercad 是一个由 Autodesk 开发的在线3D建模工具，适合初学者使用。它基于浏览器，无需下载软件，界面友好且易于使用。 Fusion 360Fusion 360 同样由 Autodesk 开发，是一款功能强大的云端3D CAD、CAM和CAE工具。它适用于从初学者到专业人士的各个层级，提供了全面的建模、仿真和制造功能。 SketchUpSketchUp 是一款广受欢迎的3D建模软件，以其直观的用户界面和易用性著称。它有免费版本（SketchUp Free）和专业版本（SketchUp Pro），适用于建筑、工程、游戏开发等多个领域。 FreeCADFreeCAD 是一款开源的3D CAD建模软件，适合于产品设计、机械工程以及建筑设计。它具有模块化的架构，可以通过插件扩展其功能。 SolidWorksSolidWorks 是一款由 Dassault Systèmes 开发的专业3D CAD软件，广泛应用于工程设计、产品设计和制造业。它功能强大，但价格较高，通常用于工业级应用。 OnshapeOnshape 是一个基于云的3D CAD建模软件，适用于团队协作和设计项目。它无需安装，直接在浏览器中运行，支持实时协作和版本控制。 OpenSCADOpenSCAD 是一款开源的3D CAD建模软件，适用于创建精确的3D模型。它使用编程语言来定义模型，适合那些有编程经验的用户。","categories":["其他","3D打印机"]},{"title":"Python","path":"/2024/05/21/语言-Python-Python/","content":"源码安装打开终端，使用以下命令更新软件包列表： 1sudo apt update 安装编译 Python 3.10 所需的依赖项： 1sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： 1wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码并进入解压后的目录： 12tar -xf Python-3.10.0.tgzcd Python-3.10.0 配置 Python 3.10 的编译选项： 1./configure --enable-optimizations 编译并安装 Python 3.10： 12make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： 1python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。","categories":["语言","Python"]},{"title":"pip下载网络问题","path":"/2024/05/21/语言-Python-pip下载网络问题/","content":"临时使用 可以在使用pip的时候加参数-i https://pypi.tuna.tsinghua.edu.cn/simple 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple gevent 这样就会从清华这边的镜像去安装gevent库。 永久修改 Linux下~/.pip/pip.conf Windows下C:\\Users\\admin\\pip\\pip.ini内容如下：12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple","categories":["语言","Python"]},{"title":"Linux下的CH34x串口识别","path":"/2024/05/21/通讯协议-串口-Linux下的CH34x串口识别/","content":"判断是否识别使用lsusb命令可以看到有Bus 001 Device 005: ID 1a86:7523 QinHeng Electronics CH340 serial converter是能识别出ch34x设备 检查串口是否被驱动加载输入指令ls /dev/ttyUSB*将会列出USB的加载情况。如果提示No such file or directory则是没有被驱动加载。 占用情况因报文件不存在错误，采用dmesg|grep tty命令检查发现，被brltty进程占用。 brltty是一个后台进程（守护进程），为盲人提供对Linux&#x2F;Unix控制台的访问（当处于文本模式时），使用可刷新盲文显示。移除该apt remove brltty。 权限chmod a+rw /dev/ttyUSB0即可 重装驱动下载最新的驱动CH341SER_LINUXhttps://github.com/WCHSoftGroup/ch341ser_linux 解压后进入”driver”目录下 输入make命令编译驱动，正常编译完成后，将会看到生成了ch341.ko模块 输入sudo make load 或者 sudo insmod ch341.ko动态加载驱动（重启需要再次加载），或者输入 sudo make install 安装驱动（重启不丢失） 输入sudo make unload 或者 sudo rmmod ch341.ko 或者sudo make uninstall 卸载驱动 *如果编译失败，可能是ch34x.c和实际内核版本不匹配，uname -r 可查看操作系统的发行版号，之后在 https://elixir.bootlin.com/linux/latest/source 中查找对应内核版本的源代码文件，一般位于/drivers/usb/serial/ch341.c，替换后重新编译 *如果insmod失败，查看/lib/modules/$(uname -r)/kernel/drivers/usb/serial目录下是否已经有了ko模块，将目录中生成ko文件复制到此处，使用lsmod查看模块","categories":["通讯协议","串口"]},{"title":"Linux自启动脚本","path":"/2024/05/21/操作系统-Linux-Linux自启动脚本/","content":"Adding as a startup service (recommended)Create a service file in /etc/systemd/system/my_startup.service: 1234567891011[Unit]Description=myStartUp ServiceAfter=network-online.target[Service]ExecStart=/start/bash/path Restart=alwaysRestartSec=3[Install]WantedBy=default.target Then start the service: 12sudo systemctl daemon-reloadsudo systemctl enable my_startup","categories":["操作系统","Linux"]},{"title":"CAN和CANFD","path":"/2024/05/20/通讯协议-CAN-CAN和CANFD/","content":"CAN和CANFDCAN与CAN-FD主要区别： 传输速率不同 CAN：最大传输速率1Mbps。 CAN-FD：速率可变，仲裁比特率最高1Mbps（与CAN相同），数据比特率最高8Mbps。 数据长度不同 CAN：一帧数据最长8字节 CAN-FD：一帧数据最长64字节。 帧格式不同和ID长度不同。 CANFD不存在远程帧，CAN报文中的RTR（用于区别标准帧与远程帧）被替换为RRS（远程请求替代位，默认值为0） CANFD报文的标准帧和扩展帧—IDE为1表示为扩展帧、为0表示标准帧 FDF用于传统CAN报文和CANFD报文，FDF位为0时为传统报文，FDF为1时为CANFD报文 BRS位速率切换为，BRS位为0时CANFD速率保持恒定速率、BRS位为1时CANFD的数据段会被切换到高速率。 ESI错误状态指示位：CAN报文中发送节点的错误状态只有该节点自己知道，CANFD报文中可以通过ESI标志位来告诉其他节点该节点的错误状态，当ESI为1时表示发送节点处于被动错误状态、当ESI为0时表示发送节点处于主动错误状态 CRC：随着数据场的扩大，为了保证信息发送的质量，CAN FD的CRC计算不仅要包括数据段的位，还包括来自SOF的Stuff Count和填充位。通过比较CRC的计算结果，可以判断接收节点是否能够正常接收。在CAN中，CRC的位数是15位，而在CAN FD中，CRC场扩展到了21位。当传输报文为15字节时：CRC 15位当传输数据为16字节或更少时：CRC 17位当传输数据超过16字节时：CRC 21位","categories":["通讯协议","CAN"]},{"title":"CANopen","path":"/2024/05/20/通讯协议-CAN-CANopen/","content":"CANopenCANopen是一种基于CAN（Controller Area Network）通信协议的高层协议和设备协议，主要用于嵌入式系统中的网络通信。 CANopen协议定义了网络管理、设备配置、通信对象和应用对象等方面的标准，以确保不同设备之间的互操作性和通信的一致性。 CANopen的OSI模型Data link和Physical是由CAN进行实现的Presentation和Session是由CANopen进行实现的 核心概念通讯模式*设备&#x2F;节点通信有3种模型：主设备&#x2F;从设备、客户端&#x2F;服务器和生产者&#x2F;消费者 通讯协议*协议用于通信，例如配置节点（SDO）或传输实时数据（PDO）定义了设备之间通信的机制和方式，包括对象字典、服务数据对象（SDO）、过程数据对象（PDO）、网络管理（NMT）等。 设备状态*设备支持不同的状态。“主”节点可以更改“从”节点的状态，例如将其重置。 对象字典（Object Dictionary，OD）*每个CANopen设备都有一个对象字典，OD带有指定设备配置的条目，类似于一个查找表，列出了设备中的所有参数和数据。对象字典包括通信对象和应用对象，使用16位索引和8位子索引进行标识。可以通过SDO访问。 EDS（Electronic Data Sheet）*EDS是用于OD的标准文件格式，允许更新设备的服务 设备配置文件*定义了特定设备类型的功能和行为，例如I&#x2F;O模块、传感器、执行器等。这些配置文件确保了同类型设备的互操作性。 通信对象CANopen协议定义了几种不同类型的通信对象，每种对象都用于特定的通信目的： 过程数据对象（PDO）：用于实时数据传输，具有高优先级和低延迟。PDO传输的数据量小，但传输速度快，适用于传感器数据和控制命令等实时性要求高的场景。 服务数据对象（SDO）：用于非实时数据传输，如配置参数和大数据块的传输。SDO传输的灵活性更大，但优先级较低，适用于设备配置和诊断等场景。 网络管理对象（NMT）：用于控制设备状态和网络操作模式，如启动、停止和复位设备。 同步对象（SYNC）：用于网络同步，确保所有节点在同一时间点进行操作。 时间戳对象（TIME）：提供时间参考，用于时间相关的操作。 11位的CAN ID称为通信对象标识符（COB-ID），分为两个部分：默认情况下，前4位等于功能代码，后7位包含节点ID。CANopen网络中使用的标识符的预定义分配 CANopen配置所有CANopen节点必须具有对象字典（OD），对象字典是指含有描述的CANopen节点的行为的所有参数的标准化结构。 通过16位索引和8位子索引查找OD条目。例如，符合CANopen的节点OD的索引1008（子索引0）包含节点设备名。 具体来说，对象字典中的条目由属性定义： 索引：对象的16位基址 对象名称：制造商设备名称 目标代码：数组，变量或记录 数据类型：例如VISIBLE_STRING或UNSIGNED32或记录名称 访问： rw（读&#x2F;写），ro（只读），wo（只写） 类别：指示此参数是否为必需&#x2F;可选（M &#x2F; O） OD标准化部分设备（例如从设备）的OD条目可以由其他设备（例如主机）使用SDO通过CAN进行访问。例如，通过SDO可以使应用程序主机更改从属发送心跳的频率。 对象字典分为标准化部分，其中一些条目是必填项，而其他条目则是完全可定制的。要了解OD，查看电子数据表和设备配置文件会很有帮助。 电子数据表（EDS）实际上，将使用适当的软件工具来配置&#x2F;管理复杂的CANopen网络。 为了简化此过程，CiA 306标准定义了一种人类可读（且对机器友好）的INI文件格式，用作设备OD（例如“ ServoMotor3000”）的“模板”。此EDS通常由供应商提供的，并且包含信息的所有设备的对象（但不是值）。 设备配置文件（DCF）DCF通常是在设备集成时创建的。但是，通常需要在初始配置后读取和&#x2F;或更改节点的对象值。 假设一家工厂购买了ServoMotor3000集成到其传送带中。为此，操作员编辑设备EDS并添加特定的参数值和&#x2F;或更改EDS中描述的每个对象的名称。 这样做，操作员可以有效地创建所谓的设备配置文件（DCF）。有了这个，ServoMotor3000就可以现场集成到特定的CANopen网络中。 EDS和DCF示例EDS &#x2F; DCF示例是真正了解CANopen对象字典的最佳方法，例如，请参见下面的EDS和DCF对象条目之间的区别。我们建议您查看CiA 306标准，以通过实际示例更深入地了解OD，EDS和DCF。 服务类型下面我们简要概述了上述7种服务类型，包括如何利用8个CAN帧数据字节。 网络管理（NMT）NMT服务用于通过NMT命令来控制CANopen设备的状态。 为了更改状态，NMT主设备发送2字节的消息，其CAN ID为0（即功能代码0和节点ID 0）。所有从节点都处理此消息。 第一个CAN数据字节Requested State包含请求的状态*命令包括转换到操作（状态01），停止（状态02），操作前（状态80）以及复位应用程序（81）和复位通信（82）。 第二个CAN数据字节包含目标节点的节点ID。节点ID 0表示广播命令。 同步（SYNC）SYNC消息通常由应用程序主机触发。 应用程序主机将SYNC消息（COB ID 080）发送到CANopen网络。 紧急情况（EMCY）紧急服务用于设备发生致命错误（例如传感器故障）的情况，从而使其可以向网络的其余部分指示此错误。 受影响的节点以高优先级向网络发送单个EMCY消息*例如，节点5具有COB-ID 085 数据字节包含有关错误的信息，可以查找有关详细信息。 时间戳（TIME）[PDO]利用该通信服务，可以分配全球网络时间。TIME服务包含一个6字节的日期和时间信息。 主机发出带有CAN ID 100的TIME消息，其中最初的4个数据字节包含午夜之后的毫秒数，随后的2个字节包含自1984年1月1日以来的天数。 过程数据对象[PDO]PDO服务用于在设备之间传输实时数据，例如来自压力传感器的压力数据或来自温度传感器的温度数据。PDO承载大量信息，被视为最重要的CANopen协议。*原则上可以使用SDO服务。但是单个SDO响应只能携带4个数据字节（需要包含命令字节和OD地址）。假设一个主节点需要来自节点5的两个参数值（例如“ SensTemp2”和“ Torque5”），要通过SDO获得此值，它将需要4个完整的CAN帧（2个请求，2个响应）。相比之下，PDO消息可以包含8个完整字节的数据-并且它可以在单个帧中包含多个对象参数值。因此，可能需要在PDO服务中用1帧完成SDO至少需要4帧的操作。 对于PDO，使用消费者&#x2F;生产者术语。因此，生产者“生产数据”，并使用传输PDO（TPDO）将其传输到“消费者”（主用户）。相反，它可以通过接收PDO（RPDO）从使用者接收数据。 生产者节点可以被配置为每100ms响应消费者所广播的SYNC触发。然后，节点5可以例如在下面广播，以COB-ID 185发送PDO： 注意数据字节是如何用3个参数值打包的。这些值反映了节点5特定OD条目的实时数据。使用此信息的节点（使用者）当然需要知道如何解释PDO数据字节。 服务数据对象[SDO]SDO服务用于访问&#x2F;更改CANopen设备的对象字典中的值-例如，当应用程序主机需要更改CANopen设备的某些配置时。 SDO服务允许的CANopen节点通过CAN网络读取另一个节点的对象字典&#x2F;编辑值。如“通信模型”中所述，SDO服务利用“客户端&#x2F;服务器”行为。 客户端节点可以通过在CAN帧以下广播来启动SDO下载到节点5，这将触发节点5（并被其他节点忽略）。SDO“接收”（即请求）CAN帧如下所示：SDO消息变量说明： COB-ID 605反映了“ SDO接收”（COB-ID 600 +节点ID）的使用。 所述CCS（客户端命令说明符）是传输类型（例如，1：下载，2：上载） n是数据字节4-7中不包含数据的#bytes （如果设置了e＆s则有效） 如果设置，e表示“快速传输”（所有数据在单个CAN帧中） 如果设置，s表示数据大小显示在n中 索引（16位）和子索引（8位）反映了要访问的OD地址 最后，字节4-7包含要下载到节点5的数据 *一旦主节点（客户端）发送了CAN帧，从节点5（服务器）便会通过“ SDO发送”进行响应，并带有COB-ID585。该响应包含索引&#x2F;子索引和4个空数据字节。自然地，如果客户端节点请求上传（即从节点5 OD读取数据），则节点5将以字节4-7中包含的相关数据进行响应。 每个SDO使用2个标识符，创建一个“ SDO渠道（包含命令字节和OD地址）”，数据包含在4个字节中，对于较大的数据方案，可以使用SDO 分段&#x2F;块传输。 SDO灵活，但会带来大量输出，使其不适用于实时操作数据。 节点监视[SDO]心跳服务有两个目的：提供“活动”消息并确认NMT命令。 NMT从设备会定期（例如，每100毫秒）发送心跳消息（例如，节点5的CAN ID 705），并在第一个数据字节中发送节点的“状态” 如果在一定时间内没有收到消息，则心跳消息的“消费者”（例如NMT主设备和可选的任何其他设备）会做出反应。","categories":["通讯协议","CAN"]},{"title":"USB权限设置","path":"/2024/05/20/通讯协议-USB-USB权限设置/","content":"因Linux系统下将涉及到usb底层驱动的调用，运行时，一定要加sudo获取权限运行，否则USB设备没有权限操作。现通过创建UDEV规则，配置USB权限后，可以调用指定设备不加权限运行。 输入lsusb，查看当前的USB设备的ID，确定需要配置的USB。 创建一个新的udev规则。名称取为：99-myusb.rulessudo vi /etc/udev/rules.d/99-myusb.rules 在99-myusb.rules文件中，输入以下内容 12##ACTION==&quot;add&quot;,SUBSYSTEMS==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;04d8&quot;, ATTRS&#123;idProduct&#125;==&quot;0053&quot;, GROUP=&quot;users&quot;, MODE=&quot;0777&quot; *这条udev规则的作用是，当供应商ID为04d8且产品ID为0053的USB设备插入系统时，将该设备的用户组设置为users，并赋予所有用户读、写、执行的全部权限。 插拔一下USBCAN设备或重启一下电脑后，即可不加sudo权限运行程序了 对某个特定USB设备设置权限。每当这个设备插入系统时，规则会自动应用。 ACTION==&quot;add&quot;：这表示规则在设备添加（插入）时生效。udev可以根据不同的动作（如添加、移除等）触发规则，add动作指设备插入时。 SUBSYSTEMS==&quot;usb&quot;：表示规则适用于USB子系统的设备。udev管理系统中的设备，子系统用于分类，USB是其中一种。 ATTRS&#123;idVendor&#125;==&quot;04d8&quot;：表示设备的供应商ID（Vendor ID）为04d8。每个USB设备都有唯一的供应商ID，用于标识设备的制造商。 ATTRS&#123;idProduct&#125;==&quot;0053&quot;：表示设备的产品ID（Product ID）为0053。每个供应商的不同产品有不同的产品ID，用于区分供应商的各个设备。 GROUP=&quot;users&quot;：表示设备的用户组被设置为users。这决定了哪些用户组的成员有权访问该设备。 MODE=&quot;0777&quot;：表示设备的权限模式被设置为0777，即所有用户对该设备都有读、写、执行权限。","categories":["通讯协议","USB"]},{"title":"Socket套接字","path":"/2024/05/20/通讯协议-网络-Socket套接字/","content":"Socket最初是作为网络上不同主机之间进程的通信接口，后来应用越来越广，在同一主机上的不同进程之间通信也可以用Socket。 简单来说，当网络上不同主机之间的两个进程（A、B）采用Socket进行通信时，那么它们之间需要建立一个通信端点，即创建Socket，创建Socket时就分配端口号和网络地址。当进程A向进程B发送数据时，那么进程A必须要知道进程B的网络地址及端口号。 Socket采用C&#x2F;S模型进行设计的，即Client&#x2F;Server，面向客户端—服务器模型。 每一个Socket都用一个半相关描述：{协议，本地地址，本地端口}一个完整的Socket则用一个相关描述:{协议，本地地址，本地端口，远程地址，远程端口} 类型字节流套接字（SOCK_STREAM）字节流的套接字可以提供可靠的数据传输、面向连接的通讯流。数据按何种顺序发送，就按何种顺序接收。例如，当我们按顺序发送A-B-C，那么在数据到达接收端时，它的顺序也是A-B-C。字节流套接字采用的是TCP（Transmission Control Protocol）协议。保证了数据传输的可靠性。 数据报套接字（SOCK_DGRAM）数据报套接字定义了一种无连接的服务。所谓无连接服务，简单来说，即在发送数据时，无需在收发两端建立类似TCP那样的握手连接，在发送时，将数据打包，然后加上远程IP地址，即可把该数据包发送出去。数据通过相互独立的报文进行传输。并且是无序的、不可靠的传输。 原始套接字（SOCK_ROW）先启动服务器，通过调用socket()函数建立一个套接字，然后调用bind()函数将该套接字和本地网络地址联系在一起，再调用listen()函数使套接字做好侦听的准备，并规定它的请求队列的长度，之后就调用accept()函数来接收连接。 客户端在建立套接字之后就可调用 connect()和服务器建立连接。 连接一旦建立，客户端和服务器之间就可以通过调用recv()&#x2F;recvfrom()函数和send()&#x2F;sendto函数来进行发收数据。 最后，待数据传送结束后，双方调用close()函数关闭套接字。","categories":["通讯协议","网络"]},{"title":"CAN协议介绍","path":"/2024/05/17/通讯协议-CAN-CAN学习笔记/","content":"概述介绍CAN 总线是一种串行通信协议，使用的是两条差分信号线，只能表达一个信号。简洁的物理层决定了CAN必然要配上一套复杂的协议。根据不同的距离、不同的网络，可配置不同的速度，最高速度为1MBit&#x2F;s。CAN 2.0A为标准格式，CAN 2.0B为扩展格式。优点： 可以多主方式工作，网络上的任意节点均可以在任意时刻主动地向网络上的其他节点发送信息，而不分主从，通信方式灵活。 网络上的节点(信息)可分成不同的优先级，可以满足不同的实时要求。 采用非破坏性位仲裁总线结构机制，当两个节点同时向网络上传送信息时，优先级低的节点主动停止数据发送，而优先级高的节点可不受影响地继续传输数据。 工作原理当CAN 总线上的节点发送数据时，以报文形式广播给网络中的所有节点，总线上的所有节点都不使用节点地址等系统配置信息，只根据每组报文开头的11位标识符(CAN 2.0A规范)解释数据的含义来决定是否接收。这种数据收发方式称为面向内容的编址方案。当某个节点要向其他节点发送数据时，这个节点的处理器将要发送的数据和自己的标识符传送给该节点的CAN总线接口控制器，并处于准备状态；当收到总线分配时，转为发送报文状态。数据根据协议组织成一定的报文格式后发出，此时网络上的其他节点处于接收状态。处于接收状态的每个节点对接收到的报文进行检 测，判断这些报文是否是发给自己的以确定是否接收。 层次结构CAN被细分为三个层次：（1）CAN对象层（the object layer）；（2）CAN传输层（the transfer layer）；（3）CAN物理层（the phyical layer）；对象层和传输层包括所有由ISO&#x2F;OSI模型定义的数据链路层的服务和功能。对象层的作用范围包括：（1）查找被发送的报文。（2）确定由实际要使用的传输层接收哪一个报文。（3）为应用层相关硬件提供接口。传输层的作用主要：（1）传送规则，也就是控制帧结构、执行仲裁、错误检测、出错标定、故障界定。（2）总线上什么时候开始发送新报文及什么时候开始接收报文，均在传输层里确定。（3）位定时的一些普通功能也可以看作是传输层的一部分。（4）传输层的修改是受到限制的。物理层的作用：在不同节点之间根据所有的电气属性进行位信息的实际传输。当然，同一网络内，物理层对于所有的节点必须是相同的。 编程在对象层进行，这一层直接与应用层交互，并且提供了管理和处理CAN消息的接口。通过对象层，应用程序可以发送和接收CAN的打包消息。打包的过程就是在原始数据的基础上再加上帧起始段、仲裁段、控制段、CRC校验、应答和帧结束，把这些内容按特定的格式打包好，就可以用一个通道表达各种信号了，当数据包被发送时，只要接收方按约定格式去解读，就能还原出原始数据。 传输层的功能主要由CAN控制器硬件和驱动程序实现。通常，程序员不直接操作传输层，而是通过对象层的API间接利用传输层的功能。传输层负责处理CAN协议的低级细节，如位级传输、错误处理和仲裁。*位填充（BitStuffing）位填充是为了防止突发错误而设定的功能。位填充的规则如下：（1）5位连续相同电平之后，必须填充一位反向位，即不允许有6个连续相同位；（2）SOF之前为总线空闲状态，不需要同步，因此不需要位填充；（3）CRC之后为固定格式，不允许填充；（4）由CAN控制器自动实现； 物理层通常由CAN收发器硬件和相关电气接口组成。 CAN属性CAN具有以下的属性：（1）报文（Messages）：CAN协议对数据、操作命令(如读&#x2F;写)以及同步信号进行打包，打包后的这些内容称为报文，简单来说就是具有固定格式的数据包。（2）信息路由（Information Routing）：即，报文寻找结点的方式。（3）位速率（Bit rate）：数据位的传输速度。（4）优先权（Priorities）：即报文发送的优先权。（5）远程数据请求（Remote Data Request）：通过发送远程帧，需要数据的节点可以请求另一节点发送相应的数据帧。（6）多主机（Multimaster）：总线空闲时，任何结点都可以开始传送报文。（7）仲裁（Arbitration）：当2个及以上的单元同时开始传送报文，那么就会有总线访问冲突。仲裁是确定哪个单元的具有发送优先权。（8）安全性（Safety）：CAN的每一个节点均采取了强有力的措施以进行错误检测、错误标定及错误自检。（9）错误检测（Error Detection）：包括监视、循环冗余检查、位填充、报文格式检查。（10）错误检测的执行（Performance of Error Detection）（11）错误标定和恢复时间（Error Sinalling and Recovery Time）：任何检测到错误的结点会标志出已损坏的报文。此报文会失效并将自动地开始重新传送。如果不再出现新的错误，从检测到错误到下一报文的传送开始为止，恢复时间最多为29个位的时间。（12）故障界定（Fault Confinement）：CAN结点能够把永久故障和短暂扰动区分开来。永久故障的结点会被关闭。（13）连接（Connections）：CAN串行通讯链路是可以连接许多结点的总线。理论上，可连接无数多的结点。但由于实际上受延迟时间或者总线线路上电气负载的影响，连接结点的数量是有限的。（14）单通道（Single Channel）：总线是由单一进行双向位信号传送的通道组成。（15）总线值（Bus value）：总线可以具有两种互补的逻辑值之一：“显性”（可表示为逻辑0）或“隐性”（可表示为逻辑1）。（16）应答（Acknowledgment）：所有的接收器检查报文的连贯性。对于连贯的报文，接收器应答；对于不连贯的报文，接收器作出标志。（17） 睡眠模式／唤醒（Sleep Mode &#x2F; Wake-up）：为了减少系统电源的功率消耗，可以将CAN器件设为睡眠模式以便停止内部活动及断开与总线驱动器的连接。CAN器件可由总线激活，或系统内部状态而被唤醒。 仲裁方式在总线空闲态，最先开始发送消息的单元获得发送权。多个单元同时开始发送时，各发送单元从仲裁段的第一位开始进行仲裁。连续输出显性电平最多的单元可继续发送。即逐位地对比 各个结点发出的报文ID。 由于线与的关系，显示位“0”可以覆盖隐性位“1”，因此ID最小的节点赢得仲裁，总线上表现为该结点的报文，其他结点失去仲裁，退出发送，转为接收状态。 *标准格式ID与具有相同ID的远程帧或者扩展格式的数据帧在总线上竞争时，标准格式的RTR位为显性位的具有优先权，可继续发送。 数据帧帧类型为了更有效地控制通讯，CAN一共规定了5种类型的帧 数据帧：发送单元向接收单元传送数据的帧。 远程帧：接收单元向发送单元请求数据的帧。 错误帧：检测出错误时向其它单元通知错误的帧。 过载帧：接收单元通知其尚未就绪的帧。 间隔帧：将数据帧及遥控帧与前面的帧分离开来的帧。 *数据帧和遥控帧有标准帧和扩展帧两种帧，标准帧有 11 个位的标识符ID，扩展帧有 29 个位的 ID 标准CAN帧定义数据帧由帧起始、仲裁段、控制段、数据段、CRC、ACK、帧结束共7个段构成 隐形=1显性=0 帧起始(Start Of Frame,SOF)，1bit表示帧开始的段，设置为0。 仲裁段（Identifier，ID），11bits&#x2F;29bits表示数据帧优先级的段标准帧与扩展帧的构成有所不同，均禁止高7位为隐性(ID&#x3D;1111111XXXX…)仲裁段的内容主要为本数据帧的ID，标准帧的ID 有11 个位，扩展帧的 ID 有29 个位，在CAN协议中，ID决定着数据帧发送的优先级，也决定着其它节点是否会接收这个数据帧。CAN总线不对挂载在它之上的节点分配优先级和地址，对总线的占有权是由信息的ID决定的，即对于重要的信息，优先级高的ID，能够优先发送出去 RTR位(Remote Transmission Request Bit)远程传输请求位，用于区分数据帧和遥控帧的，为0表示数据帧，1表示遥控帧。 控制段控制段由 6 个位构成，表示数据段的字节数 IDE位(Identifier Extension Bit)标识符扩展位，用于区分标准帧与扩展帧，为0表示标准帧，1表示扩展帧 SRR位(Substitute Remote Request Bit)只存在于扩展帧，它用于替代标准帧中的RTR位，扩展帧中的SRR位固定为1，RTR在数据帧中为0，所以两个ID相同的标准帧与扩展帧，标准帧的优先级较高 DLC数据长度码（Data Length Code）数据的字节数必须为 0～8 字节 数据段（Data Field）数据段可包含 0～8 个字节的数据 CRC段 CRC 段是检查帧传输错误的段，由15 个位的CRC值和1 个位的CRC界定符(隐性分隔位)构成 CRC是根据多项式生成的CRC值，CRC的计算范围包括帧起始、仲裁段、控制段、数据段 接收方以同样的方式计算CRC值并进行比较，不一致时利用错误帧请求重新发送 ACK段ACK段包括ACK槽位、ACK界定符位2个位发送单元的ACK 段：发送单元在 ACK 段发送2 个位的隐性位接收单元的ACK 段：接收到正确消息的单元在ACK 槽发送显性位，通知发送单元正常接收结束，这称作“发送ACK”或者“返回ACK” 帧结束(End Of Frame，EOF)帧结束是表示该帧结束的段，由发送节点发送 7 个位的隐性位构成*CAN数据帧的结束符长度并不是完全不定的，而是根据数据位速率（Data Bit Rate，DBR）而定。CAN总线协议规定，对于数据位速率低于等于125kbps的网络，CAN数据帧的结束符长度为7个位；对于数据位速率大于125kbps的网络，CAN数据帧的结束符长度为3个位。这是因为在高速网络中，由于数据传输速率更快，所以CAN控制器可以更快地检测到结束位，因此可以减少结束符的长度，从而提高网络的传输效率。而在低速网络中，由于数据传输速率较慢，所以CAN控制器需要更长的时间来检测结束位，因此需要一个更长的结束符来确保数据帧传输的正确性和完整性。因此，CAN数据帧的结束符长度是根据数据位速率而定的，并不是完全不定的。 Linux下的Socket CAN帧定义 帧头，canid_t定义了一个无符号的32位整形数，按位确定功能 *0-28位为标识符，如果是扩展帧，则高11位为标准ID 29位标识是数据帧还是错误消息 30位说明是否是远程帧 31位说明是标准帧还是扩展帧。 帧长，8位无符号表示数据区长度 数据区，定义CAN_MAX_DLEN个8位无符号数，按照数组的形式申请*__attribute__((aligned(8))) 告诉编译器，将变量 data 放在一个地址是 8 的倍数的内存位置上。1234567891011121314151617181920/* CAN payload length and DLC definitions according to ISO 11898-1 */#define CAN_MAX_DLC 8#define CAN_MAX_DLEN 8struct can_frame &#123; canid_t can_id; /* 32 bit CAN_ID + EFF/RTR/ERR flags */ __u8 can_dlc; /* frame payload length in byte */ __u8 data[CAN_MAX_DLEN] __attribute__((aligned(8)));&#125;;/** Controller Area Network Identifier structure** bit 0-28 : CAN identifier (11/29 bit)* bit 29 : error message frame flag (0 = data frame, 1 = error message)* bit 30 : remote transmission request flag (1 = rtr frame)* bit 31 : frame format flag (0 = standard 11 bit, 1 = extended 29 bit)*/typedef __u32 canid_t;typedef unsigned char __u8; Linux处理can_frame时用到的掩码和标识符： 123456789/* special address description flags for the CAN_ID */#define CAN_EFF_FLAG 0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG 0x40000000U /* remote transmission request */#define CAN_ERR_FLAG 0x20000000U /* error message frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK 0x000007FFU /* standard frame format (SFF) */#define CAN_EFF_MASK 0x1FFFFFFFU /* extended frame format (EFF) */#define CAN_ERR_MASK 0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 实际对can_frame的处理是在mcp251x_hw_tx&#x2F;mcp251x_hw_rx_frame中进行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static void mcp251x_hw_tx(struct spi_device *spi, struct can_frame *frame,int tx_buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);u32 sid, eid, exide, rtr;u8 buf[SPI_TRANSFER_BUF_LEN];//取can_id的31位，判断是标准帧还是扩展帧exide = (frame-&gt;can_id &amp; CAN_EFF_FLAG) ? 1 : 0; if (exide)//如果是扩展帧，can_id的0-28位为ID，其中高11位为标准IDsid = (frame-&gt;can_id &amp; CAN_EFF_MASK) &gt;&gt; 18;elsesid = frame-&gt;can_id &amp; CAN_SFF_MASK; /* Standard ID */eid = frame-&gt;can_id &amp; CAN_EFF_MASK; /* Extended ID */rtr = (frame-&gt;can_id &amp; CAN_RTR_FLAG) ? 1 : 0; /* 是否是远程帧*/buf[TXBCTRL_OFF] = INSTRUCTION_LOAD_TXB(tx_buf_idx); //发送缓冲器控制寄存器地址buf[TXBSIDH_OFF] = sid &gt;&gt; SIDH_SHIFT; //发送缓冲器标准ID高8位//5-7位存放发送缓冲器低3位,3位存放帧格式，0-1位存放扩展标识符低18位的高两位（16-17）buf[TXBSIDL_OFF] = ((sid &amp; SIDL_SID_MASK) &lt;&lt; SIDL_SID_SHIFT) | (exide &lt;&lt;SIDL_EXIDE_SHIFT) | ((eid &gt;&gt; SIDL_EID_SHIFT) &amp; SIDL_EID_MASK);buf[TXBEID8_OFF] = GET_BYTE(eid, 1); //存放扩展标识符低18位的8-15位buf[TXBEID0_OFF] = GET_BYTE(eid, 0); //扩展标识符低18位的低8位（0-7）buf[TXBDLC_OFF] = (rtr &lt;&lt; DLC_RTR_SHIFT) | frame-&gt;can_dlc; //6位存放远程帧标识符，0-3存放数据长度码memcpy(buf + TXBDAT_OFF, frame-&gt;data, frame-&gt;can_dlc);//拷贝要发送的数据mcp251x_hw_tx_frame(spi, buf, frame-&gt;can_dlc, tx_buf_idx);/* use INSTRUCTION_RTS, to avoid &quot;repeated frame problem&quot; */priv-&gt;spi_tx_buf[0] = INSTRUCTION_RTS(1 &lt;&lt; tx_buf_idx);mcp251x_spi_trans(priv-&gt;spi, 1);&#125;static void mcp251x_hw_rx_frame(struct spi_device *spi, u8 *buf,int buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);if (mcp251x_is_2510(spi)) &#123;int i, len;for (i = 1; i &lt; RXBDAT_OFF; i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);\tlen = get_can_dlc(buf[RXBDLC_OFF] &amp; RXBDLC_LEN_MASK);\tfor (; i &lt; (RXBDAT_OFF + len); i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);&#125; else &#123;\tpriv-&gt;spi_tx_buf[RXBCTRL_OFF] = INSTRUCTION_READ_RXB(buf_idx);\tmcp251x_spi_trans(spi, SPI_TRANSFER_BUF_LEN);\tmemcpy(buf, priv-&gt;spi_rx_buf, SPI_TRANSFER_BUF_LEN);&#125;&#125; Linux CAN 功能分析一个标准的CAN功能包括： CAN接口号指定CAN接口号can0 指定CAN通讯波特率，单位Kbps，默认为 500 Kbps 指定CAN发送帧ID 指定CAN发送帧数据*需要包含数据的大小端模式转换 指定CAN帧发送间隔，单位ms， 默认为250ms, 最小值为1ms 指定CAN帧发送次数 指定CAN发送帧为标准帧&#x2F;扩展帧 发送数据时错误判断，本地环回功能基于LINUX SOCKET机制实现的CAN接口，其基本的流程如下所示： 设置套接字socket 指定CAN设备ioctl 绑定套接字与设备bind 设置过滤规则setsockopt 发送&#x2F;接受报文read/write 关闭套接字close以下介绍各部分如何实现。 Linux应用层SocketCAN实例初始化SocketCAN 中大部分的数据结构和函数在头文件 linux&#x2F;can.h 中进行了定义。 CAN 总线套接字的创建采用标准的网络套接字操作来完成。网络套接字在头文件 sys&#x2F;socket.h 中定义。 套接字的初始化方法如下： 123456789int s;struct sockaddr_can addr;struct ifreq ifr;s = socket(PF_CAN, SOCK_RAW, CAN_RAW);//创建SocketCAN 套接字strcpy(ifr.ifr_name, &quot;can0&quot;);ioctl(s, SIOCGIFINDEX, &amp;ifr);//指定 can0 设备addr.can_family = AF_CAN;addr.can_ifindex = ifr.ifr_ifindex;bind(s, (structsockaddr *)&amp;addr,sizeof(addr)); //将套接字与 can0 绑定 数据发送在数据收发的内容方面， CAN 总线与标准套接字通信稍有不同，每一次通信都采用 can_ frame 结构体将数据封装成帧。 结构体定义如下： 12345structcan_frame &#123;canid_t can_id;//CAN 标识符__u8 can_dlc;//数据场的长度__u8 data[8];//数据&#125;; can_id 为帧的标识符， 如果发出的是标准帧， 就使用 can_id 的低 11 位； 如果为扩展帧， 就使用 0～ 28 位。 can_id 的第 29、 30、 31 位是帧的标志位，用来定义帧的类型，定义如下： 123#define CAN_EFF_FLAG 0x80000000U //扩展帧的标识#define CAN_RTR_FLAG 0x40000000U //远程帧的标识#define CAN_ERR_FLAG 0x20000000U //错误帧的标识，用于错误检查 数据发送使用 write 函数来实现。 如果发送的数据帧(标识符为 0x123)包含单个字节(0xAB)的数据，可采用如下方法进行发送： 123456789struct can_frame frame;//如果为扩展帧，那么frame.can_id = CAN_EFF_FLAG | 0x123;frame.can_id = 0x123;frame.can_dlc = 1; //数据长度为 1frame.data[0] = 0xAB; //数据内容为 0xABint nbytes = write(s, &amp;frame, sizeof(frame));//发送数据if(nbytes != sizeof(frame)) //如果 nbytes 不等于帧长度，就说明发送失败printf(&quot;Error !&quot;); 如果要发送远程帧(标识符为 0x123)，可采用如下方法进行发送： 123struct can_frame frame;frame.can_id = CAN_RTR_FLAG | 0x123;write(s, &amp;frame, sizeof(frame)); 数据接收数据接收使用 read 函数来完成，实现如下： 12struct can_frame frame;int nbytes = read(s, &amp;frame, sizeof(frame)); 套接字数据收发时常用的 send、 sendto、 sendmsg 以及对应的 recv 函数也都可以用于CAN总线数据的收发。 错误处理当帧接收后，可以通过判断 can_id 中的 CAN_ERR_FLAG 位来判断接收的帧是否为错误帧。 如果为错误帧，可以通过 can_id 的其他符号位来判断错误的具体原因。错误帧的符号位在头文件 linux&#x2F;can&#x2F;error.h 中定义。 过滤规则设置在数据接收时，系统可以根据预先设置的过滤规则，实现对报文的过滤。过滤规则使用 can_filter 结构体来实现，定义如下： 1234struct can_filter &#123;canid_t can_id;canid_t can_mask;&#125;; 过滤的规则为：接收到的数据帧的 can_id &amp; mask == can_id &amp; mask通过这条规则可以在系统中过滤掉所有不符合规则的报文，使得应用程序不需要对无关的报文进行处理。在 can_filter 结构的 can_id 中，符号位 CAN_INV_FILTER 在置位时可以实现 can_id 在执行过滤前的位反转。用户可以为每个打开的套接字设置多条独立的过滤规则，使用方法如下： 12345678structcan_filter rfilter[2];rfilter[0].can_id = 0x123;rfilter[0].can_mask = CAN_SFF_MASK;//#define CAN_SFF_MASK 0x000007FFUrfilter[1].can_id = 0x200;rfilter[1].can_mask = 0x700;//设置规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER,&amp;rfilter, sizeof(rfilter)); 在极端情况下，如果应用程序不需要接收报文，可以禁用过滤规则。这样的话，原始套接字就会忽略所有接收到的报文。在这种仅仅发送数据的应用中，可以在内核中省略接收队列，以此减少 CPU 资源的消耗。禁用方法如下： 1setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER, NULL, 0); //禁用过滤规则 通过错误掩码可以实现对错误帧的过滤， 例如： 12can_err_mask_t err_mask = (CAN_ERR_TX_TIMEOUT | CAN_ERR_BUSOFF );setsockopt(s, SOL_CAN_RAW,CAN_RAW_ERR_FILTER, err_mask,sizeof(err_mask)); 回环功能设置在默认情况下， 本地回环功能是开启的，可以使用下面的方法关闭回环&#x2F;开启功能： 12int loopback = 0; // 0 表示关闭, 1 表示开启( 默认)setsockopt(s, SOL_CAN_RAW, CAN_RAW_LOOPBACK,&amp;loopback, sizeof(loopback)); 在本地回环功能开启的情况下，所有的发送帧都会被回环到与 CAN 总线接口对应的套接字上。 默认情况下，发送 CAN 报文的套接字不想接收自己发送的报文，因此发送套接字上的回环功能是关闭的。可以在需要的时候改变这一默认行为： 12int ro = 1; // 0 表示关闭( 默认), 1 表示开启setsockopt(s, SOL_CAN_RAW, CAN_RAW_RECV_OWN_MSGS, &amp;ro, sizeof(ro)); 如何在ARM上实现CAN通讯硬件ARM需要有CAN控制器和CAN收发器CAN控制器（CAN Controller）是负责实现CAN协议的逻辑部分的组件CAN收发器（CAN Transceiver）是负责CAN总线电平信号和CAN控制器之间的电信号转换的组件CAN控制器示例： 内置于微控制器中的CAN模块（例如STM32系列微控制器的内置CAN控制器）。 独立的CAN控制器芯片（例如MCP2515）。CAN收发器示例： 常见的独立CAN收发器芯片（例如MCP2551、TJA1050等）。 先选择CAN控制器芯片，一般的PC和ARM都没有CAN控制器，一般是MCP2515和SJA1000，主要区别是MCP2515是SPI接口，SJA1000是I&#x2F;O接口。所以MCP2515占用资源少，5-6个管脚就可以控制，SJA1000占用的管脚就多。 软件需要支持CAN控制器驱动，控制CAN控制器发送CAN帧对于一般的CAN控制器，进行初始化时，最关键的是以下两步： 配置CAN的位时序； 配置CAN的消息报文； 内核Linux中有对CAN（Controller Area Network）总线的支持，主要通过SocketCAN子系统实现。内核编译时选择响应的支持芯片。 1234567891011$ make linux-menuconfigNetworking support ---&gt;CAN bus subsystem support ---&gt;--- CAN bus subsystem supportRaw CAN Protocol (raw access with CAN-ID filtering)Broadcast Manager CAN Protocol (with content filtering)CAN Device Drivers ---&gt;Virtual Local CAN Interface (vcan)Platform CAN drivers with Netlink support[*] CAN bit-timing calculationMicrochip 251x series SPI CAN Controller SocketCAN支持多种CAN控制器硬件，通过不同的内核驱动程序实现对具体硬件的支持。例如，以下是一些常见的CAN控制器驱动程序： sja1000：Philips&#x2F;NXP SJA1000 CAN控制器 mcp251x：Microchip MCP251x SPI CAN控制器系列（如MCP2515） flexcan：Freescale&#x2F;NXP FlexCAN模块这些驱动程序通常位于内核源代码树的drivers/net/can目录下。 CAN数据发送跟踪当我们在用户层通过socket进行CAN数据的发送时，需要进行以下操作： 创建一个套接字socket，采用AF_CAN协议。 将创建的套接字返回描述符sockfd，绑定到本地的地址。 通过sendto系统调用函数进行发送，sendto的系统调用会发送一帧数据报到指定的地址，在CAN协议调用之前把该地址移到内核空间和检查用户空间数据域是否可读。 在net/socket.c源文件中，在sendto的系统调用（sys_sendto）里，会调用到sock_sendmsg()函数，接下来调用__sock_sendmsg()函数。 再往下一步就是__sock_sendmsg_nosec函数。在__sock_sendmsg_nosec()函数中会返回一个sendmsg函数指针。 在/net/can/raw.c源文件中，将raw_sendmsg函数地址赋给sendmsg函数指针，即在函数__sock_sendmsg_nosec()中return sock-&gt;ops-&gt;sendmsg(iocb,sock, msg, size)，返回的函数指针将指向raw_sendmsg()函数。 在net/can/af_can.c源文件中，can_send函数负责CAN协议层的数据传输，即传输一帧CAN报文（可选本地回环）。参数skb指针指向套接字缓冲区和在数据段的CAN帧。loop参数是在本地CAN套接字上为监听者提供回环。 以下开始进行到CAN的底层驱动代码了，由于CAN驱动是编译进内核中，所以在系统启动时会注册CAN驱动。 注册CAN驱动过程中会初始化d_can_netdev_ops结构体变量。 在这个过程中，d_can_netdev_ops结构体变量定义了3个函数指针，其中(*ndo_start_xmit)函数指针指向d_can_start_xmit函数的入口地址。 在d_can_start_xmit()函数中，会调用d_can_write_msg_object()函数准备消息报文进行传输。 CAN数据接收跟踪对于网络设备，数据接收大体上采用中断+NAPI机制进行数据的接收。同样，我们现在的CAN模块也是采用同样的方式进行数据的接收。由于我们只针对CAN总线接收数据这条主线进行分析。因些，会忽略一些针对CAN协议的设置及初始化等相关代码。*NAPI（New API）是一种改进的网络数据接收机制，它通过减少中断处理的次数来提高性能。NAPI的基本思想是延迟数据包的处理，使得多个数据包可以一次性地在中断处理程序中进行处理，从而减少了中断的数量，提高了系统的处理效率。中断+NAPI机制的工作原理大致如下：当网络数据包到达时，网络接口卡会生成一个中断通知操作系统。中断服务程序会执行一些必要的处理，然后调用NAPI机制。NAPI机制会检查网络接口缓冲区中是否有足够的数据需要处理。如果有足够的数据，NAPI会立即开始处理这些数据，而不会再次触发中断。如果数据量不足，NAPI会退出，并要求在将来的某个时候再次调用。处理完数据后，系统可以选择性地决定是否重新启用中断服务程序。通过将数据包的处理延迟到一组数据包到达时再进行，中断+NAPI机制能够大大减少中断的数量，提高系统的处理效率，特别是在高负载情况下。 在初始化CAN设备时，我们需要给CAN设备分配NAPI功能。我们通过netif_napi_add()函数将CAN设备添加到NAPI机制列表中。 将CAN设备添加到NAPI机制列表中后，在中断处理函数d_can_isr中，我们通过napi_schedule()函数调度已经在NAPI机制列表中的d_can_poll()函数。该函数会通过轮询的方式接收数据。而根据NAPI机制，当中断产生后，会调度轮询机制同时关闭所有的中断。 当中断产生时，会调用函数d_can_poll()，该函数即采用轮询的方式进行数据的接收。由于CAN总线状态中断具有最高优先权，在接收数据之前，需要对CAN总线的状态进行判断。而对于CAN总线错误状态有三种：主动&#x2F;被动&#x2F;关闭。 当总线状态数据状态正常时，从CAN模块的接收寄存器中接收数据。 文件系统要在linux下面配置和测试CAN，需要安装以下三个组件。 iproute2 （配置CAN接口时需要） libsocketcan（使用CAN必须） can-utils https://github.com/linux-can/can-utils (CAN的测试小工具，linux下测试CAN比较好用应用程序) 可以直接通过命令行形式控制CAN 12345678910111213141516171819202122# 配置CAN接口（假设设备名为`can0`）：ip link set can0 up type can bitrate 500000# 启动CAN接口ip link set up can0# 查看CAN接口状态ip -details link show can0# CAN 2.0 linkupip link set can0 up type can bitrate 100000# CAN 2.0 FD linkupip link set can0 up type can bitrate 500000 dbitrate 2000000 fd on# 命令来配置 CAN 总线的位速率：ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1# 可以使用 ip 命令直接设定位速率500kbps：ip link set can0 type can bitrate 500000# 当设置完成后，可以通过下面的命令查询 can0 设备的参数设置：ip -details link show can0# 当设置完成后，可以使用下面的命令使能 can0 设备：ifconfig can0 up# 使用下面的命令取消 can0 设备使能：ifconfig can0 down# 在设备工作中，可以使用下面的命令来查询工作状态：ip -details -statistics link show can0 ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1*同步段（Sync Segment）: 固定为1 TQ，用于同步位定时器。传播时间段（Propagation Segment, prop-seg）: 用于补偿信号在总线上传播的时间延迟。相位缓冲段1（Phase Buffer Segment 1, phase-seg1）: 用于提高抗干扰能力，允许时间调整。相位缓冲段2（Phase Buffer Segment 2, phase-seg2）: 也用于提高抗干扰能力，允许时间调整。 *ip link set can0 type can: 设置名为 can0 的网络接口的类型为 CAN。tq 125: 设置时间量化（Time Quantum，TQ）为 125 ns。TQ 是CAN控制器内部的基本时间单位，用于划分整个位时间。prop-seg 6: 设置传播时间段（Propagation Segment）为 6 TQ。传播时间段用于补偿信号在CAN总线上传播的延迟。phase-seg1 7: 设置相位缓冲段1（Phase Buffer Segment 1）为 7 TQ。这个时间段用于调整边沿相位，通常包括采样点之前的时间。phase-seg2 2: 设置相位缓冲段2（Phase Buffer Segment 2）为 2 TQ。这个时间段用于调整边沿相位，通常包括采样点之后的时间。sjw 1: 设置同步跳跃宽度（Synchronization Jump Width，SJW）为 1 TQ。SJW 用于重新同步时可以跳跃的最大时间量。 *具体计算tq 125: 时间量化为125 ns。prop-seg 6: 传播时间段为 6 个时间量化，6 * 125 ns &#x3D; 750 ns。phase-seg1 7: 相位缓冲段1为 7 个时间量化，7 * 125 ns &#x3D; 875 ns。phase-seg2 2: 相位缓冲段2为 2 个时间量化，2 * 125 ns &#x3D; 250 ns。sjw 1: 同步跳跃宽度为 1 个时间量化，1 * 125 ns &#x3D; 125 ns。计算位时间总位时间是所有段的时间总和：Sync Segment: 1 TQPropagation Segment: 6 TQPhase Buffer Segment 1: 7 TQPhase Buffer Segment 2: 2 TQ总时间量化数 &#x3D; 1 + 6 + 7 + 2 &#x3D; 16 TQ总位时间 &#x3D; 16 * 125 ns &#x3D; 2000 ns &#x3D; 2 μs位速率（Bit Rate） &#x3D; 1 &#x2F; 总位时间 &#x3D; 1 &#x2F; 2 μs &#x3D; 500 kbps Qt中使用SocketCAN需要编译安装socketCAN插件， https://doc.qt.io/qt-5/qtserialbus-socketcan-overview.html ，关键字【Using SocketCAN Plugin】 pro文件中添加QT += serialbus 12345QString errorString;const QList&lt;QCanBusDeviceInfo&gt; devices = QCanBus::instance()-&gt;availableDevices(\tQStringLiteral(&quot;socketcan&quot;), &amp;errorString);if (!errorString.isEmpty())\tqDebug() &lt;&lt; errorString; 在Qt中利用线程权限进行高速的CAN通信用PC里能达到的CAN通信（使用USBCAN-II）速度是1ms 使用3个线程类：1个用来接收，1个用来发送，1个用来解析 接收线程使用最高线程权限：QThread::HighestPriority，其余线程用 QThread::HighPriority 如何循环发送报文：在发送线程里再多加一个定时器，timeout时间为需要循环发送的时间（可达到1ms）； 用户在主界面设置需要发送的报文为OBJ结构体数组，然后通过构造函数的方式传到发送线程，最后发送就行了。 解析过程：接收函数循环接收报文，每接收到n帧就发送到解析线程，然后根据ID解析，将解析数据发送主界面显示（不要append）","categories":["通讯协议","CAN"]},{"title":"数字花园建设","path":"/2024/05/17/博客-数字花园建设/","content":"页面部署打开github下方仓库https://github.com/oleeskild/digitalgarden fork到自己仓库 直接点击deploy，部署到vercel Obsidian插件配置搜索digital garden插件，配置Github仓库即可 写文章时，需要在文章属性中添加 1dg-publish: true 搜索publish single note，发布文章","categories":["博客"]},{"title":"版本控制方案","path":"/2024/05/17/版本控制方案/","content":"Git方案1. 仓库创建 仓库创建基于当前的项目，例如备份仪表项目仓库，LSA项目等 2. 分支创建 项目主分支保存项目代码及文档，负责发布代码 项目开发分支保存项目源码，分支仅管理员可见 项目运行分支保存项目头文件及库文件代码，分支所有人可见 项目人员开发分支基于运行分支创建，仅该人员有权限，该人员开发任务基于该分支进行修改代码 3. 代码提交 各人员代码仅提交在单独分支，提交完成后，由管理员审核后，同步源代码至开发分支 4. 版本回退 SVN方案"},{"title":"RAG检索知识体系","path":"/2024/05/17/AI-RAG检索知识体系/","content":"Windows本地部署Ollama + AnythingLLM解读本地文档 构建私有知识库现阶段切入大模型应用落地最合适的方案依然是结合大模型基于RAG检索增强来实现知识库的检索和生存。从而构建个人或者企业私有化的本地知识库。 你只需要将本地私有的 PDF、Word 文档和文本文件嵌入到本地向量库，连接上LLM，然后就可以通过对话、搜索的方式进行回答问题、提供见解，甚至生成摘要。 Ollama 下载地址 https://ollama.com/downloadOllama配置文档ollama笔记AnythingLLM 下载地址 https://useanything.com/downloadAnythingLLM配置文档AnythingLLM笔记 AnythingLLM 是 Mintplex Labs Inc. 开发的一个基于RAG（Retrieval-Augmented Generation）方案构建的开源、高效、可定制的私有知识库解决方案，一款开源 ChatGPT 等效工具，用于在安全的环境中与文档等进行聊天，专为想要使用现有文档进行智能聊天或构建知识库的任何人而构建。 AnythingLLM 能够把各种文档、资料或者内容转换成一种格式，让LLM（如ChatGPT）在聊天时可以引用这些内容。然后你就可以用它来和各种文档、内容、资料聊天，支持多个用户同时使用，还可以设置谁能看或改哪些内容。 支持多种LLM、嵌入器和向量数据库。 Open WebUI 安装地址 https://github.com/v1cc0/open-webui 安装Ollama工具后，在命令行输入 ollama pull qwen:4b 下载模型 千问4b的模型，也可以下载其他模型 ，支持的模型列表：https://ollama.com/library。 要开始运行Ollama的话，只需要在命令行输入 ollama run qwen:4b 就可以使用并访问这个模型了。 接下来我们需要安装向量模型和数据库，在https://ollama.com/里面搜索 nomic-embed-text ，这个模型可以将文本内容转换成向量数据，里面是模型介绍。 安装模型可以在命令行输入 ollama pull nomic-embed-text 进行下载和安装。 安装AnythingLLM工具后打开初始化界面，会进入到配置页面，在 LLM Preference 选项卡中，选择Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 qwen:4b ，token填 8192 下一步是配置 Embedding Preference 选项卡中，一样选择 Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 nomic-embed-text ，length填 512 下一步是配置 Vector Database ，选择默认的 LanceDB ，这是内置的向量数据库，如果想用云端数据库，可以选择 Pinecone 进行云端配置。 后面就是按提示下一步下一步，如果是要加新的工作空间，可以点new workspace来增加不同场景下的工作空间。如果需要更换模型，可以点左下角的配置按钮，重新执行上面三步完成配置。 到这里环境已经部署了，这时你已经可以跟大模型进行对话了。 接下来的步骤是对私有知识库的内容进行分析和获取。需要将文档上传到AnythinLLM，通过 nomic-embed-text 模型进行向量转换，然后存在向量数据库中。最后通过提问，去向量数据库获取内容并分析回答。 Data Connectors 是一种工具，它允许用户将外部数据源无缝集成到他们的 AnythingLLM 工作空间中，而无需编写任何自定义代码或处理复杂的配置。这些经过验证的数据连接器确保与你的 AnythingLLM 实例兼容，提供了一种简单且直接的方式来扩展你的工作空间功能。 以下是一些可用的数据连接器及其功能： GitHub Repo: - 通过这个连接器，你可以一键导入整个公共或私有的 GitHub 仓库到你的 AnythingLLM 工作空间中。 - 访问 GitHub 来获取你想要导入的仓库的链接。 - 这个功能对于开发者和团队来说非常有用，因为它允许他们直接在 AnythingLLM 中管理和查看代码库，跟踪问题和特性请求，以及审查代码。 YouTube Transcript: - 这个连接器允许你从 YouTube 视频链接导入整个视频的转录文本。 - 只需提供 YouTube 视频的链接，就可以轻松获取视频的文字内容。 - 这对于需要分析视频内容、创建视频摘要或者进行视频内容相关的研究的用户来说非常有用。 使用这些数据连接器，你可以快速地将外部数据集成到你的工作流程中，从而提高效率和生产力。例如，如果你正在研究一个特定的编程问题，你可以直接导入相关的 GitHub 仓库来查看代码和文档；或者，如果你需要分析一个教育视频的内容，你可以导入视频的转录文本来进行文本分析。 这些连接器的使用通常涉及到在 AnythingLLM 工作空间中选择相应的连接器，然后按照提示输入必要的信息，如仓库链接或视频链接，之后就可以开始导入数据了。整个过程简单直观，无需专业的编程知识，使得用户可以专注于数据分析和决策，而不是技术细节。 在工作空间页面上有一个上传文档的按钮，点击可以上传我们的文档内容。上传后选中文档，点击 Save and Embed ，等待一段时间，让模型进行向量转换和保存。 然后回到主界面点击工作空间的设置，选择 Chat Setting 选项卡，这里对话模式选择 Query ，这个模式是指只从提供的文档内容进行查找分析，而不要求大语言模型里面提供的信息作答。最后点击 Update workspace 进行更新。 然后就可以进行提问了，以上是本地部署应用的地方，如果你的电脑不太行，可以装Ollama部署在云端GPU服务器，然后本地安装AnythingLLM，在选择URL上填写云端Ollama的地址即可。 配置LLM这里选择Ollama作为后台的服务，URL这里填写http://127.0.0.1:11434，也就是前面Ollama启动的服务端口，填写后LLM模型选择gemma:2b 配置Embedding Model这里同样选择Ollama作为后台的服务，URL这里同样填写http://127.0.0.1:11434，填写后Embedding Model选择nomic-embed-text:latest 配置Vector DatabaseVector Database选择默认的第一个LanceDB 以上三个关键配置完成后，就可以开始使用AnythingLLM了。 创建文档库点击New Workspace新建文档库，并填写名称点击按钮开始添加文档我们使用的文档是paul_graham_essay.txt，这个文档也可以从github上下载：https://github.com/xinsblog/try-llama-index/blob/master/data/paul_graham_essay.txt 。 添加文档后还要将文档Move to Workspace然后点击Save and Embed出现Workspace updated successfully就表示配置已经完成 开始测试回到主页面，输入问题What did the author do in 9th grade?几秒钟后就可以看到AnythingLLM给出的回答 第三个工具就是Open WebUI，此工具可以支持云端部署web界面，在浏览器上访问大模型。 前置需要安装Docker，具体安装步骤可以看https://github.com/v1cc0/open-webui上面的安装步骤，这里就不再赘述。 安装完后输入github上的指令即可连通Ollama，并进行使用。","categories":["AI"]},{"title":"ollama笔记","path":"/2024/05/17/AI-ollama笔记/","content":"支持的模型 https://ollama.com/library 在用的ollama模型ollama.exe listollama run llama3:8bollama run codellama:7bollama run qwen:14bollama run starcoder2:7bollama run nomic-embed-text NAME SIZE FEATURES codellama:latest 3.8 GB llama3:latest 4.7 GB starcoder2:3b 1.7 GB qwen:4b nomic-embed-text 系统变量 OLLAMA_MODELS 指定模型位置 Ollama on Linux安装1curl -fsSL https://ollama.com/install.sh | sh Ollama使用Ollama大模型联网Python及库123import requestsimport jsonimport time 定义联网函数需要定义一个联网函数，用于与互联网上的服务器进行通信。这个函数可以发送HTTP请求，接收服务器的响应，并返回结果。以下是一个示例： 12345678def connect_to_server(url, data): headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; response = requests.post(url, data=json.dumps(data), headers=headers) if response.status_code == 200: return response.json() else: print(&quot;Error connecting to server:&quot;, response.status_code) return None 配置Ollama在联网之前，我们需要对Ollama大模型进行一些配置。这包括设置模型的参数、训练数据和测试数据等。具体的配置方法取决于你所使用的Ollama大模型。以下是一个示例： 12345678910# 设置模型参数model_params = &#123; &quot;learning_rate&quot;: 0.001, &quot;num_epochs&quot;: 100, &quot;batch_size&quot;: 32&#125;# 加载训练数据和测试数据train_data = load_train_data()test_data = load_test_data() 训练模型在配置好Ollama大模型后，我们可以开始训练模型。训练过程中，我们可以使用之前定义的联网函数将模型的中间结果上传到服务器上。以下是一个示例： for epoch in range(model_params[&quot;num_epochs&quot;]): # 训练模型 train_model(train_data, model_params) # 将中间结果上传到服务器 url = &quot;http://example.com/upload&quot; data = &#123; &quot;epoch&quot;: epoch, &quot;loss&quot;: get_current_loss(), &quot;accuracy&quot;: get_current_accuracy() &#125; connect_to_server(url, data) 测试模型训练完成后，我们可以使用测试数据对模型进行测试。同样，我们可以使用联网函数将测试结果上传到服务器上。以下是一个示例： 1234567891011# 测试模型test_model(test_data)# 将测试结果上传到服务器url = &quot;http://example.com/upload&quot;data = &#123; &quot;test_loss&quot;: get_test_loss(), &quot;test_accuracy&quot;: get_test_accuracy()&#125;connect_to_server(url, data) 通过以上步骤，我们已经成功地让Ollama大模型联网了。在实际应用中，你可能需要根据具体的需求和环境进行调整和优化。希望本文能够帮助你更好地理解和应用Ollama大模型的联网功能。","categories":["AI"]},{"title":"USB挂载监测","path":"/2024/05/17/通讯协议-USB-USB挂载监测/","content":"功能程序监测到插入U盘后，自动执行执行U盘内和本地指定文件夹双向同步功能 要点 Linux下如何用QT检测到U盘已经插入，并实现mount与umount 实现方式使用qt自带的QDBus可以实现，下面为连接代码，当系统有设备插入时，可以调用slotDeviceAdded(QString udi)函数。 在pro文件中应该加入QT +=dbus 12345678910111213141516#include &lt;QtDBus/QDBusConnection&gt;#include &lt;QDbusInterface&gt;//以下为检测设备的插入 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceAdded&quot;, this, SLOT(slotDeviceAdded(QString )));//以下为检查设备的拨出 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceRemoved&quot;, this, SLOT(slotDeviceRemoved(QString ))); 在slotDeviceAdded(QString udi)函数中，要使用到 1QDBusInterface device(&quot;org.freedesktop.Hal&quot;, udi, &quot;org.freedesktop.Hal.Device&quot; , QDBusConnection::systemBus()); 通过HAL可以查询到设备为volume的设备，然后通过判断是否为&#x2F;dev&#x2F;sd的设备，就可以判断出是否为U盘，然后调用mount就可以了。 这时记录下U盘的UDI，在检测到设备拨出时，再查询一下U盘的UDI是否还在，就知道U盘是否被拨出了。","categories":["通讯协议","USB"]},{"title":"DRM+GBM+EGL显示","path":"/2024/05/17/操作系统-Linux-Linux-Graphics-DRM-GBM-EGL显示/","content":"DRM (Direct Rendering Manager)、GBM (Generic Buffer Manager) 和 EGL (Embedded-System Graphics Library) 组合在一起，是在 Linux 平台上进行图形渲染和硬件加速的常见方式。这些组件一起提供了一个完整的图形渲染栈，允许应用程序直接与图形硬件进行交互。 DRM（Direct Rendering Manager）：DRM 是 Linux 内核中的一个子系统，用于管理图形硬件的驱动程序。它提供了一种通用的接口，允许用户空间程序直接与硬件交互，通过设备文件 /dev/dri/cardX 访问。DRM 提供了诸如模式设置、显示控制、渲染加速等功能。 GBM（Generic Buffer Manager）：GBM 是一个用于管理图形缓冲区的库，通常与 DRM 配合使用。它提供了一种标准的接口，用于分配、管理和操作图形内存。GBM 还提供了与 EGL 和 OpenGL ES 兼容的接口，使应用程序能够使用硬件加速进行渲染。 EGL（Embedded-System Graphics Library）：EGL 是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。EGL 通常与 GBM 和 DRM 一起使用，通过 GBM 提供的接口来创建图形表面，并将其与 OpenGL 或 OpenGL ES 上下文关联起来，实现硬件加速的图形渲染。","categories":["操作系统","Linux","Linux Graphics"]},{"title":"OpenGL显示","path":"/2024/05/17/操作系统-Linux-Linux-Graphics-OpenGL显示/","content":"GLUGLU（OpenGL Utility Library）是OpenGL的一个辅助库，提供了一些更高级的几何计算和对象构造函数，如曲面和体的生成、平移、旋转等，这些函数在处理复杂的几何操作时非常有用。 GLFWGLFW是一个流行的开源库，主要用于创建和管理图形应用程序中的窗口、OpenGL或Vulkan上下文，以及处理用户输入、定时器等功能。适用于各种图形应用程序的开发，提供了窗口管理、上下文管理、输入处理等功能，使开发者能够专注于图形渲染和应用逻辑的实现。主要功能： 窗口管理： GLFW允许开发者创建窗口并对其进行管理，包括调整大小、最小化、最大化、关闭等操作。 上下文管理： 它提供了创建OpenGL或Vulkan上下文的功能，使得图形渲染程序可以在窗口中绘制图形。 输入处理： GLFW支持处理用户输入，包括键盘输入、鼠标移动和点击、游戏手柄等。 事件处理： 它允许开发者监听和响应各种事件，如窗口大小改变、键盘按键、鼠标移动等。 监视器管理： GLFW支持多个显示器的管理，可以获取显示器的分辨率、刷新率等信息。 使用步骤： 初始化： 在程序启动时，调用GLFW的初始化函数来初始化库。 创建窗口： 使用GLFW的窗口创建函数来创建一个窗口并指定其属性，如大小、标题等。 创建上下文： 使用GLFW的上下文创建函数来创建一个OpenGL或Vulkan上下文。 主循环： 在主循环中轮询事件，并根据事件类型做出相应的处理。 渲染： 在渲染阶段，使用OpenGL或Vulkan等图形API绘制场景。 清理： 在程序结束时，调用GLFW的清理函数来释放资源并关闭库。 利用glfw监视器Demo 1234567891011121314151617181920212223242526272829#include &lt;GLFW/glfw3.h&gt; int main() &#123; // 初始化 GLFW if (!glfwInit()) &#123; return -1; &#125; // 获取监视器（显示器）列表 int count; GLFWmonitor** monitors = glfwGetMonitors(&amp;count); // 指定要使用的显示设备索引 int monitor_index = 0; // 设置为你想要的显示设备索引 // 获取指定索引的显示设备 GLFWmonitor* monitor = (monitor_index &lt; count) ? monitors[monitor_index] : NULL; // 获取显示设备的视频模式 const GLFWvidmode* mode = glfwGetVideoMode(monitor); // 创建窗口并指定显示设备 GLFWwindow* window = glfwCreateWindow(mode-&gt;width, mode-&gt;height, &quot;OpenGL Window&quot;, monitor, NULL); if (!window) &#123; glfwTerminate(); return -1; &#125; // 进入主循环 while (!glfwWindowShouldClose(window)) &#123; // 渲染代码 glClear(GL_COLOR_BUFFER_BIT); // ... glfwSwapBuffers(window); glfwPollEvents(); &#125; // 清理资源 glfwDestroyWindow(window); glfwTerminate(); return 0; &#125; GLUT（OpenGL Utility Toolkit） GLUT 是一个跨平台的工具包，用于创建和管理 OpenGL 窗口、处理用户输入等。它提供了一组简单的 API，使得编写基本的 OpenGL 程序变得更加容易。 - GLUT 支持多种操作系统，包括 Windows、Linux 和 macOS。 - 使用 GLUT，你可以很快地编写出一个可以在不同平台上运行的简单 OpenGL 程序，而不必担心平台特定的细节。 - 但是，GLUT 对于创建复杂的图形用户界面（GUI）可能不够灵活，因为它的功能相对有限。 GLUT 是一个跨平台的工具包，用于简化 OpenGL 应用程序的开发。它提供了一组函数，用于创建窗口、处理输入事件、进行基本的图形绘制等，使开发者可以更轻松地编写 OpenGL 应用程序，而无需处理底层的窗口系统的细节。 GLUT 提供了一个相对简单的接口，适用于快速原型设计和简单的图形应用程序。它通常用于学习 OpenGL、编写小型游戏、演示程序等。 GLX（OpenGL Extension to the X Window System） GLX 是 OpenGL 在 X Window System 上的扩展，它允许 OpenGL 应用程序与 X 服务器通信，并在 X 窗口系统中创建 OpenGL 上下文。GLX 提供了一组函数，用于在 X 窗口系统中创建 OpenGL 渲染上下文、管理 OpenGL 窗口和图形渲染等。 GLX 允许 OpenGL 应用程序直接与 X 服务器通信，而不需要借助其他库或工具。它提供了对 OpenGL 的完整支持，可以实现高性能的图形渲染和交互。 GLX 则是 OpenGL 在 X 窗口系统上的扩展，提供了与 X 服务器通信和在 X 窗口系统中创建 OpenGL 渲染上下文的功能。 EGL（Embedded Graphics Library）EGL 是一个用于管理图形渲染上下文的接口，通常用于嵌入式系统和移动设备上。 - EGL 是 OpenGL ES 和 OpenVG 的标准的本地显示系统接口，它提供了与底层窗口系统交互的能力。 - 在 Linux 上，EGL 通常与 GBM（Generic Buffer Manager）或其他图形系统配合使用，如 Wayland。 - 使用 EGL，你可以在嵌入式系统上更好地控制 OpenGL 上下文的创建和管理，以及与窗口系统的交互。","categories":["操作系统","Linux","Linux Graphics"]},{"title":"ubuntu源","path":"/2024/05/17/操作系统-Linux-Ubuntu-ubuntu源/","content":"Ubuntu18.04更换国内源Ubuntu本身的源使用的是国内的源，下载速度比较慢，不像CentOS一样yum安装的时候对镜像站点进项选择，所以选择了更换成国内的源。 bionic代表ubuntu18 备份&#x2F;etc&#x2F;apt&#x2F;sources.list文件1mv /etc/apt/sources.list /etc/apt/sourses.list.backup 新建&#x2F;etc&#x2F;apt&#x2F;sources.list文件并添加以下内容1234567891011#163源deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 更改完成之后执行以下命令12# apt update# apt upgrade 其他的一些apt命令12345678910111213141516sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 其他几个国内的源：1234567891011121314151617181920212223242526272829303132333435#中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse#阿里云源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse#清华源deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse","categories":["操作系统","Linux","Ubuntu"]},{"title":"我的博客","path":"/2024/05/17/博客-我的博客/","content":"要更换主题的情况下 修改.github&#x2F;workflows&#x2F;blogPublish.yml 修改_config.theme.yml 修改_config.yml GitHub仓库部署 拉取仓库并本地部署脚本 123456789101112rm -rf ./BlogDeploygit clone git@github.com:liuluhua/BlogDeploy.gitcd ./BlogDeploymkdir themescd themesgit clone git@github.com:xaoxuu/hexo-theme-stellar.gitgit clone git@github.com:next-theme/hexo-theme-next.gitcd ..npm installhexo cleanhexo ghexo s -p 9050 博客框架采用Hexo 部署到GitHubPages（） 部署到Vercel（GitHub Publish） 通过Netlify部署和构建 利用Obsidian Digital Garden&#x2F;Flowershow插件在Vercel上将笔记内容部署为Obsidian数字花园 部署流程 创建GitHub发布仓库GitHub仓库部署 创建GitHub源码仓库，并在仓库中部署Hexo 在源码仓库中创建工作流，工作流主要完成任务是在接收到同步后，完成以下几个动作GitHub Actions 构建静态页面生成public文件夹，在构建之前需要调用hexo插件自动生成category信息 将public文件夹拷贝至发布仓库 确定Hexo仓库部署在GitHub还是本地如果部署在GitHub则需要整个仓库拉取到obsidian，主要显示post下文件，需要通过github actions进行发布管理优点：本地不需要Hexo环境，直接提交后自动构建页面缺点：所有源码都在Github且仓库必须公开 如果部署在本地需要在本地生成静态网页，之后将静态网页通过publisher发布public文件夹到github仓库优点：仓库可以不开源缺点：本地需要具有Hexo环境，且需要在本地生成静态网页 两个仓库都在Github是否可以实现，编辑完成后，github从源码仓库复制到发布仓库？源码仓库闭源，同步笔记到源码仓库后，源码仓库通过actions时触发同步到发布仓库，更新发布仓库页面 扩展：三仓库管理，Markdown仓库只用于编辑Markdown文件，同步后触发actions，同步到源码仓库中的post，源码仓库接受到push后，触发actions生成静态页面public，public生成完成后拷贝public到发布仓库利用actions，可以实现，感觉没啥必要，太过复杂了，源码仓库+发布仓库基本就可以了 两仓库实现步骤可以实现两个仓库都在 GitHub，并通过 GitHub Actions 自动将源码仓库的内容复制到发布仓库。这样可以将编辑完成后的 Hexo 源码仓库内容自动同步到发布仓库，实现自动化的发布管理。 将 Hexo 的源码仓库设置在 GitHub 上，你可以在这个仓库中编辑和管理 Hexo 的源代码、主题和文章。 创建另一个 GitHub 仓库作为发布仓库，用于存放生成的静态网页。你可以将 Hexo 生成的 public 文件夹的内容推送到这个仓库中。该仓库利用GitHub Pages，直接通过.github.io进行访问 在 Hexo 源码仓库中设置一个 GitHub Actions workflow，以便在每次提交或推送时自动将更新的内容复制到发布仓库。 需要配置GitHub的ssh，可以有权限访问两个仓库 需要配置发布仓库的deploy key，可以有权限写入发布仓库 域名获取 GitHub二级域名GitHubPages 二级域名https://freedomain.one/ 解析包括添加三条解析记录 192.30.252.153是GitHub的地址，你也可以ping你的 http:&#x2F;&#x2F;你的用户名.github.io 的ip地址，填入进去。 第三个记录类型是CNAME，CNAME的记录值是：http:&#x2F;&#x2F;你的用户名.github.io 这里千万别弄错了。 绑定Github域名，登录GitHub，进入之前创建的仓库，点击settings，设置Custom domain，输入你的域名 图床GitHub图床 创建一个public仓库 进入Settings-Developer Settings-Personal access tokens (classic)生成token PicGo图床设计选择GitHub，输入在GitHub的仓库名，分支名和token即可 ObsidianCtrl+Shift+I在控制台里可以查看详细日志，所有插件的日志都可以在这里看到 配置Hexo忽略文件和文件夹由于 hexo 的文章只存在于 source 目录下，我们需要让 Obsidian 忽略其他文件的内容以优化性能以及减少不必要的搜索结果。具体的操作是在 设置-文件与链接-Exclude Files，将需要忽略的文件添加进去（尤其是 node_modules）。 插件Templater模板配置说明文档 https://silentvoid13.github.io/Templater/introduction.html 首先我们要创建模板，我们可以在 source 目录下创建 _obsidian 文件夹，并创建一篇 Post Template 的文章（md文件），我们再创建新文章的时候，只需要点击侧边栏的『插入模板』按钮就可以快速生成 Front-matter 信息： 123456789101112131415161718---title: &lt;% tp.file.title %&gt;date: &lt;% tp.file.creation_date(format=&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;update: &lt;% tp.file.last_modified_date(&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;comments: truetags:categories:dg-publish: true---定义脚本function generateTimestampUrl() &#123; var timestamp = Math.round(new Date() / 1000); var url = timestamp.toString(36) return url; &#125; module.exports = generateTimestampUrl; osidian-git快捷键Ctrl + P打开命令面板，输入open source control view启用可视化操作面板 ### obsidian-pangu中英文之间加空格 Hidden Folder目录隐藏插件 FileTree左侧菜单出现了一个 File Tree 的 Tab 页，点击后就可以看到文件以树形的结构呈现，我们展开 source 文件夹，并右键 _post 文件夹，选择 Focuse on Folder 后，左侧的文件列表中就只会显示 _post 文件夹中的内容了 Github Publisher将 Obsidian 中的文章和本地附件上传到 Github 仓库，上传前可以指定文件目录、自定义内容替换等操作。能将Obsidian仓库里的任意笔记自动或者手动同步到GitHub代码仓库的任意位置。首先设置好Github相关信息，包括Github repository，用户名，token以及Branch。当然也可以在单个笔记文件里，通过文档属性（frontmatter），单独设置接收笔记上传的Github仓库信息（可以选择同一用户下的不同仓库，同一仓库下的不同位置）。上传设置设定上传的笔记存储在Github仓库的位置。因为我的hexo博客日志文件保存在source&#x2F;posts目录下，故选择Fixed Folder，设定好默认上传到的目录。文章发布在文章文档属性添加一个share属性（可以根据需要在插件设置里改成其他任意名称），赋予值 true。文章写好后，share: true右键发布。 Button用于插入一个按钮设置按钮信息： 按钮类型（也就是功能）选择Link - open a url or uri 链接可以使用file://或者Obsidian URI，这个时候后者的好处就体现出来了，因为file://只能用绝对路径，例如file://C:\\Users\\GavinCrown\\Desktop\\SecondBrain\\Blog\\_config.yml，意味着每换一台设备你的链接就得改一次。 设置完成后，点Insert Button就可以将按钮插入到当前Markdown文件中： ShellCommand再介绍个终极优化方案，之前我们执行命令是通过运行bat文件，而Shell commands可以在Obsidian中设置好命令，并通过Obsidian的命令面板或快捷键快速运行。在插件设置面板中添加命令运行博客： Shell commands没有显示终端窗口的功能，所以需要我们启动powershell再传入命令 有了终端窗口我们才可以在窗口中按Ctrl + C关闭Hexo服务，否则它会一直占用端口1start powershell &#x27;-NoExit -Command start http://localhost:4000 ; cd Blog ; hexo s&#x27; 打开站点和主题配置文件：12start Blog/_config.ymlstart Blog/themes/butterfly4.3.1/_config.yml 然后修改默认执行环境为PowerShell 5，可以为每个命令设置下别名，就是在命令面板显示的名字 其他插件 Obsidian Linter 插件,我只用了在英文两边加空格的设置。 Image Converter 转化图片格式，我统一转为 webp，并设置了图片分辨率大小。 Unique attachments 用于将附件的文件名统一为 “字母 + 数字”的格式,记着在配置里加入 webp 图片格式 Image Inserter 用于找图片，我用于设置文章封面，即设置 cover.image 属性。 GitHubGithub Pages部署GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。创建GitHub账号，并创建一个基于用户名.github.io的仓库 使用GitHub Pages进行部署，所建仓库必须取名为“GitHub用户名.github.io” 勾选“Add a README file”，不然后面会看不到GitHub Pages域名和部署分支 仓库需要创建为公有仓库，即public 仓库大小限制为 创建完成后GitHub Pages给我们提供了一个格式为 https://GitHub用户名.github.io 的免费域名，并且相应的网站是从该仓库的 main&#x2F;master 分支构建得到的 自定义域名，在GitHub 仓库Settings-Pages-Custom domain添加自己的域名 GitHub Actions GitHub Actions 是 GitHub 提供的一项持续集成（CI）和持续部署（CD）服务，允许开发者自动化软件开发工作流程。通过 GitHub Actions，你可以在 GitHub 上运行自定义的代码（称为动作），以响应存储库中的事件，例如推送代码、创建拉取请求等。一个 GitHub Actions 的核心概念是 workflow（工作流），它是一系列由动作组成的自定义任务，这些任务可以在特定的事件触发时自动执行。每个 workflow 都定义了一系列步骤，每个步骤又包含一个或多个动作。workflow 可以用 YAML 格式定义，并存储在存储库的 .github/workflows 目录中。 通过GitHub Actions，实现将代码同步GitHub之后，由GitHub Actions执行页面的发布。 执行GitHub Actions，在需要执行的储存库中前往 Settings &gt; Pages &gt; Source，并将 Source 改为 GitHub Actions。 在储存库中建立 .github/workflows/blogPublish.yml并写入内容 环境变量配置在Settings –&gt; Secrets and Variables –&gt; Actions 里面,配置后，可以在actions里面通过 $&#123;&#123; secrets.dingtalk_secret &#125;&#125; 调用到对应的数据 使用Github Actions造成的文章更新时间问题参考原文：https://mrseawave.github.io/blogs/articles/2021/01/07/ci-hexo-update-time/ 当使用 Travis CI or Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。对于Github Actions可以使用命令在构建之前进行处理 123456jobs: deploy_gh_pages: steps: - name: Restore file modification time run: | git ls-files -z | while read -d &#x27;&#x27; path; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$path&quot;)&quot; &quot;$path&quot;; done 如果git命令不好用， 也可以使用find命令 1find source/_posts -name &#x27;*.md&#x27; | while read file; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$file&quot;)&quot; &quot;$file&quot;; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果github actions中使用actions&#x2F;checkout@v2，请设定它的参数fetch-depth: 0，因为0表示获取所有分支和标签的所有历史记录。默认值为1 Git HookGit hook是一种机制，允许在特定的Git事件发生时触发自定义的脚本或命令。这些事件可以包括提交(commit)、推送(push)、合并(merge)等。使用Git hook，你可以在这些事件发生时执行自定义的操作，比如运行测试、格式化代码、触发构建等。Git提供了一系列的预定义钩子，你可以将自己的脚本绑定到这些钩子上，或者创建自定义的钩子。 gitignore在Git仓库的根目录下编辑有.gitignore文件，该文件中定义了一些不需要上传至GitHub的内容，列在该文件中的文件或文件夹将会被忽略，不在上传 Hexo忽略文件12345678.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_multiconfig.yml Obsidian忽略文件1.obsidian/workspace .obsidian 文件本身是可以同步的，当前存储库的插件以及相关的配置都会下载在这个文件夹中，因此将其同步到 git 记录中也是非常有用的，假如你切换设备就不需要重新为当前的存储库重新配置 Obsidian 了。 GitHub仓库部署源码仓库部署 创建一个私有仓库，此处我创建一个BlogDeploy仓库，仓库拉取到本地后，在仓库中部署Hexo使用 创建gitignore文件，排除Hexo不用上传的文件12345678#.DS_Store#Thumbs.db#db.json#*.log#node_modules/#.deploy*/#_multiconfig.ymlpublic/ 同步仓库到远端 发布仓库部署 创建一个GitHub仓库，仓库必须取名为“GitHub用户名.github.io” 仓库需要创建为公有仓库，即public 创建一个分支，分支名为ImageBed，用于做图床上传 获取Token，选择用户Settings-&gt;Developer settings-&gt;Personal access tokens，token的权限获取，勾上workflow即可 图床分支创建用于存储图片，图床分支的相关信息部署完成后，需要在PicGo中进行配置 1234git checkout -b my-test //在当前分支下创建my-test的本地分支分支git push origin my-test //将my-test分支推送到远程git branch --set-upstream-to=origin/my-test //将本地分支my-test关联到远程分支my-test上 git branch -a //查看远程分支 Hexo部署Hexo是一个基于Node.js的静态网站生成器，主要用于快速、简单地搭建个人博客或静态网站。它采用Markdown格式来撰写内容，并提供了丰富的主题和插件生态系统，可以轻松扩展和定制网站功能和外观。 适用于个人博客、项目文档、个人简历等各种静态网站的搭建和管理。 目录架构12345678_config.yml #网站的配置信息package.json #应用程序的信息scaffolds #模版文件夹source #存放用户资源，Markdown 文档\t_drafts\t_poststhemes #主题文件夹public #网站文件 Hexo使用使用流程 安装hexosudo npm install -g hexo-cli 查看版本，确认安装成功hexo -v 创建一个新文件夹Hexo，并初始化该文件夹hexo init Hexo 清除缓存hexo clean 生成静态文件hexo g 开启本地服务器并修改端口为80hexo s -p 9050 常用命令 12345678910111213141516171819202122npm install -g hexo-cli #安装Hexo npm update hexo -g #升级 hexo init #初始化博客 命令简写 hexo n &quot;我的博客&quot;hexo new &quot;我的博客&quot; #新建文章 hexo ghexo generate #生成 hexo shexo server #启动服务预览 hexo dhexo deploy #部署 hexo server #Hexo会监视文件变动并自动更新，无须重启服务器 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令端口修改 node_modules\\hexo-server\\index.js 临时启动 hexo s -p 9050 hexo generate将Hexo源码目录中已有的源码编译生成为静态网页文件，生成以下： db.json文件：编译过程中产生的中间文件，不用关心； public文件夹：新生成的静态网页文件就存放在这个目录下。 hexo deploy将静态网页文件推送到GitHub Pages Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容 配置文件配置快捷打开站点配置文件和主题配置文件是我们DIY博客经常要编辑的两个文件，在Obsidian中没法编辑yml文件，可以通过URL来打开yml文件，会自动调用默认的编辑器打开。 在主页Markdown中，按Ctrl+K插入链接，写入我们两个配置文件所在的相对路径： 1234567891011[打开站点配置文件](Blog/_config.yml)[打开主题配置文件](Blog/themes/butterfly4.3.1/_config.yml)# 或者写成Obsidian URI的形式[打开站点配置文件](obsidian://open?file=Blog/_config.yml)[打开主题配置文件](obsidian://open?file=Blog/themes/butterfly4.3.1/_config.yml)#或者![打开站点配置文件](Blog/_config.yml)![打开主题配置文件](Blog/themes/butterfly4.3.1/_config.yml)![运行博客](Blog/RunBlog.bat) 站点配置文件在blog根目录里的_config.yml文件称为站点配置文件 主题修改：theme 网站标题:title 副标题:subtitle 网站描述:description 作者:author 网站头像外部链接:avatar 网站语言:language:zh-Hans 时区:timezone:Asia&#x2F;Shanghai 自定义域名：url: 忽略文件：123456skip_render: # 这里排除的是obsidian编辑器需要的文件 - &#x27;_posts/.obsidian/*&#x27; - &#x27;_posts/Scripts/*&#x27; - &#x27;_posts/Templates/*&#x27; - &#x27;**/README.md&#x27; 主题配置文件使用的主题： stellar Next&#96;https://github.com/next-theme/hexo-theme-next themes&#x2F;next 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Next主题配置文件scheme: Geminifavicon: small: /images/favicon-16x16.png medium: /images/favicon-32x32.png apple_touch_icon: /images/apple-touch-icon.png safari_pinned_tab: /images/avatar.svgcreative_commons: license: by-sa post: truemenu: home: / || fa fa-home tags: /tags/ || fa fa-tags archives: /archives/ || fa fa-archiveavatar: url: /images/avatar.jpg rounded: true rotated: truesocial: GitHub: https://github.com/cuefe || fab fa-github E-Mail: mailto:me@cuefe.com || fa fa-envelopetag_icon: truecodeblock: theme: light: atom-one-light dark: atom-one-light copy_button: enable: trueback2top: enable: true sidebar: true scrollpercent: truefont: enable: true host: https://fonts.loli.net global: family: Noto Serif SC size: 0.9pjax: truemediumzoom: truelazyload: truequicklink: enable: true home: true archive: true delay: true priority: truemotion: enable: falsebusuanzi_count: enable: true *进入根目录里的themes文件夹，里面也有个_config.yml文件，为主题配置文件 社交外链的设置，即在侧栏展示你的个人社交网站信息。(插件jiathis) 插入网易云，进入网页版的网易云音乐，选择喜欢的音乐，点击生成外链播放器，在侧栏插入这首歌的音乐播放器，修改 blog/themes/next/layout/_macro的sidebar.swig文件，添加刚刚复制的外链代码 设置背景，在blog/themes/next/source/css/_custom文件的custom.styl首部添加body &#123; background:url(./background.jpg); background-attachment: fixed; &#125;，fixed固定背景图片 增加侧栏菜单条目，默认的侧栏菜单条目有：首页、归档、标签、关于、搜索等。如果你想要增加其他的菜单条目，修改主题配置文件_config.yml里的Menu Settings中的menu和menu_icons两个地方 域名配置文件进入blog&#x2F;source目录下，创建一个文件，文件名CNAME，写入你的自定义域名即可 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 category 123456789并列分类，了解一下： categories: - [Linux] - [Tools]并列+子分类，再了解一下： categories: - [Linux, Hexo] - [Tools, PHP] 扩展abbrlink文章永久链接 自定义文章标签生成标签页面hexo new page tags修改blog&#x2F;source&#x2F;tags&#x2F;index.md，添加type: “tags” 123title: tagsdate: 2023-01-08 11:27:57type: &quot;tags&quot; 以后就可以在文章文件头添加标签了，如下 123456title: Hexo + GitHub 搭建个人博客date: 2023-01-07 13:15:00tags:- Hexo- Next- 博客 评论系统基于stellar主题的评论系统的配置 注册leancloud https://console.leancloud.app/ 创建一个应用后，并进入应用，选择左下角的 设置 &gt; 应用 Key。你可以看到你的 APP ID,APP Key 和 Master Key。请记录它们，以便后续使用。1234AppID`LuASoYE3f9mviMTY6yuhsDXQ-MdYXbMMI` AppKey`etyMOUJxZGMmiUFeBRb30zS2` MasterKey`MutkN6OjDzogLjWR6smA91CN` vercel上部署服务端 前往 Waline 官网 根据指引到 Vercel 进行 Waline 服务端部署 安装 @waline&#x2F;hexo-nextnpm install @waline/hexo-next 为了不使用魔法也能正常评论，我们需要有自己的域名解析到 Waline 服务端，可以在域名控制台给自己的博客域名添加二级域名，添加 CNAME 解析到cname-china.vercel-dns.com或添加 A 解析到76.223.126.88（也可以前往 Vercel All IP 自行挑选合适的节点），接着进入 Vercel 的 Waline 应用的控制台，在Settings-Domains里添加上文提到的二级域名，这样在主题配置文件添加配置后就可以正常评论了 主题配置文件添加配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Waline Config File# For more information:# - https://waline.js.org# - https://waline.js.org/reference/component.htmlwaline: # New! Whether enable this plugin enable: true # Waline server address url, you should set this to your own link serverURL: #serverURL填写自己解析到 Waline 服务端的域名https://waline.vercel.app/ # Waline library CDN url, you can set this to your preferred CDN libUrl: https://npm.elemecdn.com/@waline/client@v2/dist/waline.js # Waline CSS styles CDN url, you can set this to your preferred CDN cssUrl: https://npm.elemecdn.com/@waline/client@v2/dist/waline.css # Custom locales # locale: # placeholder: Welcome to comment # Comment box placeholder # If false, comment count will only be displayed in post page, not in home page commentCount: true # Pageviews count, Note: You should not enable both `waline.pageview` and `leancloud_visitors`. pageview: false # Custom emoji emoji: - https://npm.elemecdn.com/@waline/emojis@1.0.1/weibo - https://npm.elemecdn.com/@waline/emojis@1.0.1/alus - https://npm.elemecdn.com/@waline/emojis@1.0.1/bilibili - https://npm.elemecdn.com/@waline/emojis@1.0.1/qq - https://npm.elemecdn.com/@waline/emojis@1.0.1/tieba - https://npm.elemecdn.com/@waline/emojis@1.0.1/tw-emoji # Comment infomation, valid meta are nick, mail and link # meta: # - nick # - mail # - link # Set required meta field, e.g.: [nick] | [nick, mail] # requiredMeta: # - nick # Language, available values: en-US, zh-CN, zh-TW, pt-BR, ru-RU, jp-JP # lang: zh-CN # Word limit, no limit when setting to 0 # wordLimit: 0 # Whether enable login, can choose from &#x27;enable&#x27;, &#x27;disable&#x27; and &#x27;force&#x27; # login: enable # comment per page # pageSize: 10 在blog/source/_data文件夹下新建languages.yml并编辑1234567# languagezh-CN: # items post: views: 阅读 comments: waline: 评论 配置完评论后及时到 Waline 服务端登录，以便管理评论 可选择开启评论邮件提醒功能， Waline 官网 有详细的说明 评论系统Valine基于LeanCloud编辑主题配置文件，启用评论插件comments，补充type参数（valine&#x2F;waline）在主题配置文件中配置valine 1234567891011121314151617181920# Valine# 基于Leancloud# Based on LeanCloud# See: https://valine.js.org/valine:\tappId: appKey: placeholder:说点什么\tpath: window.location.pathname\tavatar:retro\tmeta:[&#x27;nick&#x27;,&#x27;mail&#x27;,&quot;link&#x27;]\tpagesize:10\tlang:zh-CN\thighlight:false\trecordIP:false\tserverURLs:&#x27;&#x27;\temojiCDN:\temojiMaps :\tenableQQ:false\trequiredrFields:[] 插件部署插件 hexo-deployer-git 编辑Hexo顶层目录下的_config.yml文件，文件最后可以看到deployment相关内容 1234deploy： type: git repo: git@github.com:liuluhua/liuluhua.github.io.git branch: main repo填写仓库ssh地址 branch的填写需要和GitHub Pages部分指定的Branch保持一致 搜索插件 hexo-generator-searchdb 安装 hexo-generator-searchdbnpm install hexo-generator-searchdb 修改主题配置文件12local_search:\tenable: true 自动标签插件hexo-auto-category该插件在 Hexo 进行 build 的时候会去自动根据文章目录情况来自动修改文章的 categories 信息 安装插件npm install hexo-auto-category --save 修改站点配置文件_config.yml，使文章链接清晰12345678910111213# Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the max_depth of directory-tree you want to generate, should &gt; 0# multiple: multiple category hierarchiesauto_category: enable: true multiple: true depth: 5# 修改 permalink 让你的文章链接更加友好，并且有益于 SEO permalink: :year/:month/:hash.html# 规定你的新文章在 _post 目录下是以 cateory new_post_name: :category/:title| 该插件需要每次手动构建时才会更新categories信息。执行hexo g 使用 git hook，在我们每次执行 commit 前都自动运行 npx hexo generate 触发自动生成 categories 的行为，并将生成后的变更自动添加到本次提交中，然后一同 push 到 github 上去。这里可以使用 husky 来很方便的设置这样一个 git hook1. 安装 huksy：npm install husky --save-dev2. 执行 huksy 初始化指令：npx husky install*3. 在 package.json 中的 scripts 中写入：&quot;prepare&quot;: &quot;husky install&quot;4. 在生成的 .husky 目录创建 pre-commit 文件（chmod a+x pre-commit），并写入以下内容： 1234#!/usr/bin/env sh . &quot;$(dirname -- &quot;$0&quot;)/_/husky.sh&quot; npx hexo generate &amp;&amp; git add . 提交代码时，检查有无categories的生成信息。 阅读量统计Leancloud（https://console.leancloud.cn/） 创建应用，进入该应用的 设置-&gt;应用凭证，找到 AppID 和 AppKey，记录下来后面配置要用 配置_config.yml启用网页访问统计，配置 leancloud的 app_id 和 app_key，打开计数功能，统计来源改为 leancloud123456789101112131415161718#网页访问统计#Analysis of website visitorsweb analytics:\tenable:trueleancloud:\tapp id: app key: # 浏览量计数# Number of visitsviews:\tenable:true\t#统计数据来源\t#Data Source\t#Options:busuanzi | leancloud\tsource:&quot;leancloud&quot;\tformat:&quot;&#123;&#125;次&quot; 页面底部展示网站的 PV、UV 统计数显示页面的访问量和访客数量 123456789101112# 展示网站的 pv、w 统计数# Display website pv and uv statisticsstatistics:\tenable:true\t#统计数据来源，使用leancloud 需要设置&#x27;web analytics:leancloud&#x27;中的参数;busuanzi 显示统计数据很大属于正常现象，部署后会正常\t# Data source.If use leancloud,you need to set the parameter in&#x27;web analytics:leancloud\t# Options:busuanzian | leancloud\tsource:&quot;leancloud&#x27;\t#页面显示的文本，&#123;&#125;是数字的占位符(必须包含)，下同\t# Displayed text, &#123;&#125;is a placeholder for numbers (must be included), the same below\tpv format:&quot;总访问量 &#123;&#125;次&quot;\tuv format:&quot;总访客数 &#123;&#125;人&quot; Canvas nest 背景动画 在blog/source/_data文件夹下新建footer.njk并编辑 1&lt;script color=&quot;0,255,255&quot; opacity=&quot;1&quot; zIndex=&quot;-1&quot; count=&quot;70&quot; src=&quot;https://cdn.staticfile.org/canvas-nest.js/1.0.1/canvas-nest.js&quot;&gt;&lt;/script&gt; 修改主题配置文件 12custom_file_path: footer: source/_data/footer.njk MathJax 安装 hexo-filter-mathjax 修改主题配置文件123math: mathjax: enable: true 此后可在文章文件开头添加参数mathjax: true以使用 MathJax CDN 修改主题配置文件123vendors: plugins: custom custom_cdn_url: https://cdn.staticfile.org/$&#123;cdnjs_name&#125;/$&#123;version&#125;/$&#123;cdnjs_file&#125; 字数统计 安装 hexo-word-counter 烟花动画 安装 next-theme&#x2F;hexo-next-fireworks 主题配置文件添加配置12fireworks: enable: true 由于烟花动画比较遮挡视线，已修改/blog/node_modules/hexo-next-fireworks/fireworks.js，更换为礼花动画 夜间模式 安装 hexo-next-darkmode 主题配置文件添加配置1234567891011121314151617# Darkmode JS# For more information: https://github.com/rqh656418510/hexo-next-darkmode, https://github.com/sandoche/Darkmode.jsdarkmode_js: enable: true bottom: &#x27;64px&#x27; # default: &#x27;32px&#x27; right: &#x27;unset&#x27; # default: &#x27;32px&#x27; left: &#x27;32px&#x27; # default: &#x27;unset&#x27; time: &#x27;0.5s&#x27; # default: &#x27;0.3s&#x27; mixColor: &#x27;transparent&#x27; # default: &#x27;#fff&#x27; backgroundColor: &#x27;transparent&#x27; # default: &#x27;#fff&#x27; buttonColorDark: &#x27;#100f2c&#x27; # default: &#x27;#100f2c&#x27; buttonColorLight: &#x27;#fff&#x27; # default: &#x27;#fff&#x27; isActivated: false # default false saveInCookies: true # default: true label: &#x27;🌓&#x27; # default: &#x27;&#x27; autoMatchOsTheme: true # default: true libUrl: https://npm.elemecdn.com/darkmode-js@1.5.7/lib/darkmode-js.min.js # Set custom library cdn url for Darkmode.js 运行时间在/blog/themes/next/layout/_partials/footer.njk中添加 1234567891011121314151617181920&lt;div&gt; &lt;span id=&quot;timeDate&quot;&gt;载入天数...&lt;/span&gt; &lt;span id=&quot;times&quot;&gt;载入时分秒...&lt;/span&gt;&lt;/div&gt;&lt;script&gt; var now = new Date(); function createtime() &#123; var grt= new Date(&quot;01/07/2023 13:15:00&quot;);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125; document.getElementById(&quot;timeDate&quot;).innerHTML = &quot;本站已安全运行 &quot;+dnum+&quot; 天 &quot;; document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; 小时 &quot; + mnum + &quot; 分 &quot; + snum + &quot; 秒&quot;; &#125;setInterval(&quot;createtime()&quot;,250);&lt;/script&gt; 站点地图 安装 hexo-generator-sitemap 修改主题配置文件12menu: sitemap: /sitemap.xml || fa fa-sitemap 执行hexo cl &amp;&amp; hexo g生成sitemap.xml 此时可以在blog/public文件夹下看到sitemap.xml 验证，进入 Google Search Console ，选择网址前缀，输入网址时记得加上https:&#x2F;&#x2F;，选择 HTML 标记，你会得到元标记&lt;meta name=&quot;google-site-verification&quot; content=&quot;xxxxxxxx&quot; /&gt;，将 content 后的内容加入到主题配置文件中google_site_verification: &quot;xxxxxxxx&quot;，执行hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 点击前往资源页面添加站点地图，成功提交 静态资源压缩 安装 hexo-neat 主题配置文件添加配置123456789101112131415161718neat_enable: trueneat_html: enable: true exclude:neat_css: enable: true exclude: - &#x27;**/*.min.css&#x27;neat_js: enable: true mangle: true output: compress: exclude: - &#x27;**/*.min.js&#x27; 自定义 CSS 在/blog/source/_data文件夹下新建styles.styl并编辑123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051:root &#123; --content-bg-color: rgb(0 0 0 / 0%); --text-color: #000; --waline-theme-color: #222 !important; --waline-color: #000 !important; --waline-bgcolor: rgb(0 0 0 / 0%) !important; --waline-bgcolor-light: rgb(0 0 0 / 0%) !important;&#125;.main-inner .sub-menu, .main-inner .post-block, .main-inner .tabs-comment, .main-inner &gt; .comments, .main-inner .comment-position .comments, .main-inner .pagination &#123; border-radius: 5px;&#125;.header &#123; border-radius: 5px;&#125;.sidebar-inner &#123; border-radius: 5px;&#125;.main-inner .tabs-comment, .main-inner &gt; .comments, .main-inner .comment-position .comments, .main-inner .pagination &#123; border-radius: 5px;&#125;.main-inner .post-block:not(:first-child):not(:first-child) &#123; border-radius: 5px;&#125;.darkmode--activated &#123; --content-bg-color: rgb(0 0 0 / 0%) !important; --waline-theme-color: #999 !important; --waline-color: #ccc !important;&#125;.posts-expand .post-title-link &#123; color: var(--text-color);&#125;.posts-expand .post-header &#123; margin-bottom: 0px;&#125;.post-button &#123; margin-top: 0px; text-align: right;&#125;p &#123; margin: 0 0 0px;&#125;.post-block, .comments &#123; padding: 15px;&#125;.posts-expand .post-title &#123; font-size: 1.2em; font-weight: bold;&#125;.post-tags a &#123; display: contents;&#125; 修改主题配置文件12custom_file_path: style: source/_data/styles.styl 文章页眉显示标签 在blog/source/_data文件夹下新建post-meta.njk并编辑12345678910&lt;span class=&quot;post-meta-item&quot;&gt; &#123;%- if post.tags and post.tags.length %&#125; &#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27; if theme.tag_icon else &#x27;#&#x27; %&#125; &lt;span class=&quot;post-tags&quot;&gt; &#123;%- for tag in post.tags.toArray() %&#125; &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&#123;&#123; tag_indicate &#125;&#125; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;%- endfor %&#125; &lt;/span&gt; &#123;%- endif %&#125;&lt;/span&gt; 修改主题配置文件12custom_file_path: postMeta: source/_data/post-meta.njk 扩展 ## Hugo 框架和 DoIt 主题 NetlifyRailwayhttps://railway.app/Railway提供免费容器服务。支持主流语言python、nodejs等直接运行，支持Dockerfile在线构建docker镜像。支持使用CLI部署。此外，还提供大量模板直接构建。例如code server（vscode网页版）等。 不自动休眠，不自动删数据（手动重新部署当然会删），支持自定义域名，自动SSL加密。提供数据库支持，部署完成之后添加数据库插件即可。按量付费，每个月5美元免费额度，跑个小程序够用。具体可以参考定价。 部署railway支持三种部署方式： 通过Github repo进行部署，需要连接到你自己的特定仓库。如果你的仓库中有Dockerfile文件，则会自动解析。参见：Dockerfiles | Railway Docs 使用它们的CLI，这个我试用了下感觉体验不是很好。不太推荐。 通过自带的模板进行部署，例如code server。选择Deploy Starter即可 Vercelhttps://vercel.com/Vercel 是一个云服务平台，支持静态网站和动态网站的应用部署、预览和上线。如果你用过 GitHub Pages ，那么心里可能不会太陌生，但你也能通过 vercel 集成 GitHub 后后，在 GitHub 项目进行代码推送，PR合并自动部署的目的，且你不需要考虑服务器问题。Vercel 它是一个免费的网站托管平台，也是我目前用过最好的网站托管平台，不仅仅可以部署静态网站，而且还可以部署动态网站，所以我们可以拿 vercel 充当你免费的服务器，主要有以下好处。 关联 github，只需要往 github 提交代码，它会自动获取最新的提交，然后自动部署 提供了免费的域名，省去了申请域名的问题，如果有自己的域名，还可以做个域名解析到这个平台上 提供了免费的 Https 证书，如果证书到期了，它会自动替换，完全不需要操心 傻瓜式的部署方式，它的操作非常简单，Vercel 提供了两种方式：通过命令行部署、通过 Vercel 提供管理后台部署，这期视频我们主要介绍通过命令行部署，因为命令行的部署方式更加简单 Cloudflarestellar主题提交Github报错检查后发现是博客内容中包含了github的token明文。。。。","categories":["博客"]},{"title":"Linux下实现加密","path":"/2024/04/24/操作系统-Linux-加密-linux-crypto/","content":"加密技术通常分为两大类“对称式”和“非对称式”","categories":["操作系统","Linux","加密"]},{"title":"Nginx学习笔记","path":"/2024/04/09/软件-Nginx-Nginx-1/","content":"Nginx功能： Web服务器 负载均衡 API网关 DDoS防御 反向代理 Web应用防火墙 缓存 命令查看nginx版本 nginx -v 配置文件所在位置/etc/nginx，文件名nginx.conf 检查配置文件是否有问题 nginx -t 重新加载nginx配置文件 nginx -s reload 关闭nginx nginx -s quit或nginx -s stop events http server include listen server_name root 根目录节点 index 指定页面 return location &#x3D;(完全匹配) ~(启用正则表达式) rewrite 重写 proxy_pass curl 命令 是一个功能强大的命令行传输工具，用于发送请求和下载文件。它支持多种协议，如HTTP、HTTPS、FTP等，可以设置请求头、请求参数等 -i 参数 打印出服务器回应的 HTTP 标头","categories":["软件","Nginx"]},{"title":"3D打印机介绍","path":"/2024/04/02/其他-3D打印机-3D打印机介绍/","content":"FDM 3D打印机通过将加热的材料挤出打印头，逐层堆积形成打印件 打印头 打印床&#x2F;热床 控制系统（主板、电机、传感器和用户界面） 打印材料 G-Code *一种用于控制数控机床（包括3D打印机、数控铣床、数控车床等）运动和操作的编程语言。 结构：corexy硬件：MKS GEN_Lv2.1","tags":["3D打印机"],"categories":["其他","3D打印机"]},{"title":"Linux环境下终端的使用","path":"/2024/03/26/terminal/","content":"终端一个基于文本的交互界面 快捷键 打开命令行终端Ctrl+Alt+t 放大终端Ctrl Shirft + 缩小终端Ctrl - 终端提示符含义lemonade@ubuntu:~$对应用户名(lemonade)@主机名(ubuntu):工作目录(~) 提示符($) ~：家目录 $: 普通用户#: 超级用户(root) 命令—在终端中用于告诉计算机去执行一个动作 参数— 选项—选项通常用一个连接号（-）或两个连接号（--）来划分 常用 ls: 列出当前目录内容 cd ~: 进入当前用户的家目录 ./当前目录(可省略) ../上一层目录 ../../ 上一层的上一层 文件操作指令 mkdir 创建文件夹 mkdir mydir touch 创建空文件 touch myfile rmdir删除一个空文件夹 rm 删除一个文件或文件夹,默认删除文件 rm -r 删除文件夹 打印定向指令 echo 打印一串字符 echo hello world &gt; 输出重定向&#x2F;指定输出的目标文件 &gt;&gt; 向指定文件中追加内容 cat 读文件内容并打印 cat readme root&amp;sudo sudo passwd 通过普通用户修改超级用户(root)的密码. su root 切换用户为root用户(超级用户) su lemonade 切换为lemonade用户. sudo 用普通用户权限执行root的功能 普通用户权限执行root的功能需注意用户环境下的环境变量和root用户环境的下环境变量是否一致 移动拷贝指令 mv 移动命令mv source dest``mv source dir cp 拷贝命令 man 用户帮助手册 man ls ls [options]... [file]... options选项或参数 file目标文件或文件夹 []可选标志 ... 多参机制 改变权值的命令 chmod 777 readme.sh 所有用户可读可写可执行 文件类型: - ：普通文件d : 文件夹&#x2F;目录l : 链接(快捷方式)s : 网络套接字p: 管道b : 块设备, 磁盘 c : 字符设备, 键盘 关机 halt 关机 reboot 重启 sudo shutdown -h now 加上关机时间 sudo shutdown -h +1 &quot;See You la la&quot; 加上关机备注 开机自启动设置服务编辑或创建/usr/lib/systemd/system/startmyapp.service文件 123456789101112131415[Unit] #服务的说明Description=nginx #描述服务After=network.target #描述服务类别[Service] #服务运行参数的设置Type=forking #是后台运行的形式PIDFile=/var/run/nginx.pidExecStartPre=/usr/bin/nginx -t -c ./nginx.confExecStart=/usr/bin/nginx -c ./nginx.conf #服务的具体运行命令ExecReload=/bin/kill -s HUP $MAINPID #重启命令ExecStop=/bin/kill -s QUIT $MAINPID #停止命令PrivateTmp=true #给服务分配独立的临时空间[Install] #运行级别下服务安装的相关设置WantedBy=multi-user.target #设置为多用户，系统运行级别为3 操作服务 12345678910111213141516171819# 设置开机自启动systemctl enable startmyapp.service# 停止开机自启动systemctl disable startmyapp.service# 启动服务systemctl start startmyapp.service# 关闭服务systemctl stop startmyapp.service# 重新启动服务systemctl restart startmyapp.service# 重新加载服务配置文件systemctl reload startmyapp.service# 查看服务当前状态systemctl status startmyapp.service# 查看所有已启动的服务systemctl list-units --type=services# 查询服务是否开机启动systemctl is-enabled startmyapp.service 设置脚本1234567vi /etc/rc.local# 添加启动脚本/usr/bin/nginx startchmod +x /etc/rc.d/rc.local# /etc/rc.d/rc.local是/etc/rc.local的软连接","tags":["Linux"]},{"title":"ffmpeg简介","path":"/2024/03/22/软件-Ffmpeg-other-ffmpeg/","content":"FFmpeg","tags":["其他"],"categories":["软件","Ffmpeg"]},{"title":"3. 正则表达式笔记","path":"/2024/03/12/语言-regular/","content":"正则表达式什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。 正则表达式就是记录文本规则的代码，用于模式匹配和搜索文本的工具。 正则表达式的模式 字面值字符：普通字符按照字面意义进行匹配,例如字母、数字、空格等，可以直接匹配它们自身。 特殊字符：例如点号 .、星号 *、加号 +、问号 ? 等，它们具有特殊的含义和功能。 字符类：用方括号 [ ] 包围的字符集合，用于匹配方括号内的任意一个字符。[^ ]匹配除了括号内的字符以外的任意一个字符 元字符：例如 \\d、\\w、\\s 等，用于匹配特定类型的字符，如数字、字母、空白字符等。 量词：例如 &#123;n&#125;、&#123;n,&#125;、&#123;n,m&#125; 等，用于指定匹配的次数或范围。 边界符号：例如 ^、$、\\b、\\B 等，用于匹配字符串的开头、结尾或单词边界与非边界位置。 分组和捕获：( )：用于分组和捕获子表达式。(?: )：用于分组但不捕获子表达式。 字符字符匹配直接在方括号里列出： [aeiou]就匹配任何一个英文元音字母 [.?!]匹配标点符号(.或?或!) 也可以指定一个字符范围： [0-9]代表的含意与\\d就是完全一致的：一位数字 [a-z0-9A-Z_]也完全等同于\\w。 普通字符 字符 含义 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（ 、\\r）之外的任何单个字符，相等于 [^ \\r]。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_] 非打印字符 字符 含义 \\cx 匹配由x指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 特殊字符 字符 含义 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则$ 也匹配 ‘ ’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。 * 匹配前面的子表达式零次或多次。要匹配 *字符，请使用*。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。 . 匹配除换行符 之外的任何单字符。要匹配 . ，请使用 . 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 [。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’ ’ 匹配换行符。序列 ‘&#39; 匹配 “&quot;，而 ‘(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用^。 { 标记限定符表达式的开始。要匹配 {，请使用 {。 | 指明两项之间的一个选择。要匹配|，请使用 |。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。例如IP地址表达式:((2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?).)&#123;3&#125;(2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?) 限定符 字符 含义 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于 {0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 “do” 、 “does”、 “doxy” 中的 “do” 和 “does”。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于o*。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 含义 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 或 \\r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 或 \\r 之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 不能将限定符与定位符一起使用。由于在紧靠换行或者单词边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式 转义字符与反义字符 在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。 反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法(?#comment)来包含注释 IP地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以a开始，以b结束的字符串。 如果用它来搜索aabab的话，它会匹配整个字符串aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。 前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样.*?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 现在看看懒惰版的例子吧： a.*?b匹配最短的，以a开始，以b结束的字符串。如果把它应用于aabab的话，它会匹配aab（第一到第三个字符）和ab（第四到第五个字符）。 运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?&#x3D;), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，”或”操作,字符具有高于替换运算符的优先级，使得&#96;m 反向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。 反向引用用于重复搜索前面某个分组匹配的文本。例如，\\1代表分组1匹配的文本。 分组0对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b可以用来匹配重复的单词，像go go, 或者kitty kitty。 总结 确定需要匹配的基本字符或字符类别&#x2F;集合等 确定匹配的字符或字符集合的数量 特殊字符和转义字符的处理 边界和位置的匹配 使用捕获组()进行多组匹配 使用反向引用 使用逻辑操作符进行判定 正则表达式字符含义表正则表达式字符含义表 字符 含义 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 “n”。\\ 匹配一个换行符。序列 \\\\ 匹配 “\\ 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配\\ 或 \\\\r 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配\\ 或 \\\\r 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o&#123;2&#125; 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，o&#123;2,&#125; 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o&#123;1,&#125; 等价于 o+。o&#123;0,&#125; 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。o&#123;0,1&#125; 等价于 o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，o+? 将匹配单个 “o”，而 o+ 将匹配所有 o。 . 匹配除换行符（ 、\\r）之外的任何单个字符。要匹配包括\\ 在内的任何字符，请使用像&#96;(. )&#96;的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用( 或 )。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (&#96; ) 来组合一个模式的各个部分是很有用。例如， industr(?:y (?&#x3D;pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，&#96;Windows(?&#x3D;95 98 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如&#96;Windows(?!95 98 (?&lt;&#x3D;pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，&#96;(?&lt;&#x3D;95 98 (? 反向否定预查，与正向否定预查类似，只是方向相反。例如”(?”能匹配”3.1Windows”中的”Windows”，但不能匹配”2000Windows”中的”Windows”。 &#96;x y&#96; 匹配 x 或 y。例如，&#96;z [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 “plain” 中的 a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，[^abc] 可以匹配 “plain” 中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\\\\b 可以匹配”never” 中的 er，但不能匹配 “verb” 中的 er。 \\B 匹配非单词边界。er\\\\B 能匹配 “verb” 中的 er，但不能匹配 “never” 中的 er。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的c 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\\\x41 匹配 “A”。\\\\x041 则等价于 \\\\x04 &amp; “1”。正则表达式中可以使用 ASCII 编码。 um 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)\\\\1 匹配两个连续的相同字符。 标识一个八进制转义值或一个向后引用。如果 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 m 标识一个八进制转义值或一个向后引用。如果 m 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 m 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 m 将匹配八进制转义值 nm。 ml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。 &#96;","tags":["语言"],"categories":["语言"]},{"title":"2. Shell笔记","path":"/2024/03/12/语言-解释型-shell/","content":"待补充","tags":["语言"],"categories":["语言","解释型"]},{"title":"1. Markdown笔记","path":"/2024/03/12/语言-markdown/","content":"Markdown 笔记语法表格 &amp; 文本样式 样式 语法 示例 加粗 前后** 或 __ 加粗1 加粗2 斜体 前后* 或 _ 斜体1 斜体2 删除线 前后~~ 删除线 内联代码 前后 &#96; code 下划线 前&lt;u&gt; 后 &lt;/u&gt; 下划线 高亮 前后== &#x3D;&#x3D;高亮文本&#x3D;&#x3D; 引用 此内容为引用内容 链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接 Blog网址 图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中 图片可拖动为文件到任意窗口使用 无序列表 项目 项目 1 项目 A 项目 B 项目 2 有序列表 项目 1 项目 A 项目 B 项目 2 任务列表 A 计划 A1 计划 A2 计划 B 计划 代码块代码块支持 168 种编程语言 12345678910111213141516// javascript 冒泡排序function bubbleSort(array) &#123; let swapped = true; do &#123; swapped = false; for (let j = 0; j &lt; array.length; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; let temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; swapped = true; &#125; &#125; &#125; while (swapped); return array;&#125; KaTeX 数学公式内联公式质能方程 $E&#x3D;mc^2$ 公式块$$\\displaystyle \\left( \\sum_{k&#x3D;1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k&#x3D;1}^n a_k^2 \\right) \\left( \\sum_{k&#x3D;1}^n b_k^2 \\right)$$","tags":["语言"],"categories":["语言"]},{"title":"3D打印机环境配置","path":"/2024/03/12/其他-3D打印机-3D打印机环境配置/","content":"OctoPrint和Fluidd二选一安装配置即可。 Klipper安装获取klipper源码git clone https://github.com/Klipper3d/klipper执行脚本安装一些系统依赖、设置./klipper/scripts/install-octopi.sh*安装很慢时，可以更换下pip的源pip下载网络问题 然后配置和构建 123cd ~/klipper/make menuconfigmake 需要确定连接到微控制器的串行端口 12ls /dev/serial/by-id/*ls /dev/ttyUSB* 可以用类似以下的方法来刷写固件： 123sudo service klipper stopmake flash FLASH_DEVICE=/dev/ttyUSB0sudo service klipper start *刷写时要确保 端口没有被占用 配置打印机配置文件，一般在用户主目录中名为printer.cfg的文件/home/linux/printer.cfg。 刷写Klipper后，名称可能会改变，检查USB节点名称： 123ls /dev/serial/by-id/*或者ls /dev/ttyUSB* 确认节点名称并写入配置文件中去。 123/dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0或者/dev/ttyUSB0 用这个唯一的名字更新配置文件。更新[mcu]部分，类似于： 12[mcu]serial: /dev/ttyUSB0 在编辑该文件后，发出 restart 或 FIREWARE_RESTART 命令以重新加载配置（命令根据实际上位机）。如果Klipper配置文件被成功读取，并且成功找到并配置了微控制器，那么”status”命令将报告打印机已准备就绪。*默认的Klipper启动脚本也在&#x2F;tmp&#x2F;klippy.log中放置一个日志，提供更详细的信息。 OctoPrint安装应该在虚拟环境中完成，以帮助防止依赖性冲突。首先设置 Python、依赖项和虚拟环境。 123456sudo apt updatesudo apt install python3 python3-pip python3-dev python3-setuptools python3-venv git libyaml-dev build-essential libffi-dev libssl-devmkdir OctoPrint &amp;&amp; cd OctoPrintpython3 -m venv venvsource venv/bin/activate 然后可以使用以下命令安装 OctoPrint 及其 Python 依赖项pip：pip install pip --upgradepip install octoprint*如果安装了旧版本的 OctoPrint，pip可能仍然有一些缓存。在那种情况下添加--no-cache-dir到安装命令，例如pip install --no-cache-dir octoprint要使这个永久的、干净的pip缓存：rm -r ~/.cache/pip 在启动 OctoPrint 之前，添加用户权限，以便用户可以访问串行端口：sudo usermod -a -G tty pisudo usermod -a -G dialout pi您可能必须注销并重新登录才能使这些更改生效。 之后使用octoprint serve命令启动 OctoPrint 服务器： 1234pi@raspberrypi:~ $ ~/OctoPrint/venv/bin/octoprint serve2020-11-03 17:39:17,979 - octoprint.startup - INFO - ***************************2020-11-03 17:39:17,980 - octoprint.startup - INFO - Starting OctoPrint 1.4.22020-11-03 17:39:17,980 - octoprint.startup - INFO - *************************** 访问http://&lt;pi&#39;s IP&gt;:5000 配置OctoPrint网络服务器需要进行配置，以便与Klipper host 软件进行通信。使用网络浏览器，登录到OctoPrint网页，然后配置以下项目： 导航到 “设置 “（页面顶部的扳手图标）。在 “串行连接 “下的 “附加串行端口 “中添加”&#x2F;tmp&#x2F;printer”。然后点击 “保存”。 再次进入 “设置”，在 “串行连接” 下将 “串行端口” 设置改为”&#x2F;tmp&#x2F;printer”。 在 “设置 “中，浏览到 “Behavior “子选项卡，选择 “取消任何正在进行的打印，但保持与打印机的连接 “选项。点击 “保存”。 在主页上，在 “连接 “部分（在页面的左上方），确保 “串行端口 “被设置为”&#x2F;tmp&#x2F;printer”，然后点击 “连接”。(如果”&#x2F;tmp&#x2F;printer “不是一个可用的选择，那么试着重新加载页面) 连接后，导航到 “终端 “选项卡，在命令输入框中输入 “status”（不带引号），然后点击 “发送”。终端窗口可能会报告在打开配置文件时出现了错误–这意味着 OctoPrint 与 Klipper 成功地进行了通信。 需要继续配置klipper的print.cfg文件。 FluiddFluidd适用于3D打印机的Klipper固件，提供WEB页面和控制。项目地址 https://github.com/fluidd-core/fluidd KIAUH安装项目地址 https://github.com/dw-0/kiauh安装 git 后，克隆 KIAUH 项目git clone https://github.com/dw-0/kiauh.git启动KIAUH./kiauh/kiauh.shKIAUH 的主菜单中。您将看到多个操作可供选择，具体取决于您想要执行的操作。要选择操作，只需在“执行操作”提示中输入相应的数字，然后按 ENTER 确认即可。 手动安装Fluidd 附带一个build脚本，可在项目地址https://github.com/fluidd-core/fluidd/releases 的fluidd.zip中找到。需要安装NodeJS (v16.x) 和 Git克隆Fluidd 源代码git clone https://github.com/fluidd-core/fluidd.git导航到 Fluidd 源代码目录cd fluidd安装依赖npm ci构建并捆绑 Fluiddnpm run build 构建的文件将写入该dist目录。您可以使用您首选的 HTTP 服务器来提供这些服务，例如NGINX。*要出于开发目的构建 Fluidd，请运行npm run serve而不是npm run build启用热重载。 配置热床找平及各限位开关触发状态","tags":["3D打印机"],"categories":["其他","3D打印机"]},{"title":"Git常用操作","path":"/2024/03/12/软件-Git-Git常用操作/","content":"项目创建对于网络项目git clone [url]将GitHub中的网络项目复制到本地，只需在修改完之后commit即可，然后更新仓库代码，就可同步修改。 对于本地项目首先要创建一个文件夹用以存放文件，然后使用 git init 对进行初始化操作 git status 得到git中文件的状态 git add filename 将filename文件加入到git本地仓库中去（git rm -cached 可移除） git commit -m ‘status’ 表示提交信息（status表示附加信息） 之后对本地项目进行关联 git remote add origin [url] 添加本地到远程origin仓库 git remote -v 查看当前项目有哪些远程仓库 关联之后可以向远程仓库提交代码（更新仓库代码） 日常push git status #获取状态 git add . #添加文件到暂存区 git commit -m &quot;20191121 push&quot; #提交文件 git push origin master #推送 日常pull git diff 比较工作目录和 Index 中的代码。 git fetch 当于从远程获取最新版本到本地，不会自动merge ，比 Git pull 更安全些 git checkout app/model/user.rb 将 user.rb 文件从上一个已提交的版本中更新回来，未提交的工作目录中的内容全部会被覆盖 首次使用配置ssh ssh-keygen -t rsa ssh -T &lt;git@github.com&gt; 首次使用设置用户 git config (--global) user.name &quot;username&quot; git config (--global) user.email &quot;&lt;username@gmail.com&gt;&quot; 上传&#x2F;下载常用命令 git push origin（仓库名） master（分支） 更新仓库代码（上传） git pull origin（仓库名） master（分支） 更新本地代码（下载） 回退历史版本 git log git reset --hard \\[commit\\_id] git revert \\[commit\\_id] 网络项目 git clone \\[url] git remote add origin \\[url] 添加本地到远程origin仓库 git remote -v 查看当前项目有哪些远程仓库 版本情况 git tag 查看版本情况 git tag V1.0 新建版本 git checkout V1.0 切换至版本V1.0 分支情况 git branch 查看当前分支情况 git checkout a 切换到分支a git checkout -b a 新建分支a并切换到分支a git branch -d a 删除a分支 git merge a 将a分支的代码合并到master分支上 撤销或回退在Git中，撤销和回退是指撤销或回退先前的提交或更改。 简单介绍下Git中的撤销和回退操作，以及如何使用它们来管理代码库。 #可以把版本库上的提交回退到暂存区，修改记录保留git reset –-soft []#可以把版本库上的提交回退到工作区，修改记录保留git reset –-mixed []#可以把版本库上的提交彻底回退，修改的记录全部revert。git reset –-hard reset和revert的区别git reset 和 git revert 的主要区别在于它们对历史记录的处理方式。git reset 会删除历史记录并永久删除更改，而 git revert 会创建一个新的提交来撤销更改并保留历史记录。 git reset命令会将 HEAD 指针指向指定的 commit，并将暂存区和工作目录恢复到该 commit 的状态。这意味着在执行 git reset 后，之前的更改将不再存在于工作目录和暂存区中。如果您希望永久删除一些更改并且不再需要它们，可以使用 git reset。 git revert 命令会创建一个新的提交来撤销指定的提交。这意味着在执行 git revert 后，之前的更改仍然存在于工作目录和暂存区中，并且您需要提交一个新的撤销提交。如果您想要保留更改历史记录并且不想永久删除更改，可以使用 git revert。 获取IDgit log获取到想要回退的commit_id 撤销&#x2F;回退未提交的更改**(add之后，commit之前)**要撤销未提交的更改，请使用以下命令： git checkout &lt;file-name&gt;将名为file-name的文件恢复到上一个提交的状态。 本地本次的更改也不再保存，恢复到上一个提交(commit)的状态 git reset HEAD --file 回退暂存区里的某个文件，回退到当前版本工作区状态 保存工作区的更改，只是撤销git add这一步操作 git checkout .将所有文件恢复到最新提交的状态。请注意，此操作将删除所有未提交的更改。 撤销&#x2F;回退上一个提交**(commit之后，push之前)**撤销上一个提交 git reset HEAD~1将HEAD指针移动到上一个提交。 工作区保留先前的更改，需要重新添加到暂存区(git add) 回退到上一个提交 git reset --hard HEAD~1将HEAD指针和工作树都重置为上一个提交的状态。 请注意，此操作将删除所有未提交(commit)的更改。 撤销&#x2F;回退到特定的提交**(push之后)**撤销到特定版本 git revert &lt;commit_id&gt;这将创建一个新的提交，该提交撤销名为commit-hash的提交所做的更改。 本次撤销操作也会作为一次提交(push)进行保存 回退到特定版本 git reset --hard &lt;commit_id&gt;将HEAD指针和工作树都重置为名为commit-hash的提交的状态。 请注意，此操作将删除所有未提交的更改。 回退完成后，git push -f 强制提交 分支Git是一个流行的分布式版本控制系统，一般都是存在多个分支的，开发分支，回归测试分支以及主干分支等 在Git中，分支是指指向Git提交历史中某个特定提交的指针。 每个分支都包含在Git提交历史中的一系列提交，这些提交构成了分支的历史记录。 分支在Git中非常重要，因为它们允许多个开发人员同时在同一个代码库中工作，而不会相互干扰。 通过创建分支，每个开发人员都可以在自己的分支上进行工作，而不会影响其他人的工作。 这样，开发人员可以在不干扰其他人的情况下，独立地开发和测试新功能，最终将这些更改合并到主分支中。 在Git中，分支操作非常简单。以下是一些常用的Git分支操作： 创建分支要创建一个新分支，请使用以下命令： git branch &lt;branch-name&gt;这将创建一个名为branch-name的新分支。 注意，此时仍然在当前分支上工作。 git checkout -b &lt;branch-name&gt;新建一个分支，并且切换到新的分支branch-name 查看分支要查看所有分支，请使用以下命令： git branch这将列出所有分支，当前分支将用一个星号标记。 git branch -r 查看所有远程的分支 git branch -a 查看所有远程分支和本地分支 删除分支要删除一个分支，请使用以下命令： git branch -d &lt;branch-name&gt;这将删除名为的分支。 注意，如果该分支包含未合并的更改，则必须使用-D选项而不是-d选项来强制删除该分支。 切换分支要切换到另一个分支，请使用以下命令： git checkout &lt;branch-name&gt;这将使您从当前分支切换到名为branch-name的分支。 注意，需要在切换分支之前将所有更改提交或保存。 合并分支要将一个分支合并到另一个分支，请使用以下命令： git merge &lt;branch-name&gt;将名为branch-name的分支合并到当前分支中。 注意，如果两个分支上都有对同一文件的更改，则可能会发生冲突。在这种情况下，需要手动解决冲突并提交更改。 git merge –no-ff origin&#x2F;dev 在当前分支上合并远程分支dev git merge –abort 终止本次merge，并回到merge前的状态 以上是一些常用的Git分支操作。使用这些操作，您可以轻松地创建、切换、合并和删除分支。这些操作使多人协作变得更加容易，因为每个开发人员都可以在自己的分支上进行工作，并将更改合并到主分支中。在实际开发中，分支操作是非常重要的，最好能够熟练掌握并运用这些操作 标签在 Git 中，tag 是用于标记某个特定提交的名称。它类似于一个快照，可以用于标记版本、发布或重要的里程碑。Git 中有两种类型的 tag：轻量级标签和附注标签。 轻量级标签是一个简单的指向某个特定提交的引用，类似于一个分支，但不会随着新的提交而移动。创建轻量级标签的方法很简单，只需在命令行中输入 git tag &lt;tag-name&gt; 即可。例如，git tag v1.0 将创建一个名为 v1.0 的轻量级标签。 附注标签是一个包含标签名称、标签创建者、标签创建日期和标签说明的 Git 对象。它们是 Git 中最常用的标签类型，可以用于发布版本、重要的里程碑和其他重要的提交。创建附注标签的方法是使用 -a 标志和标签名称，然后输入标签说明。例如，git tag -a v1.0 -m &quot;Release version 1.0&quot; 将创建一个名为 v1.0 的附注标签，并将其说明设置为 “Release version 1.0”。 标签可以使用 git push 命令推送到远程存储库中，以便在其他计算机上使用。例如，要将名为 v1.0 的标签推送到远程存储库，可以使用 git push origin v1.0 命令。 1234567git tag #列出所有taggit tag [tag] #新建一个tag在当前commitgit tag [tag] [commit] #新建一个tag在指定commitgit tag -d [tag] #删除本地taggit push origin [tag] #推送tag到远程git show [tag] #查看特定taggit checkout -b [branch] [tag] #新建一个分支，指向某个tag","tags":["Git"],"categories":["软件","Git"]},{"title":"Git服务器环境搭建和客户端使用","path":"/2024/03/12/软件-Git-Git服务器环境搭建和客户端使用/","content":"服务端安装git和ssh sudo apt-get install gitsudo apt-get install openssh-server openssh-client 增加git用户并生成文件夹 sudo adduser git sudo mkdir /home/git 创建ssh证书认证文件 sudo mkdir /home/git/.sshsudo touch /home/git/.ssh/authorized_keys 临时修改authorized_keys文件的权限 sudo chmod 777 /home/git/.ssh/authorized_keys 把需要访问git服务器的客户端公钥id_rsa.pub的内容复制到authorized_keys文件 修改authorized_keys文件的权限 1234567sudo chmod 700 /home/gitsudo chmod 700 /home/git/.sshsudo chmod 600 /home/git/authorized_keyssudo chown -R git:git /home/gitsudo chown -R git:git /home/git/.sshsudo chown -R git:git /home/git/.ssh/authorized_keys``` 为了安全考虑禁止登录git服务器的shell，修改git的shell 用/usr/bin/git-shell把/etc/passwd的 git:x:1004:1004:,,,:/home/git:/bin/bash 改成： git:x:1004:1004:,,,:/home/git:/usr/bin/git-shell保存 建代码仓库 sudo mkdir /home/Repo #创建仓库的目录 sudo git init --bare /home/Repo/test.git #创建仓库 sudo chown -R git:git /home/Repo/test.git #修改权限为git 以后每创建一个新的仓库，记得最后一步操作: 修改仓库所属用户为git。 客户端安装git Linux环境下 sudo apt-get install git Windows环境下直接安装Git安装包 配置连接 通过密钥方式 ssh-keygen -t rsa [-C &quot;你的邮箱地址&quot;]会生成id_rsa.pub文件 添加该公钥到到服务器 Linux环境下，密钥默认位于/home/ubuntu/.ssh/id\\_rsa Windows环境下密钥位于C:\\Users\\xxx.ssh\\id\\_rsa.pub 通过用户名&#x2F;密码 12git config –global user.name “username”git config –global user.email “username@gmail.com” 在连接git时，会需要输入账号密码，直接输入即可 附注：增量备份-Git服务器备份使用crontab建立每天凌晨3点定时触发的任务crontab -e 0 3 * * * * rsync -av -e &quot;ssh -i /path/to/id_rsa&quot; /homt/git/ remote_user@X.X.X.X:~/backup","tags":["Git"],"categories":["软件","Git"]},{"title":"Git介绍和基本命令","path":"/2024/03/12/软件-Git-Git介绍和基本命令/","content":"版本控制版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 Git是免费、开源的分布式版本控制系统。 集中式版本控制系统集中管理的中央服务器，保存着所有文件的修改历史版本。 协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。 分布式版本控制系统远程仓库同步所有版本信息到本地的每个用户 本地可以查看所有的历史版本信息，偶尔远程更新，查看其他用户修改提交到远程 用户即使离线也可以本地提交，push推送到远程服务器才需要联网 每个用户都保存了历史版本 工作区域Workspace：电脑本地看到的文件和目录，在Git的版本控制下，构成了工作区。 Index&#x2F;Stage：暂存区，一般存放在.git目录下，即.git&#x2F;index,它又叫待提交更新区，用于临时存放你未提交的改动。执行git add，这些改动就添加到这个区域。 Repository：本地仓库，你执行git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中HEAD指向最新放入仓库的版本。当你执行git commit，文件改动就到本地仓库。 Remote：远程仓库，云端版本库 文件状态Untracked: 文件未加入到git库，未参与版本控制，处于未跟踪状态。通过git add，可以变为Staged状态 Unmodified：文件已经加入git库，版本库中的文件快照内容与文件夹中还完全一致。 Unmodified的文件如果被修改, 就会变为Modified。如果使用git remove移出版本库，则成为Untracked文件。 Modified：文件被修改进入modified状态，文件这个状态通过stage命令可以进入staged状态 staged：暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodified状态。 正向工作流git 的正向工作流程一般就这样： 从远程仓库拉取文件代码回来；git pull 在工作目录，增删改文件； 把改动的文件放入暂存区；git add 将暂存区的文件提交本地仓库；git commit 将本地仓库的文件推送到远程仓库；git push 常用命令123456789101112131415161718192021222324git clone [url] #克隆远程仓库git add [dir/file]#添加目录/文件到暂存区git commit [--amend] -m [msg] #提交暂存区到仓库区,msg为说明信息(amend用新的commit覆盖提交)git log [--oneline] [-p [file]]#查看提交历史(online精简模式)(p指定文件)git blame #列表方式查看指定文件的提交历史git diff #显示暂存区和工作区的差异git diff #显示暂存区和工作区的差异git diff filepath #filepath路径文件中，工作区与暂存区的比较差异git diff HEAD filepath #工作区与HEAD ( 当前工作分支)的比较差异git diff branchName filepath #当前分支文件与branchName分支的文件的比较差异git diff commitId filepath #与某一次提交的比较差异git status [-s] [--show-stash] #查看当前工作区暂存区变动(-s概要信息)（show-stash显示暂存文件）git pull/fetch #拉取远端代码#git pull = git fetch+ git merge。pull的话，拉取远程分支并与本地分支合并#fetch只是拉远程分支，怎么合并，可以自己再做选择。git pull #拉取远程仓库所有分支更新并合并到本地分支。git pull origin master #将远程master分支合并到当前本地master分支git pull origin master:master #将远程master分支合并到当前本地master分支，冒号后面表示本地分支git fetch --all #拉取所有远端的最新代码git fetch origin master #拉取远程最新master分支代码git push #推送到远端git push origin master #将本地分支的更新全部推送到远程仓库master分支。git push origin -d #删除远程branchname分支git push --tags #推送所有标签 123456789101112131415161718192021222324252627# git rebase`rebase`又称为衍合，是合并的另外一种选择。 `rebase`好处是： 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：`git pull --rebase`# git stash`stash`命令可用于临时保存和恢复修改git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作git stash list 显示保存的工作进度列表git stash pop stash@&#123;num&#125; 恢复工作进度到工作区git stash show ：显示做了哪些改动git stash drop stash@&#123;num&#125; ：删除一条保存的工作进度git stash clear 删除所有缓存的stash。# git reflog显示当前分支的最近几次提交# git blame`git blame filepath`记录了某个文件的更改历史和更改人# git remotegit remote 查看关联的远程仓库的名称git remote add url 添加一个远程仓库git remote show [remote] 显示某个远程仓库的信息","tags":["Git"],"categories":["软件","Git"]},{"title":"1. 博客服务器环境部署","path":"/2024/03/10/Server-Setup/","content":"更新软件包sudo apt update 更新nodejs到最新版本卸载自带的nodejs sudo apt autoremove nodejs sudo apt purge nodejs 安装20版本的nodejs curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp; sudo apt-get install -y nodejs 查看版本是否更新，否则关闭命令行重新打开 nodejs -v 安装nodejs安装工具到全局 sudo npm install n -g 安装稳定版本nodejs sudo n stable 安装npmsudo apt install npm -y FTP配置-用于图床安装ftp服务端 sudo apt install vsftpd -y 修改配置文件 sudo vi &#x2F;etc&#x2F;vsftpd.conf #禁止匿名访问anonymous_enable&#x3D;NO#接受本地用户local_enable&#x3D;YES#允许上传write_enable&#x3D;YES #更改创建文件权限 local_umask&#x3D;022 重启服务 sudo service vsftpd restart 创建FTP用户 sudo useradd -d &#x2F;home&#x2F;lemonade -M lemonade sudo passwd lemonade Mysql环境搭建安装mysql sudo apt install mysql-server -y sudo service mysql status # 查看服务状态sudo service mysql start # 启动服务sudo service mysql stop # 停止服务sudo service mysql restart # 重启服务 查看并更新密码 sudo cat /etc/mysql/debian.cnf 采用默认用户名密码登录 mysql -u *** -p 更新root用户密码 ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;newpasswd&#39;; 退出后，用root用户确认正常登录 mysql -u root -p newpasswd 创建Qexo要使用表 create database qexo; Python环境安装安装编译 Python 3.10 所需的依赖项： sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码： tar -xf Python-3.10.0.tgz 进入解压后的目录： cd Python-3.10.0 配置 Python 3.10 的编译选项： ./configure --enable-optimizations 编译并安装 Python 3.10： make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。 pip下载时出现网络问题 临时使用： 可以在使用pip的时候加参数-i https://pypi.tuna.tsinghua.edu.cn/simple 例如：pip install -i https://pypi.tuna.tsinghua.edu.cn/simple gevent，这样就会从清华这边的镜像去安装gevent库。 永久修改，一劳永逸： Linux下，修改 ~&#x2F;.pip&#x2F;pip.conf (没有就创建一个)， 修改 index-url至tuna，内容如下： [global]index-url &#x3D; https://pypi.tuna.tsinghua.edu.cn/simple windows下，直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，新建文件pip.ini，内容如下 [global]index-url &#x3D; https://pypi.tuna.tsinghua.edu.cn/simple nginx环境安装安装nginx sudo apt install nginx 访问公网IP，发现nginx页面安装成功 修改nginx配置文件sudo vi /etc/nginx/sites-enabled/default 修改完成后重启nginx服务sudo service nginx restart FRP内网穿透配置待补充","tags":["博客"]},{"title":"简历","path":"/about.html","content":"个人信息 姓名： 刘璐华 学历： 本科 出生年月: 1995.09 性别： 男 联系方式： 15756000566 英语： 四级 邮箱： &#x6c;&#x69;&#117;&#108;&#117;&#x68;&#117;&#x61;&#55;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d; 教育经历： 2013-2017 铜陵学院 电气工程及其自动化 工作经历 时间 公司 职位 工作内容 2017.02-2019.10 上海华之邦科技股份有限公司 嵌入式Linux软件工程师 嵌入式Linux环境搭建，数据库，触摸库，USB库等的移植工作，Linux环境下的Qt编程，开发文档，设计文档，API文档，操作手册等文档的编写 2019.10-2020.07 上海金标生物科技有限公司 Linux Qt高级工程师 嵌入式Linux开发板的选型及环境搭建，相关库的移植工作，Linux环境下软件代码的编写&#x2F;重构&#x2F;测试，通信协议的制定，相关文档的编写 2020.07-2021.10 无锡百泰克生物有限公司（上海分公司） 软件开发负责人 NAS部署与管理，redmine的部署与项目进度控制，PCR上位机架构设计，第三方设备的选型及环境搭建使用，上位机代码编写，相关文档的编写 2021.10-至今 安徽华明航空电子系统有限公司 Linux嵌入式软件工程师 Windows环境下的C++代码的开发工作，Linux平台环境的搭建，Windows平台向Linux平台下的迁移工作，窗口的重绘工作，相关设计&#x2F;测试文档的编写工作 奖项荣誉奖学金，优秀社团干部，优秀新人，优秀员工，优秀团队 专业技能 熟练使用Linux ，熟悉Linux环境配置及平台搭建（网络配置，内核配置，文件系统配置等） 熟练掌握Linux环境下的C++程序设计和Qt程序设计 熟练掌握多项外设的移植使用，如4G终端&#x2F;相机&#x2F;扫描模块等 熟练掌握Linux下的串口通讯、MODBUS通讯、TCP/IP通信、USB通信编程 熟悉Shell，会编写脚本用于辅助编译工作 了解Python，会利用Python进行相关的辅助工作 了解Docker及docker-compose，能够编写docker-compose脚本并运行docker服务 项目经历基于嵌入式Linux环境下的烟气在线监测系统（CEMS）&#x2F;水质在线检测设备功能：系统主要通过控制设备采集污染气体&#x2F;水质，在腔体内对污染气体&#x2F;的光学数据通过程序中的Matlab算法进行分析，得到污染物实时浓度，进行监测及上报给环保局。模块：软件系统分为PC端（数据存储与上报），ARM端（数据处理及程序控制），STM32端（动作执行），主要负责的职责涉及以下方面： 环境搭建：嵌入式Linux环境的交叉编译、裁剪 外部库移植：libusb&#x2F;libmodbus&#x2F;MQTT协议等通讯库向linux环境下的移植使用 代码编写：基于Qt4完成ARM端的代码编写及PC端上位机的后期维护工作 设备测试及文档：完成模块及系统测试，输出设计文档，开发文档，测试文档，操作文档等手册 现场调试：对于初始型号在现场调试并根据反馈结果迭代程序 难点： 移植工作，根据实际嵌入式环境编译脚本及编译选项 根据国产的**A3352(基于TI AM3352)**开发板进行嵌入式程序开发、调试 通过libusb等外部库实现USB协议和上位机通讯 实际现场问题的排查，影响设备运行的原因多种多样，包含电磁兼容性，信号屏蔽，电源&#x2F;地线稳定性，从硬件到外设的各方面原因 基于Windows&#x2F;Linux环境下的光谱仪的SDK开发功能：设备主要通过控制氙灯的闪烁频率，并采集CCD的相关数据用于CEMS中的光谱监测分析。模块：设备分为PC端（数据存储与分析），STM32端（动作执行），主要负责的模块涉及以下几个方面： 多平台开发：Windows及Linux环境下PC端代码开发 多通讯协议开发：TCP&#x2F;串口&#x2F;USB三种方式连接设备，并对设备进行操作 代码编写：基于Qt5完成PC端多平台代码的编写 基于Linux环境下的PCR设备&#x2F;心室辅助装置VAD的开发功能：PCR设备主要用于通过控制TEC升降温进行扩增及溶解，通过Basler相机采集荧光数据，通过Matlab算法进行分析，依据在每个循环的荧光数据通过阈值基线计算判断样品的阴阳性。功能：VAD设备主要用于压力传感器进行ms级监测血压并显示，通过手动设置泵的速度，帮助血液泵送到身体其他部位。 环境搭建：Matlab算法移植，相机支持库的配置及使用 通信协议：制定通讯协议，熟悉CAN协议，使用socketCAN进行通讯 代码编写：包括架构涉及，功能配置，业务逻辑 难点： 设计设备的升降温、电机旋转角度、相机数据采集和多线程处理的同步控制 针对不同设备间算法的兼容性及普适性测试及参数微调 根据国产的 OK3568(基于RK3568) 开发板进行嵌入式程序开发、调试 eVTOL航电模拟器系统的平台迁移工作和备份仪表的模块开发功能：系统主要用于飞机的六大仪表显示，飞行路径规划，机体相关信息显示。系统分为Windows和Linux双平台进行开发，其中Windows主要适用于模拟器，Linux主要适用于真机。主要涉及以下几个方面： 环境搭建：Linux环境部署及内核文件系统裁剪，内核实时性xenomai的方案学习 通讯协议：熟悉原来基于socket中间件的通信协议，并基于串口和CAN进行分解 代码迁移：将原来的Windows环境下的系统代码迁移到Linux环境下，并调试程序直至正常运行 窗口系统：为迁移后的程序在Qt环境下设计新的窗口系统 MES系统项目上线 完成MES项目一阶段验收 完成SAP对接测试上线工作 完成立库的一阶段上线 负责光伏项目整体进度推进，未完成项任务计划沟通制定、实施及变更控制 负责组件试运行期间问题清单需求收集、评审和进度跟进 负责组件MES系统迭代升级和测试验证 负责MES项目与各外围系统对接的相关测试及推进工作 负责向项目干系人工作进展和阶段性成果沟通汇报 负责组件MES项目风险识别、分析、反馈风险策略实施 负责组件MES项目用户支持、培训和运维保障 自我介绍 学习了解一些python相关的内容，比较基础，通过BeautifulSoup爬取一些自己想要的信息 在局域网内搭建了一台NAS，利用docker部署了一些nextcloud等应用，用于管理自己的所有资料 基于个人私有的云服务器，利用docker部署了自己的wordpress博客，记录一些学习内容和资料 完成一台3D打印机的DIY工作，搭建了web端的fluidd上位机，连接klipper固件的主板，调试完成3D打印"}]