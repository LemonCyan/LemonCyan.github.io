[{"title":"切换开销","path":"/2024/12/19/1-语言-C语言-多线程-切换开销/","content":"进程屏蔽了 CPU 调度、内存管理等底层硬件细节，从而定义了一个简单易懂的概念，让应用程序能够更专心地实现自己的业务逻辑。这样一来，多个进程在有限的 CPU 资源上可以“同时”执行多个任务，比如同时响应成千上万的用户请求。然而，这种便利性也伴随着额外的开销。以下图示例为例，在一个进程得以运行的时间里，CPU 虽然忙于事务，却可能并未完成任何实际的用户工作，这正是进程机制带来的额外开销。 当进程 A 切换到进程 B 时，系统会先保存进程 A 的上下文信息，以确保其未来恢复时能够继续执行下一条指令。接着，系统会将进程 B 的上下文恢复到 CPU 寄存器中。这个过程称为上下文切换。上下文切换的开销在进程数量较少且切换频率不高的场景下问题不大，但在现代 Linux 操作系统中，随着高并发网络程序后端服务器的普及，这一开销变得不容忽视。在单台机器上支持成千上万个用户请求时，进程在执行网络 IO 操作（如访问 Redis 或 MySQL）时或当时间片耗尽时，都会触发上下文切换。 为了直观了解一次上下文切换需要多长时间，让我们进行一个实验。实验方法是创建两个进程，互为令牌的发送者和接收者。其中一个进程在接收令牌时会引发阻塞，而另一个进程在发送令牌后等待其被接收时也处于阻塞状态。我们可以统计经过一定次数往返传送后的平均单次切换时间开销。实验代码见 test04： # gcc main.c -o main# ./main 在实验运行后，我们得到如下结果： Before Context Switch Time: 1565352257 s, 774767 usAfter Context Switch Time: 1565352257 s, 842852 us 经过多次运行，我们发现平均每次上下文切换耗时约为 3.5 微秒。值得注意的是，这一数值会因具体机器配置和负载而有所差异，因此建议在实际机器上进行测试。之前测试系统调用时，最低值是 200 纳秒，因此可以明显看出上下文切换的开销比系统调用更为显著。系统调用仅需在用户态和内核态之间切换，而上下文切换则需要进行进程间的切换，工作量显然更大。 上下文切换的开销来源上下文切换时，CPU 的开销可分为直接开销和间接开销。 直接开销：在上下文切换过程中，CPU 必须完成的操作，包括： 切换页表全局目录 切换内核态堆栈 切换硬件上下文（在恢复进程前，必须将数据加载到寄存器中） **ip (instruction pointer)**：指向当前执行的下一条指令 **bp (base pointer)**：栈帧的栈底地址 **sp (stack pointer)**：栈帧的栈顶地址 cr3：页目录基址寄存器，保存页目录表的物理地址 刷新 TLB（Translation Lookaside Buffer） 执行系统调度器代码 间接开销：即便切换到了新进程，由于缓存热度下降，运行速度往往会减缓。这种影响特别明显当进程跨 CPU 切换时，因为原先在缓存（如 L1、L2、L3）中热度高的代码和数据，随着进程的切换会失效，从而增加了内存 IO 的开销。我们的实验对这种间接开销的测量并不理想，实际上下文切换的开销可能会大于 3.5 微秒。 对于想深入了解更多的同学，可以参考《深入理解 Linux 内核》中的相关章节。 尝试使用专业测试工具 - lmbenchlmbench 是一款开源的基准测试工具，旨在评估系统性能，包括文档读写、内存操作、进程创建与销毁开销，以及网络性能等。其操作方法简单，但有时候运行速度较慢，感兴趣的同学可以自行尝试。这个工具的优势在于进行多组实验，分别对 2 个、8 个、16 个进程进行测试，使用不同大小的数据，能较好地模拟缓存未命中的情况。 我使用 lmbench 测试后得到如下结果： Host OS 2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64Kctxsw ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw -----------------------------------------------------------------------bjzw_46_7 Linux 2.6.32- 2.7800 2.7800 2.7000 4.3800 4.0400 4.75000 5.48000 从 rsyslog 的数据来看，进程上下文切换耗时在 2.7 微秒到 5.48 微秒之间。 线程上下文切换耗时接下来我们测试 Linux 下的线程，以确定其切换是否比进程更迅速。实际上在 Linux 中并不存在真正的线程，其实是为开发者实现的轻量级进程，这种进程与普通进程相比，虽有独立的 task_struct 进程描述符和 pid，却可以共享内存地址空间、代码段、全局变量以及打开的文件集合。因此，同一进程下的线程调用 getpid() 时显示的 pid 是相同的，其实 task_struct 中还有一个 tgid 字段，意味着多线程程序的线程实际上是共享某个特定进程的标识符。 我们再次进行实验，代码见 test06。实验原理与进程测试类似，创建 20 个线程，使用管道互传信号。接收到信号后，线程会被唤醒，并传递信号给下一个线程，而自己则进入睡眠状态。实验中统计了管道传递信号的额外开销。 # gcc -lpthread main.c -o main 实验结果显示为： 0.508250 4.363495 经过多次实验后，线程切换的平均耗时大约为 3.8 微秒。从上下文切换的耗时上来看，Linux 下的线程（即轻量级进程）与进程的切换差异不大。 Linux 类相关命令既然我们清楚了上下文切换带来的 CPU 时间消耗，何不利用一些工具观察 Linux 系统中的上下文切换情况呢？如果上下文切换对整体性能造成影响，我们也许可以识别问题的进程并作相应优化。 利用以下命令： # vmstat 1 可以输出系统当前的进程状态、内存使用情况等信息。 procs -----------memory---------- --swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st ... 另外，可以用以下命令获取每秒的上下文切换信息： # sar -w 1 此命令将展示一段时间内的进程创建次数及上下文切换次数。例如： proc/s cswch/s 11:19:20 AM proc/s cswch/s... 在实验环境中，这台配置为 8 核 8G 的 KVM 虚拟机，上面运行的是 nginx + fpm（数量为 1000），每秒平均处理的用户请求约 100 左右。其中 cswch 列指示了在 1 秒内系统发生的上下文切换次数，达到大约 4 万次。这意味着每个 CPU 在 1 秒内产生约 5 千次的上下文切换，每秒消耗近 20 毫秒用于上下文切换。 为了更深入了解频繁上下文切换的源头，我们可以使用以下命令： # pidstat -w 该命令会显示各个进程的上下文切换情况，如下表所示： PID cswch/s nvcswch/s Command32316 4.00 0.00 php-fpm32508 160.00 34.00 php-fpm32726 131.00 8.00 php-fpm... 由于 fpm 运行处于阻塞模式，每当请求 Redis、Memcached 或 MySQL 时会触发自愿上下文切换，而非自愿上下文切换仅在时间片耗尽时发生，因此大多数切换都是自愿的。 如果需要查看特定进程的总上下文切换情况，可以进入 /proc 目录下查看： grep ctxt /proc/PID/status 通过这种方式，我们能够直接看到 voluntary_ctxt_switches 和 nonvoluntary_ctxt_switches 的总数。这些数据无须记住上下文切换所做的具体操作，只需知道一个结论：实验结果显示上下文切换的开销在 2.7 微秒到 5.48 微秒之间，而你也可以借助提供的代码和工具进行测试，lmbench 的测试结果更为准确，因为它考虑到了后续缓存未命中的影响。","categories":["1.语言","C语言","多线程"]},{"title":"Linux启动","path":"/2024/12/19/0-平台-平台相关-Linux启动/","content":"Linux 系统Linux 系统内核Linux 系统内核是这个操作系统的核心部分，它负责管理计算机的硬件资源。内核提供了硬件抽象层，使得应用程序可以方便地与硬件互动，而不必关心具体的硬件实现细节。例如，内核会管理 CPU 的调度、内存的分配以及硬盘的读写操作。 此外，内核支持多任务功能，允许多个程序同时运行，从而提升了计算机的使用效率。在 Linux 系统中，内核处理与硬件的所有交互，这样用户和开发者就可以关注他们的应用程序，而不必担心底层的硬件管理。 Linux 发行套件系统Linux 发行套件系统（Linux distribution）是对 Linux 内核及其周边软件的一个集合。它不仅包含了 Linux 内核，还包括了各种常用的软件工具和库，使得用户可以直接安装和使用。例如，Ubuntu、CentOS 和 Fedora 是三种流行的 Linux 发行版，每种都有其独特的特点和适用场景。 这些发行版通常会预装一些流行的软件，如文本编辑器、浏览器和开发工具，使得用户在安装系统后，可以立即开始使用。此外，许多发行版还提供了软件包管理系统，用户可以轻松地添加或更新软件，提高了系统的可用性和灵活性。比如，Ubuntu 使用了 APT 包管理系统，允许用户通过简单的命令来安装新软件，而无需手动处理依赖关系。 通过这种方式，Linux 发行套件不仅使得系统的配置变得更加简单，还使得新用户能够更快地上手，避免了繁琐的设置步骤。 分区Linux 系统按照 FHS（Filesystem Hierarchy Standard，文件系统层次结构标准）对不同目录进行了明确的定义和功能划分。这种组织结构使得用户和管理员能够轻松找到文件和程序，并确保系统的高效运作。 主要目录及其功能 （根目录） 根目录是文件系统的起点，所有其他目录都在这个目录中进行层级组织。例如，/home、/etc、/var 等都源自于根目录。 bin 存放基本的用户命令和系统工具，如 ls、cp 和 mv 等。这些命令是系统启动和操作的必要组成部分。 etc 包含系统和应用程序的配置文件。比如，/etc/fstab 文件中定义了系统的文件系统挂载点，/etc/hosts 文件用于 DNS 查找。 home 每个用户的个人目录都在此目录下，用户可以在这里存储自己的文档、设置和配置。例如，/home/username 是用户 username 的专属空间。 lib 存放系统运行所需的共享库文件，这些库支持 /bin 和 /sbin 目录中的可执行文件。例如，/lib/x86_64-linux-gnu/libc.so.6 是常用的 C 标准库。 usr 存储用户程序和数据的目录，通常包含许多重要的应用程序和工具。例如，/usr/bin 目录中放置了许多用户可用的命令行工具，如 git、python 和其他应用程序。 var 存放经常变化的数据，例如日志文件 (/var/log)、邮件 (/var/mail)、缓存和临时文件。日志文件有助于系统管理员排查问题。 tmp 用于存放临时文件，系统重启后会被清空。比如，安装软件时可能需要在此目录中写入中间文件。 举例说明假设您是一名系统管理员，需要检查用户的登录记录。您知道登录记录存放在 /var/log/wtmp 文件中。您可以使用 last 命令查看这些记录，而 last 命令会从该文件中提取信息，列出所有用户的登录时间和持续时长。 这种清晰的目录结构不仅使系统的管理变得简单明了，也有助于提升安全性和可维护性。因此，了解这些目录的用途对于任何使用或管理 Linux 系统的人来说都是至关重要的。 重置 root 密码在进行系统的安全管理时，重置 root 密码是一项重要的技能。如果你发现自己忘记了 root 用户的密码，可以按照以下步骤进行重置。 步骤如下： 启动计算机在计算机启动时，注意观察 GRUB 引导加载器的界面。这个界面通常会显示多个启动选项，尤其是在有多个操作系统时。 进入编辑模式当 GRUB 加载出现在屏幕上时，选择你想要启动的内核选项，然后按下 e 键。这将使你进入编辑模式，你会看到几个参数配置。 修改启动参数找到包含“ro”（只读）字母的行，通常是以“linux”开头的行。将“ro”更改为“rw”，这样可以让系统以读写方式启动。然后在这一行的末尾添加 init=/bin/bash。这一步是为了让系统进入一个带有 bash 的紧急模式，方便你重置密码。 示例： linux /vmlinuz-xxx ro quiet 修改为： linux /vmlinuz-xxx rw init=/bin/bash 启动修改后的内核修改完后，按下 Ctrl+x 或 F10 来启动系统。此时，系统会进入 bash 命令行界面。 更新 root 密码在 bash 命令行界面中，输入以下命令来更新 root 用户的密码： passwd 系统会提示你输入新的密码。请务必选择一个强密码，最好包含字母、数字和特殊字符。确认输入后，系统会显示密码已成功更新的消息。 重启系统更新完密码后，输入以下命令以重启系统： exec /sbin/init 或者你也可以使用： reboot 使用新密码登录系统重启后，使用你刚刚设置的新密码进行登录。 完成这些步骤后，你成功地重置了 root 密码，能够顺利访问系统。务必注意，重置 root 密码需要一定的权限，因此请确保你是系统的合法管理员。 初始化进程在 Linux 系统中，启动过程是一个复杂而又重要的流程，涉及多个阶段和组件。整个启动过程通常遵循以下顺序： BIOS：计算机开机时，首先会通过 BIOS（基本输入输出系统）进行硬件自检并初始化硬件组件。 BootLoader：完成硬件初始化后，BIOS 将控制权交给 BootLoader（引导加载程序），例如 GRUB。BootLoader 负责加载操作系统内核。 加载系统内核：BootLoader 加载 Linux 内核到内存中。 内核初始化：内核开始初始化系统硬件（如 CPU、内存、硬盘等），并准备进行用户空间的运行。 启动初始化进程：内核启动第一个用户空间进程，通常是 init，这时 Linux 系统的初始化工作正式开始。 初始化进程初始化进程是 Linux 系统中第一个被创建的进程，其进程 ID（PID）为 1。它的主要任务是完成各种初始化工作，以确保用户能够拥有一个稳定和可用的工作环境。在现代 Linux 系统中，systemd 取代了传统的 System V init，引入了一些更为高效和灵活的特性。 初始化进程服务类型System V initSystem V init 采用传统的运行级别（runlevel）机制，每个运行级别定义了系统不同的状态和可用的服务。以下是一些常见的运行级别及其对应的 Systemd 目标名称和作用： System V Init 运行级别 Systemd 目标名称 作用 0 runlevel0.target, poweroff.target 关机 1 runlevel1.target, rescue.target 单用户模式 2 runlevel2.target, multiuser.target 等同于级别 3 3 runlevel3.target, multiuser.target 多用户的文本界面 4 runlevel4.target, multiuser.target 等同于级别 3 5 runlevel5.target, graphical.target 多用户的图形界面 6 runlevel6.target, reboot.target 重启 emergency emergency.target 紧急 Shell systemd与 System V init 不同，systemd 采用并发启动机制，能够并行启动多个服务，从而显著加快启动过程。systemd 使用目标（target）来替代传统的运行级别，提供了更灵活的服务管理功能。 .systemctl 和 System V init 的对比systemctl 是 systemd 的命令行工具，用于管理系统服务。以下是一些常见的 System V init 命令与相应的 systemctl 命令的对比： System V init 命令 systemctl 命令 作用 service foo start systemctl start foo.service 启动服务 service foo restart systemctl restart foo.service 重启服务 service foo stop systemctl stop foo.service 停止服务 service foo reload systemctl reload foo.service 重新加载配置文件（不终止服务） service foo status systemctl status foo.service 查看服务状态 chkconfig foo on systemctl enable foo.service 开机自动启动 chkconfig foo off systemctl disable foo.service 开机不自动启动 chkconfig foo systemctl is-enabled foo.service 查看特定服务是否为开机自启动 chkconfig –list systemctl list-unit-files –typeservice 查看各个级别下服务的启动与禁用情况 通过使用 systemd 和 systemctl，用户能够更高效地管理服务和系统状态，同时也简化了服务的控制和配置。 基于 ARM 体系的内核启动解析Bootloader 的基本初始化准备在内核被引导加载之前，Bootloader 必须完成以下核心任务，确保系统能够顺利启动。 1. 设置并初始化 RAM (必须)引导加载程序必须找到并初始化系统的所有 RAM，以便它可以用于存储易失性数据。这一过程取决于机器架构。引导加载程序可以采用内部算法自动确定 RAM 的大小，或者利用机器的已知特性来完成初始化。例如，对于某些 ARM 设备，引导加载程序可能会读取硬件提供的 RAM 扩展信息，从而确定可用的内存范围。 2. 设置设备树 dtb (必须)设备树 Blob（dtb）必须按照 8 字节对齐，且最大不能超过 2 兆字节。这是为了确保设备树能够被有效地映射到系统中。值得注意的是，在 v4.2 之前的版本要求 dtb 放置在 512 MB 区域内。所以，在用户设计系统时，需要审核 dtb 的位置和大小，以避免初始化失败。 3. 解压缩内核映像 (可选)目前 AArch64 内核没有提供内置的解压缩器，这意味着如果使用压缩的内核映像（如 Image.gz），引导加载程序必须负责解压。对于那些没有实现此功能的引导加载程序，可以选择编译一个不压缩的内核映像。 4. 调用内核映像 (必须)内核映像的头部包含多项必要的信息，例如： u32 code0; /* 可执行代码 */u32 code1; /* 可执行代码 */u64 text_offset; /* 加载偏移，小端 */u64 image_size; /* 有效映像尺寸，小端 */u64 flags; /* 内核标志, 小端 */ 进入内核进入内核之前，必须满足一系列关键性条件，以确保系统的稳定和安全性。下面是这些条件的详细说明： 禁止 DMA 功能的设备为了防止内存因虚假的网络数据包或损坏的磁盘数据而被意外损坏，所有具有 DMA（直接内存访问）功能的设备必须被禁用。例如，网络适配器或存储控制器在内核加载前都应停止数据传输，以避免不合规操作造成的内存污染。 主 CPU 通用寄存器设置主 CPU 的通用寄存器必须进行特定的初始化。具体设置如下： x0：需设置为系统 RAM 中设备树 Blob（Device Tree Blob，简称 dtb）的物理地址。这一地址对于内核初始化至关重要，因为它提供了系统硬件的描述信息。 x1x2x3：应设置为 0，预留供将来使用。这通常意味着目前未定义的功能可以在将来进行扩展和优化。 CPU 模式在 CPU 模式方面，以下要求必须得到满足： 所有形式的中断都要在 PSTATE.DAIF 中屏蔽。这包括调试中断（Debug），系统错误（SError），标准中断（IRQ）和快速中断（FIQ）。通过阻止这些中断，系统可以专注于内核的安全加载。 CPU 必须在 EL2（异常级别 2）或非安全的 EL1 下运行。选择 EL2 作为推荐模式是因为这为虚拟化扩展提供了访问权限，这对于现代系统至关重要。 Caches 和 MMUs MMU（内存管理单元）必须关闭。这是确保内核能够准确管理内存映射的重要步骤。 指令缓存可以选择开启或关闭，根据具体的应用场景来决定。 与加载的内核映像相对应的地址范围必须被清除到 PoC（一致性点）。例如，如果某个设备正在使用系统缓存，这些缓存必须确保在内核加载之前处于干净状态。 若存在系统缓存或启用了缓存的其他相关主服务器，操作时通常应通过虚拟地址（VA）维护缓存，而非直接通过物理地址。 架构定时器在内核的启动过程中，所有 CPU 上的计时器必须根据其频率设置 CNTFRQ，并且必须一致地设置 CNTVOFF。如果内核在 EL1 级别启动，则 CNTHCTL_EL2 的 EL1PCTEN 位（即位 0）必须在可用时被设置。 连贯性当内核启动时，所有由内核引导的 CPU 必须属于同一一致性域。这一要求确保了 CPU 之间在访问共享内存时的一致性，避免了潜在的数据损坏。初始化时，每个 CPU 的维护操作必须通过定义的实现进行。 系统寄存器所有处于异常级别的可写架构系统寄存器都必须由更高异常级别的软件初始化。这是为了防止在 UNKNOWN 状态下执行，避免出现无法预知的系统行为。 CPU 进入内核的条件 所有 CPU 必须以相同的异常级别进入内核。 主 CPU 直接跳转到内核映像的第一条指令，以确保高效和迅速的启动过程。 主 CPU 还需保证传递的设备树 Blob，对于每个 CPU 节点包含一个“启用方法”属性。支持的启用方法如下所述，且这些属性由引导加载程序生成，并在内核入口之前插入到 blob 中。 启用方法示例 旋转表（Rotation Table）启用方法的 CPU，其 cpu 节点必须包含“cpu-release-addr”属性。此属性指向一个自然对齐的 64 位零初始化内存位置，用于 CPU 的安全启用。 psci（Power State Coordination Interface）启用方法的 CPU 应该在内核外部保留，确保其在内存节点之外或通过 /memreserve/ 描述给内核的内存区域。 此外，内核将根据 ARM 文档编号 ARM DEN 0022A 的说明发出 CPU_ON 调用，以将 CPU 引入内核，确保系统整合的顺畅。 第二 CPU 通用寄存器设置对于第二个 CPU，通用寄存器 x0x1x2x3 都应设置为 0，进一步预留以便未来使用。 通过确保上述所有条件都得以满足，内核能够在一个安全、稳定的环境中顺利启动，进而进行后续操作。 内核启动 init 总过程内核启动有两种主要方式：压缩格式和不压缩格式。在压缩模式下，内核的入口代码位于 arch/架构名/boot/compressed/head.S。这段代码的主要职责是进行前期初始化，准备工作是解压内核并为后续的启动做好基础环境。 一旦解压完成，控制便会跳转到 arch/架构名/kernel/head.S，此处则开始正式启动内核。这一过程中的每一步都至关重要，它不仅决定了系统的启动效率，也直接关系到系统能否成功进入正常运行状态。 本文专注于不压缩方式的内核启动过程。通过对内核代码的逐行解析，我们能够整理出内核启动过程的部分顺序，以帮助读者更好地理解这一复杂的过程。 以下是一个简化的不压缩启动过程的概述： **引导加载程序(bootloader)**：首先，系统的引导加载程序会被加载到内存。这是启动流程的第一步，引导加载程序负责把内核映像加载到内存中。例如，GRUB（GRand Unified Bootloader）就常用于这种情境。 内核入口点：从引导加载程序中，系统将控制权转交给内核的入口点，通常是 start_kernel。这是内核意识到自身被启动的地方。 内核初始化：在 start_kernel 中，根本的初始化过程和设置工作进行，例如设置内存管理单元（MMU）、中断系统，以及初始化调度器等。这一阶段确保内核能够处理多任务。 启动进程：经过一系列必要的初始化步骤后，内核会启动系统的第一个进程，通常是 init 进程。这一进程的 PID（进程标识符）为 1，是所有用户空间进程的父进程。init 进程负责启动其他用户空间服务和进程。 正常运行：当 init 进程完成启动后，系统便进入到正常的运行状态，各种服务和应用程序开始正常加载。 内核启动流程详解内核的启动过程与 U-Boot 的启动方式类似，前期同样是由一段汇编代码开始，随后跳转至 C 代码的执行。汇编代码的入口点位于 ./arm/kernel/head.S 文件中，符号名为 __HEAD，该文件还包含了 head-common.S。 从启动用户空间的第一个进程 init 来看，我们可以将这一过程大致分为四个步骤： head.S 处理：该步骤主要进行通用环境的初始化，这一部分与具体的芯片架构无关。 start_kernel 函数：当 head.S 完成后，控制会跳转到 start_kernel 函数。这一函数定义在 ./init/main.c 中。 rest_init 函数：在这一阶段，内核会创建 init 进程和 kthreadd 进程，其中 init 进程的进程号为 1，而 kthreadd 是内核的线程管理进程。 启动调度器：此时内核调度器开始运行，并执行 kernel_init 函数。kernel_init 函数会调用包含在根文件系统中的 init 进程，至此，用户空间的 init 进程启动完成。 head.S 和 head-common.S 的作用深入分析汇编代码的功能有些繁琐，但可以简要总结其主要作用： 检查架构：验证处理器和机器类型，以确保系统正确识别目标硬件。 配置 MMU：设置内存管理单元（MMU），构建页表条目，并启用虚拟内存。MMU 是现代计算机中用于管理物理内存的关键组件，它允许操作系统使用虚拟地址空间，让程序彼此隔离。 调用 start_kernel：在 init/main.c 文件中执行 start_kernel 函数。 所有架构的代码是相同的，因此使用汇编语言可以避免为不同芯片管理大量重复的代码。 start_kernel 阶段在 start_kernel 函数中，内部主要完成了以下工作： 锁依赖检测模块初始化：初始化 Lockdep 模块，以防止内核中可能出现的死锁。在 Lockdep 中，当锁被获取或释放时，会记录下这一事件以及相关详细信息，例如当时处理器是否正在处理中断。 RCU 机制初始化：RCU（Read-Copy Update，读-拷贝修改）是一种优化并发读写操作的机制。它允许读者在不获取锁的情况下访问被保护的数据结构，而写者则需先拷贝数据，然后修改副本，最后在适当的时机更新指针。这种机制的有效性在于所有 CPU 完成对共享数据的操作后，才会更新指针。 SMP 初始化：对称多处理（SMP）初始化，完成 CPU ID 的创建，确保在多核系统中各核心能有效地调度和运行操作。 调试对象的早期初始化：设置调试对象，确保内核调试可以顺利进行。 解析从 bootloader 传入的引导命令行：调用 setup_arch(command_line) 函数，初始化控制台以打印启动日志，并设置其他子系统，如虚拟文件系统（VFS）、跟踪（trace）、内存管理、进程控制组（cgroup）、ACPI（高级可扩展固件接口）、proc 文件系统等。 调用 rest_init：随后进入 rest_init 阶段，创建 init 和 kthreadd 进程，启动内核调度器。 rest_init 阶段在 rest_init 函数中，主要表现如下： static noinline void __init_refok rest_init(void) int pid; rcu_scheduler_starting(); smpboot_thread_init(); // 创建 init 进程，第一个用户空间进程 kernel_thread(kernel_init, NULL, CLONE_FS); numa_default_policy(); // 创建 kthreadd 用于管理内核线程 pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES); // 让内核进程 kthreadd 处于就绪态 TASK_NORMAL complete(kthreadd_done); // 启动调度器 init_idle_bootup_task(current); schedule_preempt_disabled(); cpu_startup_entry(CPUHP_ONLINE); 这一段代码创建了第一个用户空间进程 init，进程号为 1，负责加载和启动其他用户空间应用。之后，创建 kthreadd 进程，该进程的进程号为 2，并用于管理内核线程。所有其他内核线程都作为 kthreadd 的子线程被创建，利用 kthread_create_list 来维护这些内核进程。 kernel_init 阶段当内核调度器开始运行后，控制权转移到 kernel_init 函数： static int __ref kernel_init(void *unused) int ret; kernel_init_freeable(); // 完成所有初始化操作 async_synchronize_full(); // 如果使能了 ramdisk 执行命令启动 init if (ramdisk_execute_command) ret = run_init_process(ramdisk_execute_command); if (!ret) return 0; pr_err(Failed to execute %s (error %d) , ramdisk_execute_command, ret); // 否则根据配置启动 init if (execute_command) ret = run_init_process(execute_command); if (!ret) return 0; panic(Requested init %s failed (error %d)., execute_command, ret); // 如果上述两项都未启用，则依次在根文件系统下寻找 init if (!try_to_run_init_process(/sbin/init) || !try_to_run_init_process(/etc/init) || !try_to_run_init_process(/bin/init) || !try_to_run_init_process(/bin/sh)) return 0; panic(No working init found. Try passing init= option to kernel. See Linux Documentation/init.txt for guidance.); 在这一阶段，内核尝试启动 init 进程，具体执行哪个 init 可执行文件则依赖于系统配置。常见的进程包括 BusyBox 的 init、SystemV 的 init 或 SystemD 的 init 等。根据不同的 Linux 发行版，所选择的 init 系统会有差异。","categories":["0.平台","平台相关"]},{"title":"开源协议","path":"/2024/12/19/0-平台-平台相关-开源协议/","content":"常见开源许可证介绍开源软件许可证是软件开发中的法律文件，它规定了软件的使用、复制、修改和分发的条件。不同类型的许可证具有不同的规则和条款。以下是一些常见的开源许可证及其特点。 LGPL（较宽松通用公共许可证）LGPL，即“Lesser General Public License”，允许开发者在软件中使用 LGPL 授权的库，而不必将整个软件项目都开放源代码。举例来说，如果你使用了一个 LGPL 授权的图形库来开发应用程序，你可以选择将你的应用保密，前提是你提供了对图形库的访问权限，并且在相同版本下允许用户将其替换。在进行更新或修改时，开发者有义务确保库的源代码能够被获取，从而维护了社区对软件的持续改进。 Mozilla 许可证Mozilla 许可证是一种宽松的开源许可证，允许开发者自由使用、修改及分发基于 Mozilla 的开源软件。与 GPL 不同，Mozilla 许可证不要求派生作品也必须是开源。这意味着，使用了 Mozilla 许可证的软件可以与闭源软件结合使用。例如，Mozilla Firefox 浏览器就是基于此许可证发布的，用户和开发者可以构建自己的插件或扩展，而不必将自己的代码开源。 GPL（通用公共许可证）GPL（General Public License）是最流行的开源许可证之一，强调“如果你发布修改后的作品，你必须同样以 GPL 的条款发布”。也就是说，一旦你使用 GPL 授权的代码，你的所有源代码也必须开放给用户。这可以确保软件自由使用的权利被保护。比如，著名的 Linux 操作系统就是以 GPL 授权发行，使得社区中许多开发者基于其内核创建了不同版本的 Linux 发行版。 BSD 许可证BSD 许可证是一种非常宽松的许可协议，允许用户自由使用、修改和分发源代码，甚至可以将其用作闭源软件。BSD 许可证的一个著名实例是 FreeBSD 操作系统，它提供了一种灵活的许可方式，让企业可以在其产品中使用 BSD 授权的软件，而无需公开源代码。这种自由使得 BSD 许可证在商业应用中非常受欢迎。 MIT 许可证MIT 许可证同样是一种非常宽松的许可证，允许软件的任何人在任何情况下使用、复制和修改该软件，几乎没有限制。有很多现代的开源项目，如 Ruby on Rails 和 Node.js，都是在 MIT 许可证下发布的。这种简单明了的授权方式，有助于吸引更多的贡献者，因为它允许开发者将自己的项目与任何其他项目无缝结合。 Apache 许可证Apache 许可证提供了一种灵活的使用和分发模式，允许用户修改和分发代码，甚至包括商用。与 MIT 和 BSD 不同，Apache 许可证特别重视贡献者的权利，要求对贡献者的名字进行相应的标注。Apache HTTP 服务器是利用该许可证发布的，它被广泛应用于互联网，是一个事实上的标准选择。 通过了解这些开源许可证，开发者和用户能够更好地遵循法律框架，同时在软件开发中保持开放与自由，推动技术创新。","categories":["0.平台","平台相关"]},{"title":"操作系统","path":"/2024/12/19/0-平台-平台相关-操作系统/","content":"操作系统什么是操作系统？操作系统（Operating System, OS）是计算机系统中管理硬件和软件资源的核心程序。它负责进行进程管理、内存管理和文件系统管理等多项关键功能。这些功能帮助用户和计算机之间进行有效的互动。 操作系统的主要组成部分 内核：内核是操作系统中最重要的部分，负责直接与计算机的硬件进行交互。它管理着系统调用、进程调度、内存分配等任务。例如，Linux 内核支持多用户和多任务，确保每个进程可以同样有效地访问 CPU 时间。 驱动程序：驱动程序使操作系统能够与硬件设备通信。每种硬件设备（如打印机、显卡）都需要相应的驱动程序，以实现高效的操作。例如，安装显卡的驱动程序后，用户可以充分利用设备的图形处理能力。 接口库：接口库提供了一系列 API（应用程序接口），使得开发者能够高效地编写软件，与操作系统进行交互。通过接口，程序可以轻松调用操作系统的功能，如文件操作、网络通信等。 什么是嵌入式操作系统？嵌入式操作系统是特定硬件设备中使用的操作系统，这些设备通常具有特定功能，如智能家居产品、汽车电子系统等。嵌入式操作系统通常是可裁剪的，这意味着开发者可以根据设备的需求定制其功能。此外，对可靠性和稳定性的要求非常高。例如，在医疗设备中，嵌入式操作系统必须确保在关键时刻稳定运行，关乎患者的安全。 什么是交换分区？交换分区是计算机在内存不足时所使用的一部分硬盘空间，临时用于存放不活跃或休眠状态的进程数据。通过将这些数据转存至交换分区，计算机能够释放内存，保证其他运行中的进程能继续流畅执行。举个例子，如果打开了多个大型应用，系统会将不再使用的应用的状态存放在交换分区，从而保持系统的运行效率。 什么是文件系统？文件系统是操作系统中负责文件管理的软件和数据的集合。它提供一种组织和存取文件的方式，使得用户可以轻松地创建、读取、写入和删除文件。在文件系统中，所有文件都被组织在一个层次结构的目录中，用户可以通过路径轻松访问文件。 Windows 和 Linux 的文件系统有何区别？Windows 和 Linux 在文件系统结构上存在显著差异： 在 Windows 中，目录结构在分区下进行组织，比如 C:\\、D:\\ 等。如果用户保存了一个文档，在文件管理器中，它会显示在 C:\\Documents\\MyFile.txt 这样的路径中。 而在 Linux 中，所有的设备和分区都挂载在一个统一的目录结构下，通常以根目录（）为起点。比如，可以将一个附加的硬盘分区挂载到 mnt 目录，用户看到的路径可以是 mntexternal_driveMyFile.txt。 硬盘分区硬盘分区是将一个物理硬盘划分为多个逻辑单元，以便更好地管理和使用硬盘空间。常见的分区类型包括： 主分区：直接从硬盘启动的分区，最多可以有四个主分区。 逻辑分区：在扩展分区内创建的分区，可以有多个逻辑分区，便于管理多量数据。 扩展分区：一种特殊类型的分区，允许在硬盘上创建额外的逻辑分区。 分区格式 Windows 通常使用 FAT（文件分配表）或 NTFS（新技术文件系统）格式，以支持文件权限和其他高级特性。 Linux 则主要使用 ext（扩展文件系统），如 ext2、ext3 和 ext4，各自支持不同的功能，如日志记录、文件权限管理等。 交换分区和虚拟内存交换分区和虚拟内存密切相关。交换分区是物理硬盘上的一块空间，而虚拟内存是操作系统为每个进程创建的一个逻辑地址空间。当物理内存不足时，操作系统将不活跃的数据或程序从 RAM 中移至交换分区，使得有效利用内存，提高系统处理能力。例如，在大量数据处理时，系统可能会将不常用的程序代码移入交换分区，以为活跃程序腾出更多内存。","categories":["0.平台","平台相关"]},{"title":"用户管理","path":"/2024/12/19/0-平台-Linux-系统参数-用户管理/","content":"用户与用户组Linux 如何分辨用户在 Linux 系统中，用户并不是通过他们的用户名被识别的，而是通过一个称为 UID（用户 ID）的数字。计算机更容易处理数字，而人类则更易记住文字。这就是为何我们通常使用用户名的原因。每个文件其实是通过 UID 来标识用户，显示的用户名如“vagrant”或“root”，是因为相关信息被存储在 /etc/passwd 这一文件中。具体来说，ls 命令在显示文件信息时，会查询 /etc/passwd 文件，将 UID 转换为我们熟悉的用户名。如果你修改了 /etc/passwd 中的 UID，ls 就会显示 UID 而非用户名。 以下是用户登录到 Linux 系统的流程： 用户输入用户名。 系统查找 /etc/passwd，验证用户信息。 从文件中读取 UID 和 GID（组 ID），以及用户的主目录和默认 shell。 系统查找 /etc/shadow，核对与用户关联的密码。 登录成功后，用户进入 shell。 vagrant@saltmaster:~$ ls -ltotal 256-rw-r--r-- 1 root root 256191 Nov 13 06:26 bootstrap-salt.sh-rw-rw-r-- 1 vagrant vagrant 0 Nov 26 08:44 file_a-rw-r--r-- 1 root root 100 Nov 20 06:30 nettools.sls 在上述例子中，可以看到各个文件的拥有者是通过 UID 识别并显示用户名的。 当你查看 /etc/passwd 文件内容时： vagrant@saltmaster:~$ cat /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologin... 每一行代表一个账户，字段通过冒号进行分割。总共有 7 个字段，分别为： 用户名 密码占位符（通常为 x） UID GID 用户信息说明 主目录（用户登录后默认所在的位置） shell（用户登录后启动的 shell，如 /bin/bash） passwd 文件和 shadow 文件所有的用户信息存储在 /etc/passwd 文件中，而密码信息则被更安全地存储在 /etc/shadow 中，以增强安全性。密码移动到 /etc/shadow 后，/etc/passwd 中只保留一个占位符“x”。 /etc/shadow 文件的格式如下： vagrant@saltmaster:~$ sudo head -n 4 /etc/shadowroot:!:17466:0:99999:7:::daemon:*:17379:0:99999:7:::bin:*:17379:0:99999:7:::sys:*:17379:0:99999:7::: 每行对应一个账户，字段含义如下： 账户名称 密码（用符号如 ! 或 * 表示用户禁用） 最近改动密码的日期（以 1970 年 1 月 1 日为基准） 密码不可改动的日期（0 则可以随时修改） 密码过期前的提醒时间 过期宽限期 账户失效日期 保留字段 有效用户组与初始用户组在 Linux 中，每个用户都有一个用户组。与 UID 相似，用户组是通过 GID（组 ID）来识别的。同样，对于用户组，Linux 也有相应的文件 /etc/group 和 /etc/gshadow。 查看 /etc/group 文件： vagrant@saltmaster:~$ cat /etc/groupwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologinbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin 每一行记录一个用户组的信息，字段分别为： 用户组名称 密码（通常用 x 占位） GID 用户组成员列表（用逗号分隔） /etc/gshadow 文件内容示例： vagrant@saltmaster:~$ sudo head -n 4 /etc/gshadowroot:*::daemon:*::bin:*::sys:*:: 在这个文件中，第二个字段也是密码，如果这个字段为 !，则表示该用户组没有组管理员的权限。 一个常见问题是，为什么 /etc/passwd 中用户的用户组 ID 并不在 /etc/group 中列出？这是因为，/etc/passwd 中的用户组称为“初始用户组”，意味着当用户登录到 shell 时，所依据的用户组。该用户组不需要在 /etc/group 列表中显示。 当用户属于多个用户组时，他会获得所有这些组的权限。文件的默认组是“有效用户组”。你可以通过命令 groups 查看到当前用户的所有用户组。其中第一个用户组是有效用户组，用于创建新文件。 示例命令： vagrant@saltmaster:~$ groupsadm cdrom sudo dip plugdev lxd lpadmin sambashare vagrant 使用 newgrp 命令可以在新的 shell 中切换用户组，最后通过使用 exit 可以返回到之前的用户组。 vagrant@saltmaster:~$ newgrp sudovagrant@saltmaster:~$ touch test_b 以上命令使得用户能够在 sudo 用户组下创建文件 test_b，该文件的属性如下： vagrant@saltmaster:~$ ll test_*-rw-rw-r-- 1 vagrant adm 0 Nov 26 15:46 test_a-rw-rw-r-- 1 vagrant sudo 0 Nov 26 15:47 test_b 通过这些过程，你可以清晰地看到在 Linux 中，用户和用户组的处理是如何进行的，及其如何保持系统的安全性与组织性。 创建与管理用户useradd在熟悉了用户和用户组的基本概念后，我们现在进入用户管理的实际操作部分。创建一个新的用户账户的命令是 useradd。请注意，该命令需要对系统文件（如 /etc/passwd 等）具有读写权限，因此一般需要以 root 用户身份执行。 以下是使用 useradd 创建一个名为 tom 的账户的示例： vagrant@saltmaster:/home$ useradd tomuseradd: Permission denied.useradd: cannot lock /etc/passwd; try again later. 在尝试执行命令时，系统提醒权限不足，这说明当前用户没有足够权限。接着，我们可以使用 sudo -s 切换到 root 用户： vagrant@saltmaster:/home$ sudo -sroot@saltmaster:/home# useradd tom 在成功执行后，我们可以通过以下命令查看新创建的用户在系统中的记录： root@saltmaster:/home# grep tom /etc/passwd/etc/passwd: tom:x:1001:1001::/home/tom: 这行输出显示，系统为用户 tom 在 /etc/passwd 文件中添加了一条记录，其中包含了用户的基本信息。此外，在 /etc/shadow 中也有相应的条目，密码字段为空，表示该用户尚未设置密码： root@saltmaster:/home# grep tom /etc/shadow/etc/shadow: tom:!:17496:0:99999:7::: 用户组信息也被添加到了 /etc/group 中： /etc/group: tom:x:1001: 尽管执行命令成功，但没有为 tom 用户创建家目录，这在 CentOS 系统中是常见的情况。可以通过修改系统配置来改变这一默认行为。 另外，使用 useradd 命令时，Linux 系统会自动应用一些默认参数。通过运行以下命令，可以查看这些默认配置： vagrant@saltmaster:~$ useradd -D 比如，系统会设置组 ID（GROUP）、家目录（HOME）、默认 shell（SHELL）等，具体默认值一般存储在 /etc/default/useradd 文件中。 passwd创建用户后，需要为新账户设置密码，这需要使用 passwd 命令。例如： root@saltmaster:/home# passwd tom 在执行该命令时，系统会提示输入 tom 用户的新密码。普通用户在修改自己密码时需要输入旧密码，而 root 用户则不需要。 其他修改账户的命令（sudo）除了创建用户和设置密码外，Linux 还提供了一些命令来修改账户属性： chage：用于修改与密码有关的账户参数，例如密码的失效日期等。 usermod：可以用来修改用户的有效组、初始组和主目录等信息。 userdel：此命令用于删除用户，需谨慎使用，因为会将用户相关的记录从 /etc/passwd 和 /etc/shadow 中删除，并且会删除用户的主目录。通常情况下，可以先将账户状态设置为不可用，而不是直接删除。 如果确实需要删除用户，使用 userdel -r username 命令可以同时删除用户以及其主目录及相关文件。 用户可以使用的一些命令除了管理账户的命令外，普通用户也可以执行一些基本命令： passwd：用户可以用该命令修改自己的密码。 chage -l username：查看用户的密码和帐户信息。 finger：查询用户相关的信息。 chfn：修改用户的详细信息。 chsh：改变默认登录的 shell。 id：查询用户的 ID 信息。 用户组的管理关于用户组的管理，命令与用户管理相似，主要涉及 /etc/group 和 /etc/gshadow 文件。使用 newgrp 命令可以开启一个新的 shell，以新环境登录用户和用户组。这个命令的使用可以让用户在不同的组中切换，但实际的组权限检验是基于进程的有效组 ID。 精确的权限控制 - ACL在 Linux 文件系统中，默认的权限管理是基于“所有者、组和其他人”三组权限的。对于同一个用户组内的成员或属于“其他人”的成员，权限的细致控制是有限的，因此引入了 ACL（Access Control List）。ACL 能够针对特定用户和特定文件或目录设置读、写、执行权限。使用 ACL 需要系统文件系统的支持，可以通过命令 mount | grep acl 检查当前文件系统是否支持此功能。 用户切换 - su, su - 和 sudo用户在 Linux 中切换身份的常用命令是 su。命令的格式为 su - username，其中 - 表示将用户的所有环境变量切换为目标用户的环境，如 su - vagrant 将切换到 vagrant 用户，改变所有的环境变量。 使用 su - root 可直接以 root 身份登录。如果你只需要临时运行一个命令，可以使用 su - root -c command 格式，其中的 root 可以省略。 然而，每个人都使用 root 权限的需求可能导致不安全，所以引入了 sudo 命令。sudo 允许用户以其他用户的身份（通常是 root）执行命令。在使用 sudo 之前，用户必须在 /etc/sudoers 文件中进行授权。 sudores 文件支持对用户组的授权，使用 % 符号来表示用户组。例如，可以设置某个用户组的权限： root ALL=(ALL) ALL 此外，可以在条目中添加 NOPASSWD: ALL 来免除每次使用 sudo 时输入密码的要求。","categories":["0.平台","Linux","系统参数"]},{"title":"指针","path":"/2024/12/19/1-语言-C语言-指针-指针/","content":"什么是指针在计算机编程中，指针是一种变量类型，用于存储内存地址。简单来说，指针指向内存中的某个位置。 每个内存单元都有一个唯一的地址，指针可以存储这个地址，并通过引用该地址来访问内存中存储的数据。通过使用指针，我们可以直接访问和操作内存中的数据，而不需要将数据本身直接存储在变量中。 务必弄清楚存储单元的地址和存储单元的内容这两个概念的区别 指针可以指向任何数据类型，例如整数、字符、数组、结构体等。通过操作指针，我们可以在程序中动态地分配和释放内存，以及在函数之间传递复杂的数据结构。 使用指针时，我们可以使用一些操作符来进行不同的操作，包括： 取址操作符（）：用于获取变量的地址。 解引用操作符（*）：用于访问指针所指向的地址处存储的值。 指针在编程中非常有用，特别是在需要处理动态内存分配、传递大量数据或需要直接操作内存的情况下。然而，使用指针也需要谨慎，因为错误的使用指针可能导致内存泄漏、野指针访问等问题。 什么是指针变量指针变量是一种特殊类型的变量，它存储了一个内存地址，可以用于指向其他变量或数据的位置。换句话说，指针变量保存了一个指向内存中某个位置的值。 指针变量的声明需要指定所指向的数据类型。这是因为指针变量需要知道要解引用时应该如何解释所指向的内存。例如，如果一个指针变量指向整数类型的数据，则解引用该指针将给出该位置上的整数值。 通过指针变量，我们可以通过间接引用来访问和修改所指向的变量的值。通过解引用操作符（*），我们可以访问指针变量指向的内存地址中存储的实际数据。 以下是一个示例，展示了指针变量的声明、初始化和使用的过程： int main() int num = 10; // 定义一个整数变量 int* ptr; // 定义一个指向整数的指针变量 ptr = num; // 将指针指向变量num的地址 printf(num的值：%d , num); // 输出 num 的值 printf(ptr所指向的值：%d , *ptr); // 输出 ptr 所指向的值，即 num 的值 *ptr = 20; // 通过指针修改 num 的值 printf(修改后的num的值：%d , num); // 输出修改后的 num 的值 return 0; 在上述示例中，指针变量 ptr 被声明为指向整数类型的指针。通过使用操作符，将 ptr 指向了 num 变量的地址。然后，通过解引用 ptr，可以访问和修改 num 的值。 指针变量在许多编程语言中都存在，并且在内存管理、动态数据结构和函数参数传递等方面发挥着重要的作用。但是，正确使用指针是需要小心谨慎的，以避免出现内存错误和潜在的安全问题。 指针变量作为函数参数当将指针变量作为函数参数传递时，有几个方面需要注意，以确保正确使用指针并避免潜在的错误： 传递指针的副本：在函数调用时，指针变量作为参数传递给函数时，实际上是传递指针的副本，而不是原始指针本身。这意味着在函数内部对指针的修改不会影响函数外部的指针。 指针有效性检查：在函数内部使用指针之前，应该进行有效性检查，确保指针不为 NULL。空指针可能会导致访问无效的内存地址，导致程序崩溃或产生不可预测的结果。 指针的传递方式：指针可以通过值传递或引用传递来传递给函数。如果要在函数内部修改指针本身的值（例如使其指向不同的内存地址），则需要使用指针的引用传递，即将指针的地址作为参数传递给函数。 避免野指针：确保在函数内部正确初始化指针或分配内存，避免使用未初始化的指针。同时，注意在函数结束前释放动态分配的内存，以避免出现野指针（指向无效内存）。 下面是一个示例，展示了如何在函数中使用指针变量作为参数： #include stdio.hvoid modifyPointer(int* ptr) if (ptr != NULL) // 检查指针的有效性 *ptr = 42; // 修改指针所指向的值 ptr = NULL; // 修改指针本身的值（不会影响函数外部的指针） int main() int num = 0; int* ptr = num; printf(初始值：%d , *ptr); // 输出初始值 modifyPointer(ptr); // 将指针作为参数传递给函数 printf(修改后的值：%d , *ptr); // 输出修改后的值 return 0; 在上述示例中，定义了一个 modifyPointer 函数，该函数接受一个整型指针作为参数。在函数内部，首先进行指针的有效性检查，然后修改指针所指向的值为 42。然后，将指针本身的值设置为 NULL，但请注意这不会影响函数外部的指针。 在 main 函数中，声明了一个整型变量 num，并将其地址赋值给指针 ptr。然后，通过调用 modifyPointer 函数，并将指针 ptr 作为参数传递给函数，实现了在函数内部修改指针所指向的值。 在最后的输出中，可以观察到指针所指向的值在函数调用后发生了修改。 总结来说，当指针变量作为函数参数传递时，需要注意指针的有效性、传递方式和可能对指针本身的修改。遵循这些注意事项可以更安全地使用指针，并确保函数对指针的操作正确有效。 函数的调用可以（而且只可以）得到一个返回值（即函数值），而使用指针变量作参数，可以得到多个变化了的值。 通过指针引用数组通过指针引用数组，可以使用指针来操作数组元素。在 C 语言中，数组名本身就是指向数组第一个元素的指针。通过将数组名赋值给指针变量，可以通过指针来访问和修改数组元素。 #include stdio.hint main() int arr[5] = 1, 2, 3, 4, 5; // 定义一个整数数组 int* ptr; ptr = arr; // 将数组名赋值给指针变量 /* ptr2 = arr[0]; //是否可以？*/ printf(数组元素通过指针访问： ); for (int i = 0; i 5; i++) printf(arr[%d] = %d , i, *(ptr + i)); // 通过指针访问数组元素 return 0; 在上述示例中，arr 是一个整数数组。通过将 arr 赋值给指针变量 ptr，ptr 就指向了数组的第一个元素。然后，使用指针 ptr 通过偏移来访问数组中的其他元素，使用解引用操作符（*）来获取元素的值。 在循环中，通过递增指针 ptr 的值来访问数组的不同位置。通过*(ptr + i)，可以获得指针 ptr**偏移 i 个元素位置处(偏移大小取决于数组类型)**的值，即数组 arr 中索引为 i 的元素。 通过指针引用数组，可以实现对数组的灵活访问和操作。指针算术运算可以用于遍历数组、进行元素的读取和修改，甚至可以通过指针动态分配数组的内存空间。然而，需要小心确保指针不越界，并遵循指针的安全使用规则，以避免潜在的错误和内存访问问题。 *p++获取*p 的值要快于*p+i 的值的获取 用数组名作函数参数用数组名作函数参数时，因为实参数组名代表该数组首元素的地址，形参应该是一个指针变量 用指向数组的指针作函数参数一维数组名可以作为函数参数，多维数组名也可作函数参数。用指针变量作形参，以接受实参数组名传递来的地址。可以有两种方法：①用指向变量的指针变量②用指向一维数组的指针变量 通过指针引用多维数组指针变量可以指向一维数组中的元素，也可以指向多维数组中的元素。但在概念上和使用方法上，多维数组的指针比一维数组的指针要复杂一些。a[i]+j 代表谁的地址？代表 a[i][j]的地址*(a[i]+j)代表什么？代表元素 a[i][j]*(*(a+i)+j)代表什么？与*(a[i]+j)等价 通过指针引用字符串 字符串是存放在字符数组中的。引用一个字符串，可以用以下两种方法。(1) 用字符数组存放一个字符串，可以通过数组名和格式声明“%s”输出该字符串，也可以通过数组名和下标引用字符串中一个字符。(2) 用字符指针变量指向一个字符串常量，通过字符指针变量引用字符串常量。 在 C 语言中，字符串实际上是以 null 字符（’\\0’）结尾的字符数组。通过指针引用字符串，可以使用指针来操作字符串的字符元素。 #include stdio.hint main() char str[] = Hello, World!; // 定义一个字符串数组 char* ptr = str; // 将数组名赋值给指针变量 printf(字符串通过指针访问： ); while (*ptr != \\0) printf(%c, *ptr); // 通过指针访问字符串字符 ptr++; // 指针后移 printf( ); return 0; 在上述示例中，str 是一个字符数组，即字符串。通过将 str 赋值给指针变量 ptr，ptr 就指向了字符串的第一个字符。 使用指针 ptr，通过解引用操作符（*）来访问字符串的字符。在循环中，检查当前指针指向的字符是否为 null 字符（字符串结尾的标志），如果不是，则打印该字符并将指针后移一位。这样，通过循环迭代，可以逐个字符地访问和处理字符串。 需要注意的是，由于字符串以 null 字符结尾，因此在使用指针引用字符串时，需要通过判断 null 字符来确定字符串的结束位置。 通过指针引用字符串，可以进行各种字符串操作，例如查找、拷贝、连接等。指针算术运算也可以用于在字符串中移动和定位。然而，同样需要小心确保指针不越界，并遵循指针的安全使用规则，以避免潜在的错误和内存访问问题。 使用字符指针变量和字符数组的比较 字符数组由若干个元素组成，每个元素中放一个字符，而字符指针变量中存放的是地址（字符串第 1 个字符的地址），决不是将字符串放到字符指针变量中 可以对字符指针变量赋值，但不能对数组名赋值。 编译时为字符数组分配若干存储单元，以存放各元素的值，而对字符指针变量，只分配一个存储单元 指针变量的值是可以改变的，而数组名代表一个固定的值(数组首元素的地址)，不能改变。 字符数组中各元素的值是可以改变的，但字符指针变量指向的字符串常量中的内容是不可以被取代的。 用指针变量指向一个格式字符串，可以用它代替 printf 函数中的格式字符串 char *format;format=”a=%d,b=%f ”; printf(format,a,b);//相当于printf(“a=%d,b=%f ”,a,b); 指向函数的指针 如果在程序中定义了一个函数，在编译时，编译系统为函数代码分配一段存储空间，这段存储空间的起始地址，称为这个函数的指针。 在 C 语言中，可以定义和使用指向函数的指针来引用和调用函数。指向函数的指针可以存储函数的地址，并允许通过指针来调用该函数。 #include stdio.h// 示例函数，接受两个整数参数并返回它们的和int add(int a, int b) return a + b;int main() int (*ptr)(int, int); // 定义一个指向函数的指针 ptr = add; // 将函数名赋值给指针变量 int result = ptr(3, 4); // 通过指针调用函数 printf(函数调用的结果：%d , result); return 0; 在上述示例中，add 是一个示例函数，接受两个整数参数并返回它们的和。首先，需要使用指针语法定义一个指向函数的指针变量 ptr，通过指定函数的返回类型和参数类型。 然后，通过将函数名赋值给指针变量，将函数的地址存储在指针中。在示例中，ptr add;将函数 add 的地址赋值给指针变量 ptr。 最后，可以通过指针调用函数，使用指针后面跟上参数列表来传递参数。在示例中，ptr(3, 4)调用通过指针引用的函数，并传递参数 3 和 4。 通过指向函数的指针，可以实现一些高级的编程技巧，如回调函数、动态函数调用等。通过指针可以在运行时根据需要选择要调用的函数。然而，需要确保指针的类型与所引用的函数类型相匹配，以避免类型错误和未定义行为。 指向函数的指针作为函数参数 指向函数的指针变量的一个重要用途是把函数的地址作为参数传递到其他函数 指向函数的指针可以作为函数参数，把函数的入口地址传递给形参，这样就能在被调用的函数中使用实参函数 返回指针值的函数 一个函数可以返回一个整型值、字符值、实型值等，也可以返回指针型的数据，即地址。其概念与以前类似，只是返回的值的类型是指针类型而已 在 C 语言中，可以定义一个返回指针值的函数，该函数返回一个指针类型的值，指向某个数据或数据结构。通过返回指针值，可以在函数内部动态分配内存，并返回指向该内存的指针。 #include stdio.h#include stdlib.h// 返回动态分配内存的整数数组的指针int* createIntArray(int size) int* arr = (int*)malloc(size * sizeof(int)); // 使用malloc动态分配内存 // 假设分配内存成功，将数组元素初始化为0 for (int i = 0; i size; i++) arr[i] = 0; return arr; // 返回指向数组的指针int main() int* ptr = createIntArray(5); // 调用返回指针值的函数，接收返回的指针 printf(动态分配的数组：); for (int i = 0; i 5; i++) printf(%d , ptr[i]); // 通过指针访问和打印数组元素 printf( ); free(ptr); // 释放动态分配的内存 return 0; 在上述示例中，createIntArray 是一个返回指针值的函数。函数接受一个整数参数 size，表示要分配的数组大小。在函数内部，使用 malloc 动态分配了 size 个整数大小的内存空间，并将指向该内存的指针 arr 返回。 在 main 函数中，通过调用 createIntArray 函数，并将返回的指针赋值给指针变量 ptr。然后，使用指针 ptr 可以访问和操作动态分配的数组。 在示例中，遍历指针 ptr，并打印数组元素的值。 最后，使用 free 函数释放动态分配的内存，以避免内存泄漏。 通过定义返回指针值的函数，可以实现动态分配内存，并将该内存的地址返回给调用者。这在需要在函数外部访问和操作动态分配的数据时非常有用。然而，需要小心确保在使用返回的指针之前，进行合适的内存管理和错误处理。 指针数组和多重指针指针数组和多重指针是在 C 语言中用于处理指针的概念。它们提供了对多个指针的管理和操作，使得可以更灵活地处理和访问内存中的数据。 指针数组：指针数组是一个数组，其元素都是指针类型。每个元素可以指向不同类型的数据或数据结构。通过指针数组，可以有效地管理多个指针，每个指针可以指向不同的对象。 例如，可以定义一个指针数组来存储多个字符串的地址： char* strArray[3]; // 定义一个指针数组，每个元素指向一个字符串 指针数组可以用于实现诸如字符串数组、指向不同类型对象的数组、函数指针数组等。 多重指针：多重指针是指指向指针的指针。通过多重指针，可以实现对指针的间接引用和操作。多重指针在某些情况下非常有用，特别是在需要修改指针本身的值时。 例如，可以定义一个多重指针来引用一个整型指针的地址： int** ptrPtr; // 定义一个多重指针，指向一个整型指针 多重指针常用于动态内存分配、多级指针结构的数据结构、函数传递指针的指针等情况。 指针数组和多重指针的主要作用如下： 灵活存储和管理多个指针：指针数组允许存储和管理多个指针，每个指针可以指向不同的数据或对象。这对于需要处理多个相关指针的情况非常有用，例如字符串数组、函数指针数组等。 动态内存分配和释放：多重指针在动态内存分配和释放中非常有用。通过多重指针，可以通过引用指向指针的指针来修改指针的值，从而实现对动态分配内存的管理和释放。 传递指针的指针：多重指针可以用于函数参数，允许在函数内部修改指针的值，并使得修改在函数外部也可见。这对于需要在函数内部修改指针本身的值的情况非常有用。 总而言之，指针数组和多重指针提供了对指针的灵活管理和操作的能力。它们在 C 语言中常用于处理复杂的数据结构、动态内存分配、函数指针等情况下，提供了更高级的指针使用方式，使得程序可以更加灵活地操作和处理内存中的数据。 动态内存分配与指向它的指针变量 非静态的局部变量是分配在内存中的动态存储区的，这个存储区是一个称为栈的区域C 语言还允许建立内存动态分配区域，以存放一些临时用的数据，这些数据需要时随时开辟，不需要时随时释放。这些数据是临时存放在一个特别的自由存储区，称为堆区 动态内存分配是指在程序运行时，根据需要在堆（Heap）中动态地分配内存空间。与静态内存分配相对，静态内存分配是在编译时为变量或数据结构分配固定大小的内存空间。 在 C 语言中，动态内存分配使用了关键的函数：malloc，calloc，free，realloc。malloc 函数用于动态分配内存空间，而 free 函数用于释放之前分配的内存空间。 当使用 malloc 函数时，需要指定要分配的内存空间的大小，并返回一个指向该内存空间的指针。这样就可以通过指针来引用和操作这块动态分配的内存。 以下是一个示例代码，展示了动态内存分配和指向它的指针变量的使用： #include stdio.h#include stdlib.hint main() int* ptr; // 声明一个指针变量 ptr = (int*)malloc(sizeof(int)); // 动态分配一个整数大小的内存空间 if (ptr == NULL) printf(内存分配失败 ); return 1; *ptr = 42; // 使用指针访问和修改动态分配的内存 printf(动态分配的内存中的值：%d , *ptr); free(ptr); // 释放动态分配的内存 return 0; 在上述示例中，首先声明一个指针变量 ptr。然后，使用 malloc 函数动态分配一个整数大小的内存空间，并将返回的指针赋值给 ptr。通过将 sizeof(int)作为参数传递给 malloc，可以确保分配的内存空间足够存储一个整数。 接下来，可以使用指针 ptr 来访问和修改动态分配的内存，例如将整数值 42 存储到分配的内存中。 最后，在不再需要动态分配的内存时，使用 free 函数释放该内存空间。这是非常重要的，以防止内存泄漏和资源浪费。 动态内存分配与指向它的指针变量的使用允许在程序运行时根据需要分配和释放内存空间。这对于需要在运行时动态管理数据的大小和生命周期的情况非常有用，例如动态创建数组、构建动态数据结构等。然而，需要谨慎使用动态内存分配，确保适当地管理和释放动态分配的内存，以避免内存泄漏和潜在的错误。 有关指针的小结指针的基本概念：指针是一个变量，其值是内存地址。指针可以指向不同类型的数据或数据结构。通过指针可以访问和操作所指向的数据。指针的声明和初始化：指针的声明使用指针符号 ，例如 int ptr;表示 ptr 是一个指向整数的指针。可以通过将变量的地址赋值给指针来初始化指针，例如 ptr 将指向 num 变量的地址赋值给 ptr。指针的运算：可以使用运算符解引用指针，获取指针所指向的值，例如ptr 表示指针 ptr 所指向的值。可以使用运算符获取变量的地址，例如num 表示变量 num 的地址。可以使用指针进行算术运算，例如指针的加法、减法等。指针与数组：数组名可以看作是指向数组第一个元素的指针。可以使用指针对数组进行遍历、修改和传递等操作。通过指针可以实现动态分配数组和动态管理数组大小。指针与字符串：字符串在 C 语言中是以字符数组的形式存储的。可以使用指针引用和操作字符串。使用指针可以实现字符串的遍历、拷贝、连接等操作。指向函数的指针：可以定义指向函数的指针，存储函数的地址。通过指针可以调用函数，实现函数的动态调用和回调机制。动态内存分配与指针：使用 malloc 函数可以在程序运行时动态分配内存空间。通过指针引用和操作动态分配的内存。使用 free 函数释放动态分配的内存，防止内存泄漏。 指针是 C 语言中强大而灵活的概念，它允许直接访问内存和数据，并提供了动态分配内存、处理复杂数据结构、实现高级编程技巧等能力。指针的正确使用需要注意内存管理、空指针检查等细节，以确保程序的正确性和健壮性。理解和掌握指针的相关知识点和用法，有助于更好地理解和编写 C 语言程序。 总结 首先要准确地弄清楚指针的含义。指针就是地址，凡是出现“指针”的地方，都可以用“地址”代替，例如，变量的指针就是变量的地址，指针变量就是地址变量 要区别指针和指针变量。指针就是地址本身，而指针变量是用来存放地址的变量。 什么叫“指向”？地址就意味着指向，因为通过地址能找到具有该地址的对象。对于指针变量来说，把谁的地址存放在指针变量中，就说此指针变量指向谁。 注意：只有与指针变量的基类型相同的数据的地址才能存放在相应的指针变量中。 void * 指针是一种特殊的指针，不指向任何类型的数据，如果需要用此地址指向某类型的数据，应先对地址进行类型转换。可以在程序中进行显式的类型转换，也可以由编译系统自动进行隐式转换。无论用哪种转换，读者必须了解要进行类型转换 要深入掌握在对数组的操作中怎样正确地使用指针，搞清楚指针的指向。一维数组名代表数组首元素的地址 有关指针变量的定义形式的归纳比较 指针运算(1) 指针变量加（减）一个整数例如：p++,p–,p+i,p-i,p+i,ｐ-i 等均是指针变量加（减）一个整数。将该指针变量的原值(是一个地址)和它指向的变量所占用的存储单元的字节数相加（减）。(2) 指针变量赋值将一个变量地址赋给一个指针变量, 不应把一个整数赋给指针变量(3) 两个指针变量可以相减如果两个指针变量都指向同一个数组中的元素，则两个指针变量值之差是两个指针之间的元素个数(4) 两个指针变量比较若两个指针指向同一个数组的元素，则可以进行比较指向前面的元素的指针变量“小于”指向后面元素的指针变量如果 p1 和 p2 不指向同一数组则比较无意义(5) 指针变量可以有空值该指针变量不指向任何变量，可以这样表示：pNULL;","categories":["1.语言","C语言","指针"]},{"title":"指针基础","path":"/2024/12/19/1-语言-C语言-指针-指针基础/","content":"指针基础概念: 地址:变量在内存中的编号。 地址变量: 存放地址的变量。 地址 pointer (指针) int a = 5; a = 4;int *p = a, b; 指针定义: 存储类型 数据类型 *指针变量名；int *pa;char *pc; 赋值并初始化: int a = 5;int *p = a; //初始化,定义同时并赋值 赋值: int a = 5;int *p;p = a; //赋值*p = 6; 引用: * 与 互为逆运算,自右向左。 int a = 0x666;int *p = a; //假如a的地址为0x20008000, p的地址为0x30008000printf(%#x , a); //0x666printf(%#x , p); //0x20008000printf(%#x , *p); //0x666printf(%#x , a); //0x20008000printf(%#x , p); //0x30008000printf(%#x , *(p)); //0x20008000p == a == (*p)a == *p == *(a) 指针运算关注*p++与*++p 的区别。 野指针void 指针void 型指针可以赋值给其他任意类型，但其他类型不可以赋值给 void 类型指针. 赋值给其他类型时，建议加上强制类型转换. int *p = (int *)malloc(N); const 指针int a = 99;int const a = 99;const int a = 99; const 使 a 常量化。 int a = 99; int b = 999;int *p = a; *p=*p+1; //通过p修改a的值p = b; //p指向其他变量int *const pp = a; //pp是常量//pp = b; //pp是常量不可以改变p的值，即不可以改变p的指向。*pp = *pp+1; //不可改变指向,但可以改变指向的值.\tint const *qq = a; //(*qq)是常量const int *qq = a; //同上，两种效果相同。//*qq=*qq+1; //*qq是常量,不可以通过*qq去改变a的值。qq=b; //qq可以指向其他的变量。a=a+1;//*qq常量化，表示不能通过*qq去改变a的值，但a可以改变。int const * const ppp = a; //ppp和*ppp都被常量化。const int *const ppp = a; 练习：1.指针的加减法： char a = 100;char *p = a; 若：a 的地址为 0x20008000,则 p+1=0x______;*p + 1 =0x_____;(int )p + 1 = 0x______;(int *)p + 1 = 0x______;(char *)p + 1 = 0x______;(char)p + 1 = 0x______; 2.以下程序的运行结果是 ______。 #include stdio.hmain()\tint m=1, n=2, *p=m, *q=n, *r;\tr=p; p=q; q=r;\tprintf(%d,%d,%d,%d ,m,n,*p,*q); 3、若有语句 int *point,a4;和 point下面均代表地址的一组选项是 _______. a)a, point, *ab)*a, a, *pointc)*point, *point, ad)a, *point , point","categories":["1.语言","C语言","指针"]},{"title":"指针定义","path":"/2024/12/19/1-语言-C语言-指针-指针定义/","content":"void funArray(int *);void funArray(int []);void funArray2(int(*)[]);void funArray2(int [][]);void pointArray(int **);void pointArray(int *[]);void funPoint(int (*)(int, char **));int (*p[3])[3];int (*p)[3];void arrayPointArray(int (*[])[3]); typedef void (*fun)(int );typedef void (*)(int) fun;//此定义有误？fun function (fun);void (*function(void (*) (int)))(int);","categories":["1.语言","C语言","指针"]},{"title":"结构体占用字节大小计算","path":"/2024/12/19/1-语言-C语言-结构体占用字节大小计算/","content":"结构体的字节对齐在编程中，结构体的字节数占用通常依赖于其内部最大数据类型的字节长度。为了确保数据在内存中的正确对齐，有时会需要进行字节补齐。了解这一点，可帮助我们更有效地使用结构体。 字节对齐规则 最大数据类型：结构体的总字节数需是其最大成员数据类型所占字节数的倍数。这意味着，如果某个结构体包含不同的数据类型，必须根据占用字节数最多的类型来调整整个结构体的字节数。 示例： 如果结构体中最大的变量是 short（占用 2 个字节），那么整个结构体的大小必须是 2 的倍数。如果总占用字节数是 7，那么将增加 1 个字节，使其变为 8。 如果最大的是 int（占用 4 个字节），则结构体的大小需是 4 的倍数，例如 8 或 12。 示例结构体struct example1 char a; // 1 byte short b; // 2 bytes char c; // 1 byte char d; // 1 byte; // 总占用字节数为6，满足最大数据类型short的2的倍数要求struct example2 char a; // 1 byte short b; // 2 bytes char d; // 1 byte; // 总占用字节数为6，依然满足2的倍数要求struct example3 char a; // 1 byte char c; // 1 byte char d[5]; // 5 bytes; // 总占用字节数为7，不满足2的倍数，因此需要补齐至8struct example4 char a; // 1 byte short b; // 2 bytes char c[5]; // 5 bytes; // 总占用字节数为10，满足2的倍数要求（最大的是short）struct example5 char a; // 1 byte char c[5]; // 5 bytes short b; // 2 bytes; // 总占用字节数为8，满足2的倍数要求 字节非对齐设置通过设置结构体为字节非对齐的方式，开发者可以减少内存占用，但这种方法会引入潜在的性能问题。因为某些处理器对内存的访问要求严格，可能导致崩溃或严重降低访问速度。在实际开发中，应根据具体需要权衡字节对齐与内存使用的优劣。 结构体成员位设置开发者可以通过特定的编译器指令或展现形式来设置结构体成员所占位。 也可使使用 #pragma pack 可以强制编译器以特定的字节对齐方式来存储结构体，允许开发者控制每个成员的开始对齐位置。 各种数据类型的组合结构体能够包含不同类型的数据，只要它们的字节长度被系统明确规定。例如，结构体可以包含 int、float、double 等多种类型，进行复杂数据的组合和存储。然而，值得注意的是，结构体不能直接包含自身，但可以包含指向自身的指针，这使得在构建数据结构如链表时非常有效。","categories":["1.语言","C语言"]},{"title":"使用服务启动程序日志乱码解决","path":"/2024/12/19/1-语言-Shell-使用服务启动程序日志乱码解决/","content":"使用 service 启动 Qt 程序时，输出的日志是中文乱码 直接启动程序，输出的日志却是正常的，这种问题解决方案如下 方案一编辑 service 文件 vim /sbin/service 在 env -i 后面加上 LANG=$LANG 系统本身需支持中文语言包 方案二在启动脚本中引入环境变量","categories":["1.语言","Shell"]},{"title":"Windows的启动","path":"/2024/12/19/0-平台-平台相关-Windows的启动/","content":"零、boot 的含义在计算机领域，”启动”这个词用英语是 boot。但这个词原本的意思是“靴子”，那么，启动与靴子之间有什么联系呢？其实，这个词源自于 bootstrap（鞋带）的缩写，来源于一句谚语：“pull oneself up by one’s bootstraps”。这句谚语的字面意思是“拉着鞋带把自己拉起来”，显然，这是个不可能完成的任务。 在计算机的早期，工程师们使用这个比喻来描述一个矛盾的过程：要启动计算机，必须先运行程序，但如果计算机未启动，就无法运行程序。实际上，早期计算机的启动过程确实如此。工程师们需想尽办法将一小段程序装入内存，之后计算机才能正常运行。逐渐地，“拉鞋带”的说法便被简化为 boot。 启动过程可以分为四个阶段。 第一阶段：BIOS在上世纪 70 年代初，只读内存（Read-Only Memory，简称 ROM）被发明。开机程序被写入 ROM 芯片中，当计算机通电后，第一件事便是读取这块芯片。这块芯片中的程序称为 基本输入输出系统（Basic InputOutput System），简称为BIOS。 1.1 硬件自检BIOS 程序首先进行 硬件自检（Power-On Self-Test，简称 POST），确认计算机硬件是否能满足运行的基本条件。如果硬件出现问题，主板会发送不同的蜂鸣声音来提示错误，从而启动过程也会中止。 反之，如果硬件正常，屏幕上将显示 CPU、内存、硬盘等硬件信息，确保一切就绪后，BIOS 会把控制权转给下一阶段的启动程序。 1.2 启动顺序硬件自检完成后，BIOS 需要确定“下一阶段的启动程序”存放在哪个设备上。为此，BIOS 会参考 启动顺序（Boot Sequence），这是一个设备的优先级列表，按照此顺序搜索可启动的设备。用户可以通过 BIOS 设置界面自定义此启动顺序。 第二阶段：主引导记录BIOS 根据启动顺序，将控制权转交给第一位的存储设备。计算机会读取该设备的第一个扇区，也就是前面 512 个字节。如果这 512 个字节的最后两个字节分别是 0x55 和 0xAA，这表示该设备能够用于启动；如果不是，则继续查找启动顺序中的下一个设备。 这部分 512 字节的内容称为 主引导记录（Master Boot Record，简称 MBR）。 2.1 主引导记录的结构MBR 总计 512 个字节，其中主要有三个组成部分： 第 1-446 字节：包含调用操作系统的机器码。 第 447-510 字节：称为 分区表（Partition Table），负责描述硬盘上各个分区的情况。 第 511-512 字节：主引导记录签名，表示 MBR 正常。 2.2 分区表分区的主要优势在于能够在一个硬盘上安装多个操作系统。分区表长仅 64 个字节，最多可以定义四个 主分区。每个主分区由独立的 16 个字节组成，包含多个信息，如激活状态、分区类型以及位置等。 对于最大分区容量的计算，如果每个扇区为 512 个字节，那么每个主分区最大可达 2TB，而整个硬盘的可利用空间也受到此限制。如需更大容量，可通过增加扇区字节数或分区数量来实现。 第三阶段：硬盘启动计算机此时需将控制权转交给硬盘触发的某个分区，情况大致分为三种。 3.1 情况 A：卷引导记录在四个主分区中，有且仅有一个是被激活的。计算机读取激活分区的第一个扇区，这部分数据称为 卷引导记录（Volume Boot Record，简称 VBR）。VBR 的关键作用在于指向操作系统在该分区内的具体位置，随后计算机会加载操作系统。 3.2 情况 B：扩展分区与逻辑分区随着硬盘的容量不断增加，四个主分区已显不足。为了解决这个问题，扩展分区（Extended Partition）的概念应运而生。扩展分区内可以包含多个 逻辑分区（Logical Partition）。 计算机首先会读取扩展分区的第一个扇区，称为 扩展引导记录（Extended Boot Record，简称 EBR）。在这个记录中，也有一个分区表，但仅限于两项，即两个逻辑分区。计算机接下来会继续从逻辑分区的分区表中读取，直到仅剩下自己的单一项。 3.3 情况 C：启动管理器在这种情况下，计算机读取 MBR 前 446 字节的机器码后，不会立即交给某一特定分区，而是运行预先安装的 启动管理器（Boot Loader），由用户选择想要启动的操作系统。在 Linux 环境中，最流行的启动管理器是 Grub。 第四阶段：操作系统当控制权被转交给操作系统后，操作系统的内核首先会被加载到内存中。以Linux为例，系统会首先加载 /boot 目录下的内核文件。内核加载成功后，系统会启动第一个程序 /sbin/init。 /sbin/init 的主要功能是根据配置文件（如 Debian 系统中的 /etc/inittab）生成 init 进程。这个进程是 Linux 系统启动后第一个被激活的进程，其进程编号是 1，之后所有其他进程均为其后代。 随后，init 线程将系统的各个模块加载进来，包括窗口程序和网络程序，最终执行 /bin/login 程序，展示登录界面，等待用户输入用户名和密码。 至此，整个计算机启动过程就此完成。","categories":["0.平台","平台相关"]},{"title":"EMC","path":"/2024/12/19/0-平台-平台相关-EMC/","content":"EMC（电磁兼容性）的重要性电磁兼容性（EMC）是确保产品在特定电磁环境中能够正常工作的关键性能指标。EMC 不仅涉及到设备能否抵御外部干扰，还包括设备自身是否会向外界释放干扰。任何未能通过 EMC 测试的产品都可能面临严重后果，包括功能失常、设备损坏甚至安全隐患。 EMC 的基本概念电磁兼容性是指电气设备在其电磁环境中正常工作的能力，包括： 限制无意间产生的电磁能量：设备在运行过程中不会意外地通过 radiated 或 conducted 方式释放对其他设备的干扰。 抗干扰能力：设备在受到来自外界的电磁干扰（EMI）时，保持稳定和正常的工作状态。 例如，心脏起搏器这样的医疗设备，其对电磁干扰的敏感性极高。如果周围存在强电磁干扰，它可能会影响起搏器的工作，导致心脏停跳等严重后果，这是 EMC 保障生命安全的重要体现。 EMC 研究的三大关键问题 能量来源：电磁能量的产生可能源于各类电气设备，包括家用电器、工业机床、甚至网络设备。识别并控制这些干扰源是 EMC 研究的重要一环。 抗干扰能力：设备应具备强大的抗干扰能力，这是决定电气设备故障率的重要因素。例如，某些高端服务器测得抗干扰能力能在遭遇 RFI 时，依然保持 99.9%的正常运行时间。 耦合路径：研究干扰是如何通过电缆、空气或其他媒介耦合到敏感设备上的，以便有效实施防护措施。 常见的 EMC 测试 抗扰度测试：这包括了诸如静电放电测试、脉冲群抗扰度测试、雷击浪涌测试等。通过向设备施加特定的电磁干扰，观测其是否依旧保持正常工作。 传导辐射测试：测量设备在工作状态下，向外释放的电磁干扰水平，例如电源线的传导测试。这些测试确保设备对外界的影响在规定标准之内。 电磁失效的表现EMC 干扰的影响千万不可小觑，可能导致一系列功能失效： 系统死机无响应：例如，某应用因读取到错误的输入值，程序陷入死锁而无法响应。 执行意外指令：比如，指向错误内存地址，数据丢失导致软件行为异常。 IO 表现异常：这可能表现为显示屏闪烁、按键失灵、传感器数据出现噪声等。 软件对策的实施 看门狗技术：看门狗能够监测系统是否死机并重新启动系统。这是一个务实的解决方案，特别是在多个 EMC 测试等级中，只要系统能在干扰后恢复正常，就算是通过了。 数据冗余技术：在关键功能操作中引入备份参数。例如在航空、医疗等领域，开发者往往会为关键数据采用双重存储机制，以确保即使在最复杂的电磁干扰情况下也能迅速恢复。 管理未使用的中断：对于系统中未被使用的中断，关闭相应寄存器，并通过异常中断服务例程记录并处理这些中断。 谨慎的 IO 策略：对于输入信号，可以采用滤波策略，比如多次采样以消除抖动。在模拟信号处理中，使用数字滤波器技术以确保数据的准确性。 掉电检测存储技术：结合硬件设计，采用掉电检测及瞬时 UPS 电路。系统在交替供电的条件下，如果检测到即将掉电，能及时保存关键参数以防止数据丢失。 健壮的通信协议设计：增加 CRC 校验、错误重传机制和通信故障检测，以提升设备在通信过程中的鲁棒性。","categories":["0.平台","平台相关"]},{"title":"软路由-OpenWRT","path":"/2024/12/19/0-平台-NAS-软路由-OpenWRT/","content":"Firefly Linux 开发指南 1.1. 支持设备列表¶ 主控 板卡型号 RK3568 ROC-RK3568-PCStation-P2 1.2. 登录 IP 、登录密码和 WIFI 名称¶固件默认登录 IP 为 192.168.1.1，登录密码为 firefly。 默认 WIFI 名称为 OpenWRT-XXXX，无密码 1.3. WAN 口和 LAN 口映射¶Station P2/ROC-3568-PC： 外壳 Linux 网卡 WAN 口 网口 1 eth0 LAN 口 网口 2 eth1 1.5. 固件烧录¶1.5.1. 烧写到 SD 卡（推荐）¶1.5.1.2. 使用 balenaEtcher 制作 SD 启动卡¶ 1.5.2. 烧写到 EMMC¶1.5.2.1. 下载 RK 烧录工具¶ 安装 RK 驱动助手 下载地址：https://www.t-firefly.com/doc/download/103.html#other_432 安装 Android Tools 烧写工具 下载地址：https://www.t-firefly.com/doc/download/103.html#other_431 下载 RK3566/RK3568 NorFlash2eMMCLoader 下载地址：https://www.t-firefly.com/doc/download/103.html#other_551 切换到 EMMC 存储器 断开电源，将 type-c 线接入开发板，长按 recovery 按键，插上电源上电，进入 maskrom 模式 烧写 RK356x_NorFlash2eMMC-Loader_xxx.img 烧写成功后等待 20s 左右，系统进入 Loader 模式 烧写到 EMMC 存储器 解压固件（注意烧写到 EMMC 的固件必须进行解压） 按下图右键添加一个”OpenWRT”选项，地址为 0，选择解压的固件，然后烧录 1.6. 固件编译¶1.6.1. 必要条件¶ 安装好 Ubuntu18.04 及其以上版本的系统 1.6.2. 环境搭建¶sudo apt update -ysudo apt full-upgrade -ysudo apt install -y ack antlr3 asciidoc autoconf automake autopoint binutils bison build-essential \\bzip2 ccache cmake cpio curl device-tree-compiler fastjar flex gawk gettext gcc-multilib g++-multilib \\git gperf haveged help2man intltool libc6-dev-i386 libelf-dev libglib2.0-dev libgmp3-dev libltdl-dev \\libmpc-dev libmpfr-dev libncurses5-dev libncursesw5-dev libreadline-dev libssl-dev libtool lrzsz \\mkisofs msmtp nano ninja-build p7zip p7zip-full patch pkgconf python2.7 python3 python3-pip libpython3-dev qemu-utils \\rsync scons squashfs-tools subversion swig texinfo uglifyjs upx-ucl unzip vim wget xmlto xxd zlib1g-dev 1.6.3. 源码下载¶git clone https://github.com/FireflyTeam/ledecd lede./scripts/feeds update -a./scripts/feeds install -amake download -j$(nproc) 1.6.4. 源码编译¶ 编译 ROC-RK3568-PC/Station-P2 cp config/station_p2_base_defconfig .configmake defconfigmake V=s -j$(nproc) 1.6.5. 编译成功之后¶编译成功之后，固件所在路径：bin/targets/rockchip/armv8/ -rw-r--r-- 1 user1 user1 26085956 8月 17 09:49 Station_P2_LEDE_GPT_RAW_20220817.zip 1.7. 扩展分区¶烧录完固件之后，一般只有几百 MB 的空间供使用，因此需要将分区进行扩展。这一步操作可以在 luci 界面进行配置： 进入磁盘管理，将剩余的空间创建为一个新分区 点击磁盘管理 修改磁盘 创建一个新分区 格式化新分区为 ext4 文件系统 进入挂载点，将新分区挂载到 /overlay 点击挂载点 添加一个新的挂载点 启用此挂载点，并把 UUID 所在分区新创建分区，挂载点为 /overlay 记得保存并应用 保存挂载点信息 × 1 检测到网页存在资源资源存夸克网盘在线查看 查看资源 manual_openwrt.md.txt 未知大小 转存网盘","tags":["clippings"],"categories":["0.平台","NAS"]},{"title":"嵌入式初始配置","path":"/2024/12/19/0-平台-嵌入式-嵌入式初始配置/","content":"Firefly Linux 开发指南 1.1. Ubuntu Desktop 系统¶Ubuntu Desktop 系统开机启动后，自动登录到 firefly 用户。 如果有连接调试串口，串口终端自动登录 root 用户。 firefly 用户密码： firefly root 用户：默认没有设置 root 密码，firefly 用户通过 sudo passwd root 命令自行配置 root 密码。 1.2. Ubuntu Minimal 系统¶ Ubuntu Minimal 系统开机启动后，自动登录到 root 用户，密码为 firefly。 系统已经添加 OpenGL ES, OpenCL, DRM 支持。 1.3. Buildroot 系统¶ 用户：root 密码：firefly 2. ADB 使用¶2.1. ADB¶用 Type-C data cable 连接设备和主机，然后输入以下命令： 2.2. 网络 ADB¶查看开发板 IP 地址，PC 端通过网络访问： adb connect + IPadb shell 注意点： AIO-3399-JD4 AIO-3399J 要支持使用 ADB 需要修改 kernel/arch/arm64/boot/dts/rockchip/rk3399-firefly-aio.dtsi，将 usbdrd_dwc3_0 设置为 peripheral 模式，之后该 usb 只能作为从设备使用。 usbdrd_dwc3_0 dr_mode = peripheral;; 同理，AIO-3399Pro-JD4 要支持使用 ADB 需要修改 kernel/arch/arm64/boot/dts/rockchip/rk3399pro-firefly-aioc.dts。 然后重新编译和烧写 Kernel。 4. 导出设备系统¶当用户已经在一台设备上完成工作环境的部署，需要将当前环境完整导出，以批量部署到其它同设备上，可以通过导出设备文件系统来备份当前的开发环境。 导出设备系统分为两步： 在设备上导出 Ubuntu 根文件系统 rootfs； 二次打包完整固件，将 Ubuntu rootfs 与发布固件的其他分区组合，完成二次打包，生成新的完整固件。 4.1. 导出 rootfs¶注意以下操作均在设备端上操作！ 在设备的 Ubuntu 环境下，安装 fireflydev： sudo apt updatesudo apt install fireflydev 安装 fireflydev 后，就能使用 ff_export_rootfs 脚本导出根文件系统 建议使用容量较大的移动硬盘 导出工具会执行 apt clean 等操作以减小文件系统大小 将根文件系统导出，例如导出到 /media/firefly/AC91-C4AE/ 目录（需要等待一定时间）： ff_export_rootfs /media/firefly/AC91-C4AE/ 压缩文件系统，删除不必要的空白空间以减少存储器资源的占用： # 有部分客户说导出的 rootfs 大小为 3.3G，可实际只用了 3G，原因是没有对 rootfs 进行压缩e2fsck -p -f Firefly_Ubuntu_18.04.6_rootfs.imgresize2fs -M Firefly_Ubuntu_18.04.6_rootfs.img 4.2. 二次打包完整固件¶注意以下操作均在 PC 机端（x86-64 架构）上操作！ 安装必要的软件包：sudo apt-get install lib32stdc++6 下载二次打包工具：firefly-linux-repack（提取码：1234） 解压二次打包工具： tar -xzf firefly-linux-repack.tgzcd firefly-linux-repack 目录如下： firefly-linux-repack ├── bin │ ├── afptool │ └── rkImageMaker ├── pack.sh # 打包脚本 ├── Readme_en.md ├── Readme.md └── unpack.sh # 解包脚本 解包操作： 把官方发布的 Ubuntu 固件拷贝到 firefly-linux-repack 根目录，重命名为 update.img，执行解包脚本 unpack.sh。解包完成后，各分区文件在 output 目录下。 mv /path/to/ROC-RK3566-PC_Ubuntu18.04-r21156_v1.2.4a_220519.img update.img./unpack.sh 打包操作：保持当前目录结构，文件名等不变，接入移动硬盘到 PC 机，把前面导出的 Ubuntu rootfs 替换 output/Image/rootfs.img，然后执行打包脚本 pack.sh。 cp /media/customer/1878-4615/Firefly_Ubuntu_18.04.6_rootfs.img /path/to/firefly-linux-repack/output/Image/rootfs.img./pack.sh 新的完整固件为当前目录的 new_update.img。 5. GPIO 配置与使用¶GPIO, 全称 General-Purpose InputOutput（通用输入输出），是一种软件运行期间能够动态配置和控制的通用引脚。 以下通过控制 ROC-RK3399-PC Pro 的 LED 为例，对于其他设备，方法是类似的。 ROC-RK3399-PC Pro 的主控是 RK3399，RK3399 有 5 组 GPIO bank：GPIO0GPIO4，每组又以 A0A7, B0B7, C0C7, D0~D7 作为编号区分。 5.1. GPIO 编号计算¶ROC-RK3399-PC Pro 板载两个 LED，如下： DIY_LED 网络是接到引脚 GPIO0_B5： PIO pin 脚计算公式： GPIO 小组编号计算公式： 例如 GPIO0_B5： bank = 0; // GPIO0_B5 = 0, bank ∈ [0,4]group = 1; // GPIO0_B5 = 1, group ∈ (A=0), (B=1), (C=2), (D=3)X = 5; // GPIO0_B5 = 5, X ∈ [0,7]number = group * 8 + X = 1 * 8 + 5 = 13;pin = bank * 32 + number = 0 * 32 + 13 = 13; 注意：这个引脚在官方发布的固件中默认已被 LED 子系统占用，因此首先需要找到以下节点将其 disable！ ROC-RK3399-PC Pro 是定义在 arch/arm64/boot/dts/rockchip/rk3399-roc-pc.dtsi： user status = disabled; // 添加这一行 label = firefly:yellow:user; linux,default-trigger = ir-user-click; default-state = off; gpios = gpio0 13 GPIO_ACTIVE_HIGH; pinctrl-names = default; pinctrl-0 = led_user;; 然后编译与重新烧写内核固件。 5.2. 用户态使用 GPIO¶1、申请 GPIO echo 13 /sys/class/gpio/export 2、配置引脚方向 查看默认引脚方向： cat /sys/class/gpio/gpio13/direction 配置成输出方向： echo out /sys/class/gpio/gpio13/direction 3、配置引脚输出电平 从前面的原理图可知，输出高电平为点亮 LED： echo 1 /sys/class/gpio/gpio13/value 熄灭 LED： echo 0 /sys/class/gpio/gpio13/value 5.3. 设备树使用 GPIO¶在设备树中配置 GPIO，需要配置引脚的功能复用与电气属性 对于 rockchip 引脚，配置如下： rockchip,pins = PIN_BANK PIN_BANK_IDX MUX phandle 其中： PIN_BANK：引脚所在的 bank PIN_BANK_IDX：引脚所在 bank 的引脚号 MUX：功能复用配置，0 表示普通 GPIO，1-N 表示特殊的功能复用 phandle：引脚一般配置，例如内部上拉、电流强度等，在 Documentation/devicetree/bindings/pinctrl/pinctrl-bindings.txt 文件中描述 配置 GPIO0_B5 引脚： rockchip,pins = 0 13 RK_FUNC_GPIO pcfg_pull_none; 此处的含义： PIN_BANK 等于 0 PIN_BANK_IDX 等于 13 RK_FUNC_GPIO 代表使用普通 GPIO 功能 pcfg_pull_none 代表普通配置 对于 LED，Linux 定义了一套 GPIO 子系统，设备树的配置如下： / gpio_led: gpio-led compatible = gpio-leds; diy_led: diy-led label = diy-led; default-state = on; // 默认打开 linux,default-trigger = default-on; // 默认触发 gpios = gpio0 13 GPIO_ACTIVE_HIGH; // 引脚设置 pinctrl-names = default; pinctrl-0 = diy_led_pin; // 引用 pinctrl ;\t;;pinctrl gpio-led-pin diy_led_pin: diy-led-pin rockchip,pins = 0 13 RK_FUNC_GPIO pcfg_pull_none; ;\t;; 然后编译与重新烧写内核固件，重启系统会看到 LED 默认点亮。 如果希望 LED 具有闪烁效果，可以修改 linux,default-trigger 属性实现： linux,default-trigger = timer; 配置该属性后，LED 默认每 500ms 间隔闪烁。 更多属性配置可以参考 Documentation/devicetree/bindings/leds/leds-gpio.txt。 以上设备树配置可以在 arch/arm64/boot/dts/rockchip/firefly-gpio-demo.dtsi 找到！有需求的用户在板极设备树中包含该文件即可（记得要首先 disable rk3399-roc-pc.dtsi 里面冲突部分）： #include firefly-gpio-demo.dtsi 6. 网络配置¶6.1. 以太网口通用参数配置¶6.1.1. 查看以太网通用参数¶以太网的通用参数包括：自协商，双工模式和接口速率 6.1.2. 配置以太网通用参数¶6.1.2.1. 打开或关闭自协商¶ethtool -s port_name autoneg on | off 6.1.2.2. 修改双工模式¶ethtool -s port_name duplex half | full 注意： 当以太网接口工作在自协商模式时，缺省情况下双工模式是和对端接口协商得到的。 当以太网接口工作在非自协商模式时，缺省情况下双工模式为全双工模式。 6.1.2.3. 修改速率¶ethtool -s port_name speed 10 | 100 | 1000 注意： 当以太网接口工作在自协商模式时，缺省情况下接口速率是和对端接口协商得到的。 当以太网接口工作在非自协商模式时，缺省情况下接口速率为接口支持的最大接口速率。 6.1.3. 配置举例¶手动设置 eth0 的接口速率为 100，工作在全双工模式下。 ethtool -s eth0 autoneg offethtool -s eth0 speed 100ethtool -s eth0 duplex full 6.2. 使用 Netplan 管理网络¶Netplan 是一个用于在 linux 系统上轻松配置网络的实用程序。您只需创建所需网络接口的 YAML 描述以及每个应配置的功能。根据此描述，Netplan 将为您选择的渲染器工具生成所有必要的配置。在 Ubuntu18.04 及其以上版本进行了支持。 6.2.1. 配置¶要配置 netplan，请 /etc/netplan/ 使用 .yaml 扩展名（例如 /etc/netplan/config.yaml）保存配置文件，然后运行 sudo netplan apply. 此命令解析配置并将其应用于系统。 注意： 如果 netplan apply 报错，说明您的 yaml 配置文件未被系统支持，请仔细检查 对于以太网口，必须保证有网线接入，并且网卡灯闪烁，才能保证 Netplan 配置生效 下面根据最常使用的工作场景进行配置，需要更多的配置案例教程，请阅读 netplan官方实例 6.2.2. 基础配置¶Netplan 支持 networkd 和 NetworkManager 两种网络后端，一般为 networkd network: version: 2 renderer: networkd 如果不存在 networkd，可以使用 NetworkManager，都是一样的。 network: version: 2 renderer: NetworkManager 6.2.3. 以太网连接：动态 IP¶network: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes eth1: dhcp4: yes 6.2.4. 以太网连接：静态 IP¶network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.10.10.3/24 nameservers: addresses: [202.96.128.86] routes: - to: 0.0.0.0/0 via: 10.10.10.1 eth1: addresses: - 10.10.10.2/24 nameservers: addresses: [202.96.128.86] routes: - to: 0.0.0.0/0 via: 10.10.10.1 6.2.5. WIFI 连接：静态 IP¶network: version: 2 renderer: networkd wifis: wlan0: dhcp4: no dhcp6: no addresses: [192.168.1.200/24] nameservers: addresses: [202.96.128.86] access-points: NETGEAR25: password: ceshizhuanyong routes: - to: 0.0.0.0/0 via: 192.168.1.1 6.2.6. WIFI 连接：动态 IP¶network: version: 2 renderer: networkd wifis: wlan0: dhcp4: yes access-points: NETGEAR25: password: ceshizhuanyong 6.3. 使用 nmcli 管理网络¶nmcli 是用来管理 NetworkManager 网络连接的命令行工具 6.3.1. 常用命令¶ 显示所有连接 显示连接信息 nmcli connection show connection_name 显示网络设备列表、其状态以及使用该设备的连接 激活连接 nmcli connection up connection_name 取消激活连接 nmcli connection down connection_name 删除连接 nmcli connection del connection_name 6.3.2. 以太网连接：静态 IP¶假设进行配置以太网网卡为 eth0，IP 为 192.168.1.1024，默认网关为 192.168.1.1，DNS 服务器为 202.96.128.86 为以太网连接添加新的连接 nmcli connection add con-name Example-Connection ifname eth0 type ethernet 设置 IPv4 地址 nmcli connection modify Example-Connection ipv4.addresses 192.168.1.10/24 将 IPv4 连接方法设置为 manual nmcli connection modify Example-Connection ipv4.method manual 设置 IPv4 默认网关 nmcli connection modify Example-Connection ipv4.gateway 192.168.1.1 设置 IPv4 DNS 服务器地址 nmcli connection modify Example-Connection ipv4.dns 202.96.128.86 激活连接 nmcli connection up Example-Connection 6.3.3. 以太网连接：动态 IP¶ 为以太网连接添加新的连接 nmcli connection add con-name Example-Connection ifname eth0 type ethernet 激活连接 nmcli connection up Example-Connection 6.3.4. WIFI 连接：动态 IP¶ 确保 WiFi 被启用（默认） 刷新可用的 Wi-Fi 连接列表： 查看可用的 Wi-Fi 接入点： nmcli dev wifi listIN-USE SSID MODE CHAN RATE SIGNAL BARS SECURITY... MyCafe Infra 3 405 Mbit/s 85 ▂▄▆█ WPA1 WPA2 使用 nmcli 连接到 Wi-Fi 连接： nmcli dev wifi connect SSID-Name password wireless-password 例如： nmcli dev wifi connect MyCafe password wireless-password 请注意，如果要禁用 Wi-Fi 状态： 6.4. 快速创建无线 AP 热点¶6.4.1. 对无线热点的 IP 局域网段无要求¶在这种情况下，只需要使用 nmcli 命令创建一个无线 AP 热点即可： nmcli device wifi hotspot ifname wlan0 con-name MyHostspot ssid MyHostspotSSID password 12345678 说明： con-name：连接名称：这里设置为 MyHostspot（可自定义） ssid：创建的 AP 热点的名称：这里设置为 MyHostspotSSID（可自定义） password：创建的 AP 热点的密码：这里设置为 12345678（可自定义） 6.4.2. 对无线热点的 IP 局域网段有要求¶请阅读章节《创建桥接无线 AP》 6.5. 创建桥接无线 AP 热点¶6.5.1. 功能需求¶假设有一局域网，网段为 10.10.0.0，掩码为 255.255.255.0。Firefly 的开发板，以下简称 Firefly Board，其网口通过路由器 Router，获取到本局域网内的动态 IP 地址：为 10.10.0.2。 需求：将系统配置成软路由，具体要求如下： （1）Firefly Board 开启一个无线 AP 热点，平板和手机等外设通过该无线 AP 热点访问网络，进行上网。 （2）Firefly Board 开启的无线热点局域网为：192.168.4.1 （3）Firefly Board 如果有多个网口，要求 eth0 作为 WAN 口功能，自动从路由器获取 IP 地址，eth1 作为 LAN 口功能，能够为接入的设备分配 192.168.4.0/24 网段的 IP 地址。 网络拓扑如下： 6.5.2. 安装管理 AP 热点必要的软件包¶安装 hostapd：hostapd 可以用来模拟软 AP，所以是实现该功能必须的： 允许 hostapd 开机启动，这样重启之后无线 AP 热点会自动打开 systemctl unmask hostapdsystemctl enable hostapd 安装 isc-dhcp-server：isc-dhcp-server 用于为接入无线 AP 的设备自动分配 IP 地址和 DNS 服务器地址 apt install isc-dhcp-server 允许 isc-dhcp-server 开启启动 systemctl enable isc-dhcp-server 安装 netfilter-persistent iptables-persistent：用于保存防火墙规则 apt install netfilter-persistent iptables-persistent 安装 bridge-utils：用于创建虚拟网桥 6.5.3. 配置 Netplan¶目的是创建网桥 br0，网桥 IP 为 192.168.4.1。允许系统 eth0 网卡分配 IP 地址，禁止系统为 eth1 网卡分配 IP 地址，将 eth1 网卡绑定到网桥 br0。 假设 netplan 的配置文件为：/etc/netplan/netplan.yaml，内容如下所示： network: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes eth1: dhcp4: no bridges: br0: dhcp4: no addresses: - 192.168.4.1/24 interfaces: - eth1 接着运行如下命令启用网络配置： 6.5.4. 配置 hostapd¶创建一个 hostapd.conf 配置文件，用来设置无线热点的名称，密码，信道等属性 在其中写入如下内容： country_code=CNinterface=wlan0bridge=br0ssid=Example-Wifi-Namehw_mode=gchannel=11macaddr_acl=0auth_algs=1ignore_broadcast_ssid=0wpa=2wpa_passphrase=12345678wpa_key_mgmt=WPA-PSKwpa_pairwise=TKIPrsn_pairwise=CCMP 重要参数说明： country_code：国家码，中国使用 CN interface：开启无线 AP 热点的无线网卡 bridge：绑定到 br0 网桥，使得无线 AP 热点和以太网口在同一个局域网内 hw_mode：设置无线模式 channel：信道 ssid：无线 AP 名称，这里设置 Example-Wifi-Name wpa_passphrase：无线 AP 密码，这里设置为 12345678 关于更多，hostapd.conf 的配置无疑是非常复杂的，hw_mode 支持的模式有 a，g，channel 信道与 hw_mode，country_code 等都有关系，这里不再展开。如果需要对这些无线参数进行更自动化且紧密的配置，可以使用 OpenWRT 软路由系统来代替 Ubuntu 系统。 接下来，需要配置 hostapd 的全局配置文件 取消 DAEMON_CONF 的注释，设置它的值为上面创建的 /etc/hostapd.conf # Defaults for hostapd initscript# # See /usr/share/doc/hostapd/README.Debian for information about alternative# methods of managing hostapd.## Uncomment and set DAEMON_CONF to the absolute path of a hostapd configuration# file and hostapd will be started during system boot. An example configuration# file can be found at /usr/share/doc/hostapd/examples/hostapd.conf.gz#DAEMON_CONF=/etc/hostapd.conf# Additional daemon options to be appended to hostapd command:-# -d show more debug messages (-dd for even more)# -K include key data in debug messages# -t include timestamps in some debug messages## Note that -B (daemon mode) and -P (pidfile) options are automatically# configured by the init.d script and must not be added to DAEMON_OPTS.##DAEMON_OPTS= 重启 hostapd 服务 systemctl restart hostapd 到此，已经可以通过手机等设备，查看到有一个无线 AP 热点开启，名称为“Example-Wifi-Name”，但是连接之后无法为设备分配 IP 地址，设备会立即断开。 6.5.5. 配置 isc-dhcp-server¶isc-dhcp-server 作为一个 dhcp 服务器，为接入无线 AP 节点的设备，比如拓扑图中的 Laptop1 和 Laptop2 自动分配 IP 地址和 DNS 服务器地址。 编辑 /etc/dhcp/dhcpd.conf， 用如下内容进行替换： # 为设备指定DNS地址，多个DNS使用,隔开option domain-name-servers 202.96.128.86,202.96.128.166,8.8.8.8,114.114.114.114;default-lease-time 600;max-lease-time 7200;ddns-update-style none; ddns-updates off;subnet 192.168.4.0 netmask 255.255.255.0 range 192.168.4.2 192.168.4.200; option routers 192.168.4.1; option broadcast-address 192.168.4.255; option subnet-mask 255.255.255.0; 重要参数说明： domain-name-servers：DNS 服务器地址列表，为接入 192.168.4.0/24 网段的设备，分配 DNS subnet 192.168.4.0 netmask 255.255.255.0：定义子网网段 192.168.4.0/24 range 192.168.4.2 192.168.4.200：分配的 IP 地址范围 option routers 192.168.4.1：默认路由 option broadcast-address 192.168.4.255：广播地址 option subnet-mask 255.255.255.0：子网掩码 重启 isc-dhcp-server，让配置生效： systemctl restart isc-dhcp-server 6.5.6. 开启 IP 转发¶经过如上内容的配置，接入 eth1 的设备，和连接入无线 AP 热点的设备，都能获取到 192.168.4.0/24 网段的 IP，且都能 ping 通 192.168.4.1，也可以查看到设备获取到的 DNS 服务器地址。但是设备还无法访问 internet。 开启 IP 转发 sysctl -w net.ipv4.ip_forward=1 设置 MASQUERADE（地址欺骗）。MASQUERADE 与 SNAT 作用大致一样，MASQUERADE 不用指定明确的 IP，会动态的将报文的源地址修改为指定网卡上可用的 IP 地址。 iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 注意，这里指定为 eth0，让 Firefly Board 所有的 IP 包全部转发到 eth0，让外设能够进行上网，这里也可以指定为任何能访问外网的网卡，比如 4G 网卡 usb0，wwan0，举一反三。 现在保存 IPv4（包括上面的规则）和 IPv6 的当前防火墙规则，以便在启动时由 netfilter-persistent 服务加载： netfilter-persistent save 6.6. 使用 ip 和 netplan 配置 IP 地址和路由¶6.6.1. 静态 IP 地址配置¶一个网口接口上可以同时配置多个 IP 地址，这些 IP 地址可以属于同一网络，也可以不属于同一网络。第一个配置的 IP 地址默认为接口的主 IP 地址，后面配置的 IP 地址为接口的从 IP 地址。 6.6.1.1. 常用的 IP 配置命令：¶// 设置接口的 IP 地址ip address add PREFIX [ broadcast ADDR ] dev IFNAME// 删除接口的 IP 地址ip address del PREFIX dev IFNAME// 查看接口的 IP 地址ip address show/list [ dev IFNAME ]// 清空接口的所有 IP 地址ip address flush [ dev IFNAME ] 6.6.1.2. 配置举例：¶为 eth0 接口配置主 IP：192.168.2.2，从 IP：192.168.2.3 临时配置 ip address add 192.168.2.2/24 dev eth0ip address add 192.168.2.3/24 dev eth0 持久化配置：使用 Netplan network: version: 2 renderer: networkd ethernets: eth0: dhcp4: no addresses: - 192.168.2.2/24 - 192.168.2.3/24 6.6.2. 动态 IP 地址配置¶操作系统一般都会为网络接口自动分配 IP 地址。对于 buildroot 系统中，dhcpcd 服务会发送 dhcp 请求到 DHCP 服务器（这里的 DHCP 服务器大概率是你的路由）请求接口的 IP 地址。而在 Ubuntu 系统中，会由 NetworkManager 来完成这一过程。 临时配置 udhcpc -i eth0/eth1# 或者dhclient eth0/eth1 持久化配置：使用 netplan network: version: 2 renderer: networkd ethernets: eth0: dhcp4: yes 6.6.3. 静态路由配置¶与静态路由相对的是动态路由，动态路由有 OSPF 和 RIP，这两个协议只存在于路由器中。对于非路由器设备，如果某个目的网段无法直接到达，需要配置静态路由，告诉设备目的网段，出接口，下一跳的 IP 地址。 6.6.3.1. 常用的配置命令：¶# 查看路由表route -n # 或者netstat -rn# 添加 IP 静态路由ip route add PREFIX via ADDRESS dev IFNAME [ metric METRIC ]# 删除 IP 静态路由ip route del PREFIX via ADDRESS dev IFNAME [ metric METRIC ]# 清空 IP 路由ip route flush dev IFNAME 6.6.3.2. 配置举例：¶假设存在这样的一个网络拓扑，图中的 Router1 和 Router2 是我们的开发板设备，运行的系统是 Ubuntu 操作系统。在这个网络中，对于 Router1，网段 192.168.2.024 和网段 192.168.3.024，它们对于 Router1 属于直连网段，意味着对于 PC-A 来说，访问网段 192.168.2.024 和网段 192.168.3.024 是没有问题的，但是却不能访问网段 192.168.4.024。这是因为对于网段 192.168.4.024，对 Router1 来说是不可见的。需要在 Router1 配置静态路由，这条静态路由表明到目的网段 192.168.4.024，需要经过下一条 IP 地址为 192.168.3.224，出接口为 Router1 的 eth1。同样的，对于 Router2 来说，网段 192.168.3.024 和网段 192.168.4.024 属于直连网段，PC-B 也同样无法访问 192.168.2.024 网段，需要在 Router2 配置一条静态路由，表明到目的网络 192.168.2.024，需要经过下一跳 IP 地址为 192.168.3.124，出接口为为 Router2 的 eth1。 临时配置 对于 Router1： # 开启IP转发功能echo 1 /proc/sys/net/ipv4/ip_forward# 设置eth0, eth1的IP地址ip addr add 192.168.2.1/24 dev eth0ip addr add 192.168.3.1/24 dev eth1# 配置静态路由ip route add 192.168.4.0/24 via 192.168.3.2 dev eth1 对于 Router2： # 开启IP转发功能echo 1 /proc/sys/net/ipv4/ip_forward# 设置eth0, eth1的IP地址ip addr add 192.168.4.1/24 dev eth0ip addr add 192.168.3.2/24 dev eth1# 配置静态路由ip route add 192.168.2.0/24 via 192.168.3.1 dev eth1 持久化配置 对 Router1 和 Router2，执行以下命令永久开启 IP 转发 sysctl -w net.ipv4.ip_forward=1 对于 Router1，配置 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.2.1/24 eth1: addresses: - 192.168.3.1/24 routes: - to: 192.168.4.0/24 via: 192.168.3.2 对于 Router2，配置 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.4.1/24 eth1: addresses: - 192.168.3.2/24 routes: - to: 192.168.2.0/24 via: 192.168.3.1 6.6.4. 默认路由配置¶ 临时配置 对于通过 DCHP 服务动态获取 IP 地址的接口，操作系统会自动为其分配一条默认路由。对于静态 IP 地址配置，需要手动为其设置默认路由。 还是以上面的例子来讲解，假设 PC-A 是一个 Linux 操作系统，我们需要进行如下配置： # 配置网卡 IP，假设其网卡为eth0ip addr add 192.168.2.2/24 dev eth0# 配置默认路由ip route add 0.0.0.0/0 via 192.168.2.1 dev eth0 持久化配置：使用 Netplan network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.2.2/24 routes: - to: 0.0.0.0/0 via: 192.168.2.1 6.6.5. 调整默认路由顺序¶在双网口的开发板中，如果两个网口的 IP 地址是通过 DHCP 自动获取的，那么操作系统会生成两条默认路由，每个网口分别有一条默认路由，先插入网线的网口或者先获得 IP 的网口，会获得更高的路由优先级。如下所示，有两条默认路由，eth0 网卡的默认路由优先级高于 eth1。这就意味着开发板默认通信的时候，使用的是 eth0 网卡。 root@firefly:~# ip route listdefault via 168.168.0.1 dev eth0 proto dhcp metric 100 default via 168.168.0.1 dev eth1 proto dhcp metric 101 168.168.0.0/16 dev eth0 proto kernel scope link src 168.168.110.72 metric 100 168.168.0.0/16 dev eth1 proto kernel scope link src 168.168.110.111 metric 101 6.6.5.1. 配置举例：¶假设存在一种情况，Wireless Router1 的网段为 192.168.3.024，Wireless Router2 的网段为 192.168.2.024，此时对于 Firefly Board 来说，eth0 和 eth1 都是动态获取 IP 地址，如果 eth0 的默认路由的优先级比 eth1 的默认路由优先级高，通信时将使用 eth0 的默认路由，由于 eth0 所在网络无外网连接，Firefly Board 就无法访问 Internet，此时可以通过修改默认路由的优先级来解决。 其 Netplan 配置如下，eth1 的 metric 数值小于 eth0，数值越小优先级越高 network: version: 2 ethernets: eth0: dhcp4: yes dhcp4-overrides: route-metric: 200 eth1: dhcp4: yes dhcp4-overrides: route-metric: 100 6.7. iptables NAT 配置¶网络转换技术也称为 NAT（Network Address Translation）技术，它的基本作用就是实现私有 IP 地址和公有 IP 地址之间的转换。 在 Linux 系统中，NAT 可以细化为 SNAT（Source Network Address Translation）和 DNAT（Destinationnetwork address translation）。SNAT 也称为源地址转换技术，用于当私网主机向外网主机发起网络通信时，IP 数据包在到达外网网络之前，将 IP 数据包中的源 IP 修改为路由器或者防火墙的 IP 地址，这样外网主机就无法获知内网主机的私网 IP 地址。DNAT 也称为目标地址转换技术，用于当外网主机需要访问内网主机提供的网络服务时，比如 http，IP 数据包到达路由器或者防火墙时，由它们将 IP 数据包中的目标 IP 改为提供网络服务的私网主机 IP。 6.7.1. 常用命令¶我们可以通过配置 iptables 的 nat 表，来实现 SNAT 和 DNAT # 查看nat规则iptables -t nat -vnL# 清空nat规则iptables -t nat -F# 添加一个SNAT规则，将内网的IP，映射到外网的IPiptables -t nat -A POSTROUTING -s LocalIP -j SNAT --to-source ExtIP# 添加一个DNAT规则，将外网的IP和端口，映射到内网的IP和端口iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination LocalIP[:PORT] iptables 也支持 MASQUERADE（地址欺骗），它的作用与 SNAT 基本相同，也可以起到源地址转换的作用。在一种特殊情况中，如果外网的 IP 地址不是一个固定且长期有效的 IP 地址，比如是通过 pppoe 进行拨号动态获取的 IP 地址，就可以使用 MASQUERADE 来实现源地址转换。MASQUERADE 则不用指定明确的 IP，会动态的将报文的源地址修改为指定网卡上可用的 IP 地址。 # 添加一个MASQUERADE规则，将内网的IP，映射到外网网卡所在的IP（这里的内网IP可以省略，则默认将所有内网的IP，都映射到外网网卡所在的IP）iptables -t nat -A POSTROUTING [-s LocalIP] -o IFNAME -j MASQUERADE 6.7.2. 配置举例¶假设存在这样的一个网络拓扑，用 10.1.0.016 来模拟一个公网网络，用 192.168.1.024 来模拟私有网络。图中的机器都是用 Linux 主机进行模拟的机器。 对于 Router1，是一个连接内外网的路由器，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.3/24 eth1: addresses: - 10.1.0.7/16 同时对于 Router1，需要开启 IP 转发功能： echo 1 /proc/sys/net/ipv4/ip_forward 对于 Internet PC，是一个外网的个人主机，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.1.0.6/16 对于 Web Server，是一个私网服务器，提供 http 服务，其 netplan 配置如下： network: version: 2 renderer: networkd ethernets: eth0: addresses: - 192.168.1.100/24 routes: - to: 0.0.0.0/0 via: 192.168.1.3/24 6.7.3. SNAT¶需求：目前的网络结构中，内网主机是无法访问外网的。 添加一条 SNAT 规则，修改内网主机发往外网的 IP 数据包，将源 IP 地址为 192.168.1.024 网段的 IP，修改为 10.1.0.7 iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 10.1.0.7 验证方法： 在内网的 Web Server，ping 外网的 Internet PC ~ ping -c 4 10.1.0.6 ok PING 10.1.0.6 (10.1.0.6) 56(84) bytes of data.64 bytes from 10.1.0.6: icmp_seq=1 ttl=63 time=2.15 ms64 bytes from 10.1.0.6: icmp_seq=2 ttl=63 time=2.12 ms64 bytes from 10.1.0.6: icmp_seq=3 ttl=63 time=1.99 ms64 bytes from 10.1.0.6: icmp_seq=4 ttl=63 time=2.14 ms--- 10.1.0.6 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 7msrtt min/avg/max/mdev = 1.989/2.098/2.147/0.063 ms 在内网的 Web Server，抓包 root@firefly:/# tcpdump -i eth1 -nn icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes03:33:37.503348 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 1, length 6403:33:37.503603 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 1, length 6403:33:38.503348 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 2, length 6403:33:38.503560 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 2, length 6403:33:39.504601 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 3, length 6403:33:39.504812 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 3, length 6403:33:40.505347 IP 10.1.0.7 10.1.0.6: ICMP echo request, id 53287, seq 4, length 6403:33:40.505557 IP 10.1.0.6 10.1.0.7: ICMP echo reply, id 53287, seq 4, length 64 6.7.4. DNAT¶需求：内网 Web Server 提供 http 服务，外网主机想要访问内网的 web 网页。 添加一条 DNAT 规则，修改外网发往内网的 IP 数据包，将目的 IP 地址，和端口号，修改为内网 Web 服务器的 IP 和端口号。 iptables -t nat -A PREROUTING -d 10.1.0.7 -p tcp --dport 8000 -j DNAT --to-destination 192.168.1.100:8000 验证方法： 在外网 Internet PC 访问内网 Web Server 的 Web 服务 root@firefly:/# wget http://10.1.0.7:8000/index.html--2021-02-19 03:31:12-- http://10.1.0.7:8000/index.htmlConnecting to 10.1.0.7:8000... connected.HTTP request sent, awaiting response... 200 OKLength: 41323 (40K) [text/html]Saving to: ‘index.html’index.html 100%[===================] 40.35K --.-KB/s in 0.001s 2021-02-19 03:31:12 (29.8 MB/s) - ‘index.html’ saved [41323/41323] 6.7.5. MASQUERADE¶需求：如果连接内外网的 Router1，它的外网网卡只有一个，为 eth1，且 IP 地址动态获取。 解决方法：添加一条 MASQUERADE 规则，将内网 192.168.1.024 发往外网的 IP 数据包，修改其源 IP 地址为 eth1 网卡的 IP 地址。 iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth1 -j MASQUERADE 6.8. iptables filter 配置¶iptables 的 filter 表（过滤规则表），用于控制数据包是否允许进出及转发。filter 表可以控制的链路有 INPUT、FORWARD 和 OUTPUT。常用的动作有 ACCEPT，DROP，REJECT。 6.8.1. 通用命令¶# 清空filter表iptables -t filter -F# 显示filter表iptables -t filter -nvL 6.8.2. ACCEPT：允许数据包通过¶配置举例：默认情况下 ssh 使用 22 端口进行 tcp 通信，如果要开启远程访问，需要开启 22 端口的 tcp 连接。 iptables -A INPUT -t filter -p tcp --dport 22 -j ACCEPT 开启 ssh 访问，允许 192.168.0.024 网段进行访问 iptables -A INPUT -t filter -p tcp -s 192.168.0.0/24 --dport 22 -j ACCEPT 开启 ssh 访问，允许收到的数据包来源于 eth0 网卡 iptables -A INPUT -t filter -p tcp -i eth0 --dport 22 -j ACCEPT 开启 ssh 访问，允许 192.168.0.024 网段中 MAC 地址为 00:50:8D:FD:E6:32 的主机进行访问 iptables -A INPUT -t filter -p tcp -s 192.168.0.0/24 --dport 22 -m mac --mac-source 00:50:8D:FD:E6:32 -j ACCEPT 6.8.3. REJECT：拒绝数据包通过¶REJECT 动作的常用选项为–reject-with（使用–reject-with 选项，可以设置提示信息，当对方被拒绝时，会提示对方为什么被拒绝） 对于 ICMP 协议，可用值如下，如果不提供，默认为 icmp-port-unreachable icmp-net-unreachableicmp-host-unreachableicmp-port-unreachable,icmp-proto-unreachableicmp-net-prohibitedicmp-host-pro-hibitedicmp-admin-prohibited 配置举例：拒接外部 ping，并提示”Destination Host Unreachable” iptables -A INPUT -t filter -p icmp -j REJECT --reject-with icmp-host-unreachable 6.8.4. DROP：丢弃数据包¶配置举例：直接将外部 ping 包丢弃 iptables -A INPUT -t filter -p icmp -j DROP 7. Qt 支持¶7.1. Qt 环境支持¶Firefly 设备系统如果是 Ubuntu 22.04 可以直接通过 apt 安装 Qt 环境： # 安装基础环境apt updateapt install -y qtcreator qtbase5-dev# 安装额外组件与开发环境，例如apt install -y libqt5multimedia5 qtmultimedia5-dev libqt5quick5 qtdeclarative5-dev 安装后直接在设备上进行开发。 Ubuntu 18.04 或者 Ubuntu 20.04 需要借助电脑进行交叉编译，详情请看下一章 7.2. Qt 交叉编译环境支持¶Firefly 发布了两个 Qt 交叉编译工具链，适用于以下环境，请根据需求选择: Qt: 5.12.2 Host: x86-64 Ubuntu 18.04 Target: Firefly RK3568 RK3566 RK3399 RK3328 PX30 Ubuntu 18.04 MinimalDesktop 和 Qt: 5.15 Host: x86-64 Ubuntu 20.04 Target: Firefly RK3588 RK3568 RK3566 Ubuntu 20.04 Desktop 工具链完整支持 wenEngine, 支持 EGLFS LinuxFB XCB 等 backend。 下载地址 点击 下载链接(提取码：FFQT) 部署 详情参见工具链中的 Qt5.1x.x_Release.md 文件 注意，文档中所有路径的名称不可更改，否则会导致编译或者运行出错。 编译 在 host 端，进入 Qt 工程目录，qmake make 即可. 运行 工具链中含有例程，用户在部署完成后，可以在 host 端 build demo，在 tartget 端运行 demo 以测试部署是否成功。 确定了使用哪个后端，就可以修改设备中 etcprofile.dtarget_qtEnv.sh 文件，去除对应平台环境变量前面的 # 使其一直生效 # 例如，使用 XCB ，则将文件内 XCB 部分前面的 # 删除#XCBexport QT_QPA_PLATFORM=XCBexport QT_QPA_EGLFS_INTEGRATION=XCB_EGL 7.3. Qt 双屏异显¶Firefly Ubuntu 系统可以使用 Qt 应用实现双屏显示和操作。 （1）进入桌面环境 export XAUTHORITY=/home/firefly/.Xauthorityexport DISPLAY=:0 （2）设置环境变量 export QT_QPA_PLATFORM=xcbexport QT_QPA_EGLFS_INTEGRATION=XCB_EGL （3）运行 Demo ./firefly_arm64_qt5.12.2_18.04/demo/double_panel_demo （4）Demo 代码目录 firefly_arm64_qt5.12.2_18.04/example/double_panel_demo （5）代码编译 （6）添加自己的 Qt 工程 在 example 目录下添加用户自己的 Qt 项目工程。 编辑 example 目录下 gui.pro 文件。 假设工程目录名为 double_panel_demo，则在 gui.pro 文件中追加 SUBDIRS += double_panel_demo。 执行命令 qmake make。 （7）运行效果 7.4. Qt Creator¶目标平台的系统是 Ubuntu 22.04 则不用看本章节，直接在设备上使用 qtcreator，无需特殊设置。 其他版本系统需要交叉编译 qt，请继续往下看： 下面介绍主机上 Qt Creator 的使用说明，在操作前，请先安装、配置好 Qt 交叉编译环境和运行环境。 7.4.1. 安装¶进入 Qt 官方下载页面，选择一个版本下载 qt-creator-opensource-linux-x86_64-x.x.x.run，下载完成之后，在终端执行 ./xxxx.run 运行安装，注意文件需要有执行权限。 7.4.2. 配置¶下面以 firefly-qt-5.12.2-aarch64 环境作为例子进行配置，目标平台是 Buildroot 系统： 目标平台系统不同，配置也稍有不同，所以请仔细查看文字说明，图片仅供参考，不要照搬图片中的配置 安装完成后，启动 Qt Creator，打开菜单 Tools - Options，找到 Kits。 配置 Qt Versions 点击右侧 add 按钮添加，选择 Qt 环境安装位置中的 qmake 即可 qmake：/opt/firefly-qt-5.12.2-aarch64/host/bin/qmake 配置 Compilers 点击右侧 add 按钮添加 gcc 和 g++ 交叉编译器的位置 如果主机安装了 crossbuild-essential-arm64，则编译器就在 /usr/bin/ 下 如果使用了第三方的交叉编译器，找到安装位置并添加即可 如果目标平台是 Buildroot，则需要使用 Buildroot Qt 环境包中的编译器 g++：/opt/firefly-qt-5.12.2-aarch64/host/bin/aarch64-buildroot-linux-gnu-g++ gcc：/opt/firefly-qt-5.12.2-aarch64/host/bin/aarch64-buildroot-linux-gnu-gcc 为方便调试，配置 Debuggers 和 Devices 用于在线调试： 配置 Debuggers 首先主机中安装 gdb-multiarch：apt install -y gdb-multiarch 检查目标机上是否存在 usrbingdbserver，没有的话需要安装：apt install -y gdbserver (Buildroot 自带，无需安装) 回到主机的 Qt Creator，点击右侧 add 按钮添加 gdb 选择主机中的 gdb-multiarch ：/usr/bin/gdb-multiarch 配置 Devices 设置好设备的 IP、用户名 (root) 和密码 (firefly) 。为了方便调试，可以在设备上设置静态 IP。 GDB server 设置为 /usr/bin/gdbserver 配置 Kits 将前面设置的配置项添加到 Kits。 如果目标平台是 Ubuntu 系统，这一步也需要添加 sysroot 的路径 7.4.3. 编译运行¶打开 demo 程序，Welcome - Open Project，选择要使用的 Kits： 之后打开 Projects - Run，配置命令行参数，这里设置为 -platform wayland： 目标平台是 Ubuntu 则使用 -platform xcb (Ubuntu 桌面环境)，或者根据需要选择 linuxfb、eglfs 配置环境变量，即 export XDG_RUNTIME_DIR=/tmp/.xdg： RK356X Buildroot 则需要使用 /var/run 而不是 /tmp/.xdg 目标平台是 Ubuntu 则需要根据之前设置的 platform 添加不同的环境变量，详情在 Qt 环境包中的说明文件中 如果目标平台的运行环境(本文开头提到的)之前已经配置好并成功运行 demo，此时可以直接点击右侧 Fetch Device Environment 获取目标的环境变量 编译运行： 点击 Build 交叉编译 Qt 程序；点击 Run 或 Debug 在设备上运行或调试程序。要重新运行程序时，记得手动点击 Stop 关闭已经运行的程序。 编译生成目录和 demo 目录在同一位置。 8. Docker 支持¶Firefly 发布的普通固件一般不满足 Docker 的运行要求，如果有需求，可以使用 SDK 打开内核的相关配置，重新编译烧录内核以支持 Docker。 （RK356X v1.2.4a 及以后版本 、RK3399RK3588 默认支持 Docker，可直跳到 安装 Docker 步骤） 以下案例是基于 Firefly Ubuntu 20.04，内核配置部分是通用的！ 8.1. 检查 Kernel 配置¶首先需要通过工具检查当前设备的内核缺少了哪些 Docker 需要的配置。检测脚本 check-config.sh 可以前往 社区论坛 获取。 获取到脚本之后，开始进行检测： #将脚本拷贝到SDK的kernel目录下cp check-config.sh PathToSDK/kernel/cd PathToSDK/kernelchmod +x check-config.sh#获取当前内核配置make ARCH=arm64 firefly_linux_defconfig#检测./check-config.sh .config 执行后的结果如下，主要是两部分： Generally Necessary:- cgroup hierarchy: properly mounted [/sys/fs/cgroup]- apparmor: enabled and tools installed- CONFIG_NAMESPACES: enabled- CONFIG_NET_NS: enabled- CONFIG_PID_NS: enabled- CONFIG_IPC_NS: enabled- CONFIG_UTS_NS: enabled- CONFIG_CGROUPS: enabled......Optional Features:- CONFIG_USER_NS: enabled- CONFIG_SECCOMP: enabled- CONFIG_SECCOMP_FILTER: enabled- CONFIG_CGROUP_PIDS: enabled- CONFIG_MEMCG_SWAP: enabled...... Generally Necessary: 表示必要的配置，如果有显示 missing 的地方，就需要在内核配置中打开它。 Optional Features: 是可选配置，根据需要打开。 8.1.1. 开启需要的配置¶从上面的检测结果中得知需要打开哪些配置后，即可使用 make ARCH=arm64 menuconfig 进入菜单，搜索对应项目将其打开。请认真查看菜单中的操作说明，遇到不可选中的项目请注意依赖关系。 开启所有必要配置以及部分可选配置后，注意保存： make ARCH=arm64 savedefconfigmv defconfig arch/arm64/configs/firefly_linux_defconfig 之后进行编译内核： #退回到SDK目录cd ..#编译内核./build.sh kernel 8.2. 安装 Docker¶烧录完新内核之后，可以开始在设备上安装 Docker (此安装方法同样适用于 PC)： 步骤 1：快速安装 # 这里仅介绍直接使用脚本快速安装apt-get updatewget -qO- https://get.docker.com/ | sh 等待安装成功之后应该会看见 Docker 版本信息 步骤 2：检查 docker 存储位置（该步骤仅适用于 PC 安装 docker） 如果你在 Firefly 设备中安装 docker，请跳过步骤 2 # 执行docker info | grep -i dir# 执行结果 Docker Root Dir: /var/lib/docker 返回的信息显示了 docker 的默认存储位置，该位置在不同电脑上可能不一样 镜像和容器会占用大量空间，因此，如果默认的位置空间不大，需要修改到空间充足的位置 再次强调，此步骤只用于 PC，Firefly 设备中，修改此位置会导致 docker 无法工作，请直接跳到下一步 # 先关闭 docker 服务sudo systemctl stop docker# 修改文件 /lib/systemd/system/docker.servicesudo vim /lib/systemd/system/docker.service# 在这一行末尾添加想要修改的位置 --graph /home/firefly/docker/dataExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --graph /home/firefly/docker/data# 重启 docker 服务sudo systemctl daemon-reloadsudo systemctl start docker# 检查位置是否修改成功docker info | grep -i dir Docker Root Dir: /home/firefly/docker/data 步骤 3：将自己的用户添加到 docker 组 sudo usermod -a -G docker firefly# 添加后重启sudo reboot 步骤 4：重启后运行 demo 测试是否正常： firefly@firefly:~# docker run hello-worldUnable to find image hello-world:latest locallylatest: Pulling from library/hello-world93288797bd35: Pull completeDigest: sha256:cc15c5b292d8525effc0f89cb299f1804f3a725c8d05e158653a563f15e4f685Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the hello-world image from the Docker Hub. (arm64v8) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 9. ROS 支持¶9.1. 安装 ROS¶首先按照官方安装教程安装，根据系统选择对应 ROS 版本安装。 官方安装教程 9.1.1. 安装 GLX 库¶rviz,gazebo 是基于 GLX 编写的，我们系统目前只支持 EGL，所以他们无法使用 GPU 加速，同时需要安装 GLX 库才能能够正常运行。 apt install -y libgl1-mesa-glx libgl1-mesa-dri libglx-mesa0reboot 9.2. 更新 libqt5opengl5-dev¶如果遇到 rviz 还不能运行，rqt 报 QOpenGLTimeMonitor 等错误，需要更新官方的 libqt5opengl5-dev， 执行下面操作，再尝试运行 rqt、rviz 和 gazebo 等程序 sed -i s/.*wiki.t-firefly.com.*/\\#/ /etc/apt/sources.listapt install libqt5opengl5-devsed -i /.*wiki.t-firefly.com.*/s/^#// /etc/apt/sources.list 9.3. wayland 下运行 rviz，rqt 和 gazebo 等程序¶XWayland说明 基于 GLX 的程序在 wayland 运行，需要使用 XWayland。使用 QT_QPA_PLATFORMxcb 强制 Qt 应用程序使用 X11 QT_QPA_PLATFORM=xcb rvizQT_QPA_PLATFORM=xcb rqtQT_QPA_PLATFORM=xcb gazebo# 也可以将该环境设置到.bashrc，就可以直接运行rviz等程序。echo export QT_QPA_PLATFORM=xcb /~/.bashrc 9.4. ROS教程¶10. 显示架构支持¶对于 Rockchip 平台，主要有以下几种显示架构可供选择： Qt + Wayland Qt + EGLFS EGL program + X11 Wayland None 多窗口的功能需求，选择： X11 Wayland 桌面的功能需求，选择： X11 4K 视频播放 + 全屏： Qt + Wayland Qt + EGLFS X11 Wayland 4K 视频播放 + 多窗口： X11 Qt + Wayland Wayland 如果您对显示架构的技术不太理解，可以继续往下阅读。 10.1. X11¶X11 是 X 显示协议的第 11 个版本。 X 协议已经延用了 30 年，X 协议的 ClientServer 结构起初是为了在以前硬件性能太弱的情况下，设备（Client 端）通过发送渲染请求给 X server（以前 X server 是运行在另一个独立的硬件）渲染显示。 但是随着现代硬件性能不断提升，同一个硬件系统上可以同时运行 Client 和 Server 了，但是这种远程通讯结构运用在本地机器上带来的后果就是性能的丢失，目前在 Debian 官方已经有分支在开发 Wayland 用于替换掉 X11，但是目前 Wayland 对现有软件兼容性并不好所有还没有正式替换使用。 参考资料: https://en.wikipedia.org/wiki/X.Org_Serverhttps://www.comptechdoc.org/os/linux/howlinuxworks/linux_hlxwindows.htmlhttps://dri.freedesktop.org/wiki/DDX/https://www.freedesktop.org/wiki/Software/Glamor/https://en.wikipedia.org/wiki/X.Org_Server 10.2. Qt + EGLFS¶Qt + EGLFS 是 Qt 自己实现的一个 GUI 系统，不支持多窗口，但也因此少了 window composite。 Qt + EGLFS 和 dri2 的方式类似，区别就在于 Qt + EGLFS 的 font buffer 在自己用 gpu composite 后，是直接送给 DRM 显示，而 X 里是送至 Window manager 做 composite，所以 EGLFS 在效率上是有优势的。 10.3. Qt + Wayland¶在 Wayland 中，Weston 是 Wayland 显示协议中的具体实现，其对应关系就好比 Xorg （X server）和 X 的关系一样。 目前 Wayland 和 X 对比唯一缺点就是在兼容性上了，所以目前主流的系统版本中依然大部分使用 X。 Weston 不再使用 X 的 ClientServer 的结构，而是直接由合成器接受内核事件，并传递给 Client 端，由 Client 端直接渲染，只向合成器发送需要更新的区域，再由合成器通知内核安排翻页。 需要注意的是由于 UbuntuDebian 已经有 X11，所以 SDK 默认是在 Buildroot 添加了 Weston 的支持，实际上如果 UbuntuDebian 需要安装 Weston 的话也可以在 Minimal 版本上搭建。 （Firefly Ubuntu 20.04，将会默认自带 Wayland 和 X，并且可以自由切换。） 建议使用 BuildrootYocto 做 Wayland 的开发。效率上 Wayland 要比 X11 好点，主要是兼容性问题。 如果不需要桌面，又要多窗口，可以尝试使用 Wayland。 10.4. None¶除了 X11 和 Wayland 之外，还有 None，这也是嵌入式上接触比较多的。比如 MiniGUI，SDL 皆是如此。 若要支持到 DRM 和 opengl 的话，就只能选择 Qt 了。 MiniGUI 是一个定位于轻量级的嵌入式图形库，对系统资源的需求完全考虑到了嵌入式设备的硬件情况，如 MiniGUI 库所占的空间最小可以裁剪到 500K 左右。 针对 Buildroot 系统适配在硬件资源比较紧张的设备上的特性，MiniGUI 搭配 Buildroot 是再适合不过了。 参考资料: https://wayland.freedesktop.org/architecture.htmlhttps://en.wikipedia.org/wiki/Wayland","tags":["clippings"],"categories":["0.平台","嵌入式"]},{"title":"1. 桌面应用 — Firefly Wiki","path":"/2024/12/19/0-平台-嵌入式-嵌入式交叉编译/","content":"Firefly Linux 开发指南 官方发布的 Buildroot 固件，默认支持 Wayland 桌面环境和一些 Qt 应用，如下图： 1.1. multivideoplayer¶多路视频播放器用于测试设备的多路视频播放能力、显示能力以及硬件解码能力。 1.2. qfm¶qfm 是一个文件浏览应用 1.3. qplayer¶qplayer 是一个多功能播放器，可以播放视频、音频和浏览图片。 1.4. qcamera¶qcamera 是一款相机应用，可以进行拍摄和录像。 设备连接摄像头的情况下启动 qcamera 将自动显示摄像头画面，右侧按钮： Image Mode: 照相模式，点击可切换为 Video Mode 视频录制模式。 Capture: 捕捉图像，在 Video Mode 下会变为 Record 录制按钮。 Exit: 退出。 1.5. qsetting¶qsetting 是系统设置工具，可以设置 WiFi ，蓝牙，恢复出厂以及固件升级。 2. 用户和密码¶ 用户：root 密码：firefly 3. 以太网配置¶Buildroot的网络配置需要使用到 /etc/network/interfaces 配置文件，配置完成之后，运行/etc/init.d/S40network restart即可重启网络。手动调试可以直接使用 ifdown -a 和 ifup -a来重启网络。 3.1. 常用配置¶配置文件举例：如下配置文件将eth0网卡设置为动态IP地址，将eth1设置为静态IP地址 注意：/etc/network/interfaces的文件格式要求比较严格，如果遇到Error: either local is duplicate, or /24 is a garbage.，那么很有可能是配置文件中多了一个空格 auto loiface lo inet loopbackauto eth0iface eth0 inet dhcpauto eth1iface eth1 inet staticaddress 168.168.110.137netmask 255.255.0.0broadcast 168.168.1.255gateway 168.168.0.1 （1）inet static：定义静态IP地址。支持的选项有： address address Address (dotted quad/netmask) requirednetmask mask Netmask (dotted quad or number of bits) deprecatedbroadcast broadcast_address Broadcast address (dotted quad, + or -) deprecated. Default value: +metric metric Routing metric for default gateway (integer)gateway address Default gateway (dotted quad)pointopoint address Address of other end point (dotted quad). Note the spelling of point-to.hwaddress address Link local address or random.mtu size MTU sizescope Address validity scope. Possible values: global, link, host （2）inet dhcp：通过DHCP协议获取IP地址。支持的选项有： hostname hostname Hostname to be requested (pump, dhcpcd, udhcpc)metric metric Metric for added routes (dhclient)leasehours leasehours Preferred lease time in hours (pump)leasetime leasetime Preferred lease time in seconds (dhcpcd)vendor vendor Vendor class identifier (dhcpcd)client client Client identifier (dhcpcd)hwaddress address Hardware address. （3）inet manual：没有为接口定义IP地址。通常由作为桥接或聚合成员的接口，需要以混杂模式运行的接口（ 例如，端口镜像或网络TAP ）或在其上配置了VLAN设备的接口使用。这是保持接口不带IP地址的一种方法。支持的选项有： hwaddress address Link local address or random.mtu size MTU size 3.2. 高级设置¶/etc/network/interfaces支持设置在网卡关闭启动时，运行Linux命令行指令。由于/etc/network/interfaces支持的功能相对有限，这在配置静态路由、默认路由等网络配置时将会非常有帮助。 支持的可选选项有：pre-up、up、post-up、pre-down、down、post-down，在这些选项之后，加上命令行即可。 pre-up\t网卡启用前的动作up\t启用时候的动作post-up\t启用后的动作pre-down\t关闭前的动作down\t关闭时动作post-down\t关闭后动作说明：$IFACE自适应对于相应的网卡节点 配置举例：给eth1网卡配置一条静态路由 auto eth1iface eth1 inet staticaddress 192.168.3.1netmask 255.255.255.0broadcast 192.168.3.255post-up ip route add 192.168.4.0/24 via 192.168.3.2 dev $IFACE 配置举例：创建一个网桥，将eth0，eth1绑定到网桥，将其作为LAN口 auto loiface lo inet loopbackauto eth0iface eth0 inet manualpre-up ifconfig $IFACE uppost-down ifconfig $IFACE downauto eth1iface eth1 inet manualpre-up ifconfig $IFACE uppost-down ifconfig $IFACE downauto br0iface br0 inet staticaddress 192.168.2.1netmask 255.255.255.0broadcast 192.168.2.255pre-up brctl addbr $IFACEpre-up brctl addif $IFACE eth0pre-up brctl addif $IFACE eth1bridge_ports eth0 eth1post-down brctl delif $IFACE eth0post-down brctl delif $IFACE eth1post-down ifconfig $IFACE downpost-down brctl delbr $IFACE 4. WiFi 连接¶4.1. 修改配置文件的方式¶4.1.1. 方式1¶通过 qsetting QT应用进行配置。 4.1.2. 方式2¶修改如下文件： vi /data/cfg/wpa_supplicant.confctrl_interface=/var/run/wpa_supplicantap_scan=1 添加如下配置项 network=ssid=WiFi-AP // WiFi 名字psk=12345678 // WiFi 密码key_mgmt=WPA-PSK\t// 加密方式# key_mgmt=NONE // 不加密 启动wpa_supplicant进程 wpa_supplicant -B -i wlan0 -c /data/cfg/wpa_supplicant.conf 4.2. 临时修改的方式¶修改如下文件： vi /data/cfg/wpa_supplicant.confctrl_interface=/var/run/wpa_supplicantap_scan=1 启动wpa_supplicant进程： wpa_supplicant -B -i wlan0 -c /data/cfg/wpa_supplicant.conf 4.2.1. 通过wpa_cli配置WiFi¶常用命令： wpa_cli -i wlan0 scan // 搜索附近wifi网络wpa_cli -i wlan0 scan_result // 打印搜索wifi网络wpa_cli -i wlan0 add_network // 添加一个网络连接 如果要连接加密方式是[WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][ESS] (wpa加密)，wifi名称是name，wifi密码是：psk。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 psk pskwpa_cli -i wlan0 set_network 0 key_mgmt WPA-PSKwpa_cli -i wlan0 enable_network 0 //使能WiFi 如果要连接加密方式是[WEP][ESS] (wep加密)，wifi名称是name，wifi密码是psk。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 key_mgmt NONEwpa_cli -i wlan0 set_network 0 wep_key0 pskwpa_cli -i wlan0 enable_network 0 如果要连接加密方式是[ESS] (无加密)，wifi名称是name。操作如下： wpa_cli -i wlan0 set_network 0 ssid namewpa_cli -i wlan0 set_network 0 key_mgmt NONEwpa_cli -i wlan0 enable_network 0 使能保存WIFI连接信息 wpa_cli -i wlan0 set update_config 1 保存WIFI连接信息 wpa_cli -i wlan0 save_config 连接已有的连接 wpa_cli -i wlan0 list_network // 列举所有保存的连接wpa_cli -i wlan0 select_network 0 // 连接第1个保存的连接wpa_cli -i wlan0 enable_network 0 // 使能第1个保存的连接 关闭WiFi 5. 音视频播放¶# 播放 wavaplay test.wavgstwavplay.sh test.wav# 播放 mp3mp3play.sh test.mp3gstmp3play.sh test.mp3# 播放 mp4gstmp4play.sh test.mp4gstvideoplay.sh test.mp4 6. SSH¶官方发布的 SDK 默认已开启 ssh，用户为”root”，密码为”firefly”。如果不需要修改用户登录密码，可以跳过此章节。 6.1. 修改方法¶ 使能SSH相关选项 openssh 配置登录的账户root和密码 BR2_TARGET_ENABLE_ROOT_LOGIN=yBR2_TARGET_GENERIC_ROOT_PASSWD=firefly 修改配置文件 修改板卡里/etc/ssh/sshd_config文件 7. 外部存储设备¶Buildroot 支持自动挂载外部存储设备： U 盘挂载路径：/udisk TF 卡挂载路径：/sdcard 8. 恢复出厂设置¶注意：此出厂设置表示恢复为设备最后一次升级固件之后的初始状态。 8.1. 方法1¶通过 qsetting QT 应用进行配置，点击 “Factory Reset” 功能选项进行操作。 8.2. 方法2¶通过 update 命令 update# 或者update factory / update reset 9. 固件本地升级¶Buildroot 支持从外部存储设备升级固件，以下是升级流程说明。关于如何编译 Buildroot 固件请用户参考相应板卡维基的编译 Buildroot 固件页面。 9.1. 制作升级固件¶按照正常的固件编译流程，制作用于升级的固件。 升级固件不一定要全分区升级，可修改 package-file 文件，将不要升级的分区注释掉，或者改为RESERVED （1）修改文件 tools/linux/Linux_Pack_Firmware/rockdev/package-file 例如，将 rootfs 的相对路径改为 RESERVED，这样就不会打包根文件系统，即不升级根文件系统分区。 # name relative path##hwdef hwdefpackage-file package-filebootloader image/miniloaderall.binparameter image/parameter.txttrust image/trust.imguboot image/uboot.imgmisc image/misc.imgboot image/boot.imgrecovery image/recovery.imgrootfs RESERVEDoem image/oem.imguserdata:grow image/userdata.imgbackup RESERVED （2）编译固件 将制作好的升级固件拷贝到 U 盘、TF 卡或者设备的 /userdata/ 目录下，重命名为 update.img。 注意： 若将升级固件放至设备的 /userdata/ 目录，则不要打包 userdata.img，将 image/userdata.img 改为 RESERVED。 9.2. 升级过程¶9.2.1. 方法1¶通过 qsetting QT应用进行配置。点击 “Update” 功能选项进行操作。 9.2.2. 方法2¶通过 update 命令。 # U 盘update ota /udisk/update.img# TF 卡update ota /sdcard/update.img# /userdata/update ota /userdata/update.img 等待升级完成，升级成功后，设备会重新启动进入系统。 10. Weston 配置¶我们可以通过配置 Weston 对显示进行一些自定义设置，下文对部分设置进行说明。 10.1. 状态栏设置¶Weston 支持在 weston.ini 配置文件的 shell 段设置状态栏的背景色、位置，以及在 launcher 段设置快捷启动程序，如： # /etc/xdg/weston/weston.ini[shell]# 颜色格式为 ARGB8888panel-color=0xff002244# top|bottom|left|right|nonepanel-position=bottom[launcher]icon=/usr/share/weston/terminal.pngpath=/usr/bin/weston-terminal[launcher]# 图标路径icon=/usr/share/weston/icon_flower.png# 快捷启动命令path=/usr/bin/qsetting 10.2. 背景设置¶Weston 支持在 weston.ini 配置文件的 shell 段设置背景图案、颜色，如： # /etc/xdg/weston/weston.ini[shell]# 背景图案(壁纸)绝对路径background-image=/usr/share/weston/background.png# scale|scale-crop|tilebackground-type=scale# 颜色格式为 ARGB8888，未设置背景图案时生效background-color=0xff002244 10.3. 待机及锁屏配置¶Weston 的超时待机时长可以在启动参数中配置，也可以在 weston.ini 的 core 段配置，如： # /etc/init.d/S50launcher start) ... # 0 为禁止待机，单位为秒 weston --tty=2 -B=drm-backend.so --idle-time=0 或者： # /etc/xdg/weston/weston.ini[core]# 设置 5 秒未操作后进入待机状态idle-time=5 10.4. 显示颜色格式配置¶Buildroot SDK 内 Weston 目前默认显示格式为 ARGB8888，对于某些低性能平台，可以在 weston.ini 的 core 段配置为 RGB565，如： # /etc/xdg/weston/weston.ini[core]# xrgb8888|rgb565|xrgb2101010gbm-format=rgb565 也可以在 weston.ini 的 output 段单独配置每个屏幕的显示格式，如： # /etc/xdg/weston/weston.ini[output]# output 的 name 可以查看 /sys/class/drm/card0-namename=LVDS-1# xrgb8888|rgb565|xrgb2101010gbm-format=rgb565 10.5. 屏幕方向设置¶Weston 的屏幕显示方向可以在 weston.ini 的 output 段配置，如： # /etc/xdg/weston/weston.ini[output]name=LVDS-1# normal|90|180|270|flipped|flipped-90|flipped-180|flipped-270transform=180 如果需要动态配置屏幕方向，可以通过动态配置文件，如： echo output:all:rotate90 /tmp/.weston_drm.conf # 所有屏幕旋转 90 度echo output:eDP-1:rotate180 /tmp/.weston_drm.conf # eDP-1 旋转 180 度 10.6. 分辨率及缩放配置¶Weston 的屏幕分辨率及缩放可以在 weston.ini 的 output 段配置，如： # /etc/xdg/weston/weston.ini[output]name=HDMI-A-1# 需为屏幕支持的有效分辨率mode=1920x1080# 需为整数倍数scale=2 如果需要动态配置分辨率及缩放，可以通过动态配置文件，如： echo output:HDMI-A-1:mode=800x600 /tmp/.weston_drm.conf # 修改 HDMI-A-1 分辨率为800x600 这种方式缩放时需要依赖 RGA 加速。 10.7. 冻结屏幕¶在启动 Weston 时，开机 logo 到 UI 显示之间存在短暂切换黑屏。如需要防止黑屏，可以通过以下种动态配置文件方式短暂冻结 Weston 屏幕内容： # /etc/init.d/S50launcher start) ... export WESTON_FREEZE_DISPLAY=/tmp/.weston_freeze # 设置特殊配置文件路径 touch /tmp/.weston_freeze # 冻结显示 weston --tty=2 -B=drm-backend.so --idle-time=0 ... sleep 1 rm /tmp/.weston_freeze # 1 秒后解冻 10.8. 多屏配置¶Buildroot SDK 的 Weston 支持多屏同异显及热拔插等功能，不同显示器屏幕的区分根据 drm 的 name (通过 sysclassdrmcard0-name 获取)，相关配置通过环境变量设置，如： # /etc/init.d/S50launcher start) ... export WESTON_DRM_PRIMARY=HDMI-A-1 # 指定主显为 HDMI-A-1 export WESTON_DRM_MIRROR=1 # 使用镜像模式(多屏同显)，不设置此环境变量即为异显 export WESTON_DRM_KEEP_RATIO=1 # 镜像模式下缩放保持纵横比，不设置此变量即为强制全屏 export WESTON_DRM_PREFER_EXTERNAL=1 # 外置显示器连接时自动关闭内置显示器 export WESTON_DRM_PREFER_EXTERNAL_DUAL=1 # 外置显示器连接时默认以第一个外显为主显 weston --tty=2 -B=drm-backend.so --idle-time=0 镜像模式缩放显示内容时需要依赖 RGA 加速。 同时也支持在 weston.ini 的 output 段单独禁用指定屏幕： # /etc/xdg/weston/weston.ini[output]name=LVDS-1mode=off# off|current|preferred|WIDTHxHEIGHT@RATE 10.9. 输入设备相关配置¶Weston 服务默认需要至少一个输入设备，如无输入设备，则需要在 weston.ini 中的 core 段特殊设置： # /etc/xdg/weston/weston.ini[core]require-input=false 11. Buildroot 开发¶Buildroot 是 Linux 平台上一个构建嵌入式 Linux 系统的框架。整个 Buildroot 是由 Makefile(*.mk) 脚本和 Kconfig(Config.in) 配置文件构成的。你可以和编译 Linux 内核一样，通过 buildroot 配置，menuconfig 修改，编译出一个完整的可以直接烧写到机器上运行的 Linux 系统软件（包含 boot、kernel、rootfs 以及 rootfs 中的各种库和应用程序）。若您要了解更多 Buildroot 开发相关内容，可以参考 Buildroot 官方的 《开发手册》。 下面以 RK356x 平台的 Buildroot 开发为例进行阐述。 11.1. 目录结构¶Buildroot SDK 位于 Firefly_Linux_SDK 目录，其目录结构如下： buildroot/├── arch # CPU 架构的构建、配置文件├── board # 具体单板相关的文件├── boot # Bootloaders 的构建、配置文件├── build├── CHANGES # Buildroot 修改日志├── Config.in├── Config.in.legacy├── configs # 具体单板的 Buildroot 配置文件├── COPYING├── DEVELOPERS├── dl # 下载的程序、源码压缩包、补丁等├── docs # 文档├── fs # 各种文件系统的构建、配置文件├── linux # Linux 的构建、配置文件├── Makefile├── Makefile.legacy├── output # 编译输出目录├── package # 所有软件包的构建、配置文件├── README # Buildroot 简单说明├── support # 为 Bulidroot 提供功能支持的脚本、配置文件├── system # 制作根文件系统的构建、配置文件├── toolchain # 交叉编译工具链的构建、配置文件└── utils # 实用工具 11.2. 配置¶选择默认配置文件： # 进入 Firefly_Linux_SDK 根目录cd path/to/Firefly_Linux_SDK/# 选择配置文件# \\`configs/rockchip_rk3568_defconfig\\`source envsetup.sh rockchip_rk3568 执行完成后会生成编译输出目录，output/rockchip_rk3568，后续也可以在该目录下执行 make 相关操作。 11.2.1. 软件包配置¶打开配置界面： 我们可以在配置界面添加或裁剪一些工具，按需求定制系统功能。以添加 qt53d 为例： 输入 / 进入搜索界面，输入要查找的内容 qt53d，按回车进行搜索： 选择 1 跳转到对应页面，按空格选中配置： 配置完成后，移动到 Save 按回车保存到 .config；移动到 Exit 按回车退出。 保存配置文件： 将修改保存到配置文件 configs/rockchip_rk3568_defconfig。 11.2.2. Busybox 配置¶打开配置界面，进行配置： 配置完成后，移动到 Exit 按回车退出，在弹窗页面选择 Yes 保存到 .config。 保存配置文件： make busybox-update-config 将修改保存到配置文件 board/rockchip/common/base/busybox.config。 11.3. 编译¶配置好 Buildroot 后，直接运行 make 进行编译。 11.3.1. 编译说明¶运行 make 进行编译时，会执行以下过程： 下载源码； 配置、编译、安装交叉编译工具链； 配置、编译、安装选择的软件包； 按选择的格式生成根文件系统； 关于 make 的更多用法，可通过 make help 获得。 11.3.2. 编译软件包¶我们可以执行 make package 单独编译某个软件包。软件包的编译主要包括下载，解压，打补丁，配置，编译，安装等过程，具体可以查看 package/pkg-generic.mk。 下载 Buildroot 会根据配置 package/package/package.mk，自动从网络获取对应的软件包，包括一些第三方库，插件，实用工具等，放在 dl/ 目录。 解压 软件包会解压在 output/rockchip_rk3568/build/package-version 目录下。 打补丁 补丁集中放在 package/packgae/ 目录，Buildroot 会在解压软件包后为其打上相应的补丁。如果要修改源码，可以通过打补丁的方式进行修改。 配置 编译 安装 编译完成后，会将需要的编译生成文件拷贝到 output/rockchip_rk3568/target/ 目录。 对于某个软件包，我们可以通过 make package-target 调用软件包构建中的某一步骤，如下： Package-specific: pkg - Build and install pkg and all its dependencies pkg-source - Only download the source files for pkg pkg-extract - Extract pkg sources pkg-patch - Apply patches to pkg pkg-depends - Build pkgs dependencies pkg-configure - Build pkg up to the configure step pkg-build - Build pkg up to the build step pkg-graph-depends - Generate a graph of pkgs dependencies pkg-dirclean - Remove pkg build directory pkg-reconfigure - Restart the build from the configure step pkg-rebuild - Restart the build from the build step 11.4. 编译输出目录¶编译完成后，在编译输出目录 output/rockchip_rk3568 会生成子目录，说明如下： build/ 包含所有的源文件，包括 Buildroot 所需主机工具和选择的软件包，这个目录包含所有软件包源码。 host/ 主机端编译需要的工具，包括交叉编译工具。 images/ 包含压缩好的根文件系统镜像文件。 staging/ 这个目录类似根文件系统的目录结构，包含编译生成的所有头文件和库，以及其他开发文件，不过它们没有裁剪，比较庞大，不适用于目标文件系统。 target/ 包含完整的根文件系统，对比 staging/，它没有开发文件，不包含头文件，二进制文件也经过 strip 处理。 11.5. 交叉编译工具¶Buildroot 编译完成后，会在 output/rockchip_rk3568/host/ 目录下，生成交叉编译工具，我们可以用来编译目标程序。 交叉编译工具目录 output/rockchip_rk3568/host/bin/ 编译示例 hello.c #include stdio.h#include stdlib.hint main(int argc, char *argv[]) printf(Hello World! ); return 0; 编译 .../host/bin/arm-buildroot-linux-gnueabihf-gcc hello.c -o hello 运行 将可执行程序 hello 拷贝到设备，运行 ./hello，则会看到打印信息 Hello World!。 11.6. 重建¶对于重建的具体说明，可以查看文档 buildroot/docs/manual/rebuilding-packages.txt。 11.6.1. 重建软件包¶在开发过程中，若修改了某个软件包的源码，Buildroot 是不会重新编译该软件包的。可以按如下方式操作： 方式一 方式二 # 删除软件包的编译输出目录rm -rf output/rockchip_rk3568/build/package-version# 编译make package 11.6.2. 完全重建¶当通过 make menuconfig，make xconfig 或其他配置工具之一更改系统配置时，Buildroot 不会尝试检测应重建系统的哪些部分。在某些情况下，Buildroot 应该重建整个系统，在某些情况下，仅应重建软件包的特定子集。但是以完全可靠的方式检测到这一点非常困难，因此 Buildroot 开发人员已决定不尝试这样做。 11.6.2.1. 何时需要完全重建¶ 更改目标体系结构配置时，需要完全重建； 更改工具链配置时，需要完全重建； 将其他软件包添加到配置中时，不一定需要完全重建； 从配置中删除软件包时，Buildroot 不会执行任何特殊操作。它不会从目标根文件系统或工具链中删除此软件包安装的文件。需要完全重建才能删除这些文件； 更改软件包的子选项时，不会自动重建软件包； 对根文件系统框架进行更改时，需要完全重建； 一般而言，当你遇到构建错误并且不确定所做的配置更改可能带来的后果时，请进行完全重建。具体说明可以查看文档 rebuilding-packages.txt。 11.6.2.2. 如何完全重建¶ 方式一 直接删除编译输出目录，之后重新进行配置、编译。 方式二 执行如下命令，会删除编译输出并重新编译。 11.7. 新增本地源码包¶开发过程中，Buildroot 自带的软件包有时可能无法满足我们的需求，为此我们需要添加自定义的软件包。Buildroot 支持多种格式的软件包，包括 generic-package、cmake-package、autotools-package 等，我们以 generic-package 举例说明。 创建工程目录 cd path/to/Firefly_Linux_SDK/mkdir buildroot/package/rockchip/firefly_demo/ 新建 Config.in 在 firefly_demo/ 下添加 Config.in： config BR2_PACKAGE_FIREFLY_DEMO bool Simple Firefly Demo 新建 firefly_demo.mk 在 firefly_demo/ 下添加 firefly_demo.mk： ################################################################# firefly_demo##############################################################ifeq ($(BR2_PACKAGE_FIREFLY_DEMO), y) FIREFLY_DEMO_VERSION:=1.0.0 FIREFLY_DEMO_SITE=$(TOPDIR)/../external/firefly_demo/src FIREFLY_DEMO_SITE_METHOD=localdefine FIREFLY_DEMO_BUILD_CMDS $(TARGET_MAKE_ENV) $(MAKE) CC=$(TARGET_CC) CXX=$(TARGET_CXX) -C $(@D)endefdefine FIREFLY_DEMO_CLEAN_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) cleanendefdefine FIREFLY_DEMO_INSTALL_TARGET_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) installendefdefine FIREFLY_DEMO_UNINSTALL_TARGET_CMDS $(TARGET_MAKE_ENV) $(MAKE) -C $(@D) uninstallendef$(eval $(generic-package))endif 创建源码目录 上文的 Makefile 文件里已经指定了源码目录 external/firefly_demo/src。 cd path/to/Firefly_Linux_SDK/mkdir external/firefly_demo/src 编写源码 firefly_demo.c 在 firefly_demo/src/ 下添加 firefly_demo.c： #include stdio.h#include stdlib.hint main(int argc, char *argv[]) printf(Hello World! ); return 0; 编写 Makefile 在 firefly_demo/src/ 下添加 Makefile： DEPS =OBJ = firefly_demo.oCFLAGS =%.o: %.c $(DEPS) $(CC) -c -o $@ $ $(CFLAGS)firefly_demo: $(OBJ) $(CXX) -o $@ $^ $(CFLAGS).PHONY: cleanclean: rm -f *.o *~ firefly_demo.PHONY: installinstall: cp -f firefly_demo $(TARGET_DIR)/usr/bin/.PHONY: uninstalluninstall: rm -f $(TARGET_DIR)/usr/bin/firefly_demo 修改上一级 Config.in 在 buildroot/package/rockchip/Config.in 末尾添加一行： source package/rockchip/firefly_demo/Config.in 配置软件包 打开配置菜单 make menuconfig，找到 firefly_demo 并选中配置。 编译 # 编译 firefly_demomake firefly_demo# 打包进根文件系统make# 若修改源码，重新编译软件包make firefly_demo-rebuild 11.8. rootfs-overlay¶rootfs-overly 是一个相当不错的功能，它能够在目标文件系统编译完成后将指定文件覆盖到某个目录。通过这种方式，我们可以方便地添加或修改一些文件到根文件系统。 假设我们要在根文件系统的 /etc/ 目录下添加文件 overlay-test，可以按如下步骤操作： 设置 rootfs-overlay 根目录 打开配置菜单 make menuconfig，通过设置 BR2_ROOTFS_OVERLAY 选项，添加用于覆盖的根目录。对于 RK3568，默认已添加了目录 board/rockchip/rk356x/fs-overlay/。 添加文件到覆盖目录 cd buildroot/board/rockchip/rk356x/fs-overlay/mkdir etc/touch etc/overlay-test 编译 下载根文件系统 将编译好的根文件系统 output/rockchip_rk3568/images/rootfs.ext2 下载到设备。启动设备，可以看到已添加文件 /etc/overlay-test。 也可以通过查看 target/ 目录，验证是否添加成功： ls buildroot/output/rockchip_rk3568/target/etc/overlay-test 11.9. Qt 交叉编译环境支持¶Firefly 提取了 Buildroot 的交叉编译工具链，支持 EGLFS、LinuxFB、Wayland 等插件，您可以直接使用该工具链开发 Buildroot 上的 Qt 应用程序，而无需下载编译 SDK 代码。 版本：Qt-5.15.2主机：x86-64 / Ubuntu 18.04设备：Firefly RK3568 RK3566 / Buildroot 下载地址：Buildroot Qt 环境部署：详见 Qt5.1x.x_Release.md 文件。","tags":["clippings"],"categories":["0.平台","嵌入式"]},{"title":"1. 介绍 — Firefly Wiki","path":"/2024/12/19/0-平台-嵌入式-RealTime-嵌入式实时性优化/","content":"Firefly Linux 开发指南 为了满足用户对系统实时性的需求，官方在 SDK 源码的内核基础上支持升级 Linux 到 RTLinux。 我们RTlinux支持有preempt和xenomai两个版本,下面以preempt版本来测试。 1.1. RTLinux 系统固件支持¶支持RK3562、RK356X及RK3588等芯片平台，可前往对应机器版型下载固件页面下载实时固件。如需要源码请联系商务。 1.2. 测试实时效果¶测试实时性能需要cyclictest,可以使用apt安装。 apt updateapt install rt-tests 1.2.1. 测试RTLinux的实时效果¶使用stress或stress-ng模拟通用的压力场景，使CPU处于满负荷状态。 # 根据芯片核心数运行cpu压测线程、io压测线程及内存压测线程stress --cpu 4 --io 4 --vm 4 --vm-bytes 256M --timeout 259200s 执行以下命令测试每个核心实时响应延迟，将进行为期3天的测试，测试完成后的测试结果输出到output文件。 cyclictest -m -S -p99 -i1000 -h800 -D3d -q output 我们执行以上操作分别在rk3568、rk3562及rk3588进行3天的延迟测试。其中rk3568和rk3562将CPU3从内核SMP平衡和调度算法中剔除，而rk3588将CPU6和CPU7从内核SMP平衡和调度算法中剔除，以便观察芯片最好的实时性能。 为了便于观察，我们将rk3568、rk3562及rk3588的测试结果转换成直方图和表，如下所示。 在本次测试中，RK3562的CPU2核心Max Latencies值最大，为152us，隔离CPU3核心（从内核SMP平衡和调度算法中剔除的核心）的Max Latencies值最小，为20us。 RK3568的CPU0核心的Max Latencies值最大，为135us，隔离CPU3核心的Max Latencies值最小，为18us。 RK3588的CPU0核心的Max Latencies值最大，为45us，隔离CPU7核心的Max Latencies值最小，为3us。 由此可见，在同芯片平台下隔离核心的实时性最好。所以尽量将我们的实时任务绑定到隔离核心运行，以获得最好的实时效果。 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 Total 420738794 420738789 420738773 420738757 Min Latencies 00003 00003 00003 00002 Avg Latencies 00009 00008 000012 00003 Max Latencies 00074 00078 00152 00020 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 Total 259200000 259199935 259199824 259199769 Min Latencies 00004 00003 00003 00003 Avg Latencies 000017 000015 000017 00004 Max Latencies 000135 000112 00107 00018 Latencies \\ Core CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 Total 259200000 259199978 259199943 259199926 259199914 259199930 259199871 259199898 Min Latencies 00003 00003 00003 00003 00001 00001 00001 00001 Avg Latencies 00007 00006 00006 00006 00003 00003 00001 00001 Max Latencies 00045 00037 00035 00033 00024 00020 00004 00003 1.2.1.1. 其他压力场景¶不同场景的延迟测试结果不尽相同，为了尽可能接近我们的生产环境，可同时制作其他压力场景，如： 制造网络压力： #使用iperf进行上下行同时测试，使网卡的发送和接收处于满负载状态iperf -c 192.168.1.220 -p 8001 -f m -i100 -d -t 259200 制造gpu压力： #无限地运行，从最后一个基准循环到第一个基准glmark2-es2-wayland --run-forever 1.2.2. Cyclictest标准测试¶threads选项(-t)用于指定Cyclictest在检测延迟时将使用的测量线程数。通常，在系统上的每个CPU上只运行一个测量线程是一个标准的测试方案。可以使用亲和性选项(-a)指定线程必须在其上执行的cpu。 这些选项对于最小化运行Cyclictest对观察到的系统的影响至关重要。在使用Cyclictest时，确保在任何给定时间只执行一个测量线程是很重要的。如果两个或多个Cyclictest线程的预期执行时间重叠，则Cyclictest的测量将受到其自己的测量线程所造成的延迟的影响。确保在给定的时间只执行一个测量线程的最好方法是在给定的CPU上只执行一个测量线程。 例如，如果要分析三个特定cpu的延迟，则指定应该使用这些cpu(使用-a选项)，并指定应该使用三个测量线程(使用-t选项)。在这种情况下，为了最小化Cyclictest的开销，请确保收集度量数据的主Cyclictest线程没有运行在三个隔离的cpu之一上。主线程的关联性可以使用taskset程序设置，如下所述。 1.2.2.1. 在评估一组隔离的cpu上的延迟时，减小cyclictest的影响¶在测量cpu子集上的延迟时，确保主Cyclictest线程正在未被评估的cpu上运行。例如，如果一个系统有两个CPU，并且正在评估CPU 0上的延迟，那么主Cyclictest线程应该固定在CPU 1上。Cyclictest的主线程不是实时的，但是如果它在被评估的CPU上执行，它可能会对延迟产生影响，因为会有额外的上下文切换。在启动Cyclictest之后，可以使用taskset命令将主线程限制为在cpu的某个子集上执行。例如，针对CPU1到CPU3的延时测试: #CPU1到CPU3运行实时程序，主线运行在CPU0上taskset -c 0 ./cyclictest -t3 -p99 -a 1-3 taskset程序还可以用于确保系统上运行的其他程序不会影响隔离CPU上的延迟。例如，启动程序top查看线程并固定到CPU 0上，使用下面的命令: taskset --cpu 0 top -H -p PID#top打开之后点击f键，光标移动到 P 选项，空格选中，然后点击 q建退出，便可查看到实时线程在哪些CPU上运行。 1.3. 提高实时策略¶1.3.1. 抑制控制台消息及禁止内存过度使用¶#可以使用内核参数quiet启动内核，或者启动之后抑制，如下：echo 1 /proc/sys/kernel/printk#禁用内存过度使用以避免 Out-of-Memory Killer产生的延迟echo 2 /proc/sys/vm/overcommit_memory 1.3.2. 不使用桌面或者使用轻量级窗口管理器¶为了更好的实时，我们不建议使用带桌面的系统，因为这将为CPU延迟带来很大的挑战。建议使用minimal ubuntu、自己的QT程序等。 356x的rt固件默认不使用桌面，而是使用窗口管理器weston，显示协议是Wayland。 1.3.2.1. 切换X11环境¶如果你需要X11的环境，可手动切换到X11 sudo set_display_server x11reboot#sudo set_display_server weston 可再次切换回weston，重启生效 1.3.2.1.1. 使用openbox 窗口管理器启动¶切换到X11环境默认使用桌面，如果需要使用轻量级的窗口管理器 在etclightdmlightdm.conf 指定ession使用openbox窗口管理器： cat /etc/lightdm/lightdm.conf.d/20-autologin.conf [Seat:*]user-session=openboxautologin-user=firefly 1.3.2.1.2. 只运行自己的X11程序¶若是不用登录管理器启动 X显示服务，可使用xinit手动启动Xorg显示服务。 执行xinit和startx时，它们将寻找.xinitrc做为shell脚本运行以启动客户端程序。 若是.xinitrc不存在，startx将运行默认值etcX11xinitxinitrc(默认的xinitrc启动一个Twm，xorg-xclock和Xterm环境)。 首先关闭lightdm服务 systemctl disable lightdm 然后使用startx启动自己的程序 也可修改默认startx指定的client 的xinitrc文件,默认的会运行Xorg vim /etc/X11/xinit/xinitrc-------------------------------------------------------------#!/bin/sh # /etc/X11/xinit/xinitrc## global xinitrc file, used by all X sessions started by xinit (startx)# invoke global X session script#. /etc/X11/Xsession#chromium --window-size=1920,1080chromium --start-maximized 1.3.3. 绑定核心¶实时要求高的事件固定到某个核心上处理，系统及其它实时要求不高的事件集中到一个核心上处理。例如特定的中断，实时程序等事件可以用专门的核心为他们服务。 1.3.3.1. 任务绑定核心¶rt应用可由特定核心处理，将rt应用绑定到cpu3 1.3.3.2. 中断绑定核心¶由于arm将所有外设中断全部由cpu0处理，对于重要的中断可以在系统启动之后将中断绑定到其他核心。 例如将eth0中断绑定到cpu2 root@firefly:~# cat /proc/interrupts | grep eth0 38: 28600296 0 0 0 GICv3 64 Level eth0 39: 0 0 0 0 GICv3 61 Level eth0root@firefly:~# cat /proc/irq/38/smp_affinity_list 0-3root@firefly:~# echo 2 /proc/irq/38/smp_affinity_listroot@firefly:~# cat /proc/irq/38/smp_affinity_list root@firefly:~# cat /proc/interrupts | grep eth0 38: 29009292 0 52859 0 GICv3 64 Level eth0 39: 0 0 0 0 GICv3 61 Level eth0 1.3.4. 使用smp+amp方案¶对于实时要求更高的，可以使用amp方案，以达到更好的实时控制。 rk3568支持了amp（非对称多核架构），你可以定制某些核心跑定制的系统。 比如0～2核心跑kernel，3核心跑rt-thread等；支持 Linux(Kernel-4.19、rt-kernel-4.19)、 Baremetal(HAL)、RTOS(RT-Thread) 组合AMP构建形式，可任意搭配。 不同内核之间可以使用核间通信来进行信息交互。","tags":["clippings"],"categories":["0.平台","嵌入式","RealTime"]},{"title":"移植步骤","path":"/2024/12/18/0-平台-嵌入式-应用软件移植-移植步骤/","content":"嵌入式 Linux 系统移植的四大步骤在学习嵌入式 Linux 系统移植时，了解每个步骤的目的和过程至关重要。我在这个过程中发现了一些常见问题，并努力找到解决方案。但对于开发结果，常常会感到不解。经过思考，我意识到对开发环境的透彻理解是非常必要的。有时一个简单的命令可以实现复杂的功能，但如果没有深入思考这些命令的工作原理，我们可能只是机械地完成任务，而无法真正掌握系统移植的精髓。 在进行每一步时，应该先问自己：为什么要这样做？正在做什么？一旦澄清了这些问题，无论之后你面临何种平台、芯片或开发环境，都能够迅速上手。我的学习方法是：从宏观上把握（解决“为什么”的问题），再微观上研究（解决“正在做什么”的问题）。以我学习的 ARM Cortex-A8 开发板为例，下面将详细介绍嵌入式 Linux 系统移植的四大部分。 搭建交叉开发环境搭建交叉开发环境是移植的第一步。为了理解这一部分，我们需要首先思考两个问题：什么是交叉开发环境？为什么需要它？ 什么是交叉开发环境？在嵌入式开发中，交叉开发是一个核心概念。交叉开发环境指的是在开发主机（通常是个人电脑）上编写的程序能够在目标机（通常是开发板）上运行。嵌入式系统往往因为其硬件限制，无法在自己身上直接进行开发。例如，大多数开发板在初始状态下无法运行任何程序，因此我们需要在 PC 上进行编译、构建，并且将烧录到开发板中。 为什么需要交叉开发环境？ 硬件限制：嵌入式设备的处理速度和内存有限。比如，使用几百 MHz 主频的微控制器去编译 Linux 内核，结果会让人坐等得不耐烦。相比之下，个人电脑通常拥有更快的处理器和更丰富的内存资源，这让在这样的上进行开发变得更为高效。 体系结构和指令集差异：各个嵌入式系统的 MCU（微控制单元）往往有不同的体系结构和指令集。因此，我们必须使用交叉编译器来生成可在目标平台（如 ARM、MIPS、PowerPC 等）上正常运行的程序。 硬件组成交叉开发环境主要由以下组成部分： 开发主机：通常是我们常用的个人电脑。 目标机（开发板）：我们要移植系统的设备。 连接介质：常用的连接方式包括： 串口线 USB 线 网络线 针对以上硬件部分，我们还必须具备相应的软件支持： 串口调试助手：通常会用到 Putty 等工具来进行串口通信。 USB 驱动：例如三星芯片的 USB 下载可以用 DNW 软件完成。 网络协议支持： TFTP 服务：用于实现文件下载，可将需要测试的 bootloader、kernel 和文件系统直接下载到内存运行，而不需要提前烧录到 Flash 中。这种方式对于频繁的测试非常有用，因为 Flash 的擦写次数有限。 NFS 服务：用于实现网络文件系统的挂载，方便在开发板和开发主机之间共享文件，尤其是在制作文件系统测试时，可以直接挂载，而不必烧录到 Flash 中。 还有一个名为Samba的服务也值得关注，它实现的是 Windows 主机和 Linux 虚拟机之间的文件共享，便于进行不同平台之间的文件传输。 通过上述工具，嵌入式开发的效率得到了极大的提升。所有的工作过程都是围绕着测试进行的。测试完成后，我们才会将相应的目标文件烧录到 Flash 中。 使用交叉编译器的必要性在搭建完交叉开发环境后，关键的一步是选择交叉编译器。交叉编译器是一个能够在一个平台（如 X86 架构的 PC）上生成适合另一种平台（如 ARM 架构的开发板）上运行的程序。通常所称的本地编译在当前平台上进行，因此编译得到的程序自然也只能在本地执行。为了确保在目标机上运行的程序可以正确生成，我们必须使用交叉编译工具链。 交叉编译工具不仅仅是编译器，它包括编译器、链接器和调试器等组成部分，形成一个完整的开发环境。它的核心逻辑类似于构建嵌入式 Linux 内核，关注于我们所需的组件，去掉不需要的部分。 构建交叉编译工具链的方法构建交叉工具链有三种主要方法： 分步编译和安装：这是最传统和困难的方法，适合希望深入学习交叉工具链构建的读者。 使用 Crosstool-ng 脚本工具：这是较为简便且易于实现的方法，更适合大多数开发者。 下载现成的交叉编译工具链：虽然这种方法简单省事，但往往因固定性和不灵活，可能引发各种意外错误。 Crosstool-ng 是一个流行的脚本工具，可以帮助我们创建适合不同平台的交叉编译工具链。在使用之前，需要确保环境中安装了一些依赖软件，例如： $ sudo apt-get install g++ libncurses5-dev bison flex texinfo automake libtool patch gcj cvs cvsd gawk 下载 Crosstool-ng 脚本工具后，解压并进行配置，主要流程包括： 设定源码包路径和交叉编译器的安装路径。 修改交叉编译器针对的架构。 增加并行编译的进程数，以提高编译效率。 关闭 JAVA 编译器，减少编译时间。 开始编译。 添加环境变量并刷新。 测试交叉工具链的有效性。 到这里，嵌入式 Linux 系统移植的第一部分工作便已经完成，接下来可以进行电源选择、bootloader、内核等其他步骤的开发。 Bootloader 的选择和移植Boot Loader 概念Bootloader 是在操作系统内核运行之前的一段小程序。它的主要作用是初始化硬件设备、建立内存空间的映射关系，从而将系统的软硬件环境调整到一个合适的状态，以便为最终调动操作系统内核准备好正确的执行环境。因此，Bootloader 被称为引导加载程序（Boot Loader）。 为什么系统移植之前要先移植 Boot Loader？Bootloader 的任务是引导操作系统，具体来说，就是将内核加载到内存（RAM）中运行。那么首先要明确两个问题：谁负责把内核搬到内存中？内存是 SDRAM，和 SRAM 有哪些不同？SRAM 一上电就能够正常工作，但 SDRAM 则需要通过软件初始化。由此， Bootloader 首先要初始化 SDRAM，然后才能将内核加载到内存中。因此，可以得出结论：没有 Bootloader，我们的系统无法启动。 Bootloader 的分类首先纠正一个常见误解：Bootloader 并不等同于 U-Boot，U-Boot 只是 Bootloader 的一种。Bootloader 拥有多种不同的实现和类型，不同类型的 Bootloader 各有其特定的使用范围。其中最受关注的就是 U-Boot，这是一款通用的引导程序，支持多种处理器架构，包括 X86、ARM 和 PowerPC 等。U-Boot，全称 Universal Boot Loader，遵循 GPL 条款，是由德国 DENX 团队开发的开源项目。它为多种嵌入式 CPU 提供支持，并对 Linux 的发展做出了重大贡献。 U-Boot 具有以下特点： 开放源码：开发者可以自由使用和修改源代码。 多操作系统支持：支持多种嵌入式操作系统内核，如 Linux、NetBSD、VxWorks、QNX、RTEMS、ARTOS 和 LynxOS。 多处理器架构兼容性：本身设计成可以支持 PowerPC、ARM、x86、MIPS 和 XScale 等多种处理器系列。 高可靠性和稳定性：在各类设备中的应用表现稳定。 灵活性：具有高度可配置的功能设置，适合调试、不同操作系统的引导需求，以及产品发布。 丰富的设备驱动：包括串口、以太网、SDRAM、FLASH、LCD、NVRAM、EEPROM、RTC、键盘等多个外设驱动。 详尽的开发文档，以及强大的网络技术支持。 从某种程度上说，可以把 U-Boot 理解为一个轻量级的操作系统。 U-Boot 的目录结构U-Boot 的文件结构如下： board：存放目标板相关文件，主要包含 SDRAM 和 FLASH 驱动。 common：包含独立于处理器的通用代码，例如内存大小探测与故障检测。 cpu：与处理器相关的文件，例如某处理器的串口、网络、LCD 驱动及中断初始化等。 driver：通用设备驱动，比如 CFI FLASH 驱动，目前对 Intel FLASH 支持相对较好。 doc：U-Boot 的说明文档。 examples：可在 U-Boot 下运行的示例程序，如 hello_world.c 和 timer.c。 include：U-Boot 的头文件，尤其是 configs 子目录中与目标板相关的配置头文件，这些文件在移植过程中经常需要修改。 lib_xxx：与处理器体系结构相关的文件库，例如 lib_ppc 和 lib_arm，分别包含 PowerPC 和 ARM 相关的代码。 net：与网络功能相关的文件目录，包括 bootp、nfs 和 tftp 等。 post：上电自检相关文件目录，尚在完善中。 rtc：RTC 驱动程序。 tools：用于创建 U-Boot S-RECORD 和 BIN 镜像文件的工具。 U-Boot 的工作模式U-Boot 的工作模式主要分为启动加载模式和下载模式。在启动加载模式下，Bootloader 是默认的工作模式，通常在嵌入式产品发布时使用。在这一模式下，Bootloader 将嵌入式操作系统自动从 FLASH 加载到 SDRAM 中运行。 而下载模式则是通过某些通信手段将内核映像、根文件系统映像等从 PC 机下载到目标板的 SDRAM 中。在这一模式下，用户可利用 Bootloader 提供的命令接口完成所需操作，主要用于开发和测试。 U-Boot 的启动过程大多数 Bootloader 都被划分为阶段 1（stage1）和阶段 2（stage2），U-Boot 也不例外。通常，依赖于 CPU 体系结构的基础代码（如设备初始化代码）放在阶段 1，并用汇编语言编写，而阶段 2 则用 C 语言实现，以便实现更复杂的功能和更好的可读性与移植性。 Stage1（start.s 代码结构）U-Boot 的 stage1 代码通常用汇编语言存放在 start.s 文件中，主要包括以下部分： 入口定义：一个可执行的映像必须有一个入口点，通常放置在 ROM（Flash）的 0x0 地址。 设置异常向量。 设置 CPU 的速度、时钟频率和中断控制寄存器。 初始化内存控制器。 将 ROM 中的程序复制到 RAM 中。 初始化堆栈。 跳转到 RAM 中执行，通常通过指令 ldrpc 实现。 Stage2（C 语言代码部分）在文件 lib_arm/board.c 中，start_armboot 是 C 语言实现的函数，也是整个启动代码中的主函数。它主要完成以下操作： 调用一系列的初始化函数。 初始化 FLASH 设备。 初始化系统内存分配函数。 如果目标系统包含 NAND 设备，则初始化相应设备。 如果有显示设备，则进行初始化。 初始化相关的网络设备，填写 IP 地址等信息。 进入命令循环，接受用户通过串口输入的命令，进行相应的操作。 基于 Cortex-A8 的 S5PC100 Bootloader 启动过程分析S5PC100 支持两种启动方式：USB 启动方式和 NAND Flash 启动方式。 S5PC100 USB 启动过程 执行 A8 reset，运行 iROM 中的程序。 iROM 程序根据 S5PC100 的配置管脚（SW1 开关 4，拨到 4 对面），判断启动来源（USB）。 iROM 程序初始化 USB，等待 PC 机下载程序。 利用 DNW 工具，从 PC 下载 SDRAM 的初始化程序到 iRAM 中运行，初始化 SDRAM。 SDRAM 初始化完毕后，iROM 程序接管 A8，并等待 PC 下载 Bootloader。 PC 利用 DNW 下载 Bootloader 到 SDRAM 中。 在 SDRAM 中运行 Bootloader。 S5PC100 NAND Flash 启动过程 执行 A8 reset，运行 IROM 中的程序。 iROM 程序根据 S5PC100 的配置管脚判断启动来源（NAND Flash）。 iROM 程序驱动 NAND Flash。 iROM 程序拷贝 NAND Flash 的前 16KB 到 iRAM 中。 前 16KB 程序（Bootloader 的前半部分）初始化 SDRAM，然后拷贝完整的 Bootloader 到 SDRAM 并运行。 Bootloader 拷贝内核到 SDRAM 中，并运行动态加载的内核。 内核运行后，挂载 rootfs，并运行系统初始化脚本。 U-Boot 移植（基于 Cortex-A8 的 S5PC100 为例） 下载稳定版本的源码包，如 2010.03 版本。 解压后，添加自己平台的信息，参考 SMDKC100 进行 S5PC100 开发板的移植。 修改相应目录的文件名及 Makefile，指定交叉工具链。 编译。 针对平台进行相应移植，主要包括修改 SDRAM 的运行地址（通常从 0x20000000 开始）。 开关相应的宏定义。 添加 NAND 和网卡的驱动代码。 优化 go 命令。 重新编译，执行 make distclean（彻底删除中间文件和配置文件），然后执行 make s5pc100_config（配置开发板）和 make（生成 u-boot.bin 镜像文件）。 设置环境变量，即启动参数，并将编译好的 u-boot 下载到内存中，具体步骤如下： 配置开发板网络 IP 地址配置: setenv ipaddr 192.168.0.6 保存环境变量到 NAND Flash 的参数区： saveenv 网络测试： ping 192.168.0.157 # 虚拟机的 IP 地址 如果网络测试失败，请检查以下几点： 网络线是否连接良好。 开发板和虚拟机的 IP 地址是否在同一网络段。 虚拟机网络设置必须选择桥接（VM → Setting → option）。 连接开发板时，虚拟机需要设置为静态 IP 地址。 在开发板上配置 TFTP 服务器（虚拟机）的 IP 地址： setenv serverip 192.168.0.157 # 虚拟机的 IP 地址saveenv 拷贝 u-boot.bin 到 /tftpboot（虚拟机上的目录）。 通过 TFTP 下载 u-boot.bin 到开发板内存： tftp 20008000 u-boot.bin # 下载到指定内存地址 如果上述命令无法正常下载，请检查： serverip 的配置是否正确。 TFTP 服务是否启动，必要时重启 TFTP 服务： sudo service tftpd-hpa restart 烧写 u-boot.bin 到 NAND Flash 的 0 地址： nand erase 0 40000 # 擦除 NAND Flash 0 - 256k 的区域nand write 20008000 0 40000 # 烧写大小 切换开发板的启动方式到 NAND Flash： 关闭开发板。 将 SW1 开关 4 拨到 4 的那边。 启动开发板，它将从 NAND Flash 启动。 Kernel 的配置、编译和移植Linux 源码首先，将下载下来的 linux-2.6.35.tar.bz2 文件移动或拷贝到主目录中。在 Linux 环境中，可以使用以下命令完成这一步骤： cp ~/Downloads/linux-2.6.35.tar.bz2 ~/ 接下来，可以使用下面的命令解压这个文件： tar -xvjf linux-2.6.35.tar.bz2 解压完成后，会在主目录中生成一个名为 linux-2.6.35 的文件夹，里面包含了 Linux 内核的所有源代码。 修改顶层目录下的 Makefile在进入 linux-2.6.35 的目录后，我们需要修改顶层目录下的 Makefile。这一步骤很关键，因为它决定了我们要编译的平台架构和使用的交叉编译器。可以通过文本编辑器打开 Makefile，找到如下代码： ARCH ?= $(SUBARCH)CROSS_COMPILE ?=CROSS_COMPILE ?= $(CONFIG_CROSS_COMPILE:%=%) 我们要将这些行修改为： ARCH ?= arm # 体系架构是 arm 架构CROSS_COMPILE ?= arm-cortex_a8-linux-gnueabi- # 交叉编译器是 arm-cortex_a8 平台的 这两项设置非常重要，因为它们会直接影响到 Makefile 在编译时的行为。ARCH 变量定义了目标 CPU 的架构，而 CROSS_COMPILE 则指明了我们将使用的交叉编译器，从而确保编译出的代码可以在 ARM 的 Cortex-A8 平台上运行。 拷贝标准版配置文件接下来，我们需要拷贝一个标准版的配置文件，以便获取与我们开发板相关的配置信息。使用以下命令： cp arch/arm/configs/s5pc100_defconfig .config 这一命令的目的是将 s5pc100_defconfig 文件复制到顶层目录下，并命名为 .config。这样做的好处是，它提供了一种快速的方法来选择与我们的开发板相关的代码。Linux 支持的硬件平台非常庞大，不仅包括 ARM 架构，还包括多种其他架构。因此，在编译时，我们只希望专注于与我们具体开发板相关的代码，而不希望无谓地编译不相关的部分。 考虑到 Linux 源代码的文件数量超过一万，我们需要确保选择的配置文件能够有效地过滤出所需的代码。这一过程设计得非常巧妙，内核开发者早就预见了这个需求，针对不同的硬件平台设定了对应的配置文件，只需通过简单的文件复制操作，我们的 .config 文件便可自动记录下与平台相关的信息。 当我们首次执行 make menuconfig 命令时，系统会自动解析 .config 文件中的配置，根据我们之前选择的平台信息，选取合适的代码和模块。此时，我们只需要进入该配置界面，做一些简单的修改，最后选择保存即可。这样，系统会将所有与我们目标平台相关的信息保存到顶层目录的 .config 文件中。这种操作方式不仅高效，而且减少了人为错误的可能，使得内核的配置和编译变得更加简便。 配置内核运行以下命令以进入配置界面： $ make menuconfig 在第一次进入这个配置界面时，无需进行任何修改，直接退出。当系统提示是否保存配置信息时，一定要选择“YES”。通过此步骤，我们将开发平台的信息保存至 .config 文件中，这个文件对于后续的编译和配置至关重要。 make menuconfig 的过程在执行 make menuconfig 时，我们需要理解系统到底进行了哪些操作。特别地，为什么会出现图形化的界面？而这个界面中的内容又是从哪里来的呢？ 图形化界面的实现该图形化界面是通过一个名为 ncurses 的图形库实现的。当我们首次执行 make menuconfig 时，如果系统没有安装 ncurses 库，会导致报错并显示缺少 ncurses-devel 的信息。在这种情况下，你可以通过以下命令安装所需的库： sudo apt-get install libncurses5-dev 有了 ncurses 的支持，系统才能正常显示图形化界面，让用户进行配置。 图形界面内容的来源在解决了图形界面问题后，我们必须明确图形界面里的内容是如何生成的。这个问题的答案与 Linux 内核的设计理念密切相关。Linux 内核采用模块化的组织方式。这种设计使得内核不再是一个庞大的单一实体，而是由多个独立的模块组成，每个模块负责特定的功能。 在 Linux 2.6 内核的源码树中，通常可以找到两个重要的文件：Kconfig 和 Makefile。分布在各个目录下的多个 Kconfig 文件共同构成了一个分布式的内核配置数据库。每个 Kconfig 描述了其所在目录下源文件相关的内核配置菜单。这意味着每个目录都可存放与功能相对独立的信息。 例如，在 /dev/char/ 目录下，存放了所有字符设备的驱动程序。这些驱动程序的代码在内核中以模块的形式存在。这就意味着，当系统需要某个驱动时，会将其以模块的形式编译进内核，分为静态编译和动态编译。静态编译的内核体积普遍比动态编译的大。 Kconfig 文件的作用Kconfig 文件中保存了目录下可用模块的信息。如果将某个目录的 Kconfig 文件内容全部删除，图形化界面将无法显示该模块的信息，用户也就无法进行相应的配置。 在内核配置过程，如运行 make menuconfig 或 xconfig 时，系统会自动从 Kconfig 文件中读取配置菜单。用户在界面中进行的配置被保存到 .config 文件中，该文件生成在顶层目录。.config 文件包含了所有的配置信息，记录了用户对内核配置的具体情况。主 Makefile 会引用 .config，以了解用户的内核配置。 扩展驱动的步骤如果想要在内核源码中添加新驱动，可以通过修改 Kconfig 文件来增设该驱动的配置菜单，以便用户能够选择。而如果希望使这个驱动被编译，必须修改该驱动所在目录下的 Makefile 文件。当添加新的驱动时，通常需要关注两个文件：Kconfig 和相关目录的 Makefile。尽管这两者是最为关键的，实际上，整个系统移植过程中还可能涉及其他多个文件的修改。因此，Kconfig 和相应目录的 Makefile 是添加或删除内核模块的核心文件。 编译内核通过运行以下命令： $ make zImage 我们能够在 arch/arm/boot 目录下生成一个 zImage 文件。这是经过压缩的内核镜像，通常用于嵌入式系统。zImage 通常比未压缩的内核镜像小，能够更快地加载到内存中，从而提升系统启动速度。 内核的编译过程相当复杂。需要注意的是，这里的编译是静态编译，我们执行的是顶层目录下的 Makefile 中定义的 zImage 命令。这个过程中，编译系统会依据当前目录的 .config 文件来选择需要的源代码，而这个 .config 文件中包含了关于内核各个组件的配置信息，例如启用或禁用特定的驱动程序或功能模块。 整个编译内核的过程包括多个步骤，如配置、编译和链接，具体步骤诸如： 配置内核选项：使用 make menuconfig 或 make xconfig 生成 .config 文件。 编译内核：执行 make zImage 开始编译。 生成压缩镜像：最终生成的 zImage 文件将放置在适当的目录中。 由于整个过程的复杂性，编译内核的细节我们可以在后续的文章中进行深入探讨。 通过 TFTP 网络服务下载测试内核使用下面的命令设置引导参数： setenv bootcmd tftp 20008000 zImage; go 20008000 在这个命令中，20008000 是目标内存地址，这个地址是在开发板的内存中用于加载内核镜像的。zImage 是我们之前编译得到的内核镜像。go 命令会从指定的地址启动内核，整个过程是通过 TFTP（Trivial File Transfer Protocol）完成的。 接下来，我们设置内核启动的参数： setenv bootargs nfs nfsroot=192.168.1.199:/source/rootfs ip=192.168.1.200 init=/linuxrc ttySAC0,115200 这里的 nfsroot 指明了 NFS 服务器的 IP 地址和根文件系统的路径。ip 用于指定开发板的 IP 地址，以便于网络通信。init=/linuxrc 表示启动后将执行的第一个用户进程，ttySAC0,115200 则设置了串口的配置，其中 ttySAC0 是开发板的串口设备，波特率为 115200。 最后，保存以上环境变量并复位开发板，命令如下： saveenvreset 确认 NFS 文件系统已设置好，并能够成功挂载。这个过程相对复杂，特别是涉及到网络设置的问题，因此确保网络连接正常非常关键。要确保在启动之前，网络上的 NFS 服务器是可以访问的，否则启动过程将无法完成。在后续的文章中，我们将详细介绍内核测试和启动的其他相关步骤。 根文件系统的介绍本部分以 Flash 存储中存放文件的分布图为起点，探讨文件系统的制作和移植，这通常是系统移植过程的最后一步。在此之前，我们首先需要明确几个关键问题： 什么是文件系统？ 如何实现文件系统？ 常用的文件系统有哪些？为什么需要这些文件系统？ 接下来，我们将逐一解答这些问题。 文件系统概述在我们日常生活中，虽然很少有人直接提及“文件系统”这个名词，但其实际上无处不在，日常所称的资料库便是一个常见的例子。资料库中包含大量文件，而我们该如何快速且准确地找到需要的那份文件呢？这正是文件系统所负责的。类比于学校图书馆，其一楼可能是哲学类书籍，二楼是社科类，三楼是电子类，四楼则是计算机类。采取这种分类和索引的方法的资料库，我们称之为文件系统。 在计算机环境中，文件被视作数据的集合，存储于物理介质上，例如硬盘。用户无法直接访问物理介质上的文件，因此，所有文件的读写操作均需要通过程序来完成。为确保这一过程的顺畅，程序被划分为三个部分：物理介质驱动程序、内容存储程序和文件内容存储程序。物理介质驱动程序用于从物理介质读取和写入数据；内容存储程序的任务是将文件内容和其属性信息进行打包；文件内容存储程序则负责接收用户输入，从而形成文件内容，或者将读取的文件内容展示给用户。 文件系统的层次结构想象一下，我们可以将一个文件系统（倒树形结构）分解成多个文件系统（倒树形结构），并将这些子系统分别存放至不同的存储介质上。例如，一个文件系统存储在光盘中，另一个则存储在硬盘中。在使用时，我们将光盘中该文件系统的根目录挂载到硬盘文件系统的某个目录下。如此一来，访问这个特定目录就如同访问光盘的根目录一样，找到了根目录，我们就能访问整个光盘上的文件系统。 “在 Linux 系统中一切皆是文件”，这句话在我们学习 Linux 时常常能够听到，它虽然略显夸张，却有效揭示了文件系统在 Linux 中的重要性。实际上，文件系统在所有操作系统中都至关重要，它们通过文件的形式管理大部分的硬件设备和软件数据。以下是 Linux 系统中设备和数据管理的框架图： Linux 系统的文件系统结构 **VFS (Virtual File System)**：虚拟文件系统，管理特殊文件（如虚拟文件）、磁盘文件和设备文件。 fs_operations 结构：由一系列文件操作接口函数组成，由文件系统层来实现，为 VFS 提供文件操作。 文件系统层：在这一层，磁盘文件能实现多种文件系统，如 ext2，而设备文件则须实现各种抽象的设备驱动。 设备驱动层：重点在于磁盘驱动，需实现多种磁盘驱动程序，其他设备驱动负责具体设备的驱动。 物理层：这就是设备本身。 为什么会有不同的文件类型？由于存在多样的存储介质，单一的文件系统格式无法适用于所有介质，因此需要设计多种不同的存储格式，以优化存取效率和空间利用率。每种存储格式必须遵循特定的规范，这些规范被称为文件系统类型。 常见文件系统类型 DOS 系列： FAT16 Windows 系列： FAT16、FAT32、NTFS Linux 系列： Minix、ext、ext2、ext3、ISO9660、jffs2、yaffs、yaffs2、cramfs、romfs、ramdisk、rootfs、proc、sysfs、usbfs、devpts、tmpfs 和 ramfs、NFS 由此可见，Linux 支持的文件系统种类最为丰富。根据不同的介质进行分类如下展示： 磁盘：FAT16、FAT32、NTFS、ext、ext2、ext3、Minix 光盘：ISO9660 Flash 存储：jffs2、yaffs、yaffs2、cramfs、romfs 内存：ramdisk、tmpfs 和 ramfs 虚拟文件系统：rootfs、proc、sysfs、usbfs、devpts、NFS 理论上，常用的存储介质都可以支持所列的 Linux 文件系统。不过在嵌入式系统的应用中，由于受限于体积和便携特性，无法使用磁盘和光盘，因而只能选择 Flash 类型的存储设备、内存和虚拟存储设备。 Flash 存储和内存中的文件系统Flash 芯片的驱动程序由系统提供，因此其存取特性完全取决于 Flash 本身特点，因此需要更适合 Flash 的文件系统，如 JFFS、YAFFS、CramFS 和 ROMFS。这些文件系统都是在嵌入式 Linux 系统中常用的，并可根据各自特点进行选择，具体特点如下： 共同特点 基于 MTD 驱动 JFFS 针对 NOR Flash 的实现 基于哈希表的日志型文件系统 通常采用损耗平衡技术确保存储效能 支持数据压缩，可读写 提供崩溃掉电的安全保护 当文件系统接近满时，由于垃圾收集机制可能会影响运行速度 YAFFS 针对 NAND Flash 的实现 日志型文件系统 实施损耗平衡，确保存储均衡 可读写，不支持数据压缩 挂载时间短，内存占用少 自带 NAND Flash 驱动，无需外部 VFS 和 MTD CramFS 单页压缩，支持随机访问，压缩比最高可达 2:1 速度快，效率高 只读特性有助于保护文件系统，提高系统可靠性，但无法扩充内容 ROMFS 简单、紧凑、只读文件系统 顺序存放数据，支持 XIP（Execute In Place，片内运行），在系统运行时节省 RAM 空间 特有的文件系统类型：Ramdisk 文件系统在 Linux 系统中，Ramdisk 常用于存储文件系统，Ramdisk 分为两种：一种将物理内存视作物理存储介质，模拟磁盘；另一种则仅在内存中存储文件系统的逻辑结构，运用 tmpfs 和 ramfs 文件系统类型。 tmpfs ramfs 概述 物理内存模拟磁盘分区，挂载后可像读写磁盘文件一样读写文件，其操作速度显著高于磁盘文件。 一般应用场景包括： 速度要求快的文件可放置于此文件系统中 当磁盘分区为 Flash 时，将频繁读写的文件放置于此，并定期写回 Flash 系统的临时文件，如 /tmp 和 /var 目录下的文件 /dev 设备文件（因为设备文件随驱动和设备加载卸载而变化） 特点 数据保存在物理内存中，系统重启后，该文件系统的数据会全部丢失。 ramfs 在没有指定最大大小时会自行增长，直至占用所有物理内存，可能导致系统崩溃，因此建议在挂载时设定最大值。 tmpfs 如果指定大小，将在达到最大值后不再继续增长，且其占用的物理内存页可以换出到 swap 分区，而 ramfs 则不具备这一特性。 不同的文件系统拥有各自的构建方法。","categories":["0.平台","嵌入式","应用软件移植"]},{"title":"C语言函数速查","path":"/2024/12/18/1-语言-C语言-C语言函数速查/","content":"字符串函数（string） bcmp比较字符串 s1 和 s2 的前 n 个字节是否相等。这可用于检验两个子串是否相同，常用于验证数据完整性或校验。 bcopy将字符串 src 的前 n 个字节复制到 dest 中。这个函数用于在内存中快速地移动数据，常见于操作字符串或缓冲区时的复制需求。 bzero将字节字符串 s 的前 n 个字节置为零。在初始化数据结构时常用，比如清空一个数组，确保没有垃圾值存在。 memccpy从 src 所指内存区域复制不超过 count 个字节到 dest，如果遇到字符 ch 则停止复制。该函数可以在复制途中查找特定字符，十分适合处理需要分隔的数据。 memchr从 buf 所指内存的前 count 字节中查找字符 ch。返回指向首次出现该字符的指针，如果未找到则返回 NULL。适合查找数据包中的特定标志。 memcmp比较内存区域 buf1 和 buf2 的前 count 个字节。这可以用于二进制数据比较，例如在网络协议中校验接收数据是否正确。 memcpy将从 src 所指内存区域复制 count 个字节到 dest 中。这个函数负责精准无误的字节拷贝操作，常用于数据管理和缓冲。 memicmp比较内存区域 buf1 和 buf2 的前 count 个字节，但不区分字母的大小写。非常适合需要忽略大小写的字符串比较情况。 memmove类似于 memcpy，但它支持在内存重叠时的安全复制。这意味着数据可以在重叠内存区域间安全移动，例如在数组元素排序时。 memset将 buffer 所指内存区域的前 count 个字节设置为字符 c。可以快速清理或初始化内存空间，例如填充数组。 movmem由 src 所指内存区域复制 count 个字节到 dest。它和 memmove 类似，主要用于特定情况下的内存移动。 setmem将 buf 所指内存区域的前 count 个字节设置为字符 ch，有助于统一数据格式或初始化。 stpcpy将 src 所指的以 NULL 结束的字符串复制到 dest 所指的数组中，并返回指向结果字符串末尾的指针。这对于字符串的进一步处理和拼接十分方便。 strcat将 src 所指字符串添加到 dest 结尾，并在末尾添加一个 \\0。例如，将一个文件的路径附加到根目录路径后，形成完整路径。 strchr查找字符串 s 中首次出现字符 c 的位置，返回指向该位置的指针。如果没有找到，返回 NULL。这个功能对查找特定字符非常实用。 strcmp比较字符串 s1 和 s2，返回值用于判断字典序关系。它是处理字符串排序和查找的重要函数。 strcmpi不区分字母大小写地比较 s1 和 s2。对于需要用户输入不敏感的比较场景非常有用。 strcpy将 src 指向的以 NULL 结束的字符串复制到 dest 指向的数组中，适合一般字符串初始化。 strcspn在字符串 s1 中搜寻 s2 中出现的字符，并返回首次出现的位置，适合过滤特定字符集。 strdup复制字符串，创建该字符串的新副本。可以用于动态内存管理中，例如需要存储复制字符串而不影响原字符串的场合。 stricmp不区分字母大小写地比较 s1 和 s2，有助于执行用户输入的比较时忽略大小写。 strlen计算字符串 s 的长度。该函数在字符串处理时非常基础且关键。 strlwr将字符串 s 转换为小写形式，适合于标识符规范化和统一格式。 strncat将 src 字符串的前 n 个字符追加到 dest 的末尾，并添加 \\0，有助于控制合并的长度。 strncmp比较字符串 s1 和 s2 的前 n 个字符，适合需要部分比较的场合。 strncmpi类似于 strncmp ，但不区分字母大小写，针对用户输入时可用。 strncpy将 src 指向的以 NULL 结束的字符串的前 n 个字节复制到 dest 中，适合在宽度限制下处理字符串。 strnicmp不区分大小写地比较 s1 和 s2 的前 n 个字符，适合在不关注大小写的前提下执行部分比较。 strpbrk在字符串 s1 中寻找 s2 中的任意字符匹配，返回第一个匹配字符的位置，适合行为匹配查找。 strrev将字符串 s 的所有字符的顺序颠倒（不包括 NULL），此功能用于加密和加扰数据时非常实用。 strset将字符串 s 中的所有字符都设置成字符 c，可用于初始化或格式化。 strstr从字符串 haystack 中寻找 needle 第一次出现的位置，并返回指针，适合简单的子串查找。 strtok分解字符串为一组标记串，使用指定的分隔符。此函数对解析输入数据格式尤其有效。 strupr将字符串 s 转换为大写形式，适合需要大小写统一的申请场合。 数学函数（math） abs返回整数的绝对值，例如 abs(-5) 返回 5，用于处理数值标准化。 acos计算给定值的反余弦值，反应角度的大小，适用于三角函数和物理计算。 asin计算给定值的反正弦值，常用于三角函数应用在几何图形解析上。 atan计算一个数的反正切值，通常用于科学计算和工程分析。 atan2利用 y 和 x 值计算反正切，常在极坐标和直角坐标之间转换。 ceil返回大于或等于 x 的最小整数，适用于向上取整的场合。 cos计算给定角度的余弦值，广泛应用于波形和周期函数计算。 cosh计算给定值的双曲余弦，常在物理和工程等领域使用。 exp计算 e 的指定次幂，适用于指数增长和衰减计算。 fabs返回浮点数的绝对值，避免数值为负时候的误处理。 floor返回小于或等于 x 的最大整数，适合向下取整使用。 fmod计算浮点数的余数，常用于循环和排列计算。 frexp将浮点数分解为尾数和指数，便于科学计数和存储。 hypot根据两条直角边计算斜边长度，直接适用在毕达哥拉斯定理中。 ldexp载入浮点数，允许以指数形式进行浮点运算。 log计算自然对数，很多数学、物理公式都会涉及对数运算。 log10计算常用对数，广泛应用于科学和工程领域中的数据处理。 modf分解浮点数为整数和小数部分，有助于处理复杂的浮点算式。 pow计算 x 的 y 次方，基础的指数运算功能。 pow10计算 10 的 x 次方，便于大数处理和科学计算。 sin计算给定角度的正弦值，适用于周期性现象。 sinh计算双曲正弦的值，常用于相对论和波动方程。 sqrt返回给定数的平方根，处理几何和代数运算时不可或缺。 tan计算正切值，涉及角度时的各种物理现象。 tanh计算给定值的双曲正切，适合在信号处理等领域。 输入输出函数（stdio） getchar从键盘上读取一个字符，并返回该字符的键值，非常适合用户输入。 getch是 getchar 的宏定义，通常用于无回显情况下获取单个字符。 kbhit检测键盘是否有键按下。如果有键按下，返回对应键值；否则返回零。这个函数快速有效，无需等待用户输入。 printf格式化字符串输出，支持多种输出格式，提供了对数据展示的灵活控制。例如： 格式 描述 %c 输出单个字符 %d 输出十进制整数 %f 输出十进制浮点数 %o 输出八进制数 %s 输出字符串 %u 输出无符号十进制数 %x 输出十六进制数 常用的修饰符： 修饰符 含义 - 左对齐输出 + 输出带符号数时加上正负号 0 用零填充域宽 putchar在屏幕上显示字符 c，字符会在当前光标位置输出。可以通过 move 或 gotoxy 移动光标到指定位置。 系统函数system ClearScreen清屏，清除屏幕缓冲区及液晶显示缓冲区，光标位置回到屏幕的左上角。这在重置显示器状态时非常方便。 DispBCD用于在七段数码管上显示数字，根据调用显示对应数字，最大为 999，常用于数字显示。 SetScrollBar显示一个滚动条，可以用于长列表的目的。 TextOut在屏幕上的指定位置输出字符串，适合在图形界面应用开发中显示信息。 UpdateLCD以指定模式刷新屏幕，适用于需要更新显示内容的场合。 bell发出声音信号。 block涉及特定的系统操作。 clrscr清除屏幕，类似于 ClearScreen 函数。 cursor控制光标的显示和隐藏。 delay短暂延时，延时 msec*4 毫秒，常用于控制程序运行节奏。 get_chi_font获取中文字体设置。 get_eng_font获取英文字体设置。 getkey从键盘读取按键信息。 getpixel获取指定坐标的像素值。 gotoxy移动光标到指定坐标位置。 line在屏幕上绘制线段。 move操控光标位置。 noidle确保程序在无用户活动时不进入空闲状态。 outtextxy在指定坐标输出文本。 putpixel设置指定坐标的像素值。 pyfc与自定义函数有关的操作。 rectangle在屏幕上绘制一个矩形。 sleep暂停程序的执行，等待一段时间。 textmode设置文本显示模式。 time获取系统当前时间，返回 struct tm，其中包括小时、秒、分钟等信息，用于精准时间处理。 struct tm int hsec; /* 半秒数 [0-119] */ int sec; /* 秒 [0-59] */ int min; /* 分钟 [0-59] */ int hour; /* 小时 [0-23] */ int day; /* 天 [0-30] */ int wday; /* 星期 [0-6] */ int mon; /* 月 [0-11] */ int year; /* 年 - 1881 */; write_chi_font将中文字符输出到屏幕。 write_eng_font将英文字符输出到屏幕。 stdlib exit结束程序的执行，常用于处理异常情况或正常退出。 itoa将整数 i 转换成字符串，适用于需要显示数字的 UI。 字符函数（ctype） isalnum判断字符 c 是否为字母或数字，适合输入校验和过滤。 isalpha判断字符 c 是否为英文字母，常用于字符集验证。 iscntrl判断字符 c 是否为控制字符，例如 0x00-0x1F 或 0x7F，通常用于数据清理。 isdigit判断字符 c 是否为数字字符，有助于输入验证。 islower判断字符 c 是否为小写字母，适合对字母大小写的处理。 isascii判断字符 c 是否为 ASCII 字符，确保输入在合理范围内。 isgraph判断字符 c 是否为可打印字符（不包括空格），有助于字符输出控制。 isprint判断字符 c 是否为可打印字符（包含空格），用于界面输出时的字符处理。 ispunct判断字符 c 是否为标点符号，有助于分隔文本中的重要部分。 isspace检查字符是否为空白符，含空格、制表符等，常在文本解析中使用。 isupper判断字符 c 是否为大写字母，适用于大小写转换的场景。 isxdigit判断字符 c 是否为十六进制数字，适合处理需要十六进制数据的功能。 toascii将字符 c 转换为 ASCII 码，清除高位只保留低七位，确保数据在标准字符集内。 tolower将字母 c 转换为小写，适合用户输入的统一处理。 toupper将字母 c 转换为大写，适合文档标识中的要求。 内存管理函数（alloc） calloc为具有 num_elems 个长度为 elem_size 的数组分配内存，确保所有初始值为零，避免数据污染。 free释放指针 p 所指向的内存空间，防止内存泄漏。 malloc分配长度为 num_bytes 字节的内存块，创造新的内存区域，后续需通过 free 手动释放。 realloc改变 mem_address 所指的内存区域大小为 newsize，适用于动态增长或缩小数据结构的场景。","categories":["1.语言","C语言"]},{"title":"man帮助手册","path":"/2024/12/18/1-语言-C语言-man帮助手册/","content":"什么是 man 帮助手册在 Linux 系统中，”man”是”manual”的缩写，意指手册。它为用户提供了一种方便的方式来查找和浏览已经安装在系统上的各种命令、函数和配置文件的详细信息。”man”命令则是一个命令行工具，用于访问这些手册。 当你在命令行中输入”man”后跟特定的命令、函数或配置文件名时，系统会显示出相应的帮助页面。这些页面不仅解释了该命令或函数的基本用法，还列出其各种选项和参数。例如，使用命令 man ls 可以查看关于 ls 命令的详尽信息。页面通常还会包含示例，以便于用户理解如何在实际应用中使用该功能。 帮助页面通常依照不同层级的详细程度划分为多个部分，从基础到复杂应有尽有。你可以根据需要使用”man”命令的选项来访问特定部分的信息。例如，输入 man 1 ls 将为你展示关于”ls”命令的帮助信息，而 man 2 open 则将提供更深层次的关于”open”系统调用的说明。 “man”帮助手册是 Linux 用户必不可少的资源之一。无论你是新手还是经验丰富的用户，它都为你提供了深入理解和学习各种系统命令、函数，以及遇到问题时的解决方案的重要支持。 man 后面加数字代表什么在 Linux 中，”man”命令后面加上数字，表示你想查看帮助页面的特定部分。这些部分涉及到不同类型的命令和功能。具体来说，这里有一些常见的数字及其对应的帮助页部分： 1：标准命令。这部分提供了常见命令行工具和可执行程序的信息，如 ls、cp 等。 2：系统调用。这里包含与操作系统核心功能相关的函数的文档，例如处理文件和进程的系统调用，如 open() 和 fork()。 3：库函数。这部分聚焦于 C 语言中的标准库函数，涵盖如 printf() 和 malloc() 等函数的使用。 4：特殊设备。这部分涉及设备驱动程序、字符设备及块设备的说明，帮助用户理解如何与硬件交互。 5：文件格式。这部分描述系统配置文件、数据库文件及其他文件格式的相关信息，如 passwd 文件的格式和用法。 6：游戏和玩具。这部分列出一些可以在终端运行的小游戏，像 nethack 和其他趣味命令。 7：杂项。提供一些其他文档、约定和标准的信息，可能包括协定或者特殊情况下的使用说明。 8：管理员命令。这部分专门为系统管理员设计，包含如 shutdown 和 useradd 等命令的文档。 9：其他与 Linux 特定相关的内容，主要包含内核例行程序文档。 举个例子，使用命令 man 1 ls 你能迅速取得关于 ls 命令的全面指导，而输入 man 5 passwd 则能了解 passwd 配置文件的详细内容。 请注意，并非所有命令或主题都与每个数字对应某个帮助页面。了解这些细分区域可以帮助你更高效地查找信息，并利用 Linux 系统的强大功能。","categories":["1.语言","C语言"]},{"title":"stat函数_获取文件信息","path":"/2024/12/18/1-语言-C语言-stat函数-获取文件信息/","content":"Linux stat 函数详解表头文件在使用 stat 函数之前，需要包含以下头文件： #include sys/stat.h#include unistd.h 定义函数stat 函数的基本原型如下： int stat(const char *file_name, struct stat *buf); 函数说明stat 函数用于获取指定文件（通过 file_name 参数给出）的详细信息，并将获取到的信息保存在 buf 指向的 struct stat 结构体中。这一结构体包含了文件的多种属性，例如大小、权限和时间戳等。 示例以下是一个使用 stat 函数的简单示例： #include sys/stat.h#include unistd.h#include stdio.hint main() struct stat buf; if (stat(/etc/hosts, buf) == 0) printf(/etc/hosts file size = %lld , (long long)buf.st_size); else perror(stat failed); 在这个示例中，程序尝试获取 /etc/hosts 文件的信息。如果成功，将打印出文件的大小；如果失败，则输出错误信息。 返回值 成功时：stat 函数返回 0。 失败时：返回 -1，并且错误信息存储在 errno 中。 错误代码以下是 stat 函数可能返回的一些错误代码，及其含义： ENOENT：指定的 file_name 不存在。 ENOTDIR：路径中的某个部分存在，但不是一个目录。 ELOOP：由于过多的符号链接而导致的循环问题，通常上限为 16。 EFAULT：buf 为无效指针，指向无法访问的内存空间。 EACCESS：尝试访问文件时被拒绝。 ENOMEM：内存不足。 ENAMETOOLONG：指定的路径名称过长。 struct stat 结构体struct stat 是用于存储文件信息的结构体，包含以下成员： struct stat dev_t st_dev; // 文件所在设备的编号 ino_t st_ino; // 文件的节点号 mode_t st_mode; // 文件类型和访问权限 nlink_t st_nlink; // 连接到该文件的硬连接数 uid_t st_uid; // 文件所有者的用户ID gid_t st_gid; // 文件所有者的组ID dev_t st_rdev; // 设备类型（若该文件为设备文件） off_t st_size; // 文件的字节数（即文件大小） unsigned long st_blksize; // 块大小（文件系统的 I/O 缓冲区大小） unsigned long st_blocks; // 文件占用的块数 time_t st_atime; // 最后访问时间 time_t st_mtime; // 最后修改时间 time_t st_ctime; // 状态最后改变时间（包括属性更改）; 文件类型和权限的定义st_mode 字段中定义了一系列不同的文件类型和权限，如下： S_IFMT 0170000：文件类型的位遮罩 S_IFSOCK 0140000：套接字 S_IFLNK 0120000：符号链接 S_IFREG 0100000：普通文件 S_IFBLK 0060000：区块设备 S_IFDIR 0040000：目录 S_IFCHR 0020000：字符设备 S_IFIFO 0010000：先进先出 S_ISUID 04000：文件的 set user-id on execution 位 S_ISGID 02000：文件的 set group-id on execution 位 S_ISVTX 01000：文件的 sticky 位 S_IRUSR (S_IREAD) 00400：所有者可读 S_IWUSR (S_IWRITE) 00200：所有者可写 S_IXUSR (S_IEXEC) 00100：所有者可执行 S_IRGRP 00040：用户组可读 S_IWGRP 00020：用户组可写 S_IXGRP 00010：用户组可执行 S_IROTH 00004：其他用户可读 S_IWOTH 00002：其他用户可写 S_IXOTH 00001：其他用户可执行 在 POSIX 中定义了检查这些类型的宏： S_ISLNK(st_mode)：判断是否为符号链接 S_ISREG(st_mode)：判断是否为普通文件 S_ISDIR(st_mode)：判断是否为目录 S_ISCHR(st_mode)：判断是否为字符设备文件 S_ISBLK(st_mode)：判断是否为区块设备 S_ISSOCK(st_mode)：判断是否为套接字 在一个目录上设置了 sticky 位（由 S_ISVTX 表示）时，该目录下的文件只能被文件所有者、目录所有者 或 root 用户删除或重命名。 struct statfs 结构体除了获取文件信息，statfs 函数也可以获取文件系统的信息，通过以下结构体定义： struct statfs long f_type; // 文件系统类型 long f_bsize; // 块大小 long f_blocks; // 总块数 long f_bfree; // 空闲块数 long f_bavail; // 可用块数 long f_files; // 文件节点总数 long f_ffree; // 空闲文件节点数 fsid_t f_fsid; // 文件系统 ID long f_namelen; // 文件名最大长度 long f_spare[6]; // 备用字段; stat、fstat 和 lstat 函数在 UNIX 中有三个相关函数，分别为 stat、fstat 和 lstat。 int stat(const char *restrict pathname, struct stat *restrict buf); 提供文件名，获取文件的属性。一般用于文件尚未打开时的情况。 int fstat(int filedes, struct stat *buf); 通过文件描述符获取文件的属性。适用于文件已经打开的情况。 int lstat(const char *restrict pathname, struct stat *restrict buf); 获取文件属性，涉及到符号连接(directory symlink)时，返回的是符号连接本身的信息，而不是连接的目标文件的信息。 函数返回值这三个函数的返回值一致：成功则返回 0，出错则返回 -1。 赋予一个 pathname，stat 函数会返回关于这个文件的信息，fstat 适用于已经在文件描述符 filedes 上打开的文件，lstat 则专门处理符号连接，并返回符号连接的信息。 struct stat 结构体中成员的详细说明每个成员都提供了关于文件属性的重要数据： st_mode：文件类型和权限，表示文件的种类（如目录或文件）以及访问控制。 st_ino：唯一的节点编号，用于在文件系统中标识文件。 st_rdev：设备编号，专门针对字符和块设备。 st_nlink：表示和该文件相关的硬链接数量。 st_uid 和 st_gid：文件所有者的用户 ID 和组 ID，对于权限控制非常重要。 st_size：普通文件的字节数。 st_atime：最后一次访问该文件的时间，这对了解文件使用情况很关键。 st_mtime：文件内容最后一次被修改的时间。 st_ctime：文件状态变化的时间，包括元数据的修改。 st_blksize：文件系统实现针对文件的最佳块大小。 st_blocks：已分配给该文件的 512 字节块的数量。 通过这些函数和结构体，用户可以方便地获取文件的全方位信息，管理和操作文件，也因而在 UNIXLinux 系统中 stat 函数是不可或缺的工具。","categories":["1.语言","C语言"]},{"title":"字符串相关函数","path":"/2024/12/18/1-语言-C语言-字符串相关函数/","content":"putsputs 函数是 gets 函数的输出版本，主要用于将指定的字符串写入标准输出。此函数不仅将字符串打印到屏幕上，还在字符串末尾自动添加一个换行符。这使得每次调用 puts 后，输出都会开始于新的一行，增加了输出的可读性。例如，调用 puts(Hello, World!); 将在控制台上显示： Hello, World! getchar/*丢弃该行中包含最后一个数字的那部分内容*/while((ch = getchar()) != EOF ch != ) 当 scanf 函数处理输入值时，它只会读取实际需要的字符，留下该行最后部分未读取的字符。这些字符可能是单独的换行符，或者是其他意外输入内容。无论如何，while 循环将读取这些剩余字符并将其丢弃，从而防止它们被误解为有效数据。我们可以分析以下表达式： (ch = getchar()) != EOF ch != 在这个表达式中，getchar 函数从标准输入读取一个字符并返回它的值。如果输入流到达文件的结束（EOF），该函数就会返回一个标志常量（EOF），以指示结束。值得注意的是，返回的值被赋给变量 ch，接着通过逻辑运算符进行比较。使用括号确保赋值操作在比较前执行，避免逻辑上的错误。如果 ch 的值是 EOF，整个表达式的结果变为假，循环随之终止。反之，如果 ch 是换行符，循环也会停止。只有在输入仍然可用且未遇到换行符时，循环才会继续执行。这样，这个循环可以有效去除当前输入行的最后部分。 与其他编程语言的写法相比，下面这种写法更为简洁和易读： ch = getchar();while(ch != EOF ch != ) ch = getchar(); 这个结构首先读取一个字符，若未到达输入的末尾且该字符不是换行符，则会继续读取下一个字符，直到满足退出条件。 getsgets 函数负责从标准输入读取一行文本，并将其存储在传递给它的字符数组中。整行输入由一串字符组成，最后以换行符结束。此函数在存储完成后会丢弃换行符，并在字符数组的末尾加上一个空字符（NUL 字节），用于表明字符串的结束。例如，通过调用 gets(myString);，会把用户输入的一行文本读入 myString，并在末尾添加 \\0。如果输入行无效（例如用户直接按下回车），gets 将返回 NULL，指示已到达输入的末尾（EOF）。 strchrstrchr 是一个用于在字符串中查找字符的函数。它接受两个参数：第一个参数是要搜索的字符串，第二个参数是需要查找的单个字符。这个函数会在字符串中寻找该字符第一次出现的位置。如果找到字符，则返回指向其位置的指针；如果未找到，则返回 NULL。例如，调用 strchr(Hello, World!, W); 会返回指向字符 ‘W’ 的指针。 strstr 函数与 strchr 类似，但其第二个参数是一个字符串而非单个字符。strstr 会搜索这些字符组成的字符串在第一个字符串中第一次出现的位置，这对于查找子串来说非常有用。 strcpystrcpy 和 strncpy 函数用于将字符串从一个位置复制到另一个位置。这两个函数都会返回一个指向目标字符串的指针，其中 strcpy 将会复制整个源字符串，包括终止的 NUL 字节；而 strncpy 允许用户指定要复制的最大字符数，以更好地控制内存使用。例如，调用 strcpy(destination, source); 将会将 source 字符串复制到 destination 中，确保 destination 是足够大的以容纳这段文本。","categories":["1.语言","C语言"]},{"title":"Shell基础","path":"/2024/12/18/1-语言-Shell-Shell基础/","content":"变量定义Shell 支持自定义变量，不区分数据类型,全部识别为字符串 定义变量时，命名符合标识符规定，变量名不加 $ 符号 varName=value 注意变量名和等号之间不能有空格，同时变量名的命令遵循以下规则 首个字符必须为字母 中间不能有空格，支持下划线 不能使用标点符号，不能使用 bash 里的关键字 使用使用一个定义过的变量，只要在变量名前面加 $ 符号即可 echo $varNameecho $varName //帮助进行边界识别 变量名外的花括号时可选的，可以用于帮助解释器识别变量，比如下面这种情况 for skill in Adado\techo i am good at $skillScriptdone 如果不给 skill 变量加{}，解释器会把 $skillScript 当成一个变量 重新定义已定义的变量可以被重新定义 myUrl=http://see.xidian.edu.cn/cpp/linux/echo $myUrlmyUrl=http://see.xidian.edu.cn/cpp/shell/echo $myUrl 第二次赋值的时候不能写 $myUrl=http://see.xidian.edu.cn/cpp/shell/，只有使用变量时才加 $ 符号 只读变量使用 readonly 可以将变量定义为只读变变量，只读变量的值不能被改变 #!/bin/bashmyUrl=http://see.xidian.edu.cn/cpp/shell/readonly myUrlmyUrl=http://see.xidian.edu.cn/cpp/danpianji/ 运行脚本，会报如下错误： /bin/sh: NAME: This variable is read only. 删除变量使用 unset 可以删除变量，unset 不能删除只读变量 unset 变量名set 显示本地的所有变量 变量类型位置变量接收用户参数 $0 表示当前脚本名称 $1 表示接收的第一个命令行参数 $2 表示第二个命令行参数，以此类推 $# 参数的个数$? 命令执行结果,函数返回结果,$$ 进程id$1,$2..$9,$10, $11$@ $* $* 当做整体处理 环境变量 (全局可以访问的变量)脚本中定义的变量只在本脚本有效 envexport 变量名 //将局部变量变为全局变量 特殊变量 $0 当前脚本的文件名 $n 传递给脚本或函数的参数，$1,$2 $# 传递给脚本或函数的参数个数 $* 传递给脚本或函数的所有参数 $@ $? 上个命令的退出状态或函数的返回值 $$ 当前 shell 进程 ID $* 和 $@ 的区别 #!/bin/bashecho \\$*= $*echo \\\\$*\\=$*echo \\$@= $@echo \\\\$@\\=$@echo print each param from \\$*for var in $*do\techo $vardoneecho print each param from \\$@for var in $@do\techo $vardoneecho print each param from \\\\$*\\for var in $*do\techo $vardoneecho print each param from \\\\$@\\for var in $@do\techo $vardone 运行 .test.sh “a” “b” “c” “d”，看到下面的结果： $*= a b c d$*= a b c d$@= a b c d$@= a b c dprint each param from $*abcdprint each param from $@abcdprint each param from $*a b c dprint each param from $@abcd 替换，运算符，字符串，数组替换如果表达式中包含特殊字符，Shell 将会进行替换。例如，在双引号中使用变量就是一种替换，转义字符也是一种替换。 #!/bin/basha=10echo -e Value of a is $a 这里 -e 表示对转义字符进行替换。如果不使用 -e 选项，将会原样输出 Value of a is 10 命令替换命令替换是将一个命令的输出作为另一个命令的参数。命令格式如下所示。 command1 `command2` 其中，命令 command2 的输出将作为命令 command1 的参数。 ls `pwd` //这里是反引号,和~是同一个按键 pwd 命令用于显示当前目录的绝对路径。在上面的命令行中，使用命令置换符，将 pwd 的运行结果作为 ls 命令的参数。最终，命令执行结果是显示当前目录的文件内容。 需要注意命令置换和管道 pipe 的区别 变量替换变量替换可以根据变量的状态（是否为空、是否定义等）来改变它的值可以使用的变量替换形式 形式 说明 ${var} 变量本来的值 ${var:-word} 如果变量 var 为空或已被删除 (unset)，那么返回 word，但不改变 var 的值。 ${var:word} 如果变量 var 为空或已被删除(unset)，那么返回word，并将 var 的值设置为 word。 ${var:?message} 如果变量 var 为空或已被删除 (unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值。若此替换出现在 Shell 脚本中，那么脚本将停止运行。 ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值。 运算符Bash 支持很多运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符算数运算符awk 和 expr，expr #!/bin/bashval=`expr 2 + 2`echo value : $valval=`expr 2 \\* 2`echo value : $val 输出 value : 4 value : 4 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边 乘号 * 前边必须加反斜杠 \\ 才能实现乘法运算 `+``-``*``/``%`取余`=`赋值`==`相等`!=`不等 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字-eq 相等-ne 不等-gt 左侧大于右侧，返回 true-lt 小于-ge 大于等于-le 小于等于布尔运算符! 非-a 与-o 或字符串运算符 [ -z $String ] echo $? `=` 检测两个字符串是否相等，相等返回 true。`!=` 不等`-z` 检测字符串长度是否为0，为0返回 true`-n` 检测字符串长度是否为0，不为0返回 true`str` 检测字符串是否为空，不为空返回 true。 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性 [ -d /etc/fstab ] echo $? 操作符 作用 -b file 检测文件是否是块设备文件 -c file 检测文件是否是字符设备文件 -d file 检测文件是否是目录 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件） -g file 检测文件是否设置了 SGID 位 -k file 检测文件是否设置了粘着位 (Sticky Bit) -p file 检测文件是否是具名管道 -u file 检测文件是否设置了 SUID 位 -r file 检测文件是否可读 -w file 检测文件是否可写 -x file 检测文件是否可执行 -s file 检测文件是否为空（文件大小是否大于 0） -e file 检测文件（包括目录）是否存在 字符串字符串可以用单引号，也可以用双引号，也可以不用引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号里可以有变量 双引号里可以出现转义字符 数组bash 支持一维数组（不支持多维数组），并且没有限定数组的大小。类似与 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组 在 Shell 中，用括号来表示数组，数组元素用“空格”符号分割开。定义数组的一般形式为： array_name=(value1 ... valuen) 还可以单独定义数组的各个分量： array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组读取数组元素值的一般格式是： $array_name[index] 使用 @ 或 * 可以获取数组中的所有元素 $array_name[*]$array_name[@] 获取数组长度或取数组长度的方法与获取字符串长度的方法相同，例如： # 取得数组元素的个数length=$#array_name[@]# 或者length=$#array_name[*]# 取得数组单个元素的长度lengthn=$#array_name[n] 逻辑语句功能语句read 是用来读取用户输入信息的命令，能够把接收到的用户输入信息赋值给后面的指定变量，-p 参数用于向用户显示一定的提示信息。 操作符 作用 -p “ 提示内容 “ -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 read -n 5 AA BB CCread AA BB CChello xiaoming, mingtian you kongread -p Enter your score（0-100）： GRADE 判断语句判断语句格式： [ 条件表达式 ] 对应两边应均有一个空格 逻辑测试语句： 与 (当前面的命令执行成功后才会执行它后面的命令) 或（当前面的命令执行失败后才会执行它后面的命令） ！ 非（把条件测试中的判断结果取相反值） 得到当前内存剩余量： FreeMem=`free -m | grep Mem: | awk print $4`[ $FreeMem -lt 1024 ] echo Insufficient Memory break 语句break 命令允许跳出所有循环（终止执行后面的所有循环）。在嵌套循环中，break 命令后面还可以跟一个整数，表示跳出第几层循环。例如： break n //表示跳出第 n 层循环。 continue 语句continue 命令与 break 命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。同样，continue 后面也可以跟一个数字，表示跳出第几层循环。 结构语句case casecase var in1)...;;2|3|4)...;;esac case 工作方式如上所示。取值后面必须为关键字 in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。;; 与其他语言中的 break 类似，意思是跳到整个 case 语句的最后。 demo: #!/bin/bashread -p 请输入一个字符，并按Enter键确认： KEYcase $KEY in[a-z]|[A-Z]) echo 您输入的是 字母。 ;;[0-9]) echo 您输入的是 数字。 ;;*) echo 您输入的是 空格、功能键或其他控制字符。esac 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 if if [ ] thenelsefiif [ ] thenelif [ ] thenelsefi demo: #!/bin/bashread -p Enter The Users Password : PASSWDfor UNAME in `cat users.txt`doid $UNAME /dev/null （就是和2这两个的结合体）if [ $? -eq 0 ] then echo Already existselse useradd $UNAME /dev/null echo $PASSWD | passwd --stdin $UNAME /dev/null if [ $? -eq 0 ] then echo $UNAME , Create success else echo $UNAME , Create failure fifidone 循环语句for for 变量 in 列表do..donefor ((i=0; iN; i++))dodonefor var in `ls`for var in $(ls)for var #列表的内容是位置参数变量时，可以省略in ... 列表是一组值（数字、字符串等）组成的序列，每个值通过空格分隔。每循环一次，就将列表中的下一个值赋给变量。 demo: HLIST=`echo www.baidu.com`for IP in $HLISTdo ping -c 3 -i 0.2 -W 3 $IP /dev/nullif [ $? -eq 0 ] then echo baidu is onlineelse echo baidu is offlinefidone while while 表达式do..donewhile (($i $loop))do...done while 循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。 demo: PRICE=$(expr $RANDOM % 1000)TIMES=0echo 商品实际价格为0-999之间，猜猜看是多少？while truedo read -p 请输入您猜测的价格数目： INT let TIMES++ if [ $INT -eq $PRICE ] ; then echo 恭喜您答对了，实际价格是 $PRICE echo 您总共猜测了 $TIMES 次 exit 0 elif [ $INT -gt $PRICE] ; then echo 太高了！ else echo 太低了！ fidone untilluntil 循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。一般 while 循环优于 until 循环。 a=0until [ ! $a -lt 10 ]doecho $aa=`expr $a + 1`done 函数函数定义 function_name () list of commands [ return value ]function function_name () list of commands [ return value ] 如果你希望直接从终端调用函数，可以将函数定义在主目录下的 .profile 文件，这样每次登录后，在命令提示符后面输入函数名字就可以立即调用。返回值函数返回值，可以显式增加 return 语句；如果不加，会将最后一条命令运行结果作为返回值。接收函数返回值用 $?。Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0 表示成功，其他值表示失败。（返回值范围 0-255）如果 return 其他数据，比如一个字符串，往往会得到错误提示：“numeric argument required”。如果一定要让函数返回字符串，那么可以先定义一个变量，用来接收函数的计算结果，脚本在需要的时候访问这个变量来获得函数返回值。调用调用函数只需要给出函数名，不需要加括号。 Hello() echo hello, worldHelloHello2() echo hello2, worldreturn 1Hello2ret=$? 输出给了变量 var=$(Hello2) 删除像删除变量一样，删除函数也可以使用 unset 命令，不过要加上 .f 选项，如下所示： unset .f function_name 参数在 Shell 中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1 表示第一个参数，$2 表示第二个参数 获取第十个参数需要 $10。当 n10 时，需要使用 $n 来获取参数。 $# 传递给函数的参数个数。 $* 显示所有传递给函数的参数。 $@ 与 $* 相同，但是略有区别 $? 函数的返回值。 传参: function add_fun () add_fun str1 str2 str3 文件包含Shell 也可以包含外部脚本，将外部脚本的内容合并到当前脚本。 . filenamesource filename 两种方式的效果相同，简单起见，一般使用点号 (.)，但是注意点号 (.) 和文件名中间有一空格 被包含脚本不需要有执行权限","categories":["1.语言","Shell"]},{"title":"Shell任务","path":"/2024/12/18/1-语言-Shell-Shell任务/","content":"计划任务服务程序一次性计划任务“at 时间”是一个命令行工具，用于在指定的时间执行一次性任务。 通过使用该命令，您可以安排计划在将来的某个时间运行的命令或脚本。 时间参数可以采用多种格式，如 HH:MM，HH:MM AMPM 或者明天的日期。 例如，以下命令将在下午 2 点运行一个脚本： at 2pm 脚本路径 查看计划任务“at -l”命令用于列出当前计划的 at 任务列表，显示已经被安排的任务及其相关信息，如任务序号、执行时间等。 例如，以下命令将列出当前计划的 at 任务列表： at -l 取消计划任务“atrm 任务序号”命令用于取消一个已经计划的 at 任务，其中任务序号是通过”at -l”命令列出的任务的序号。 例如，以下命令将取消任务序号为 1 的 at 任务： atrm 1 长期性计划任务crontab -e 创建、编辑计划任务 crontab -l 查看当前计划任务 crontab -r 删除某条计划任务 crontab -u 编辑他人的计划任务 demo: crontab -e crontab -l25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar /home/wwwroot whereis rm 时间周期设置：25 3 * * 1,3,5 依次对应 分钟，小时，日期，月份，星期 任务内容:要运行的命令 /usr/bin/tar -czvf backup.tar /home/wwwroot","categories":["1.语言","Shell"]},{"title":"Shell环境变量","path":"/2024/12/18/1-语言-Shell-Shell环境变量/","content":"环境变量在操作系统中扮演着极为重要的角色，它们指定了系统的运行环境，包括一些基本的参数，如临时文件夹位置和系统文件夹位置等。下面将更详细地探讨 Linux 的环境变量，涵盖变量的种类、设置方法及常用环境变量的示例。 一、Linux 的变量种类根据变量的生存周期，Linux 变量可以大致分为两类： 永久变量：这些变量需要在系统的配置文件中进行修改。一旦更改，它们会对未来的所有会话有效。 临时变量：这些变量使用 export 命令声明后，仅在当前的 shell 会话中有效。一旦关闭 shell，此变量便失效。 二、设置变量的三种方法 在 /etc/profile 文件中添加变量【对所有用户生效（永久的）】使用文本编辑器（如 VI）编辑 /etc/profile 文件，可以将变量添加到所有用户的环境中。例如，想要添加一个新的路径到 PATH 变量中，你可以这样做： # vi /etc/profile 在文件中添加以下行： export PATH=/home/fs:$PATH 注：修改完文件后，记得执行 source /etc/profile 命令，使更改立即生效，否则将在下次重新登录时才会生效。 在用户目录下的 .bash_profile 文件中增加变量【对单一用户生效（永久的）】每个用户都有自己的配置文件，通常名为 .bash_profile。修改这一文件也可以实现变量的持久化。例如，对用户 guok 的 .bash_profile 文件进行修改： # vi /home/guok/.bash_profile 添加如下内容以设置 CLASSPATH： export CLASSPATH=./JAVA_HOME/lib:$JAVA_HOME/jre/lib 注：同样地，修改后需要运行 source /home/guok/.bash_profile 以快速应用更改。 直接运行 export 命令定义变量【只对当前 shell（BASH）有效（临时的）】如果你在命令行运行 export 命令，可以设置一个仅在当前会话内有效的变量，例如： export TEMP_VAR=Temporary Value 这个变量在当前的 shell 被关闭后将失效。如果重新打开一个 shell，你需要再次设定该变量。 三、PATH 声明PATH 环境变量是系统查找可执行文件时的重要参数。它的格式为：PATH=$PATH:your_custom_path，其中你可以添加自己的路径，并用冒号 : 进行隔开。为了使路径更改立即生效，可以执行： source ~/.bash_profile 需要特别注意的是，将当前路径 ./ 添加到 PATH 中可能会引起安全问题，容易受到意想不到的攻击。完成设置后，可以使用以下命令查看当前的 PATH： echo $PATH 这样可以确保你能够迅速访问位于 PATH 中目录的程序，避免每次都输入完整路径。 四、常用的环境变量 变量名 内容 PATH 指定 shell 查找命令或程序的目录 HOME 当前用户的主目录 HISTSIZE 记录的历史命令数 LOGNAME 当前用户的登录名 HOSTNAME 主机的名称 SHELL 当前用户使用的 shell 类型 LANGUAGE 语言相关的环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符（root 用户为 #，普通用户为 $） 五、常用的环境变量相关命令 显示环境变量 HOME fs@ubuntu:~$ echo $HOME/home/fs 设置一个新的环境变量 HELLO fs@ubuntu:~$ export HELLO=Hellofs@ubuntu:~$ echo $HELLOHello 使用 env 命令显示所有环境变量 fs@ubuntu:~$ envSSH_AGENT_PID=2427GPG_AGENT_INFO=/tmp/keyring-Sqfg93/gpg:0:1...HELLO=Hello... 使用 set 命令显示所有本地定义的 shell 变量 fs@ubuntu:~$ setBASH=/bin/bashBASH_VERSION=2.05b.0(1)-release... 使用 unset 命令来清除环境变量 fs@ubuntu:~$ export TEST=Test # 增加一个环境变量 TESTfs@ubuntu:~$ env | grep TEST # 验证环境变量 TEST 是否存在TEST=Testfs@ubuntu:~$ unset TEST # 删除环境变量 TESTfs@ubuntu:~$ env | grep TEST # 确认变量已被删除 使用 readonly 命令设置只读变量 fs@ubuntu:~$ export TEST=Test # 增加环境变量 TESTfs@ubuntu:~$ readonly TEST # 将 TEST 设为只读fs@ubuntu:~$ unset TEST # 尝试删除只读变量# 输出将显示不可删除的错误信息 通过这些操作，用户可以清晰地管理和设置环境变量，从而定制 Linux 系统的行为和性能，以适应不同的需求和工作环境。","categories":["1.语言","Shell"]},{"title":"Shell和终端和控制台的区别","path":"/2024/12/18/1-语言-Shell-Shell和终端和控制台的区别/","content":"shell、控制台、终端的区别终端(terminal，或者叫物理终端）：是一种设备，不是一个程序，一般说的就是能提供命令行用户界面的设备，典型的是屏幕和键盘，或其他的一些物理终端。 虚拟终端：屏幕和键盘只是一个终端，可能不够用，又不想增加设备投入，就产生了虚拟终端。 gnome-terminal,urxvt，mlterm，xterm 等等是一个程序，职责是模拟终端设备，和虚拟终端的区别表面上在于它以 GUI 形式的窗口出现，内部则是程序结构和系统控制结构有所不同，但本质上差不多。 控制台（console):显示系统消息的终端就叫控制台，Linux 默认所有虚拟终端都是控制台，都能显示系统消息。 但有时专指 CLI 下的模拟终端设备的一个程序，和 gnome-terminal,urxvt，mlterm，xterm 等相同，只是 CLI 和 GUI 界面的区别。 一般 console 有 6 个，tty1-6，CTRL+ALT+f1~6 切换。 shell：shell 是一个抽象概念，shell 的一切操作都在计算机内部，负责处理人机交互，执行脚本等，是操作系统能正常运行的重要组成部分,bash，ash，zsh，tcsh 等是 shell 这个抽象概念的一种具体的实现，都是一个程序，都能生成一个进程对象 如果想换 shell 的程序，可以修改etcpasswd，把里面的binbash 换成你想要的 shell，或者用 chsh 命令来切换 终端和 Shellshell 与终端的关系：shell 把一些信息适当的输送到终端设备，同时还接收来自终端设备的输入。一般每个 shell 进程都会有一个终端关联，也可以没有。 字符程序 — 虚拟终端 — 图像显示 shell — xterm — X11 终端和控制台终端，英文叫做 terminal ,通常简称为 term ，比如我们在 X 下的 xterm. 控制台，英文叫做 console。 要明白这两者的关系，还得从以前的多人使用的计算机开始。 大家都知道，最初的计算机由于价格昂贵，因此，一台计算机一般是由多个人同时使用的。 在这种情况下一台计算机需要连接上许多套键盘和显示器来供多个人 使用。 在以前专门有这种可以连上一台电脑的设备，只有显示器和键盘，还有简单的处理电路，本身不具有处理计算机信息的能力，他是负责连接到一台正常的计算 机上（通常是通过串口） ，然后登陆计算机，并对该计算机进行操作。 当然，那时候的计算机操作系统都是多任务多用户的操作系统。 这样一台只有显示器和键盘能够通过串口连接到计算机 的设备就叫做终端。 而控制台又是什么回事呢？ 学机电的人应该知道，一台机床，或者数控设备的控制箱，通常会被称为控制台，顾名思义，控制台就是一个直接控制设备的台面（一个面板，上面有很多控制按 钮）。 在计算机里，把那套直接连接在电脑上的键盘和显示器就叫做控制台。 请注意它和终端的区别，终端是通过串口连接上的，不是计算机本身就有的设备，而控制台是 计算机本身就有的设备，一个计算机只有一个控制台。 计算机启动的时候，所有的信息都会显示到控制台上，而不会显示到终端上。 也就是说，控制台是计算机的基 本设备，而终端是附加设备。 当然，由于控制台也有终端一样的功能，控制台有时候也被模糊的统称为终端。 计算机操作系统中，与终端不相关的信息，比如内核消息，后台服务消息，都可以显示到控制台上，但不会显示到终端上。 以上是控制台和终端的历史遗留区别。 现在由于计算机硬件越来越便宜，通常都是一个人独占一台计算机超做，不再连接以前那种真正意义上的“终端设备了”，因此，终端和控制台的概念也慢慢演化了。 终端和控制台由硬件的概念，演化成了软件的概念。 现在说的终端，比如 linux 中的虚拟终端，都是软件的概念，他用计算机的软件来模拟以前硬件的方式。 比如在 linux 中，你用 alt+f1 ~ f6 可以切换六个虚拟终端，就好比是以前多人公用的计算机中的六个终端设备，这就是为什么这个叫“虚拟终端”的原因。 当然，现在的 linux 也可以通过串口 线，连接一个真正的终端，现在这种终端设备已经非常罕见了，但是还存在，只是一般人很难见到。 也有人利用以前的老电脑（386，486）装上一个串口通信 软件，连上一台计算机，来模拟一个终端来用。这样可以达到一台电脑多人使用的目的。 简单的说，能直接显示系统消息的那个终端称为控制台，其他的则称为终端。 但是在 linux 系统中，这个概念也已经模糊化了。 比如下面这条命令： echo hello,world /dev/console 这条命令的目的是将”hello,world”显示到控制台上devconsole 是控制台设备的设备名。 在 linux 中，在字符模式下，你无论在哪个虚拟终端下执行这条命令，字符 hello,world 都会显示在当前的虚拟终端下。 也就是说，linux 把当前的终端当作控制台来看待。 可见，linux 中已经完全淡化了控制台和终端的区别。 但是在其他的 UNIX 类系统中，却很明显的有虚拟终端和控制台的区别。比如 freeBSD 系统。 在 freebsd 中，只有第一个“终端”才是真正的控制台。 （就是说按 alt+f1 得到的那个虚拟终端），你无论在哪个虚拟终端上执行上面的那条命令（哪怕是通过网络连接的伪终端上执行这条命令）。 hello,world 字符总会显示到第一个“终端”也就是 真正的控制台上。 另外，其他的一些系统内部信息，比如哪个用户在哪个终端登陆，系统有何严重错误警告等信息，全都显示在这个真正的控制台上。 在这里，就明 显的区分了终端和控制台的概念。其他 UNIX 中也是这样的。 比如 Tru64 unix 在 X 下有一个控制台模拟软件，你无论在哪里输入 echo “hello,world” devconsole 命令，hello,world 总会显示在这个控制台模拟器中。 我们在 X 界面下用的那些输入命令的软件，比如 xterm ,rxvt, gnome-terminal 等等，都应该被称为终端模拟软件。 请注意它和控制台模拟软件的区别。 linux 中好象没有控制台模拟软件。 在 X 中的终端模拟 软件中输入的 echo “hello,world”devconsole 命令的输出信息，都会输出到启动该 X 服务器的虚拟终端上。 比如，你用字符方式登陆系统。 进入第一个虚拟终端，然后 startx 启动 X 服务器。 再打开 xterm 来输入 echo “hello,world”devconsole 命令，那么字符串 hello,world 就显示在第一个虚拟终端上。 你按 ctrl+alt+f1，回到那个启动 X 服务器的终端，就可以看到 hello, world 字符串。 现在该明白终端和控制台的区别了吧。 再简单的说，控制台是直接和计算机相连接的原生设备，终端是通过电缆、网络等等和主机连接的设备。 在以前的硬件终端设备中，由于生产厂家不同，所遵循的标准不同，因此有不同的型号标准。 比如 vt100 等。这里的 vt100 就是一个标准，那么现在我 们所说的终端，往往不是真正的硬件终端了，而是终端模拟软件了，因此不同的终端模拟软件可能符合不同的标准，还有一些终端模拟软件符合很多种不同终端的标 准。 比如 gnome 的终端模拟软件 gnome-terminal，他提供好几中标准可供用户选择。 用户只要设置一下就可以了。 现在，由于原先的这些设备在我们的视线中渐渐淡出，控制台和终端的概念也慢慢谈化。 普通用户可以简单的把终端和控制台理解为：可以输入命令行并显示程序运行过程中的信息以及程序运行结果的窗口。 不必要严格区分这两者的差别。","categories":["1.语言","Shell"]},{"title":"Linux下C程序插入shell脚本","path":"/2024/12/18/1-语言-Shell-Linux下C程序插入shell脚本/","content":"linux 下 C 程序插入执行 shell 脚本最近在看深入理解计算机系统，看到一个函数叫做 execve()，这个函数很有意思，可以在一个进程插入另外一个进程执行，但是又不像 fork()一样产生一个子进程，execve()插入的进程和原进程共享进程号，就好像执行这进程就像执行过程调用一般随意。 函数原型如下： int execve(const char *filename, char *const argv[], char *const envp[]); EXAMPLE The following program is designed to be execed by the second program below. It just echoes its command-line one per line. * myecho.c * #include stdio.h#include stdlib.hintmain(int argc, char *argv[])\tint j;\tfor (j = 0; j argc; j++)\tprintf(argv[%d]: %s , j, argv[j]);\texit(EXIT_SUCCESS); This program can be used to exec the program named in its command-line argument: * execve.c * #include stdio.h#include stdlib.h#include unistd.hintmain(int argc, char *argv[])\tchar *newargv[] = NULL, hello, world, NULL ;\tchar *newenviron[] = NULL ;\tif (argc != 2) fprintf(stderr, Usage: %s file-to-exec , argv[0]); exit(EXIT_FAILURE); newargv[0] = argv[1];\texecve(argv[1], newargv, newenviron);\tperror(execve); /* execve() only returns on error */\texit(EXIT_FAILURE); We can use the second program to exec the first as follows: $ cc myecho.c -o myecho$ cc execve.c -o execve$ ./execve ./myechoargv[0]: ./myechoargv[1]: helloargv[2]: world 插入一个 shell 脚本执行：#include stdio.h#include stdlib.h#include unistd.hintmain(int argc, char *argv[])\tchar *newargv[] = /etc ;\tchar *newenviron[] = NULL ;\tif (argc != 2) fprintf(stderr, Usage: %s file-to-exec , argv[0]); exit(EXIT_FAILURE); newargv[0] = argv[1];\texecve(argv[1], newargv, newenviron);\tperror(execve); /* execve() only returns on error */\texit(EXIT_FAILURE); script.sh 如下： #!/bin/bashls 执行： ./execve ./script.sh 会在当前终端下输出所有的文件 yca@ubuntu:~/桌面/hello$ ./execve ./script.sh1 execve hello1 hello3 hello5 hello_lex1.txt execve.c hello1.c hello3.cpp hello5.c k_maxBubble hello hello1.o hello3.o hello5.o k_max.cBubble.c hello.c hello2.c hello3.s hello5.s lex.yy.cQuickSort.c hello.lex hello2.o hello4 hello5.s1 script.shQuicksort1.c hello.sh hello2.s hello4.c hello51.s","categories":["1.语言","Shell"]},{"title":"Python资料","path":"/2024/12/18/1-语言-Python-Python资料/","content":"0. GitHubGitHub 拥有丰富的开源项目，用户可以找到大量的 Python 库和工具，例如 Pipenv，它能有效地管理 Python 项目的依赖和虚拟环境。 1. Python Code ExamplesPython Code Examples 是一个极好的在线资源，提供多种 Python 代码示例。在这个网站上，学习者可以通过搜索具体的功能实现，找到相关的代码范例进行参考。在面对特定问题时，查找相关示例并进行模仿可以加速学习过程。例如，若你想实现字符串的排序，只需要输入“string sort”，就能找到众多相关的代码片段，从中学习和理解其用法。 2. Python 中文学习大本营Python中文学习大本营 是一个为中文用户提供 Python 学习资料的平台。在这里，你能找到丰富的 Flask 资源，包括书籍、视频教程和代码示例，几乎涵盖了学习 Flask 所需的所有内容。无论你是想快速上手构建 Web 应用，还是深入理解 Flask 的底层机制，都能在这个网站上找到合适的指南。 3. Python Module of the Week Python 3 Module of the Week Python Module of the Week 这个系列的文章致力于介绍 Python 的标准库，每一篇文章详细讲解一个模块的功能和使用方法。例如，collections 模块提供了多种特殊的容器数据类型，适合不同的数据存储需求，学习这些模块能帮助你更高效地使用 Python。 4. Welcome to Python for you and meWelcome to Python for you and me 是一个专为初学者设计的网站。它以简单易懂的方式介绍 Python 的基本语法、数据结构和项目经验。通过实例和练习，初学者可以逐步掌握 Python 的精髓，提升编程技能。 5. CheckiO is a code game codersCheckiO 是一个独特的学习平台，将编程与游戏结合在一起。用户在这个网站上可以通过解决一系列编程挑战来提升自己的技能。每个关卡都要求你编写代码来完成特定任务，这种互动学习方式不仅有趣，还能有效提高你的逻辑思维与编程能力。 6. Python 基础教程Python基础教程 是一个广为人知的学习平台，提供 Python 的基础知识。如果你完全没有编程经验，建议从这个网站开始。它涵盖了 Python 的基本语法、数据类型、控制结构等内容，并配有简单的例子和练习，帮助你打下坚实的基础。 学习资源 A Byte of Python: 该书提供 Python 的基本知识，边学习边实践的方式加深理解。 Google’s Python Lessons: Google 发布的 Python 教程，内容清晰，非常适合自学者。 Python Documentation: 官方在线文档，适合深入了解 Python 各个模块及其使用。 CS61A: SICP with Python: MIT 课程，结合 Python 深入探讨计算机科学的基本原理。 Python Guide：由 requests 的作者编写，尤其偏向软件工程方面的实践。 Use Python：提供一些更为实际的 Python 使用技巧和案例。 Python 核心编程：全面介绍 Python 语言的各个方面。 Dive Into Python：一本开源的优质书籍。 Fluent Python：深入探讨 Python 的高级主题。 Python3 Cookbook：收集了众多 Python 编程技巧。 Python 核心编程 Python 网络数据采集 利用 Python 进行数据分析","categories":["1.语言","Python"]},{"title":"公众号消息推送","path":"/2024/12/18/0-平台-服务器-微信-公众号消息推送/","content":"步骤 1：注册微信公众号测试号注册微信公众号的第一步是访问 微信公众号平台的测试号申请页面。在这里，你将能够创建一个测试号，以便进行开发和测试。 步骤 2：获取 appID 和 appsecret一旦成功注册，你将能够在微信公众号平台的后台查看到相关的 appID 和 appsecret。这两个值是你调用微信公众号接口的凭证，确保妥善保存。 步骤 3：获取 access_tokenaccess_token 是公众号调用各类接口的重要凭证，它的有效期为 2 小时。要最大化利用这个凭证，你需要时刻监控它的有效期，并在过期后及时获取。特别注意的是，你每天最多可获取 2000 次 access_token。 API 调用：获取 access_token 的接口如下： GET https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=APPIDsecret=APPSECRET 步骤 4：获取粉丝的 openidopenid 是关注你公众号的用户的唯一标识。例如，如果你想给某位粉丝发送消息，首先要通过接口获取他们的 openid。这可以通过以下方法调用： GET https://api.weixin.qq.com/cgi-bin/user/get?access_token=ACCESS_TOKENnext_openid=NEXT_OPENID 步骤 5：发送消息发送消息的接口如下： POST https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=ACCESS_TOKEN 下面是使用 “客服消息” 接口发送消息的代码示例。 # -*- encoding:utf-8 -*-import requestsimport jsonclass SendMessage(): def __init__(self): self.appID = xxxx self.appsecret = xxxx self.access_token = self.get_access_token() self.opend_ids = self.get_openid() def get_access_token(self): 获取微信公众号的access_token值 url = https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=secret=.format(self.appID, self.appsecret) headers = User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 response = requests.get(url, headers=headers).json() access_token = response.get(access_token) return access_token def get_openid(self): 获取所有粉丝的openid next_openid = url_openid = https://api.weixin.qq.com/cgi-bin/user/get?access_token=%snext_openid=%s % (self.access_token, next_openid) ans = requests.get(url_openid) open_ids = json.loads(ans.content)[data][openid] return open_ids def sendmsg(self, msg): 给所有粉丝发送文本消息 url = https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=.format(self.access_token) if self.opend_ids: for open_id in self.opend_ids: body = touser: open_id, msgtype: text, text: content: msg data = bytes(json.dumps(body, ensure_ascii=False).encode(utf-8)) response = requests.post(url, data=data) result = response.json() print(result) else: print(当前没有用户关注该公众号！) def upload_media(self, media_type, media_path): 上传临时文件到微信服务器，并获取该文件的media_id url = https://api.weixin.qq.com/cgi-bin/media/upload?access_token=type=.format(self.access_token, media_type) meida = media: open(media_path, rb) response = requests.post(url, files=meida) parse_json = json.loads(response.content.decode()) return parse_json.get(media_id) def send_media_to_user(self, media_type, media_path): 给所有粉丝发送媒体文件，媒体文件以media_id表示 media_id = self.upload_media(media_type, media_path) url = https://api.weixin.qq.com/cgi-bin/message/custom/send?access_token=.format(self.access_token) if self.opend_ids: for open_id in self.opend_ids: if media_type == image: body = touser: open_id, msgtype: image, image: media_id: media_id elif media_type == voice: body = touser: open_id, msgtype: voice, voice: media_id: media_id data = bytes(json.dumps(body, ensure_ascii=False).encode(utf-8)) response = requests.post(url, data=data) result = response.json() print(result) else: print(当前没有用户关注该公众号！)if __name__ == __main__: data = Hello,3Nod! sends = SendMessage() sends.sendmsg(data) sends.send_media_to_user(image, ./test.png) 功能说明 获取 access_token: get_access_token 方法根据 appID 和 appsecret 查询并返回 access_token，确保接口调用的顺利进行。 获取粉丝的 openid: get_openid 方法获取当前所有粉丝的 openid，以便后续可以发送消息。 发送文本消息: sendmsg 方法接收消息内容，利用 access_token 和粉丝的 openid 发送指定的文本消息。 上传媒体: upload_media 方法用于上传临时文件（如图片、音频等），并返回其 media_id 以便后续发送。 发送媒体文件: send_media_to_user 根据文件类型（图像或语音）准备相应的消息体，并将文件发送给所有粉丝。 通过这些步骤，你能够有效地使用微信公众号的 API 实现与粉丝的互动，无论是发送简单的文本信息还是上传和分享多媒体内容。","categories":["0.平台","服务器","微信"]},{"title":"使用Python的flask框架对接微信公众号开发 1","path":"/2024/12/18/0-平台-服务器-微信-flask框架对接微信公众号/","content":"使用说明第一步：找一台具有公网 IP 的服务器首先，确保你有一台可以连接互联网并具有公网 IP 的服务器。这台服务器将用于部署 Flask 应用，并接收来自微信公众平台的请求。服务提供商如阿里云、腾讯云或 AWS 等都可以为你提供这样的服务器。 第二步：安装 Python3，搭建 nginx+uwsgi+flask 环境使用 SSH 连接到你的服务器后，执行以下命令来安装 Python3 及所需的软件： sudo apt updatesudo apt install python3 python3-pip nginxpip3 install flask uwsgi 安装完毕后，你需要配置 nginx 和 uwsgi，使得它们能够协同工作。 创建 uwsgi 配置文件。例如，命名为 myapp.ini： [uwsgi]module = wsgi:appmaster = trueprocesses = 5socket = myapp.sockchmod-socket = 660vacuum = truedie-on-term = true 在 nginx 中配置网站，编辑 /etc/nginx/sites-available/default，加入如下内容： server listen 80; server_name wechat_pro.lehuoha.com; location / include uwsgi_params; uwsgi_pass unix:/home/wechat_pro/myapp.sock; 完成以上步骤后，确保 nginx 和 uwsgi 服务都已经启动。 第三步：在 PyCharm 上配置 Deployment在 PyCharm 中，将本地代码直接上传到服务器： 新建项目在 PyCharm 中新建项目，命名为 wechat_pro。确保你的项目结构和将要在服务器上部署的一致。 设置 Deployment导航到 Tools - Deployment - Configuration，选择相应的连接方式，例如 FTP 或 SFTP。这里以 SFTP 为例： Connection Name: 开发测试服务器 Host: 输入你的公网 IP 地址 Username: 输入你的服务器登录名 Password: 输入你的密码 点击“测试链接”确认连接成功。 映射本地与服务器路径在配置中设置本地目录与服务器目录路径的映射，确保甚至更新文件时本地代码能够上传到服务器的指定目录，如 /home/wechat_pro/。 第四步：nginx 配置文件中设置域名，配置好域名解析确保你已经在域名服务提供商处配置好 DNS 解析，将 wechat_pro.lehuoha.com 指向你的服务器公网上的 IP 地址。接下来，使用以下配置更新 nginx： server listen 80; server_name wechat_pro.lehuoha.com; location / include uwsgi_params; uwsgi_pass unix:/home/wechat_pro/myapp.sock; 保存配置文件后，使用命令重启 nginx 服务： sudo systemctl restart nginx app.py 文件代码 (注意文件权限)接下来，在 /home/wechat_pro/ 目录下创建 app.py 文件，内容如下。请确保文件权限设置正确，以便 web 服务能够执行。 #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flaskapp = Flask(__name__)@app.route(/)def index(): return hello world！if __name__ == __main__: app.run(host=0.0.0.0, port=80, debug=True) 确保这个文件有执行权限： chmod +x /home/wechat_pro/app.py 通过访问 http://wechat_pro.lehuoha.com 你应该能看到“hello world！”的返回。 微信公众号开发对接在完成服务器配置后，进入微信公众平台官网，并登录到你的公众号管理界面： 设置接口配置信息在后台的“开发者中心”中点击“修改配置”按钮。 URL: 填写你的服务器地址，例如 http://wechat_pro.lehuoha.com/. Token: 填写一个自定义的安全 Token（例如：wechat_pro），这个值将在后续的请求校验中被使用。 EncodingAESKey: 由你随机生成或手动填写，用于消息体加解密。 选择加解密方式确保选定的加解密方式准确。默认设置是明文模式，其他两种模式下需要预先做好代码配置。 在配置完成后，微信服务器会发送一个 GET 请求到你指定的 URL，并携带以下四个参数： 参数 描述 signature 微信加密签名，结合 Token、timestamp 和 nonce 生成。 timestamp 请求发送的时间戳 nonce 随机数 echostr 随机字符串，在成功验证时返回该值 开发者的任务是校验这个请求的合法性。若请求的 signature 与自己程序生成的 signature 一致，则返回 echostr 以完成接入，否则返回错误信息。 Python 代码实现如下： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibapp = Flask(__name__)@app.route(/)def index(): token = wechat_pro data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 字典排序并 SHA-1 加密 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403if __name__ == __main__: app.run(host=0.0.0.0, port=8000, debug=True) 注意通常会遇到的错误是：“TypeError: Unicode-objects must be encoded before hashing”，这个错误主要是由于在进行 hash 加密时未指定编码。文中的 temp.encode(utf8) 是为了解决这个问题。 一旦接入成功，你可以在测试平台网页上看到“配置成功”的提示信息。 公众号接收与发送消息1. 接收普通消息当普通微信用户向公众账号发送消息时，微信服务器将以 POST 方式将消息的 XML 数据包发送到开发者事先填写的 URL 地址。微信服务器会在五秒内无响应的情况下，会自动重试最多三次。开发者应该保证在五秒内处理完请求。 收到的消息使用 XML 数据包格式： xml ToUserName![CDATA[gh_866835093fea]]/ToUserName FromUserName![CDATA[ogdotwSc_MmEEsJs9-ABZ1QL_4r4]]/FromUserName CreateTime1478317060/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[你好]]/Content MsgId6349323426230210995/MsgId/xml 注意：使用 ![CDATA[ ... ]] 保护的内容不会被 XML 解析器解析。 普通消息类别 文本消息 图片消息 语音消息 视频消息 小视频消息 地理位置消息 链接消息 2. 文本消息当接收到文本消息时，其 XML 数据格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1348831860/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[this is a test]]/Content MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间 （整型） MsgType 消息类型，文本为 text Content 文本消息内容 MsgId 消息的 ID 3. 被动回复消息开发者可以在处理用户的消息后，返回特定格式的 XML 数据包，以便进行响应。支持的消息类型有文本、图片、语音等。当接收请求后，你需要在 5 秒内做出响应，否则微信会对用户发送提示。 例如，回复文本消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[你好]]/Content/xml 参数 是否必须 描述 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者微信号 CreateTime 是 消息创建时间 （整型） MsgType 是 消息类型，文本为 text Content 是 回复的消息内容 确保正确响应用户的消息，以体现良好的用户体验。 4. 代码实现在与微信服务器的交互过程中，我们通过 HTTP 请求处理不同类型的请求。若接收到 GET 请求，系统会进行服务器验证，这一部分处理与上一步的逻辑相似，旨在确保请求来源的合法性。另一方面，若接收到 POST 请求，则需要进一步解析和处理请求内容。 基本的业务逻辑遵循“鹦鹉学舌”原则：用户发送的任何文本信息，系统会自动返回相同的信息，确保用户能感受到互动的即时性和流畅性。 以下是代码的详细解析： # 根据请求方式进行判断if request.method == POST: # 获取微信服务器post过来的xml数据 xml = request.data # 将xml格式的数据进行处理，转换成字典形式以便提取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是否是文本 if text == req.get(MsgType): # 获取用户的信息，并开始构造响应数据 # 这里将用户发送的信息原封不动地返回，保持字典格式 resp = ToUserName: req.get(FromUserName), # 接收方的用户唯一标识 FromUserName: req.get(ToUserName), # 开发者微信号 CreateTime: int(time.time()), # 消息创建时间 MsgType: text, # 消息的类型 Content: req.get(Content) # 用户发送的内容 # 将构造的字典转换成xml格式以便返回 xml = xmltodict.unparse(xml: resp) # 返回构造好的XML数据 return xml else: # 如果消息类型不是文本，返回一条固定信息 resp = ToUserName: req.get(FromUserName, ), # 接收方的用户唯一标识 FromUserName: req.get(ToUserName, ), # 开发者微信号 CreateTime: int(time.time()), # 消息创建时间 MsgType: text, # 消息的类型 Content: I LOVE ITCAST # 固定的返回内容 xml = xmltodict.unparse(xml: resp) # 转换为XML格式 return xml 特别注意事项： QQ 表情、Emoji 表情及自定义表情的处理都需要认真对待。QQ 表情在技术上被视为文本消息，因其实际上是字符的转义。而 Emoji 表情也是 Unicode 字符，因此同样视为文本信息。至于自定义表情，它既不属于文本也不是图片，而是微信未提供处理的格式，开发者需谨慎应对。 完整代码示例： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibimport xmltodictimport timeapp = Flask(__name__)@app.route(/, methods=[GET, POST])def index(): if request.method == GET: # 设置token，开发者配置中使用 token = wechat_pro # 获取微信服务器发送过来的参数 data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 对参数进行字典排序并拼接字符串 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) # 加密 if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403 # 根据请求方式进行判断 if request.method == POST: # 获取微信服务器post过来的xml数据 xml = request.data # 将xml格式的数据进行处理，转换成字典形式以便提取值 req = xmltodict.parse(xml)[xml] if text == req.get(MsgType): resp = ToUserName: req.get(FromUserName), FromUserName: req.get(ToUserName), CreateTime: int(time.time()), MsgType: text, Content: req.get(Content) xml = xmltodict.unparse(xml: resp) return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml: resp) return xmlif __name__ == __main__: app.run(host=0.0.0.0, port=8000, debug=True) 5. 接收其他普通消息接收图片消息图片消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1348831860/CreateTime MsgType![CDATA[image]]/MsgType PicUrl![CDATA[this is a url]]/PicUrl MediaId![CDATA[media_id]]/MediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 image PicUrl 图片链接 MediaId 图片消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 MsgId 消息 ID，64 位整型 接收视频消息视频消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[video]]/MsgType MediaId![CDATA[media_id]]/MediaId ThumbMediaId![CDATA[thumb_media_id]]/ThumbMediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 video MediaId 视频消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 ThumbMediaId 视频消息缩略图的媒体 ID MsgId 消息 ID，64 位整型 接收小视频消息小视频消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[shortvideo]]/MsgType MediaId![CDATA[media_id]]/MediaId ThumbMediaId![CDATA[thumb_media_id]]/ThumbMediaId MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 shortvideo MediaId 小视频消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 ThumbMediaId 小视频消息缩略图的媒体 ID MsgId 消息 ID，64 位整型 接收语音消息语音消息的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime1357290913/CreateTime MsgType![CDATA[voice]]/MsgType MediaId![CDATA[media_id]]/MediaId Format![CDATA[Format]]/Format MsgId1234567890123456/MsgId/xml 参数 描述 ToUserName 开发者的微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 voice MediaId 语音消息媒体 ID，可以通过多媒体文件下载接口拉取数据。 Format 语音格式，如 amr，speex 等 MsgId 消息 ID，64 位整型 注意：如果公众号已开通语音识别功能，当用户发送语音消息时，微信会在推送的语音消息 XML 数据包中增加一个 Recognition 字段。在这种情况下，格式字段会继续显示语音格式，其它系统不会受影响。 回复其他普通消息回复图片消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[image]]/MsgType Image MediaId![CDATA[media_id]]/MediaId /Image/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间（整型） MsgType 是 消息类型，值为 image MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 回复语音消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[voice]]/MsgType Voice MediaId![CDATA[media_id]]/MediaId /Voice/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间戳 （整型） MsgType 是 消息类型，值为 voice MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 回复视频消息xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[video]]/MsgType Video MediaId![CDATA[media_id]]/MediaId Title![CDATA[title]]/Title Description![CDATA[description]]/Description /Video/xml 参数 是否必须 说明 ToUserName 是 接收方帐号（收到的 OpenID） FromUserName 是 开发者的微信号 CreateTime 是 消息创建时间 （整型） MsgType 是 消息类型，video MediaId 是 通过素材管理接口上传多媒体文件，得到的 ID。 Title 否 视频消息的标题 Description 否 视频消息的描述 可以使用微信提供的网页调试工具进行测试：https://mp.weixin.qq.com/debug/cgi-bin/apiinfo?t=index 关注取消关注事件当用户关注或取消关注公众号时，微信会推送相关事件到开发者设置的 URL。为了确保消息的可靠性，若微信服务器在五秒内未收到响应，它将断开连接并重新发起请求，总共会重试三次。开发者需注意，如果服务器无法保证在五秒以内处理完请求，可以直接回复一个空串，此时微信服务器不会发起重试。 接收关注事件的 XML 格式如下： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[FromUser]]/FromUserName CreateTime123456789/CreateTime MsgType![CDATA[event]]/MsgType Event![CDATA[subscribe]]/Event/xml 参数 描述 ToUserName 开发者微信号 FromUserName 发送方帐号（一个 OpenID） CreateTime 消息创建时间（整型） MsgType 消息类型，值为 event Event 事件类型，值为 subscribe（订阅）或 unsubscribe（取消订阅） 代码实现如下： #!/usr/bin/env python# -*- coding: utf-8 -*-from flask import Flask, request, make_responseimport hashlibimport xmltodictimport timeimport requestsimport jsonapp = Flask(__name__)@app.route(/, methods=[GET, POST])def index(): if request.method == GET: # 设置token, 开发者配置中心使用 token = wechat_pro # 获取微信服务器发送过来的参数 data = request.args signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) echostr = data.get(echostr) # 对参数进行字典排序并拼接字符串 temp = [timestamp, nonce, token] temp.sort() temp = .join(temp) # 加密 if (hashlib.sha1(temp.encode(utf8)).hexdigest() == signature): return echostr else: return error, 403 if request.method == POST: xml = request.data req = xmltodict.parse(xml)[xml] MsgType = req.get(MsgType) if text == MsgType: resp = ToUserName: req.get(FromUserName), FromUserName: req.get(ToUserName), CreateTime: int(time.time()), MsgType: text, Content: 这是一个文本消息！ elif event == MsgType: if subscribe == req.get(Event): resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: u感谢您的关注！ else: resp = None else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: 无法识别该消息！ xml = xmltodict.unparse(xml: resp) return xmlif __name__ == __main__: app.run(host=0.0.0.0, port=80, debug=True) 微信网页授权要实现一个在微信内访问的网页，该网页能够展示微信用户的个人信息，用户必须授权才能访问这些数据。授权后，开发者服务器会接收到一个“授权书”（code），利用这个 code 向微信服务器请求访问令牌（access_token）以及用户的身份号码（openid）。之后，开发者可以使用 access_token 和 openid 提取用户的个人信息。 流程概览 用户同意授权，获取 code 通过 code 换取网页授权 access_token 拉取用户信息（需 scope 为 snsapi_userinfo） 如何获取授权 code？用户授权的过程由微信发起。用户首先需要访问微信的授权链接。如果用户同意授权，微信将用户重定向到开发者指定的网页，附带 code 参数。这一过程被称为网页回调，类似于程序编写中的回调函数，都是通过回调的方式进行信息交互。 1. 设置网页授权回调域名在请求用户网页授权之前，开发者需要登录微信公众号平台，在开发者中心配置授权回调域名。注意，填入的应为域名的字符串形式，不能包含 http: 等协议前缀。例如，如果需要进行网页授权的域名是 www.qq.com，则配置后，该域名下的任何页面，例如： http://www.qq.com/music.html http://www.qq.com/login.html 都可以进行 OAuth2.0 授权。但是，如下域名则无法进行 OAuth2.0 鉴权： http://pay.qq.com http://music.qq.com http://qq.com 2. 用户同意授权，获取 code开发者应引导用户访问以下链接： https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPIDREDIRECT_URIresponse_typecodescopeSCOPEstateSTATE#wechat_redirect 当 scope 设置为 snsapi_userinfo 时，用户将看到授权页面。如果用户选择同意，页面将重定向至 redirect_uri/?code=CODEstate=STATE；如果用户拒绝，则将重定向至 redirect_uri?state=STATE，此时不会附带 code 参数。 3. 通过 code 换取网页访问 access_token请求方法 向微信服务器发起请求： https://api.weixin.qq.com/sns/oauth2/access_token?appidAPPIDsecretSECRETcodeCODEgrant_typeauthorization_code 参数说明 在请求中，需提供对应的参数，即 appid、secret、code 和 grant_type。 返回值 成功时，微信服务器返回的 JSON 数据如下： access_token: ACCESS_TOKEN, expires_in: 7200, refresh_token: REFRESH_TOKEN, openid: OPENID, scope: SCOPE 如果请求出现错误，比如 code 无效，微信会返回如下 JSON 数据： errcode: 40029, errmsg: invalid code 4. 拉取用户信息 (需 scope 为 snsapi_userinfo)请求方法 使用以下格式请求用户信息： https://api.weixin.qq.com/sns/userinfo?access_tokenACCESS_TOKENopenidOPENIDlangzh_CN 参数说明 此请求 2 需要提供 access_token 和 openid 的参数。 返回值 如果请求成功，返回的 JSON 数据格式如下： openid: OPENID, nickname: NICKNAME, sex: 1, province: PROVINCE, city: CITY, country: COUNTRY, headimgurl: http://wx.qlogo.cn/mmopen/g3MonUZtNHkdmzicIlibx6iaFqAc56vxLSUfpb6n5WKSYVY0ChQKkiaJSgQ1dZuTOgvLLrhJbERQQ4eMsv84eavHiaiceqxibJxCfHe/46, privilege: [PRIVILEGE1, PRIVILEGE2], unionid: o6_bmasdasdsad6_2sgVt7hMZOPfL 如果出现错误，例如 openid 无效，返回如下 JSON 数据： errcode: 40003, errmsg: invalid openid","tags":["clippings"],"categories":["0.平台","服务器","微信"]},{"title":"网易云评论获取","path":"/2024/12/18/1-语言-Python-网易云评论获取/","content":"在使用 Ajax 技术加载数据的网站中，JavaScript 发起的 HTTP 请求通常需要带上参数，而且这些参数的值经过加密处理。如果我们想使用网站的 REST API 来爬取数据，就必须首先了解其加密方式。整个过程需要通过抓包工具，仔细阅读和分析网站的 js 代码，这样可能会耗费一天甚至更长的时间。虽然这个过程繁琐，但我们可以采用一些更为高效的方法来提取数据。一个可行的方法是使用 Selenium 库，这能够模拟浏览器行为，直接抓取所需的网页数据，提升我们的工作效率。 实现目标本文将展示如何利用 Selenium 爬取网易云音乐中歌曲《Five Hundred Miles》的所有评论，然后将这些评论存储到 MongoDB 数据库中。 工具为了实现这个目标，我们需要一些特定的工具。以下是所需的工具清单： Selenium: 这是一个 Web 应用程序自动化测试工具，能够模拟用户在浏览器中的操作，如打开页面、点击按钮等。它能够有效解决 JavaScript 渲染问题，使得我们能获取动态加载的数据。 安装方法： pip install selenium Chrome 浏览器: 我们将使用 Chrome 浏览器来进行抓取操作。 WebDriver: 这是 Selenium 控制浏览器的必要组件。因为使用的是 Chrome 浏览器，所以需要下载对应的 ChromeDriver。下载后需解压，并将其放到 Python 的 Scripts 文件夹中。 MongoDB: 网易云音乐的评论数量庞大，常常超过十万条，为了有效管理这些数据，我们需要数据库进行存储。在此我们选择使用 MongoDB。 pymongo: 这是 Python 访问 MongoDB 的库，安装同样采用 pip： pip install pymongo 爬取思路接下来的步骤将详细描述我们的爬取逻辑： 启动 Selenium: 使用 Selenium 驱动 Chrome 浏览器，打开要爬取的页面。 计算评论分页数: 获取页面中“最新评论”标签后的评论总数，以此计算出总共的评论分页数。这可以通过将评论总数除以每页显示的评论数量（20 条）并向上取整来实现。 爬取数据: 首先爬取第一页的评论，然后将数据存储到 MongoDB。 分页处理: 利用 Selenium 模拟点击“下一页”按钮，继续抓取后续页面的评论数据，并存储。 循环迭代: 重复步骤 4，直到所有评论数据都被爬取完毕。 代码实现首先，我们需要确定要爬取的歌曲《Five Hundred Miles》的 URL 地址，并调用爬取函数。 if __name__ == __main__: url = http://music.163.com/#/song?id=27759600 # Five Hundred Miles start_spider(url) 接下来，使用 Selenium 启动 Chrome 浏览器并访问指定页面： from selenium import webdriverimport timefrom math import ceilfrom selenium.webdriver.common.by import Bydef start_spider(url): 启动 Chrome 浏览器访问页面 brower = webdriver.Chrome() brower.get(url) # 等待5秒，确保评论数据加载完成 time.sleep(5) # 页面嵌套在一个 iframe 中，必须先切换到 iframe 才能定位其中的元素 iframe = brower.find_element(By.CLASS_NAME, g-iframe) brower.switch_to.frame(iframe) # 获取【最新评论】总数 new_comments = brower.find_elements(By.XPATH, //h3[@class=u-hd4])[1] max_page = get_max_page(new_comments.text) 然后定义一个函数，用于计算出总分页数： def get_max_page(new_comments): 根据评论总数, 计算出总分页数 print(=== + new_comments + ===) max_page = int(new_comments.split(()[1].split())[0]) # 每页显示20条最新评论 max_page = ceil(max_page / 20) print(一共有, max_page, 个分页) return max_page 接下来，可以开始循环爬取评论数据，初始时从第一页开始： current = 1is_first = Truewhile current = max_page: print(正在爬取第, current, 页的数据) if current == 1: is_first = True else: is_first = False data_list = get_comments(is_first, brower)def get_comments(is_first, brower): 获取评论数据 items = brower.find_elements(By.XPATH, //div[@class=cmmts jflag]/div[@class=itm]) # 首页包含15条精彩评论与20条最新评论，只需保留最新评论 if is_first: items = items[15:] data_list = [] for each in items: data = # 获取用户昵称、评论内容等信息 userId = each.find_element(By.XPATH, ./div[@class=head]/a).get_attribute(href).split(=)[1] nickname = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[1]/div[1]/a).text content = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[1]/div[1]).text.split(：)[1] like = each.find_element(By.XPATH, ./div[@class=cntwrap]/div[@class=rp]/a[1]).text like = like.strip().split(()[1].split())[0] if like else 0 avatar = each.find_element(By.XPATH, ./div[@class=head]/a/img).get_attribute(src) data.update( userId: userId, nickname: nickname, content: content, like: like, avatar: avatar ) print(data) data_list.append(data) return data_list 最后，将爬取到的评论数据存储到 MongoDB 中，并模拟点击“下一页”按钮： save_data_to_mongo(data_list)def save_data_to_mongo(data_list): 一次性插入20条评论，以提高插入效率，降低数据丢失风险 collection = db_manager[MONGO_COLLECTION] try: if collection.insert_many(data_list): print(成功插入, len(data_list), 条数据) except Exception: print(插入数据出现异常)# 模拟点击“下一页”按钮time.sleep(1)go_nextpage(brower)def go_nextpage(brower): 模拟人为操作, 点击【下一页】 next_buttons = brower.find_elements(By.XPATH, //div[@class=mcmmt]/div[3]/div[1]/a) if next_buttons and next_buttons[-1].text == 下一页: next_buttons[-1].click() 扩展访问普通网站的整个过程： 我们访问使用 Ajax 加载数据的网站的整个过程：","categories":["1.语言","Python"]},{"title":"爬虫","path":"/2024/12/18/1-语言-Python-爬虫/","content":"ScrapyScrapy 是一个开源的爬虫框架，特别适合用于提取网络数据。它通过异步网络请求提高了爬取效率，常用于网络抓取、数据挖掘等任务。Scrapy 的强大之处在于其模块化设计，便于扩展和定制。比如，你可以快速定制爬取规则，存储抓取的数据，或是构建复杂的爬虫项目。 BeautifulSoupBeautifulSoup 是一个用于解析 HTML 和 XML 文档的库，对于处理网页抓取中常见的文件结构非常有效。它提供很方便的 API 来搜索和操作解析结果，比如通过 tags 和 CSS Selectors 直接找到网页中的特定元素。例如，你可以使用如下方式提取一个 p 标签中的文本内容： from bs4 import BeautifulSouphtml_doc = htmlbodypHello, World!/p/body/htmlsoup = BeautifulSoup(html_doc, lxml)print(soup.p.text) # 输出: Hello, World! MechanizeMechanize 是一个用于自动化 Web 表单的 Python 库，支持模拟用户行为，如填写表单、点击链接等。它允许脚本自动处理各种状态和返回的数据。比如，你可以使用 Mechanize 登陆一个需要身份验证的网站，输入用户名和密码，提交表单并访问受保护的页面。 SeleniumSelenium 是一个流行的 Web 测试自动化框架，能够控制浏览器进行各种测试和自动化任务。它特别适用于处理 JavaScript 渲染的网页，因为它仿佛是真正的用户在操作浏览器。通过 Selenium，你可以模拟点击、滚动等操作，甚至可以等待特定的元素出现在页面上。以下是一个简单的例子，用于打开网页并等待某个元素： from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECdriver = webdriver.Chrome()driver.get(http://example.com)try: element = WebDriverWait(driver, 10).until( EC.presence_of_element_located((By.TAG_NAME, h1)) ) print(element.text)finally: driver.quit() 变量在 Python 中，变量可以存储不同类型的数据，包括数字、字符串、列表、元组和字典： 数字：可以是整数或浮点数（如 age = 30）。 字符串：文本数据（如 name = Alice）。 列表：有序集合（如 fruits = [apple, banana, cherry]）。 元组：不可变的有序集合（如 coordinates = (10.0, 20.0)）。 字典：键值对集合（如 person = name: Alice, age: 30）。 函数在 Python 中，函数是一段封装的代码，用于执行特定的任务，如计算和数据处理。你可以自定义函数来实现复杂的功能并提高代码的复用性。 循环体循环体允许你重复执行一段代码。Python 提供了 for 循环和 while 循环。例如，使用 for 循环迭代一个列表： fruits = [apple, banana, cherry]for fruit in fruits: print(fruit) 网页的构成网页一般由 HTML、CSS 和 JavaScript 构成： HTML：提供网页的基本结构，包含如 p, div, ul, img, h1, a href= 等标签。 CSS：用于样式设计，控制颜色、字型和布局。 JavaScript：提供交互功能。 网页的整体结构通常可分为三个部分： header：通常包含网站的标题和导航菜单。 content：网页的主要内容区域，存放文本、图片等。 footer：页面底部的额外信息，如版权声明和链接。 在 HTML 中，head 标签包含诸如元数据和链接到 CSS 文件等信息，通常用户看不见。而 body 标签则包含网页的可见内容。 解析网页中的元素信息网页数据的解析可以借助各种工具和库来实现。 BeautifulSoup 用于解析网页，其底层可以使用 lxml 或 html.parser。 选择器： CSS Selector: 例如，body div:nth-child(1) img 可以精确选择第一个 div 标签中的图片。 XPath: 例如，/html/body/div[1]/img 提供另一种选择路径语法。 Request进行 HTTP 请求时，主要有以下几种方法： GET：用于请求数据，常用于获取页面。 POST：用于提交数据，如登录操作。 PUT 和 DELETE：用于更新和删除数据，通常在 RESTful API 中使用较少。 使用 requests 库可以轻松发送这些请求： import requestsresponse = requests.get(http://example.com) 第三方库Python 拥有丰富的第三方库，便于用户进行网络请求及数据处理，比如： requests：用于发起网络请求。 BeautifulSoup：用于解析 HTML 和 XML。 Selenium：用于自动化浏览器操作。 在进行网络爬虫时，伪装成浏览器进行访问非常重要，通常会设置 User-Agent 以避免阻止请求。 黑客攻击模块Python 的优势之一是它拥有许多库支持网络安全研究与黑客攻击。比如： pydbg：用于调试和操控进程。 scapy：用于网络包分析和生成。 sqlmap：用于检测和利用 SQL 注入漏洞。 httplib：用于 HTTP 请求的处理。 这些库被广泛应用于信息安全领域，帮助研究人员和开发者探测潜在的网络漏洞。 能够访问各种 APIPython 的 ctypes 库允许黑客访问 Windows、OS X、Linux 和其他操作系统提供的动态链接库和共享库。这种能力使得开发者可以创建跨平台的攻击脚本，利用各种系统提供的 API 进行深层次的交互。 黑客攻击工具与 Python许多常用的黑客攻击工具都提供了 Python API，以便于高级用户进行自定义扩展。最具代表性的包括： sqlmap：自动化 SQL 注入和数据库接管。 Nmap：用于网络探测和安全审计。 Metasploit：渗透测试框架，包含大量的攻击模块。 通过 Python，这些工具可以被整合，并根据具体需要进行强大的自定义，极大提升了攻击的灵活性和效率。","categories":["1.语言","Python"]},{"title":"Python学习路线","path":"/2024/12/18/1-语言-Python-Python学习路线/","content":"Python 自学计划Python 的主体内容大致可以分为以下几个部分： 1. 面向过程面向过程编程是 Python 的基础组成部分，这一部分涵盖了基本的表达式、条件语句（如 if 语句）、循环结构（如 for 和 while 循环）以及函数的定义与使用。如果你有任何编程语言的基础，特别是像 C 语言这样的语言，这一部分内容就会显得比较直观。例如，循环结构可以用来处理重复任务，而函数则帮助你组织代码，避免重复。例如，一个简单的函数可以轻松地计算两个数字的和： def add(a, b): return a + b 如果你没有编程的基础，建议从一本基础性参考书开始学习，例如《Python Programming》。这本书的内容通俗易懂，面向计算机导论，读者不需要有编程经验也能顺利入门。 2. 面向对象在 Python 中，面向对象编程是另一个重要的概念，涉及到基本的面向对象概念，比如类、对象、方法、属性和继承等。Python 是一种面向对象的语言，强调“一切皆对象”。与 Java 和 C++ 不同，Python 的面向对象机制相对松散，意味着学习者可以更灵活地进行创造和修改。 例如，定义一个类可能是这样的： class Animal: def __init__(self, name): self.name = name def speak(self): return fself.name says hello. 松散的结构使得学习和维护代码变得简单，但也会带来一定的灵活性，容易让初学者犯错。因此，在使用面向对象编程时，需要注意如何管理和维护自己的代码。 3. 应用功能Python 的应用功能包括输入输出（IO）、数据容器如列表（list）和字典（dictionary）、内置函数、模块和格式化字符串等。这些概念在其他编程语言中也同样存在，具有很强的实用性和可移植性。例如，字典是一种灵活的数据结构，可以使用键值对的方式存储数据，这样我们可以通过键快速访问到对应的值： person = name: Alice, age: 30print(person[name]) # 输出: Alice 这些应用功能使得 Python 成为一个高效和易于使用的编程语言，适合开发各种类型的应用。 4. 高级语法Python 还提供了一些高级语法，如上下文管理器、列表推导、函数式编程、装饰器和特殊方法等。这些高级功能虽然不是学习 Python 的必需，但它们使编程更加简洁和优雅。例如，列表推导能够在一行中实现复杂的列表创建，相较于传统的循环使用，能够减少代码量，提高可读性： squares = [x**2 for x in range(10)] 这里，我们仅用一行代码就生成了从 0 到 9 的平方列表，这在用传统的 for 循环时需要更多的行数。 Web 开发方向 阅读资料: 完成《简明 Python 教程》。这本书以清晰易懂的语言为初学者介绍 Python 的基本概念和语法结构，适合初次接触编程的读者。 适应开发环境: 安装 Python 最新版本，并设置好开发环境（推荐使用 Anaconda 或直接安装 Python）。熟悉基本的命令行操作（例如创建虚拟环境、安装包等），为后续项目打下基础。 项目目标: 编写一个简单的网络爬虫。 必学模块: re: 学习正则表达式，用于提取网页内容（例如获取网页中的特定信息）。 urllib2: 处理 URL 请求与 HTTP 响应，从而获取网页数据。 sqlite3: 了解如何使用 SQLite 数据库存储抓取的数据。 threading 和 Queue: 实现多线程爬取，提高抓取效率和速度。 实施细节: 学习如何使用正则表达式分析抓取到的数据，举例来说，可以从文章中提取出标题、作者及发布时间。 实现程序自动重启功能，当获取数据的请求失败时可以自动继续，确保爬虫的持续抓取的稳定性和有效性。 选择框架: 学习 Flask 或 webpy 等轻量级 Web 开发框架。这些框架易于上手，并且具有丰富的文档支持，适合初学者进行实践。 数据库接口: 掌握如何连接和操作 SQLite 数据库，以便在你的 Web 应用中存储和检索数据。 项目实例: 开发一个简单的 Web 应用，如博客，至少实现以下功能： 用户可以注册和登录。 用户可以发表新文章。 用户可以查看已有文章的列表，并点击进入查看详细内容。 项目功能实施: 基于前面的学习，给你的 Web 应用增加一个小功能，比如评论功能，用户能在文章下方留下评论。 测试与上线: 测试包括单元测试、集成测试等，确保应用程序的稳定性和正确性。 理解基本的部署流程（如使用 Heroku 或 VPS 来上线你的应用），让你的项目从开发环境转变为生产环境。 算法与数据结构在 Python 中，常用的数据结构包括 list、tuple、set、frozenset 和 dict，以及 collections 模块中的 OrderedDict、defaultdict、deque、namedtuple 和 Counter 等。特别是对这些数据结构的特性和使用场景进行深入理解，可以帮助你在不同的编程任务中选择合适的工具，从而提高代码的效率。 例如，了解当需要一个可变的、有序的数据集合时，可以使用 OrderedDict，而在需要一个无重复元素的集合时，应选择 set。此外，掌握基本的算法思想，如递归、二分查找等，可以帮助你编写出高效且易用的代码。如果你想通过实践来加深理解，推荐在 ACM 竞赛平台或 LeetCode 等网站上进行刷题训练。 Python 与数据库在网站业务的后端，主流的数据库类型有三种：关系型数据库（如 MySQL）、文档型数据库（如 MongoDB）以及内存型数据库（如 Redis）。这些数据库各自具有不同的优势和适用场景。作为后端程序员，了解如何灵活使用这些数据库以及它们各自的特点至关重要，尤其是 MySQL 和 Redis。 SQLiteSQLite 是一个轻量级的数据库，引入了简便的文件存储方式，适合快速开发和小型应用。你可以参考 SQLite Python Tutorial 来掌握基础知识。《The Definitive Guide to SQLite》是一本深入解析 SQLite 的书籍，适合需要更高效使用该数据库的开发者。 在使用 SQLite 3 时，了解一些基本的命令和操作是至关重要的。可以通过阅读 SQLite Documentation 来获取相关信息。 MySQLMySQL 是一种流行的关系数据库，对于需要进行大数据量存储和操作的应用尤为合适。想要接触 MySQL 的开发者可查阅 Python MySQL Database Access 的教程。 MongoDBMongoDB 作为 NoSQL 的一员，因其灵活的数据模型而受到广泛欢迎。对于熟悉 SQL 的开发者，学习 MongoDB 的门槛相对较低。推荐你阅读 MongoDB官方文档 进行入门。两个常用的 Python 驱动是： PyMongo - 提供了类似 Mongo Shell 的接口，便于实现 MongoDB 的各种操作。 MongoEngine - 作为 MongoDB 的 ORM 框架，它把数据模型转化为 Python 对象，通用性和易用性较高。 RedisRedis 是一个基于内存的高性能键值存储数据库。虽然 Redis 需要一定的学习成本，但它能带来显著的性能提升，尤其在实时应用中。入门推荐阅读 The Little Redis Book。常用的 Python 客户端驱动包括： redis-py - 官方支持的 Redis Python 客户端。 更多客户端选择可以参考 Redis Clients。 Python 的 Web 框架Python 拥有众多 Web 框架供开发者选择，适合不同类型的项目。可以在 Python Web Frameworks 中一览这些框架优势。如果找不到合适的框架，你也可以考虑基于自己的需求开发一个。这些框架之所以如此繁多，反映了 Python 社区的活跃和多样化。 web.pyweb.py是一个简约而强大的 Python Web 框架。它被公开归属，意味着你可以将其用于任何目的，而不受限制。 项目链接: 在线 demo 创始人: Aaron Swartz 的博客【在 GitHub 上有分享】。 FlaskFlask是一个轻量级的 Web 应用框架，基于 Werkzeug WSGI 工具包和 Jinja2 模板引擎。它采用 BSD 许可，因此允许自由使用和修改。Flask 被称为微框架，因为它核心部分简单但可扩展。 实战教程: Flask Mega-Tutorial TornadoTornado是一个异步框架，最初在 FriendFeed 开发，之后在 Facebook 收购后开源。Tornado 是一个 Python web 框架和异步网络库，非常适合构建高性能的非阻塞实时 Web 应用。如果你希望你的 Web 应用具有高并发的能力，Tornado 将是一个不错的选择。 项目链接: Tornado on GitHub DjangoDjango是一个高级 Python Web 框架，旨在鼓励快速开发以及干净、务实的设计。作为一个全栈式框架，Django 拥有许多内置组件，确保快速构建可靠的 web 应用。 资料链接: Django 资料","categories":["1.语言","Python"]},{"title":"Nginx配置","path":"/2024/12/18/3-软件-Web相关-Nginx配置/","content":"URL 最后的斜杠当访问的 URL 最后没有斜杠时，Nginx 会自动为其补上斜杠，并进行 301 跳转。这意味着用户在访问某个路径时，如 http://example.com/path，将会被重定向到 http://example.com/path/。 使用 proxy_pass 的注意事项如果你在配置中使用了 proxy_pass 等流量转发手段，则需要关闭绝对路径： absolute_redirect off; 这个设置确保了在斜杠的处理上 Nginx 不会直接跳转到后端，而是保留相对路径。 如果你的 Nginx 版本低于 1.11.8，需要使用禁止端口跳转的选项： port_in_redirect off; 或者，你可以编写判断规则，检查无斜杠的 URL 是否是文件。如果不是，可以加一个斜杠。下面是一个示例配置： if ( -d $request_filename ) rewrite ^/(.*)([^/])$ https://api.myserver.com/$1$2/ permanent;if (-d $request_filename) rewrite [^/]$ $scheme://$http_host$uri/ permanent; 推荐方案选择上述两种方法之一，后者会强制一些 API 的 URL 加上斜杠，例如： 请求 GET myserver.com/api?param=1 会被强制转变为 myserver.com/api/?param=1。这会导致请求失败，因为不是所有 API 都支持尾部斜杠。 在具体的配置中，可以针对 location 进行设置： location /api proxy_pass http://127.0.0.1:1111/;location /api/ proxy_pass http://127.0.0.1:1111/; 基本认证准备工具时，如果你在 Debian 或 Ubuntu 系统上，可以使用 apache2-utils，而在 RHELCentOSOracle Linux 系统上，则用 httpd-tools。 生成密码文件可以使用以下命令创建密码文件并添加用户： htpasswd -c /etc/apache2/.htpasswd user1htpasswd /etc/apache2/.htpasswd user2 配置基本认证以下是设置 API 保护的示例： location /api auth_basic Administrator’s Area; auth_basic_user_file /etc/apache2/.htpasswd; 如果某些资源不需要认证，可以使用以下配置： location /public/ auth_basic off; IP 控制你可以灵活地设置哪些 IP 地址能够访问特定服务，这对于提高安全性非常有用。例如： location /api satisfy all; deny 192.168.1.2; # 阻止特定 IP 访问 allow 192.168.1.1/24; # 允许特定网段访问 allow 127.0.0.1; # 允许本地访问 deny all; # 阻止其他所有 IP auth_basic Administrator’s Area; auth_basic_user_file conf/htpasswd; Satisfy 指令可以设置为 all（全部条件满足）或 any（只需一个条件满足即可）。 按路径反代通过指定路径，将流量转发至下级服务。若配置如下： location /path/ proxy_pass http://127.0.0.1:4444; 那么所有到达 /path/ 的请求会被转发至 http://127.0.0.1:4444。 案例分析案例 1：设置路径为 /path： location /path proxy_pass http://127.0.0.1:4444/; 对这个路径的请求结果如下： GET myserver.com/path - 返回 OK。 GET myserver.com/path/ - 成功重定向，可能返回 301 或 404。 GET myserver.com/path?param=1 - 返回 OK。 GET myserver.com/path/?param=1 - 返回 301 后重定向，可能返回 404。 案例 2：设置路径为 /path/： location /path/ proxy_pass http://127.0.0.1:4444/; 此时的请求结果： GET myserver.com/path - 返回 301，重定向至 /path/。 GET myserver.com/path/ - 返回 OK。 GET myserver.com/path?param=1 - 成功重定向，返回 OK。 GET myserver.com/path/?param=1 - 返回 OK。 案例 3：设置路径为 = /path： location = /path proxy_pass http://127.0.0.1:4444/; 其请求结果为： GET myserver.com/path - 返回 OK。 GET myserver.com/path/ - 返回 404。 GET myserver.com/path?param=1 - 返回 OK。 GET myserver.com/path/?param=1 - 返回 404。 总结对于 RESTful API，建议直接使用 location = /path，这样不会有 301 重定向。而对于普通网站，则建议使用 location /path/ 以确保有效的重定向。 WebSocket 代理如果需要将请求反代到 WebSocket 协议，必须在 Header 中添加 Upgrade 字段，具体示例如下： http map $http_upgrade $connection_upgrade default upgrade; close; server location /chat/ proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; 使用 Docker引入 Nginx 后，使用 Docker 部署服务变得容易许多，只需执行以下命令： docker pull someimagedocker run -v 映射空间 -p 本地端口:docker端口 完整配置示例以下是一个完整的 Nginx 配置示例： user root;worker_processes 1;load_module /usr/lib/nginx/modules/ngx_stream_module.so;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events worker_connections 1024;stream map $ssl_preread_server_name $backend_name myserver.com myserver; api.myserver.com api; cdn.myserver.com cdn; default bad; upstream myserver server 127.0.0.1:666; upstream api server 127.0.0.1:777; upstream cdn server 127.0.0.1:888; upstream bad server 127.0.0.1:400; server listen 443 reuseport; listen [::]:443 reuseport; proxy_pass $backend_name; ssl_preread on; http include /etc/nginx/mime.types; default_type application/octet-stream; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 120; client_max_body_size 20m; gzip on; ssl_protocols TLSv1.2 TLSv1.3; server listen 80; listen [::]:80; server_name myserver.com api.myserver.com cdn.myserver.com; return 301 https://$host$request_uri; server listen 80 default_server; listen [::]:80 default_server; server_name _; return 400; server listen 127.0.0.1:888 ssl http2; ssl_certificate /path/to/my/public.cer; ssl_certificate_key /path/to/my/private.key; ssl_client_certificate /etc/nginx/ssl/cert/cloudflare.crt; ssl_verify_client on; root /share; server listen 127.0.0.1:777 ssl http2; root /path/to/api; index index.html; absolute_redirect off; if (-d $request_filename) rewrite [^/]$ $scheme://$http_host$uri/ permanent; location /private/ auth_basic Login required; auth_basic_user_file /etc/nginx/passwd/.htpasswd; autoindex on; location /public/ autoindex on; location /service/ proxy_pass http://127.0.0.1:8080/; ssl_certificate /path/to/my/public.cer; ssl_certificate_key /path/to/my/private.key; server listen 400 ssl; ssl_reject_handshake on;","categories":["3.软件","Web相关"]},{"title":"GitLab部署","path":"/2024/12/18/3-软件-Git-GitLab部署/","content":"手动部署 GitLab 环境1. 安装依赖包首先，我们需要安装一些必要的依赖包，以确保环境运行顺畅。这些包包括： curl：用于获取文件和数据的工具。 policycoreutils-python：为 SELinux 提供管理工具的 Python 包。 openssh-server：SSH 服务，用于安全远程访问。 以下命令用于安装这些依赖包： sudo yum install -y curl policycoreutils-python openssh-server 2. 配置 SSH 服务接下来，我们需要配置 SSH 服务，以便能够安全地管理 GitLab 服务器。 启动 SSH 服务使用下面的命令来启动 SSH 服务： sudo systemctl start sshd 设置 SSH 服务为开机自启动确保 SSH 服务在系统重启后自动启动，运行以下命令： sudo systemctl enable sshd 3. 安装 Postfix 以发送通知邮件我们需要安装 Postfix，它是一个广泛使用的邮件传输代理，可以用来发送邮件通知。 安装 Postfix运行以下命令，以安装 Postfix： sudo yum install postfix 设置 Postfix 为开机自启动确保 Postfix 在重启时自动启动： sudo systemctl enable postfix 启动 Postfix 服务使用以下命令来启动 Postfix 服务： sudo systemctl start postfix 4. 配置 Postfix我们需要编辑 Postfix 的配置文件，使其能够接受外部连接。 编辑 Postfix 配置文件运行以下命令来打开 Postfix 主配置文件： vim /etc/postfix/main.cf 找到以下行： set_inet 将其修改为： inet_interfaces = all 保存配置文件并退出按 Esc 键退出编辑模式，然后输入 :wq 并回车，以保存并关闭文件。 5. 添加 GitLab 软件包仓库接下来，我们需要添加 GitLab 的官方软件包仓库，使用以下命令： curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 6. 安装 GitLab安装 GitLab 的命令如下，用您 GitLab 服务器的公网 IP 地址替换占位符： sudo EXTERNAL_URL=http://GitLab服务器的公网IP地址 yum install -y gitlab-ce 获取公网 IP 地址您可以在 ECS 管理控制台的实例与镜像 实例页面找到 GitLab 所属 ECS 实例的公网 IP 地址。 7. 使用浏览器访问 GitLab在浏览器中输入 GitLab 服务器的公网 IP 地址。成功访问后，将看到如下页面，表示环境搭建成功，并且系统会提示您设置新密码。 8. 登录 GitLab输入登录信息在浏览器的地址栏中，输入 ECS 服务器的公网 IP，进入 GitLab 的登录界面。首次登录时，使用用户名 root，密码为您首次访问 GitLab 时设置的新密码。 登录成功后界面成功登录后，您将看到如下界面： 9. 创建项目在 GitLab 中，我们可以轻松创建新项目。 安装 Git 工具首先，确保您已安装 Git 工具，用于版本控制。可以使用 Linux 自带的软件源安装 Git： yum install git 生成密钥文件使用以下命令生成 SSH 密钥文件，以便能够与 GitLab 安全地进行交互： ssh-keygen 查看公钥文件运行以下命令以查看生成的公钥内容，并将其用于 GitLab 的配置中： cat .ssh/id_rsa.pub 10. 在 GitLab 中创建项目新建项目在 GitLab 的主页中，单击“New Project”按钮，新建一个项目。 配置项目设置与项目相关的各项配置，然后单击“Create project”按钮完成项目创建。 添加 SSH Key点击“Add an SSH key”按钮，将第二步中生成的公钥粘贴到相应的配置框中。 完成后，您将看到 SSH key 已成功添加的提示信息。 保存项目地址项目地址在进行克隆操作时需要用到，请务必保存该地址。 11. 简单配置 Git 用户信息为了在项目中正确记录提交者信息，您需要配置 Git 用户的姓名和电子邮件地址。 git config --global user.name testname git config --global user.email abc@example.com 12. 克隆项目使用以下命令将您在 GitLab 上创建的项目克隆到本地： git clone git@iZ****3Z:root/test.git 执行后，将在本地生成同名目录，该目录中会包含项目的所有文件。 13. 上传文件进入项目目录使用以下命令进入刚克隆的项目目录： cd test/ 创建并上传文件创建一个要上传到 GitLab 的文件，例如： echo test /root/test.sh 将目标文件或目录复制到项目目录下： cp /root/test.sh ./ 将文件加入版本控制使用以下命令将新创建的文件 test.sh 添加到 Git 的暂存区： git add test.sh 提交更改执行提交操作，记录此次更改： git commit -m test.sh 推送到 GitLab 服务器将本地更改同步到 GitLab 服务器： git push -u origin master 14. 验证文件同步在网页中查看，您将看到上传的 test.sh 文件已经成功同步到 GitLab 中。确认同步成功的界面如下：","categories":["3.软件","Git"]},{"title":"WordPress搭建","path":"/2024/12/18/0-平台-服务器-博客-WordPress搭建/","content":"搭建 WordPress 网站在准备工作后首先是部署 LNMP 环境，LNMP 环境的部署详见 LNMP环境 MySQL 数据库配置首先，使用 root 用户登录到 MySQL 数据库。确保您输入的是在搭建环境时为数据库设置的密码。您可以通过以下命令登录： mysql -uroot -p 为 WordPress 网站创建数据库在 MySQL 中创建一个新的数据库，以便存放 WordPress 网站的数据。本教程中，数据库名称为 wordpress。执行以下 SQL 命令： create database wordpress; 创建新用户管理 WordPress 库为了提高安全性，创建一个新的用户来管理 WordPress 数据库。从 MySQL 5.7 版本开始，系统默认启用密码强度验证插件 validate_password。您可以通过以下命令查看当前的密码强度规则： show variables like %password%; 在本教程中，我们将创建一个用户名为 user 的新用户，密码设置为 PASSword123.。执行以下命令创建新用户： create user user@localhost identified by PASSword123.; 接着，赋予新用户对 wordpress 数据库的所有权限： grant all privileges on wordpress.* to user@localhost; 为了使配置生效，执行： flush privileges; 最后，退出 MySQL 系统： exit; WordPress 配置接下来，下载 WordPress 并将其移动到网站根目录。首先，进入 Nginx 网站根目录，下载 WordPress 的压缩包。本示例中下载的是英文版本： cd /usr/share/nginx/htmlwget https://wordpress.org/wordpress-5.4.2.zip 如果您需要安装 WordPress 的中文版本，则可以使用以下命令： wget https://cn.wordpress.org/latest-zh_CN.zip 请注意，后续操作中，您需要将压缩包的文件名替换为 latest-zh_CN.zip。 解压 WordPress 压缩包： unzip wordpress-5.4.2.zip 在 WordPress 安装目录下，将 wp-config-sample.php 文件复制为 wp-config.php，并将原文件作为备份： cd /usr/share/nginx/html/wordpresscp wp-config-sample.php wp-config.php 接下来，编辑 wp-config.php 文件以添加数据库连接信息： vim wp-config.php 按 i 键切换至编辑模式，并根据您已配置的 WordPress 数据库信息，修改以下 MySQL 相关配置： // ** MySQL 设置 - 具体信息来自您正在使用的主机 ** ///** WordPress数据库的名称 */define(DB_NAME, wordpress);/** MySQL数据库用户名 */define(DB_USER, user);/** MySQL数据库密码 */define(DB_PASSWORD, PASSword123.);/** MySQL主机 */define(DB_HOST, localhost); 完成后，按下 Esc 键并输入 :wq，然后按回车键保存并退出配置文件。 Nginx 配置接下来，您需要修改 Nginx 的配置文件以适配 WordPress。使用以下命令打开 Nginx 配置文件： vi /etc/nginx/conf.d/default.conf 在文件中按 i 键进入编辑模式，找到 location / 大括号内的 root 指令，将其替换为 WordPress 的根目录。例如： root /usr/share/nginx/html/wordpress; 同时，在 location ~ \\.php$ 大括号内，做相同的修改。完成后，按 Esc 键输入 :wq 保存并退出。 最后，重启 Nginx 服务以使配置生效： systemctl restart nginx 安装并登录 WordPress访问 https://localhost:80 ，这将引导您进入 WordPress 的安装页面。按照说明填写网站的基本信息，然后单击“安装 WordPress”按钮。填写信息参数说明： 站点标题：您 WordPress 网站的名称，例如：demowp。 用户名：用于登录 WordPress 的用户名，建议选择安全性高的名称，例如：testwp。 密码：登录 WordPress 所需的密码，强烈建议使用安全性高的密码，例如：Wp.123456。 您的电子邮件：用于接收重要通知的电子邮件，例如：1234567890@aliyun.com。 完成信息填写后，单击“登录”按钮。输入您刚刚设置的用户名和密码，成功后您将进入 WordPress 的管理后台。 其他问题WordPress 中设置固定链接后，跳转页面无法访问。为了让搜索引擎更好地收录您的网站，建议您在 WordPress 中设置伪静态链接。但在设置固定链接之前，需要在 Nginx 服务器中配置伪静态规则。打开 Nginx 配置文件： vi /etc/nginx/conf.d/default.conf 按 i 键进入编辑模式，在 location / 大括号内，添加以下代码： if (-f $request_filename/index.html)\trewrite (.*) $1/index.html break;if (-f $request_filename/index.php)\trewrite (.*) $1/index.php;if (!-f $request_filename)\trewrite (.*) /index.php; 保存退出文件后重启 Nginx 服务： systemctl restart nginx WordPress 中更新版本、上传主题或插件时，提示需要 FTP 登录凭证或无法创建目录。打开 WordPress 的配置文件： vim /usr/share/nginx/html/wordpress/wp-config.php 在文件的最下方，添加以下代码： define(FS_METHOD,direct);define(FS_CHMOD_DIR, 0777);define(FS_CHMOD_FILE, 0777); 保存并退出配置文件。返回 WordPress 仪表盘，刷新页面。这将有助于解决需要输入 FTP 登录凭证的问题。如果问题依然存在，您可能需要更新 WordPress 网站根目录的权限，将其用户更新为 Nginx 对应的用户。在本示例环境中，这个用户是 nginx： chown -R nginx /usr/share/nginx/html/wordpress","categories":["0.平台","服务器","博客"]},{"title":"FTP站点","path":"/2024/12/18/0-平台-Linux-网络-FTP-FTP站点/","content":"FTP（File Transfer Protocol）是一个基于客户端服务器架构的文件传输协议，支持两种工作模式： 主动模式：客户端向 FTP 服务器发送端口信息，服务器主动连接该端口。 被动模式：FTP 服务器开启并发送端口信息给客户端，客户端连接服务器的端口，服务器被动接受连接。 说明：大多数 FTP 客户端运行在局域网中，通常没有独立的公网 IP 地址，并且可能会被防火墙拦截。在主动模式下，FTP 服务器连接客户端将面临更多困难。因此，除非有特殊需求，否则建议将 FTP 服务器配置为被动模式。 FTP 支持以下三种认证模式： 匿名用户模式：允许任何人无需密码直接登录 FTP 服务器。此模式安全性最低，通常只用于存放不重要的公开文件，生产环境中不推荐使用。 本地用户模式：依赖于 Linux 系统的本地账号进行验证，相较于匿名模式更为安全。 虚拟用户模式：FTP 服务器专用的用户，限制访问 Linux 系统的其他资源，进一步提升 FTP 服务器的安全性。 本文主要介绍如何在被动模式下，使用本地用户访问 FTP 服务器的配置方法。关于匿名模式的配置方式、以及第三方 FTP 客户端工具的使用说明，请参见常见问题部分。 安装 vsftpd安装 vsftpd 运行以下命令进行安装： dnf install -y vsftpd 安装成功时，系统将显示类似如下的信息：vsftpd 3.0.3。 设置 FTP 服务开机自启动 使用以下命令： systemctl enable vsftpd.service 启动 FTP 服务 运行以下命令： systemctl start vsftpd.service 说明：如果提示错误信息 Job for vsftpd.service failed because the control process exited with error code，请排查以下问题： 如果网络环境不支持 IPv6，打开配置文件，修改 listen_ipv6=YES 为 listen_ipv6=NO： vim /etc/vsftpd/vsftpd.conf 检查 MAC 地址是否匹配。使用命令 ifconfig 查看 MAC 地址，并在 /etc/sysconfig/network-scripts/ifcfg-xxx 配置文件中新增或修改：HWADDR=MAC地址。 查看 FTP 服务的监听端口 使用以下命令： netstat -antup | grep ftp 如果看到输出中包含端口 21，表示 FTP 服务已成功启动。 此时，vsftpd 默认启用了本地用户模式，但您还需要进行进一步配置才能正常使用 FTP 服务。 配置 vsftpd为了确保数据安全，本节将详细介绍如何在被动模式下配置本地用户以访问 FTP 服务器。 为 FTP 服务创建 Linux 用户使用以下命令创建一个名为 ftptest 的用户： adduser ftptest 设置用户密码运行命令： passwd ftptest 根据命令行提示设置 FTP 用户的密码。 创建 FTP 服务使用的文件目录用以下命令创建： mkdir /var/ftp/test 创建测试文件使用以下命令： touch /var/ftp/test/testfile.txt 更改目录的拥有者运行以下命令，确保 ftptest 用户对目录拥有权限： chown -R ftptest:ftptest /var/ftp/test 修改 vsftpd.conf 配置文件打开配置文件： vim /etc/vsftpd/vsftpd.conf 在打开的文件中按 i 进入编辑模式，进行以下配置： # 禁止匿名登录FTP服务器anonymous_enable=NO# 允许本地用户登录local_enable=YES# 启用IPv4listen=YES# 注释掉以下行以禁用IPv6# listen_ipv6=YES# 设置登录后所在目录local_root=/var/ftp/test# 用户被限制在主目录chroot_local_user=YES# 启用例外用户名单chroot_list_enable=YES# 指定例外用户列表文件（可不包含用户）chroot_list_file=/etc/vsftpd/chroot_list# 开启被动模式pasv_enable=YESallow_writeable_chroot=YES# 设置被动模式的公网IPpasv_address=FTP服务器公网IP地址# 设置被动模式下的端口范围pasv_min_port=port numberpasv_max_port=port number 重要：在修改配置文件时，请注意格式问题，如多余的空格会导致服务无法重启。 保存并退出编辑模式按 Esc 退出，然后输入 :wq 并按 回车 保存并关闭文件。 创建 chroot_list 文件运行以下命令： vim /etc/vsftpd/chroot_list 在文件中按 i 进入编辑模式，输入例外用户名单。如果没有例外用户，文件内容可以留空。 重启 vsftpd 服务使用以下命令生效配置： systemctl restart vsftpd.service 设置安全组在搭建完 FTP 站点后，需在实例的安全组设定入方向规则，放行 FTP 相关端口。具体操作见添加安全组规则。 说明：许多客户端位于局域网，IP 地址经过 NAT 转换，使用 ipconfig 或 ifconfig 返回的 IP 可能不是实际的公网 IP。若客户端无法登录 FTP 服务器，请再次检查其真实公网 IP。 在被动模式下，您需要开放 21 端口，以及在配置文件 /etc/vsftpd/vsftpd.conf 中指定的 pasv_min_port 到 pasv_max_port 之间的所有端口。例如： 规则方向 授权策略 协议类型 端口范围 授权对象 入方向 允许 自定义 TCP 2121 所有要访问 FTP 服务器的客户端公网 IP 地址（多个地址用逗号隔开）如允许所有客户端访问则为 0.0.0.0/0。 入方向 允许 自定义 TCP pasv_min_portpasv_max_port 如：5000050010 所有要访问 FTP 服务器的客户端公网 IP 地址（多个地址用逗号隔开）如允许所有客户端访问则为 0.0.0.0/0。 客户端测试您可以使用 FTP 客户端、Windows 命令行工具或浏览器来测试 FTP 服务器。我们将以 Windows Server 2012 R2 64 位系统为例，介绍访问步骤： 在本地主机上，打开文件资源管理器。 在地址栏中输入 ftp://FTP服务器公网IP地址:FTP端口，例如：ftp://121.43.XX.XX:21。 在弹出的登录框中，输入之前设置的 FTP 用户名和密码，然后点击登录。 登录成功后，您可以看到 FTP 服务器指定目录下的文件，例如： 测试文件 testfile.txt。 vsftp 配置文件及参数说明在 /etc/vsftpd 目录下的文件说明如下： /etc/vsftpd/vsftpd.conf：vsftpd 的核心配置文件。 /etc/vsftpd/ftpusers：黑名单文件，列出的用户将无法访问 FTP 服务器。 /etc/vsftpd/user_list：白名单文件，列出的用户可以访问 FTP 服务器。 配置文件 vsftpd.conf 参数说明如下：用户登录控制参数： 参数 说明 anonymous_enableYES 允许匿名用户访问 no_anon_passwordYES 匿名用户登录时不询问口令 anon_root(none) 匿名用户主目录 local_enableYES 允许本地用户登录 local_root(none) 本地用户的主目录 用户权限控制参数： 参数 说明 write_enableYES 允许用户上传文件（全局控制） local_umask022 本地用户上传文件的权限 file_open_mode0666 上传文件的权限，配合 umask 使用 anon_upload_enableNO 匿名用户不能上传文件 anon_mkdir_write_enableNO 匿名用户不能创建目录 anon_other_write_enableNO 匿名用户没有修改删除权限 chown_usernamelightwiter 匿名上传文件所属的用户名","categories":["0.平台","Linux","网络","FTP"]},{"title":"Flask模块","path":"/2024/12/18/1-语言-Python-Flask模块/","content":"什么是 Flask？Flask 是一个用 Python 编写的轻量级 Web 框架。它以简单、灵活和可扩展著称，特别适合快速开发和原型设计。Flask 遵循 WSGI(Web Server Gateway Interface)标准，并使用 Jinja2 模板引擎。它的核心设计是最小化默认功能，同时允许通过插件和扩展轻松添加所需的功能。 Flask 的特点 轻量级：只提供基础的 Web 开发功能，没有强制性的项目结构。 模块化和可扩展性：通过扩展支持数据库 ORM（如 SQLAlchemy）、表单处理（如 WTForms）等功能。 简洁清晰：非常适合初学者，代码简单易读。 社区活跃：拥有大量文档、教程和第三方扩展支持。 学习 Flask 的关键路线1. 基础知识 Python 基础：掌握 Python 语法、函数、模块和包的使用。 HTTP 协议：了解 HTTP 的请求方法（GET、POST 等）、状态码、URL、请求头和响应头。 HTMLCSSJS：掌握基本的前端技术，用于构建用户界面。 2. Flask 核心概念 安装与快速开始： 使用 pip install flask 安装 Flask。 学习构建一个简单的 “Hello, World” 应用。 路由与视图函数： 学习使用 @app.route() 定义路由。 理解动态路由和 URL 变量。 模板引擎： 学习使用 Jinja2 模板引擎。 理解模板继承和动态渲染 HTML。 请求与响应： 使用 request 解析表单数据、查询参数和文件上传。 使用 Response 对象构建自定义响应。 静态文件： 学习如何提供 CSS、JS 和图片等静态文件。 表单处理： 学习如何处理 HTML 表单，初步了解 CSRF 保护。 3. 高级功能 **蓝图 (Blueprints)**： 理解模块化应用的构建方式。 通过蓝图拆分大项目，提高代码组织性。 数据库： 学习 Flask-SQLAlchemy 集成。 掌握基本的 CRUD 操作。 认证与授权： 使用 Flask-Login 实现用户登录和会话管理。 学习基于角色的权限控制。 错误处理： 自定义错误页面（如 404 和 500）。 中间件： 理解请求钩子（before_request、after_request）的作用。 API 开发： 使用 Flask 构建 RESTful API。 学习如何使用 Flask-RESTful 或 Flask-RESTX。 4. 部署与优化 部署： 使用 Gunicorn、uWSGI 等部署 Flask 应用。 使用 Docker 打包和部署 Flask 项目。 日志和调试： 配置日志记录。 学习调试工具（如 Flask-DebugToolbar）。 性能优化： 学习缓存机制（如 Flask-Caching）。 使用 CDN 提升静态资源加载速度。 5. 综合项目 构建一个完整的 Web 应用： 用户认证系统（注册、登录、注销）。 数据库操作（例如博客或留言板）。 前后端分离（如使用前端框架 Vue.js 或 React）。 6. 扩展阅读 Flask 官方文档：https://flask.palletsprojects.com/ 学习 Flask 扩展，如： Flask-Mail（邮件发送） Flask-Migrate（数据库迁移） Flask-SocketIO（实时通信） 通过以上学习路线，逐步掌握 Flask 的核心功能和常见扩展，可以高效开发自己的 Web 应用。","categories":["1.语言","Python"]},{"title":"公众号介绍","path":"/2024/12/18/0-平台-服务器-微信-公众号介绍/","content":"公众号类型订阅号 普通订阅号：普通订阅号是最基本的公众号类型，适合个人用户和小型企业用来发布信息和与用户互动。普通订阅号的功能相对简单，只能群发消息，每个用户在公众号列表中只能看到一条消息，无法发送服务消息。 认证订阅号：相比于普通订阅号，认证订阅号可以提供更多的接口和功能，比如自定义菜单、信息推送和品牌展示等。认证后，可以享受更高的用户信任度及服务质量。 服务号 普通服务号：针对中大型企业，具有较强的服务功能，比如提供更复杂的支付、客服以及信息推送功能。普通服务号每月只能群发 4 条消息，但更接近于用户的需求。 认证服务号：认证服务号是服务号的加强版，提供完整的 API 接口，支持更多复杂的应用，如企业内部管理、客户服务等。认证后，服务号可以定制更多增值服务和功能，适合需要广泛与用户进行互动的大型企业。 服务方式 公众号消息会话：这一功能允许公众号与用户之间进行消息的双向交流。包括被动回复，即用户主动发送信息后，公众号可以根据内容进行智能回复，这样可以极大提升用户体验。 公众号内嵌网页：通过内嵌网页，公众号可以直接提供一些服务，如在线商城、活动报名等，用户可以在微信中完成更多操作，无需跳转到外部浏览器。 公众号消息类型 群发消息：公众号可以定期向所有关注的用户发送一条消息，保持用户的活跃度和对品牌的关注。 被动回复消息：用户主动给公众号发送消息后，公众号可以在不主动发布内容的情况下，做出相应。这让用户与公众号的互动显得自然且流畅。 客服消息：当用户主动发消息到公众号，公众号在 48 小时内可以无限制地回复。这对于解决用户问题、提供支持以及加强客户关系至关重要。 模板消息：公众号可以利用特定的模板来向用户发送内容丰富的消息，比如订单状态更新、活动通知等，保持用户的系统性关注。 公众号的网页接口 接口 1：该接口能让网页获取用户的基本信息，简化用户的登录和交互体验。开发者需要在其网页中添加相关代码。 接口 2：微型 JS-SDK 允许开发者轻松使用微信的功能，比如拍照、录音、定位等，增强网页用户的互动体验。 微信公众号开发 先注册一个微信公众号：访问 注册页面，按步骤完成注册。 注册成功后的设置：登录后，进入微信公众号管理后台，进行公众号设置，包括上传头像、生成二维码以及设定公众号名称等。 微信号设置：设置后，用户可以通过微信号轻松找到你的小程序。 注意事项：对接微信公众平台 填写服务器配置： URL：需设定为可访问的域名或直接的 IP 地址加端口，HTTP 需为 80 端口，HTTPS 则为 443 端口。 Token：用于生成签名，帮助微信服务器识别公众号的服务器。 EncodingAESKey：设置消息加解密密钥，确保消息安全。 验证服务器地址的有效性开发者需自行架设服务器。当填写 URL 并提交后，微信服务器发送 GET 请求到开发者的服务器，携带四个参数，用于验证。 校验流程 对 token、timestamp、nonce 三个参数进行字典序排序。 拼接字符串并进行 SHA1 加密。 比较加密后的字符串与微信返回的 signature，确认请求来源。 校验经典代码示例可以使用以下代码实现上述校验，适用于 Django、Flask、web.py 等框架： import hashlibdef handle(request): try: signature = request.get(signature) timestamp = request.get(timestamp) nonce = request.get(nonce) echostr = request.get(echostr) token = xxxx # 自定义token # 字典序排序 params_list = [token, timestamp, nonce] params_list.sort() temp = .join(params_list) # SHA1加密 sha1 = hashlib.sha1(temp.encode(utf-8)) hashcode = sha1.hexdigest() # 校验 if hashcode == signature: return echostr else: return except Exception as e: return str(e) 使用第三方包 wechatpy 实现通过 wechatpy 简化开发，可以通过如下代码实现： from wechatpy.utils import check_signaturefrom flask import Flask, requestapp = Flask(__name__)def get_all_args(req_dict): echostr = req_dict.get(echostr) signature = req_dict.get(signature) timestamp = req_dict.get(timestamp) nonce = req_dict.get(nonce) return echostr, signature, timestamp, nonce@app.route(/wechat_verify/, methods=[GET])def wechat_verify(): rq_dict = request.args if not rq_dict: return tuple_args = get_all_args(rq_dict) token = current_app.config.get(TOKEN) try: check_signature(token, tuple_args[1], tuple_args[2], tuple_args[3]) except InvalidSignatureException as e: logger.error(e, exc_info=True) return else: return tuple_args[0] 消息发送流程当普通用户向公众号发消息时，微信服务器会将消息以 XML 格式的 POST 数据包发送给开发者设定的 URL。此时，公众号可以覆盖微信提供的自动回复功能，实现更加个性化的响应。 基于 XML 的消息处理微信消息通信使用 XML 数据格式，可以使用 xmltodict 模块处理： **xmltodict.parse()**：将 XML 数据转换为 Python 字典。 **xmltodict.unparse()**：将字典转换为 XML 字符串。 消息格式示例 文本消息： xml ToUserName![CDATA[公众号]]/ToUserName FromUserName![CDATA[粉丝号]]/FromUserName CreateTime1460537339/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[欢迎开启公众号开发者模式]]/Content MsgId6272960105994287618/MsgId/xml 回复文本： xml ToUserName![CDATA[toUser]]/ToUserName FromUserName![CDATA[fromUser]]/FromUserName CreateTime12345678/CreateTime MsgType![CDATA[text]]/MsgType Content![CDATA[你好吗]]/Content/xml 图片消息： xml MsgType![CDATA[image]]/MsgType PicUrl![CDATA[this is a url]]/PicUrl MediaId![CDATA[media_id]]/MediaId/xml 视频消息： xml MsgType![CDATA[video]]/MsgType MediaId![CDATA[media_id]]/MediaId/xml 语音消息： xml MsgType![CDATA[voice]]/MsgType MediaId![CDATA[media_id]]/MediaId Format![CDATA[Format]]/Format/xml 视图处理原则建议将普通消息处理放在一个视图中进行判断和处理，简化视图数量。当处理时间超过 5 秒未完成时，先返回成功或空字符串，避免触发微信的错误处理机制。 实现内嵌网页内嵌网页的实现分为三个步骤： 用户同意授权，获取 code，这是用户的授权书。 通过 code 换取网页授权 access_token，这是微信下发的通信凭证。 拉取用户信息（需 scope 为 snsapi_userinfo）。 设置网页授权回调域名需填写域名，不包括 http:// 等前缀，也可填写 IP 和端口。 获取微信公众号 access_token 接口凭证访问接口： https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=APPIDsecret=APPSECRET 获取微信 IP 地址访问接口： https://api.weixin.qq.com/cgi-bin/getcallbackip?access_token=ACCESS_TOKEN 自定义菜单接口可以通过以下接口自定义微信公众号的菜单按钮： https://api.weixin.qq.com/cgi-bin/menu/create?access_token=ACCESS_TOKEN 支持定义不同的按钮类型，包括扫码、跳转网页等，增强用户参与度。 微信开发文档欲了解更多详细信息和最新更新，访问 微信开发文档。","categories":["0.平台","服务器","微信"]},{"title":"Linux下配置clash代理访问Github","path":"/2024/12/18/3-软件-代理穿透-Linux下配置clash代理访问Github/","content":"安装 Clash可以通过以下链接找到 Clash 的下载地址：Clash Releases。 在下载完成后，记得为 Clash 二进制文件赋予执行权限，并运行以下命令： ./clash-linux-amd64 -d . 这条命令会在当前目录下生成配置文件和 IP 数据库文件。如果 IP 数据库下载失败，您还可以手动下载并将其上传到服务器。接下来，您需要使用本地的配置文件替换默认配置，以下是必要的配置参数： port: 7890socks-port: 7891redir-port: 7892allow-lan: falsemode: Global# 设置日志输出级别（默认级别为 silent，不输出任何内容，以避免日志内容过大导致程序内存溢出）。# 日志级别有 5 种：silent / info / warning / error / debug。级别越高，日志输出量越大，更适合调试。如果需要可以自行开启。log-level: info# Clash 的 RESTful APIexternal-controller: 0.0.0.0:9090# RESTful API 的口令secret: # 您可以将静态网页资源（如 clash-dashboard）放置在某一目录，Clash 将为其提供服务。# external-ui: folderproxies: - name: Standard|广台|IEPL|01 type: ss server: ************* port: 3026 cipher: rc4-md5 password: *************** udp: true plugin: obfs plugin-opts: mode: http host: ****************** 由于默认设置为全局代理，您可以省略源配置文件中的 rules 标签，这样可以显著减小配置文件的体积。 接下来，再次执行命令： ./clash-linux-amd64 -d . 如果执行成功，您将看到代理服务已经启动完毕。 配置 ClashClash 提供了一个方便的 Web 接口用于管理，首先请设置 Web 接口的口令。接着，登录腾讯云控制台，开放 9090 端口以便访问。 在浏览器中，访问以下网址： http://clash.razord.top/#/proxies 在页面中，host 字段填入您的服务器公网 IP，密钥 为上一步设置的口令。通过这个界面，您可以轻松切换代理，查看日志，修改端口等。 完成测试后，确认代理功能正常。为了减少日志输出，您可以将 Clash 的日志记录级别降低，以防止过多日志导致程序崩溃。 要将 Clash 作为后台服务运行，可以使用以下命令： nohup ./clash-linux-amd64 -d . 切记定期更新配置文件，以确保使用最新的代理设置。 在 Linux 终端使用代理使用 proxychains 工具来便捷地在特定环境下使用代理。 安装 proxychains 完成后，您需要修改配置文件 /etc/proxychains4.conf，在 [ProxyList] 项目下添加 Clash 的 socks5 代理监听端口： [ProxyList]# add proxy here ...# meanwhile# defaults set to torsocks5 127.0.0.1 7891 使用代理安装 Metasploit 框架，可以执行以下命令： proxychains curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb msfinstallchmod 755 msfinstallproxychains ./msfinstall 通过这样的方法，您可以确保所有通过 proxychains 发出的请求都能够走 Clash 配置的代理，实现安全与高效的网络访问。","categories":["3.软件","代理穿透"]},{"title":"NFS服务的搭建","path":"/2024/12/18/0-平台-Linux-网络-NFS-NFS服务的搭建/","content":"NFS 简介NFS，即网络文件系统（Network File System），是一种广泛支持的文件系统。它允许不同操作系统之间共享文件和目录，使用户能够像访问本地文件一样，便捷地访问远程系统上的文件。这种功能使得 NFS 在网络环境中至关重要，尤其是在企业和开发者的日常工作中。 NFS 的共享机制建立在对于信任的基础上，因此在向其他用户开放共享资源之前，必须仔细确认对方的可靠性。某些敏感或重要数据不应在不信任的环境下共享，以避免数据泄露的风险。 NFS 的应用场景在嵌入式开发中，NFS 扮演着不可或缺的角色。通过将“根文件系统”保留在主机上，我们可以在开发板启动时，通过 NFS 轻松挂载主机上的根文件系统。这一过程不仅节省了时间，因为不需要每次都把文件系统烧写到开发板的存储设备上，而且还提高了开发的灵活性和效率。相比之下，使用 TFTP（Trivial File Transfer Protocol）需要多次进行单独的文件传输，而 NFS 提供了一个更为简便的解决方案。 NFS 的配置过程以 Ubuntu 为例，我们将详细讲解如何配置 NFS 服务。 Server（服务器端）： PCClient（客户端）： ARM (这里使用同一台机器进行模拟，主要展示安装过程)一、配置服务器端首先，我们需要安装 NFS 服务器程序。可以使用以下命令： sudo apt-get install nfs-kernel-server 在执行命令时，系统会提示输入密码。如果之前已经安装过 NFS，系统会显示“NFS kernel server is already the newest version.”，这意味着我们无需重复安装。 二、配置 NFS 资源NFS 允许挂载的目录和权限在 /etc/exports 文件中进行定义。因此，配置 NFS 服务器的关键在于编辑此文件。 我们可以使用以下命令查看和编辑 /etc/exports 文件： cat /etc/exports 在此文件中，我们需要按照以下方式定义共享目录： 共享目录的绝对路径，例如 /home/fs/qiang。 网络访问控制，使用 * 表示允许所有 IP 地址访问，或指明特定的 IP 地址，例如 192.168.3.51(rw)。 其他参数，如： insecure 表示 NFS 将通过 1024 以上的端口进行通信。 rw 表示给予读写权限。 async 允许系统在写入数据之前处理请求。 root_squash 意味着 root 用户的权限被限制，仅能以普通用户身份访问共享目录。 可以在 /etc/exports 文件中添加如下配置： /home/fs/qiang 192.168.3.51(rw)/home/fs/qiang *(insecure,rw,async,root_squash) 三、手动启动和停止 NFS 服务完成配置后，您可以通过以下命令启动 NFS 服务： sudo /etc/init.d/nfs-kernel-server start 启动服务后，系统会输出正在导出目录的信息。如果配置没有问题，会显示 [ OK ]。 要停止 NFS 服务，请使用： sudo /etc/init.d/nfs-kernel-server stop 若要重新启动 NFS 服务，可以简单地执行： sudo /etc/init.d/nfs-kernel-server restart 要查看 NFS 服务当前状态，可以使用以下命令： sudo /etc/init.d/nfs-kernel-server status 四、查看 NFS 服务器的共享资源使用以下命令可以查看 NFS 服务器当前导出的共享资源： showmount -e 192.168.3.51 这将显示服务器上共享的文件和目录。 五、挂载共享资源在客户端，您可以使用 mount 命令来挂载 NFS 共享资源。命令如下： sudo mount -t nfs 192.168.3.51:/home/fs/qiang /mnt/nfs 这里，-t 指明文件系统类型为 NFS，192.168.3.51 是服务端的 IP 地址，/home/fs/qiang 是服务端的共享目录，而 /mnt/nfs 是客户端的挂载点。 挂载成功后，客户端对挂载的文件系统的操作将与本地文件系统没有区别，用户可以自由地读取和写入数据。 六、卸载共享资源当您完成对共享资源的操作后，可以使用以下命令卸载： sudo umount /mnt/nfs 请注意，如果有其他用户正在使用该共享目录的文件，则无法成功卸载。如果确实需要强制卸载，可以使用： sudo umount -f /mnt/nfs 通过以上步骤，您可以顺利配置和使用 NFS，实现高效的文件共享与管理。","categories":["0.平台","Linux","网络","NFS"]},{"title":"NFS环境配置","path":"/2024/12/18/0-平台-Linux-网络-NFS-NFS环境配置/","content":"配置 TFTP 服务a. 安装 TFTP 服务使用以下命令在系统中安装 TFTP 服务及其守护进程： sudo apt-get install tftp tftpd-hpa 这一步骤确保你拥有一个功能齐全的 TFTP（简易文件传输协议）服务，能够在网络环境中进行文件的传输和共享。 b. 修改配置文件编辑 TFTP 的默认配置文件，以便于调整服务参数： sudo vi /etc/default/tftpd-hpa 在该文件中，可以设置 TFTP 服务器的基本属性，例如服务启动的方式、监听的 IP 地址等。确保根据自己的需求对这些参数进行适当的配置。 c. 修改服务目录指定 TFTP 服务的根目录，不同于默认目录： /home/fs/tftpboot 确保该目录的存在，并具备足够的存储空间以存放要共享的文件。 d. 重启 TFTP 服务保存配置文件后，通过下面的命令重启 TFTP 服务，以应用上述配置： sudo service tftpd-hpa restart 这将重新加载 TFTP 服务，确保新的配置被正确应用。 e. 拷贝内核文件为了保证开发环境能够从虚拟机中下载内核文件，需要将 zImage 文件拷贝到 TFTP 服务的根目录： cp /path/to/zImage /home/fs/tftpboot/ 确保在拷贝之前，zImage 文件已经存在于指定路径。 常见报错 权限不允许检查权限设置，可通过以下命令更改 tftpboot 目录及其子目录的访问权限： chmod 777 /home/fs/tftpboot -R 文件名未找到确保 zImage 文件确实存在于 TFTP 根目录。 确认配置文件中定义的服务目录与实际运行的目录一致。 挂载目录a. 配置 NFS 文件编辑 NFS 导出文件以定义要共享的目录： sudo vi /etc/exports 添加共享目录的配置： /home/fs/nfsboot *(rw,sync,no_subtree_check) 这里 *(rw,sync,no_subtree_check) 的含义是所有客户端可以以读写模式访问这个目录，且文件同步时不会检查子目录。 b. 重启 NFS 服务虽然 NFS 服务默认情况下会一直运行，但在更改配置后，执行以下命令以确保更改生效： sudo service nfs-kernel-server restart c. 拷贝文件系统将 rootfs.tgz 文件系统拷贝到 NFS 的共享目录中： cp /path/to/rootfs.tgz /home/fs/nfsboot/ d. 解压文件解压刚才拷贝的 rootfs.tgz 文件，以便使用： sudo tar -zxvf /home/fs/nfsboot/rootfs.tgz 此命令将文件解压到 nfsboot 目录，方便后续访问。 e. 改变文件权限确保文件系统内的文件和目录对所有用户开放访问权限： sudo chmod 777 /home/fs/nfsboot/rootfs -R 开发板设置a. 设置开发相关 IP在开发板的环境中设置相关的网络参数： setenv serverip 192.168.2.2 // 服务器 IP 地址setenv ipaddr 192.168.2.3 // 开发板 IP 地址setenv netmask 255.255.255.0 // 子网掩码setenv gatewayip 192.168.1.1 // 网关 这些环境变量将确保开发板能够连接到网络和服务器。 b. 设置开发板启动参数定义启动命令，以通过 TFTP 从服务器下载内核文件并启动： setenv bootcmd tftp 20008000 zImage; go 20008000 当开发板启动时，它会自动执行该命令，通过 TFTP 从服务器（192.168.2.2）下载 zImage 文件到开发板内存地址 0x20008000，下载完成后，CPU 从该地址开始执行内核。 如果你想使用 zImage_all 内核进行启动，可以按照以下步骤操作： 重启开发板。 设置新的启动命令： setenv bootcmd tftp 20008000 zImage_all; go 20008000 使用命令保存更改： save 启动开发板： boot c. 设置文件系统挂载方式配置开发板的启动参数，以指定 NFS 文件系统的相关信息： setenv bootargs root=nfs nfsroot=192.168.2.2:/home/fs/nfsboot/rootfs ip=192.168.2.3 init=/linuxrc console=ttySAC0,115200 这些设置将确保开发板在启动时通过 NFS 挂载指定的文件系统。 d. 保存设置注意，以上所有设置仅在内存中生效，重启后将会丢失。因此，需要将设置保存到非易失性存储中： saveenv 各种方式启动开发板 按电源键重启开发板。 在启动命令行输入 boot 命令。 使用以下命令从 TFTP 下载内核： tftp 20008000 zImagego 20008000 通过以上步骤，你可以轻松配置和启动开发板，以便于进行开发和测试。","categories":["0.平台","Linux","网络","NFS"]},{"title":"NFS配置","path":"/2024/12/18/0-平台-Linux-网络-NFS-NFS配置/","content":"配置 NFS（网络文件系统）NFS（Network File System）是一种允许用户在网络中访问和共享文件的协议。它使得跨不同机器访问文件成为可能，简化了文件管理。在实际应用中，比如在企业环境中，常常需要将配置文件、共享文档或应用程序集中管理。 主要功能 共享：通过网络将文件系统共享给所有需要的用户或计算机。 挂载：使得远程的文件系统像本地文件系统一样被访问。 1. 安装 NFS首先确保你已经安装了 NFS 服务器，如果未安装，可以使用以下命令进行安装： sudo apt-get install nfs-kernel-server 请注意，你可能需要有管理员权限才能执行此命令，通常需要输入密码。 2. 配置 NFS安装完成后，接下来需要配置 NFS。你需要编辑 NFS 服务器的导出文件 /etc/exports，这是一个保存共享目录及其权限的配置文件。使用下面的命令打开文件： sudo vi /etc/exports 在文件的最后一行添加以下内容，以共享 /nfsboot 目录： /nfsboot * (rw,sync,no_subtree_check) nfsboot：这是你希望共享的目录。 *****：表示允许所有主机访问该目录。你可以修改为指定的 IP 地址或主机名来限制访问。 rw：表示读写访问权限。 sync：确保数据在响应请求之前写入磁盘，增加数据的安全性。 no_subtree_check：关闭子目录检查，可提高性能，特别是当一个大的目录被共享时。 如果 /nfsboot 目录不存在，你需要先创建它。可以使用以下命令： sudo mkdir /nfsboot 然后，修改其权限以确保其他用户可以访问： sudo chmod 777 /nfsboot -R 这里的 777 权限允许所有用户进行读、写和执行操作。使用 -R 选项可以递归地更改权限，以确保目录内的文件也继承该权限。 3. 重启 NFS 服务修改配置后，需要重启 NFS 服务以应用更改。执行如下命令： sudo /etc/init.d/nfs-kernel-server restart 当你看到 4 个连续的 “OK” 消息时，说明服务已经成功启动，且配置生效。 4. 测试 NFS 配置接下来，进行 NFS 的挂载测试。首先，创建一个临时挂载点： cd /mntsudo mkdir /mnt/tempsudo chmod 777 /mnt/temp -R 然后，执行挂载操作，将远程 NFS 目录挂载到本地的 /mnt/temp： sudo mount -t nfs 127.0.0.1:/nfsboot /mnt/temp 在这里，127.0.0.1 是本地主机的 IP 地址，/nfsboot 是你之前配置的共享目录，/mnt/temp 是本地挂载点。 完成测试后，别忘了卸载 NFS 目录以释放挂载： sudo umount /mnt/temp 通过这些步骤，你可以成功配置和测试 NFS。这样，你的网络中的其他机器便可以轻松访问共享的文件系统。","categories":["0.平台","Linux","网络","NFS"]},{"title":"FTP服务介绍及配置","path":"/2024/12/18/0-平台-Linux-网络-FTP-FTP服务介绍及配置/","content":"FTP 协议 文件传输协议（File Transfer Protocol，FTP）标准是在 RFC959 说明的。 FTP 协议是一个客户机服务器系统 。 FTP 协议定义了一个在远程计算机系统和本地计算机系统之间传输文件的一个标准。 FTP 运行在 OSI 模型的应用层，并利用传输控制协议 TCP 在不同的主机之间提供可靠的数据传输。 由于 TCP 是一种面向连接的、可靠的传输协议，正是这种可靠性保证了 FTP 文件传输的可靠性。 FTP 在文件传输中还具有一个重要的特点，支持断点续传功能，可以大幅度地减小 CPU 和网络带宽的开销。 FTP 的数据传输模式 主动传输模式– FTP 的数据连接和控制连接的方向是相反的，也就是说，是服务器向客户端发起一个用于数据传输的连接。客户端的连接端口是由服务器端和客户端通过协商确定的。 被动传输模式– FTP 的数据连接和控制连接的方向是一致的，也就是说，是客户端向服务器发起一个用于数据传输的连接。客户端的连接端口是发起这个数据连接请求时使用的端口号。 FTP 的典型消息|:—:|:—:| |消息号|含义| |125|数据连接打开，传输开始| |200|命令 OK| |226|数据传输完毕| |331|用户名 OK，需要输入密码| |425|不能打开数据连接| |426|数据连接被关闭，传输被中断| |452|错误写文件| |500|语法错误，不可识别的命令| FTP 服务的使用者 根据 FTP 服务器服务的对象不同可以将 FTP 服务的使用者分为三类：– 本地用户（real 用户）– 虚拟用户（guest 用户）– 匿名用户 Linux 环境下的 FTP 服务器 Wu-ftpd– 历史最久的非商业 ftp 服务器程序之一– 安全性较 Proftpd 和 vsftpd 差– Wu-ftpd 的主页为 http://www.wu-ftpd.org/ Proftpd– 完全独立而完整、重新改写的 FTP Server– 为了追求一个安全且易于设定的 FTP Server 而编制的– Proftpd 的主页为 http://www.proftpd.org/ vsftpd– 编制者的初衷就是代码的安全性– 性能稳定且速度快– vsftpd 的主页为 http://vsftpd.beasts.org/ 安装并启动 vsftpd • 安装– # rpm –ivh vsftpd-1.1.3-8.i386.rpm 启动和停止– # service vsftpd start – # service vsftpd stop– # service vsftpd restart vsftpd 的配置文件 etcvsftpdvsftpd.conf– 主配置文件 etcpam.dvsftpd– vsftpd 的 PAM 配置文件 etcvsftpd.ftpusers– 指定了哪些用户不能访问 FTP 服务器。 etcvsftpd.user_list– 当在etcvsftpdvsftpd.conf 中设置了 userlist_enable YES 且 userlist_denyNO 时，仅仅允许etcvsftpd.user_list 中指定的用户访问 FTP 服务器。 vsftpd 的默认配置 查看 RedHat 9.0 中的默认配置– # grep -v “#” etcvsftpdvsftpd.conf 默认配置说明– 允许匿名用户和本地用户登录；– 匿名用户的登录名为 ftp 或 anonymous，口令为一个 Email 地址；– 匿名用户不能离开匿名服务器目录varftp，且只能下载不能上传；– 本地用户的登录名为本地用户名，口令为此本地用户的口令；– 本地用户可以离开自家目录切换至有权访问的其他目录，并在权限允许的情况下进行上传下载；– 写在文件etcvsftpd.ftpusers 中的本地用户禁止登录。– 要使用户在下载文件时能够续传文件，必须保证文件对其他用户有读的权限。 配置访问速度和每客户的连接数限制 设置最大传输速率限制 例如下面的配置： local_max_rate50000 anon_max_rate30000 将使本地用户的最大传输速率为 50kbytessec，匿名用户的最大传输速率为 30kbytessec。 设置每客户的连接数限制 例如下面的配置： max_per_ip3 将指明每个客户机的最大连接数为 3。 配置允许匿名用户上传 允许匿名用户上传– anon_upload_enable– anon_mkdir_write_enable 注意– 只有设置 anon_world_readable_onlyNO 后，才能开放匿名用户的读权限，即：浏览此服务器中全部的内容。– 续传必须添加如下的配置语句 anon_other_write_enableYES– 匿名用户对varftpincoming 目录而言是其他用户，所以必须为此目录添加对其他用户的可写权限才可上传 ，即此目录权限的数字表示是 707 配置 chroot 如果希望用户登录后不能切换到自家目录以外的目录，则需要设置 chroot 选项，涉及如下选项：– chroot_local_user– chroot_list_enable– chroot_list_file 有两种设置 chroot 的方法：– 1. 设置所有的本地用户执行 chroot，只要将 chroot_local_user 的值设为 YES 即可，即： chroot_local_userYES– 2. 设置指定的用户执行 chroot 需要如下的设置： chroot_local_userNO chroot_list_enableYES chroot_list_file etcvsftpd.chroot_list 这样，只有etcvsftpd.chroot_list 文件中指定的用户才可以执行 chroot。 配置基于本地用户的访问控制 限制指定的本地用户不能访问，而其他本地用户可访问– userlist_enableYES– userlist_denyYES– userlist_file etcvsftpd.user_list– 使文件etcvsftpd.user_list 中指定的本地用户不能访问 FTP 服务器，– 而其他本地用户可访问 FTP 服务器。 限制指定的本地用户可以访问，而其他本地用户不可访问– userlist_enable YES– userlist_deny NO– userlist_file etcvsftpd.user_list– 使文件etcvsftpd.user_list 中指定的本地用户可以访问 FTP 服务器，– 而其他本地用户不可以访问 FTP 服务器。","categories":["0.平台","Linux","网络","FTP"]},{"title":"FTP服务搭建","path":"/2024/12/18/0-平台-Linux-网络-FTP-FTP服务搭建/","content":"安装 VSFTPD 默认使用**21端口作为服务端口，需要保证服务器的规则启用的21** 端口 vsftpd 是在 Linux 上被广泛使用的 FTP 服务器，根据其官网介绍，它可能是 UNIX-like 系统下最安全和快速的 FTP 服务器软件。 sudo apt install vsftpd 安装完成后，通过 sudo netstat -nltp | grep 21 查看到 vsftpd 已经启动并监听了 21 端口 或者手动开启 vsftpd 服务 sudo systemctl start vsftpd.service 配置用户访问目录新建用户主目录sudo mkdir /home/uftp 执行完后，在这里 homeuftp 就能看到新建的文件夹 uftp 了。 创建登录欢迎文件： sudo touch /home/uftp/welcome.txt 方便用户登录后可以看到欢迎信息，并且确定用户确实登录到了主目录上。 用户的主目录是用户通过 FTP 登录后看到的根目录 新建用户 uftp 并设置密码创建一个用户 uftp： sudo useradd -d /home/uftp -s /bin/bash uftp 为用户 uftp 设置密码： sudo passwd uftp 删除掉 pam.d 中 vsftpd，因为该配置文件会导致使用用户名登录 ftp 失败： sudo rm /etc/pam.d/vsftpd 限制该用户仅能通过 FTP 访问限制用户 uftp 只能通过 FTP 访问服务器，而不能直接登录服务器： sudo usermod -s /sbin/nologin uftp 修改 vsftpd 配置 sudo chmod a+w /etc/vsftpd.conf 修改 etcvsftpd.conf 文件中的配置（直接将如下配置添加到配置文件最下方）： # 限制用户对主目录以外目录访问 chroot_local_user=YES # 指定一个 userlist 存放允许访问 ftp 的用户列表 userlist_deny=NO userlist_enable=YES # 记录允许访问 ftp 用户列表 userlist_file=/etc/vsftpd.user_list # 不配置可能导致莫名的530问题 seccomp_sandbox=NO # 允许文件上传 write_enable=YES # 使用utf8编码 utf8_filesystem=YES 新建文件 /etc/vsftpd.user_list，用于存放允许访问 ftp 的用户： sudo touch /etc/vsftpd.user_list``sudo chmod a+w /etc/vsftpd.user_list 修改 /etc/vsftpd.user_list ，加入刚刚创建的用户： echo uftp /etc/vsftpd.user_list 设置访问权限设置主目录访问权限（只读）： sudo chmod a-w /home/uftp 新建公共目录，并设置权限（读写）： sudo mkdir /home/uftp/public sudo chmod 777 -R /home/uftp/public 重启 vsftpd 服务： sudo systemctl restart vsftpd.service 访问 FTP 服务根据您个人的工作环境，选择一种方式来访问已经搭建的 FTP 服务 通过 FTP 客户端工具访问 FTP 客户端工具众多，下面推荐两个常用的： FileZilla - 跨平台的 FTP 客户端，支持 Windows 和 Mac WinSCP - Windows 下的 FTP 和 SFTP 连接客户端 ftp:liuluhua:密码@ip 地址","categories":["0.平台","Linux","网络","FTP"]},{"title":"TFTP功能实现简介","path":"/2024/12/18/0-平台-Linux-网络-FTP-TFTP功能实现简介/","content":"服务端 Server 网络初始化 等待客户连接 接受命令 命令 动作 get filename 判断文件是否存在，如果不存在，发送错误编号；如果存在，打开文件，读取文件，写到读写套接字，关闭文件 put filename 创建文件，读套接字，写入文件，关闭文件 list 打开服务器共享目录，读目录，发送到套接字，关目录 客户机 Client 网络初始化 连接服务器 判断命令 命令 动作 get filename 在当前目录创建文件，读套接字，写入文件，关闭文件 put filename 打开文件，写入套接字，关闭文件 list 读套接字 quit 退出 help 打印帮助信息 通信内容ID+文件内容 FileContent ID 含义 0 正常通信 1 表示有错误 2 表示文件结束","categories":["0.平台","Linux","网络","FTP"]},{"title":"TFTP配置","path":"/2024/12/18/0-平台-Linux-网络-FTP-TFTP配置/","content":"配置 TFTP（文件传输协议）TFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于在计算机网络中进行文件的上传和下载。下面是详细的配置步骤，确保顺利地实现文件传输功能。 1) 安装 TFTP（已安装）首先，检查 TFTP 是否已经安装。如果未安装，可以通过以下命令安装所需的相关软件包： sudo apt-get install tftp-hpa tftpd-hpa 这里，tftp-hpa 是 TFTP 客户端，而 tftpd-hpa 是 TFTP 服务器。通过这条命令可以确保你的系统中有适当的工具来进行文件传输。 2) 配置 TFTP接下来，需要配置 TFTP 服务器。使用下面的命令打开配置文件： sudo vi /etc/default/tftpd-hpa 在文件中，找到并修改以下内容： TFTP_DIRECTORY=/tftpboot 注意事项如果 /tftpboot 目录不存在，需要手动创建它： sudo mkdir /tftpboot 添加权限：确保 TFTP 服务器能够访问该目录，并允许读写操作。使用以下命令更改目录权限： sudo chmod 777 /tftpboot -R 这里，-R 参数表示递归更改权限，使所有子目录和文件都继承这个权限设置。选择 777 权限意味着所有用户（包括普通用户）都有读、写和执行权限，方便进行文件的上传和下载，但在实际生产环境中，建议根据安全需求设置更严格的权限。 3) 重启服务完成配置后，需要重启 TFTP 服务，以使更改生效。使用以下命令重启服务： sudo /etc/init.d/tftpd-hpa restart 重启服务后，TFTP 服务器将使用新的配置进行工作。 4) 测试测试步骤确保 TFTP 在本机正常运行。首先，选择一个目录： cd ~ 接下来，连接到本地 TFTP 服务器，使用以下命令： tftp 127.0.0.1 这里的 127.0.0.1 是本地回环地址，指向本机。连接后，您将进入 TFTP 交互环境，您可以使用以下命令进行文件 transfer： 从 tftpboot 下载文件： tftp get xx 这条命令会尝试从 /tftpboot 目录中下载名为 xx 的文件到当前目录。 将文件上传到 tftpboot： tftp put xx 这条命令会将当前目录下的名为 xx 的文件上传到 /tftpboot 目录中。 退出 TFTP 环境： tftp quit 输入 quit 命令可以安全退出 TFTP 客户端。 通过上述步骤，您可以顺利配置并测试 TFTP 守护程序。确保在测试过程中，检查任何错误信息并根据需要调整配置或权限设置。","categories":["0.平台","Linux","网络","FTP"]},{"title":"快速搭建 FTP 服务","path":"/2024/12/18/0-平台-Linux-网络-FTP-快速搭建-FTP-服务/","content":"通过 yum 安装 vsftpd首先，打开终端并使用以下命令安装 vsftpd（非常安全的 FTP 服务器）： yum install -y vsftpd 此命令将从 CentOS 软件库中下载并安装 vsftpd 及其依赖包，安装完成后，您便可以配置和启动 FTP 服务。 修改配置文件 etcvsftpdvsftpd.conf接下来，使用文本编辑器打开配置文件以进行自定义设置： vim /etc/vsftpd/vsftpd.conf 配置示例在文件中，您可以看到一些原有的初始配置。以下是完整的具体配置，确保根据您的需求进行适当调整： # 原有初始配置local_umask=022 # 设置用户在上传文件时的权限掩码dirmessage_enable=YES # 启用目录消息，允许用户在进入目录时看到消息xferlog_enable=YES # 启用传输日志，记录所有传输的信息connect_from_port_20=YES # 通过端口 20 进行数据连接xferlog_std_format=YES # 使用标准格式记录传输日志tcp_wrappers=YES # 启用 TCP 包裹（用于访问控制）local_enable=YES # 允许本地用户登录write_enable=YES # 允许写入权限pam_service_name=vsftpd # 定义 PAM 服务名# 不支持匿名访问anonymous_enable=NO # 禁用匿名用户访问，保护敏感数据# 所有用户都被限制在其主目录下chroot_local_user=YES # 将本地用户限制在其主目录中chroot_list_enable=NO # 禁止用户列表allow_writeable_chroot=YES # 允许可写的 chroot 目录# 支持 IPv4 及 IPv6, 监听端口 8021listen=NO # 不在 IPv4 上监听listen_ipv6=YES # 在 IPv6 上监听listen_port=8021 # 设置监听端口为 8021# 只允许 userlist_file 文件中的用户可访问 ftpuserlist_enable=YES # 启用用户列表功能userlist_deny=NO # 允许列表中的用户登录userlist_file=/etc/vsftpd/user_list # 指定用户列表文件的位置# ftp 用户主目录local_root=/data/ftp # 设置本地 FTP 用户的根目录# passive 模式，数据端口范围自定义(6000-6010)pasv_enable=YES # 启用被动模式pasv_min_port=6000 # 设置被动模式下的最小端口pasv_max_port=6010 # 设置被动模式下的最大端口 注意，您可以根据需要修改端口和根目录的设置，以提供最适合您网络环境的配置。例如，如果您希望 FTP 服务在更常见的 21 端口上运行，可以将 listen_port 改为 21。 配置允许登录的用户 etcvsftpduser_list在同样的位置，编辑用户列表文件，以定义可以访问 FTP 的用户： vim /etc/vsftpd/user_list 在文件中输入允许登录的用户名，每个用户占一行，例如： ftpUser 添加的信息必须与您将要创建的 FTP 用户名相符。如果您将 userlist_deny 设置为 YES，则该文件中的用户将不被允许访问。 创建 ftp 登录用户接下来，创建一个组和用户来进行 FTP 登录： groupadd ftpGroup # 创建 FTP 用户组useradd -d /opt/reconciliation -s /sbin/nologin -g ftpGroup -G root ftpUser # 创建 FTP 用户passwd ftpUser # 为新用户设置密码 通过以上命令，您创建了一个名为 ftpUser 的用户，并将其添加到 ftpGroup 中。注意，/opt/reconciliation 是该用户的主目录，您可以根据需要进行调整。 创建 ftp 文件存放目录在创建用户之后，您需要为 FTP 文件设置存放目录： mkdir -p /data/ftp # 创建 FTP 数据存放目录chown -R ftpUser /data/ftp # 赋予 ftpUser 用户对该目录的所有权 这将确保用户 ftpUser 有权在 /data/ftp 目录下读写文件。 启动 ftp 服务最后，启动 vsftpd 服务，使 FTP 功能生效： service vsftpd start # 启动 vsftpd 服务 您可以通过以下命令确认服务的状态： systemctl status vsftpd # 检查 vsftpd 服务的状态 FTP 访问测试可以使用工具如 FileZilla 来进行连接测试。启动 FileZilla，输入以下信息进行连接： 主机：服务器 IP 地址 用户名：ftpUser 密码：相应的密码 端口：8021（或其他您设置的端口） 连接成功后，您可以通过左侧窗口拖拽文件到右侧窗口来上传文件，或从右侧窗口下载文件到本地。如果一切配置正确，您应能顺畅地使用 FTP 服务。","categories":["0.平台","Linux","网络","FTP"]},{"title":"正则表达式_介绍","path":"/2024/12/17/1-语言-工具语言-正则表达式-介绍/","content":"参考链接：正则表达式30分钟入门教程 什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。 很可能你使用过 Windows 下用于文件查找的通配符(wildcard)，也就是和?。如果你想查找某个目录下的所有的 Word 文档的话，你会搜索.doc。在这里，* 会被解释成任意的字符串。和通配符类似，正则表达式也是用来进行文本匹配的工具。 元字符正则表达式中的元字符是指具有特殊意义的字符，它们用于定义模式或规则，以便在文本中匹配特定的模式。以下是一些常见的元字符 — — . 匹配任意单个字符（除了换行符）。 * 匹配前面的字符零次或多次。 + 匹配前面的字符一次或多次。 ? 匹配前面的字符零次或一次。(懒惰模式) ^ 匹配字符串的开头。 $ 匹配字符串的结尾。 [] 匹配方括号中的任意一个字符。 () 标记一个子表达式的开始和结束位置。 | 用于在两个或多个模式之间进行选择。 字符转义如果需要匹配这些特殊字符本身，就需要使用字符转义。 字符转义是指用反斜杠 \\ 将特殊字符转义成普通字符的过程。例如，如果要匹配句子中的句号，就需要使用 . 来表示句号本身，而不是任意单个字符。同样的，如果要匹配星号本身，就需要使用 * 来表示星号本身，而不是匹配前面的字符零次或多次。 在正则表达式中，还有一些常用的转义字符，如 \\d 表示匹配任意一个数字字符，\\w 表示匹配任意一个字母、数字或下划线字符，\\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等），\\b 表示匹配单词的边界等。这些转义字符可以方便地匹配一些常见的字符类型，避免了手动输入所有可能的字符的麻烦。 重复{n}重复 n 次 {n,}重复 n 次或更多次 {n,m}重复 n 到 m 次 字符字符匹配直接在方括号里列出： [aeiou]就匹配任何一个英文元音字母； [.?!]匹配标点符号(.或?或!)。 也可以指定一个字符范围： [0-9]代表的含意与\\d 就是完全一致的：一位数字； [a-z0-9A-Z_]也完全等同于\\w。 **表达式解析：(?0\\d{2}[) -]?\\d{8}**这个表达式可以匹配几种格式的电话号码，像(010)88886666，或 022-22334455，或 02912345678 等。首先是一个转义字符(,它能出现 0 次或 1 次(?),然后是一个 0，后面跟着 2 个数字(\\d{2})，然后是)或-或空格中的一个，它出现 1 次或不出现(?)，最后是 8 个数字(\\d{8})。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。 IP 地址表达式((2[0-4]\\d|25[0-5]|[01]?\\d\\d?).){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?) 转义字符与反义字符在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法(?#comment)来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样.?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。现在看看懒惰版的例子吧： a.?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 后向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。 后向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b可以用来匹配重复的单词，像 go go, 或者 kitty kitty。","categories":["1.语言","工具语言"]},{"title":"Matlab静态代码转换为动态加载","path":"/2024/12/17/1-语言-Matlab-Matlab静态代码转换为动态加载/","content":"1. 将 MATLAB 转换为 CC++ 代码在将 MATLAB 代码转换为 C 或 C++ 代码时，通常使用 MATLAB 的 MATLAB Coder 工具。这个工具可以将 MATLAB 函数、脚本、甚至整个项目转换为相应的 C 或 C++ 代码。具体步骤如下： 打开 MATLAB 环境并加载要转换的脚本或函数。 在命令窗口中输入 codegen 命令，后面跟上想要转换的函数名。例如：codegen myFunction -args 0，其中 myFunction 是你的 MATLAB 函数名，-args 后面的参数是函数的输入类型。 MATLAB 将生成一个以 CC++ 语言编写的代码副本，输出到当前工作目录下。 2. 在文件中执行 Makefile執行 Makefile 的过程就是通过该文件控制编译流程。以下是用来交叉编译代码的 Makefile 示例： CC:= arm-none-linux-gnueabi-gccOBJS:=$(patsubst %.c, %.o, $(wildcard *.c))PRO_NAME:= libmatlab.so$(PRO_NAME):$(OBJS)\t$(CC) -shared -o $(PRO_NAME) $(OBJS)%.o:%.c\t$(CC) -c -Wall -I. -o $@ $\tclean:\trm -rf *.o $(PRO_NAME) CC 变量指定了交叉编译器（在这个例子中是 arm-none-linux-gnueabi-gcc），该编译器用于编译适用于 ARM 架构的代码。 OBJS 自动生成当前目录下所有 C 源文件的目标文件列表，省去了手动维护对象文件列表的烦恼。 PRO_NAME 是所生成的共享库的名称 libmatlab.so。 此 Makefile 定义了生成共享库的规则：在 $(PRO_NAME) 依赖的目标文件构建成功后，链接成最终的共享库。 3. 执行 make，生成动态库文件在命令行中执行 make 命令，这将触发 Makefile 的默认目标。在你的终端中输入： make 如果一切顺利，系统将按照 Makefile 中定义的规则进行编译并生成 libmatlab.so 文件。这一步骤会将所有的 C 源文件编译成对象文件，并链接成一个共享库。 4. 将动态库文件添加到开发板上的 /opt 目录下将生成的 libmatlab.so 库文件复制到开发板的 /opt 目录下，可以通过以下命令实现： scp libmatlab.so user@your_board_ip:/opt 请确保替换 user 和 your_board_ip 为实际的用户名和开发板的 IP 地址。复制完成后，你的开发板将在 /opt 目录中找到这个动态库。 在软件项目的 .pro 文件中的 LIBS 选项中，添加以下内容，以便编译器能够找到并链接到 libmatlab.so： -L./extlibrary/matlab -lmatlab -Wl,-rpath,/opt 其中： -L 指定库文件的路径。 -l 表示要链接的库名（去掉前面的 lib 和后面的 .so）。 -Wl,-rpath 指定运行时的库搜索路径。 5. 复制头文件和库文件最后，确保将 Matlab 编译生成的全部 CC++ 头文件，以及通过 Makefile 生成的库文件复制到项目的工程目录下。这可以通过简单的 cp 命令来完成，例如： cp /path/to/matlab/headers/*.h /path/to/your/project/include/cp /opt/libmatlab.so /path/to/your/project/lib/ 这一步确保在编译你的项目时，编译器能够找到所有需要的头文件和库文件，使得编译过程顺利进行。","categories":["1.语言","Matlab"]},{"title":"从Matlab生成独立C语言代码","path":"/2024/12/17/1-语言-Matlab-从Matlab生成独立C语言代码/","content":"MATLAB Coder 使用详解MATLAB Coder 是一个强大的工具，它可以从 MATLAB 代码生成独立的、可阅读且可移植的 CC++ 代码。这使得用户能够在各种不同的开发环境中使用其 MATLAB 开发的算法和功能，而无需完全依赖 MATLAB 环境。 生成 CC++ 代码的步骤使用 MATLAB Coder 生成 CC++ 代码的过程分为以下三步： 准备 MATLAB 算法: 确保所要生成代码的 MATLAB 文件编写无误。函数需要以适合代码生成的格式书写，例如不使用不兼容的函数或特性。 检查 MATLAB 代码的兼容性: 有些 MATLAB 代码的语句并不能直接转换成 CC++ 代码。因此，进行兼容性检查是必要的，这样可以避免在后续步骤中出现错误。 生成源代码或 MEX 文件: 最终步骤是通过 MATLAB Coder 工具选择合适的输出类型生成 CC++ 代码或者 MEX 文件，具体操作如下。 示例：简单的乘法函数对 MATALB Coder 的使用进行了解后，我们以一个简单的例子——计算两个数的乘积为例，介绍具体实现步骤。 步骤详解 安装 MATLAB: 确保安装的是 MATLAB 2011a 或更新版本，这样可以确保兼容性和功能完整性。 编写 MATLAB 文件: 创建一个名为 foo.m 的 MATLAB 文件，其中实现两个数相乘的功能代码如下： function c = foo(a, b) %#codegen% This function multiplies a and bc = a * b; % 乘法操作 在此代码中，%#codegen 注解的作用是告诉编译器进行代码生成时不要生成关于不兼容语法的警告。 选择编译器: 在命令窗口中输入 mex -setup，然后选择一个已经安装的编译器。 启动 MATLAB Coder: 在命令窗口输入 coder 并回车，这将会弹出 MATLAB Coder Project 对话框。 创建新项目: 在 “New” 选项卡的 Name 中输入项目名称 foo.prj，然后单击 OK，进入 MEX Function 对话框。 添加文件: 点击 Overview 选项卡中的 Add files，选择并打开 foo.m 文件。 定义输入变量: 单击变量 a，然后选择 Define by Example…，在 MATLAB Expression 中输入值 5，点击 OK。相同的操作对于变量 b 输入 6。 设置输出类型: 在 Build 选项卡中，选择 Output type 为 cc++ Static Library，并勾选 Generate code only。 更多设置: 点击 More settings，选择 General - Language 为 C++，在 Interface 选项中去掉所有选项，完成后点击 Close。 生成代码: 点击 Build 进行编译，完成后可点击 View report 来查看生成报告，其中会显示变量 a、b、c 的详细信息。 设置 VS2008 项目: 在 Visual Studio 2008 中创建一个控制台应用程序，将生成的 foo.h、foo.cpp、rtwtypes.h、foo_types.h 文件拷贝到项目相关目录并添加到项目中。 修改 CPP 文件: 在 foo.cpp 文件的顶部添加 #include stdafx.h。 编写测试代码: 在一个名为 test.cpp 的文件中，写入以下代码来测试生成的功能： #include stdafx.h#include foo.h#include iostreamusing namespace std;int _tmain(int argc, _TCHAR* argv[]) double a = 0.0, b = 0.0, c = 0.0; cout Enter two numbers: ; cin a b; // 读取用户输入 c = foo(a, b); // 调用生成的 foo 函数 cout c = c endl; // 输出结果 return 0; 示例：计算 N 次方根的复杂例子接下来，我们将介绍一个稍复杂的例子，以计算一个数的 n 次方根为目标。 准备工作 创建两个 MATLAB 函数文件: 第一个文件 nrt.m 和第二个文件 newtonSearchAlgorithm.m，实现 N 次方根的计算。 nrt.m: function [nth_rt, iterations, hstry] = nrt(varargin) %#codegen% This function uses a Newton Search Technique to find% the nth root of a number.a = varargin1;n = varargin2;if nargin ~= 3 tol = 1e-9; % 默认容忍误差else tol = varargin3;endif a 0 nth_rt = 0; iterations = 0; hstry = 0;else [nth_rt, hstry] = newtonSearchAlgorithm(a, n, tol); iterations = length(find(hstry ~= 0)); % 计算迭代次数end newtonSearchAlgorithm.m: function [x, h] = newtonSearchAlgorithm(b, n, tol) %#codegencoder.inline(never); % 生成单独的 C++ 文件% 使用牛顿搜索算法迭代notDone = 1;aNew = 0; % 新的猜测a = 1; % 初始猜测cnt = 0;h = zeros(50, 1); % 记录每步的结果h(1) = a;while notDone cnt = cnt + 1; [curVal, slope] = f_and_df(a, b, n); yint = curVal - slope * a; aNew = -yint / slope; % 新的猜测 h(cnt) = aNew; if (abs(aNew - a) tol) notDone = 0; % 迭代已收敛 elseif cnt 49 % 超过 50 次则停止 notDone = 0; aNew = 0; else a = aNew; % 更新猜测 endendx = aNew; % 返回根值function [f, df] = f_and_df(a, b, n)f = a^n - b; % 函数df = n * a^(n - 1); % 导数 编译和验证后续步骤与上述简单例子的处理流程类似： 在命令窗口中输入 coder，弹出 Project 对话框。 输入工程名 nrt.prj，并添加 nrt.m 文件。 输入参数（如 10, 2, 1e-9）。 在 Build 选项卡中选择输出类型，为《CC++ Static Library》，并选择只生成代码。 完成设置并点击 Build 进行编译，然后查看报告。 VS2008 中的控制台应用程序 在 VS2008 中，创建控制台应用程序，并将相关生成文件（如 nrt.cpp 等）添加到项目中。 在 nrt.cpp 和其他相关文件顶部添加 #include stdafx.h。 编写如下测试代码在 test.cpp 文件中： #include stdafx.h#include nrt.h#include iostreamusing namespace std;int _tmain(int argc, _TCHAR* argv[]) double varargin_1 = 0, varargin_2 = 0, varargin_3 = 1e-9; cout Enter a number and its root: ; cin varargin_1 varargin_2; // 读取用户输入 double nth_rt = 0, iterations = 0; double hstry_data[50] = 0; int hstry_sizes[1] = 0; nrt(varargin_1, varargin_2, varargin_3, nth_rt, iterations, hstry_data, hstry_sizes); cout nth_rt = nth_rt endl; cout iterations = iterations endl; cout hstry_data = endl; for (int i = 0; i 50; i++) cout hstry_data[i] endl; cout hstry_sizes = hstry_sizes[0] endl; return 0; 通过上述步骤，用户能够有效地从 MATLAB 算法生成 CC++ 代码，无论是简单的乘法函数还是复杂的 N 次方根计算，都能实现功能的有效移植和验证。","categories":["1.语言","Matlab"]},{"title":"CppCheck","path":"/2024/12/17/1-语言-调试输出-CppCheck/","content":"CppCheck 的安装和使用CppCheck 概述CppCheck 是一个旨在检测 CC++ 代码缺陷的静态检查工具。与 CC++ 编译器以及其他分析工具不同，CppCheck 专注于识别那些编译器无法捕捉到的 bug，而不会干扰于语法错误的检查。简单来说，静态代码检查是一种利用工具来评估我们编写的代码是否安全且稳健，是否存在潜在的问题。 例如，考虑下面这段代码： int n = 10; char* buffer = new char[n]; buffer[n] = 0; 尽管这段代码符合语法规范，CppCheck 就可能会发出警告，提示您此行代码可能导致缓冲区溢出。这种溢出的问题通常是因为数组下标超出范围，可能会导致程序崩溃或者数据损坏。CppCheck 在线静态分析中提供了更严格的检测，帮助开发者在编译之前识别和修复潜在的错误，这无疑是提升代码质量的一大利器。 目前比较流行的 CC++ 静态代码检查工具除了 CppCheck 外，还有 pc-lint 等。虽然 pc-lint 作为老牌工具其功能强大，但它是收费软件，并且配置上相对复杂。而 CppCheck 则是一个免费的开源软件，使用起来更加友好，适合广泛的开发者群体。 CppCheck 安装和使用要安装 CppCheck，请访问 CppCheck 官网 下载最新版本。CppCheck 的使用方式有两种，分别为 GUI 方式和命令行方式。 GUI 方式安装完成后，可以直接使用 cppcheck-gui 来检测代码，界面如下： 在界面中，您可以选择要检查的文件或目录，设置检查选项，然后一键检测，非常直观方便。 命令行方式您也可以通过命令行快速运行 CppCheck，命令行界面示例如下： 在命令行中，您可以使用不同的参数来定制检查过程。例如，可以使用 --enable=style 来检查代码风格问题，或使用 --output-file=result.txt 将输出结果保存到文件中。 集成到 IDE 开发环境中使用Visual Studio (VS)您可以通过以下步骤将 CppCheck 嵌入到 Visual Studio 中，方便地对项目中的文件进行检查，并支持错误的跳转功能。具体操作如下： 在 Visual Studio 中，打开菜单：工具 外部工具。 点击“添加”按钮。 在弹出的窗口中，设置标题，例如 Cppcheck。 设置命令为 C:\\Program Files (x86)\\Cppcheck\\cppcheck.exe（请根据实际安装路径调整）。 在参数框中输入：--quiet --verbose --template=vs $(ItemPath)。 在初始目录框中设置为 $(ItemDir)。 确保选中“使用输出窗口”复选框。 通过反复点击“上移”按钮，将该命令移动到列表顶部，以便更方便地识别。 点击“确定”保存设置。 这样一来，您在 Visual Studio 中就可以通过工具菜单轻松调用 CppCheck 进行代码检查。 Qt Creator在 Qt Creator 中，您同样可以通过简单的步骤将 CppCheck 集成到开发环境中。具体步骤如下： 打开 Qt Creator，点击菜单：工具 外部 配置... 添加。 在弹出的对话框中，填写如下参数： 命令：设置为 CppCheck 的可执行文件路径。 参数：可以输入 --enable=all 来启用所有检查。 初始目录：设置为项目的根目录。 以下是设置后的对话框示例： 完成设置后，您可以通过菜单 工具 外部 CppCheck 来开始检查指定目录下的代码文件，确保开发过程中的代码质量。","categories":["1.语言","调试输出"]},{"title":"PID算法","path":"/2024/12/17/1-语言-语言结构-PID算法/","content":"简介无人机可以在空中进行智能自动飞行，直升机能够悬停在空中，而地铁则可以在每个站点精准地停下。这其中，火车按照预定速度行驶，平衡车也能做到保持直立平衡，所有这些现代技术的实现背后，离不开自动控制技术。这种技术使得机器在各自的领域变得更加智能与高效。 自动控制技术是 20 世纪发展最快、影响最大的技术之一，它已经成为 21 世纪最重要的高技术之一。在科技、生产、军事、管理乃至我们的日常生活中，自动控制技术都扮演着不可或缺的角色。简单来说，自动控制技术是控制论的技术实现，是通过具备特定控制功能的自动控制系统来完成特定的控制任务，确保某个过程按照预设要求运行，从而实现预定目标。 自动控制原理根据控制方式的不同，自动控制系统一般分为闭环控制和开环控制两种类型。 闭环控制闭环控制，又称负反馈控制，其工作原理与人类或动物的目标导向行为类似。闭环控制系统由多个部分构成：传感器、控制装置和执行机构。传感器如同生物的感官，负责检测被控对象的状态信息（输出量），并将其转换为物理或电信号传输给控制装置。控制装置相当于人体的神经系统，它会比较被控对象的实际状态和设定目标，以便生成一个控制信号，通过执行机构来驱动被控对象，调整其到达理想状态。 在实际应用中，闭环控制的方法多种多样，涵盖了最优控制、自适应控制、专家控制、模糊控制、容错控制和智能控制等，广泛应用于现代工业及科技领域。 开环控制开环控制，也被称为程序控制，是依据事先设定的程序依次发出信号以控制对象。根据信号产生的方式，开环控制可以分为时限控制、次序控制和条件控制。从 20 世纪 80 年代以来，应用微电子技术生产的可编程序控制器已在各类工业控制中得到广泛应用，例如电梯控制、数控机床和自来水厂的运行管理，表现出极大的灵活性和效率。 然而，在实际情况中，大多数系统都倾向于使用闭环控制，因为闭环控制具备反馈调节功能，可以实时监测系统状态，并基于偏差进行动态调整，确保状态最终趋近于预设目标。 PID 控制器原理PID 控制算法是闭环控制中一种基础而重要的控制算法，已有近 70 年的使用历史，它以简单的结构、良好的稳定性和可靠的工作性能，广泛应用于工业控制领域。尤其在对系统动态特性不完全了解或者无法有效测量系统参数时，PID 控制技术尤为适用。 在一个单回路控制系统中，受到外界扰动的影响时，被控变量的值会偏离设定值，产生误差。自动控制系统会将来自传感器的测量值与设定值进行比较，产生的误差值随后通过比例、积分和微分运算生成一个标准控制信号，进而调整执行机构的动作。PID 控制器的核心便是基于误差，通过比例（P）、积分（I）与微分（D）三者的计算，得到所需的控制量。很重要的一点是：PID 控制算法的核心要素就是比例（P）、积分（I）、微分（D）。 ① 比例（P）控制比例控制是最基本的控制方式。其理念是系统一旦发现偏差，比例调节就会立即做出反应，努力减少这种偏差。比例控制能快速调整，减小误差，但如果比例参数设置过大，系统将可能崩溃，甚至变得不稳定。尽管比例控制带来快速的响应，往往在稳态条件下仍会存在误差。 ② 积分（I）控制积分控制的输出与误差信号在时间上的积累量成正比。随着时间的推移，即使误差非常小，积分项也会逐渐增加，推动控制器的输出以使稳态误差趋近于零。然而，由于积分的累积特性，调节速度可能变慢，过快的增益将导致系统不稳定。因此，积分项通常与比例项结合使用，形成 PI 调节器，以减少稳态误差。 ③ 微分（D）控制微分控制则是将控制器的输出与误差信号的变化率（即误差的变化速度）相联系。自动控制系统在调整的过程中常常会产生振荡，尤其是在存在较大延迟的情形下，这种现象更为明显。微分控制可以提前预测误差变化，进而避免过大的超调。因此，当控制对象具有显著惯性或滞后特性时，比例+微分（PD）控制器可以改善系统在调节过程中的动态特性。 在自动调节系统中，干扰刚出现时微分控制立刻起效，同时比例控制会随着误差的加大而增加作用，帮助系统迅速稳定。之后，积分控制会渐渐增强直至消除余差，实现设定值上的精确控制。 在实际应用中，PID 控制算法有两种计算方法：位置式算法和增量算法。增量算法相较于标准算法，根据相邻两次运算的差异计算。 标准的位置式计算法公式：[P_{out}(t) K_p \\cdot e(t) + K_i \\cdot \\sum e(t) + K_d \\cdot (e(t) - e(t-1))] 增量法计算公式：[\\Delta P P_{out}(t) - P_{out}(t-1) K_p \\cdot (e(t) - e(t-1)) + K_i \\cdot e(t) + K_d \\cdot (e(t) - 2e(t-1) + e(t-2))] PID 控制器的参数整定PID 控制器的参数整定是控制系统设计的核心内容，常见方法可以大致分为理论计算整定法和工程整定法。前者依赖于所设计系统的数学模型，经过理论计算确定控制器的参数。后者更加依赖经验，通常在实际工程中进行试验调整。常用的参数整定方法包括临界比例法、反应曲线法和衰减法。 在我的经验中，PID 参数的确定步骤如下： 确定比例系数 Kp先将积分项和微分项去掉，使其成为纯比例调节。设定输入为系统最大输出的 60% 至 70%，从 0 开始逐渐提升 Kp 直至观察到系统开始振荡。随后逐步减小 Kp，直至系统恢复稳定。记录此时的 Kp，并将最终比例系数设定为其 70% 至 80%。 确定积分时间常数 TiKp 确定后，设定一个较大的积分时间常数 T，然后逐渐减小到系统形成振荡，再逐步增大 T 直至消失。最终记录 T，并将 PID 控制器的 Ti 值设定为当前的 150% 至 180%。 确定微分时间常数 Td微分时间常数 Td 一般设为 0，使 PID 调节转变为 PI 调节。如果非要设定，取不振荡时的值的 30% 即可。 系统空载、带载联调最后进行 PID 参数的微调，确保其满足特定性能要求。 通过以上步骤，读者可以更深入地理解 PID 控制的工作原理。接下来，我将以电机转速控制系统为例，形象地展示 PID 为什么能使系统达到设定值。 在电机转速控制系统中，输入量是目标设定值（设定转速），测量装置实时测量当前转速。控制器（PID 控制器）根据偏差计算控制值，最终输出给执行机构。初始状态下电机转速为零，设定值为 100 RPM，则控制过程是： 当前速度偏差计算为 (U_e(k) U_r(k) - U_d(k)) PID 控制器计算比例、积分和微分控制值，合并得出当前控制值。 该过程不断重复，最终电机在加负载时仍然能够稳定在设定值。 最后，咱们借用单摆现象进一步说明 PID 控制的原则。抬高单摆的小球后放手，小球会因重力自然摆动最终静止。这个现象反映了比例部分，重力相当于系统的“恢复力”，其始终指向平衡位置。同样，空气阻力的存在使得小球最终回到静止状态，类似于 PID 中微分部分的作用。积分在此的角色则相似于抵消外界扰动的额外力量，确保系统准确平衡。 通过这样的对比，读者能够更形象易懂地把握 PID 控制的本质与机制。PID 的三个部分相互补充，确保控制系统稳定、可靠。 代码#includestdio.h#includestdlib.h//#includeMacianPID.h/**PID 控制其实是对偏差的控制过程。 *如果偏差为0,则比例环节不起作用，只有存在偏差时，比例环节才起作用。 *积分环节主要是用来消除静差，所谓静差，就是系统稳定后输出值和设定值之间的差值，积分环节实际上就是偏差累计的过程，把累计的误差加到原有系统上以抵消系统造成的静差。 *微分信号则反应了偏差信号的变化规律，或者说是变化趋势，根据偏差信号的变化趋势来进行超前调节，从而增加了系统的快速性。 1.比例系数 Kp 的作用是加快系统的响应速度，提高系统的调节精度。Kp 越大，系统的响应速度越快，系统的调节精度越高，但是容易产生超调，甚至会使系统不稳定。Kp 取值过小，则会降低调节精度，使响应速度缓慢，从而延长调节时间，是系统静态、动态特性变差；2.积分作用系数 Ki 的作用是消除系统的稳态误差。Ki 越大，系统的静态误差消除的越快，但是 Ki 过大，在响应过程的初期会产生积分饱和的现象，从而引起响应过程的较大超调。若 Ki 过小，将使系统静态误差难以消除，影响系统的调节精度；3.微分系数 Kd 的作用是改善系统的动态特性，其作用主要是在响应过程中抑制偏差向任何方向的变化，对偏差变化进行提前预报。但是 kd 过大，会使响应过程提前制动，从而延长调节时间，而且会降低系统的抗干扰性。 12/16 去除变积分PID控制方式 变积分 PID 的基本思想是设法改变积分项的累加速度，使其与偏差大小相对应：偏差越大，积分越慢; 偏差越小，积分越快*/struct _pid\tfloat SetParam; //定义设定值 float ActualParam;\t//定义实际值 float err; //定义偏差值\tfloat err_next; //定义上一个偏差值 float err_last; //定义最上前的偏差值 float Kp,Ki,Kd; //定义比例、积分、微分 float voltage; //控制执行器的变量 float integral; //定义积分值 //积分分离\t当被控量与设定值偏差较大时，取消积分作用。当被控量接近设定值时，引入积分控制，已消除静差，提高精度 float err_max; //积分分离 被控量与设定偏差最大值 //抗积分饱和 控制器输出继续增大 执行器开度不可能开大 此时输出控制量超出正常运行范围而进入饱和区 float umax; // 抗积分饱和 控制量极限范围 float umin; // 抗积分饱和 控制量极限范围 pid; void PID_init()\tpid.SetParam = 0.0;\tpid.ActualParam = 0.0;\tpid.err = 0.0;\tpid.err_next = 0.0; pid.err_last = 0.0;\tpid.integral = 0.0;\tpid.Kp = 0.200000;\tpid.Ki = 0.015000;\tpid.Kd = 0.200000;\tpid.err_max = 200;\tpid.umax = 400;\tpid.umin= -200; float PID_realize(float param)//\tfloat incrementParam ;\tint index; pid.SetParam = param;\tpid.err = pid.SetParam - pid.ActualParam; if( pid.ActualParam pid.umax ) //抗积分饱和 if(\tabs(pid.err) pid.err_max ) //积分分离过程 index = 0; else index = 1; if( pid.err 0 ) pid.integral+=pid.err; else if( pid.ActualParam pid.umin ) if(\tabs(pid.err) pid.err_max ) index = 0; else index = 1; if(pid.err 0 ) pid.integral+=pid.err; else if(abs(pid.err) pid.err_max) //积分分离过程 index=0; else index=1; pid.integral+=pid.err; //pid.integral/2 梯形积分； 消除余差 提高积分项运算精度 矩形积分改为梯形积分 pid.voltage = pid.Kp*pid.err + index*pid.Ki*pid.integral/2 + pid.Kd*(pid.err-pid.err_last);\tpid.err_last = pid.err;\tpid.ActualParam = pid.voltage*1.0; //增量式PID 结果与最近三次的偏差有关 提高系统的稳定性 //incrementParam = pid.Kp*(pid.err-pid.err_next) + pid.Ki*pid.err + pid.Kd*(pid.err-2*pid.err_next+pid.err_last); //pid.ActualParam += incrementParam;\t//pid.err_last = pid.err_next;\t//pid.err_next = pid.err; return pid.ActualParam;int main()\tPID_init();\tint count=0; while(count1000) float speed=PID_realize(200.0); printf(%f ,speed); count++; if(count%6 ==0) printf( ); return 0;","categories":["1.语言","语言结构"]},{"title":"最小二乘法","path":"/2024/12/17/1-语言-语言结构-最小二乘法/","content":"最小二乘法（又称最小平方法）是一种广泛应用于数据分析和统计推断的技术。它的核心思想是通过最小化数据点与拟合函数之间的误差的平方和，来寻找数据的最佳匹配。换句话说，最小二乘法能够有效地帮助我们找到一个函数，使得该函数与给定数据点的距离尽可能小。这种方法不仅适用于简单的线性回归，也能够扩展应用于多种形式的曲线拟合。 假设已知有 N 个点，设这条直线方程为： y a·x + b 其中，a 和 b 的计算公式如下： 利用最小二乘法，我们可以迅速估计出未知的数据值，并确保这些估计值与实际观测值之间的误差的平方和达到最小。例如，考虑我们拥有一组观测点，这些点可能代表某种物理现象或实验结果。通过应用最小二乘法，我们可以得到符合这些点趋势的一条直线，这条线能有效总结和描述这些观测数据。 假设我们有 N 个数据点，这些数据点可能代表多种情况，比如一组学生的考试成绩和学习时间。我们的目标是拟合一条直线，这条直线可以帮助我们理解学习时间与考试成绩之间的关系。该直线可以用以下数学表达式表示： [ y a \\cdot x + b ] 这里的 ( y ) 表示考试成绩，( x ) 表示学习时间， ( a ) 是斜率，反映了学习时间每增加一个单位，考试成绩的变化量；而 ( b ) 则是截距，表示当学习时间为零时，预计的考试成绩。 为了计算这两个参数 ( a ) 和 ( b )，我们需要使用以下公式： 斜率 ( a ) 的计算公式斜率 ( a ) 的计算公式为： [ a \\frac{N \\cdot \\Sigma (x_i \\cdot y_i) - \\Sigma x_i \\cdot \\Sigma y_i}{N \\cdot \\Sigma (x_i^2) - (\\Sigma x_i)^2} ] 在这个公式中： ( \\Sigma (x_i \\cdot y_i) ) 是所有数据点的 ( x ) 和 ( y ) 值乘积的总和。 ( \\Sigma x_i ) 是所有 ( x ) 值的总和。 ( \\Sigma y_i ) 是所有 ( y ) 值的总和。 ( \\Sigma (x_i^2) ) 是所有 ( x ) 值的平方的总和。 例如，假设我们有以下学习时间（小时）和相应考试成绩（分数）的数据点： 学习时间 (x) 考试成绩 (y) 1 60 2 70 3 75 4 80 5 90 在这个例子中，通过计算相关的求和，可以代入公式计算出斜率 ( a )。 截距 ( b ) 的计算公式截距 ( b ) 的计算公式为： [ b \\frac{\\Sigma (x_i^2) \\cdot \\Sigma y_i - \\Sigma x_i \\cdot \\Sigma (x_i \\cdot y_i)}{N \\cdot \\Sigma (x_i^2) - (\\Sigma x_i)^2} ] 这一公式同样依赖于之前提到的求和项，目的是找出当学习时间为零时，考生的期望成绩。通过同样的例子，我们可以通过插入数据计算出截距 ( b )。 这些公式提供了一种有效的方法来量化变量之间的线性关系。对于公式推导的详细过程，这里不再赘述，网上有许多资源，如统计和机器学习教材，提供了相关解释和示例代码，方便读者进一步查阅。通过实践和示例，您将能够更好地理解线性回归的基本概念及其应用。 算法代码以下是实现最小二乘法进行直线拟合的核心代码： //-------------------------------------------------------------//功能 : 最小二乘法直线拟合 y = a·x + b， 计算系数a 和 b//参数 : x -- 辐照度的数组// y -- 功率的数组// num -- 数组包含的元素个数，x[]和y[]的元素个数必须相等//返回 : 拟合计算成功返回true, 拟合计算失败返回false//-------------------------------------------------------------bool leastSquareLinearFit(float x[], float y[], const int num, float a, float b) float sum_x2 = 0.0; float sum_y = 0.0; float sum_x = 0.0; float sum_xy = 0.0; try for (int i = 0; i num; ++i) sum_x2 += x[i] * x[i]; sum_y += y[i]; sum_x += x[i]; sum_xy += x[i] * y[i]; catch (...) return false; a = (num * sum_xy - sum_x * sum_y) / (num * sum_x2 - sum_x * sum_x); b = (sum_x2 * sum_y - sum_x * sum_xy) / (num * sum_x2 - sum_x * sum_x); return true; 数据样本在进行拟合计算时，我们可以使用以下示例数据： x: 表示辐照度的浮点数数组 float x[96] = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.46667,11.4667, 31.6, 52.7333, 80.3333, 116.333, 156.6, 199.4, 242.2, 283.4, 329.2, 379.333, 431.333,482.6, 541, 594.4, 643.533, 692.133, 736.267, 772.667, 810.133, 841.867, 868.2, 892.4, 917.667,939.8, 954.667, 969, 976.8, 983.4, 987.467, 994.933, 1023.67, 875.2, 873.933, 758.8, 678.2,515.867, 782.533, 908.8, 779.2, 831.4, 645.533, 734.067, 679.533, 610.267, 565.067, 512.467,462, 405.2, 354.133, 302, 247.8, 191.533, 140, 94.2667, 57.5333, 25.9333, 4, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0; y: 表示功率的浮点数数组 float y[96] = 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595,0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595,0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 0.595, 1.785, 2.57833, 3.927, 5.79233, 7.379, 9.48133,11.1473, 12.4167, 13.6627, 16.193701, 18.248699, 19.042, 19.042, 19.105301, 16.6383,17.240999, 14.631, 11.8217, 11.663, 12.155, 15.488, 21.859301, 19.32, 19.042, 19.6133, 21.105,22.9937, 20.827299, 23.858299, 23.0333, 19.2883, 15.6937, 21.5893, 23.802999, 20.518299,21.5893, 17.907301, 17.971001, 17.574301, 16.781, 15.5513, 12.3773, 10.2747, 8.60867,6.86333, 5.39567, 3.88767, 2.856, 2.142, 2.142, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952,0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952; 计算结果在这个过程中，通过调用 leastSquareLinearFit 函数，我们可以计算出最终结果： 斜率 ( a ) 计算结果为 0.0215136 截距 ( b ) 计算结果为 0.608488 这些结果显示了辐照度变化与功率之间的关系，为后续数据分析奠定了基础。","categories":["1.语言","语言结构"]},{"title":"基础算法","path":"/2024/12/17/1-语言-语言结构-基础算法/","content":"10 大基础实用算法及其讲解算法一：快速排序算法快速排序是一种高效的排序算法，由计算机科学家东尼·霍尔发展而成。其核心理念是利用分治法将待排序的数组分成多个子数组，通过递归不断排序。快速排序在平均情况下，排序 n 个项目的比较次数为 Ο(n log n)，而在最坏情况下则需要 Ο(n²) 次比较。但其实，最坏情况并不常见，快速排序的性能通常优于其他平均时间复杂度为 Ο(n log n) 的算法。这主要归因于其内部循环在许多计算机架构上可以被有效地实现。 算法步骤： 选择基准：从数列中挑出一个元素作为基准（pivot）。 分区操作：重新排序数列，确保所有比基准小的元素在基准前面，而所有比基准大的元素在基准后面。 递归排序：对基准前后两个子数组递归应用上述步骤，直到每个子数组的大小为零或一。 例如，给定数组 [3, 6, 8, 10, 1, 2, 1]，选择 3 作为基准，分区后可能得到 [1, 2, 1, 3, 6, 8, 10]，然后递归排序 [1, 2, 1] 和 [6, 8, 10]。 算法二：堆排序算法堆排序利用堆这一数据结构进行排序。堆是近似完全二叉树并且遵循堆的性质，即每个父节点的键值总是大于或小于其子节点的键值。堆排序的时间复杂度为 Ο(n log n)，适合在大规模数据处理时使用。 算法步骤： 创建堆：构建一个最大堆（或者最小堆）。 交换元素：将堆的最大元素（根节点）与堆的最后一个元素交换。 调整堆：减小堆的大小并对根节点进行下沉操作，维护堆的性质。 重复：持续执行步骤 2 和步骤 3，直到堆的大小为 1。 通过这种方式，可以确保所有元素按顺序排列。举个例子，初始堆 [10, 9, 8, 7, 6] 被调整为 [9, 7, 8, 10, 6]，并继续逐步形成有序数组。 算法三：归并排序归并排序是一种有效的排序算法，属于分治法的典型应用，能高效处理大数据集。 算法步骤： 申请空间：为合并后序列申请一个大小为两个已排序序列之和的空间。 指针初始化：设定两个指针，分别指向两个已排序序列的开始位置。 合并操作：比较两个指针所指向的元素，选择较小的元素放入合并空间，并移动相应指针。 重复比较：继续直到其中一个指针到达序列尾部。 复制剩余元素：将剩下的序列全部复制到合并序列的尾部。 例如，将 [1, 3, 5] 和 [2, 4, 6] 合并到同一空间，最终形成排序后的序列 [1, 2, 3, 4, 5, 6]。 算法四：二分查找算法二分查找算法是一种高效的搜索算法，只适用于有序数组。其每一步都将搜索范围缩小一半，具有 Ο(log n) 的时间复杂度。 算法步骤： 确定中间元素：从数组中选取中间元素，如果该元素是目标，则搜索结束。 范围缩小：如果目标值与中间元素不符，则根据目标值与中间元素的大小关系，选择新的搜索范围。 重复查找：该过程持续进行，直到找到目标值或范围为空。 例如，在列表 [1, 2, 3, 4, 5] 中查找 3，第一个中间元素是 3，直接找到目标。 算法五：BFPRT(线性查找算法)BFPRT 算法，也称为“中位数的中位数”，用于选择第 k 大或第 k 小的元素，保证在最坏情况下时间复杂度为 Ο(n)。 算法步骤： 分组：将元素分为 n5 组，每组包含 5 个元素。 计算中位数：对每组排序并提取中位数。 递归查找：递归调用选择算法找到中位数的中位数，以此作为基准进行分割。 分割数组：根据中位数，将数组分为小于和大于该中位数的部分。 递归搜索：根据 k 的值判断在左边还是右边继续搜索，直到确定 k-th 元素。 比如，在数组 [1, 5, 2, 6, 3] 中选择第 k 大的元素时，通过多次分割和选择中位数来缩小范围。 算法六：DFS（深度优先搜索）深度优先搜索（DFS）是一种有效的树和图遍历方法，其核心思想是尽可能深地探索分支，直到访问到所有节点。 算法步骤： 访问节点：访问起始节点 v。 递归遍历：从未访问过的邻接点出发，进行深度优先遍历。 回溯处理：一旦整个分支被遍历完，回溯并检查其他未访问的节点。 例如，从节点 A 开始，DFS 可能访问顺序为 A - B - D - C，直到所有节点被访问。基于这一概念，还可生成拓扑排序用于解决最大路径等问题。 算法七：BFS（广度优先搜索）广度优先搜索（BFS）从根节点开始，沿着图的宽度逐层遍历所有节点。主要用于寻找最短路径。 算法步骤： 入队根节点：将根节点放入队列。 探查节点：取出队头节点，判断是否为目标。如果是，则结束搜索。 队列处理：将尚未访问的子节点加入队列。 重复步骤：直至队列为空，或者目标被找到。 在一棵树中，从 Node A 开始，BFS 可能会按层访问每一行的节点，保证找到最短的路径。 算法八：Dijkstra 算法Dijkstra 算法是求解单源最短路径的经典算法，适用于非负权重的有向图。 算法步骤： 初始化：设定源节点 S 的距离为零，其他节点的距离为无穷大。 选择顶点：从未访问的节点中选择距离最小的节点，标记为已访问。 更新距离：对所有邻接的节点，若通过当前节点的距离更小，则更新它们的距离值。 重复：持续进行上述步骤直到所有节点均已访问。 例如，在有向图中，Dijkstra 算法能够从源节点出发找到其余所有节点的最短路径，帮助解决如路由问题等多项应用。 算法九：动态规划算法动态规划是一种通过将原问题分解为简单的子问题，从而高效解决复杂问题的方法。常用于优化问题中。 算法步骤： 最优子结构：确定问题的最优解是否包含子问题的最优解。 重叠子问题：识别出相同的子问题，保证每个子问题只计算一次并存储结果以提高效率。 构建递归关系：通过递归或迭代构建算法以解决实际问题。 例如，背包问题需要在给定物品中选择组合以最大化价值，利用动态规划可以显著提高计算效率。 算法十：朴素贝叶斯分类算法朴素贝叶斯分类算法基于贝叶斯定理，通过特征之间独立性的假设来处理分类问题。 算法步骤： 特征独立：假设特征之间相互独立，对每个特征的条件概率进行估计。 计算概率：基于训练数据计算每个类别的概率。 分类决策：通过计算后验概率，选择具有最高概率的分类结果。 朴素贝叶斯算法在许多实际应用中（如文本分类和垃圾邮件过滤）表现良好，虽假设较为简单，但其效率和准确性往往令人惊讶。","categories":["1.语言","语言结构"]},{"title":"算法","path":"/2024/12/17/1-语言-语言结构-算法/","content":"提到算法时，就不能忽视数据结构之间的紧密联系。我们经常会见到这样一个著名的公式： 数据结构 + 算法 程序为了更好地理解这个公式，我们不妨先看一张示意图，来具体展示算法与数据结构的关系。 算法的定义算法可以被视为一系列有穷的规则、语句和指令的集合。这些指令指明了如何通过特定的步骤解决某个具体的问题。举个例子，制作一杯咖啡的过程可以看作是一种算法，它包含了步骤，比如：1）烧水，2）冲泡咖啡粉，3）加入牛奶等。每一步都必须清晰地定义，才能确保最终得到一杯美味的咖啡。 一、算法的特性在讨论算法时，有几个关键特性是必须了解的： 有穷性算法的执行步骤是有限的，意味着在某个特定的时间内，算法一定能够完成。 确定性每个步骤应当清晰明确，没有歧义。这一点很重要，因为一个模糊的步骤可能导致错误的结果。 可行性算法的每一计算步骤都要在合理的时间限制内完成，确保算法在实际应用中的可用性。 输入一个算法可以接收一个或多个外部输入。例如，计算两个数字的和需要用户提供这两个数字作为输入。 输出一个算法必须会生成一个或多个输出结果，这实际上是算法执行的目的所在。 二、如何评价一个算法的好坏评估一个算法的好坏，需要从多个角度进行考量： 时间消耗算法执行过程中的时间消耗是一个重要指标。例如，在排序算法中，时间复杂度可以决定其在处理大数据集时的表现。 存储空间消耗一些算法在运行期间可能需要大量内存，这会影响到程序的性能和可用性，因此要考虑存储空间的消耗。 易于理解和实现算法的设计应当应易于理解与实现，这不仅有助于编程，还方便后期的调试与维护。例如，快速排序的算法相对通俗易懂，因而被广泛使用。 三、时间复杂度时间复杂度是用来描述算法随输入规模增长而增长的时间消耗情况。我们先介绍几个基本概念： 问题的规模输入数据的大小通常用 n 来表示。更大的 n 意味着更复杂的计算。 时间复杂度算法的时间复杂度是消耗时间与问题规模 n 之间的函数关系，通常记为 T(n)。 1. 语句的频度语句的频度是指在一个算法中可执行的语句被反复执行的次数。假设某个可执行语句的执行时间为 t，并且执行次数为 f，那么该语句所耗费的时间可以计算为：t*f 例如，如果有一个算法需要执行的循环体中存在五个可执行语句，每个语句执行的时间为 1 毫秒，那么总耗时为 5 毫秒。以下面程序为例，求两个 N 阶方阵乘积： void MATRIXM(A, B, C) float A[n][n], B[n][n], C[n][n]; int i, j, k; // 语句频度 for (i = 0; i n; i++) // n+1 for (j = 0; j n; j++) // n(n+1) C[i][j] = 0; // n*n for (k = 0; k n; k++) // n*n(n+1) C[i][j] = C[i][j] + A[i][k] * B[k][j]; // n*n*n 2. 算法的时间复杂度算法的时间复杂度是所有可执行语句的频度之和，记为 T(n)。T(n) 是算法所需时间的一种估计，其中 n 为问题的规模（或大小、体积）。如上面的例子中，问题的规模 n 为矩阵的阶，该算法的时间复杂度为： T(n) = (n+1) + n(n+1) + n^2 + n^2(n+1) + n^3 = 2n^3 + 3n^2 + 2n + 1 当问题规模 n 趋近于无穷大时，lim(T(n)/(n³) =2，故 T(n) 与 n³ 为同阶无穷大，或者说 T(n) 与 n³ 成正比、T(n) 的量级为 n³，记为 T(n) = O(n³); 问题规模 n 的某个函数 f(n), T(n) O (f(n))。随着问题规模 n 的增大，算法执行时间的增长率和 f(n)的增长率相同","categories":["1.语言","语言结构"]},{"title":"Make和Makefile","path":"/2024/12/17/1-语言-编译链接-Make和Makefile/","content":"在开发一个系统时，一般会将系统划分为多个模块。这种模块化的方式改善了系统的可维护性，便于更改和调试。然而，不同模块之间的关联不可避免，模块的修改可能需要对其他模块进行更新。对于小型系统而言，手动编译和连接非常高效且简单，但当面对大型系统，包括多个模块时，手动编译的方式就显得繁琐且容易出错。 因此，Linux 系统引入了 make 命令来自动管理目标文件的更新。与手动编译相比，make 命令的主要优点是只更新那些被修改过的文件。在 Linux 中，文件有一个最后修改时间，make 通过这一时间戳来判断是否需要重新编译该文件。这样，未修改的文件不会被重复处理，避免了不必要的浪费，同时确保不会遗漏需要更新的文件。 模块与模块之间可能存在依赖关系，make 命令正是根据这些依赖关系进行自动维护的。因此，理解依赖关系是理解 make 命令的关键。需要注意的是，make 并不自动知道这些依赖关系，程序员需要在一个叫做 Makefile 的文件中显式地定义它们。 Makemake 是一个常用的构建工具，使用它可以自动化编译和构建程序。这对大型项目尤其重要，可以大大简化复杂项目的构建过程。 make 通过读取名为 Makefile 的文本文件，根据其中定义的规则和依赖关系，识别出哪些文件需要重新编译，然后执行相应的编译命令。 在英语中，Make 这个词的意思是“制作”。在命令行中，使用 make 命令时，如果你需要生成文件 a.txt，可以通过以下命令实现： $ make a.txt 但是，如果直接执行此命令，make 并不知道如何生成 a.txt。它需要依赖于 Makefile 中定义的规则。这条命令的代表性规则可能如下所示： 假设 a.txt 依赖于 b.txt 和 c.txt，两者合并生成 a.txt。为此，make 需要明白以下规则： a.txt: b.txt c.txt cat b.txt c.txt a.txt 这样的规则需要写入 Makefile 中。值得一提的是，Makefile 的名称并不是唯一的，可以写为 makefile，也可以通过命令行参数指定其他文件名，例如： $ make -f rules.txt $ make --file=rules.txt 这样，make 命令会根据 rules.txt 文件中的规则执行相应操作。 Make 命令make 命令可以带有四种参数：标志、宏定义、文件名和目标文件名，其标准形式为： make [flags] [macro definitions] [targets] 在 Unix 系统中，常用的标志选项及其含义如下表所示： 标志位 含义 -f file 指定文件 file 作为描述文件；如果 file 为 -，则描述文件指向标准输入。系统默认查找当前目录下的 makefile 或 Makefile 文件。 -i 忽略命令执行返回的错误信息。 -s 沉默模式，执行前不输出命令行信息。 -r 禁止使用内置规则。 -n 非执行模式，打印所有执行命令，但不实际执行。 -t 更新目标文件。 -q make 根据目标文件是否已更新返回状态信息”0”或非”0”。 -p 输出所有宏定义和目标文件描述。 -d 调试模式，输出有关文件及检测时间的详细信息。 在 Linux 下，某些标志选项与 Unix 系统略有不同，以下是不同之处： 标志位 含义 -c dir 在读取 Makefile 之前切换到指定目录 dir。 -I dir 指定搜索目录以包含其他 Makefile 文件。 -h 帮助文档，显示所有的 make 选项。 -w 在处理 Makefile 前后显示工作目录。 在命令行参数中，可以通过指定目标 target 来告诉 make 需要编译的目标。如果命令行中未指定目标，则 make 会默认执行描述文件中定义的第一个目标。 通常，Makefile 中还定义有 clean 目标，用于清除编译过程产生的中间文件，例如： clean: rm -f *.o 当运行 make clean 时，会执行 rm -f *.o 命令，删除所有中间文件。 隐含规则 make 工具包括内置的隐含规则，这些规则定义了从不同的依赖文件生成特定类型目标的方法。Unix 系统支持基于文件扩展名的隐含规则，例如，将 .c 文件编译为 .o 文件： .c: .o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $ 系统中常见的文件扩展名及其含义如下表所示： 扩展名 含义 .o 目标文件 .c C 源文件 .f FORTRAN 源文件 .s 汇编源文件 .y Yacc-C 源语法 .l Lex 源语法 在早期 Unix 系统中也支持 Yacc-C 和 Lex 源语法。编译过程中，系统会首先在 Makefile 中查找与目标文件相关的 .C 文件。如果存在依赖的 .y 和 .l 文件，则会先将其转换为 .c 文件后再编译生成对应的 .o 文件；如果只有 .y 文件，系统则会直接编译该文件。 GNU make 不仅支持后缀规则，还支持另一类隐含规则，称为模式规则。这类规则更为通用，可以定义复杂的依赖规则。模式规则的语法类似于正则表达式，但目标名称前多了一个 % 符号。 例如，下面的模式规则定义了如何将任意 file.c 文件转换为 file.o： %.c: %.o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $ MakefileMakefile 是一个包含构建规则的文本文件，定义了项目中各个源文件之间的依赖关系及如何生成目标文件。make 依据 Makefile 中的规则来判断哪些文件需要重新编译，并执行相应命令生成目标文件。 规则Makefile 包含了一系列规则，每个规则定义了一个或多个目标文件及其所需的依赖文件和编译命令。规则的形式如下： target: prerequisites commands target 是规则的目标，prerequisites 是前置条件，可以是一个或多个文件。命令行中必须以 tab 键开头，以执行相关命令。 目标是必需的，而前置条件和命令是可选的，但至少需要有一个。每条规则表明两件事：构建目标的前置条件是什么，以及如何构建。 目标一个目标定义了一条规则。目标通常是文件名，表示 make 将要构建的对象，比如 a.txt。 目标可以是单个文件名，也可以是多个文件名，用空格分隔；除了文件名，目标还可以是某个操作的名称，这被称为伪目标（phony target）： clean: rm *.o 在上面的例子中，目标是 clean，这是一个伪目标，表示执行删除对象文件的操作。当你运行 $ make clean 时，make 会去执行相应的命令。 需要注意的是，如果当前目录含有名为 clean 的文件，make 可能不会执行该命令，因为它认为目标已经存在，就不需要再构建。为了避免这种情况，可以通过以下方式声明 clean 为“伪目标”： .PHONY: cleanclean: rm *.o 一旦声明为伪目标，make 就不会检查是否存在名为 clean 的文件，而是在每次运行时都执行对应的命令。 .PHONY 还有其他很多内置目标名，可以查看手册。如果运行 make 命令时没有指定目标，默认执行 Makefile 中的第一个目标。例如： $ make 会执行 Makefile 第一个目标。 示例：执行多个目标.PHONY: cleanclean: rm *.o temp.PHONY: cleanall cleanobj cleandiffcleanall: cleanobj cleandiff rm programcleanobj: rm *.ocleandiff: rm *.diff 上述示例定义了多个目标的执行结构，clean 会删除中间文件，cleanall 则在执行 cleanobj 和 cleandiff 后删除最终程序文件。","categories":["1.语言","编译链接"]},{"title":"g++参数介绍","path":"/2024/12/17/1-语言-编译链接-g-参数介绍/","content":"介绍gcc and g++分别是 gnu 的 c c++编译器，gccg++在执行编译工作的时候，总共需要 4 步 预处理,生成.i 的文件 将预处理后的文件不转换成汇编语言,生成文件.s 有汇编变为目标代码(机器代码)生成.o 的文件 连接目标代码,生成可执行程序 总体选项 -E 只激活预处理,这个不生成文件,你需要把它重定向到一个输出文件里面. gcc -E hello.c pianoapan.txtgcc -E hello.c | more 慢慢看吧,一个 hello word 也要与处理成 800 行的代码 -S 只激活预处理和编译，就是指把文件编译成为汇编代码。 gcc -S hello.c 他将生成.s 的汇编代码，你可以用文本编辑器察看 -c 只激活预处理,编译,和汇编,也就是他只把程序做成 obj 文件 gcc -c hello.c 他将生成.o 的 obj 文件 目录选项-Idir 在你是用#include”file”的时候,gccg++会先在当前目录查找你所制定的头文件,如果没有找到,他回到缺省的头文件目录找,如果使用-I 制定了目录,他回先在你所制定的目录查找,然后再按常规的顺序去找.对于#include,gccg++会到-I 制定的目录查找,查找不到,然后将到系统的缺省的头文件目录查找-include file -i 相当于“#include”包含某个代码,简单来说,就是便以某个文件,需要另一个文件的时候,就可以用它设定,功能就相当于在代码中使用#include gcc hello.c -include /root/pianopan.h -I-就是取消前一个参数的功能,所以一般在-Idir 之后使用-idirafter dir 在-I 的目录里面查找失败,讲到这个目录里面查找. -iprefix prefix -iwithprefix dir 一般一起使用,当-I 的目录查找失败,会到 prefix+dir 下查找 -Ldir 制定编译的时候，搜索库的路径。比如你自己的库，可以用它制定目录，不然编译器将只在标准库的目录找。这个 dir 就是目录的名称。 -llibrary 制定编译的时候使用的库 gcc -lcurses hello.c 使用 ncurses 库编译程序 调试选项 -g 只是编译器，在编译的时候，产生调试信息。 -gstabs 此选项以 stabs 格式声称调试信息,但是不包括 gdb 调试信息. -gstabs+ 此选项以 stabs 格式声称调试信息,并且包含仅供 gdb 使用的额外调试信息. -ggdb 此选项将尽可能的生成 gdb 的可以使用的调试信息. -glevel 请求生成调试信息，同时用 level 指出需要多少信息，默认的 level 值是 2 链接方式选项：-static 此选项将禁止使用动态库。 优点：程序运行不依赖于其他库 缺点：文件比较大 -shared (-G) 此选项将尽量使用动态库，为默认选项 优点：生成文件比较小 缺点：运行时需要系统提供动态库 -symbolic 建立共享目标文件的时候,把引用绑定到全局符号上. 对所有无法解析的引用作出警告(除非用连接编辑选项 -Xlinker -z -Xlinker defs’取代)。 注：只有部分系统支持该选项. 错误与告警选项 -Wall 一般使用该选项，允许发出 GCC 能够提供的所有有用的警告。也可以用-W{warning}来标记指定的警告。 -pedantic 允许发出 ANSIISO C 标准所列出的所有警告 -pedantic-errors 允许发出 ANSIISO C 标准所列出的错误 -werror 把所有警告转换为错误，以在警告发生时中止编译过程 -w 关闭所有警告,建议不要使用此项 预处理选项 -Dmacro 相当于 C 语言中的#define macro -Dmacrodefn 相当于 C 语言中的#define macrodefn -Umacro 相当于 C 语言中的#undef macro -undef 取消对任何非标准宏的定义 其他选项-o 制定目标名称,缺省的时候,gcc 编译出来的文件是 a.out gcc -o hello.exe hello.c (哦,windows用习惯了)gcc -o hello.asm -S hello.c -O0 -O1 -O2 -O3 编译器的优化选项的 4 个级别，-O0 表示没有优化,-O1 为缺省值，-O3 优化级别最高 -fpic 编译器就生成位置无关目标码.适用于共享库(shared library). -fPIC 编译器就输出位置无关目标码.适用于动态连接(dynamic linking),即使分支需要大范围转移. -v 显示详细的编译、汇编、连接命令 -pipe 使用管道代替编译中临时文件,在使用非 gnu 汇编工具的时候,可能有些问题 gcc -pipe -o hello.exe hello.c -ansi 关闭 gnu c 中与 ansi c 不兼容的特性,激活 ansi c 的专有特性(包括禁止一些 asm inline typeof 关键字,以及 UNIX,vax 等预处理宏, -fno-asm 此选项实现 ansi 选项的功能的一部分，它禁止将 asm,inline 和 typeof 用作关键字。 -fno-strict-prototype 只对 g++起作用,使用这个选项,g++将对不带参数的函数,都认为是没有显式的对参数的个数和类型说明,而不是没有参数.而 gcc 无论是否使用这个参数,都将对没有带参数的函数,认为城没有显式说明的类型 -fthis-is-varialble 就是向传统 c++看齐,可以使用 this 当一般变量使用. -fcond-mismatch 允许条件表达式的第二和第三参数类型不匹配,表达式的值将为 void 类型 -funsigned-char -fno-signed-char -fsigned-char -fno-unsigned-char 这四个参数是对 char 类型进行设置,决定将 char 类型设置成 unsigned char(前 两个参数)或者 signed char(后两个参数) -imacros file 将 file 文件的宏,扩展到 gccg++的输入文件,宏定义本身并不出现在输入文件中 -nostdinc 使编译器不再系统缺省的头文件目录里面找头文件,一般和-I 联合使用,明确限定头文件的位置 -nostdin C++ 规定不在 g++指定的标准路经中搜索,但仍在其他路径中搜索,.此选项在创建 libg++库使用 -C 在预处理的时候,不删除注释信息,一般和-E 使用,有时候分析程序，用这个很方便的 -M 生成文件关联的信息。包含目标文件所依赖的所有源代码你可以用 gcc -M hello.c 来测试一下，很简单。 -MM 和上面的那个一样，但是它将忽略由#include 造成的依赖关系。 -MD 和-M 相同，但是输出将导入到.d 的文件里面 -MMD 和-MM 相同，但是输出将导入到.d 的文件里面 -Wa,option 此选项传递 option 给汇编程序;如果 option 中间有逗号,就将 option 分成多个选项,然后传递给会汇编程序 -Wl.option 此选项传递 option 给连接程序;如果 option 中间有逗号,就将 option 分成多个选项,然后传递给会连接程序. -x language filename 设定文件所使用的语言,使后缀名无效,对以后的多个有效.也就是根据约定 C 语言的后缀名称是.c 的，而 C++的后缀名是.C 或者.cpp可以使用的参数有下面的这些 `c’, `objective-c’, `c-header’, `c++’, `cpp-output’, `assembler’, and `assembler-with-cpp’. gcc -x c hello.pig -x none filename 关掉上一个选项，也就是让 gcc 根据文件名后缀，自动识别文件类型 gcc -x c hello.pig -x none hello2.c","categories":["1.语言","编译链接"]},{"title":"GCC编译流程","path":"/2024/12/17/1-语言-编译链接-GCC编译流程/","content":"GCC 编译流程GCC（GNU Compiler Collection）是一款强大的编译器，主要用于将 C、C++ 等语言的源代码编译成机器可执行文件。整个编译过程可以分为四个主要步骤，每个步骤都有其特定的功能和重要性。 Step 1: 预处理在预处理阶段，GCC 会处理一些特殊的指令和文件： 头文件加载：源代码中通常会使用 #include 指令来引用外部库或其他文件。例如，#include stdio.h 允许我们使用标准输入输出函数。 宏定义替换：通过 #define 指令定义的宏会被直接替换成其对应的值，简化代码的编写。例如，#define PI 3.14 会将源代码中的 PI 替换成 3.14。 条件编译：使用 #ifdef 和 #ifndef 等指令，可以根据不同的条件启用或禁用代码块。这在处理不同平台或功能模块时尤其有用。 去除注释：所有的注释（如 // 和 /* */）都会在此步骤被移除，因为它们对编译过程没有意义。 通过这个步骤，GCC 生成一个名为 name.i 的预处理文件，这是一个纯文本文件，包含了所有的加载内容和替换结果。这一过程的命令为： gcc -E name.c -o name.i 或简写为： gcc -o name.i -E name.c Step 2: 编译在编译阶段，GCC 对 name.i 文件进行以下操作： 语法检查：编译器会检查代码是否符合 C 语言的语法规范。如果发现任何错误如缺少分号、括号不匹配等，GCC 会立即报错并终止编译过程。比如，如果代码中有错误，输出可能会提示出错的行和具体错误信息，帮助开发者快速定位问题。 生成汇编代码：如果没有语法错误，编译器接着生成汇编语言代码，文件名为 name.s。 这个步骤的命令如下： gcc -S name.i -o name.s 或简写为： gcc -o name.s -S name.i Step 3: 汇编在汇编阶段，GCC 将汇编代码转换为机器代码，即目标文件（.o 文件）。这一步骤可以视为将高级语言翻译成计算机能够直接理解的指令集。 机器码生成：汇编代码中每一条指令都会被转化为相应的机器指令，形成一个目标文件 name.o。此文件包含了编译后的代码，但尚未链接成完整的可执行文件。 执行汇编的命令为： gcc -c name.s -o name.o 或简写为： gcc -o name.o -c name.s Step 4: 链接最后一个步骤是链接。链接的主要工作是将一个或多个目标文件（name.o 和可能的其他.o 文件）结合起来，生成一个最终的可执行文件。 生成可执行文件：在这个阶段，GCC 将处理目标文件之间的符号引用，将它们合并，并生成可执行文件（如可称为 name 的文件）。如果程序依赖于外部库，链接器会在这里找到并包含所需的库文件。 执行链接的命令为： gcc name.o -o name 或简写为： gcc -o name name.o 经过这四个步骤后，编译完成，生成的可执行文件可以在操作系统中运行。整个过程确保代码从人类可读的高级语言转化为机器能够理解和执行的二进制文件。","categories":["1.语言","编译链接"]},{"title":"常见的内存问题","path":"/2024/12/17/1-语言-调试输出-常见的内存问题/","content":"利用 Memcheck 发现常见的内存问题在 Linux 平台开发应用程序时，开发者经常会遇到内存使用不当的问题。我们总结了一些常见的内存错误，并说明了如何使用 Valgrind 的 Memcheck 工具来检测这些错误。 使用未初始化的内存在程序的不同上下文中，变量的初始值存在差异。全局变量和静态变量的初始值为 0，而局部变量和动态分配的变量则具有不确定的随机值。如果程序意外地使用了这些随机值，可能导致程序行为不可预测。 示例考虑以下示例代码： #include stdio.hvoid example() int a[5]; // a 是局部变量，其所有初始值为随机值 printf(%d , a[0]); // 使用未初始化的变量 a[0] 在这个例子中，数组 a 是一个具有随机初始值的局部变量，若在未对其进行初始化的情况下直接使用，将会带来不可预测的输出。假设这个文件名为 badloop.c，生成的可执行程序名为 badloop。用 Memcheck 对其测试结果如下： ==12345== Use of uninitialized value of size 4==12345== at 0x4005A1: example (badloop.c:5) 输出结果显示，在程序的第 5 行中，程序的跳转依赖于一个未初始化的变量。这准确地帮助我们发现了问题。 内存读写越界问题分析内存读写越界是指对不该访问的内存地址进行读写操作，例如数组越界或对动态分配的内存超出范围的访问。这样的操作可能导致对程序状态的严重影响。 示例典型的数组越界代码如下： #include iostreamvoid example() int pt[4]; int *p = pt; // p指向pt数组的起始地址 for (int i = 0; i 5; i++) p[i] = i; // 超出pt数组的范围 当我们运行这个文件 badacc.cpp 并用 Memcheck 测试时，结果如下： ==12345== Invalid write of size 4==12345== at 0x4005A1: example (badacc.cpp:6)==12345== Address 0x602010 is 4 bytes after a block of size 16 allocd 输出结果表明，在该程序的第 6 行，进行了非法的写操作，这帮助我们准确地发现了该问题。 内存覆盖问题分析C 语言允许直接操作内存，这种特性虽然强大，但也可能导致内存覆盖错误。当源地址和目标地址重叠时，操作的结果可能不如预期。 示例看看下列代码： #include cstringvoid example(char* x) strcpy(x + 10, x); // src 和 dst 发生重叠 在这里，src 和 dst 指向相互重叠的内存区域，调用 strcpy 时可能覆盖之前的值。假设这个文件名为 badlap.cpp，测试输出如下： ==12345== Invalid write of size 1==12345== at 0x4005A1: example (badlap.cpp:4) 输出表明在第 4 行有非法写操作，可以有效识别该内存覆盖问题。 动态内存管理错误问题分析动态内存管理不仅提供了灵活的内存控制能力，也容易引发错误。C 和 C++ 对动态内存的分配和释放有不同的方式，应保持一致性。 示例考虑以下代码： void example() int* p = (int*)malloc(sizeof(int)); // 使用 malloc 申请内存 delete p; // 错误使用 delete 释放内存 在这个例子中，用 malloc 申请的内存，使用 delete 释放会导致未定义行为。测试输出如下： ==12345== Invalid free() / delete / delete[] / realloc()==12345== at 0x4005A1: example (badmac.cpp:5) 输出结果显示在第 5 行，分配和释放函数不一致，成功识别了代码问题。 内存泄露问题描述内存泄露指在动态申请内存后未释放，导致该内存空间无法被访问。内存泄露常在大型项目中出现，开发者需培养良好的编程习惯，以防止此类问题。 示例考虑如下代码示例： struct Node int data; Node* left; Node* right;;void mk(Node** root) *root = new Node; // 动态申请内存int main() Node* root; mk(root); // 没有释放内存，造成内存泄露 测试这个文件 badleak.cpp 的输出如下： ==12345== 8 bytes in 1 blocks are definitely lost in loss record 1 of 1 Memcheck 成功检测到了内存泄露的情况，输出帮助我们发现了未释放的内存。 小结通过上述示例和分析，可以看出利用 Memcheck 识别和修复内存问题的强大功能。定期使用这一工具，能有效提高程序的稳定性和性能。","categories":["1.语言","调试输出"]},{"title":"内存泄漏检测工具比较","path":"/2024/12/17/1-语言-调试输出-内存泄漏检测工具比较/","content":"内存泄露检测工具比较 内存泄露和 malloc 调试库 在 Linux 和 Solaris 下，针对 C 和 C++ 程序的简单内存泄露检测。通过使用这一库，开发者可以方便地跟踪内存分配和释放，以识别潜在的泄露。例如，可以追踪每次 malloc() 的调用，查找没有相应 free() 的内存块。 Debug Malloc Library 这是一种专用的调试库，旨在帮助开发者快速定位内存问题。通过记录每个分配的内存块和对应的调用栈，它能显示何时及为何发生内存泄露。 Bruce Perens 的 malloc() 调试库 特别设计用于 Linux 分发版，Bruce Perens 开发的此库提供了内存分配的调试功能，允许程序员检测动态内存分配过程中的问题。 Linux 下的内存泄漏检测程序 提供多种工具用于分析 Linux 环境中程序的内存使用情况。开发者可以通过这些工具轻松查找无用的内存引用，以提高最终产品的稳定性。 跨平台的内存泄漏分析工具 在 Linux、Solaris 和 HP-UX 平台上，能够有效追踪 C++ 程序中的内存泄露。这类工具往往具有高度的可配置性，适应不同编程模型和编译环境。 Johan Lindh 的开源 C 语言内存错误检测工具 利用 GCC 的预处理器，Johan Lindh 开发的这一工具专注于检测 C 语言中的内存错误。它为开发者提供了一种低开销的解决方案以提高代码质量。 调试和性能分析工具 这些工具专注于 Linux 程序的调试和性能分析，特别是 C 和 C++ 语言的应用程序。此类工具通常提供可视化的性能报告，帮助开发者更好地理解程序的运行情况。 可视化工具 这种工具将性能数据以图形化方式呈现，帮助开发者更直观地理解程序执行的内存使用模式和性能瓶颈。 Firefox 扩展 一个专门为 Firefox 浏览器设计的扩展，能够识别与浏览器相关的内存泄漏。这对于网页开发者尤为重要，因为浏览器的内存管理直接影响用户体验。 Drip 和 IE Sieve 内存泄漏探测器 专为网页开发者设计，帮助识别 Internet Explorer 中的内存泄露。这两种工具可以展示由于 IE 的限制而导致的可避免的内存泄漏，从而提高网页性能。 Win32 应用程序资源泄漏探测器 通过监控 Win API 调用，这款工具能够检查任何 Win32 应用程序中的资源泄漏，包括内存、句柄等，帮助开发者发现并解决问题。 SAP 的内存分析软件 作为一种开源工具，SAP 可以辅助开发者快速定位 Java 程序中的内存泄漏。其基于 Eclipse RCP（Rich Client Platform），提供了友好的用户界面，简化了内存使用情况的分析。 动态跟踪（DTrace） 这是一个开源的动态跟踪工具，能够在类 Unix 操作系统上运行。通过跟踪内核和用户进程，开发者能够实时监测系统资源的使用情况，并及时进行调整以优化系统性能。 IBM Rational PurifyPlus 此工具集成了内存错误检测、应用程序性能描述和代码覆盖分析等多种功能，帮助开发人员发现 CC++、.NET、Java 和 VB6 代码中的潜在错误，并提供全面的解决方案。 Parasoft 专为 CC++ 应用程序设计的自动检测工具，能发现程序中的内存破坏、内存泄漏、指针错误和 IO 问题。利用 SCI 技术和变异测试等方法，Parasoft 提供了详细的错误症状和解决方案。 Compuware 的运行时错误检测工具 为 C++ 开发者设计，作为 Microsoft Visual Studio 和 C++ 6.0 的插件，帮助开发者迅速定位程序中的错误。 Electric Software 这个工具包集成了内存泄漏检查、代码剖析和函数调用跟踪等多种功能，适用于 C++ 和 .NET 开发者，提供全面的错误诊断和性能分析。 Compuware Java 功能模块 包含 Java 内存检测、代码覆盖率测试和性能分析等多种功能，帮助开发者实现高效的代码优化与性能提升。 Quest 的 Java 内存泄漏分析工具 专注于 Java 应用程序的内存使用，帮助开发者快速识别和修复内存泄漏，提高应用的稳定性和性能。 ej-technologies 的 JProfiler 一个全面的 Java 性能与内存分析工具，支持 J2SE 和 J2EE 应用程序，提供丰富的 IDE 和应用服务器整合功能，其直观的 GUI 可以帮助开发者快速识别性能瓶颈和内存泄漏。 BEA 的内存泄漏诊断工具 针对 Intel 平台优化，专注于 Java 内存泄漏的根本原因，提供高性能的内存使用分析。 SciTech Software AB 专注于 C# 和 VB.Net 程序的内存泄漏检测和优化，帮助开发者提高应用程序的性能和稳定性。 YourKit 被业界广泛认可的 Java 和 .NET 性能分析工具，能够深入分析应用程序性能，并定位潜在的内存问题。 AutomatedQA 的性能剖析和内存调试工具 为 .NET 和 Windows 程序提供详细的报告，帮助开发者识别和解决性能和内存泄漏问题，兼容多种编程语言和编译器。 微软 JavaScript 内存泄漏探测工具 由微软全球产品开发团队发布，用于探测 JavaScript 代码中的内存泄漏，作为 IE 浏览器的插件运行，专门针对 web 开发中的内存管理问题。 附录：内存泄漏的发生方式 常发性内存泄漏常发性内存泄漏指的是某段代码在程序运行过程中被反复调用时，每次执行都会占用额外的内存而未能正常释放。这种情况常常发生在循环结构或递归调用中，比如在一个不停创建对象的循环中，若创建的对象未被销毁，就会导致内存占用持续增加，从而造成泄漏。 偶发性内存泄漏偶发性内存泄漏则与特定的条件相关。只有在特定的操作条件下，执行某段代码时才可能发生内存泄漏。这种泄漏在不同的环境中可能表现得截然不同。例如，在特定版本的软件中，用户操作一种特定的功能可能触发内存泄漏，而在其他版本或未执行该功能时则不会。测试环境与测试方法的选择对发现这种问题至关重要，工程师通常需要模拟各种场景以确保漏泄问题被发现。 一次性内存泄漏一次性内存泄漏发生在某段代码只被执行一次的情况下，但由于算法或逻辑缺陷，依然会留下一块内存未被释放。典型的例子包括由于未释放大对象或未清理全局引用，导致在一次运行中的内存损失。例如，开发人员可能在初始化时分配了一个缓冲区，但未正确解除对该缓冲区的引用。 隐式内存泄漏隐式内存泄漏并不表现为传统意义上的“泄漏”，因为程序在运行结束时会释放所有申请的内存。然而，若程序需要长时间运行，如几天或几周而不释放内存，可能会导致系统总体内存耗尽，从而产生“隐式”效果。这在服务器或长期运行的应用中尤为棘手，例如长时间运行的数据库服务，若不定期清理引用，可能会使系统最终崩溃。 什么是系统资源？在 Windows 操作系统中，每当应用程序启动并运行时，系统不仅需要执行代码，还需要随时”跟踪”该程序的状态。这包括管理按钮、光标、菜单的位置，以及窗口状况等信息。这些信息被存储在名为堆（Heap）的内存块中。堆是一种特殊的内存管理结构，有效地分配和回收内存资源。 Windows 将堆分为两大类：用户资源堆（User Resource Heap）和GDI 资源堆（GDI Resource Heap）。用户资源堆由系统内核 User.exe 管理，而 GDI 资源堆由系统内核 Gdi.exe 管理。它们共同构成系统资源堆（System Resource Heap），通常合称为系统资源。 资源堆的分类微软将 Windows 的系统资源划分为五个堆，其中三个属于用户资源堆，两个属于 GDI 资源堆： 用户资源堆 16 位用户堆（User Heap）: 最大 64KB 32 位窗口堆（Windows Heap）: 最大 2MB 32 位用户菜单堆（User Menu Heap）: 最大 2MB GDI 资源堆 16 位 GDI 堆（GDI Heap）: 最大 64KB 32 位 GDI 堆（GDI）: 最大 2MB 这样的分类和大小说明了不论 CPU 的种类（如 P4 或 486）或内存大小（如 8MB 或 1GB），所有 Windows 用户的系统资源都相同。用户无法自主增加或减少这些资源的大小，操作系统将其固定，而这与硬件的档次毫无关系。 为了实时监控系统资源的使用情况，Windows 以百分比的形式展示可用用户资源（Free User Resource）和可用 GDI 资源（Free GDI Resource），用户可以通过“开始”菜单的“附件”中的“系统工具”找到“系统信息”，以查看当前系统资源的状态。 在 Linux 平台中调试 CC++ 内存泄漏方法C 和 C++ 程序的内存管理完全由程序员负责，从申请到释放内存，稍不注意便可能在系统中引入内存错误。这种错误往往后果严重，可能导致系统崩溃或内存耗尽等问题。本文将介绍在 Linux 环境中检测内存泄漏的方法，包括静态分析和动态检测两个角度，重点讲解静态分析工具 BEAM、动态检测工具 Valgrind 和 Rational Purify 的使用方法。希望本文能为处理其他产品或项目中与内存泄漏相关的问题提供借鉴。 内存问题的重要性由于 C 和 C++ 程序需手动管理内存，因此内存错误可能导致严重的问题。历史上，从计算机应急响应小组和供应商发布的安全公告中，许多都是因内存错误引起的。自上世纪 70 年代末期以来，程序员们一直在讨论这些问题，并且到 2007 年时其影响依旧显著。与其他类型的错误不同，内存错误通常隐蔽且难以重现，其症状常常不易在源代码中识别。例如，内存泄漏可能导致应用程序逐渐变得响应迟缓，最终使程序崩溃，而内存的浪费并不总是立刻显而易见。 内存错误的 C 和 C++ 程序可能表现为不同的问题：内存泄漏可能导致程序的运行时间越来越长，进而崩溃；而覆盖内存的问题使得程序变得脆弱，容易受到恶意攻击。这些问题表明了对 C 和 C++ 编程时内存管理，尤其是内存泄漏的重视是多么重要。 本文将探讨如何发现内存泄漏，接着使用不同工具定位这些内存泄漏，最后对这些工具进行比较，并简单介绍资源泄漏的处理（以句柄泄漏为例）。测试平台为：Linux (Redhat AS4)，但所介绍的方法和工具并不限于 CC++ 语言和 Linux 操作系统。 内存泄漏的定义内存泄漏通常指的是堆内存的泄漏。堆内存是指程序从堆中分配的内存，大小可以在程序运行期间动态确定，使用完后必须显式释放。这通常通过 malloc、realloc、new 等函数进行内存分配。忘记使用 free 或 delete 释放内存会导致该内存无法再被利用，这就是典型的内存泄漏。 1. 如何发现内存泄漏内存泄漏在代码检查过程中，某些简单的问题容易被识别。而一些较为严重的泄漏，可能在短时间内导致程序崩溃，或在内存不足时被系统报告，这也是比较容易发现的。然而，最难发现的是那些泄漏比较慢的问题，需要多天、几周甚至几个月才能显露出异常现象。 要在较短的时间内检测潜在的内存泄漏，可以利用内存监视工具收集一段时间内的堆栈内存信息，观察它的增长趋势。在 Linux 平台上，可以使用 ps 命令监视内存的使用，如下所示： ps -aux 2. 静态分析静态分析是一种低成本的调试方法，包括手动检测和使用静态分析工具。 2.1 手动检测采用一致的编程规范是防止内存问题的第一道防线。手动检测可以作为编码标准的补充。即使是专业的 CC++ 程序员，也可以通过查看不熟悉的代码，以非常低的成本快速识别内存问题。例如，通过查找 malloc() 和 free()，或者 new 和 delete 的配对，可以发现像以下示例中的内存泄漏问题。 #include stdio.h#include string.h#include stdlib.hint LeakTest(char * Para) if (NULL == Para) return -1; // 空参数处理 char * Logmsg = new char[128]; // 动态分配内存 if (NULL == Logmsg) return -2; // 内存分配失败 sprintf(Logmsg,LeakTest routine exit: %s. , Para); // 此处漏掉了释放 Logmsg 的代码 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); return 0; 在上述代码中，Logmsg 分配的内存没有被释放，就造成了内存泄漏。 2.2 静态代码分析工具有多种代码静态分析工具可用，例如 Splint、PC-LINT 和 BEAM。由于 BEAM 支持多种平台，这里将以它为例进行简单介绍。 BEAM 能够检测四类问题：未初始化的变量、废弃的空指针、内存泄漏和冗余计算，且支持多种平台（如 Linux x86、s390s390x、PowerPC、AIX、Windows 2000 以上等）。 以下是用于 BEAM 分析的代码示例： #include stdio.h#include string.h#include stdlib.hint *p;void foo(int a) int b, c; b = 0; if (!p) c = 1; if (c a) c += p[1]; // 这可能会导致错误int LeakTest(char * Para) char * Logmsg = new char[128]; if ((Para == NULL) || (Logmsg == NULL)) return -1; sprintf(Logmsg, LeakTest routine exit: %s. , Para); // 漏掉了 Logmsg 的释放 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); return 0; 在 Linux x86 环境中，使用 BEAM 进行分析的过程如下： ./beam-3.4.2/bin/beam_configure --c gcc./beam-3.4.2/bin/beam_configure --cpp g++./beam-3.4.2/bin/beam_compile --beam::compiler=compiler_cpp_config.tcl -cpp code2.cpp 从编译报告中，BEAM 会提示几个错误，例如内存泄漏和变量未初始化的问题。 2.3 内嵌程序可以重载内存分配和释放函数 new 和 delete，编写程序定期统计内存的分配和释放，进一步找出内存泄漏。这种方法较为复杂，详细示例不再赘述。 3. 动态运行检测用于实时检测的工具主要有 Valgrind 和 Rational Purify。 3.1 ValgrindValgrind 提供了一组工具来帮助程序员寻找程序中的 bug 并提高性能。其中，Memcheck 主要用于检查 CC++ 程序中的内存管理错误。Valgrind 能识别以下几种常见错误： 读写已释放的内存 读写超出分配范围的内存 使用未初始化的变量 向系统调用传递无效的参数 内存泄漏 3.2 Rational PurifyRational Purify 是一种针对难以发现的内存错误和运行时错误的工具。它能自动识别错误并定位，从而减少调试时间。Purify 支持多种平台，并可和其他主流开发工具集成。它可以检查每一个模块，甚至能发现复杂多进程应用中的错误。 在 Linux 上使用 Purify 时，需重新编译程序。通常通过修改 Makefile 中的编译器变量来实现。以下是编译示例 Makefile： CC=purify gcc 运行 Purify 的设置脚本并重新编译： ./purifyplus_setup.shmake 下面是使用 Purify 和 g++ 编译代码文件的示例命令，使用 -g 选项添加调试信息： purify g++ -g test3.cpp -o test 运行生成的可执行文件 ./test，就可以定位出内存泄漏的具体位置。 #include unistd.hchar * Logmsg;int LeakTest(char * Para) if (NULL == Para) return -1; // 空参数处理 Logmsg = new char[128]; for (int i = 0; i 128; i++) Logmsg[i] = i % 64; // 数据填充 if (NULL == Logmsg) return -2; // 内存分配失败 sprintf(Logmsg, LeakTest routine exit: %s. , Para); // 忽略释放 Logmsg 的代码 return 0;int main(int argc, char **argv) char szInit [] = testcase1; LeakTest(szInit); for (int i = 0; i 2; i++) if (i % 200 == 0) LeakTest(szInit); sleep(1); return 0; 记住，程序必须以调试版本编译，才能准确定位到内存泄漏发生的具体代码行。使用 -g 选项进行编译是必要的。","categories":["1.语言","调试输出"]},{"title":"使用Valgrind发现内存泄露","path":"/2024/12/17/1-语言-调试输出-使用Valgrind发现内存泄露/","content":"Valgrind 简介Valgrind 是一款强大的内存调试工具，可在 Linux 环境下使用，兼容多种架构，包括 x86、x86_64 和 ppc32。它专门设计用于对编译后的二进制程序进行内存监测，主要关注 C 和 C++ 程序中的动态内存管理，比如 C 语言中的 malloc 和 free，以及 C++ 中的 new 和 delete。这款工具的最大优势在于它能够有效识别和定位内存泄漏问题，这一问题通常会导致程序在运行时消耗过多内存，甚至引发崩溃。 Valgrind 是一套在 Linux 环境下运行的开源仿真调试工具的集合，采用 GPL V2 许可证。其核心部件称为 内核，这个内核充当了一个框架，为其他基于内核的调试工具提供服务和支持。在这个框架中，内核模拟了 CPU 环境，使得不同的工具可以在这种虚拟环境中执行。 此外，Valgrind 的其他工具类似于 插件，它们利用内核提供的服务来完成特定的内存调试任务。这些工具各有其独特的功能，可以帮助开发者提高程序的稳定性和性能。以下是几个重要的工具及其详细作用： Memcheck：这是 Valgrind 中最为常用的工具，负责检测程序中的内存泄漏、未初始化内存读取以及无效的内存访问等问题。想象一下，当一个程序在运行时动态分配了一块内存以存储用户输入的数据，但在程序结束时没有正确释放这块内存，导致内存持续被占用。Memcheck 可以通过提供详细的错误报告，帮助开发者准确定位这些内存泄漏。例如，开发者可能会看到类似于“在函数 foo() 中，分配的内存未被释放”的报告，这让他们可以追踪问题所在并及时修复，避免程序长时间运行导致的性能下降。 Cachegrind：这个工具用于分析程序的缓存使用情况，提供缓存命中率和踩踏率等信息，帮助开发者优化程序的性能。缓存命中率指的是程序对于已经存储在缓存中的数据的访问，若缓存命中率较高，程序的运行将更为迅速而高效；相反，高踩踏率则显示程序频繁地访问未缓存的数据，导致性能下降。例如，若 Cachegrind 反馈缓存踩踏率过高，开发者可以根据反馈重新考量数据的访问模式，或重构数据结构，以提升缓存效率。这种微调常常能显著提高程序的运行速度。 Callgrind：用于性能分析，记录程序函数的调用次数及调用关系。通过对函数调用的详细记录，开发者可以方便地发现运行中的瓶颈。例如，如果某个函数被调用的次数异常增多，它很可能成为程序的性能瓶颈，开发者就可以针对这一点进行深入的优化，从而提升整体性能。这种方式类似于在交通流量中找出拥堵路段，修复这些“堵点”可以大幅改善整体流畅度。 Helgrind：专门检查多线程程序中的竞争问题，它帮助开发者识别在访问共享资源时可能发生的竞争条件。假设一个多线程程序中多个线程同时尝试更新同一数据，若没有正确的同步机制，可能会导致数据不一致或错误的结果。Helgrind 能够监测到这些潜在的竞争情况，提醒开发者注意并采取适当的锁机制来确保数据的完整性。 Massif：它主要用于分析程序的堆栈使用情况，帮助开发者识别内存使用的热点。Massif 通过定期捕获程序的堆内存使用情况绘制内存分配图。这使得开发者可以轻松识别出哪些部分的内存占用率过高，从而采取措施减少内存使用。例如，若 Massif 报告某个功能模块内存占用接近极限，开发者就能够聚焦于该模块进行优化，可能是通过减少不必要的对象创建，或利用更高效的数据结构。 Extensions：开发者还可以利用 Valgrind 的核心功能，自行编写特定的内存调试工具。这就相当于开发者在现有工具的基础上，创造出一款符合自己独特需求的定制化工具，进一步提升程序的调试能力。 Valgrind 的体系结构如图所示，体现出内核与多种调试工具之间密切的协作关系。通过这种设计，Valgrind 不仅能够增强对程序的调试能力，还能为开发人员提供更为详尽的内存与性能分析，确保程序在各种操作条件下的可靠性。 了解 Linux 内存分布 内存分布 Memcheck 工具Valgrind 的核心组件是 Memcheck，它能够检查多种内存使用错误，包括但不限于以下几种常见问题： 未初始化的内存使用：当程序试图使用一个未初始化的变量，可能会导致不可预测的行为。例如，读取一个本应为零的缓冲区时，如果没有初始化，可能会得到一些垃圾值。 已释放内存的访问：这是一个典型的错误，表示程序试图通过指向已释放内存的指针读取或写入数据。例如，当 free 一个指针后，若继续使用该指针，很可能导致程序崩溃。 超出分配的内存范围：即尝试在已分配的内存块外进行读写，这不仅可能导致数据损坏，还可能引发安全隐患。举个例子，当分配了 10 字节的内存却试图写入 15 字节数据时，就会发生这种错误。 非法的堆栈访问：访问某些不应访问的堆栈区域，通常由于数组越界或错误的指针运算导致。 内存泄漏：指程序在动态分配内存后失去对该内存块的所有指针，导致这些内存无法再被访问或释放，最终可能导致程序的可用内存逐渐耗尽。 内存分配与释放的不匹配：指在使用 malloc 和 free、new 和 delete 时不匹配的情况。比如，如果用 malloc 分配了内存，但用 delete 去释放，就会产生错误。 重叠的内存操作：在使用 memcpy() 等函数时，若源地址和目标地址重叠，可能会导致意外的数据覆盖。 重复的释放：指尝试对同一内存块进行多次释放，导致未定义行为。 Memcheck 的内存检测原理Memcheck 是一种强大工具，可以有效识别程序中的内存问题，其核心机制在于两个全局的表格：Valid-Value 表和 Valid-Address 表。这两个表格通过比特位（bits）精确地追踪进程的内存状态，确保每个字节的可用性和有效性。Memcheck 检测内存问题的原理如下图所示： 地址空间管理对于进程的每一个字节（byte），Memcheck 会为其分配对应的 8 个 bits，用于记录这个字节是否拥有有效且已初始化的值。这意味着每当程序试图访问或修改内存时，Memcheck 都会查看与该字节相关联的 bits，以确定该内存位置的有效性。 例如，考虑一个程序试图读取数组中的一个元素。在进行读取操作之前，Memcheck 首先会检查该元素对应的 8 个 bits。如果这些 bits 中的任意一个指示该元素没有被初始化，程序就会被告知尝试访问未初始化的内存，这是因为这些 bits 确保了该内存的状态被正确追踪。 有效性跟踪除了 Valid-Value 表外，Memcheck 还维护了一个 1 bit 的 Valid-Address 表，专门用于标识内存地址是否可以被读写。每当程序试图进行读写操作时，该操作都会经过该表的验证。 假设一个程序企图修改一个无效的内存地址，无论是因为地址已经释放还是超出了有效范围，Memcheck 会提前捕获这个错误。一旦发现相关的 A bit 显示该地址无效，Memcheck 将立即报告为读写错误。这种即时反馈极大地帮助开发者定位问题，避免潜在的程序崩溃。 核心与虚拟 CPU 环境值得注意的是，Memcheck 的内部核（core）运行在一个类似于虚拟的 CPU 环境中。这意味着，当进程中的一个字节被加载到实际的 CPU 时，其对应的 V bit 也会一同被加载到虚拟环境中。这种机制确保了即便是在底层硬件交互的瞬间，内存的有效性记录依然得到维护。 当程序的寄存器中的值被用于生成内存地址，或当该值可以影响程序的输出时，Memcheck 会进行一次额外的检查，确保所有相关的 V bits 已被正确设置。如果发现这些 bits 指向一个尚未初始化的值，Memcheck 将发出关于使用未初始化内存的错误警告。这种设计进一步增强了程序运行的安全性和正确性。 总体来说，Memcheck 通过严密的内存追踪机制，帮助开发者有效识别并解决内存相关的问题，确保程序的稳定和高效。 Memcheck 内存问题检测机制Memcheck 是一个强大的工具，专门用于检测程序中的内存问题。其核心在于构建两个全局表，这使得它能够高效、准确地运行内存检查。 内存和寄存器监测对于进程中的每一个字节（byte），Memcheck 会对应地创建 8 个 bits。而每个 CPU 寄存器同样会对应一个 bit 向量。这个 bit 向量的作用是记录某个字节或寄存器的值是否有效且已初始。例如，如果程序试图访问一个数组的元素，而该元素之前未被初始化，Memcheck 的记录系统会标记这个字节的对应 bit，帮助开发者追踪导致错误的情况。 地址有效性跟踪此外，Memcheck 还为进程地址空间中的每一个字节创建了一个单独的 bit，用以记录该地址是否能被正确读写。所谓读写，是指程序尝试从该内存地址读取数据或将数据写入该内存地址。这一机制确保系统能快速识别出无效内存访问，避免程序因使用非法地址而崩溃。 检测原理Memcheck 的检测机制可总结为以下两个表： Valid-Value 表：用于追踪每个内存字节和寄存器的值是否有效。 Valid-Address 表：用于监控每个内存字节的可读写性。 读取与写入内存的过程当程序尝试读写内存中的某个字节时，Memcheck 首先检查该字节对应的有效地址 bit（A bit）。如果 A bit 表明该位置为无效，则 Memcheck 会立即报告一个读写错误。举例来说，如果程序尝试访问一个指向清空或未分配内存的指针，Memcheck 会捕捉到此类错误，提示开发者该操作是非法的。 虚拟 CPU 环境内核（core）运作像一个虚拟 CPU 环境。这样，当某个字节被加载到真实 CPU 时，其对应的有效值 bit（V bit）也同时加载进虚拟 CPU 环境。一旦寄存器的值用于生成内存地址，或可能影响程序的输出，Memcheck 就会进行又一次的检查，确保 V bits 记录的值是有效且已初始化的。如果发现该内存地址的值尚未被合理初始化，Memcheck 将会报告出错，提示开发者存在未初始化内存的风险。这种详细的检查机制大大简化了调试过程，减少了难以排查的问题。 通过这一系列的监控和记录，Memcheck 有效地帮助开发者识别和修复内存相关的错误，提升代码的稳定性和可靠性。 安装 Valgrind以下是 Valgrind 的安装步骤，确保你有 wget 和 make 等基本工具： wget http://valgrind.org/downloads/valgrind-3.4.1.tar.bz2tar xvf valgrind-3.4.1.tar.bz2cd valgrind-3.4.1/./configure --prefix=/usr/local/webserver/valgrindmakemake install 使用示例准备好程序#include stdlib.h // 引入标准库，提供malloc和free函数的声明void fun() // 分配内存：为10个整数分配足够的空间 int *p = (int *)malloc(10 * sizeof(int)); // 检查内存是否分配成功 if (p == NULL) // 如果分配失败，输出错误信息并退出函数 fprintf(stderr, Memory allocation failed ); return; // 错误的内存访问：尝试访问数组的第11个元素（索引为10） // 这是越界访问，可能导致未定义行为 p[10] = 0; // 在 C/C++ 中，数组的有效索引是 0 到 9，而这里越界了 // 在实际应用中，访问越界的内存可能导致程序崩溃或数据损坏。 // 为了避免这种情况，确保访问的索引在合理范围内非常重要 // 正确的访问应该是 p[0] 到 p[9] // 记得释放分配的内存，防止内存泄漏 //free(p);int main() fun(); // 调用 fun 函数 return 0; // 返回 0，表示程序成功结束 细节说明： 使用 malloc 函数分配的内存等同于 10 个 int 类型的空间，每个 int 通常占用 4 字节，因此总共分配了 40 字节的内存。 在分配内存后，使用指针 p 存取内存，但必须确保访问的数组索引不超过初始化的大小。错误的写法 p[10] 实际上是访问了未分配的内存区域，可能导致程序意外崩溃。 在成功使用 malloc 之后，应该立即检查返回指针是否为 NULL，以确认内存是否成功分配。 最后，使用 free 函数释放掉之前分配的内存，以避免内存泄漏。这是内存管理中的一个好习惯，确保程序运行高效、稳定。 为了确保 Valgrind 能够准确发现并定位源代码中的错误，我们在编译程序时需要加入 -g 参数，开启调试信息。同时，为了避免优化影响调试，推荐使用 -O0 选项，这样虽然会降低程序的运行效率，但能够保证调试信息的准确性。这一过程所使用的示例程序名为 sample.c，编译器选择 gcc。生成可执行程序的命令如下： gcc -g -O0 sample.c -o sample 在此命令中，-g 选项使得编译器在生成的可执行文件中包含调试符号，从而帮助 Valgrind 定位到出错的源代码行。而 -O0 选项则禁止优化，确保每条代码都与源代码一致。 在 Valgrind 下，运行可执行程序Valgrind 主要用于调试内存相关的问题，这意味着我们可以直接对编译得到的二进制可执行文件进行分析，无需重新编译源代码。运行 Valgrind 命令的通用格式如下： valgrind [valgrind-options] your-prog [your-prog-options] Valgrind 的参数分为核心参数和特定工具的参数。核心参数适用于所有的 Valgrind 工具，而特定工具的参数则依赖于选择的具体工具。Valgrind 默认会启动 memcheck 工具，但你也可以使用 --tool=tool name 选项指定其他工具。Valgrind 提供丰富的参数集以满足不同的调试需求，详细信息请参考其用户手册。 在这个示例中，我们选择使用 memcheck 工具，可以执行以下命令运行程序： valgrind ./sample 分析 Valgrind 的输出信息当我们运行上面的命令时，Valgrind 会产生一系列输出信息。这些信息将帮助我们定位到程序中的内存问题。输出中包含了多个部分： 左侧显示的数字（如 32372）标识了进程 ID，帮助用户跟踪正在分析的程序。 顶部的红色框显示 Valgrind 的版本信息，例如 “Valgrind-3.16.1”。 中间的红色框展示了 Valgrind 在运行被测试程序时检测到的内存错误。这些信息包括： 非法写操作的描述，例如“Invalid write of size 4”。 报错时的函数堆栈信息，包括函数的调用链（比如 fun() 到 main()）。 涉及非法写操作的具体地址空间，通常是类似于 “0x4a3c4” 的地址。 最底部的红色框会总结发现的内存问题，以及内存泄漏的统计报告。例如，可能会有“HEAP SUMMARY”部分，显示内存泄漏的大小（如“40 bytes”）。 根据这些信息，我们可以确切知道示例程序存在两个主要问题： 在 fun 函数中动态申请的堆内存没有被释放，导致内存泄漏。 代码中存在对堆内存的越界访问问题。 这两个问题均被 Valgrind 有效识别和标记，为我们修复代码提供了依据。通过仔细分析这些输出信息，开发者能够准确定位并修复潜在的错误。 Memcheck 工具进行 CC++ 的内存泄漏检测在系统编程中，有效地管理内存是至关重要的。随着程序与系统底层的接触越深，面临的内存问题也越多。处理这些问题时，常常会遇到棘手的调试挑战，所以使用合适的工具是非常关键的。在众多可用工具中，Valgrind 并不是一个新的名字，它是一个强大的开源内存管理框架。 Valgrind 是一个动态分析工具的框架，包含多种工具，各自针对不同类型的调试和分析任务，以帮助提高程序的质量和稳定性。Valgrind 的模块化架构使得开发新工具变得相对简单，而不会对现有功能产生负面影响。很多实用的工具都是作为标准配备，而一些工具则只对特定用户群体有用，比如 Lackey 和 Nulgrind 主要用于演示和测试目的。 在这篇文章中，我们将重点讨论 Memcheck 工具，它是 Valgrind 的核心功能之一。 使用 Valgrind MemcheckMemcheck 工具的基本使用方式如下： valgrind --tool=memcheck ./a.out 在以上命令中，valgrind 是调用工具的主命令，而 --tool 选项指定我们要使用的工具为 memcheck。a.out 是我们希望通过 Memcheck 进行测试的可执行文件。 Memcheck 工具可以检测多种与内存相关的问题，以下是一些主要的能力： 未释放内存的使用 对释放后内存的读写 对已分配内存块尾部的读写 内存泄漏 不匹配的使用 malloc/new/new[] 和 free/delete/delete[] 重复释放内存 我们将逐一探讨这些场景，使用代码示例和输出结果来说明。 1. 使用未初始化的指针#include stdio.h#include stdlib.hint main(void) char *p; char c = *p; // 未初始化的指针 printf( [%c] ,c); return 0; 当我们尝试通过未初始化的指针 p 读取内存时，运行 Memcheck 将显示如下输出： $ valgrind --tool=memcheck ./val==2862== Memcheck, a memory error detector==2862== Use of uninitialised value of size 8==2862== at 0x400530: main (valgrind.c:8)==2862== ...==2862== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 4 from 4) 2. 在内存释放后进行读写#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; free(p); // 先释放内存 char c = *p; // 再次访问已释放内存 printf( [%c] ,c); return 0; 运行上面的代码后，我们得到了以下结果，Memcheck 报告了一个无效读取： $ valgrind --tool=memcheck ./val==2849== Invalid read of size 1==2849== at 0x400603: main (valgrind.c:30)==2849== Address 0x51b0040 is 0 bytes inside a block of size 1 freed 3. 从已分配内存块尾部进行读写#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; char c = *(p + 1); // 访问超出分配的内存 printf( [%c] ,c); free(p); return 0; 该代码同样会引发内存读取问题： $ valgrind --tool=memcheck ./val==2835== Invalid read of size 1==2835== at 0x4005D9: main (valgrind.c:25) 4. 内存泄漏#include stdio.h#include stdlib.hint main(void) char *p = malloc(1); *p = a; // 还未释放，内存泄漏 return 0; 运行此代码时，Memcheck 会报告检测到内存泄漏： $ valgrind --tool=memcheck --leak-check=full ./val==2888== LEAK SUMMARY:==2888== definitely lost: 1 bytes in 1 blocks 5. 不匹配的使用 malloc/new/new[] 和 free/delete/delete[]#include stdio.h#include stdlib.h#include iostreamint main(void) char *p = (char*)malloc(1); delete p; // 错误，应该使用 free() return 0; 运行上述代码，Memcheck 提供了清晰的错误信息： $ valgrind --tool=memcheck --leak-check=full ./val==2972== Mismatched free() / delete / delete [] 6. 重复释放内存#include stdio.h#include stdlib.hint main(void) char *p = (char*)malloc(1); free(p); free(p); // 重复释放 return 0; 执行后会返回以下错误信息，表明我们对同一指针调用了两次释放操作： $ valgrind --tool=memcheck --leak-check=full ./val==3167== Invalid free() / delete / delete[] 在本文中，我们详细介绍了 Valgrind 内存管理框架，并通过 Memcheck 工具展示了它如何帮助开发者简化内存管理，避免常见的内存问题。 Valgrind 是一个强大的工具，能够检测到许多手动检查不易发现的内存错误。 如果你想在开发环境中使用 Valgrind，Qt Creator 提供了对 Valgrind 的前端集成，可以轻松分析和优化代码。也可以使用 KCacheGrind 分析 Valgrind 输出的信息，从而进一步优化性能。 利用 valgrind 定位内存泄漏问题通过实例来看看如何利用 Valgrind 来定位内存泄漏问题。以下是要分析的程序示例： #include stdlib.h#include stdio.hchar* getMemory() char *p = (char *)malloc(30); return p;int main() char *p = getMemory(); p = NULL; return 0; 对于这段程序，任何对 CC++ 有基本了解的人都能轻易识别出其中的内存泄漏问题。getMemory 函数分配了 30 字节的内存，但在 main 函数中，仅仅将指针 p 设置为 NULL，却没有释放那段内存。接下来，我们使用 Valgrind 工具进行检测： [root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==19226== Memcheck, a memory error detector==19226== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==19226== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==19226== Command: ./a.out==19226====19226====19226== HEAP SUMMARY:==19226== in use at exit: 30 bytes in 1 blocks==19226== total heap usage: 1 allocs, 0 frees, 30 bytes allocated==19226====19226== 30 bytes in 1 blocks are definitely lost in loss record 1 of 1==19226== at 0x4C278FE: malloc (vg_replace_malloc.c:270)==19226== by 0x4005B5: getMemory() (in /root/valgrind-3.8.1/bin/a.out)==19226== by 0x4005CC: main (in /root/valgrind-3.8.1/bin/a.out)==19226====19226== LEAK SUMMARY:==19226== definitely lost: 30 bytes in 1 blocks==19226== indirectly lost: 0 bytes in 0 blocks==19226== possibly lost: 0 bytes in 0 blocks==19226== still reachable: 0 bytes in 0 blocks==19226== suppressed: 0 bytes in 0 blocks==19226====19226== For counts of detected and suppressed errors, rerun with: -v==19226== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 从上面的输出中可以清楚地看到，getMemory 函数中调用 malloc 的地方存在内存泄漏。输出中最左边的 19226 表示进程号，这对于多进程的调试尤为重要。 然而，在代码量较大的情况下，手动查找泄漏的地方可能会比较困难。我们可以使用 Valgrind 提供的更详细的信息，来标识出发生内存泄漏的代码行。为了实现这一点，我们需要在编译时加入 -g 参数，并且确保编译后的程序没有被 strip 处理。我们可以这样做： [root@xxx ~/valgrind-3.8.1/bin]# g++ -g test.cpp[root@xxx ~/valgrind-3.8.1/bin]#[root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==20448== Memcheck, a memory error detector==20448== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==20448== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==20448== Command: ./a.out==20448====20448====20448== HEAP SUMMARY:==20448== in use at exit: 30 bytes in 1 blocks==20448== total heap usage: 1 allocs, 0 frees, 30 bytes allocated==20448====20448== 30 bytes in 1 blocks are definitely lost in loss record 1 of 1==20448== at 0x4C278FE: malloc (vg_replace_malloc.c:270)==20448== by 0x4005B5: getMemory() (test.cpp:5)==20448== by 0x4005CC: main (test.cpp:11)==20448====20448== LEAK SUMMARY:==20448== definitely lost: 30 bytes in 1 blocks==20448== indirectly lost: 0 bytes in 0 blocks==20448== possibly lost: 0 bytes in 0 blocks==20448== still reachable: 0 bytes in 0 blocks==20448== suppressed: 0 bytes in 0 blocks==20448====20448== For counts of detected and suppressed errors, rerun with: -v==20448== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 可以看到，输出中已经显示了具体的文件名和行号。例如，getMemory 函数在 test.cpp 的第 5 行，main 函数在第 11 行。这些信息极大地方便了开发者迅速定位问题。 修复内存泄漏后，代码应该改为： #include stdlib.h#include stdio.hchar* getMemory() char *p = (char *)malloc(30); return p;int main() char *p = getMemory(); if (p != NULL) free(p); p = NULL; return 0; 在这个版本中，我们在确定 p 不为 NULL 时使用 free 函数释放了之前分配的内存。现在再次使用 Valgrind 检测一下： [root@xxx ~/valgrind-3.8.1/bin]# g++ -g test.cpp[root@xxx ~/valgrind-3.8.1/bin]#[root@xxx ~/valgrind-3.8.1/bin]# ./valgrind --tool=memcheck --leak-check=yes --show-reachable=yes ./a.out==21033== Memcheck, a memory error detector==21033== Copyright (C) 2002-2012, and GNU GPLd, by Julian Seward et al.==21033== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info==21033== Command: ./a.out==21033====21033====21033== HEAP SUMMARY:==21033== in use at exit: 0 bytes in 0 blocks==21033== total heap usage: 1 allocs, 1 frees, 30 bytes allocated==21033====21033== All heap blocks were freed -- no leaks are possible==21033====21033== For counts of detected and suppressed errors, rerun with: -v==21033== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 6 from 6)[root@xxx ~/valgrind-3.8.1/bin]# 检验结果显示没有内存泄漏了，所有分配的内存块都成功释放。这意味着我们的代码现在更加安全和高效，确保在再次执行时不会导致内存的浪费或潜在的崩溃问题。 ARM 交叉编译1. 下载及编译准备首先，您需要下载 Valgrind 的源代码并进行解压。可以使用以下命令： wget http://valgrind.org/downloads/valgrind-3.12.0.tar.bz2tar xvf valgrind-3.12.0.tar.bz2cd valgrind-3.12.0apt-get install automake./autogen.sh 下载指令说明：wget 用于从互联网下载文件，tar 用于解压缩打包文件。 依赖工具：automake 是自动化生成 Makefile 的工具，确保您的系统中安装了它。 初始化脚本：./autogen.sh 会创建配置文件，使后续编译步骤顺利进行。 2. 交叉编译在配置阶段，需要对 configure 文件进行修改，以适应 ARM 架构。具体步骤如下： vi configure # 使用文本编辑器打开 configure 文件 找到如下行： armv7*) 将其修改为： armv7*|arm) 接下来，您可以执行以下命令进行配置和编译： ./configure --host=arm-linux CC=arm-none-linux-gnueabi-gcc CPP=arm-none-linux-gnueabi-cpp CXX=arm-none-linux-gnueabi-g++makemake install --prefix=/home/dcj/valgrind 配置选项说明： --host=arm-linux：指定目标平台是 ARM。 CC=arm-none-linux-gnueabi-gcc：指定交叉编译器。 --prefix=/home/dcj/valgrind：指明安装路径，确保与开发板上目录一致。 成功后，在 /home/dcj/valgrind 目录下会生成四个重要的子目录：bin、include、lib 和 share。确保这些文件能够在您的开发环境中找到。 如果不按预期设置 --prefix，在运行 Valgrind 时可能会出现错误提示： valgrind: failed to start tool ‘memcheck’ for platform ‘arm-linux’: No such file or directory 3. 运行将安装好的 Valgrind 目录通过 WinSCP 工具复制到目标板的 /home/dcj/ 下。完成后，您需要为 bin 目录下的可执行文件给予执行权限： chmod -R +x /home/dcj/valgrind/bin/ 此时，如果在尝试运行 bin 目录下的 valgrind 时收到如下错误： valgrind: failed to start tool memcheck for platform arm-linux: Permission denied 解决方法：这是因为 Valgrind 的库文件权限不足。可以通过以下命令修复： export VALGRIND_LIB=/home/dcj/valgrind/lib/valgrind chmod -R +x /home/dcj/valgrind/lib/valgrind/ 环境变量设置：通过 export 声明环境变量，Valgrind 能够找到其必要的库文件。 权限修改：确保所有文件都有适当的执行与访问权限，这样 Valgrind 才能正常工作。 完成以上步骤后，您便可以在 ARM 上运行 Valgrind 进行内存泄漏等问题检查。 补充Valgrind 无法发现的问题Valgrind 是一个强大的内存调试工具，然而，它存在一些显著的局限性。主要的问题之一是，它无法检查在栈上分配的静态数组的边界。例如，考虑以下代码： int main() char x[10]; x[11] = a; // 越界写入 在这个例子中，x 是一个大小为 10 的字符数组。然而，程序尝试访问 x[11]，这会导致越界写入。在实际应用中，这种错误可能会导致不可预测的行为，包括数据损坏或程序崩溃。然而，Valgrind 并不会发出警告。这是因为静态数组是在栈上分配的，Valgrind 并不跟踪栈内存的边界。 一种解决方案是将静态数组转换为动态分配的内存。具体来说，可以使用 malloc 来分配内存，但要注意在使用完后调用 free 来防止内存泄漏。比如： int main() char *x = (char *)malloc(10 * sizeof(char)); // 动态分配内存 if (x == NULL) return 1; // 检查内存分配是否成功 x[11] = a; // 仍然是越界写入，但Valgrind会捕捉到 free(x); // 释放内存 尽管这样可以让 Valgrind 能够检测出问题，但动态分配的内存可能引入其他问题，如未释放的内存（unfreed memory），从而增加内存管理的复杂性。 额外的警告信息Valgrind 的一个显著缺点是它消耗的内存量，通常是你源程序需求的两倍。例如，如果你的程序需要 100MB 的内存，Valgrind 可能会使其消耗高达 200MB。这在检测大型内存问题时可能会引发问题。 此外，Valgrind 的运行时间比普通执行程序要长，通常是因为它需要进行深度内存检查。这对于通常运行较快的程序来说，可能不是什么大问题，但对于本身执行速度较慢的程序，这可能会引起很大的困扰。例如，一段原本在十秒内完成的程序，使用 Valgrind 后，可能需要十分钟或更长时间。 这种内存消耗和运行时间的增加，对于开发人员在调试过程中来说，可能需要平衡严谨的内存检查与开发效率之间的关系。所以，对于在较大项目中频繁遇到内存问题的开发者来说，合理选择使用 Valgrind 的时机，将是提高工作效率的关键。","categories":["1.语言","调试输出"]},{"title":"段错误","path":"/2024/12/17/1-语言-调试输出-段错误/","content":"段错误是什么段错误，也称为“分段错误”，是指在程序运行过程中，软件试图访问的内存地址超出了操作系统为该程序所设定的有效内存空间。例如，这种情况可能发生在程序试图访问一个不存在的内存地址，或者非法访问系统保护的内存区域，以及尝试写入一个只读内存地址等。对于“段错误”，我们可以参考以下准确的定义： “分段错误是一种特定的错误状态，会在计算机软件运行时发生。简而言之，当程序尝试访问一个它没有权限访问的内存位置，或以不允许的方式进行内存操作（如写入只读位置或重写操作系统部分）时，就会产生段错误。” 段错误产生的原因 访问不存在的内存地址：程序可能指向一个未分配或已释放的地址，例如一个未初始化的指针。 int *ptr = NULL;*ptr = 0; // 尝试写入NULL地址 访问系统保护的内存地址：当程序试图修改或读取保留给操作系统的数据时，会导致段错误。 访问只读的内存地址：例如，程序试图对一个常量字符串进行修改，会产生错误。 char *ptr = test;strcpy(ptr, TEST); // 尝试写入只读内存 栈溢出：反复调用自身（如递归）而不设置适当的终止条件，会导致栈空间耗尽。 其他原因：如使用了已释放的内存、数据类型转换错误等。 段错误信息的获取段错误发生时，系统所提供的错误信息通常较少，为了准确诊断问题，可以通过以下工具获取详细信息。 1. dmesg使用 dmesg 命令可以查看最近发生的系统日志，包括段错误的具体信息，例如程序名称、内存地址、指令指针地址及堆栈指针地址等。 $ dmesg[ 2329.479037] segfault3[2700]: segfault at 80484e0 ip 00d2906a sp bfbbec3c error 7 in libc-2.10.1.so[cb4000+13e000] 2. -g 参数在使用 gcc 编译程序时添加 -g 参数，可以在生成的二进制文件中包含符号信息，方便后续调试。 $ gcc -g -o segfault3 segfault3.c 3. nm使用 nm 命令可以列出二进制文件中的符号表，包括符号地址、类型及名称等，有助于确定发生段错误的位置。 $ nm segfault308049f20 d _DYNAMIC08049ff4 d _GLOBAL_OFFSET_TABLE_...080483e4 T main 4. ldd使用 ldd 命令可以查看程序依赖的 lib。通过可视化库的信息，帮助确定段错误是程序本身导致，还是依赖库的问题。 $ ldd ./segfault3linux-gate.so.1 = (0x00e08000)libc.so.6 = /lib/tls/i686/cmov/libc.so.6 (0x00675000) 段错误的调试方法1. 使用 printf 输出信息在程序的关键代码附近加入 printf 输出，可以帮助追踪程序执行过程中的状态，使开发者能够快速定位段错误发生的位置。 为了便于使用 printf，可以利用条件编译，在编译时决定是否输出调试信息： #ifdef DEBUGprintf(Debug info: ...);#endif 2. 使用 gcc 和 gdb 确保程序在编译时加上 -g 参数以启用调试信息。 使用 gdb 命令启动调试： $ gdb ./segfault3 运行程序后，若出现段错误，gdb 会输出错误信息，指明发生错误的位置。 Program received signal SIGSEGV, Segmentation fault.0x001a306ain memcpy() from /lib/tls/i686/cmov/libc.so.6 通过 quit 命令结束调试会话。 3. 使用 core 文件和 gdb在 Linux 系统中，当程序因段错误而异常退出时，若配置正确，会生成一个 core 文件。该文件包含程序的运行状态信息，可以用 gdb 对其进行分析。 检查并可能修改 core 文件生成的限制： $ ulimit -c$ ulimit -c unlimited 运行程序生成 core 文件： $ ./segfault3Segment fault (core dumped) 使用 gdb 加载 core 文件进行调试： $ gdb ./segfault3 core 4. 使用 objdumpobjdump 可以提供程序的汇编代码，从而进一步分析段错误发生的指令。 查找最近的段错误信息，如地址、指针等。 使用 objdump 来查看汇编细节，并找到指向的汇编指令。 5. 使用 catchsegvcatchsegv 命令是专门捕获段错误的工具，通过动态加载库实现捕获并输出详细的错误信息。 一些注意事项 考虑错误原因：在面对段错误时，首先明确段错误的定义并追踪引发原因。 指针初始化：在定义指针后，要立即初始化，使用前确保其不为 NULL。 数组安全：确保数组被初始化，访问时避免越界。 内存管理：注意变量的生存周期，不要使用已释放的内存。 合理控制格式：在处理变量时，控制格式应当合理，避免类型错误。","categories":["1.语言","调试输出"]},{"title":"微信公众号","path":"/2024/12/17/0-平台-服务器-微信-公众号配置/","content":"微信公众号端配置需要配置公众号的相关信息，以确保能够接收微信的消息。在公众号管理后台，找到消息服务器设置，修改以下信息： URL: 填入你的云服务器的 IP 地址，后面加上路径，如 /chatgpt。注意: 由于默认只能使用 80 端口，所以不要在 URL 后添加端口号。 Token: 这里填写你之前设置的 token，以确保消息的安全接入。 EncodingAESKey: 随机生成一个字符串，用作消息加解密的密钥。 云服务器端配置基础配置 修改云服务的安全组，确保开放 80 端口。 服务端代码这里需要我们自定义处理用户发送过来的消息。首先，确保安装必要的依赖，werobot 是微信公众号官方推荐的用于自定义消息处理的模块。你可以通过以下命令安装： pip install werobotpip install openai 下面是一个示例代码，展示了如何创建一个基础的微信机器人。 import werobot # token 是微信公众号用来指定接入当前云服务器的服务凭证，起到认证的作用robot = werobot.WeRoBot(token=123456) @robot.handler def hello(messages): # messages.content 是用户发送的消息内容 print(messages.content) return hello! # 配置机器人监听的主机和端口robot.config[HOST] = 0.0.0.0 robot.config[PORT] = 80 # 启动机器人robot.run() 运行时需要加上 sudo 在这段代码里，不管用户发送什么消息，机器人都会回复 “hello!”。通过更改 hello 函数里的返回值，你可以自定义机器人的回复内容。 import werobot from openai import OpenAI# 设置 OpenAI 的 API 密钥client = OpenAI( # defaults to os.environ.get(OPENAI_API_KEY) api_key=YOUR API KEY, base_url=https://api.chatanywhere.tech/v1)# 初始化 WeRoBot 实例robot = werobot.WeRoBot() class RobotConfig(object): HOST=0.0.0.0 PORT=80 TOKEN=your token # 微信公众号的接入凭证robot.config.from_object(RobotConfig) # 非流式响应def generate_response(prompt): 为提供的对话消息创建新的回答 Args: messages (list): 完整的对话消息 messages = [role: user,content: prompt,] completion = client.chat.completions.create(model=gpt-3.5-turbo, messages=messages) return (completion.choices[0].message.content) @robot.handler def hello(messages): print(messages.content) return generate_response(messages.content) if __name__ == __main__: robot.run() #流式传输def gpt_35_api_stream(messages: list): 为提供的对话消息创建新的回答 (流式传输) Args: messages (list): 完整的对话消息 stream = client.chat.completions.create( model=gpt-3.5-turbo, messages=messages, stream=True, ) for chunk in stream: if chunk.choices[0].delta.content is not None: print(chunk.choices[0].delta.content, end=)if __name__ == __main__: # 流式调用 gpt_35_api_stream(messages) 这段代码集成了 ChatGPT 服务。机器人会对用户发送的每一条消息生成一个基于 ChatGPT 的响应。你只需替换 你的api_key 和 your token 为你实际使用的密钥。 增加语音消息支持-待补充 语音消息识别转文字 文字输入以上 API 发送定时消息提醒-待补充爬取某页面并自动回复这是一个结合了 WeRoBot、OpenAI API 和网页爬取功能的微信自动回复机器人，以下是详细的功能模块和工作原理： 模块依赖 werobot：一个流行的微信机器人开发框架，它提供了接收和回复微信消息的接口，允许开发者快速建立与用户的互动。 openai：用于调用 OpenAI 的 API，例如 GPT-3.5，它能够生成高质量的文本响应，进行智能对话。 requests：一个专门用于发送 HTTP 请求的库，能方便地获取网页数据，例如获取网页的 HTML 内容。 BeautifulSoup：用于解析 HTML 数据的库，能够帮助提取网页中的有用信息，如特定的链接或文本。 pandas、re 和其他模块：虽然这些模块在本代码中未被使用，但通常用于数据处理、正则表达式匹配等功能，可以使数据操作更高效。 配置参数 headers：包含用户代理（User-Agent）、授权信息（Authorization）和 Cookies，可以模拟一个正常用户的浏览行为，例如避免被网站的防爬虫机制阻止。 OpenAI 客户端：配置 API key 和 base URL，以便正确调用 OpenAI 的服务。 WeRoBot 实例：初始化一个微信机器人实例，用于处理消息和与微信 API 交互。 RobotConfig 类：存储服务器配置参数，提供可变的连接配置： HOST 和 PORT：指定服务器监听的主机地址和端口号，例如 HOST 可设置为 0.0.0.0（监听所有可用网络）以允许外部访问。 TOKEN：用于微信公众号接入时的校验凭证，以确保接入的安全性。 GPT 回复 当用户发送消息时，系统将用户的消息作为 prompt 传递给 OpenAI API，获取 GPT-3.5 模型生成的回复。 发送的 messages 参数将模拟对话历史，目前只包含用户的提问，未来可以扩展包括机器人的回复，以便实现更连贯的对话。 爬取某网页 通过 HTTP 请求获取指定网页的数据，并使用 BeautifulSoup 进行解析。 查找网页中的所有链接，特别过滤出特定内容，比如包含特定网址（如 https://********.com/）。 进行二次爬取时，再次提取所有以 https://pan.quark 开头的链接，并将其拼接成字符串返回，以供后续处理。 该功能可以用于根据关键词抓取特定网页中的相关链接，方便用户快速获取目标信息。 微信消息处理逻辑 使用 @robot.handler 装饰器来定义消息处理函数，负责处理用户的微信输入。 如果用户输入的消息以“夸克”开头： 从用户的输入中提取关键词，将其拼接至基本 URL 后，形成完整的链接。 调用 getUrl 函数，爬取相关网页并返回抓取的结果。 当输入不以“夸克”开头时，则调用 generate_response，通过 GPT-3.5 自动生成智能回复。 最终返回构建的字符串 retMsg，作为微信消息的回复内容。 import werobot#import openaifrom openai import OpenAIimport reimport jsonimport requestsimport pandas as pdfrom bs4 import BeautifulSoupfrom functools import partialfrom datetime import datetime, timedeltaheaders = User-Agent: ********, Authorization: ********, Cookie: ********client = OpenAI( # defaults to os.environ.get(OPENAI_API_KEY) api_key=********, base_url=********)# 初始化 WeRoBot 实例robot = werobot.WeRoBot()class RobotConfig(object): HOST=******** PORT=80 TOKEN=******** # 微信公众号的接入凭证robot.config.from_object(RobotConfig)def generate_response(prompt): messages = [role: user,content: prompt ,] 为提供的对话消息创建新的回答 Args: messages (list): 完整的对话消息 completion = client.chat.completions.create(model=gpt-3.5-turbo, messages=messages) return (completion.choices[0].message.content)def getUrl(url): response = requests.get(url,headers=headers) str= # 检查请求是否成功 if response.status_code == 200: # 解析HTML内容 soup = BeautifulSoup(response.content, html.parser) #print(soup) # 查找所有class为info790的元素 elements = soup.find_all(class_=container) for links in elements: link = links.find_all(a, href=True) # 找到所有带有href属性的a标签 for a in link: #print(a[href]) if(a[href].startswith(https://********.com/)): response2 = requests.get(a[href],headers=headers) if response2.status_code == 200: # 解析HTML内容 soup2 = BeautifulSoup(response2.content, html.parser) #print(soup) # 查找所有class为info790的元素 elements2 = soup2.find_all(a, href=True) # 找到所有带有href属性的a标签 for b in elements2: if(b[href].startswith(https://pan.quark)): str += b[href]+ \\r else: str = (f请求失败，状态码: response.status_code) return str@robot.handlerdef weChatReturn(messages): #print(messages.content) msg = messages.content; #msg = messages retMsg = if msg.startswith(夸克): url = https://********.com/?q= url += msg[3:] retMsg += getUrl(url) else: retMsg += generate_response(msg) return retMsg;if __name__ == __main__: robot.run() 公众号返回超时问题","categories":["0.平台","服务器","微信"]},{"title":"移动平均法的理论依据与计算方法","path":"/2024/12/13/4-其他-金融-移动平均法的理论依据与计算方法/","content":"移动平均法的理论依据与计算方法移动平均分析法是指用统计分析的方法，将一定时期内的证券价格（指数）加以平均，并把不同时间的平均值连接起来，形成一根移动平均线，用以观察证券价格变动趋势的一种技术分析方法。 移动平均法的理论依据移动平均的理论依据是道·琼斯理论的“平均成本”概念。该理论指出，证券市场的价格波动状况可分为：长期运动、中期运动和短期变动三种形式。其中长期运动和中期运动是两种主要的形式，其技术分析意义最大，而短期变动的影响相对较小。为了消除短期变动和其他偶然因素对证券价格变动所造成的影响，确认证券价格的变动趋势，可将一定时期内的价格或指数加以平均，即可得到一定时期的平均价格（指数）。它反映了在这一时期内购买该证券的平均成本。将证券的当前价格与平均价格进行比较，可以判断出证券价格的运动趋势。若证券价格在平均价格（指数）之上，则意味着市场的买力（需求）较大，其价格将会继续上升；反之当证券价格落到平均价格之下时，则意味着供过于求，市场卖压较重，其价格将会继续下跌。移动平均理论正是根据上述理论来对未来证券价格的变动趋势作出研判，以作出最佳的投资决策。 移动平均的计算方法移动平均理论是指通过将一段时期内的证券价格的平均价（或平均指数〕连成一条曲线，从曲线的波峰、谷底和转折之处研判证券价格运动方向，所以说，移动平均理论亦可称为移动平均线理论。 根据对数据统计处理方法的不同，移动平均可分为算术移动平均线（SMA）、加权移动平均线（WMA）和指数平滑移动平均线（EMA）三种，但不管是算术移动平均线还是加权移动平均线，均得储存大量的数据资料，且费时费力。因此，实际应用中常使用指数平滑移动平均线方法，这种方法可避免以上弊端。 指数平滑移动平均线（EMA）的计算公式如下： 其中： 为计算期中 t 日的收盘价；EMAt-1 为 t-1 日的移动平均数。 当指数平滑移动平均线起算基点不同时，起算基点较晚的计算结果，会与起算基点较早的数字有所差异。但这种差异经过稍长一段时间的平滑运算后会逐渐消失，两者趋向一致。 根据计算时期的长短，移动平均线又可分为短期、中期和长期移动平均线。通常以 5 日、10 日线观察证券市场的短期走势；以 10 日、20 日线观察中短期趋势；以 30 日、60 日线观察中期走势；以 13 周、26 周移动平均线，研判长期趋势。西方投资机构非常看重 200 天长期均线，并以此作为长期投资的依据；若行情价格在 200 天均线以下，属空头市场；反之，则为多头市场。 综合短、中、长期移动平均线，亦可研判市场多空属性。当短、中、长期均线由上而下依次排列时，可认为是多头市场（牛市）；反之，移动平均线的排列，由上而下依次为长、中、短期移动平均线时，则认为是在空头市场（熊市）。由于短期移动平均线较长期移动平均线易于反应行情价格的涨跌，所以一般又把短期移动平均线称之为“快速移动平均线”，长期移动平均线则称为“慢速移动平均线”。 移动平均线的特点移动平均线的基本思想是消除偶然因素的影响。它具有以下几个特点： 追踪趋势。移动平均线能够表示股价的趋势方向，并追踪这个趋势。如果从股价的图表中能够找出上升或下降趋势，那么，移动平均线将保持与趋势方向一致，能消除在这个过程中出现的起伏。 滞后性。在股价原有趋势发生反转时，由于移动平均线追踪趋势的特征，使其行动往往过于迟缓，调头速度落后于大趋势。 稳定性。根据移动平均线的计算方法，要想较大地改变移动平均的数值，必须当天的股价有很大的变化，因为移动平均线是几天变动的平均值。这个特点也决定了移动平均线对股价反映的滞后性。 助长助跌性。当股价突破移动平均线时，无论是向上还是向下突破，股价都有继续向突破方向发展的愿望，这就是移动平均线的助长助跌性。 支撑线和压力线的作用。移动平均线在股价走势中起支撑线和压力线的作用，即移动平均线被突破，实际上就是支撑线和压力线的被突破。 移动平均线的参数作用实际上是对上述几个特征的加强。参数选得越大，上述特征就越明显。 葛兰威尔法则与移动平均线的组合葛兰威尔法则在移动平均线的应用上，最著名的莫过于葛兰威尔的“移动平均线八大买卖法则”。此法则是以证券价格（或指数）与移动平均线之间的偏离关系来作为研判的依据。八大法则中有四条是买进法则，四条是卖出法则（见图 9-17）。 葛兰威尔八大买卖法则如下： 当平均线从下逐渐转为盘局或上升，面股价从平均线下方突破平均线，此为买进信号（见图 9-17①）。 当股价趋势线仍在平均线上方，股价下跌却并未跌破平均线且立刻反转上升，是买进信号（见图 9-17②）。 当股价虽跌破平均线，但又立刻回升到平均线上，此时平均线仍持续上升，为买进信号（见图 9-17③〕。 当股价突然暴跌，跌破且远离平均线，则极有可能止跌反弹，为买进时机（见图 9-17④）。 当股价突然暴涨，突破且远离平均线，则极有可能回档调整，为卖出时机（见图 9-17⑤）。 当平均线从上升逐渐转为盘局或下跌，而股价向下跌破平均线，为卖出信号（见图 9-17⑥）。 当股价趋势走在平均线之下，股价上升并未突破平均线且又开始下跌，是卖出信号（见图 9-17⑦）。 当股价虽然向上突破平均线，但又立刻回跌至平均线以下，此时平均线仍持续下降，为卖出信号（见图 9-17⑧）。 经过长时间的实践，葛兰威尔认为上述八法则中，第 3 条和第 8 条实际操作风险较大，为初学者所慎用；同时认为若将第 1 条和第 2 条、第 6 条和第 7 条合并使用，可捕捉最佳买进（卖出）时机；第 4 条和第 5 条可结合乖离率指标使用，以提高其适用性和可操作性。 移动平均线的组合长、短期移动平均线的配合作用投资者可利用快、慢两种移动平均线的交叉情况来决定买进和卖出的时机。当现在行情价位站稳在长期与短期移动平均线之上，短期移动平均线向上突破长期移动平均线时，为买进信号，此种交叉称为“黄金交叉”；反之，则为卖出信号，交叉称之为“死亡交叉”（如图 9-18）。 长、中、短期移动平均线的配合使用长期平均线（250 日），中期平均线（50 日），短期平均线（10 日）的移动方向有时趋于一致，有时不一致，可从两个方面来分析、研判。 ①方向一致 在空头市场中，经过长时间的下跌，股价与 10 日平均线、50 日平均线、250 日平均线的排列关系，从下到上依次为股价、10 日均线、50 日均线和 250 日均线。若股市出现转机，股价开始回升，反应最敏感的是 10 日平均线，首先跟着股价从下跌转为上升；随着股价继续攀升，50 日平均线才开始转为向上方移动。至于 250 日平均线的方向改变，则意味股市的基本趋势的转变，多头市场的来临。若股市仅出现次级移动，股价上升数星期或两三个月，使得短期均线和中期均线向上移动；当次级移动结束后，股价再朝原始方向运动，平均线则从短期均线、中期均线依次向下移动。 在多头市场中，情形则恰恰相反。 ②方向不一致 当股价进入整理盘旋后，短期平均线、中期平均线很容易与股价缠绕在一起，不能正确地指明运动方向。有时短期均线在中期均线之上或之下，此种情形表示整个股市缺乏弹性，静待多方或空方打破僵局，使行情再度上升或下跌。 另一种不协调的现象是中期平均线向上移动，股价和短期平均线向下移动，这表明股市上升趋势并未改变，暂时出现回档调整现象。只有当股价和短期均线相继跌破中期均线，并且中期均线亦有向下反转迹象，则上升趋势改变。或是中期平均线仍向下移动，股价与短期平均线却向上移动；这表明下跌趋势并未改变，中间出现一段反弹行情而已。只有当股价和短期均线都回到均线之上，并且中期均线亦有向上反转，则趋势才改变。 平滑异同移动平均线（MACD）平滑异同移动平均线（MACD），是运用快速与慢速移动平均线聚合和分离的征兆，加以双重平滑运算，用以研判证券买进与卖出时机的方法。 计算方法在应用 MACD 时，以 12 日 EMA 为快速移动平均线，26 日 EMA 为慢速移动平均线；首先计算出两条移动平均线数值间的离差值（DIF）作为研判行情的基础，然后再求 DIF 的 9 日平滑移动平均线，即 MACD 线，来作为买卖时机的判析。 （1）计算移动平均值（EMA） 快速平滑移动平均线的计算： 今日 EMA（12）＝213 今日收盘价 1113 昨日 EMA（12） 慢速平滑移动平均线的计算： 今日 EMA（26）＝227 今日收盘价+2527 昨日 EMA（26） （2）计算离差值（DIF） DIF＝EMA（12）-EMA（26） （3）计算 DIF 的 9 日 EMA 根据离差值计算其 9 日 EMA，即“离差平均值”，是所求的 MACD 值。为了不与指标原名相混淆，此值又名 DEM。 今日 DEM（MACD）＝210 今日 DIF+810 昨日 DEM 理论上，在持续的涨势中，12 日 EMA 线在 26 日 EMA 线之上，其间的正离差值（+DIF）会愈来愈大。反之在跌势中，离差值可能变负（-DIF），其绝对值也愈来愈大；如果行情开始回转，正或负离差值将会缩小。MACD 就是利用正负的离差值，与离差值的 9 日平均线的交叉信号，作为买卖行为的依据。 为了方便判断，亦可用 DIF 值减去 DEM 值，用以绘制柱状图。 运用法则MACD 在买卖交易的判断上，有以下几个信号功能。 （1）当 DIF 和 MACD 在 0 以上，属多头市场，DIF 向上突破 MACD 是买入信号；若 DIF 向下突破 MACD 只能认为是回档，作获利了结。 （2）当 DIF 和 MACD 在 0 以下，属空头市场。此时，若 DIF 向下突破 MACD，是卖出信号；若 DIF 向上突破 MACD，只能认为是反弹，可暂时补空。 （3）当 DIF 跌破 0 轴线时，此为卖出信号，即 12 日 EMA 与 26 日 EMA 发生死亡交叉的信号。当 DIF 上穿 0 轴线时，为买入信号，即 12 日 EMA 与 26 日 EMA 发生黄金交叉的信号。 （4）“背离信号”的判断。当股价走势出现二或三个近期低点时，而 DIF（MACD〕并不配合出现新低点，可买入；当股价走势出现二或三个近期高点时，而 DIF（MACD）并不配合出现新高点，可卖出。 MACD 的优点是除掉了移动平均线产生的频繁出现买入与卖出信号，避免一部分假信号的出现，用起来比移动平均线更有把握。MACD 的缺点与移动平均线相同，在股市没有明显趋势而进入盘整时，失误的时候较多。 乖离率（BIAS）乖离率（BIAS）是测算股价与移动平均线偏离程度的指标，从而得出股价在剧烈波动时因偏离移动平均趋势而造成的可能回档或反弹，以及股价在正常范围内移动而继续原有趋势的可信度。 乖离率的技术原理在于：如果股价偏离移动平均线太远，不管是在移动平均线上方或下方，都有可能趋向平均线。乖离率是表示股价偏离趋向指标的百分比值。 计算公式 其中：Ct 为当日指数或收盘价，MAn 为 N 日移动平均价。 应用法则一般说来，乖离率的研判要点如下： （1)乖离率分正乖离和负乖离。当股价在平均线之上，则为正乖离率，反之，则为负乖离率；当股价与平均线相交时，则乖离率为零。正的乖离率愈大，表示短期多头的获利愈大，获利回吐的可能性愈高；负的乖离率愈大，则空头回补的可能性也愈高。 （2）个别股因多空双方激战的影响，股价和各种平均线的乖离率容易出现异常现象（偏高或偏低），其操作策略也应随之而变。 （3）在大势上升市场中如遇负乖离率，可择机跌价买进；在大势下跌的走势中如遇正乖离率，可以等待回升高价时出脱持股。 对于乖离率达到何种程度方为正确的买入点或卖出点，目前并无统一的标准，投资者可凭经验和对行情强弱的判断得出综合的结论。","categories":["4.其他","金融"]},{"title":"IMA系统开发方法的研究","path":"/2024/12/12/3-软件-航电-IMA系统开发方法的研究/","content":"随着 IMA 架构的推广应用，IMA 架构已成为大型民用飞机系统的典型架构，而 IMA 系统的开发涉及到与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方利益相关者提出的约束。 本文主要从两个方面探讨 IMA 系统的开发方法:一是与飞机制造商的交互，通过飞机级任务的运行场景捕获功能系统的需求，协商 IMA 可驻留的飞机系统，确定 IMA 系统的功能、性能需求;二是技术、环境、利益相关者等多方提出的约束，包括成熟技术复用、适航要求、维修性要求、装机环境要求、时间和成本、人为因素、公司战略等方面的约束要求。 IMA 系统开发方法的研究旨在帮助开发人员深入了解这些利益相关者对 IMA 的影响，为 IMA 系统设计实践提供参考。 随着飞机对航电系统需求的不断增长,机载系统的功能和性能要求不断提高,现代航空电子系统越来 越呈现复杂系统特征,联合式架构已远不能满足航电系统的发展要求。为解决上述问题,20 世纪 90 年代国外开始了综合模块化航空电子系统的研究工作,并很快取得技术突破;而微电子技术和集成电路的迅速发展,强大的微处理器技术、集成电路集成度的不断增长和成本降低,大大促进了综合模块化航空电子(Integrated Modular Avionics,IMA)架构的推广应用,IMA 架构成为大型民用飞机系统的典型架构。 目前 IMA 技术的发展日趋成熟,开放式 IMA 系统架构能够满足大型客机对航空电子系统高灵活性、高可靠性以及便于升级换代的要求,综合化航电系统得到了广泛关注,并逐步成为民用客机航空电子系统发展的主流趋势。典型代表包括美国波音公司 B787 飞机、欧洲空客公司的 A380 飞机和 A350 飞机等先进干线飞机。我国的大型客机 C919 也采用 IMA 系统架构。 IMA 系统简介 DO-297 中对 IMA 的定义是:“IMA 是一组灵活的、可重用的、可互操作的共享硬件和软件资源,当把这些资源综合在一起时可以构建一个平台,该平台按一组确定的安全和性能需求进行设计和验证,能提 供各种服务,并驻留执行飞机功能的应用”。 由此可见,IMA 系统由 IMA 平台以及一组驻留应用组成,其中 IMA 平台通常包含 1 个或多个模块组件,驻留应用通常也包含 1 个或多个组件。 联合式架构下,每个航电功能都有各自特定的独享的计算资源(处理器、数据通信和接口),这些计算资源驻留在各自独立的现场可更换单元(Line Replaceable Unit,LRU)中。 IMA 系统架构为高度集成的实时系统提供所必需的核心资源框架,提供公共硬件计算模块的集中计算资源,为航电系统的通用处理功能构建了一个独立的通用处理平台,提供公共硬件计算模块的集中计算资源。 IMA 架构为多个飞机功能的驻留提供了公共计算资源,取代了联合式架构中航电功能面向任务的专用计算机。以前联合式航空电子应用软件嵌入在面向任务的专用计算机中,现在则驻留在 IMA 系统的公共核心计算资源上,提高了系统资源的利用率和可用性。 IMA 平台属复杂机载设备,为飞机功能提供支持通用功能的公共平台,如计算功能、网络传输功能、数据转换功能;而且,IMA 平台与机上多个驻留应用软件、机载设备组件(如传感器、控制器、显示器、作动器等)进行交互,并为驻留应用软件提供支持其运行的执行环境,包括硬件资源和平台基础服务。虽然 IMA 平台可以驻留多个飞机功能,但是 IMA 平台本身并不具备专用的飞机功能。因此,开发 IMA 平台可独立于专用飞机功能和驻留应用进行定义与开发。 IMA 系统开发方法 由于 IMA 系统驻留多个飞机功能,因此 IMA 系统的综合化程度、系统内和系统间的相互关系的复杂度相对于单一功能实现方式的联合式架构均有了很大的提升,联合式架构的开发方法很难适用于 IMA 架构的开发。 IMA 系统的开发涉及与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方 利益相关者提出的约束。 其主要可划分为两个方面: 一是与飞机制造商的交互,IMA 系统供应商可捕获飞机级任务的运行场景和飞机功能需求,并参与飞机系统联合设计即飞机功能的划分和分配、迭代,协商可驻留在 IMA 平台上的飞机功能,确定 IMA 系统的功能、性能需求; 二是技术、环境、利益相关者等多方提出的约束,包括 IMA 成熟技术复用、适航条款、维修性要求、装机环境要求、人为因素、公司战略等方面的约束要求。这两个方面与 IMA 系 统 开发的关系如图 1 所示。 图 1 IMA 系统开发输入因素之间的关系 图 1 中,垂直方向代表自顶向下分解的功能性能维度,水平方向代表 IMA 系统开发的约束集(图 1 黑斜线外侧的区域),这两个维度的交集(黑斜线内侧的区域)是可接受的方案设计。显而易见,功能性能需求和开发约束集这两个方面决定了 IMA 系统的解决方案,IMA 系统开发不但要考虑飞机级自顶向下分解出 IMA 系统的功能性能需求,还要考虑这些约束集对方案设计的“限制”,才能交付出满足装机要求的 IMA 系统。 一、功能性能需求 随着飞机任务复杂度的提升,飞机功能和系统功能之间并不是简单的一对一的分配关系,一个飞机级功能可能由多个系统完成,一个系统也可能完成多个飞机级功能。飞机级功能分配的过程也是确定飞机级系统架构的过程,需要对多种因素进行设计权衡。飞机级功能分配首先应确定初步飞机级系统架构,然后 根据初步飞机级系统架构将飞机级功能分配到相关系统,经过多次迭代安全性评估结果以及与系统供应商的协商结果,确定最终的飞机级系统架构及分配给特定系统的功能。 飞机功能分配阶段,飞机制造商自顶向下分解来自飞机系统的功能,确定驻留在 IMA 平台上的飞机功能,形成 IMA 系统的顶层需求。IMA 系统开发商应积极联系飞机制造商、参与飞机系统设计过程即联合设计阶段,向飞机制造商提供来自 IMA 的技术支持(包括 IMA 架构、模块设计、硬件设计、软件设计、安全性评估、平台资源、运行效率等),以实现航空电子系统逻辑架构到 IMA 公共处理资源的映射,通过双方协商联合设计 IMA 系统初步架构确保满足飞机级系统架构的要求。 同时,联合设计还有助于 IMA 系统开发商更好地了解飞机级顶层需求、确定 IMA 系统需求并向下分解、制定公司战略、将系统级需求作为开发下一代可认证 IMA 平台的输入等工作,为 IMA 系统开发奠定了基础。 IMA 平台为多个飞机功能提供公共计算资源以及通用接口资源,支持同时驻留多个飞机功能,其开发涉及多个机载系统的参与。基于 IMA 架构的飞机级功能分配过程中,飞机系统被划分为计算处理功能和系统专用功能两部分,其中飞机系统的计算处理功能可被分配到 IMA 系统中实现,系统专用功能则必须保留由具有特殊接口的专用设备完成; 由于 IMA 系统主要提供公共计算资源以及通用接口资源,不能满足所有驻留功能的需求,对于一些需要特殊资源的系统功能, 需要 IMA 系统和系统专用设备共同实现。此外,基于 IMA 架构下除完成联合式架构下飞机级功能分配工作外,还需要通过对安全性、平台资源、运行效率等多种因素进行权衡,确 定可驻留在 IMA 平台中的系统功能。 飞机功能分配到 IMA 系统后,需要再多次逐级向下进行功能分解,一直分解到软硬件可进行设计实现的程度。功能性能的需求在层与层之间的追踪关系必须严格得到保证,即设计过程中任何层级的描述和考虑始终对最顶层———任务层负责,这样才能确保最终的设计实现与飞机任务需求。 二、约束集 IMA 系统开发不但要考虑飞机级自顶向下分解出 IMA 系统的功能性能需求,还要考虑这些约束集对方案设计的“限制”。“约束”经常以需求的形式出现,例如认证需求,同样,来自于顶层飞机级任务的功能性能需求将逐级分解到底层———实现层,以驱动底层需求生成某种形式的解决方案。对于 IMA 开发商,识别飞机级任务的需求与约束之间的差异性非常重要,在 多方协商以及解决方案的“权衡”中起到至关重要的作用。 1、适航认证需求 适航认证需求源自飞机级的定义,是飞机制造商与适航认证的局方达成一致的结果,中国民用航空局 发布的适航规章(或者美国联邦航空管理局或欧洲航空安全局使用。例 如,中国民 用航空规章第 25 部适用于航空运输类飞机的适航认证。国内民用飞机以 CCAR 25 部为审定基础,但考虑到型号后续发展以取得 FAA 和 EASA 颁发的型号合格证的需要,因此在设计过程中往往会同时考虑 FAA 颁发的适航规章 14CFR 25 和 EASA 颁发的适航认证规范 CS 25 的要求。 下面以 CCAR 25 条款为例说明适航认证需求到飞机系统和航电系统的分解。条款 §25.1301 规定, “(a)所安装的每项设备必须符合下列要求:(1)其种类和设计与预定功能相适应。”其中设备的设计与安装符合“预定功能”是指在飞机的运行和环境条件下,设 备功能正常。在研制过程中设备的功能及性能指标通常在设备规范中明确,作为后续研制的依据。此需求是通过符合技术标准规定来满足的,而 TSO 又会调用一系列行业标准,例如美国航空无线电技术委员会 发布的相关最低操作性能标准,这些需求都需要与认证机构进行讨论并达成一致。 此外,功能性能需求和适航需求生成的约束均对系统子系统的可靠性需求产生影响。通常,飞机任务成功率的目标是电子设备可靠性要求的关键驱动因素。但是,适航规章的安全性段落也包括可靠性需求。例如,适航规章 CCAR 25 中安全性相关条款§25.1309 以相应可接受的符合性方法 AC 25.13091A 描述安全性需求及其与可靠性需求之间的关系。飞机安全性相关的失效状况影响与可靠性之间的关系如表 1 所列。 表 1 功能危害性影响分类 由于飞机功能的失效可能会对飞机性能产生不利影响,所以必须评估飞机功能的失效影响。如果失效影响涉及到机组人员和或乘客,那么相关飞机功能的失效概率必须是远不可能发生的。例如:如果某飞机功能失效对飞机乘员的影响包括对少数乘客或机组人员造成严重的致命的伤害,那么该飞机功能的失效概率不能高于 1×10-7飞行小时。由此可见,飞机级的安全性要求被转换成功能子功能级的可靠性需求。 在功能层及以下层级不存在“安全性”需求,只有可靠性需求;这些可靠性需求将伴随着功能一起逐级向下分解,以确保满足顶层功能级的初始可靠性需求。因此,系统子系统的可靠性指标必须同时满足顶层任务分解的可靠性需求和来自适航安全性的可靠性需求。 2、运营需求 飞机运营必须考虑要求强制执行的功能和性能需求。如欧洲颁发规章作为“委任规章 No.9652012”,根据欧洲议会和理事会的 No.2162008 规定,制定航空运营相关的技术需求和行政程序。飞机运营要求由局方发布规章制定航空运营相关的技术需求和行政程 序,这些规章包括对运营组织方的不同类型的需求。对于飞机功能,为了进行特定类别的操作飞机必须装备机载电子设备,如“商用航空运输”。 常见的相关飞机功能包括,高度告警系统、地形识别及告警系统、防碰撞系统、天气探测设备、飞行机组对讲系统、座舱语音及飞行数据记录仪、最小无线电导航与通信功能等。这些功能来自飞机运营的需求,而不是适航;而且,这些设备的装机必须满足适航认证的要求,即满足安全性、可靠性的要求。 3、行业标准和推荐实践 所有航电设备和相关功能的分配和实现都应与行业标准、规定保持一致,分别规定并逐项详细说明,以获取认可和航空可批准的性能(即适航性),行业互换性符合航空实践(即考虑人为因素,材料,表面处理,制造工艺)以及与通用航空领域规定保持一致。常用行业标准和推荐实践包括: (1) RTCA,美国航空无线电技术委员会,协调 MOPS 和最低航空系统性能标准并达成共识。符合 MOPS 和 MASPS 的标准通常由 TSO 提出,因此 TSO 是设备获得 FAA 认可、装机使用资格的基础。 （2）EUROCAE ,欧洲民航设备组织,是欧洲相当于 RTCA 的机构,负责制定欧洲的航空标准。EUROCAE 标准是设备获得 EASA 认可、装机使用资格的基础。 （3）SAE ,汽车工程学会,负责航空电子相关功能和性能领域的航空航天标准和航空航天推荐实践的编写和汇总,如飞行操纵和飞行控制、飞行座舱显示和信号、维护实践、应用人为因素。 （4）ARINC，航空无线电公司,由航空公司电子工程委员会组成,根据电子设备特性制定类型、尺寸和功能约定,是设备之间独 立于系统制造商实现互换性所必需的。该特性定义了设备的功能性能、系统间和控制显示接口的连接器引脚层等规定。 4、时间和成本目标 与航电功能相关的时间和成本目标必须在飞机级 的设计和开发过程中被识别,并向下分解到系统级作为系统供应商的成本目标或预算,IMA 系统开发需关注开发周期、开发成本、飞行和维护机组的培训费用、维护成本等因素。 5、企业标准 企业标准可能需要在开发过程中进行特定的考 虑,如首选工具、首选开发功能、特殊开发软件的使用、特定的命名、归档、记录规定等。这些标准可能会偏离 或增加以其他方式或从行业通用实践中获得的标准, 由其他项目应用或因成本的考虑等因素产生的标准。 6、最低性能要求(MPS) 航电设备包研发过程中的一个关键参数是各功能 的性能要求。性能要求将适用于每个航电设备功能, 因此每个航电设备功能必须毫无例外地派生出所需的 性能 指 标 值,MPS 源 于认证和操作批准需求,例 如 IMA 模块 MPS 来自 TSO 153。 7、复用需求 复用需求与公司战略和公司标准密切相关。根据 公司制定的商业计划和技术发展战略,航空电子设备研发项目可能是公司已经参与或者希望在未来参与的多个类似项目之一。在这种情况下,可应用到多个项目的技术复用会为公司节约开发成本,提高利润。 反过来说,技术复用也可能会在设计方面规定约束,包括文档、功能分区、系统性能、系统成本,甚至系统功能。当前项目可能只需要这些功能的一个子集,但是将来的技术重用的需求可能会更为广泛。 而且,复用需求可能会迫使公司使用专用的项目管理和财务功能,由于公司项目管理和财务工作只能 在当前项目上收取部分费用,其余工作的收费将在复用项目中产生。 8、环境 目标飞机为航电设备提供装机环境,航电功能必须在机上运行性能必需的等级。环境特性包括:温度、高度(气压)、空气质量和湿度、振动和冲击、气压梯度(爆炸)、电磁特性和对射频信号的敏感性、闪电效应的敏感性等。实际的飞机环境为每种试验“类型”给出一组特定的值和参数,因此必须从标准 RTCA DO 160 中选出适用环境特性的相关章节。 环境适应性设计是航电设备研发工作中非常重要和相当严苛的一个方面,因为设备装机环境需求方面 出现错误将会导致已完成研发的设备无法应用到预期的装机环境中,而设计更改到位后,代价高昂的试验和评估功能的工作可能必须重新开展。 例如,IMA 系统开发者对装机环境要求的理解出错,温度范围未完全覆盖,那么元器件的选型就会出错,设备的散热加热设计、结构设计可能不满足散热要求。 9、重量 飞机制造商在飞机初步设计中确定了飞机的总体重量,以及分配给各系统和航电设备包的重量“预算”,并向下分解到各子功能。IMA 架构下,因为 IMA 硬件可能是整个系统架构中的通用公共计算资源,而 IMA 平台的重量可能与驻留应用的数量不存在线性关系, 因此重量设计具有一定的优势,而“正确的”初步系统架构定义则变得非常重要。 从飞机设计的视角来看,超过或低于重量预算都可能是不利于飞机设计的,因此设备重量设计出现偏 差应该及时与飞机制造商进行协商。 10、功耗 与重量预算类似,飞机制造商在飞机初步设计中将功耗预算分配给系统和航电设备包,这些将作为整体飞机功耗组成的一部分。 功耗不超出预算非常重要,因此在航电系统设计阶段初期,分配给各系统的功耗预算必须被尽可能精确地分配,以便飞机功能初步验证架构设计的可行性。在 IMA 架构下,面向软件的飞机应用与硬件需求不存在线性关系,这是 IMA 架构的优点,但它以更复杂的设计迭代和系统复杂性为代价。 11、散热 散热预算与功耗预算相辅相成。散热需要设计机械接口,根据设备装机运行环境的温度和湿度,与航电系统设计工作进行协调,选择正确散热方式(如自然散热、强迫风冷散热、传导散热、液体冷却等)是至关重要的。 散热在很大程度上影响了航电设备的平均故障间隔时间(MTBF),而航电设备硬件的内部热分布需要根据实际硬件设计进行专用的特殊的热设计,通过在设备内部设计专用的热传递路径,包括热布局、散热方式、散热介质、热传输路径、风道、液冷通道等,以便将设备内部的热量传导到散热区。 任何散热需求都可能规定后续具体的要求,例如大气洁净度、大气温度、压力和湿度;而且考虑到飞机 服役寿命和设备将来潜在的功能升级或设计更改,可能会提出更高的散热需求。 12、维护和修理需求 维护和修理需求是考虑从机场外场维护到车间维修等各种维修场景、不同维护级别的维护、修理需求。 IMA 系统开发示例 由于 IMA 系统驻留多个飞机功能,因此 IMA 系统的综合化程度、系统内和系统间的相互关系的复杂度相对于单一功能实现方式的联合式架构均有了很大的提升,IMA 系统开发除了完成传统的飞机级功能分配外,还需要通过安全性、平台资源、运行效率等多种因素权衡确定哪些系统驻留在 IMA 平台中以及 IMA 系统与驻留 ATA 系统的关系等。 为了便于理解本文介绍的 IMA 系统开发方法,本外场维护需要设备具有一定的故障报告和诊断的能力,既有与飞机操作人员的数据链路,也有与飞行机组人员到达后的沟通交流,以便航线维护人员在规定的时间内做出响应。 因此,飞机航线维护规定内部航电设备失效状态和飞机级安装问题(如线缆、连接器、系统内部通信故 障)并汇总形成通用语言的故障报告,既可以通过维护电脑的诊断功能输出,也可以通过与飞行机组人机 接口输出,用于航线维护人员成功响应故障并保持低概率无故障发现 (NFF)状况。 一旦设备从飞机上拆除,假定设备具备良好的故节以起落架系统、座舱显示系统、飞行管理系统和机上维护系统到 IMA 系统的驻留为例,通过飞机系统功能 IMA 平台通用资源的分配以及对约束的权衡来进一步说明 IMA 系统开发方法。LGS 由起落架收放系统、刹车控制系统、车轮转向控制系统、起 落 架 监 控 系 统四个功能子系统以及三个独立的起落架组成。 LGERS 负责起落架的控制以及监控功能,由 LG-ERS 命令通道和自检测通道组成;BCS 负责飞机刹车控制以及监控功能,由 BCS 命令通道、监控通道和自检测通道组成;WSCS 负责起落架前轮转向控制液压伺服阀的控制和监控功能,由 WSCS 命令通道和监控通道组成;LGMS 负责刹车温度监控与指示、胎压检测与指示、刹车散热风扇的控制功能,由 LGMS 控制功能和自检测功能组成;以上各子系统命令通道的开发保证等级(DAL)均为 A 级,监控通道的开发保证等级均为 B 级,且必须考虑命令通道与监控通道的隔离性。其中 IMA 平台通用处理资源可以满足 LGS 各应用软件的处理需求,四个功能子系统可以驻留在 IMA 平台上;但是起落架需要特殊的飞机接口来实现,因此不能驻留在 IMA 平台上。 CDS 由 6 个显示单元和 2 个键盘控制单元组成 CDS 软件驻留在每个显示单元上,IMA 平台仅提供通用数据传输和接口的驻留。 FMS 包括飞行计划、飞行优化与预测、导航和飞行指引四部分功能,均由应用软件实现。因此,FMS 的应用软件均驻留在 IMA 系统中,飞行管理功能由 IMA 系统实现。 OMS 包括数据加载与配置管理、中央维护系统、飞机状况监控系统三部分功能。IMA 平台的硬件资源可以满足这三部分的功能需求,因此 OMS 所有功能都驻留在 IMA 平台上。 初步飞机级功能到 IMA 的分配示意如图 2 所示。 图 2 IMA 系统中飞机级功能分配示意图 从图 2 可以看出,FMS、OMS 这两个系统均由软件实现,因此均驻留在 IMA 系统上,与 IMA 系统一起实现系统功能;LGS 的应用软件部分均驻留在 IMA 系统上,与各自系统的专用设备一起实现系统功能;CDS 的通信功能和接口数据转换功能驻留在 IMA 系统上, 与 CDS 系统的专用设备、显示器与键盘控制单元,一起实现显示系统的功能。 飞机级功能分配阶段,IMA 平台供应商首先需要考虑使用能够满足各系统应用软件驻留的要求,其次 要初步评估平台性能以确保满足各系统驻留应用的运行需求,还需要详细考虑 2.2 节描述的各项约束,逐步实现 IMA 系统的开发,例如: **(1)适航认证约束:**识别适航认证需求,即必须满足的适航规章,如大型运输类飞机以 CCAR 25 部为审定基础。 **(2)适航符合性约束:**确定 IMA 系统适航方法,如采用 DO 297 作为 IMA 系统开发和认证的可接受的符合性方法,IMA 系统通过增量式认可方法获得安装批准。 **(3)安全性约束:**如驻留应用 DAL A 级的安全性要求、命令通道与监控通道的隔离性要求等。 **(4)供电约束:**余度供电的隔离性要求以及应急供电的要求等。 **(5)环境约束:**根据 LGS 的需求,确定 IMA 平台,尤其关注执行 LGS 接口数据转换功能的远程接口单元的安装环境、安装方式、功耗及散热条件等。 **(6)MPS:**TSO 是局方颁布的民用航空器上所用的特定零部件的最低性能标准。IMA 系统相关的 TSO 分为两大类: ① TSO-153,适用于 IMA(硬件)模块单元。覆盖到 IMA 系统用到的两类硬件组件——通用硬件模块和驻留这些硬件模块的机柜。 ② 功能 TSOs,适用于飞机功能单元。 (7) 复用: 考虑到开发周期、认证成本、研制风险等因素,IMA 系统开发首选采纳成熟技术的复用,包括驻留系统以及 IMA 平台技术的复用。 (8) 维修保障性约束: 确定平均修复性时间、维修间隔等。 通过考虑这些约束集对 IMA 系统方案设计的“限制”,系统设计人员将来自于顶层飞机级任务的功能性能需求逐级分解到底层实现层,最终以驱动底层需求生成具体的解决方案。 以驻留在 IMA 系统的飞行管理系统为例,其飞机功能分配到 IMA 系统的功能性能需求层次结构如图 3 深色图框所示。最顶层的任务描述与最底层的设计实现从不同的角度描述了同一个飞机功能,“最顶层”是从飞机级任务的角度抽象地描述整个飞机的预期操作;“最底层”的设计实现层则是从软硬件设计实现的角度,描述飞机级任务的最终实现。“设计实现层”描述的是具体的设计“需求”,可以逐级向上追溯到最顶层的“任务”描述,即最底层的需求是从最顶层的任务分解而捕获到的。 图 3 功能性能需求层次结构示意图 由图 3 可以看出,设计实现层的软件和硬件模块组成了飞行指引功能,逐级向上看,飞行指引功能是飞行管理功能的组成部分,飞行管理功能是航电系统的组成部分,航电系统是飞机系统的组成部分。一般情况下,从飞机层到最终的设计实现层之间会包括 7~10 层级(某些复杂系统可能会超过 10 层),相邻层与层之间的功能性能需求存在一一对应的关系,需求自顶向下逐层分解,而底层设计实现逐层向上集成,最终支持顶层飞机级任务功能的实现。 结 论 无论是基于传统的联合式架构还是复杂可复用的 IMA 架构的航电设备研发,都与飞机整体定义密切相关,都需要满足飞机的功能性能要求以及各种“限制因素”。本文通过研究 IMA 系统开发中与飞机制造商的交互、现有技术的应用、安装位置的环境、维护人员的操作等多方利益相关者提出的约束,帮助开发人员深入了解这些利益相关者对 IMA 的影响,为 IMA 系统开发提供参考。 （以上文章来源于作者：韩嫚莉，高杨，高瑞坤，作者单位：中国航空工业集团 西安航空计算技术研究所）","tags":["clippings"],"categories":["3.软件","航电"]},{"title":"ARINC-429","path":"/2024/12/12/3-软件-航电-ARINC-429/","content":"ARINC-429 是一个关键的标准，用于商用飞机航空电子系统之间的数字数据传输。这个协议旨在确保不同设备间的互换性，使得不同制造商的航空电子设备可以无缝协作，显著提升了系统的灵活性与安全性。 ARINC 429 通常被称为 Mark 33 数字信息传输系统（DITS）总线。尽管它主要用于航空电子领域，但这种总线技术也成功应用于地面车辆、武器系统以及其它商业和军事设备。举例来说，在现代战斗机中，ARINC 429 可以用于通讯导航设备和火控系统之间的数据交换，确保设备间能够准确地共享关键信息。 ARINC-429 标准的组成部分 PART 1: 提供了 ARINC 429 的功能基本描述，包括支持的物理和电气接口，数据字格式、标准标签和地址分配以及相关示例。这部分确保设备制造商可以理解和实现与该标准相关的基本要求。 PART 2: 定义了 ARINC 429 离散量字及按标签顺序的位分配，确保数据传输的正确性和兼容性。 PART 3: 描述了 ARINC 429 的数据传输协议及其通过大块或者文件格式进行数据传输的消息定义，为后续的数据交互提供框架。 PART 4: 列出了多年来发表的 ARINC 429 第 1 部分的补编档案，并作为 ARINC 429 第 18 号补编的一部分进行更新（2012 年）。这为研究和开发人员提供了丰富的历史背景和技术演变的信息。 数据传输特点ARINC 429 的数据传输特点在于其简单的单向总线通信数据流设计。与典型的多向数据总线不同，ARINC-429 的单向设计能显著提升系统的可靠性。如下图所示，发送器（Sender）可以同时支持最高 20 个接收器（Receiver），每个接收器可以独立接收消息而不产生信号冲突。 ┌──────────┐ ┌─────────┐ ┌────────────┐│RECEIVER_1│ │ ... │ │ RECEIVER_N │└──────────┘ └─────────┘ └────────────┘ ▲ ▲ ▲ │ │ │┌─────────┐──────────────┴──────────────────┘│ SENDER │└─────────┘ 双向传输: 添加一根额外线缆即可实现双向数据传输，允许接收器在需要时转变为发送器。 数据字格式: 每个数据字（WORD）为 32 位，代表特定的工程单位，如高度、气压等，标准的数据传输速率分为高速（100 kbs）和低速（12.5 kbs）。 设备标识: 各个设备通过设备 ID 号进行管理，违反了 ARINC 429 的地址分配原则，从而允许更灵活的数据管理。 信号自锁: 对于数据字之间的连续区分，一个至少 4 位的空或零电压标识可以让系统在没有单独时钟信号的情况下正常工作，这就是 ARINC 429 的自锁特性。 数据字结构通过 ARINC-429 总线发送的数据以 32 位字的形式传输，每个字包含多种信息。结构示例如下： ┌──┬─────┬───────────────────────┬─────┬───────────────────────┐│P │ SSM │ DATA │ SDI │ LABEL │└──┴─────┴───────────────────────┴─────┴───────────────────────┘ LABEL: 8 位标签用于解释数据字段。举个例子，标签为 372 的航向参考系统提供了风向信息，而标签为 203 的空气数据计算机则提供气压高度，312 则表示地面速度。这样的标准化标签使得不同厂商的设备能够使用相同的参数定义。 SDI: 2 位源目的地标识符，帮助发送器识别消息应发送给哪个接收器，若不需要该标识符，这部分可以用作额外的数据位。 DATA: 19 位数据部分，承载具体的数值信息。 SSM: 符号状态矩阵，提供信息的状态指示。 P: 奇偶校验位用于错误检测，采用奇数奇偶校验确保数据接收的准确性。ARINC 429 仅规定检测错误的方法，而不包括纠错机制。 SSM 的状态可根据 LABEL 的不同而有所不同，如下： 00 (0)：故障； 01 (1)：无计算数据或输出无效； 10 (2)：功能实验； 11 (3)：正常。 #include stdio.htypedef unsigned int uint32_t;// 获取二进制表示中位1的个数int getBit1Count(uint32_t x) uint32_t i = 0, count = 0, temp = x; for (i = 0; i 32; i++) if (1 == (temp 0x00000001)) count++; // 如果最低位为1，计数增加 temp = temp 1; // 右移一位，检查下一位 return count; // 返回1的总数// 设置校验位uint32_t setCheckBit(uint32_t x) // 如果当前x中1的个数为偶数，则设置校验位 if (getBit1Count(x) % 2 == 0) x = x ^ 0x80000000; // 0x80000000在二进制中为1000...0000 else x = x ^ 0x00000000; // 如果已经是奇数个1，不做改变 return x; // 返回新的数值// 打印出每一位的值void print_bits(uint32_t x) uint32_t i = 0; for (i = 0; i 32; i++) printf(%d, (x 0x80000000) 31); // 输出最高位 x = x 1; // 左移，检查下一个位 // 检查校验位并还原原始值uint32_t checkAndRestore(uint32_t x) uint32_t bit1Count = getBit1Count(x); // 获取1的个数 if (bit1Count % 2 == 0) printf(错误! ); // 输出错误信息 return 0; // 返回0，表示出错 else printf(正确! ); // 校验成功的提示 // 删掉最高位的校验位 x = x 0x7FFFFFFF; // 通过与运算清除最高位 return x; // 返回还原后的数值int main() uint32_t data[] = 0, 100, 101, 1001, 0x23456; // 初始化测试数据 uint32_t i = 0, set; // 遍历每个数据并进行处理 for (i = 0; i 5; i++) printf(设置校验位之前: ); print_bits(data[i]); // 打印二进制表示 printf(,%d个1, 0x%x , getBit1Count(data[i]), data[i]); // 打印1的个数和十六进制值 set = setCheckBit(data[i]); // 设置校验位 printf(设置校验位之后: ); print_bits(set); printf(,%d个1, 0x%x , getBit1Count(set), set); // 打印设置后数据的状态 printf(校验和还原:0x%x , checkAndRestore(set)); // 校验并还原 printf(------- ); // 分隔线 return 0; 输出 设置校验位之前: 00000000000000000000000000000000,0个1, 0x0设置校验位之后: 10000000000000000000000000000000,1个1, 0x80000000正确! 校验和还原:0x0-------设置校验位之前: 00000000000000000000000001100100,3个1, 0x64设置校验位之后: 00000000000000000000000001100100,3个1, 0x64正确! 校验和还原:0x64-------设置校验位之前: 00000000000000000000000001100101,4个1, 0x65设置校验位之后: 10000000000000000000000001100101,5个1, 0x80000065正确! 校验和还原:0x65-------设置校验位之前: 00000000000000000000000001111101001,7个1, 0x3e9设置校验位之后: 00000000000000000000000001111101001,7个1, 0x3e9正确! 校验和还原:0x3e9-------设置校验位之前: 00000000000000100011010001010110,8个1, 0x23456设置校验位之后: 10000000000000100011010001010110,9个1, 0x80023456正确! 校验和还原:0x23456------- ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ └────────────────────┴────────────────────┴─────────────┘ ┌──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐LSB │ 8 │ 7 │ 6 │ 5 │ 4 │ 3 │ 2 │ 1 │ MSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘LSB: 最低有效位 MSB: 最高有效位 注意到，上述表中的最低有效位（LSB）和最高有效位（MSB）概念相对较为特殊，和我们平时理解的可能是反着的。 并且，8 位数字被划分为三个部分，其中百位数通常用二进制 11 表示，即为数字 3，而十位数和个位数最多可以用二进制 111 表示，也就是数字 7。因此，上述内容实际上是在将 8 位数字分成三段，每段表示一个 8 进制数，且高低位顺序相反。这种表示方式被称为 反向八进制。 最大的 Label 值我们可以观察到，最大的 Label 值为 377，这对应了八进制中的最大三位数。 实际示例以 312 作为飞机的 ground speed 进行编码的示例，过程如下： 百位数： 取出数 3，它用二进制 11 表示。在反转高低位后，结果仍为 11。 十位数： 取出数 1，它用三位二进制表示为 001。在反转高低位后，得到 100。 个位数： 取出数 2，用三位二进制表示为 010，反转后保持为 010。 在这个过程中，我们的每一位都被处理并正确编码。 ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ ├────────────────────┼────────────────────┼─────────────┤ │ 2 │ 1 │ 3 │ ├──────┬──────┬──────┼──────┬──────┬──────┼──────┬──────┤ MSB │ 0 │ 1 │ 0 │ 1 │ 0 │ 0 │ 1 │ 1 │ LSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘ 通过对照 ARINC429P1 的 ATTACHMENT 6 中的值，可以确认上述编码过程的正确性。 示例代码以下代码展示了如何实现这种编码及解码。 #include stdio.htypedef unsigned int uint32_t;// 打印出每一位void print_bits(uint32_t x) uint32_t i = 0; for (i = 0; i 32; i++) printf(%d, (x 0x80000000) 31); x = x 1; // 翻转指定数的比特位uint32_t reverse_bits(uint32_t x, uint32_t from, uint32_t to) uint32_t result = 0; for (uint32_t i = from; i = to; i++) result += (x i 1) (to - i); return result;// 编码函数uint32_t encodeLabel(uint32_t word, uint32_t x) if (x 377) printf(out of range); return 0; // 清零word的前8位 word = 0xffffff00; // 编码百位数 uint32_t hundreds = (x % 1000) / 100; hundreds = reverse_bits(hundreds, 0, 1); word = word | hundreds; // 编码十位数 uint32_t tens = (x % 100) / 10; tens = reverse_bits(tens, 0, 2); word = word | (tens 2); // 编码个位数 uint32_t ones = x % 10; ones = reverse_bits(ones, 0, 2); word = word | (ones 5); return word;int main() print_bits(reverse_bits(0x4, 0, 2)); // Outputs: 100 - 001 printf( ); print_bits(reverse_bits(0x1, 0, 2)); // Outputs: 001 - 100 printf( ); print_bits(reverse_bits(0x1, 0, 31)); // Outputs: 1 - 10000000000000000000000000000000 printf( ------------ ); uint32_t word = 0x22849800; print_bits(encodeLabel(word, 313)); printf( ); print_bits(encodeLabel(word, 323)); printf( ); return 0; 输出结果运行后程序的输出结果示例： 00000000000000000000000000000001 00000000000000000000000000000100 10000000000000000000000000000000 ------------ 00100010100001001001100011010011 00100010100001001001100011001011 解码过程理解了编码之后，解码便变得简单。以下是解码的实现： uint32_t decodeLabel(uint32_t word) // 获取低8位 word = 0xff; // 得到百位数 uint32_t hundreds = word 0x3; hundreds = reverse_bits(hundreds, 0, 1); // 得到十位数 uint32_t tens = (word 2) 0x7; tens = reverse_bits(tens, 0, 2); // 得到个位数 uint32_t ones = (word 5) 0x7; ones = reverse_bits(ones, 0, 2); return hundreds * 100 + tens * 10 + ones; 附加信息在计算机系统和数据处理领域，还有一些重要的编码标准和技术，例如： BNR：二进制补码小数 BCD：二进制编码十进制 IOS5：IOS5 编码的字母与数字 离散量：用于处理不连续的数据 图形表示：在地图和显示器上显示的线条、圆形以及文字数字，这些通常使用与 ISO 5 字母数字数据传输类似的技术。ARINC 特性 744A 提供了具备图形功能的全格式打印机，这使得附加信息和示例图形字符的传输成为可能。","tags":["clippings"],"categories":["3.软件","航电"]},{"title":"Field-Oriented Control (FOC) 矢量控制 磁场定向控制_sensorless field oriented control of a pmsm中文-CSDN博客","path":"/2024/12/12/3-软件-FOC-Field-Oriented-Control-FOC-矢量控制-磁场定向控制-sensorless-field-oriented-control-of-a-pmsm中文-CSDN博客/","content":"永磁同步电机（PMSM, Permanent Magnet Synchronous Motor）由于它噪声小、高效节能的显著优势，广泛被用于新能源汽车、机器人伺服和家电等领域。上图是一个 PMSM 的示意图，ABC 为三相交流电，外圈为定子，内部为转子。转子为永磁体（permanent magnet）。当定子线圈通上 ABC 三相交流电后，由于电磁效应带动转子转动，而转子转动的频率和 ABC 三相交流电的频率相同，所以叫同步电机（synchronous motor）。 和 PMSM 非常相似的一种电机叫做 BLDC Motor（直流无刷电机，Brushless DC）。它们显著的区别在于反电动势（back EMF）的波形。BLDC 的反电动势呈梯形状，而 PMSM 的反电动势呈正弦波状。这两者的差异的原因是由于 PMSM 的定子绕组线圈缠绕呈正弦分布，而 BLDC 的定子绕组线圈缠绕为集中式。 下面的动图展现了 BLDC 和 PMSM 在控制上的差异： 浅蓝色箭头代表转子的磁场矢量方向，可以看到浅蓝色箭头在 BLDC 和 PMSM 都是在不停旋转，并且这个旋转会产生力矩（torque）带动机械负载的运动。BLDC 的转子旋转是一顿一顿的，PMSM 的转子旋转是非常连续平滑。控制 BLDC 的最经济的方法是 6 步换向法。通常通过检测转子角度位置，来依次给定子换向，这样的换向，造成了输出力矩有波动。而 PMSM 通过 FOC 控制，不需要换向，可以使得转子保持连续、平滑的转动。这样的“平滑”效应就是 Field Oriented Control（FOC）的结果。定子三相交流电流生成的空间磁场向量，通过控制驱动转子磁场旋转，形成力矩–—— 这就是 Field Oriented Control（磁场定向控制）。 MTPA（最大力矩电流比控制，Maximum Torque Per Amp） 永磁同步电机一般分为两种：SPM（表贴式）和 IPM（内嵌式）。从控制的角度 SPM 要比 IPM 简单很多，我们先以 SPM 为例，暂不考虑弱磁（一种高转速情况下的控制方法）。如果我们的目标是“相同的电流输入，达到最大的输出力矩”。假设下图中上下端是定子，中间的是转子。让我们人为改变定子磁场矢量和转子磁场矢量的夹角，当夹角为 0 度的时候，没有输出任何力矩，因为磁性的南北极互相吸引。再让我们旋转转子，改变一下夹角，会觉得力矩增大。当定子和转子磁场向量成 90 度的时候，产生的力矩最大。这是我们想达到的效果 – 最大化电流的利用效率，我们称之为：MTPA(Maximum Torque Per Amp)。在这种状态下，输出的力矩和输入的电流幅度成正相关。我们只需要调整电流的幅值，就可以控制电机输出的力矩。如果我们需要根据反馈来调整电机的电流、速度和位置，可以通过三个 PI 控制器的级联的电流环、速度环和位置环来实现。但最终，还是通过对电流的控制来实现。 通过上面的介绍，我们可以把 ABC 三相交流电形成的磁场，看着一个矢量。FOC 最重要的原则就是使这个电流矢量和永磁体转子转动形成的磁场矢量保持垂直。由于转子是在不停的转动，FOC 的任务就是：1.不停的观测转子的角度2.将电流矢量的角度保持和转子磁场矢量垂直（MTPA）上图右侧是 ABC 三相交流电的示意图。三种颜色代表三相交流电 ABC。它们的相位差为 120 度，我们可以把它们表示为上图左侧的矢量形式（abc 矢量坐标系）。它们合成的总矢量是淡蓝色。 为了研究方便，我们将静止的 abc 坐标系变为静止的 αβ 坐标系，这一步也叫 Clarke 变换： 接着，我们将静止的 αβ 坐标系变为旋转的 dq 坐标系，这一步也叫 Park 变换： 在经历 Clarke-Park 变换后，三相交流电变成了“直流电”：Id（深蓝）和 Iq（红色），它们实际上是电流矢量在 dq 坐标系的投影。d 表示 direct（直接），q 代表了 quadrature（正交）。如果是 SPM，为了使得电流效率最高（MTPA），我们只要使 Id 0，即所有的电流都作用于正交 – 产生力矩。这样大大简化了控制。 我们通过控制 Id、Iq 去产生相应的 Vd、Vq，经过反 ParkClarke 变换和 SVPWM（Space Vector Pulse Width Modulation）调制电压信号，经过门驱动（Gate Driver）和逆变器（Inverter）产生三相电压 Va、Vb、Vc，最后将 Va、Vb、Vc 输入到 PMSM，完成了 FOC。上图是 FOC 的控制信号示意图，其中蓝色的模块是软件实现模块，灰色的为硬件部分。 我们经常听到，电流环的的控制周期为 100us（10K Hz）。通常来说，上面的蓝色部分一般在 DSP 或者 MCU 的 ISR（interrupt service routine，中断服务程序）中实现。也就是说，每隔 100us，DSP 或者 MCU 就有专门的 ISR 函数做如下处理动作：1.测量出转子的角度（θ），得出所需的 Id、Iq 电流。将所需要的 Iq 电流向量和该角度保持垂直。在 MTPA 情况下，如果是 SPM，所需 Id 设为 0。2.测量出实际相电流（Ia、Ib、Ic），通过 ClarkePark 变换产生实际 Id、Iq 电流。3.利用上述的所需电流和实际电流信号差，通过 PI 控制器，得出 Vd、Vq。4.经过反 ParkClarke 变换、SVPWM 产生占空比，交给逆变器生成 Va、Vb、Vc 驱动电机。 Field-Oriented Control (FOC)磁场定向控制（FOC），也称为矢量控制，是一种用于控制永磁同步电动机（PMSM）和交流感应电动机（ACIM）的技术。 FOC 在整个扭矩和速度范围内都具有良好的控制能力。 FOC 的实现需要将定子电流从固定参考系转换为转子磁通参考系（也称为 d-q 参考系）。 矢量控制是建立在被控对象准确的数学 模型 上，使交流电机控制由外部宏观稳态控制深入到电机内部电磁过程的瞬态控制。矢量控制通过坐标变换将交流电机内部复杂耦合的非线性变量变换为相对坐标系为静止的直流变量（电流、磁链、电压等），实现近似解耦控制，并从中找到约束条件，获得某一目标的最佳控制策略，id0 控制是矢量控制的一种特定的控制策略，在转子坐标系内实现永磁同步电机交直轴电流解耦，由于 id、iq 双电流闭环的存在，使电机 iq 电流动态跟随系统力矩给定（tektiq，kt 为电机力矩系数），实现电机电磁力矩控制。 速度控制和转矩控制是 FOC 最常用的控制模式。位置控制模式不太常见。大多数牵引应用使用转矩控制模式，在该模式下，电动机控制系统遵循参考转矩值。在速度控制模式下，电机控制器遵循参考速度值，并生成用于形成内部子系统的转矩控制的转矩参考。在位置控制模式下，速度控制器构成内部子系统。 FOC算法 的实现需要电流和转子位置的实时反馈。使用传感器测量电流和位置。您也可以使用无传感器技术，该技术使用估计的反馈值代替实际的基于传感器的测量。 Permanent Magnet Synchronous Motor (PMSM)下图为永磁同步电机（PMSM）的 FOC 架构： AC Induction Motor (ACIM)下图为交流感应电动机（ACIM）的 FOC 架构： PMSM的数学模型（Mathematical Model of PMSM） 原理解析 | Field Oriented Control（磁场定向控制）的 Simulink 实现","tags":["clippings"],"categories":["3.软件","FOC"]},{"title":"FOC（磁场定向控制）及电机控制技术简介-RoboticsCV","path":"/2024/12/12/3-软件-FOC-FOC（磁场定向控制）及电机控制技术简介-RoboticsCV/","content":"前言 理论基础 FOC驱动器与无刷电调的区别 无刷电机驱动原理 基础知识 BLDC驱动原理 电机模型和运动分析 驱动电路简述 FOC原理 FOC项目（开源） 参考 前言理论基础 BLDC（Brushless DC Motor），无刷直流电机，与传统的有刷直流电机（Brushed DC Motor）相比具有更高效率、更长寿命和更低的维护要求。除此之外，BLDC 还具有高功率密度（体积小、重量轻、功率输出大）和高转速的优势。 PMSM（Permanent Magnet Synchronous Motor），永磁同步电机，亦称无刷交流电机（BLAC, Brushed AC Motor）。PMSM 具有和 BLDC 类似的结构特点。 FOC（Field-Oriented Control），磁场定向控制技术，也被称作矢量控制（Vector Control），是一种用于交流电机控制的高级控制算法。它通过准确控制电机的磁场方向和大小，实现对电机速度和转矩的精确控制。 FOC 驱动器与无刷电调的区别电调（ESC）的全称为电子调速器（Electronic Speed Controller），是一种硬件产品。FOC 则是一种电机驱动控制方法。 无刷电机驱动原理电机由两个主要组成部分构成：固定的定子（stator）和旋转的转子（rotor），无刷电机也不例外。转子又分为内转子和外转子两类。我们最熟悉的、在航模和无人机上使用的就是外转子结构的无刷电机，而内转子无刷电机则通常用于家电、工业驱动和机器人等应用。 注：若线圈是转子则磁极是定子，若线圈是定子则磁极是转子。下图所示无刷电机属于前一种结构。 另一组常见的概念是相数和极数。电机的相数，可以简单理解为电机定子线圈的组数。电机的极数则是指电机转子上磁极的数量（一对磁极包括一个 N 极和一个 S 极）。下图所示为一个具有12个电机绕组槽（slot）、16个磁极（magnet）的三相无刷直流电机示意图。 常见电机的相数，通常有以下几种： 单相电机（Single-Phase Motor）：单相电机具有一个绕组（相），通常用于低功率应用，如小型家用电器、风扇、泵等。单相电机的运行起动相对简单，但通常功率较低。 三相电机（Three-Phase Motor）：三相电机具有三个绕组（相），广泛应用于工业和商业领域，包括大型马达、制造设备、电动车、空调等。它们通常比单相电机具有更高的功率和效率，因为它们的电流分布更均匀，能够提供平稳的旋转力矩。 步进电机（Stepper Motor）：步进电机通常具有多个相，通常是两相、四相或八相。它们通过逐步激活不同的相来实现精确的角度控制，因此在需要精确位置控制的应用中非常有用，如打印机、CNC 机床和 3D 打印机。 通过相数和极数可用以下公式计算转速（单位：转每分钟，RPM）：转速 (60 * 电源频率) (极对数 * 相数) 这个公式称为同步转速公式，它描述了电机转子旋转的速度与相数和极对数之间的关系。需要注意的是，这个公式是针对同步运行状态下的电机转速，实际运行时可能存在一定的滑差。 基础知识 左手定则（电动机原理。事实后面介绍的安倍定则也适用于解释电机的运动原理）：用于判断导线在磁场中的受力方向。拇指与其他四指方向垂直且在同一平面，磁感线从手心垂直穿过，四指指向电流方向，则大拇指指向的就是安培力方向（即导体受力方向）或洛伦兹力。（当电流方向与磁场平行时，电荷运动方向也与磁场方向平行，所受洛伦兹力为零） 右手螺旋定则（安培定则）：用于判断电流的感应磁场方向。一般来说有两种情况，分别为“单根导线的感应磁场方向”和“通电螺线管的磁场方向”。左图所示，右手大拇指指向电流方向，则四指弯曲方向就是磁场方向。右图所示，四指蜷握并顺着电流方向，则拇指指向的就是磁场方向，即 N 极。 右手定则（发电机原理）：用于判断导线切割磁感线时所产生的电流的方向。伸开右手，使大拇指跟其余四指垂直并且都跟手掌在一个平面内，让磁感线垂直穿入手心，大拇指指向导体运动方向，则其余四指所指方向即为感生电动势方向。（注：利用反电动势测量电路获取转子位置，是无感电调工作原理之一） BLDC 驱动原理BLDC 驱动原理基于电子换向技术，相比传统有刷直流电机，它没有碳刷和机械换向器。BLDC 的驱动依靠精确改变电机上多个定子线圈（假设线圈绕组是定子如航模无刷电机）的电流交变频率和幅值（表现为多个波形变化曲线及其相序关系），在定子周围形成磁场, 驱动转子永磁体转动。因此可以将研究的重点放在如何改变多个定子线圈的相序和电流，而这需要交给驱动电路、控制器、传感器（若是闭环控制）这些硬件以及控制器上的算法软件，所以到了具体实现这一步，就得靠硬件和软件！ 电机模型和运动分析为了分析方便，以简化的三相二极内转子电机为例（且转子为磁极、定子为绕组）。事实上，定子的三相绕组有星形连结和三角连结两种方式，其中星形连结更为常用（连接方式是每一相引出导线的一头，而另一头和其他相两两相连），而我们后续就采用该模型做分析。 假设此时我们对 A、B 极分别施加正、负电压，那么由右手螺旋定则可以判断出线圈磁极的方向如下图红色箭头和蓝色箭头所示（绿色箭头可以理解为两线圈合成的磁极方向）。此时当转子处于与 C 点与转轴中点连线重合的角度时，受到的力矩最大（两个磁极一推一拉），直到旋转到与 AB 连线平行的且磁铁内部磁力线方向和 AB 间磁力线方向一致的时候，才是稳定的平衡位置。换句话说，AB 相通电会让转子努力转到下图右边的状态。 以此类推，可以得到每个通电状态线圈绕组的磁极方向，进而获得转子的方向和角度（方向重叠、角度相反），就是下图中的 6 个状态，每个状态相隔 60°，即完整的一周转动包括 6 个状态，共进行了 6 次换相： 注：事实上，横坐标 1 和 2 的中间位置也是一个力平衡点。但此处三相均没有换向，因此未计入状态之一。 推荐一篇呈现了运动规律动画演示的 博文。在这篇文章中，电机为外转子磁极结构，且极数为 12。该电机旋转一周所需的总步数为 12*336（极数乘以相数得到的结果，反映了电机中磁场变化的次数，决定了电机旋转一周所需的步数。总极对数越高，电机通常会具有更平滑的输出特性。至于绕组数量如何确定我还没有深究，但似乎可以使用公式 线圈绕组数360(相邻磁极夹角 + 360(pole*3))) 计算出正确的值，感兴趣的朋友可以自行研究下。 驱动电路简述无刷电机的驱动电路主要使用三相逆变电路来实现。逆变电路的主要功能是将直流电转换为交流电（通过前一节的分析可知，无刷电机驱动需要在不同时刻施加不同方向的电压，故需要逆变电路）。逆变器的工作原理是通过控制开关器件（如晶体管或 MOSFET）的导通和截止，来改变电流的方向和幅值，从而产生所需频率和幅值的交流电。 逆变电路一般是采用半桥 MOS 电路实现。两个功率开关器件即 MOS 管组成上、下桥臂，以中间点作为输出，提供方波型号。这种结构在 PWM 电机控制、DC-AC 逆变、电子镇流器等场合有着广泛的应用。由于开关延时的存在，当其中的一个管子栅极信号变为低时，它并不会立刻关断，因此一个管子必须在另一个管子关断后一定时间方可开启，以防止同时开启造成的电流穿通，这个时间称为死区时间。 用 3 个半桥电路就可以组合成三相逆变电路，每个半桥引出的一根输出线跟无刷电机的一根相线相连，就完成了最基本的无刷驱动电路。 FOC 原理FOC 项目（开源）SimpleFOC ODrive 参考稚晖君 【自制FOC驱动器】深入浅出讲解FOC算法与SVPWM技术 DengFOC 主页文档 FOC最基本原理、clark变换 、park变换、附代码 野火 电机应用开发实战指南","tags":["clippings"],"categories":["3.软件","FOC"]},{"title":"大小端，字节序，位序，字节对齐，位域对齐","path":"/2024/12/12/1-语言-C语言-位运算-大小端，字节序，位序，字节对齐，位域对齐/","content":"测试用源代码：#includestdio.h#includestring.h#if 1struct Test unsigned short a:2; unsigned short b:3; unsigned short c:5; unsigned short d:8;;#elsestruct Test unsigned char a:2; unsigned char b:3; unsigned char c:5; unsigned char d:8;;#endifint main(void) struct Test t; memset(t, 0x00,sizeof(t)); t.a = 1; t.b = 1; t.c = 1; t.d = 1; printf(%08X , *(unsigned int *)t); return 0; 分析与结果： 总结： csdn 上很多文章称“位域不可以跨越字节”，错。正确说是位域不可以跨越变量类型。如图中中间的例子（测试用源代码里用#if #else分别测试了unsigned short 和 unsigned char 两种情况）。 字节对齐与位域对齐的规则网上有很多文章，图中给出了两种例子，其实原则都是一样的：以对齐要求为边界（通常是 4 字节为边界），能挤就挤。不能挤就再开一个。 面试时遇到这类题的解题思路如上图：1，先从低地址到高地址画出一张图；2，再把结构体成员按照字节对齐和位域对齐要求填入；3，再把成员变量的二进制值填入，小端与书写顺序相反（从右往左写值），大端符合书写和阅读习惯（从左往右）4，根据二进制的值计算出最终的输出。（注意小端低地址存的是数字的低位） MSB,LSB,结合大小端的问题：网上大多数文章的例子： 大端模式：一个多字节数据的高字节在前，低字节在后，以数据 0x1234ABCD 看例子：低地址 ——————— 高地址±±±±±±±±±±±±±±±| 12 | 34 | AB | CD |±±±±±±±±±±±±±±±小端模式：一个多字节数据的低字节在前，高字节在后，仍以 0x1234ABCD 看：低地址 ——————— 高地址±±±±±±±±±±±±±±±| CD | AB | 34 | 12 |±±±±±±±±±±±±±±± 这里有一个重大的存在可能误导的地方，就是上面只做了字节序的调整，没有做位序（比特序）的调整。严格的说这只是小端 CPU 里网络序与主机序的转换，而不是大小端的转换。 如果真要做大小端的转换呢？我们都知道上面的例子中小端模式十六进制的 CD 存在低地址。那小端模式十六进制的 CD 的二进制到底是怎么存的呢？ 看了上面的图例我们可以推测出“CD”的二进制形式在小端模式下，仍然是反书写顺序的（即从右往左看才能得到 CD）这里给出一个更直观的大小端对比图： 以上图再导出 MSB 与 LSB： MSB 与 LSB 是数字的高低位的概念，是数字就有最高位和最低位。 MSB first 与 LSB first 是传输或拷贝时的概念，常见于不同协议之间的转换（比如 32 位传输转换到到 8 位传输），以上图举例：如果是 LSB first ，这是在告诉我们传输或拷贝时，数据的低位放在前面，即从 2 的 0 次方开始传输或拷贝。 为什么 htonl()、ntohl()只做了字节转换？因为在以太网中，字节序我们是按照大端序来发送，但是位序（比特序）却是按照小端序的方式来发送（LSB first）结合上图，网络发送顺序为： 224 225 226 227 228 229 230 231 216 217 218 219 220 221 222 223 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 这里解释了为什么小端 CPU 的网络序与主机序的转换是 0x12345678,变成 0x78563412.（即比特序在一个字节内是没有变化的） 为什么只做字节序的转换就可以了，大小端之间传送不用做位序（比特序）的转换吗？是的，大小端之间传送不用做位序（比特序）的转换。重复上面的话，LSB first， MSB first 是协议约定，约定好了，之后自然再按约定还原即可。打个比方，快递一套家具，先要拆分，再打包，再发送，到了之后再组装还原。这个过程就是协议做的事情。对用户（读写程序）来说，看到的一直是一套完整的家具（数据）。 那为什么说大端不用做转换呢？大端 CPU 不用做字节转换，发送时的位序（比特序）的转换是协议的事情，当然发送的位序与内存里的位序是不一样的。怎么发送，是协议的事情。 小端机内存中（低地址到高地址） 字节转换后 以太网中 大端机内存中（低地址到高地址） 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 200 201 202 203 204 205 206 207 215 214 213 212 211 210 209 208 207 206 205 204 203 202 201 200 脚-下半身-上半身-头 上半身-头，脚-下半身 上半身-头，脚-下半身 头-上半身-下半身-脚 小端 CPU 要做字节转换，然后让以太网协议去传输，传输完成，最终的数据是一致的（大小端只是方向反了而已）。 可见从大端机到网络也是有“转换”的。只是编写上层的程序时不用考虑。驱动或硬件要考虑。 为什么小端机不做成驱动硬件自动字节转换？字节转换有长度问题，比如两个字节一转？还是四个字节一转？还是八个字节一转？而位转换只有一种，就是 8 个位一转。所以小端 CPU 要调用字节 转换函数。 带位域的 结构体 应该如何编写才能在网络上正确传输？先看几个例子： //linux-3.4/include/linux/netfilter/nf_conntrack_proto_gre.hstruct gre_hdr #if defined(__LITTLE_ENDIAN_BITFIELD) __u16 rec:3, srr:1, seq:1, key:1, routing:1, csum:1, version:3, reserved:4, ack:1;#elif defined(__BIG_ENDIAN_BITFIELD) __u16 csum:1, routing:1, key:1, seq:1, srr:1, rec:3, ack:1, reserved:4, version:3;#else#error Adjust your asm/byteorder.h defines#endif __be16 protocol;;//linux-3.4/include/linux/icmpv6.hstruct icmpv6_nd_advt #if defined(__LITTLE_ENDIAN_BITFIELD) __u32 reserved:5, override:1, solicited:1, router:1, reserved2:24;#elif defined(__BIG_ENDIAN_BITFIELD) __u32 router:1, solicited:1, override:1, reserved:29;#else#error Please fix asm/byteorder.h#endif u_nd_advt;struct icmpv6_nd_ra __u8 hop_limit;#if defined(__LITTLE_ENDIAN_BITFIELD) __u8 reserved:3, router_pref:2, home_agent:1, other:1, managed:1;#elif defined(__BIG_ENDIAN_BITFIELD) __u8 managed:1, other:1, home_agent:1, router_pref:2, reserved:3;#else#error Please fix asm/byteorder.h#endif __be16 rt_lifetime; u_nd_ra; 由上面三个内核源代码里的结构体可以看出规律：1. 以一个字节为单位，字节内的位域位置反转。2. 大端结构体里位域字段顺序与网络序相同，小端相反。 位域跨越字节应该如何处理？有没有跨字节的例子？有 802.1Q 协议里的 vlan 字段就跨了字节。 Type PRI CFI Vlan ID 16bits 3bits 1bits 12bits //linux-3.4/include/linux/if_vlan.h/** * struct vlan_ethhdr - vlan ethernet header (ethhdr + vlan_hdr) * @h_dest: destination ethernet address * @h_source: source ethernet address * @h_vlan_proto: ethernet protocol (always 0x8100) * @h_vlan_TCI: priority and VLAN ID * @h_vlan_encapsulated_proto: packet type ID or len */struct vlan_ethhdr unsigned char h_dest[ETH_ALEN]; unsigned char h_source[ETH_ALEN]; __be16 h_vlan_proto; __be16 h_vlan_TCI; __be16 h_vlan_encapsulated_proto;; 使用位移或位运算处理，占 2 个字节的 h_vlan_TCI 在网络序转主机序后，去掉高位的 4 位就是 vlan ID. 参考资料：https://www.linuxjournal.com/article/6788","tags":["clippings"],"categories":["1.语言","C语言","位运算"]},{"title":"信号与槽详解","path":"/2024/12/12/1-语言-Qt-信号与槽详解/","content":"1、概述信号槽是 Qt 框架引以为豪的机制之一。所谓信号槽，实际就是 观察者模式。当某个事件发生之后，比如，按钮检测到自己被点击了一下，它就会发出一个信号（signal）。这种发出是没有目的的，类似广播。如果有对象对这个信号感兴趣，它就会使用连接（connect）函数，意思是，将想要处理的信号和自己的一个函数（称为槽（slot））绑定来处理这个信号。也就是说，当信号发出时，被连接的槽函数会自动被回调。这就类似观察者模式：当发生了感兴趣的事件，某一个操作就会被自动触发。（这里提一句，Qt 的信号槽使用了额外的处理来实现，并不是 GoF 经典的观察者模式的实现方式。） 信号和槽是 Qt 特有的信息传输机制，是 Qt 设计程序的重要基础，它可以让互不干扰的对象建立一种联系。 槽的本质是类的成员函数，其参数可以是任意类型的。和普通 C++成员函数几乎没有区别，它可以是 虚函数；也可以被重载；可以是公有的、保护的、私有的、也可以被其他 C++成员函数调用。唯一区别的是：槽可以与信号连接在一起，每当和槽连接的信号被发射的时候，就会调用这个槽。 1.1 对象树(子对象动态分配空间不需要释放)参考连接：https://blog.csdn.net/fzu\\_dianzi/article/details/6949081 Qt 提供了一种机制，能够自动、有效的组织和管理继承自 QObject 的 Qt 对象，这种机制就是对象树。 Qt 对象树在 用户界面 编程上是非常有用的。它能够帮助程序员减轻内存泄露的压力。 比如说当应用程序创建了一个具有父窗口部件的对象时，该对象将被加入父窗口部件的孩子列表。当应用程序销毁父窗口部件时，其下的孩子列表中的对象将被一一删除。这让我们在编程时，能够将主要精力放在系统的业务上，提高编程效率，同时也保证了系统的稳健性。 下面笔者将简单分析对象树。 代码验证： int main(int argc, char *argv[]) QApplication app(argc, argv); QDialog *dlg = new QDialog(0); QPushButton *btn = new QPushButton(dlg); qDebug() dlg = dlg; qDebug() btn = btn; dlg-exec(); delete btn; qDebug() dlg = dlg; return 0;dlg = QDialog(0x3ea1a0) btn = QPushButton(0x3ea228) 关闭窗口后，dlg QDialog(0x3ea1a0)这说明关闭窗口，不会销毁该窗口部件，而是将其隐藏起来。我们在 qDebug() “dlg “ dlg;之后加上qDebug() “btn “ btn;明显的，我们之前已经 delete btn，btn 指针没有被赋值为 0，这是编译器决定的。执行程序后，必然出现段错误。 2、将程序稍微修改下。 int main(int argc, char *argv[]) QApplication app(argc, argv); QDialog *dlg = new QDialog(0); QPushButton *btn = new QPushButton(dlg); qDebug() dlg = dlg; qDebug() btn = btn; dlg-exec(); delete dlg; qDebug() btn = btn; return 0; 2、信号和槽为了体验一下信号槽的使用，我们以一段简单的代码说明：Qt5 的书写方式：（推荐的使用）★★★★★ #include QApplication#include QPushButtonint main(int argc, char *argv[]) QApplication app(argc, argv); QPushButton button(Quit);\tQObject::connect(button, QPushButton::clicked,\tapp, QApplication::quit); button.show(); return app.exec(); 我们按照前面文章中介绍的在 Qt Creator 中创建工程的方法创建好工程，然后将 main()函数修改为上面的代码。点击运行，我们会看到一个按钮，上面有“Quit”字样。点击按钮，程序退出。 connect()函数最常用的一般形式： connect(sender, signal, receiver, slot); 参数： sender：发出信号的对象 signal：发送对象发出的信号 receiver：接收信号的对象 slot：接收对象在接收到信号之后所需要调用的函数 信号槽要求信号和槽的参数一致，所谓一致，是参数类型一致。如果不一致，允许的情况是，槽函数的参数可以比信号的少，即便如此，槽函数存在的那些参数的顺序也必须和信号的前面几个一致起来。这是因为，你可以在槽函数中选择忽略信号传来的数据（也就是槽函数的参数比信号的少），但是不能说信号根本没有这个数据，你就要在槽函数中使用（就是槽函数的参数比信号的多，这是不允许的）。 如果信号槽不符合，或者根本找不到这个信号或者槽函数，比如我们改成： connect(button, QPushButton::clicked, QApplication::quit2); 由于 QApplication 没有 quit2 这样的函数，因此在编译时会有编译错误： quit2 is not a member of QApplication 这样，使用成员函数指针我们就不会担心在编写信号槽的时候出现函数错误。 Qt4 的书写方式： int main(int argc, char *argv[]) QApplication a(argc, argv); QPushButton *button = new QPushButton(Quit); connect(button, SIGNAL(clicked()), a, SLOT(quit())); button-show(); return a.exec(); 这里使用了SIGNAL和SLOT这两个宏，将两个函数名转换成了字符串。注意到 connect()函数的 signal 和 slot 都是接受字符串，一旦出现连接不成功的情况，Qt4 是没有编译错误的（因为一切都是字符串，编译期是不检查字符串是否匹配），而是在运行时给出错误。这无疑会增加程序的不稳定性。 Qt5 在语法上完全兼容 Qt4 小总结： 1. 格式: connect(信号发出者对象(指针), className::clicked, 信号接收者对象(指针), classB::slot); 2. 标准信号槽的使用: connect(sender, Send::signal, receiver, Receiver::slot) 3、自定义信号槽使用 connect()可以让我们连接系统提供的信号和槽。但是，Qt 的信号槽机制并不仅仅是使用系统提供的那部分，还会允许我们自己设计自己的信号和槽。 下面我们看看使用 Qt 的信号槽，实现一个报纸和订阅者的例子： 有一个报纸类 Newspaper，有一个订阅者类 Subscriber。Subscriber 可以订阅 Newspaper。这样，当 Newspaper 有了新的内容的时候，Subscriber 可以立即得到通知。 #include QObject // newspaper.h // class Newspaper : public QObject Q_OBJECTpublic: Newspaper(const QString name) : m_name(name) void send() emit newPaper(m_name); signals: void newPaper(const QString name); private: QString m_name;; // reader.h //#include QObject#include QDebug class Reader : public QObject Q_OBJECTpublic: Reader() void receiveNewspaper(const QString name) qDebug() Receives Newspaper: name; ; // main.cpp //#include QCoreApplication #include newspaper.h#include reader.h int main(int argc, char *argv[]) QCoreApplication app(argc, argv); Newspaper newspaper(Newspaper A); Reader reader; QObject::connect(newspaper, Newspaper::newPaper, reader, Reader::receiveNewspaper); newspaper.send(); return app.exec(); ●首先看 Newspaper 这个类。这个类继承了 QObject 类。只有继承了 QObject 类的类，才具有信号槽的能力。 所以，为了使用信号槽，必须继承 QObject。凡是 QObject 类（不管是直接子类还是间接子类），都应该在第一行代码写上 Q_OBJECT。不管是不是使用信号槽，都应该添加这个宏。这个宏的展开将为我们的类提供信号槽机制、国际化机制以及 Qt 提供的不基于 C++ RTTI 的反射能力。 ● Newspaper 类的 public 和 private 代码块都比较简单，只不过它新加了一个 signals。signals 块所列出的，就是该类的信号。信号就是一个个的函数名，返回值是 void（因为无法获得信号的返回值，所以也就无需返回任何值），参数是该类需要让外界知道的数据。信号作为函数名，不需要在 cpp 函数中添加任何实现。 ●Newspaper 类的 send()函数比较简单，只有一个语句 emit newPaper(m_name);。emit 是 Qt 对 C++ 的扩展，是一个关键字（其实也是一个宏）。emit 的含义是发出，也就是发出 newPaper()信号。感兴趣的接收者会关注这个信号，可能还需要知道是哪份报纸发出的信号？所以，我们将实际的报纸名字 m_name 当做参数传给这个信号。当接收者连接这个信号时，就可以通过槽函数获得实际值。这样就完成了数据从发出者到接收者的一个转移。 ● Reader 类更简单。因为这个类需要接受信号，所以我们将其继承了 QObject，并且添加了 Q_OBJECT 宏。后面则是默认构造函数和一个普通的成员函数。Qt 5 中，任何成员函数、static 函数、全局函数和 Lambda 表达式都可以作为槽函数。与信号函数不同，槽函数必须自己完成实现代码。槽函数就是普通的成员函数，因此作为成员函数，也会受到 public、private 等访问控制符的影响。（如果信号是 private 的，这个信号就不能在类的外面连接，也就没有任何意义。） 3.1 自定义信号槽需要注意的事项●发送者和接收者都需要是 QObject 的子类（当然，槽函数是全局函数、Lambda 表达式等无需接收者的时候除外）； ●使用 signals 标记信号函数，信号是一个函数声明，返回 void，不需要实现函数代码； ●槽函数是普通的成员函数，作为成员函数，会受到 public、private、protected 的影响； ●使用 emit 在恰当的位置发送信号； ●使用 QObject::connect()函数连接信号和槽。 ●任何成员函数、static 函数、全局函数和 Lambda 表达式都可以作为槽函数 3.2 信号槽的更多用法● 一个信号可以和多个槽相连　如果是这种情况，这些槽会一个接一个的被调用，但是它们的调用顺序是不确定的。 ●多个信号可以连接到一个槽只要任意一个信号发出，这个槽就会被调用。 ●一个信号可以连接到另外的一个信号当第一个信号发出时，第二个信号被发出。除此之外，这种信号-信号的形式和信号-槽的形式没有什么区别。 ●槽可以被取消链接这种情况并不经常出现，因为当一个对象 delete 之后，Qt 自动取消所有连接到这个对象上面的槽。 ●使用 Lambda 表达式在使用 Qt 5 的时候，能够支持 Qt 5 的编译器都是支持 Lambda 表达式的。 我们的代码可以写成下面这样： QObject::connect(newspaper, static_castvoid (Newspaper:: *)(const QString )(Newspaper::newPaper),[=](const QString name) /* Your code here. */ ); 在连接信号和槽的时候，槽函数可以使用 Lambda 表达式的方式进行处理。 4、Lambda 表达式C++11 中的 Lambda 表达式用于定义并创建匿名的函数对象，以简化编程工作。首先看一下 Lambda 表达式的基本构成：[函数对象参数](操作符重载函数参数)mutable或exception -返回值函数体 ①函数对象参数； []，标识一个 Lambda 的开始，这部分必须存在，不能省略。函数对象参数是传递给编译器自动生成的函数对象类的构造函数的。函数对象参数只能使用那些到定义 Lambda 为止时 Lambda 所在作用范围内可见的局部变量（包括 Lambda 所在类的 this）。函数对象参数有以下形式： ▲空。没有使用任何函数对象参数。 ▲。函数体内可以使用 Lambda 所在作用范围内所有可见的局部变量（包括 Lambda 所在类的 this），并且是值传递方式（相当于编译器自动为我们按值传递了所有局部变量）。 ▲。函数体内可以使用 Lambda 所在作用范围内所有可见的局部变量（包括 Lambda 所在类的 this），并且是引用传递方式（相当于编译器自动为我们按引用传递了所有局部变量）。 ▲ this。函数体内可以使用 Lambda 所在类中的成员变量。 ▲ a。将 a 按值进行传递。按值进行传递时，函数体内不能修改传递进来的 a 的拷贝，因为默认情况下函数是 const 的。要修改传递进来的 a 的拷贝，可以添加 mutable 修饰符。 ▲ a。将 a 按引用进行传递。 ▲ a, b。将 a 按值进行传递，b 按引用进行传递。 ▲ ，a, b。除 a 和 b 按引用进行传递外，其他参数都按值进行传递。 ▲ , a, b。除 a 和 b 按值进行传递外，其他参数都按引用进行传递。 int m = 0, n = 0;[=] (int a) mutable m = ++n + a; (4); [] (int a) m = ++n + a; (4); [=,m] (int a) mutable m = ++n + a; (4); [,m] (int a) mutable m = ++n + a; (4); [m,n] (int a) mutable m = ++n + a; (4); [m,n] (int a) m = ++n + a; (4); ② 操作符重载函数参数； 标识重载的()操作符的参数，没有参数时，这部分可以省略。参数可以通过按值（如：(a,b)）和按引用（如：(a,b)）两种方式进行传递。 ③ 可修改标示符； mutable 声明，这部分可以省略。按值传递函数对象参数时，加上 mutable 修饰符后，可以修改按值传递进来的拷贝（注意是能修改拷贝，而不是值本身）。 ④ 错误抛出标示符； exception 声明，这部分也可以省略。exception 声明用于指定函数抛出的异常，如抛出整数类型的异常，可以使用 throw(int) ⑤ 函数返回值； -返回值类型，标识函数返回值的类型，当返回值为 void，或者函数体中只有一处 return 的地方（此时编译器可以自动推断出返回值类型）时，这部分可以省略。 ⑥ 是函数体； {}，标识函数的实现，这部分不能省略，但函数体可以为空。 总结： 案例代码： mainwidget.h #ifndef MAINWIDGET_H#define MAINWIDGET_H#include QWidget#include QPushButton#include subwidget.h //子窗口头文件class MainWidget : public QWidget Q_OBJECTpublic: MainWidget(QWidget *parent = 0); ~MainWidget();public slots: void mySlot(); void changeWin(); void dealSub(); void dealSlot(int, QString);private: QPushButton b1; QPushButton *b2; QPushButton b3; SubWidget subWin;;#endif // MAINWIDGET_H subwidget.h #ifndef SUBWIDGET_H#define SUBWIDGET_H#include QWidget#include QPushButtonclass SubWidget : public QWidget Q_OBJECTpublic: explicit SubWidget(QWidget *parent = 0); void sendSlot();signals: /* 信号必须有signals关键字来声明 * 信号没有返回值，但可以有参数 * 信号就是函数的声明，只需声明，无需定义 * 使用：emit mySignal(); * 信号可以重载 */ void mySignal(); void mySignal(int, QString);public slots:private: QPushButton b;;#endif // SUBWIDGET_H main.cpp #include mainwidget.h#include QApplicationint main(int argc, char *argv[]) QApplication a(argc, argv); MainWidget w;//执行MainWidget的构造函数 w.show(); return a.exec(); mainwidget.cpp #include mainwidget.h#include QPushButton#include QDebug //打印MainWidget::MainWidget(QWidget *parent) : QWidget(parent) b1.setParent(this); b1.setText(close); b1.move(100, 100); b2 = new QPushButton(this); b2-setText(abc); connect(b1, QPushButton::pressed, this, MainWidget::close); /* b1: 信号发出者，指针类型 * QPushButton::pressed：处理的信号， 发送者的类名::信号名字 * this: 信号接收者 * MainWidget::close： 槽函数，信号处理函数 接收的类名::槽函数名字 * 发送-处理-接收-处理 */ /* 自定义槽，普通函数的用法 * Qt5：任意的成员函数，普通全局函数，静态函数 * 槽函数需要和信号一致（参数，返回值） * 由于信号都是没有返回值，所以，槽函数一定没有返回值 */ connect(b2, QPushButton::released, this, MainWidget::mySlot); connect(b2, QPushButton::released, b1, QPushButton::hide); /* 信号：短信 * 槽函数：接收短信的手机 */ setWindowTitle(老大); //this-setWindowTitle(老大);//等价同上 b3.setParent(this); b3.setText(切换到子窗口); b3.move(50, 50); //显示子窗口 //subWin.show(); connect(b3, QPushButton::released, this, MainWidget::changeWin); //处理子窗口的信号// void (SubWidget::*funSignal)() = SubWidget::mySignal;// connect(subWin, funSignal, this, MainWidget::dealSub);// void (SubWidget::*testSignal)(int, QString) = SubWidget::mySignal;// connect(subWin, testSignal, this, MainWidget::dealSlot); //Qt4信号连接 //Qt4槽函数必须有slots关键字来修饰 connect(subWin, SIGNAL(mySignal()), this, SLOT(dealSub()) ); connect(subWin, SIGNAL(mySignal(int,QString)), this, SLOT(dealSlot(int,QString)) ); //缺点： SIGNAL SLOT 将函数名字 - 字符串 不进行错误检查 //Lambda表达式, 匿名函数对象 //C++11增加的新特性， 项目文件： CONFIG += C++11 //Qt配合信号一起使用，非常方便 QPushButton *b4 = new QPushButton(this); b4-setText(Lambda表达式); b4-move(150, 150); int a = 10, b = 100; connect(b4, QPushButton::clicked, // = :把外部所有局部变量、类中所有成员以值传递方式 // this: 类中所有成员以值传递方式 // : 把外部所有局部变量， 引用符号 [=](bool isCheck) qDebug() isCheck; ); resize(400, 300);void MainWidget::dealSlot(int a, QString str) // str.toUtf8() - 字节数组QByteArray // ……data() - QByteArray - char * qDebug() a str.toUtf8().data();void MainWidget::mySlot() b2-setText(123);void MainWidget::changeWin() //子窗口显示 subWin.show(); //本窗口隐藏 this-hide();void MainWidget::dealSub() //子窗口隐藏 subWin.hide(); //本窗口显示 show();MainWidget::~MainWidget() subwidget.cpp #include subwidget.hSubWidget::SubWidget(QWidget *parent) : QWidget(parent) this-setWindowTitle(小弟); b.setParent(this); b.setText(切换到主窗口); connect(b, QPushButton::clicked, this, SubWidget::sendSlot); resize(400, 300);void SubWidget::sendSlot() emit mySignal(); emit mySignal(250, 我是子窗口);SingnalAndSlot.proQT += core guigreaterThan(QT_MAJOR_VERSION, 4): QT += widgetsTARGET = 03_SignalAndSlotTEMPLATE = appSOURCES += main.cpp\\ mainwidget.cpp \\ subwidget.cppHEADERS += mainwidget.h \\ subwidget.hCONFIG += C++11","tags":["clippings"],"categories":["1.语言","Qt"]},{"title":"信号槽分析","path":"/2024/12/12/1-语言-Qt-信号槽分析/","content":"moc 元对象编译器, 全称是 Meta-Object Compiler，也就是“元对象编译器”。是 QT 翻译扩展语法到 C++语言的工具，目前见扩展了信号与槽机制。 信号槽方式编程上更方便（不容易出错） 回调需要自行处理麻烦的回调管理，稍微不注意就出错。 而且信号槽方式更利于 mvc 分离实现。 信号和槽机制的优点: 类型安全, 关联的信号和槽的参数必须是等同。 降低 Qt 对象间的耦合度,只需要 emit,对象无需知道哪个对象来接收该信号, 信号槽的效率和回调函数相比,变低 10 倍, 原因如下: 1）需要定位接收信号的对象。 2）遍历所有的关联（如一信号对多槽） 3）传递的参数 4）多线程的时候。信号可能需要排队等待。 **1.**信号和槽实现 1.Q_OBJECT Q_OBJECT 展开后,会有一个 QMetaObject 元对象静态类、还有一些元对象操作函数： signals****和 slots: 我们以这为例: 预处理之前会调用 moc 程序，对文件预处理之后生成一个 moc_xxx.cpp 文件. 如下图所示: moc 会将 signals 和 slots 下的函数名转换为字符数组.并生成一个名称 idx 索引号. 然后生成一个 qt_meta_data_Widget(由于类名是 Widget,所以后缀是 Widget)数组: 其中 4, 14,表示有 4 个方法,然后 14 表示 unit 偏移位置,即 qt_meta_data_Widget[14]就是第一个方法. 然后并创建一个 qt_static_metacall 回调函数,实现调用目标类指针的槽函数: 当我调用 emit 信号时,其实就是调用 moc 实现的一个信号函数, 信号函数内部调用了 QMetaObject::activate()函数: 而 activate 函数就会去 QObjectConnectionListVector 连接链表容器里面查找信号对应的索引号所在的值,里面存放了每个接受对象指针和槽函数 id 的链表: 然后遍历该信号关联的链表里的所有目标对象指针和槽函数,并调用 qt_static_metacall 回调函数,实现调用槽函数. connect: connect 会将信号和槽函数字符串化, 然后执行 connect 的时候会判断信号槽参数是否一致.并遍历”信号槽”字符串的索引号.如果索引号都定义了,则在发送方的连接链表容器的信号索引处,添加一个目标对象指针和槽函数索引号的类到链表中.","tags":["clippings"],"categories":["1.语言","Qt"]},{"title":"信号槽传递大量数据的效率","path":"/2024/12/12/1-语言-Qt-信号槽传递大量数据的效率/","content":"1. 隐式共享在开发过程中，开发者经常面临着数据传递时的效率问题。特别是在 Qt 框架下，当需要通过信号槽传递大量数据时候，复制和拷贝的开销可能会给性能带来影响。为了优化这一过程，很多开发者选择使用指针传递数据，以避免不必要的数据复制。然而，Qt 中的隐式共享机制有效地解决了这个问题，使得开发者无需为此担忧。 隐式共享是一种资源管理策略，通过共享相同的数据副本来减少内存使用和提高效率。需要指出的是，隐式共享有其特定的条件和适用规则，并不是所有数据结构都支持。例如， QByteArray 和 QString 就支持隐式共享，但一些其他结构可能不具备这一特性。 #include QCoreApplication#include QDebugint main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建一个包含hello world的字节数组 QByteArray b2 = b1; // 这里发生了浅拷贝，b1和b2指向相同的数据 qDebug() 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); qDebug() 0x + QString::number(reinterpret_castqintptr(b2.constData()), 16); b2 = 你好，世界; // 修改b2的内容，此时会触发深拷贝 qDebug() Qt::endl; qDebug() 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); // 仍然为b1的地址 qDebug() 0x + QString::number(reinterpret_castqintptr(b2.constData()), 16); // b2的新地址 return a.exec(); 输出结果为： 0x1b65580x1b65580x1b65580x1b7d68 在这个示例中，b1 和 b2 初始时指向同一个内存地址。对 b2 的修改会触发深拷贝，这意味着 b2 现在有了自己的内存副本，而 b1 的数据依然是原来的内容。这种机制不仅提高了效率，也减轻了不必要的内存占用。 2.信号槽中的隐式共享信号槽机制是 Qt 的一个核心特性，它允许对象之间以松耦合的方式进行通信。这种通信方式也能受益于隐式共享，进一步提升数据传输的效率。 #include QCoreApplication#include QDebugclass Test : public QObject Q_OBJECTpublic: void received(QByteArray byte) qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); byte = x; // 此时会触发深拷贝 qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); signals: void sigByte(QByteArray byte); // 定义信号;int main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建字节数组 qDebug() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); Test t; // 创建Test类的实例 QObject::connect(t, Test::sigByte, t, Test::received); //连接信号和槽 emit t.sigByte(b1); // 发送信号 return a.exec();#include main.moc 输出结果为： int main(int, char**) 0xf66558void Test::received(QByteArray) 0xf66558void Test::received(QByteArray) 0xf67df8 这个例子展示了在信号槽中如何使用隐式共享。当信号 sigByte 发送时，received 槽接收的 byte 最初与 b1 指向同一内存位置。修改 byte 的内容，将触发深拷贝，确保 b1 的数据不会被改变。这意味着在添加信号槽时间劣化的风险可以被降到最低，优化了程序整体性能。 3.多线程中信号槽的隐式共享在现代应用开发中，多线程编程可以显著提升程序的响应能力和处理性能。Qt 的信号槽机制在多线程环境中同样有效，并且隐式共享在这里依然能大放异彩。 #include QCoreApplication#include QDebug#include QThreadclass Test : public QObject Q_OBJECTpublic: void received(QByteArray byte) qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); byte = x; // 触发深拷贝 qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(byte.constData()), 16); signals: void sigByte(QByteArray byte); // 定义信号;int main(int argc, char *argv[]) QCoreApplication a(argc, argv); QByteArray b1 = hello world; // 创建字节数组 qDebug() QThread::currentThread() Q_FUNC_INFO 0x + QString::number(reinterpret_castqintptr(b1.constData()), 16); Test t; QObject::connect(t, Test::sigByte, t, Test::received); // 连接信号和槽 QThread th; // 创建新的线程 t.moveToThread(th); // 将测试对象移入新线程 th.start(); emit t.sigByte(b1); // 发送信号，通过新线程处理 return a.exec();#include main.moc 输出结果为： QThread(0xdd5ff0) int main(int, char**) 0xdd6558QThread(0x69fd60) void Test::received(QByteArray) 0xdd6558QThread(0x69fd60) void Test::received(QByteArray) 0x2593a48 此示例中，信号 sigByte 发送的数据在新的线程 th 中被处理。标准的隐式共享机制依然适用，从上面的输出可以看到，received 槽输出的内存地址最初与 b1 相同，之后的深拷贝确保了 b1 的数据不被修改。这样不仅保持了数据安全性，也提供了多线程的灵活性。 4.结论通过以上示例，无论是在单线程还是多线程环境中，Qt 的信号槽机制都有效支持隐式共享。这种机制减少了数据传输中的拷贝开销，使得即使在传递大数据量时也不会显著影响性能。 尽管在测试中主要围绕 QByteArray 展示了隐式共享的性质，但其他数据结构是否支持隐式共享仍需查阅 Qt 官方文档或进行功能测试。在某些情况下，为了进一步优化性能，建议在信号槽连接时使用常引用 const QByteArray 来传递数据，这样既能避免临时变量的构造开销，也能确保在信号传输过程中不会造成数据的复制和不必要的内存使用。在多线程环境中，使用常引用同样是一个有效且高效的选择。","tags":["clippings"],"categories":["1.语言","Qt"]},{"title":"信号与槽连接的优化","path":"/2024/12/12/1-语言-Qt-信号与槽连接的优化/","content":"包括我在内，许多初学者在连接信号与槽的时候，常常使用一个信号对应一个槽函数，这种方式虽然在简单的小练习中能正常工作，但一旦项目规模稍微扩大，所需要编写的槽函数数量迅速增加，似乎变得有些难以管理。例如，当用户在界面上进行各种操作时，每个操作都可能触发相应的事件来发出信号，而这些信号如果要一一对应到槽函数，将会导致代码量的显著增加。 m_firstButton = new QPushButton(first, this);m_secondButton = new QPushButton(second, this);connect(m_firstButton, SIGNAL(clicked()), this, SLOT(firstButtonSlot()));connect(m_secondButton, SIGNAL(clicked()), this, SLOT(secondButtonSlot())); 显然，上述方式适用于简单的场景，但在复杂的项目中我们需要寻找更高效的方法来减少槽函数的数量，达到简化代码的目的。这里，QObject 类中的 sender() 方法将大大简化我们的工作。通过这个方法，我们可以确定哪个对象发出了信号，从而在一个通用的槽函数中处理不同的按钮事件。 m_firstButton = new QPushButton(first, this);m_secondButton = new QPushButton(second, this);QHBoxLayout *layout = new QHBoxLayout(this);layout-addWidget(m_firstButton);layout-addWidget(m_secondButton);connect(m_firstButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));connect(m_secondButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));void c::buttonClickedSlot() // 获取发出信号的对象 auto button = qobject_castQPushButton*(this-sender()); // 对对象进行判断 if (button == m_firstButton) qDebug() firstButtonClicked; else if (button == m_secondButton) qDebug() secondButtonClicked; 通过这种方式，我们可以清楚地识别是哪个按钮触发了点击事件，从而在一个集中处理的地方管理按钮的响应。这样，我们不仅减少了槽函数的数量，代码的逻辑也更加清晰。 除了这种连接信号与槽的方式，Qt 还允许使用信号连接信号。但是，如果我们这样做，会存在一个问题：无法判断到底是哪个对象发出的信号。例如，当我们连接两个按钮的点击信号到同一个槽时，最终只会收到一个按钮信号，导致无法区分。 // 用信号连接一个信号connect(m_firstButton, SIGNAL(clicked()), this, SLOT(buttonClickedSlot()));connect(m_secondButton, SIGNAL(clicked()), m_firstButton, SIGNAL(clicked()));void c::buttonClickedSlot() auto button = qobject_castQPushButton*(this-sender()); if (button == m_firstButton) qDebug() firstButtonClicked; else if (button == m_secondButton) qDebug() secondButtonClicked; 在这种情况下，即使我们点击第二个按钮，发出的信号仍然是与第一个按钮关联的，因此不能达到我们想要的结果。 此外，在实际开发中，常常需要通过代码模拟用户的操作，尤其是在自动化测试或特定功能实现时。以 QPushButton 为例，它内置了一些方法，可以通过代码模拟按钮的点击事件。 // 模拟用户点击按钮m_firstButton-click();m_firstButton-toggle(); 此外，QPushButton 中提供了一系列与信号相对应的槽函数，如： public Q_SLOTS: void setIconSize(const QSize size); void animateClick(int msec = 100); // 模拟点击 void click(); // 通常用于模拟按钮点击 void toggle(); // 切换按钮的选中状态 void setChecked(bool); // 设置按钮是否选中 这些方法为开发者提供了更加灵活的方式，以便在代码中实现复杂的用户交互逻辑，从而提升程序的可维护性和可读性。","tags":["clippings"],"categories":["1.语言","Qt"]},{"title":"librkcrypto","path":"/2024/12/11/0-平台-Linux-加密-librkcrypto/","content":"librkcryptolibrkcrypto 提供了一套基于硬件的加密算法接口，能够有效地使用直接内存访问（DMA）方式进行数据处理。这一特性使得 librkcrypto 可广泛应用于加密、解密、数据认证等多种场景，提升了数据处理的效率和安全性。 librkcrypto 的设计依赖于内核加密驱动的实现。对于驱动开发以及应用 API 的开发，建议参考名为 Rockchip_Developer_Guide_Crypto_HWRNG_CN.pdf 的文档，该文档为开发者提供了详尽的指导。 版本号查询若需查询当前 API 的版本号，可以通过以下两种方式进行验证。 使用 strings 命令 # 在 64 位 Linux 平台上运行以下命令$ strings /lib64/librkcrypto.so | grep api | grep versionrkcrypto api version 1.2.0 执行以上命令后，您将获得当前的 API 版本，其格式为 “rkcrypto api version x.x.x”。 查看日志输出 当任一进程首次调用 librkcrypto 的接口时，该接口会在日志中输出当前版本号。例如： RKCRYPTO I[rk_crypto_init, 262]: rkcrypto api version 1.2.0 此信息确保开发者能够迅速确认正在使用的版本。 适用芯片平台librkcrypto 支持以下多个芯片平台，这些平台包括但不限于： RK3588 RK356x RV1109 RV1126 RK3326PX30 RK3308 RV110603 请注意，部分 API 可能不适用于某些特定的芯片平台，用户应参考应用开发说明文档以获取详细信息。 版本依赖V1.2.0 对于 kernel 4.19 版本：需要更新到以下提交： c255a0aa097a crypto: rockchip: rk3326/px30 add aes gcm support 对于 kernel 5.10 版本：需更新至以下提交： 47e85085826d crypto: rockchip: rk3326/px30 add aes gcm support V1.1.0 对于 kernel 4.19 版本：需进行如下更新： 1e549d833bc3 crypto: rockchip: v2: ahash init/update/final use hardware crypto 对于 kernel 5.10 版本：需更新至： 4d2020372e7e crypto: rockchip: v2: ahash fix hash_algo2name setting error. 此外，若需要使用 OTP key 的加解密功能，请确保 rkbin 更新至相应的提交版本，具体步骤如下： 对于 RK3588： 23ca562 rk3588: bl32: update version to v1.07 对于 RK356x： 86e9bb7 rk3568: bl32: update version to v2.07 对于 RV1109RV1126： 42eea81 rv1126: tee: update version to v2.05 目录说明项目目录结构简洁明了，包含以下重要部分： demo: 提供 API 使用示例，帮助开发者快速上手。 docs: 包含应用开发说明文档，详细介绍各类接口的使用。 include: 包含头文件，供外部程序调用。 src: 用户空间的驱动及 API 实现代码。 test: 包含 API 测试代码，确保功能的正确性。 third_party: 包含第三方开源代码以供引用。 编译说明Android要在 Android 平台上编译 librkcrypto，包括库、测试和示例，可以按照以下步骤操作： # 首先，在 Android 工程目录下执行$ source build/envsetup.sh$ lunch rk3588_s-userdebug # 选择 RK3588 平台# 然后 cd 到 librkcrypto 目录并执行编译$ mm 编译成功后，将根据您选择的芯片平台生成相应的 32 位或 64 位目标文件，包括 librkcrypto.so、librkcrypto_test 和 librkcrypto_demo。编译日志中会标明这些目标文件所在的目录。 Linux要在 Linux 平台上进行编译，步骤如下： # 在 librkcrypto 的目录下执行$ ./build.sh # 编译 32 位和 64 位$ ./build.sh 32 # 仅编译 32 位$ ./build.sh 64 # 仅编译 64 位 成功编译后，目标文件将位于 librkcrypto/out/target 目录下，文件包括 librkcrypto.so、librkcrypto.a 以及 librkcrypto_test。 编译 demo # 进入 demo 目录进行编译$ cd demo$ make 32 # 或直接 $ make，编译 32 位$ make 64 # 仅编译 64 位$ make clean # 清除目标文件 编译后，librkcrypto/demo 目录将生成目标文件 librkcrypto_demo。 使用说明 头文件 在使用 librkcrypto API 时，需包含以下头文件： #include rkcrypto_common.h // 包含通用函数#include rkcrypto_core.h // 使用 cipher、hash、hmac 等接口#include rkcrypto_mem.h // 使用支持 dma_fd 的接口#include rkcrypto_otp_key.h // 使用 otp_key 相关接口#include rkcrypto_random.h // 使用随机数接口 库文件 包括： librkcrypto.so librkcrypto.a (仅限于 Linux 平台) 日志打印 librkcrypto 设置了多种日志等级，方便开发者调试和获取运行信息： 等级 1 - TRACE_ERROR：表示错误信息，关键信息用以调试。 等级 2 - TRACE_INFO：包含常用信息，比如版本号等，默认级别。 等级 3 - TRACE_DEBUG：提供更深入的一般调试信息。 等级 4 - TRACE_VERBOSE：包括详细的调试信息，利于追踪问题。 您可以通过以下方式自定义日志等级，设置后将打印该等级及其以下等级的日志。请注意，设备重启后日志等级将恢复为默认的等级 2。 使用 API 设置： RK_RES rkcrypto_set_trace_level(enum RKCRYPTO_TRACE_LEVEL level); 使用指令设置： # Androidsetprop vendor.rkcrypto.trace.level 1/2/3/4# Linuxexport rkcrypto_trace_level=1/2/3/4 应用开发说明文档 开发者可以参考 Rockchip_Developer_Guide_Crypto_HWRNG_CN.pdf 文档，以获取具体的应用开发信息和指导。 FAQ 编译链依赖 本项目的 CMake 默认使用的编译链为 gcc 10.3 版本，通过如下路径进行访问： gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu 如果您的系统中没有相应的编译链版本，编译过程中可能会出现以下报错信息： make[2]: librkcrypto/../../prebuilts/gcc/linux-x86/arm/gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin/arm-none-linux-gnueabihf-gcc: Command not found 您可以通过修改 CMakeLists.txt 文件中的编译链路径和版本来解决此问题： set (TOOLCHAIN_PREBUILTS $CMAKE_CURRENT_SOURCE_DIR/../../prebuilts)set (TOOLCHAIN_PATH_ARM32 gcc/linux-x86/arm/gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin)set (TOOLCHAIN_PATH_AARCH64 gcc/linux-x86/aarch64/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin) 若在运行时遇到如下报错，说明编译链的 GLIBC 版本与设备上的 GLIBC 版本不一致。您需要修改编译链的版本或调整设备上的 GLIBC 版本。 version GLIBC_2.29 not found (required by /lib/librkcrypto.so)","categories":["0.平台","Linux","加密"]},{"title":"荧光定量 PCR中基线、阈值、 Ct 值","path":"/2024/12/11/3-软件-PCR-荧光定量-PCR中基线、阈值、-Ct-值/","content":"基线 (Baseline)基线指的是在 PCR（聚合酶链式反应）扩增反应的初始几个循环中，荧光信号的变化极小，基本保持在一个稳定的水平。这一段的荧光信号表现为接近一条直线，这样的直线称为基线。通常，这个基线区域显示了背景荧光信号，对后续的数据分析至关重要，因为它帮助确定真实的扩增信号何时开始超出背景噪声的水平。 阈值线 (Threshold)在 PCR 反应的前 15 个循环中所获得的荧光信号通常被视为荧光的本底信号。为了便于后续分析，许多实验室会将荧光阈值设定为 PCR 3—15 个循环荧光信号标准差的 10 倍。这个阈值线通常是在 PCR 扩增的指数期内设定的。 不同厂家会采用不同的算法设定阈值： 罗氏的算法：一般选择 3-12 个循环（可调，灵活变化），以基线的 10 倍标准差为依据。 大多数其他厂家的做法：同样选择 3-12 个循环，设定为基线平均值的 1.05-1.1 倍，旨在更好地反映实时荧光信号的变化。 CT 值CT 值，即循环阈值，在荧光曲线与阈值线的交点位置对应的循环数。这个值反映了每个 PCR 反应管内所需的扩增循环数，以达到设定的荧光域值。研究显示，各模板的 CT 值与其起始拷贝数的对数之间存在线性关系：起始拷贝数越高，CT 值越小，反之亦然。通过使用已知起始拷贝数的标准品，可以绘制出一条标准曲线。在这条曲线上，横坐标是起始拷贝数的对数，纵坐标是 CT 值。只需获得未知样品的 CT 值，就可以从标准曲线上得到该样品的起始拷贝数。 归一数据的归一化是过程中的另一重要步骤，包含两个主要方法： 荧光曲线减去基线平均值：这一操作可以去除背景信号的影响，增强信号的对比度。 荧光曲线除以最大值（或平台期的平均值）：这一方法有助于标准化信号强度，使得不同样本数据之间可比较。 扩增曲线在 PCR 过程中，以循环数为横坐标，实时荧光强度为纵坐标所绘制的曲线称为扩增曲线。评估扩增曲线是否良好的指标主要有以下几个方面： 曲线拐点清楚：尤其在低浓度样本的指数期，应表现明显。良好的扩增曲线在基线区域平坦，无明显上扬现象，确保低浓度样本的指数期凸显。 曲线指数期斜率与扩增效率成正比：斜率越大，扩增效率越高，意味着样本中的目标序列被快速且有效地产生。 标准的基线应保持平直或略微下降：无明显的上扬趋势，表示反应过程稳定且没有干扰。 各管的扩增曲线平行性好：表明各反应管的扩增效率相近，有助于获得可靠的一致性结果。 熔解曲线 (-RFUdT)熔解曲线分析是在对 PCR 产物进行加热时，随着温度升高，双链扩增产物逐渐解链，从而导致荧光强度下降的过程。在达到某一特定温度时，大量的产物会快速解链，荧光信号将急剧下降。不同 PCR 产物的 Tm（熔化温度）不同，因此不同产物的荧光信号发生迅速下降的温度也会有所不同。通过熔解曲线，可以有效鉴定 PCR 产品的特异性，确认扩增的结果是否可靠。 拷贝数拷贝数用单位 copiesml 表示，常用于生化检测中检查 DNA 复制状况。这里： copies 是 copy 的复数形式，表示从原始 DNA 复制出新 DNA 的个体副本。 ml 则是每毫升的度量。 结合起来，copiesml 表示每毫升待测样本中 DNA 的复制数量，这一参数对于评估样本中的 DNA 含量和扩增效率至关重要。","categories":["3.软件","PCR"]},{"title":"Obsidian在ios端利用git 同步","path":"/2024/12/11/0-平台-服务器-Obsidian在ios端利用git-同步/","content":"在 Apple Store 下载并安装 iSH 应用程序。iSH 是一个基于 Alpine Linux 的终端模拟器，允许用户在 iOS 设备上使用 Linux 环境。 打开已安装的 iSH 应用程序，并按照以下步骤执行命令： 安装 GitGit 是一个广泛使用的版本控制系统，它帮助开发者管理和跟踪文件的变化。在终端中输入以下命令以安装 Git： apk add git 这条命令会从 Alpine 软件包管理器（apk）中下载安装 Git。 创建名为 “obsidian” 的新文件夹通过下面的命令，可以在当前用户的主目录下创建一个新的文件夹，这个文件夹将用于存储与 Obsidian 相关的数据： cd ~ mkdir obsidian 这里的 cd ~ 切换到主目录，mkdir obsidian 则创建一个名为 “obsidian” 的新文件夹。 装载本地的 obsidian 文件夹到 iSH输入以下命令会打开手机的文件管理器，让你选择本地存储中的 obsidian 文件夹。选择后点击完成，这一步骤确保 Obsidian 软件中的 “math” 文件夹与 iSH 上的 obsidian 文件夹相互连接。这样，在 Obsidian 中对 “math” 文件夹的任何修改都将及时同步到 iSH 环境中： mount -t ios . obsidian 进入 obsidian 文件夹输入以下命令切换到刚才创建的 obsidian 文件夹中： cd ~/obsidian 这一步使你可以在 iSH 中查看和操作该文件夹内的文件。 克隆 Git 仓库到 obsidian 目录将你的 Git 仓库克隆到 obsidian 文件夹中，输入以下命令并在提示时输入你的 GitHub 账号和个人访问密钥（personal access token）： git clone https://xxxxxx.git 确保将 https://xxxxxx.git 替换为你的实际 Git 仓库 URL。成功后，就能看到仓库中的所有文件在 obsidian 文件夹里。 打开 Obsidian 并配置 Git 账号密码启动 Obsidian 后，将看到你之前克隆下来的仓库文件。接下来，打开 Obsidian 的 Git 设置，并输入你的 Git 账号和密码。这一步是为了确保任何在 Obsidian 中进行的更改都能通过 Git 进行版本控制及同步，从而更好地管理工作。","tags":["clippings"],"categories":["0.平台","服务器"]},{"title":"Git 同步时报错","path":"/2024/12/11/3-软件-Git-Git-同步时报错/","content":"Git 同步时报错在使用 Git 进行同步时，有时会遇到这样的错误信息：“error: RPC failed; curl 92 HTTP2 stream 7 was not closed cleanly: CANCEL (err 8)”。这一错误通常意味着存在网络连接问题、Git 配置未优化，或是 HTTP2 协议支持不足。为了解决这个问题，以下是详尽的解决方案及步骤。 1. 检查网络环境这个错误往往源于网络的不稳定性，因此首先应确保网络连接畅通。 确保网络稳定：观察连接状态，检查是否有消失的网络信号，是否出现了频繁的断线重连。如果在使用无线网络时，尝试靠近路由器或者切换到有线连接。 使用代理：在一些网络环境中，尤其是公司网络或公共 Wi-Fi，可能由于防火墙或其他限制导致连接问题。在这种情况下，可以尝试通过代理来进行连接。执行以下命令来配置 HTTP 或 SOCKS 代理： git config --global http.proxy http://代理地址:端口git config --global https.proxy http://代理地址:端口 例如，如果你的代理地址是 proxy.com，端口是 8080，那么可以这样设定： git config --global http.proxy http://proxy.com:8080git config --global https.proxy http://proxy.com:8080 使用 VPN：如果在中国大陆访问 GitHub 等国外网站时常遇到网络问题，考虑使用 VPN 工具来提高连接稳定性。 2. 禁用 HTTP2 协议某些版本的 Git 对 HTTP2 的支持可能并不稳定，可以尝试强制使用 HTTP1.1 的协议： git config --global http.version HTTP/1.1 这种设置通常可以帮助解决因为协议不兼容引起的错误。 3. 调整 Git 缓存设置在传输大文件时，缓冲区过小可能会导致错误。可以通过增加 Git 的缓冲区设置来解决： git config --global http.postBuffer 524288000 # 设置缓冲区为500MBgit config --global http.maxRequestBuffer 524288000 # 设置请求缓冲区git config --global core.compression 0 # 禁用压缩 例如，设置 http.postBuffer 为 500MB 使得大型文件的上传更为顺畅。 4. 降低并发请求如果请求数过多，可能会导致服务器无法处理。通过限制同时请求的数量，可以减少服务器压力，缓解错误： git config --global http.maxRequests 10 该命令将最大请求数限制为 10。 5. 检查 Git 和 cURL 版本确保你的 Git 和 cURL 版本是最新的。老旧的版本可能存在未修复的缺陷，导致连接问题。 git --versioncurl --version 若发现版本较旧，建议通过官方网站或包管理工具进行升级。例如，在 Ubuntu 系统上，你可以使用： sudo apt updatesudo apt install git curl 6. 克隆单个分支在同步大的版本库时，下载所有内容可能会导致错误。相反，尝试只克隆需要的分支，这样可以减少传输量： git clone --single-branch --branch 分支名 仓库地址 在此命令中，只需替换 分支名 和 仓库地址 为目标分支名和仓库链接。 7. 验证远程仓库地址确保你配置的远程仓库地址是正确且可访问的。可以使用以下命令查看当前配置的远程地址： git remote -v 如果发现地址错误，可以通过以下命令进行更新： git remote set-url origin 正确的地址 确保 正确的地址 是你要访问的实际仓库地址。 如果尝试以上方法仍未解决问题，建议详细描述你的应用环境，包括操作系统类型、Git 版本、网络配置等，以便更有效地进行问题排查。","categories":["3.软件","Git"]},{"title":"GDB调试","path":"/2024/12/04/1-语言-调试输出-GDB调试/","content":"GDB 调试指南GDB（GNU Debugger）是一种强大的调试工具，可以帮助开发人员逐步检查程序运行过程中的行为。使用 GDB，您可以设置断点，单步执行代码，并查看变量的值，确保程序按照预期运行。 重新编译程序在使用 GDB 调试之前，程序必须以调试模式重新编译。这意味着需要在编译命令中添加 -g 选项。例如： gcc -g main.c -o main.out 执行上述命令后，会生成一个可以使用 GDB 进行调试的可执行文件 main.out。确保不要删除源代码文件 main.c，因为 GDB 在运行时需要源代码来显示相关的行号和变量信息。如若删除，GDB 将无法正确执行断点和单步调试。 启动调试开始调试 main.out 文件可以使用以下命令： gdb ./main.out 或者： gdb main.out 一旦进入 GDB 环境，可以使用 list 或其简写 l 命令列出当前调试程序的源代码。默认情况下，系统会显示当前程序的前 10 行代码。按回车键可以显示接下来的代码行。 断点与单步调试要启动程序并设置第一个断点，可以使用 start 命令。当程序启动时，GDB 会在 main() 函数的默认断点处暂停。例如，它会反馈如下信息： 默认断点1在main()处，具体行数为本文件的第13行 假设第 13 行的代码是： int a = 5; 要查看内存中变量的值，可以使用 print a 或其简写 p a。通过这个命令，您可以检查变量 a 的当前值。由于 int a = 5; 这一指令尚未执行，因此在这之前， a 的值将是未初始化状态下的默认值。 在单步执行中，有几个重要的命令： n 或 next: 执行下一条指令。这个命令仅推进到下一行，不进入调用的函数。 s 或 step: 执行当前行并进入函数内部。如果当前行是一个函数调用，它会让您进入该函数。 例如，当程序运行到一个函数时，使用 step 命令后，GDB 会显示当前被调用的函数的参数已被赋值，并且会定位到参数对应行。 查看函数调用堆栈使用 bt 命令可以查看当前函数的调用堆栈。每个函数都有自己的编号和当前执行行。例如，可能会得到如下输出： 编号0 change 函数 定位到第6行编号1 main函数 定位到第15行 这里的编号 0 表示您当前在 change 函数，编号 1 表示您可以跳转回 main 函数。 f num: 切换到指定的堆栈帧。例如，通过输入 f 1，您可以返回到 main 函数并查看其位置。 退出调试完成调试后，输入 q 可以安全退出 GDB。 使用 GDB 调试的案例解析在调试过程中，您可能会使用诸如取地址符 和十六进制符号 0x 等特性。例如，如果有如下变量赋值： int a = b; // 这将存储b的地址 在命令行调试中，您可能看到下列内存地址的输出来反馈参数的值： a = 0xbffff064 // 变量a的地址b = 0xbffff068 // 变量b的地址 通过如下语句，将内存地址中的值赋给变量： int temp = *a; // temp现在为5，即a指向的值int temp = a; // temp现在为指向b的内存地址0xbffff064 使用 x 命令查看内存内容也是一种常见操作。例如，命令： x/3d 0x7fffffffde14 该命令将输出内存地址 0x7fffffffde14 处的连续 3 个值，并以十进制格式展示。 通过这些命令和操作，您可以深入了解程序的内部运作，提高调试效率，确保代码的正确性与稳定性。 段错误借助 GDB 查找方法在调试程序时， segment fault（段错误）是常见且令人沮丧的问题之一。我们可以使用 gdb（GNU 调试器）来帮助定位和解决这些问题。以下是使用 gdb 和 ulimit 命令的详细指南，可以帮助您发现和解决段错误。 使用 ulimit 设置资源限制ulimit 命令在 Unix 和 Linux 系统中用于控制 shell 启动进程所使用的资源。理解如何设置和查看这些限制至关重要，因为某些资源限制可能会导致程序意外崩溃或无法正常运行。 资源限制选项 -H：设置硬资源限制。硬限制是系统允许的最大值，只有超级用户可以修改。 -S：设置软资源限制。软限制是可以随时更改的，用户可以随意调整以适应其需求。 -a：显示当前所有资源的限制，包括文件描述符数量、堆栈大小等。 -c size：设置 core 文件（程序崩溃时生成的转储文件）的最大值，单位为 blocks。核心转储文件对于调试段错误非常有用。 -d size：设置数据段的最大值，单位为 kbytes。如果数据段超出此限制，程序可能会因内存不足而发生段错误。 -f size：设置创建文件的最大值，单位为 blocks。这可以防止程序生成过多或过大的临时文件。 -l size：设置可以在内存中锁定进程的最大值，单位为 kbytes。过高的锁定内存可能会消耗系统资源。 -m size：设置可以使用的常驻内存的最大值，单位为 kbytes。这有助于限制程序的内存使用。 -n size：设置内核可以同时打开的文件描述符的最大数量，单位为 n。如果此限制过低，程序可能无法开启新的文件或套接字。 -p size：设置管道缓冲区的最大值，单位为 kbytes。缓冲区限制可以影响输入输出的性能。 -s size：设置堆栈大小的最大限制，单位为 kbytes。若堆栈大小不够，可能会导致栈溢出。 -t size：设置 CPU 使用时间的最大限制，单位为 seconds。过高的使用时间可以影响系统性能。 -v size：设置虚拟内存的最大值，单位为 kbytes。设置虚拟内存的限制可以帮助避免内存溢出。 -u 程序数目：限制用户可开启的程序最大数目。这个限制取决于用户的机器和特性。 查看和设置资源限制要查看当前所有的资源限制，可以执行： ulimit -a 这将列出所有相关设置及其当前值，比如： core file size (blocks -c) unlimiteddata seg size (kbytes -d) 2097152file size (blocks -f) unlimited... 如果您希望程序生成核心文件，从而方便后续调试，可以设置核心文件的最大值为无限制： ulimit -c unlimited 再次执行 ulimit -a 确认设置已经生效。 使用 GDB 调试程序当程序发生段错误时，生成的核心转储文件至关重要。使用 gdb 工具，我们可以方便地分析该文件并寻找导致崩溃的原因。 打开 gdb首先，使用如下命令打开您的可执行文件和生成的核心文件： gdb xxx core 其中，xxx 是您的可执行程序的名称，core 是生成的核心转储文件。成功启动后，gdb 会加载相关信息。 查看段错误要查看导致段错误的具体位置，可以使用以下命令： bt bt 表示 “backtrace”，这个命令会显示函数调用栈的详细信息。在调试过程中，这个信息可以帮助您确定哪一部分代码出问题了。 列出出错位置代码如果您想查看出错的具体源代码位置，可以使用： list 这个命令会显示当前所在函数的源码，帮助您快速定位问题所在。 通过结合使用 ulimit 和 gdb，您将能够更深入地了解并解决段错误，使您的程序更加稳定和可靠。 GDB 简易调试方法GDB 可以对程序进行断点调试，单步调试，如果用 gdb 调试，需要对程序重新编译，格式为: gcc –gmain.c –o main.out 这样生成的 main.out 才能用 gdb 调试。 需要注意的是，在调试的时候不能删除原代码文件，即 main.c ，如果将 main.c 删除了，gdb 依然不支持断点、单步调试。 用 gdb 调试程序格式： gdb ./main.out 或gdb main.out 列出当前调试程序的部分（前 10 行）源代码 list 或者 l 再按一次回车（默认执行上一次命令），继续列出下面的源代码 单步调试命令： start 执行后显示：默认断点 1 在 main()处，断点处指令为： int a=5; 查看内存中变量的值 print a 简写 p a 回车显示 a 的值 因为 int a=5; 指令还没有执行完毕，所以 a 为编译器给的默认值。 下一条指令 n //n----next 执行一行源代码并进入函数内部 s //s----step 当前被调用函数将实参赋于形参，并定位 查看函数堆栈 bt 编号 0 change 函数 定位到第 6 行 编号 1 main 函数 定位到第 15 行 编号 0 在最上层，所以当前在 change 函数中 f 编号可以定位到哪一层函数 f(frame)切换调用的上下文，进入相应的栈里，使用该命令可以打印栈层编号，当前的函数名，函数参数值，函数所在的文件及行号，函数执行到的语句等等； f 1 进入到编号 1 的函数中，即 main 函数 并定位到 15 行的那条语句 q 退出调试 常用的 GDB 指令常见断点设置与删除命令 命令格式 作用 break + 设置断点的行号 用于在程序中对应行设置断点 tbreak + 行号或函数名 设置临时断点，到达后被自动清除 break + filename + 行号 用于在指定文件的对应行设置断点 break + 0x… 用于在内存某一位置处暂停 break + 行号 + if + 条件 用于设置条件断点，在循环中使用非常方便 info breakpoints/watchpoints 查看断点、观察点的情况 clear + 要清除断点的行号 用于清除对应行的断点 delete + 要清除断点的编号 清除断点和自动显示的表达式（区别：clear 提示行号，delete 提示编号） disable + 断点编号 让所有断点暂时失效（多个编号可用空格分隔） enable + 断点编号 与 disable 相反，使断点重新生效 awatch + 变量 设置观察点，变量被读或写时程序暂停 rwatch + 变量 设置观察点，变量被读时程序暂停 watch + 变量 同 awatch 数据相关命令 命令格式 作用 display + 表达式 显示表达式的值（程序到断点时自动显示） info display 显示当前所有需要显示的表达式情况 delete + display 编号 删除某个要显示的表达式 disable + display 编号 使某个要显示的表达式暂时无效 enable + display 编号 恢复 disable display 命令失效的表达式 undisplay + display 编号 结束某个表达式值的显示 whatis + 编号 查看某个表达式的数据类型 print（p）+ 变量或表达式 打印变量或表达式的值 set + 变量 = 变量值 改变程序中某个变量的值 运行环境相关命令 命令格式 作用 set args 设置运行参数 show args 显示运行参数 set width + 数目 设置 GDB 的行宽 cd + 工作目录 切换工作目录 run 程序开始执行 step（s） 进入式单步执行（进入子函数） next（n） 非进入式单步执行（不进入子函数） finish 一直运行到函数返回 until + 行数 运行到指定行号 continue（c） 执行到下一个断点或程序结束 return 返回值 改变程序流程，结束当前函数并返回指定值 call + 函数 在当前位置执行指定的函数 堆栈相关命令 命令格式 作用 back 或 bt 打印栈帧指针（可指定要打印的个数） frame 打印栈帧 info reg 查看寄存器使用情况 info stack 查看堆栈情况 up 跳到上一层函数 down 跳到下一层函数（与 up 相对）","categories":["1.语言","调试输出"]},{"title":"运算符优先级","path":"/2024/12/04/1-语言-C语言-运算符优先级/","content":"优先级C 语言中，运算符的运算优先级共分为 15 级。1 级最高，15 级最低。 在表达式中，优先级较高的先于优先级较低的进行运算。而在一个运算量两侧的运算符 优先级相同时，则按运算符的结合性所规定的结合方向处理。 结合性C 语言中各运算符的结合性分为两种，即左结合性(自左至右)和右结合性(自右至左)。例如算术运算符的结合性是自左至右，即先左后右。如有表达式 x-y+z 则 y 应先与”-“号结合，执行 x-y 运算，然后再执行+z 的运算。这种自左至右的结合 方向就称为”左结合性”。而自右至左的结合方向称为”右结合性”。最典型的右结合 性运算符是赋值运算符。如 xyz,由于””的右结合性，应先执行 yz 再执行 x(yz)运算。C 语言运算符中有不少为右结合性，应注意区别，以避免理解错误。 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 所有的优先级中，只有三个优先级是从右至左结合的，它们是单目运算符、条件运算符、赋值运算符。其它的都是从左至右结合。 具有最高优先级的其实并不算是真正的运算符，它们算是一类特殊的操作。()是与函数相关，[]与数组相关，而-及.是取结构成员。 其次是单目运算符，所有的单目运算符具有相同的优先级，因此在我认为的 真正的运算符中它们具有最高的优先级，又由于它们都是从右至左结合的，因此p++与(p++)等效是毫无疑问的。 另外在 C 语言里，没有前置后置之分，因为++ – 是右结合所以右侧优先运算，表现为 “操作数后置优先级比较高” 的假象，前置和后置的区分是因为运算符重载而后加入 C++的 接下来是算术运算符，*、/、% 的优先级当然比 +、- 高了。移位运算符紧随其后。 其次的关系运算符中， = = 要比 == != 高一个级别，不大好理解。 所有的逻辑操作符都具有不同的优先级(单目运算符除外，!和~) 逻辑位操作符的”与”比”或”高，而”异或”则在它们之间。 跟在其后的 比 || 高。 接下来的是条件运算符，赋值运算符及逗号运算符。 在 C 语言中，只有 4 个运算符规定了运算方向，它们是 、| |、条件运算符及赋值运算符。 、| | 都是先计算左边表达式的值，当左边表达式的值能确定整个表达式的值时，就不再计算右边表达式的值。如 a = 0 b; 运算符的左边位 0，则右边表达式 b 就不再判断。 在条件运算符中。如 a?b:c;先判断 a 的值，再根据 a 的值对 b 或 c 之中的一个进行求值。 赋值表达式则规定先对右边的表达式求值，因此使 a = b = c = 6;成为可能。 口诀注释- 圆方括号、箭头一句号， 自增自减非反负、针强地址长度，- 乘除，加减，再移位，小等大等、等等不等，- 八位与，七位异，六位或，五与，四或，三疑，二赋，一真逗。- 圆方括号、箭头一句号指的是第 15 级的运算符。其中圆方括号很明显()、[]，箭头 指的是指向结构体成员运算符-，句号 指的是结构体成员运算符. ;- 自增自减非反负、针强地址长度指的是第 14 级的运算符。其中 非 指的是逻辑运算符!，反 指的是按位取反运算符~，负 指的是负号运算符-，针 指的是指针运算符*，强 指的是强制类型转换运算符，地址 指的是地址运算符，长度 指的是长度运算符sizeof ;- 乘除，加减，再移位移位指的是左移运算符和右移运算符，其中除法还包括了 取余运算符%;- 小等大等、等等不等 指的是第 10 级到第 9 级的运算符:、=、和=，等等指的是等于运算符==，不等指的是不等于运算符!=- 八位与，七位异，六位或其中 八位与 指的是第 8 级的 按位与 运算符，七位异 指的是第 7 级的按位异或运算符^，六位或 指的是第 6 级的按位或运算符|;- 五与，四或指的是第 5 级、第 4 级的逻辑与运算符和逻辑或运算符||;- 三疑，二赋，一真逗指的是第 3 级到第 1 级的运算符。其中，三疑指的是条件运算符?: (三有双重含义:即指优先级别是三，它的运算符类型也是三目，疑也取?之意)，二赋 指的是赋值运算符=、+=、-=、*=、/=、%=、=、=、=、^=和|= ，一真逗 指的是第 1 级的，运算符，真字只是为了语句需要罢了。 应用举例 赋值运算符: a=5; a=b=0; 第一个赋值语句将整数 5 赋给变量 a。第二个赋值语句同时把 0 赋给两个变量 b 和 a。这是因为赋值运算从右向左进行，首先执行 b=0，然后将 b 的值（0）赋给 a。因此，最终 a 和 b 的值都是 0。 复合赋值运算符: a=1; a+=3; 上述复合赋值可以理解为：首先将 1 赋给 a，然后执行 a+=3，它相当于 a=a+3。所以，3 加到原本的 1 上，最终结果为 4。因此，a 的最终值是 4。 算术运算符: Area=Height*Width; num=num1+num2/num3-num4; 第一个赋值语句将 Height 和 Width 的乘积赋给变量 Area。这用于计算矩形的面积，例如当 Height10，Width5 时，Area50。第二个赋值语句中，首先计算 num2 与 num3 的除法，之后将结果与 num1 相加，最后减去 num4。例如，如果 num1=10，num2=20，num3=5，num4=3，那么计算顺序依次是 20/5=4，然后 10+4-3=11，所以 num 的值为 11。 逻辑运算符: a=1, b=1; a||b-1; 这里 a=1 表示逻辑真，因此整个表达式 a || b-1 的结果也是逻辑真。在逻辑运算中，如果一个运算符的某个操作数为真，后面的部分就不再计算。例如，无论 b-1 的结果如何，总体表达式都为真。 关系运算符: if(a0)... 这个语句检查 a 是否大于 0。如果条件为真（即 a 的值确实大于 0），那么将执行 if 块内的内容；如果条件为假，则程序将跳过这个块。这通常用于控制程序的执行流程。 条件运算符: a=(b0)?b:-b; 运算中，如果 b 大于 0，则将 b 的值赋给 a；如果 b 不大于 0，则将 -b（即 b 的相反数）赋给 a。这个运算符的作用类似于获取 b 的绝对值，具体解释为当 b 为 -3 时，a 会得到 3。 逗号运算符: b=2, c=7, d=5; a=(++b, c--, d+3); 这里有三个表达式用逗号分隔。逗号运算符从左到右依次计算每一个表达式，但整个表达式的值等于最后一个表达式的值。在这个例子中，++b 和 c-- 的结果虽然被计算，但并没有被使用，最后 d+3 的计算结果是 8，因此 a=8。 位逻辑运算符 位逻辑运算符包括： （位与） |（位或） ^（位异或） ~（位取反） 以操作数 12 为例，数字 12 在二进制表示为 1100。位运算符将数字看作二进制位进行操作。比如： 表达式 1015 表示 1010 1111，返回值为 10，因为二进制的 1010 和 1111 在每一位上都进行了与运算，结果是 1010。 表达式 10|15 表示 1010 | 1111，返回值为 15，任何位中有值为 1 的都为真，因此结果为 1111。 表达式 10^15 表示 1010 ^ 1111，返回值为 5，只有在对应位不同时该位才为真，结果为 0101。 表达式 ~10 表示 ~1010，返回值为 -11，因为其按位取反，结果为 0101，在使用补码表示时为 -11。","categories":["1.语言","C语言"]},{"title":"DB9定义","path":"/2024/12/04/2-通讯协议-串口-DB9和DB25引脚定义/","content":"","categories":["2.通讯协议","串口"]},{"title":"Modbus","path":"/2024/12/04/2-通讯协议-Modbus-Modbus/","content":"MODBUS 是一种单主站的主从通信模式。MODBUS 网络上只能有一个主站存在，主站在 MODBUS 网络上没有地址，从站的地址范围为 0 - 247，其中 0 为广播地址，从站的实际地址范围为 1 - 247。 MODBUS 协议可以通过各种传输方式传播，如 RS232C、RS485、光纤、无线电等。 MODBUS 具有两种串行传输模式，ASCII 和 RTU。它们定义了数据如何打包、解码的不同方式。支持 MODBUS 协议的设备一般都支持 RTU 格式。通信双方必须同时支持上述模式中的一种。 MODBUS 的通讯规范： 起始符 + 设备地址 + 功能代码 + 数据 + 校验和 + 结束符 通讯格式通讯格式设置举例：9600，o，8，1 即： 波特率为 9600； 校验方式为奇校验； 数据位为八位； 停止位为一位； 波特率波特率是每秒钟传输的数据位数。常用的波特率数值有：2400、4800、9600、19200、38400、57600、115200； 其值越大，通讯传输速度越高，同时波特率设置的越大，要承担的通讯失败风险越大。 波特率设为 9600，即一秒钟之内能够传输 9600 个”0”或是”1”，它决定了通讯的数据传输速度。 数据位计算机处理的语言是”0”和”1”组合而成的信息，即机器语言 01000001 ，01000010 ，01000011 ，01000100 ，01000101，01000110 A B C D E F 上面一组机器码分别代表的字符是 A，B，C，D，E，F；如 A: 是用 01000001 表示，共八个”0”或”1”，即数据位为八位. 数据位的含义：是一个字符可以用多少个位的组合来表示；设置数据位后，我们就知道了数据长度，然后可以根据波特率(9600)计算出传输一个字符 A 需要多少时间。 停止位：知道一个字符何时传输结束。目前常用的停止位是一位与二位。 停止位是一个高电平(1)，当接收方接收到连续的高电平时，表示一个字符传输结束。 起始位是一个低电平(0),当接收方接收连续的低电平时，表示下一个字符的传输开始。 如果停止位可靠(1 位或是 2 位)，那么干扰造成低电平起始位假象的可能性就不大，所以不用设置起始位。 校验方式：在传输的数据中再加上一个校验位防止干扰。目前所用的校验方式为： 偶校验(even):简单表示为”e” ，保证总的 1 的个数是偶数； 如果一个字符中”1”的个数是奇数那么校验位就置为”1”； 如果一个字符中”1”的个数是偶数，那么校验位就置为 0； 奇校验(odd):简单表示为”o” ，保证总的”1”的个数是奇数； 如果一个字符中”1”的个数是偶数，那么校验位就置为 1； 如果一个字符中”1”的个数是奇数，那么校验位就置为 0； 无校验(none):简单表示为”n” ，没有校验位； 奇偶校验方式不可能完全校验一个字符发送是否正确。当只是”1”的位置改变了，”1”的个数还是奇数，虽然发送的是 A，接收到的是 B，但是奇校验还认为是正确的字符； 为了解决奇偶校验方式的上述缺陷，每种标准协议都会要求校验和计算，比如 MODBUS 通讯协议的 RTU 方式是 CRC 校验计算；MODBUS 通讯协议的 ASCII 方式是 LRC 校验计算； 奇偶校验：判断一个字符传输的是否正确； 校验和： 判断一组字符传输的是否正确； 终端电阻光从空气进入水面时，水面从反射回一些光线，这是因为空气与水的媒质不同。光进入不同的媒质时，会在临界点反射。 电信号传输也一样，在传输过程中如果传输末端阻抗突然减小甚至没有，信号就会在此产生反射，这种反射会造成传输线路数据混乱，所以加一个偏置电阻，人为地保持阻抗平衡，减弱信号反射对线路的影响","categories":["2.通讯协议","Modbus"]},{"title":"FreeModbus代码解析","path":"/2024/12/04/2-通讯协议-Modbus-FreeModbus代码解析/","content":"eMBInit 设置设备站号 设置函数接口 eMBRTUInit xMBPortSerialInit 设置打开串口的名称 serialInit 打开串口 设置串口属性（波特率、数据位、奇偶校验位等） 计算计时器计时时间 xMBPortTimersInit TimersInit（设置为单次触发、ms 级别） 设置为 RTU 模式 eMBState STATE_DISABLED eMBEnable pvMBFrameStartCur（函数指针指向 eMBRTUStart） eRcvState STATE_RX_INIT vMBPortSerialEnable( TRUE, FALSE );（设置为接收模式） vMBPortTimersEnable（开启定时器） 定时器中断事件（判断 eRcvState） STATE_RX_INIT 将 event 设置为 EV_READY STATE_RX_RCV 将 event 设置为 EV_FRAME_RECEIVED STATE_RX_ERROR 执行完中断事件，定时器关闭 eRcvState STATE_RX_IDLE eMBState STATE_ENABLED eMBPollxMBPortEventGet（判断事件） EV_READY EV_FRAME_RECEIVED peMBFrameReceiveCur（函数指针指向 eMBRTUReceive） 校验数据长度和 CRC 保存设备站号 保存待校验数据首地址和长度 检查设备站号是否相同 xMBPortEventPost 将等待队列里的事件 eEvent 设为 EV_EXECUTE EV_EXECUTE 执行操作并返回消息 EV_FRAME_SENT","categories":["2.通讯协议","Modbus"]},{"title":"健康","path":"/2024/12/04/4-其他-生活-健康/","content":"子时—胆经—23:00-1:00 丑时—肝经—1:00-3:00 寅时—肺经—3:00-5:00 卯时—大肠经—5:00-7:00 辰时—胃经—7:00-9:00 巳时—脾经—9:00-11:00 午时—心经—11:00-13:00 未时—小肠经—13:00-15:00 申时—膀胱经—15:00-17:00 酉时—肾经—17:00-19:00 戌时—心包经—19:00-21:00 亥时—三焦经—21:00-23:00","categories":["4.其他","生活"]},{"title":"论文下载方法","path":"/2024/12/04/3-软件-0杂项-论文下载方法/","content":"浙江省公共资源门户网址： https://zjisa.zjlib.cn/home/zy_home.jsp 登录后进入 知网数据库总站（含会议、博硕论文） 万方数据库本地镜像（含学位、会议论文）等模块下载 上海研发公共服务平台网址： https://lib.sgst.cn/ 登录后选择文献服务，基于万方数据 进入个人中心后签到赠送积分用于下载文献 其他浙江图书馆网址： https://www.zjlib.cn/ 上海图书馆网址： https://www.library.sh.cn/#/index 绍兴图书馆网址： https://www.sxlib.com/jypxwgzy/index.htm 贵州数字图书馆网址： https://www.gzlib.org/","categories":["3.软件","0杂项"]},{"title":"6. Git标签","path":"/2024/11/19/3-软件-Git-6-Git标签/","content":"标签在 Git 中，tag 是用于标记某个特定提交的名称。它类似于一个快照，可以用于标记版本、发布或重要的里程碑。Git 中有两种类型的 tag：轻量级标签和附注标签。 轻量级标签是一个简单的指向某个特定提交的引用，类似于一个分支，但不会随着新的提交而移动。创建轻量级标签的方法很简单，只需在命令行中输入 git tag tag-name 即可。例如，git tag v1.0 将创建一个名为 v1.0 的轻量级标签。 附注标签是一个包含标签名称、标签创建者、标签创建日期和标签说明的 Git 对象。它们是 Git 中最常用的标签类型，可以用于发布版本、重要的里程碑和其他重要的提交。创建附注标签的方法是使用 -a 标志和标签名称，然后输入标签说明。例如，git tag -a v1.0 -m Release version 1.0 将创建一个名为 v1.0 的附注标签，并将其说明设置为 “Release version 1.0”。 标签可以使用 git push 命令推送到远程存储库中，以便在其他计算机上使用。例如，要将名为 v1.0 的标签推送到远程存储库，可以使用 git push origin v1.0 命令。 git tag #列出所有taggit tag [tag] #新建一个tag在当前commitgit tag [tag] [commit] #新建一个tag在指定commitgit tag -d [tag] #删除本地taggit push origin [tag] #推送tag到远程git show [tag] #查看特定taggit checkout -b [branch] [tag] #新建一个分支，指向某个tag","categories":["3.软件","Git"]},{"title":"4. Git分支","path":"/2024/11/19/3-软件-Git-4-Git分支/","content":"分支Git 是一个流行的分布式版本控制系统，一般都是存在多个分支的，开发分支，回归测试分支以及主干分支等 在 Git 中，分支是指指向 Git 提交历史中某个特定提交的指针。 每个分支都包含在 Git 提交历史中的一系列提交，这些提交构成了分支的历史记录。 分支在 Git 中非常重要，因为它们允许多个开发人员同时在同一个代码库中工作，而不会相互干扰。 通过创建分支，每个开发人员都可以在自己的分支上进行工作，而不会影响其他人的工作。 这样，开发人员可以在不干扰其他人的情况下，独立地开发和测试新功能，最终将这些更改合并到主分支中。 在 Git 中，分支操作非常简单。以下是一些常用的 Git 分支操作： 创建分支要创建一个新分支，请使用以下命令： git branch branch-name 这将创建一个名为 branch-name 的新分支。 注意，此时仍然在当前分支上工作。 git checkout -b branch-name 新建一个分支，并且切换到新的分支 branch-name 查看分支要查看所有分支，请使用以下命令： git branch 这将列出所有分支，当前分支将用一个星号标记。 git branch -r 查看所有远程的分支 git branch -a 查看所有远程分支和本地分支 删除分支要删除一个分支，请使用以下命令： git branch -d branch-name 这将删除名为的分支。 注意，如果该分支包含未合并的更改，则必须使用 -D 选项而不是 -d 选项来强制删除该分支。 切换分支要切换到另一个分支，请使用以下命令： git checkout branch-name 这将使您从当前分支切换到名为 branch-name 的分支。 注意，需要在切换分支之前将所有更改提交或保存。 合并分支要将一个分支合并到另一个分支，请使用以下命令： git merge branch-name 将名为 branch-name 的分支合并到当前分支中。 注意，如果两个分支上都有对同一文件的更改，则可能会发生冲突。在这种情况下，需要手动解决冲突并提交更改。 git merge –no-ff origindev 在当前分支上合并远程分支 dev git merge –abort 终止本次 merge，并回到 merge 前的状态 以上是一些常用的 Git 分支操作。使用这些操作，您可以轻松地创建、切换、合并和删除分支。这些操作使多人协作变得更加容易，因为每个开发人员都可以在自己的分支上进行工作，并将更改合并到主分支中。在实际开发中，分支操作是非常重要的，最好能够熟练掌握并运用这些操作","categories":["3.软件","Git"]},{"title":"5. Git撤销或回退","path":"/2024/11/19/3-软件-Git-5-Git撤销或回退/","content":"撤销或回退在 Git 中，撤销和回退是指撤销或回退先前的提交或更改。 简单介绍下 Git 中的撤销和回退操作，以及如何使用它们来管理代码库。 可以把版本库上的提交回退到暂存区，修改记录保留 git reset –-soft [] 可以把版本库上的提交回退到工作区，修改记录保留 git reset –-mixed [] 可以把版本库上的提交彻底回退，修改的记录全部 revert。git reset –-hard reset 和 revert 的区别git reset 和 git revert 的主要区别在于它们对历史记录的处理方式。git reset 会删除历史记录并永久删除更改，而 git revert 会创建一个新的提交来撤销更改并保留历史记录。 git reset 命令会将 HEAD 指针指向指定的 commit，并将暂存区和工作目录恢复到该 commit 的状态。这意味着在执行 git reset 后，之前的更改将不再存在于工作目录和暂存区中。如果您希望永久删除一些更改并且不再需要它们，可以使用 git reset。 git revert 命令会创建一个新的提交来撤销指定的提交。这意味着在执行 git revert 后，之前的更改仍然存在于工作目录和暂存区中，并且您需要提交一个新的撤销提交。如果您想要保留更改历史记录并且不想永久删除更改，可以使用 git revert。 获取 IDgit log 获取到想要回退的 commit_id 撤销回退未提交的更改**(add 之后，commit 之前)** 要撤销未提交的更改，请使用以下命令： git checkout file-name 将名为 file-name 的文件恢复到上一个提交的状态。 本地本次的更改也不再保存，恢复到上一个提交 (commit) 的状态 git reset HEAD --file 回退暂存区里的某个文件，回退到当前版本工作区状态 保存工作区的更改，只是撤销 git add 这一步操作 git checkout . 将所有文件恢复到最新提交的状态。请注意，此操作将删除所有未提交的更改。 撤销回退上一个提交**(commit 之后，push 之前)** 撤销上一个提交 git reset HEAD~1 将 HEAD 指针移动到上一个提交。 工作区保留先前的更改，需要重新添加到暂存区 (git add) 回退到上一个提交 git reset --hard HEAD~1 将 HEAD 指针和工作树都重置为上一个提交的状态。 请注意，此操作将删除所有未提交 (commit) 的更改。 撤销回退到特定的提交**(push 之后)** 撤销到特定版本 git revert commit_id 这将创建一个新的提交，该提交撤销名为 commit-hash 的提交所做的更改。 本次撤销操作也会作为一次提交 (push) 进行保存 回退到特定版本 git reset --hard commit_id 将 HEAD 指针和工作树都重置为名为 commit-hash 的提交的状态。 请注意，此操作将删除所有未提交的更改。 回退完成后，git push -f 强制提交","categories":["3.软件","Git"]},{"title":"通讯备注","path":"/2024/11/19/2-通讯协议-其他-通讯备注/","content":"传输方式需要注意传输方式与通讯协议两个概念 485 通讯，232 通讯，这讲的是采用何种传输方式。既然是传输方式，重要就是“传输”两字，不管是 232 还是 485，只是起到传输作用，可以传输 MODBUS 通讯协议信息，也可以传输其他通讯协议信息 MODBUS 通信标准协议可以通过各种传输方式传播，如 232、485 等。工业通讯协议有 modbus,interbus,canbus 等，modbus 分 RTU 和 ASCII，interbus 是串行通讯，是传感器调节器总线系统。canbus 是 real-time 数据总线。 终端电阻光从空气进入水面时，水面从反射回一些光线，这是因为空气与水的媒质不同。光进入不同的媒质时，会在临界点反射。 电信号传输也一样，在传输过程中如果传输末端阻抗突然减小甚至没有，信号就会在此产生反射，这种反射会造成传输线路数据混乱，所以加一个偏置电阻，人为地保持阻抗平衡，减弱信号反射对线路的影响。 波特率波特率是每秒钟传输的数据位数；什么是位数呢？计算机处理的语言是”0”和”1”组合而成的信息，即机器语言。一个”0”或是一个”1”就是一个位； 如果把波特率设为 9600，即一秒钟之内能够传输 9600 个”0”或是”1”，它决定了通讯的数据传输速度。 常用的波特率数值有：2400、4800、9600、19200、38400、57600、115200；其值越大，通讯传输速度越高，那么是不是把波特率的数值设置的越大越好呢？当然不是，它要根据现场传输条件来决定，波特率设置的越大，要承担的通讯失败风险越大。 数据位前面说过，计算机处理的语言是”0”和”1”组合而成的信息，即机器语言。01000001 ，01000010 ，01000011 ，01000100 ，01000101，01000110 。上面一组机器码分别代表的字符是 A，B，C，D，E，F；如 A: 是用 01000001 表示，共八个”0”或”1”，即数据位为八位；数据位的含义：是一个字符可以用多少个位的组合来表示。 设置数据位后，我们就知道了数据长度，然后可以根据波特率(9600)计算出传输一个字符 A 需要多少时间。如果数据位设为 8,则：896000.00083 秒即传输一个字符”A”需要 0.83 毫秒的时间（这不是正确的计算，原因在停止位的解释中再论述。） 定义一个标准，方便通讯双方分析。 合法的数据位值：4、5、6、7、8，目前常用的数据位是 8 位与 7 位。 停止位 设置了数据位，就可以正常通讯了吗？不是。接收方何时才知道一个字符传输结束了，这就需要一个停止位，有停止位当然还需要一个起始位来告诉接收方一个字符的传输开始。目前常用的停止位是一位与二位。 还有一个问题，为什么在通讯格式中不用设置起始位？停止位是一个高电平(1)，当接收方接收到连续的高电平时，表示一个字符传输结束。 起始位是一个低电平(0),当接收方接收连续的低电平时，表示下一个字符的传输开始。如果停止位可靠(1 位或是 2 位)，那么干扰造成低电平起始位假象的可能性就不大，所以不用设置起始位。 假如设置停止位为 2，则一个起始位，两个停止位，8 个数据位，总位数为 11。1196000.0011 秒，即传输一个字符”A”需要 1.1 毫秒的时间（这还不是正确的计算，原因在校验方式的解释中再论述。） 校验方式如果抗干扰处理的不理想，在通讯传输过程中，”0”可能会变成”1”，或是将”1”干扰成”0”，造成传输错误。干扰是消除不了的，提高抗干扰能力也只是提高而已，并不能完全防止干扰。所以因为干扰造成的传输错误一定会发生。接收方如何知道接收到字符是否正确呢？解决方式就是加上一个校验，即在传输的数据中再加上一个校验位。 目前所用的校验方式为： 偶校验(even):简单表示为”e” ； 偶校验：如果一个字符中”1”的个数是奇数那么校验位就置为”1”；如果一个字符中”1”的个数是偶数，那么校验位就置为”0”；从而保证总的 1 的个数是偶数；比如设置数据位为 8 位，字符”A”是：0100 0001 其”1”的个数是 2 个，为偶数。那么校验位则为”0” 真正发送的信息为：0100 0001 0 奇校验(odd):简单表示为”o” ； 奇校验：如果一个字符中”1”的个数是偶数，那么校验位就置为 1；如果一个字符中”1”的个数是奇数，那么校验位就置为 0；从而保证总的”1”的个数是奇数；比如设置数据位为 8 位，字符”A”是：0100 0001 其”1”的个数是 2 个，为偶数。那么校验位则为”1” 真正发送的信息为：0100 0001 1 无校验(none):简单表示为”n” ； 无校验：没有校验位； 校验位的作用： 如果在传输过程中，由于干扰将某个”0”变成了”1”，偶校验时，”1” 的个数因为干扰变成奇数，奇校验时，”1” 的个数因为干扰变成偶数，接收方会返回一个奇偶校验错误信息给发送方。比如：当采用奇校验时，发送”A”字符的 0100 0001 1。当传输到接收方，由于干扰变成了 0100 0011 1。接收方接收到四个”1”，是偶数，不符合奇校验的”1”的个数为奇数的规定，所以返回一个奇偶校验错误信息给发送方。 注意：奇偶校验方式不可能完全校验一个字符发送是否正确。比如采用奇校验方式时，发送”A”字符时 0100 0001 1。由于干扰接收方接收到的是 0100 0010 1 (是”B”)。由于只是”1”的位置改变了，”1”的个数还是奇数，虽然发送的是 A，接收到的是 B，但是奇校验还认为是正确的字符；为了解决奇偶校验方式的上述缺陷，每种标准协议都会要求校验和计算，比如 MODBUS 通讯协议的 RTU 方式是 CRC 校验计算； MODBUS 通讯协议的 ASCII 方式是 LRC 校验计算； 有些朋友对于奇偶校验 与 校验和计算 这两个概念分不清楚。 奇偶校验：判断一个字符传输的是否正确； 校验和： 判断一组字符传输的是否正确； 通讯格式为：9600，o，8，2。一个起始位，八个数据位，一个校验位，两个停止位，总位数为 12。1296000.00125 秒，传输一个字符”A”需要 1.25 毫秒的时间；这个计算值才是最后的理论计算值。可以大致评估传输一组字符需要的时间。当然，选用无校验方式，计算传输方式不需要加上校验位。","categories":["2.通讯协议","其他"]},{"title":"滤波算法","path":"/2024/11/19/1-语言-语言结构-滤波算法/","content":"在进行数据收集的过程中，我们难免会遭遇到随机误差。这种误差源于随机干扰，其特征是在相同条件下测量同一物理量时，误差的大小和符号表现出无规律的变化，难以预测。例如，在监测温度时，某次测量记录 为 22.5°C，下一次则可能 是 22.7°C，后又回 到 22.4°C，这种波动看似偶然，但在多次测量后，我们可以发现其结果却能够符合某种统计规律。为了减少随机干扰导致的这些误差，硬件层面可以采用滤波技术，软件层面则可以利用特定的软件算法实现数字滤波。 数字滤波算法是系统测控算法中非常关键的一部分，其具有极强的实时性。利用数字滤波器克服随机干扰带来的误差，具体有以下几个显著优点： 成本效益高：数字滤波不需要额外的硬件设备，仅依赖一个计算过程，因此具有很高的可靠性，同时避免了阻抗匹配问题。例如，传统的模拟滤波器可能因频率不匹配而无法有效处理某些信号，但数字滤波器能够稳定地处理那些频率极低的信号，这是模拟设备所无法做到的。 共用性强：数字滤波使用软件实现，一台系统中多条输入通道可以共享同一个滤波程序，这无疑降低了整体的系统开支。例如，在一套气象监测系统中，对于风速、气温和湿度等多个传感器数据，可以仅用一个软件算法对所有信号进行滤波，避免了为每个信号配备独立硬件的高昂成本。 灵活性：通过简单地调整滤波器的程序或运算，我们可以方便地改变滤波特性。对于去除低频干扰和随机信号，这种灵活性尤为重要。例如，当我们察觉某一测量系统受到低频噪声影响时，只需更新程序设置，就能立刻优化信号处理，确保最终结果的准确性。 常用算法多样：在实际应用中，我们常用的数字滤波算法包括有限幅滤波法、中值滤波法、算术平均滤波法、加权平均滤波法和滑动平均滤波法等。这些算法各有特点，例如，中值滤波法在处理含有脉冲噪声的信号时表现尤为出色，而滑动平均滤波法则适合于平滑整体趋势。 然而，也需注意个别算法在获取有效采样值时可能需要对数据进行多次采样，这在采样速度较慢的情况下，可能会影响系统的实时性。在高速实时监测的场合，这种延迟可能导致数据失真或错过重要信息。因此，选择适合的滤波算法和设计合理的采样策略是提升数据收集准确性和及时性的关键因素。 递推平均滤波（滑动平均滤波法） 递推平均滤波，也称滑动平均滤波法，是一种通过平滑数据来抑制噪声和波动的技术。它将连续的 N 个采样值视作一个固定长度的队列，其中每采样到一个新数据，就会将其放入队尾，而队首的一个旧数据悄然被丢弃。这种先进先出的处理方式确保了每次计算平均值时，队列中总是最新的 N 个数据点。 滤波的过程如下：从队列中的 N 个数据进行算术平均运算，就能得到一个新的滤波结果。通常情况下，N 值设定为 12，这代表我们将过去的 12 个数据值结合在一起，为当前值提供更稳定的表现。 滤波算法对周期性干扰如电磁干扰和振动噪声具有良好的抑制作用，因其可以有效地平滑系统输出，尤其适用于高频振荡系统。例如，在测量温度时，如果传感器受到风速变化的影响，使用滑动平均法就能平滑温度值，使其波动减少，便于观察真实温度趋势。 然而，这种滤波方法的灵敏度相对较低，对偶然出现的脉冲性干扰，比如瞬间的电压尖峰或机械敲击等，滤波效果不佳。这意味着如果采样数据中出现突发性干扰，滤波结果可能不会得到有效的修正，因此在面临严重脉冲干扰的环境中，滑动平均法可能并不适用。 需要注意的是，滑动平均法可能会消耗一定的 RAM，因为它需要为 N 个数据分配存储空间。此外，使用环型队列的结构可以有效地管理缓冲区，使得在不断获得新数据的同时，保持存储效率。 C 语言代码如下： #define N 12char value_buf[N];char i = 0;char filter() char count; int sum = 0; value_buf[i++] = get_ad(); // 将新的采样值存入缓冲区 if (i == N) i = 0; // 循环缓冲区 for (count = 0; count N; count++) sum += value_buf[count]; // 计算当前缓冲区的和 return (char)(sum / N); // 返回平均值 这段代码定义了一个名为 filter 的函数，实现了递推平均滤波（滑动平均滤波法）。它使用一个长度为 N（定义为 12）的缓冲区 value_buf 来存储采样值。每当调用 filter 函数时，它会获得一个新的采样值，首先将其存入缓冲区，然后计算并返回该缓冲区内所有采样值的平均值，实现数据的平滑处理。如果 i 达到 N，代码会将 i 重设为 0，从而实现一个循环缓冲区的行为。 滑动平均滤波的方式设计了一次采样的处理策略，将当前采样值与过去的若干个采样值一起进行平均，这有效地过滤了原始数据中的极端变化。因此，在实际应用中，我们会预先为 N 个数据分配内存空间以供存储。每次新数据的加入会伴随最旧的数据被删除，从而始终保持最新的 N 个有效数据。这种设计确保了对数据的连续更新和高效管理，非常适合处理动态变化的信号。 程序代码的简单存取结构展示了如何不断更新和计算滑动平均值，示例如下： char value_buff[N];char i=0;char filter() char count; int sum=0; value_buff[i++] = get_data(); // 读取新数据 if(i == N) i = 0; // 实现环形队列 for(count = 0; count N; count++) sum += value_buff[count]; // 累加所有数据 return (char)(sum / N); // 返回平均值 整体来看，滑动平均滤波法是有效且简单的一种数据处理方法，尤其适合需要平滑输出结果的应用场景。 中位值平均滤波法中位值平均滤波法，也被称为防脉冲干扰平均滤波法，是一种有效的信号处理技术。它旨在从一组数据中去除异常值和脉冲干扰，提取更为稳定的平均值。 原理 操作流程： 采集 N 个数据。首先，去掉这一组数据中的最大值和最小值。接着，对剩余的 N-2 个数据进行平均计算。这种方法结合了中位值滤波法的优点与算术平均滤波法的优点，降低了偶然脉冲干扰对结果的影响。 例如，如果我们采集到的一组数据为 [5, 4, 3, 2, 1, 4, 5, 8, 3, 7, 2, 3, 6, 7]，当我们 N 设为 5 时，首先去掉最大值 8 和最小值 1，剩余数据为 [5, 4, 3, 4, 3]，最后得出它们的平均值。 优点： 脉冲干扰的消除：中位值平均滤波法能够有效消除偶然出现的脉冲干扰。例如，当某个传感器受到瞬时电击或噪声影响，导致一个数据点异常高或低时，中位值的方法可以避免这一异常值对平均的影响。 抑制周期性干扰：对于周期性干扰（如电源频率干扰），中位值算法展现出良好的抑制能力，因为它只关注中心位置的数据，而忽略掉那些波动较大的极端值。 高平滑度：在高频振荡的系统中，该算法提供了较好的平滑效果，适用于信号需要稳定的应用场景，如温湿度监测。 缺点： 计算速度：与算术平均滤波法一样，中位值平均滤波的计算速度较慢。这是因为它需要对数据进行排序，而排序通常是一个计算量较大的操作，尤其是在数据量较大的情况下。 内存消耗：该方法在处理数据时可能会占用较多的 RAM。在保存和处理大量数据时，应考虑优化内存使用。 示例代码下面是应用中位值平均滤波法的 C++ 示例代码。在这些代码中，首先获取一组数据，然后进行排序，去掉最大和最小值，并计算平均值。 #define FILTER_N 5 // 定义采样数量int Filter() int i; int filter_sum = 0; int filter_max, filter_min; int filter_buf[FILTER_N]; // 进行数据采集 for(i = 0; i FILTER_N; i++) filter_buf[i] = Get_AD(); // 获取数据 delay(1); // 延时确保数据稳定 filter_max = filter_buf[0]; filter_min = filter_buf[0]; filter_sum = filter_buf[0]; // 寻找最大值和最小值 for(i = 1; i FILTER_N; i++) if(filter_buf[i] filter_max) filter_max = filter_buf[i]; if(filter_buf[i] filter_min) filter_min = filter_buf[i]; filter_sum += filter_buf[i]; // 去掉最大值和最小值后计算平均 filter_sum = filter_sum - filter_max - filter_min; return filter_sum / (FILTER_N - 2); 详细过程说明 数据采集：通过 Get_AD() 函数从传感器获取输入数据，循环执行相应的延时确保数据准确。 数据分析：首先初始化最大值和最小值为第一项数据，随后遍历所有采集的数据，以确定真正的最大和最小值。 处理结果：计算所有数据的和，然后减去最大值和最小值，最后将结果除以 N-2（有效数据点的数量）得到最终的平均值。 总结使用中位值平均滤波法可以有效地消除数据中的脉冲干扰和极端异常值，尤其适合于数据波动较大的场景。尽管计算速度较慢且可能占用较多内存，但在需要稳定输出的应用场合，使用此方法往往能够获得更为可靠的结果。 限幅滤波算法在这个算法的运作过程中，它首先计算两次相邻采样的数据差异，也就是两次数据的增量。然后，将这个增量的绝对值与预先设定的允许最大差值 ( A ) 进行比较。这样的比较决定了新数据的有效性。 具体步骤 计算增量：将最新采样值与前一次采样值相减，得到的数据称为增量。假设我们有两次测量温度的数据，第一次测量的温度为 20°C，第二次为 21.5°C，增量为 ( 21.5 - 20 1.5 )°C。 比较绝对值：接着，取增量的绝对值 1.5°C，判断是否超过最大允许差值 ( A )。假设我们设定 ( A 2 )°C，则 ( 1.5 )°C ≤ ( 2 )°C，此时可以认为本次采样有效。 选择数据：如果增量小于或等于 ( A )，新采样值被视为有效数据，被接受并作为最新的数据。如果增量大于 ( A )，那么本次数据被认为异常，系统将使用上一次的有效数据作为本次数据，以确保输出的稳定性和准确性。例如，若本次增量计算为 2.5°C，而 ( A 2 )°C，系统会选择上一次的有效数据，而非新的异常数据。 算法的程序代码如下： #define A // 允许的最大差值char data; // 上一次的数据char filter() char data_new; // 新数据变量 data_new = get_data(); // 获得新数据变量 if ((data_new - data) A || (data - data_new A)) return data; // 如果增量超出限制，返回上一次数据 else return data_new; // 否则返回新数据 应用场景限幅滤波算法特别适用于处理变化缓慢的信号，比如温度监测、物体位置追踪等场景。例如，在监控房间温度时，如果探测器读取到的温度突变，可能是由于外部环境瞬间变化引起的。通过限幅滤波，可以有效忽略这些突发的异常数据，确保系统输出的温度值反映的是环境的真实状态。 对于选取合适的最大允许差值 ( A ) 来说，这通常是非常关键的一步。它的大小因被测对象的不同而异，可能需要依赖经验数据或进行实验来确定。在实际应用中，合理设定 ( A ) 将提高算法的鲁棒性，保证数据的有效性和准确性。例如，某些环境中的温度变化通常很缓和，选取 ( A 1 )°C 可能就足够了；而在气温变化较大的地区，则可能需要设置 ( A 3° )C 或更高，以避免误判。 算术平均滤波算法算术平均滤波算法是一种简单有效的信号处理技术，其核心原理在于对连续的 N 次采样值进行计算，求得其平均值，从而减少随机干扰对信号的影响。这种方法特别适用于存在随机噪声的信号，如温度传感器的输出、电压信号或其他传感器数据。在这些情况下，信号可能会受到环境因素的波动影响而产生干扰，导致读数不稳定。 算法实现以下是该算法的基本程序代码示例，用于计算 N 次采样值的算术平均： char filter() int sum = 0; // 初始化总和变量 for (int count = 0; count N; count++) // 循环 N 次进行采样 sum += get_data(); // 累加每次采样值 delay(); // 读取下一个数据前的延迟，确保数据稳定 return (char)(sum / N); // 返回 N 次采样值的平均值 算法详解此算法中，get_data() 函数是用来获取当前采样值的。在循环中，sum 变量逐步累加这些值，而 delay() 函数则用于在每次采样之间引入必要的延时，确保信号读取的稳定性。例如，假设我们在测量温度，当环境温度因风速或阳光照射等因素变化时，连续采样以捕捉稳定读数尤为重要。 平滑程度与灵敏度的关系算术平均滤波算法在实际应用中，其表现与选择的 N 值有直接关系： 大 N 值：例如，当 N 取值为 32，算法会对更多的样本进行平均处理。这会导致结果变得平滑，减少短时间内的波动，但也会使系统对瞬时变化的不敏感。例如，在温度变化剧烈的环境下，大 N 值可能会导致测量响应迟缓，从而丧失对突发温度变化的及时感知。 小 N 值：相对而言，当 N 取值为 4，系统可以更快反应，灵敏度提高，能够快速捕捉到信号的变化。然而，这样会增加输出信号的波动性，可能使得测量过程中的噪声更为明显。 N 值的选择为了简化计算和提高处理速度，N 通常会选择为 2 的整数幂（例如 4、8、16、32），这样可以利用位移操作代替除法，从而提高运算效率。比如，对于 N16，可以通过右移 4 位代替除以 16 的操作，这在嵌入式系统和实时处理场景中尤其重要，因为运算速度直接影响了系统的响应能力。 通过合理设置 N 值，算术平均滤波算法能在灵敏度和平滑度之间找到一个平衡点，以适应不同的信号处理需求。 加权平均滤波算法加权平均滤波算法是为了解决算术平均滤波算法在平滑度和灵敏度之间存在的冲突而提出的一种方法。算术平均滤波在平滑数据时可能会丢失一些重要的细节，而加权平均滤波则通过赋予不同采样值不同的重要性来改善这一问题。具体来说，它的原理是对于连续 N 次采样值，分别乘以不同的加权系数，然后求出这些加权值的加和。加权系数的特点是一般采用从小到大的分配方式，以增强对后续采样值的关注，从而更有效地捕捉到数据变化的趋势。 加权系数通常是小于 1 的实数，并且它们的总和必须等于 1。这一设置确保了加权运算后的结果仍然是一个有效的采样值。例如，假设我们有 5 个采样值，其对应的加权系数是 0.1、0.2、0.3、0.4、0.0，那么这些系数的总和为 1.0，能够有效提升最近几次的采样在最终结果中的影响力。 加权平均数字滤波的数学模型可以表示为： [ D \\sum_{i0}^{N-1} C_i X_{N-i} ] 其中： ( D ) 为 N 个采样值的加权平均值； ( X_{N-i} ) 为第 ( N-i ) 次采样值； ( N ) 为采样次数； ( C_i ) 为加权系数。 在公式中，加权系数 ( C_i ) 显示了各个采样值在最终平均值中所占的比例。通常情况下，越靠后的采样值，其对应的加权值会越大，这种策略有助于增加新近数据在最终结果中的重要性，从而更敏感地反映采样值的变化。 加权平均滤波方法的核心在于它能够从众多信号中突出一个特定信号，同时压制其他部分的信号，从而提高对参数变化的感知能力和信号处理的效率。 以下是一个实现加权平均滤波的样例程序代码： char jq[N] = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12; // 加权系数表，存放于程序存储区char sum_jq = 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12; // 计算加权系数的总和char filter() char count; char value_buff[N]; // 存储获取到的采样值 int sum = 0; // 用于存储加权和 // 获取 N 次采样值 for (count = 0; count N; count++) value_buff[count] = get_data(); // 从外部获取数据 delay(); // 等待一定时间以稳定数据 // 计算加权和 for (count = 0; count N; count++) sum += value_buff[count] * jq[count]; // 每个采样值乘以其对应的权重 return (char)(sum / sum_jq); // 返回加权平均值 在这段代码中，jq 数组包含了加权系数，而 get_data() 函数负责获取实际的采样值。这种实现方式确保了程序能够灵活处理数据并有效提取出重要信号，进而获得期望的滤波效果。 低通滤波低通滤波是信号处理中的一种重要技术，其作用在于去除高频噪声，同时保留低频信号。为了实现这一功能，普通的硬件 RC 低通滤波器可通过微分方程表示。然而，通过使用差分方程，我们可以使用软件算法模拟硬件滤波的效果。经过推导，最终得到低通滤波的算法如下： Yn = a * Xn + (1 - a) * Yn-1 在上述公式中： Xn 表示本次的采样值。 Yn-1 是上次的滤波输出值。 a 是滤波系数，通常其值远小于 1，决定了当前采样对输出的影响程度。 Yn 是本次滤波的输出值。 从公式中，可以看出，本次的滤波输出值主要依赖于上次的输出值，而不是直接基于上次的采样值。这一特性使得该算法与加权平均滤波有了本质的区别：加权平均滤波会直接结合所有过去的采样值给予权重，而此算法强调了过去输出的持续影响。这使得低通滤波器在信号处理时能够有效地减少因快速变化引起的波动，从而实现平滑效果。 同样重要的是，低通滤波的截止频率可以通过以下公式计算： fL = a / (2 * π * t) （其中 π 约等于 3.14） 在这个公式中： a 是滤波系数。 t 是采样间隔时间。 例如，假设采样间隔时间 t 为 0.5 秒（即每秒采样 2 次），且我们设定 a 为 132，则可以这样计算截止频率： fL = (1/32) / (2 * 3.14 * 0.5) = 0.01 Hz 当目标参数是变化很慢的物理量时，该滤波算法显得特别有效，它能够有效地将高频噪声过滤掉，提高信号的稳定性。然而，值得注意的是，该算法无法滤除高于 12 采样频率的干扰信号。在本例中，由于采样频率为 2Hz，因此对于 1Hz 以上的干扰信号，我们需要采用其他更强的滤波方法加以处理。 虽然低通滤波算法与加权平均滤波存在相似之处，但加权系数仅有两个：a 和 1-a。为简化计算，可以将 a 取为一个整数，而将 1-a 用 256-a 来替代，从而避免复杂的浮点运算。为了确保计算的准确性，过滤输出值使用双字节表示，其中一个字节存储整数部分，另一个字节存储小数部分。这种设计避免了因每次计算时舍去尾数而引起的输出不变问题，确保了滤波的有效性。 通过上述方法，我们可以在软件中有效实现低通滤波器的功能，高效地处理和优化信号，满足各种数据处理需求。 卡尔曼滤波卡尔曼滤波器是一个 “optimalrecursivedataprocessingalgorithm（最优化自回归数据处理算法）”。对于解决很大部分的问题，他是最优，效率最高甚至是最有用的。 假设我们要研究的对象是一个房间的温度。根据你的经验判断，这个房间的温度是恒定的，也就是下一分钟的温度等于现在这一分钟的温度（假设我们用一分钟来做时间单位）（这里的假设相当于状态方程的系数 A 为 1）。假设你对你的经验不是 100%的相信，可能会有上下偏差几度。我们把这些偏差看成是高斯白噪声（White GaussianNoise）（这里就是 W(k)），也就是这些偏差跟前后时间是没有关系的而且符合高斯分配（Gaussian Distribution）。另外我们在房间里放一个温度计，但是这个温度计也不准确的，测量值会比实际值偏差。我们也把这些偏差看成是高斯白噪声。（温度计的测量值就是 Z(k),而由于温度测到的温度就是温度，不用再换算，所以系数 H 就是 1，偏差就是 V(k)）好了，现在对于某一分钟我们有两个有关于该房间的温度值：你根据经验的预测值（系统的预测值 X(k|k-1)）和温度计的值（测量值 Z(k)）。下面我们要用这两个值结合他们各自的噪声来估算出房间的实际温度值。 假如我们要估算 k 时刻的是实际温度值。首先你要根据 k-1 时刻的温度值，来预测 k 时刻的温度。因为你相信温度是恒定的，所以你会得到 k 时刻的温度预测值是跟 k-1 时刻一样的，假设是 23 度，同时该值的高斯噪声的偏差是 5 度（5 是这样得到的：如果 k-1 时刻估算出的最优温度值的偏差（p(k-1|k-1)就是上一时刻的 p(k|k)）是 3，你对自己预测的不确定度是 4 度，他们平方相加再开方，就是 5（算出来的就是 P(k|k-1)））。然后，你从温度计那里得到了 k 时刻的温度值（测量值 Z(k)），假设是 25 度，同时该值的偏差是 4 度。由于我们用于估算 k 时刻的实际温度有两个温度值，分别是 23 度和 25 度。究竟实际温度是多少呢？相信自己还是相信温度计呢？究竟相信谁多一点，我们可以用他们的 covariance（协方差）来判断。因为 `Kg^2=5^2/(5^2+4^2)`，所以 ` Kg=0.78`，我们可以估算出 k 时刻的实际温度值是：`23+0.78*(25-23)=24.56` 度。可以看出，因为温度计的 covariance 比较小（比较相信温度计），所以估算出的最优温度值偏向温度计的值。 现在我们已经得到 k 时刻的最优温度值了，下一步就是要进入 k+1 时刻，进行新的最优估算。到现在为止，好像还没看到什么自回归的东西出现。对了，在进入 k+1 时刻之前，我们还要算出 k 时刻那个最优值（24.56 度）的偏差。算法如下：((1-Kg)*5^2)^0.5=2.35。这里的 5 就是上面的 k 时刻你预测的那个 23 度温度值的偏差，得出的 2.35 就是进入 k+1 时刻以后 k 时刻估算出的最优温度值的偏差（对应于上面的 3）。 就是这样，卡尔曼滤波器就不断的把 covariance 递归，从而估算出最优的温度值。他运行的很快，而且它只保留了上一时刻的 covariance。上面的 Kg，就是卡尔曼增益（Kalman Gain）。 kalman 滤波器算法首先，我们先要引入一个离散控制过程的系统。该系统可用一个线性随机微分方程（Linear Stochastic Difference equation）来描述： x(k)是 k 时刻的系统状态，u(k)是 k 时刻对系统的控制量。A 和 B 是系统参数，对于多模型系统，他们为矩阵。y(k)是 k 时刻的测量值，H 是测量系统的参数，对于多测量系统，H 为矩阵。q(k)和 r(k)分别表示过程和测量的噪声。他们被假设成高斯白噪声(White Gaussian Noise)，他们的 covariance 分别是 Q，R（这里我们假设他们不随系统状态变化而变化）。 对于满足上面的条件(线性随机微分系统，过程和测量都是高斯白噪声)，卡尔曼滤波器是最优的信息处理器。下图给出 KF 算法的流程和五个核心更新方程如下： 下面我们来结合 covariances 来估算系统的最优化输出（类似上一节那个温度的例子）。首先我们要利用系统的过程模型，来预测下一状态的系统。假设现在的系统状态是 k，根据系统的模型，可以基于系统的上一状态而预测出现在状态： X(k|k-1)=A X(k-1|k-1)+B U(k) ……….. (1) 式(1)中，X(k|k-1)是利用上一状态预测的结果，X(k-1|k-1)是上一状态最优的结果，U(k)为现在状态的控制量，如果没有控制量，它可以为 0。 到现在为止，我们的系统结果已经更新了，可是，对应于 X(k|k-1)的 covariance 还没更新。我们用 P 表示 covariance： P(k|k-1)=A P(k-1|k-1) A’+Q ……… (2) 式(2)中，P(k|k-1)是 X(k|k-1)对应的 covariance，P(k-1|k-1)是 X(k-1|k-1)对应的 covariance，A’表示 A 的转置矩阵，Q 是系统过程的 covariance。式子 1，2 就是卡尔曼滤波器 5 个公式当中的前两个，也就是对系统的预测。 现在我们有了现在状态的预测结果，然后我们再收集现在状态的测量值。结合预测值和测量值，我们可以得到现在状态(k)的最优化估算值 X(k|k)： X(k|k)= X(k|k-1)+Kg(k) (Z(k)-H X(k|k-1)) ……… (3) 其中 Kg 为卡尔曼增益(Kalman Gain)： Kg(k)= P(k|k-1) H’ / (H P(k|k-1) H’ + R) ……… (4) 到现在为止，我们已经得到了 k 状态下最优的估算值 X(k|k)。但是为了要另卡尔曼滤波器不断的运行下去直到系统过程结束，我们还要更新 k 状态下 X(k|k)的 covariance： P(k|k)=（I-Kg(k) H）P(k|k-1) ……… (5) 其中 I 为 1 的矩阵，对于单模型单测量，I1。当系统进入 k+1 状态时，P(k|k)就是式子(2)的 P(k-1|k1)。这样，算法就可以自回归的运算下去。 卡尔曼滤波器的原理基本描述了，式子 1，2，3，4 和 5 就是他的 5 个基本公式。根据这 5 个公式，可以很容易的实现计算机的程序。 kalman 实现把房间看成一个系统，然后对这个系统建模。当然，我们见的模型不需要非常地精确。我们所知道的这个房间的温度是跟前一时刻的温度相同的，所以 A1。没有控制量，所以 U(k)0。因此得出： X(k|k-1)=X(k-1|k-1) ……….. (6) 式子（2）可以改成： P(k|k-1)=P(k-1|k-1) +Q ……… (7) 因为测量的值是温度计的，跟温度直接对应，所以 H1。式子 3，4，5 可以改成以下： X(k|k)= X(k|k-1)+Kg(k) (Z(k)-X(k|k-1)) ……… (8)Kg(k)= P(k|k-1) / (P(k|k-1) + R) ……… (9)P(k|k)=（1-Kg(k)）P(k|k-1) ……… (10) 现在我们模拟一组测量值作为输入。假设房间的真实温度为 25 度，我模拟了 200 个测量值，这些测量值的平均值为 25 度，但是加入了标准偏差为几度的高斯白噪声（在图中为蓝线）。 为了令卡尔曼滤波器开始工作，我们需要告诉卡尔曼两个零时刻的初始值，是 X(0|0)和 P(0|0)。他们的值不用太在意，随便给一个就可以了，因为随着卡尔曼的工作，X 会逐渐的收敛。但是对于 P，一般不要取 0，因为这样可能会令卡尔曼完全相信你给定的 X(0|0)是系统最优的，从而使算法不能收敛。我选了 X(0|0)1 度，P(0|0)10。 该系统的真实温度为 25 度，图中用黑线表示。图中红线是卡尔曼滤波器输出的最优化结果（该结果在算法中设置了 Q1e-6，R1e-1）。 matlab 下面的 kalman 滤波程序： clearN=200;w(1)=0;w=randn(1,N)x(1)=0;a=1;for k=2:N;x(k)=a*x(k-1)+w(k-1);endV=randn(1,N);q1=std(V);Rvv=q1.^2;q2=std(x);Rxx=q2.^2;q3=std(w);Rww=q3.^2;c=0.2;Y=c*x+V;p(1)=0;s(1)=0;for t=2:N;p1(t)=a.^2*p(t-1)+Rww;b(t)=c*p1(t)/(c.^2*p1(t)+Rvv);s(t)=a*s(t-1)+b(t)*(Y(t)-a*c*s(t-1));p(t)=p1(t)-c*b(t)*p1(t);endt=1:N;plot(t,s,r,t,Y,g,t,x,b); Kalman 过程详解： 预测：做出先验估计 x[n|n-1]=A*x[n-1|n-1] 【对于一维的情况，A 可以看成一个常数使用，经常取 1，同时对于 B 经常取零(—可能有人会有疑问：取 0 没事吗，可以放心的告诉你，问题不大。反过来想想，这只是一个估计，可以在估计噪声方差得到修正)】 向前推算协方差：做出预测后的新的概率分布的方差（预测上次的最优估计为当前时刻的先验估计这个过程可以当成一个符合预测过程噪声分布的和另一个(上一次的最优估计可以看做高斯分布的)也符合高斯分布的相加。预测结果也是符合高斯噪声分布的，方差是两个相互独立的方差之和）。 【对于一维的情况,P[n|n-1]=P[n-1|n-1]+Q。 Q 为预测方差，代表对预测的不信任程度，工程上根据实际调节以改善滤波器的性能:动态效果和去噪效果】 计算卡尔曼增益： 【对于一维的情况，K[n]=H*P[n|n-1]/H^2*P[n|n-1]+R。其中 H 是对观测的响应倍数，通常取 1，R 为测量的方差，工程上一般都可以直接获得】 更估计值：做出后验估计，修正后的估计值，更接近真实值。 【对于一维的情况，最优估计由下式给出：x[n|n]=x[n|n-1]+K[n]*z[n]-x[n|n-1]。其中 z[n]为观测值】 更新误差协方差：得到最优估计的概率分布的方差。 【对于一维的情况，新的误差协方差由下给出：P[n|n]=(1-K[n]*H)*P[n|n-1]】 代码实现// 一维滤波器信息结构体typedef struct double filterValue; // k-1时刻的滤波值，指的是在上一个时刻的估计值 double kalmanGain; // Kalman增益，控制当前估计值与新测量值的融合程度 double A; // 状态转移模型，x(n)=A*x(n-1)+u(n)，u(n)服从正态分布N(0,Q) double H; // 观测模型，z(n)=H*x(n)+w(n)，w(n)服从正态分布N(0,R) double Q; // 过程噪声方差，量化预测过程中的不确定性 double R; // 测量噪声方差，通过实验获取，此值决定了测量的可靠性 double P; // 估计误差协方差，反映了当前估计的准确程度 KalmanInfo;/** * @brief Init_KalmanInfo 初始化滤波器的初始参数 * @param info 滤波器指针，指向KalmanInfo结构体 * @param Q 预测噪声方差，由系统外部确定 * @param R 测量噪声方差，由系统外部确定 */void Init_KalmanInfo(KalmanInfo* info, double Q, double R) info-A = 1; // 状态转移矩阵设置为1，表示当前状态等于上一个状态 info-H = 1; // 观测矩阵设置为1，表示直接测量状态 info-P = 10; // 后验状态估计值的误差初始值，设置为10以减少初期不确定性的影响 info-Q = Q; // 过程噪声方差，影响滤波收敛速度，需根据实际情况设定 info-R = R; // 测量噪声方差，建议通过实验统计获得，对测量准确性很重要 info-filterValue = 0; // 初始滤波值设为0，表示开始的状态double KalmanFilter(KalmanInfo* kalmanInfo, double lastMeasurement) // 预测下一时刻的值 double predictValue = kalmanInfo-A * kalmanInfo-filterValue; // 基于上一个滤波值进行预测，此处适合多种应用场景 // 更新协方差 kalmanInfo-P = kalmanInfo-A * kalmanInfo-A * kalmanInfo-P + kalmanInfo-Q; // 计算先验均方差，反映当前预测的不确定性 double preValue = kalmanInfo-filterValue; // 记录上次实际的滤波值，为后续可能的计算做准备 // 计算Kalman增益 kalmanInfo-kalmanGain = kalmanInfo-P * kalmanInfo-H / (kalmanInfo-P * kalmanInfo-H * kalmanInfo-H + kalmanInfo-R); // Kalman增益在0到1之间，较大时表示对测量值的信任度提高 // 修正结果，结合预测值与新测量值 kalmanInfo-filterValue = predictValue + (lastMeasurement - predictValue) * kalmanInfo-kalmanGain; // 通过残余（测量值与预测值之差）来调整估计，输出当前时刻的滤波值 // 更新后验估计协方差 kalmanInfo-P = (1 - kalmanInfo-kalmanGain * kalmanInfo-H) * kalmanInfo-P; // 更新后的协方差反映了更准确的状态估计结果 return kalmanInfo-filterValue; // 返回当前时刻的滤波值 此代码实现了一个简单的一维 Kalman 滤波器，主要用于信号预测和噪声抑制。滤波器的有效性在于调整参数 Q 和 R，这些参数直接影响滤波器对不同来源噪声的敏感度，使得它可以在动态环境下提供平滑且准确的估计。通过合理设置这些初始值和更新步骤，Kalman 滤波器将能够逐渐学习并优化对环境状态的预测。","categories":["1.语言","语言结构"]},{"title":"预处理和宏","path":"/2024/11/19/1-语言-C语言-预处理和宏/","content":"按照 ANSI 标准的定义，预处理程序负责处理一系列指令。这些指令都以符号 # 开始且必须独占一行。在 C 程序中，预处理阶段是一个重要的步骤，它在编译之前对代码进行分析和修改，使得源代码可以更灵活和高效地编译。 #define宏替换#define 指令用于定义一个标识符（称为宏名字）和一个字符串（字符集）。当源程序中出现该标识符时，它会被对应的字符串替换。宏代换的定义形式如下： #define macro-name char-sequence 注意，#define 语句不需要以分号结尾。宏名字和字符串之间可以有多个空白符，但字符串的结束只能以新行终止。例如，我们可以使用两个 #define 指令来定义： #define LEFT 1#define RIGHT 0 每当在源程序中遇到 LEFT 或 RIGHT 时，编译程序都会将其替换为 1 或 0。定义宏之后，我们还可以在其他宏定义中引用它，如： #define ONE 1#define TWO ONE + ONE 宏代换的实际作用在于用指定的字符串替换标识符，这使得代码更易于管理和维护。如果想要定义一条标准错误信息，可以如下操作： #define ERROR_MSG An error has occurred. 如果一个字符串长于一行，可以在其行尾使用反斜线 \\ 来继续到新一行。例如： #define LONG_STRING This is a very very long \\string that continues here. 宏体种不能递归包含自身的宏名，预处理的时候会把宏名看做字符串 带参宏我们也可以在宏中定义函数。例如： #define SWAP(a, b) int temp = a; a = b; b = temp; 在调用 SWAP(a, b) 时，它会被替换为实际的代码块： int temp = a; a = b; b = temp; 宏定义函数 vs 外部调用函数宏定义和外部调用函数是以时间和空间进行权衡的策略：宏定义用更快的方式来替代代码，而函数则通过严格的类型检查和更好的内存管理来保证代码的安全性和可维护性。开发者在选择时，需根据实际需求，灵活选用合适的工具。例如，假设一个性能敏感的计算任务，使用宏可能是更合适的选择；而在需要复杂逻辑的应用场景中，外部函数则会显得更可靠。 宏定义函数宏实际上是可以理解为一段在编译时会被替换的代码片段。宏通过预处理器来实现，其传递的内容仅仅是字符串。与此关联的是，宏不会进行任何语法检查或数据类型校验。例如，在 C 语言中定义一个简单的宏： #define SQUARE(x) ((x) * (x)) 当你在代码中使用 SQUARE(5) 时，预处理器会将其替换为 ((5) * (5))，直接在编译阶段进行文本替换。这意味着，程序运行时不会有额外的调用开销，宏的执行速度是非常快的。 优点: 使用宏时，程序的执行效率更高。由于编译时直接插入代码，这消除了函数调用所需的上下文切换和栈的操作，例如压栈和出栈的过程。 缺点: 由于宏不具备类型检查，当传递的参数类型不符合预期时，可能导致意想不到的结果。例如，如果你使用 SQUARE(3.5)，则会产生 ((3.5) * (3.5))，这可能不是开发者的本意。同时，宏也不在运行时占用内存的释放过程，可能导致更高的内存消耗。 外部调用函数与宏不同，外部调用函数（通常被称为函数）则在运行时执行，并且在传递参数时会执行严格的类型匹配。例如，在 C 语言中定义一个求平方的函数如下： int square(int x) return x * x; 这里，函数 square 在运行时根据传入的参数来计算值。如果传入了不匹配的类型，例如浮点数，编译器会报错，从而帮助开发者及时发现问题。 优点: 函数提供了类型安全的参数传递机制，避免了许多潜在的错误。此外，函数在调用完成后可以灵活地释放资源，有助于优化内存使用。 缺点: 函数调用涉及到一定的开销，特别是在频繁调用的场景中，因为它需要在函数调用栈上安排内存，增加了执行时间。 #error#error 指令用于强制编译器停止编译，主要应用于调试阶段。它的一般形式是： #error error-message 例如，我们可以定义标准错误信息如： #define ERROR_MSG Standard error on input #error ERROR_MSG 注意，宏字符串 error-message 不需要用双引号包围。当编译器遇到 #error 指令时，会显示指定的错误信息和其他可能的编译信息。 #include在程序中，#include 指令告诉编译器读取并编译另一个源文件。被包含的文件名可以用双引号 或尖括号 包围。例如，使用标准输入输出库包含头文件： #include stdio.h 被包含的文件中可以再次包含其他 #include 指令，这种行为称为嵌套包含。编译器对于嵌套包含的最大深度依赖于具体的实现。 文件名的包围方式决定了搜索文件的位置： 使用尖括号 时，编译器会按预定义目录搜索，一般用于标准库文件。 使用双引号 时，编译器首先在当前目录查找，如果没有找到再转向按尖括号方式搜索。 自定义包含路径在编译时，可以通过添加选项例如： gcc -I /home/fs/include 来指定搜索目录，如果 stdio.h 未在当前目录中找到，编译器会进一步查找 /home/fs/include，最后再查找系统默认目录。 通常，程序员在包含标准库文件时使用尖括号，而对于程序相关的文件则使用双引号。 条件编译指令条件编译允许程序员选择性地编译源代码的不同部分，这一过程称为条件编译。 #if #else #elif #endif条件编译指令中最常用的是 #if、#else、#elif 和 #endif。这些指令允许根据常数表达式的结果有条件地编译代码。 #if 的一般形式如下： #include stdio.h#if constant-expression Statement sequence#endif 如果 #if 后面的常数表达式为真，则执行 #if 和 #endif 之间的代码；否则，编译器将忽略这段代码。 #else 指令与 C 语言中的 else 相似，当 #if 失败时，可以作为备选指令。例如： #if MAX 99 printf(Compiled for array greater than 99. );#else printf(Compiled for small array. );#endif 这里 #else 既标记了 #if 块的结束，同时标记了 #else 块的开始。 为实现多重条件选择，可以使用 #elif： #if expression Statement sequence#elif expression1 Statement sequence#elif expression2 Statement sequence#else Statement sequence#endif #ifdef #ifndef条件编译的另一种方法是使用 #ifdef 和 #ifndef，用来判断宏是否已定义或未定义。 #define MAX 100int main(void) #ifdef MAX printf(MAX is defined. ); #else printf(MAX is not defined. ); #endif return 0; #ifndef MY_HEADER_H#define MY_HEADER_H // Header content#endif 在这个例子中，如果 MY_HEADER_H 未被定义，则包含头文件的内容。 #undef#undef 指令用于删除之前定义的宏名字，即 不定义 宏的功能。形式为： #undef macro-name #defined另一种检查宏是否已定义的方法是结合 #if 指令与 defined 操作符。形式如下： #if defined(MY) // Code if MY is defined#endif 可以通过感叹号 ! 来反转条件： #if !defined(DEBUG) printf(Final Version! );#endif #line #pragma#line#line 指令用于改变 __LINE__ 和 __FILE__ 的值，分别表示当前代码行号和文件名。形式为： #line number filename #pragma#pragma 是一种用于在编译过程中向编译器提供特殊指令或编译选项的预处理指令。不同的编译器可以定义自己的 #pragma 指令集，因此其行为在不同编译器中可能有所不同。使用 #pragma 指令时要确保其兼容性，尤其在跨编译器和跨平台开发中。常见的 #pragma 主要用于修改编译器的行为或进行代码的优化控制。#pragma 通常紧接其后的内容定义了具体的编译指令或选项。 #pragma 指令 编译器会忽略它不支持的 #pragma 选项，从而提高 C 源程序的可移植性。 常见用法 禁用或启用警告：可以临时禁用或启用特定的编译警告。 设置代码段：一些编译器支持使用 #pragma 来将代码放入指定的内存段。 优化设置：可以指定某个代码块的优化级别或其他优化相关选项。 指令对齐：控制结构对齐或数据对齐。 #pragma warning#pragma warning(push) // 保存当前警告状态#pragma warning(disable : 4996) // 禁用警告 4996（在 MSVC 中，常用于禁用安全函数相关的警告）#include stdio.hint main() char str[10]; gets(str); // 使用可能不安全的函数，编译器通常会发出警告 printf(%s , str); return 0;#pragma warning(pop) // 恢复之前的警告状态 在这个示例中，#pragma warning(disable : 4996) 用于禁用警告编号为 4996 的警告，通常与不安全的函数使用相关。 #pragma pack用途：调整结构体、联合体或类的成员对齐方式。它用于减少结构体的填充，优化内存占用。 #pragma pack(push, 1) // 设置对齐方式为 1 字节struct MyStruct char a; int b;;#pragma pack(pop) // 恢复默认对齐方式 #pragma pack(push, 1) 将结构体的成员对齐设置为 1 字节，这样可以减少结构体占用的内存，但在某些平台上可能影响性能。 #pragma once用途：防止头文件被多次包含。相比传统的头文件保护宏（如 #ifndef、#define），使用 #pragma once 可以简化头文件保护。 #pragma once// 头文件内容 #pragma once 是一种用于防止头文件被重复包含的指令，等效于传统的头文件保护宏： #ifndef HEADER_FILE_NAME#define HEADER_FILE_NAME// 头文件内容#endif 使用 #pragma once 可以简化编写头文件保护代码，避免重复包含问题。 #pragma GCC poison用途：禁止使用特定的标识符。如果在代码中使用了这些标识符，编译器将发出错误。 #pragma GCC poison printf scanf// 使用 printf 或 scanf 会导致编译错误 #pragma GCC optimize用途：控制特定代码段的优化选项，可以用于启用或禁用优化。 #pragma GCC optimize (O3) // 在此代码段启用最高优化级别void optimizedFunction() // 高度优化的代码 #pragma GCC target用途：为指定的函数设置特定的目标架构。这在编译器支持多种 CPU 指令集时非常有用。 #pragma GCC target (sse4.2)void sseOptimizedFunction() // 仅在支持 SSE4.2 的平台上进行优化 #pragma message用途：在编译时向用户显示自定义消息。 #pragma message This is a custom compile-time message 当编译器处理到这条指令时，会输出消息到编译器的输出中，方便开发者提醒或调试。 #pragma weak用途：定义弱符号，即使符号未被定义，链接器不会报错。通常用于库函数的替代实现。 #pragma weak myFunctionvoid myFunction() // 如果另一个 myFunction 实现存在，则不会使用此实现 预处理操作符 # 和 ##有两个预处理操作符可用于 #define 中： #：字符串化操作符，将宏参数转换为用双引号包围的字符串。 ##：拼接操作符，将两个标记结合形成新标记。 #define mkstr(s) #sprintf(mkstr(I like C)); // 转换为 I like C #define concat(a, b) a##bprintf(%d, concat(x, y)); // 假设 x 变量和 y 变量存在，将输出 xy 的值 ##粘连## 本质上是一个 胶水运算。在 C 语言中，## 运算符用于将参数宏中的形参与其它没有天然分割的内容粘连在一起。比如，我们可以定义一个宏，让它自动地定义一个数组： #define def_u32_array(__name, __size) uint32_t array_##__name[__size]; 在实际使用时，我们可能会这样调用这个宏： def_u32_array(sample_buffer, 64) 经过宏展开后，最终效果是： uint32_t array_sample_buffer[64]; 这里可以观察到，array_ 与形参 __name 是没有天然分隔符的，因此要将 array_ 与 name 所代表的内容粘连在一起，## 运算符是必不可少的。反之，name 与 [ 之间有天然分隔，编译器能够识别这两个部分。因此不用额外使用 ## 运算符。 连接可变参数宏## 运算符还有一个不太为人所知的用法。我们需要提及另外一种参数宏扩展 — 可变参数宏。举个例子： #define safe_atom_code(...) \\ uint32_t int_flag = __disable_irq(); __VA_ARGS__ __set_PRIMASK(int_flag); \\ 这里定义了一个宏 safe_atom_code()，在括号中，无论你填写任何内容，这些内容都会被放置到 __VA_ARGS__ 所在的位置。可以理解为括号里的 ... 实际上对应着 __VA_ARGS__。例如，我们可以写如下代码： /** \\fn void wr_dat (uint16_t dat) * \\brief Write data to the LCD controller * \\param[in] dat Data to write */static __inline void wr_dat(uint_fast16_t dat) safe_atom_code( LCD_CS(0); GLCD_PORT-DAT = (dat 8); /* Write D8..D15 */ GLCD_PORT-DAT = (dat 0xFF); /* Write D0..D7 */ LCD_CS(1); ) 这个代码块确保在向寄存器 GLCD_PORT-DAT 写入数据的过程不会被其它中断打断。此时聪明的你可能会提出疑问：这段宏与下面的写法有何区别？ #define safe_atom_code(__CODE) \\ uint32_t int_flag = __disable_irq(); __CODE __set_PRIMASK(int_flag); \\ 参数宏与预编译器的博弈参数宏通过 ,（逗号）作为分隔符来计算实际传入的参数个数。在使用参数宏的时候，预编译器实际上并不理解 C 语言语法 —— 在它眼中，除了它认识的少数符号外，其他的都是无意义的字符串。在处理括号内的内容时，预编译器只认识 , 和 ...。因此，当内容中的 , 增加时，编译器会认为参数的个数也增多。当你使用参数宏时，传入的参数个数（需通过 , 分隔）必须与定义参数宏时的形参数量一致。如果不一致，预编译器通常不会直接报错，而是会无视你所传递的内容，将其传递到编译阶段。如果出现未定义函数的错误，可能是因为宏本身被误认为是一个不存在的函数。可变参数宏解决了这一问题。可变参数宏中，... 只能位于形参列表的最后，当用户提供的参数个数超过定义的数量时，额外的参数就会通过 __VA_ARGS__ 进行处理。当用户提供的参数个数正好等于形参个数时，__VA_ARGS__ 等效于一个空字符串。 log_info 的使用回到上述的 safe_atom_code 宏，我们再看看： #define log_info(__STRING, ...) printf(__STRING, __VA_ARGS__) 使用时，我们可以这样调用： log_info(------------------------------------\\r );log_info( Cycle Count : %d, total_cycle_cnt); 这段代码会展开为： printf(------------------------------------\\r ,);printf( Cycle Count : %d, total_cycle_cnt); 看似没有问题，但注意到一个细节：此时第一个 printf() 函数的参数列表结尾多了一个 ,。尽管某些编译器（如 GCC）可能对此不予太多关注，但对于追求代码整洁的开发者来说，这种多余的逗号就显得很不舒服。 ANSI-C99 标准为了解决这种情况，引入了一个有用的语法：在 ,##__VA_ARGS__ 的组合使用时，如果 __VA_ARGS__ 为空字符串，前面的 , 将会被删除。这样，我们可以将宏改写为： #define log_info(__STRING, ...) printf(__STRING,##__VA_ARGS__) 最终展开为： printf(------------------------------------\\r );printf( Cycle Count : %d, total_cycle_cnt); 这样最后的逗号就不会出现了，让代码更加干净整洁。 逗号表达式的灵活性结合前面关于 ,##__VA_ARGS__ 的用法，我们可以意识到，这里的逗号不仅可以作为参数列表的分隔符，还是逗号表达式的运算符。因此，我们可以写出类似这样的宏： #define EXAMPLE(...) ( 默认值 ,##__VA_ARGS__) 这种写法可以分为两种情况： 无参数调用：当使用时不填写任何内容，最终会展开为仅有默认值的情况： EXAMPLE(); // 展开为：( 默认值 ) 提供有效值：如果提供了有效值，则展开成逗号表达式： EXAMPLE(我们提供的值); // 展开为：( 默认值, 我们提供的值 ) 由于逗号表达式的特性，默认值会被丢弃，这虽然在某些编译器中可能报出无效的警告，但在用法上是完全合理的。 这一技巧在 API 封装上非常有效，可以为函数简化使用方式。例如，当用户调用初始化函数并通过结构体配置某些参数时，如果用户传入的配置为 NULL，系统则可以用默认的配置： #define XXXX_INIT(...) xxxx_init((NULL,##__VA_ARGS__)) 在消息处理方面，开发者可以设计类似机制，允许程序根据用户传入的参数自动处理必要的配置： #define def_msg_map(__name, ...) \\ const msg_t __name[] = __VA_ARGS__; #define add_msg(__msg, __handler, ...) \\ \\ .msg = (__msg), \\ .handler = (__handler), \\ .msk = (0xFFFF, ##__VA_ARGS__), \\ 这样，当用户省略参数时，系统就会提供默认值，例如： def_msg_map(iap_message_map, add_msg(SIGN_UP, iap_sign_up_handler), add_msg(WRITE_MEM, iap_write_mem, 0xFF00), add_msg(READ_MEM, iap_read_mem, 0xFF00)); 这条代码展示了如何让系统在处理消息时采用默认值，同时也允许用户自定义特定条件，从而实现灵活的消息管理。这让程序在运行时表现得更加智能和友好。 预定义宏C 语言规范了五个固有的预定义宏： __LINE__：当前编译的代码行号。 __FILE__：当前编译的源文件名。 __DATE__：源文件编译时的日期，格式为 month/day/year。 __TIME__：源代码编译时的时间，格式为 hour:minute:second。 __STDC__：如果内容是十进制常数 1，表示编译程序符合标准 C。 typedef 的应用在预处理和代码编写中，我们经常使用 #define。需要注意的是，typedef 与 #define 用法相似，但它们有明确的区别： typedef 是 C 语言的关键字。 #define 是预处理命令。 typedef 常用于为现有数据类型定义新名字，在数据结构中尤为频繁。例如： typedef struct _node_ int data; struct _node_ *next; listnode, *linklist; 在此示例中，listnode 被定义为结构体类型，而 linklist 则是指向该结构体的指针类型。通过使用 typedef，程序员可以让代码更加清晰和易于维护。","categories":["1.语言","C语言"]},{"title":"曲线绘制","path":"/2024/11/18/1-语言-Qt-曲线绘制/","content":"QChartQwt绘图坐标转换为时间/*******4---绘图坐标转换为时间类****/class TimeScaleDraw: public QwtScaleDraw//定义一个新类去继承QwtScaleDraw,重新实现方法public: TimeScaleDraw( const QTime base ): baseTime( base ) //baseTime，成员初始化QTime类型的base virtual QwtText label( double v ) const//重新实现里面的虚方法，此方法含义，将v值转换为代表标签label QTime upTime = baseTime.addSecs((int)v);//强制将double类型的v转化为int类型，其实v就是坐标，当前时间加上坐标 return upTime.toString(hh:mm); //返回一个String类型 private: QTime baseTime; //在构造函数进行初始化;","categories":["1.语言","Qt"]},{"title":"Qt的socket通信","path":"/2024/11/18/2-通讯协议-网络-Qt的socket通信/","content":"在 Qt 中执行收发工作较为耗时或交互频率较高的时候，为了使得通信过程不造成 UI 的卡顿现象，一般要求通信工作在次线程（子线程）中完成。 将 Qt 套接字对象移动到次线程，并在主线程中直接调用套接字接口，此时存在 “以其他线程对象为父对象，在本线程创建子对象” 的告警。 定义一个 workker 类对象，将其移动到次线程中，由其负责对 m_socket 套接字对象的操作，包括使用套接字进行连接、断开、数据发送等操作。套接字对象没有进行过 moveToThread 操作，其还是归属于创建它的主线程，但相关函数调用线程却为所在的次线程。 在多线程情况下需要注意，线程的构造函数和 run 函数所隶属的线程是不一致的，如果在构造函数中初始化节点时，会出现警告 QSocketNotifier: socket notifiers cannot be enabled from another thread 套接字的相关接口只能在套接字对象所属的线程内调用（如果套接字对象没有执行过 moveToThread 操作，那么套接字对象的所属线程就是创建它的线程）。因此，如果想支持在次线程中执行连接断开服务、数据收发过程，则必须的要将套接字对象本身进行 moveToThread 操作，且要将其他线程对该对象的操作转换到 moveToThread 后的线程内。 //.h#pragma once#include QTcpSocket//该对象最终运行在次线程中class TcpClient : public QTcpSocket Q_OBJECTpublic: TcpClient(QObject *parent = NULL); ~TcpClient();public: // void ClientConnectToHost(const QString address, quint16 port); // void ClientSendingData(const QByteArray c_btaData); // bool IsOnline();signals: //转换来自主线程的链接操作 void SignalConnectToHost(const QString address, quint16 port);signals: //转换来自主线程的发送操作 void SignalSendingData(const QByteArray c_btaData);signals: //在次线程中缓冲并滑动解析TCP流后/按约定格式再发布 void SignalPublishFormatRecvData(const QString c_btaData);private: //标记连接情况 bool m_bOnLine = false; //缓冲收到的流数据 QByteArray m_btaReceiveFromService;; //.cpp#include QThread#include QDebug#include QHostAddress#include tcp_client.hTcpClient::TcpClient(QObject *parent) : QTcpSocket(parent) //自动连接在信号发射时被识别为队列连接/信号在主线程发射 connect(this, TcpClient::SignalConnectToHost, this, [](const QString address, quint16 port) //test record# in child thread id 20588 qDebug(SlotConnectToHost ThreadID:%d, QThread::currentThreadId()); // connectToHost(QHostAddress(address), port, QIODevice::ReadWrite); , Qt::AutoConnection); //连接了TCP服务端 connect(this, QAbstractSocket::connected, this, []() //test record# in child thread id 20588 qDebug(SlotHasConnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = true; , Qt::DirectConnection); //断开了TCP服务端 connect(this, QAbstractSocket::disconnected, this, []() //test record# in child thread id 20588 qDebug(SlotHasDisconnected ThreadID:%d, QThread::currentThreadId()); // m_bOnLine = false; , Qt::DirectConnection); //收到了TCP服务的数据 connect(this, QIODevice::readyRead, this, []() //test record# in child thread id 20588 qDebug(SlotIODeviceReadyRead ThreadID:%d, QThread::currentThreadId()); //读取全部数据 m_btaReceiveFromService.append(this-readAll()); // int iFindPos = m_btaReceiveFromService.indexOf(\\r ); //检查分隔符 while (-1 != iFindPos) //分割数据流 QString strPublish = m_btaReceiveFromService.left(iFindPos); //发布解析后的格式数据 emit SignalPublishFormatRecvData(strPublish); // m_btaReceiveFromService.remove(0, iFindPos + strlen(\\r )); // iFindPos = m_btaReceiveFromService.indexOf(\\r ); , Qt::DirectConnection); //执行数据发送过程 connect(this, TcpClient::SignalSendingData, this, [](const QByteArray c_btaData) //test record# in child thread id 20588 qDebug(SlotSendingData ThreadID:%d, QThread::currentThreadId()); // this-write(c_btaData); , Qt::AutoConnection);//TcpClient::~TcpClient()//跨线程转换void TcpClient::ClientConnectToHost(const QString address, quint16 port) emit SignalConnectToHost(address, port);//跨线程转换void TcpClient::ClientSendingData(const QByteArray c_btaData) emit SignalSendingData(c_btaData);//是否在线bool TcpClient::IsOnline() return m_bOnLine; //main /using of my tcp clientUpdateCamera::UpdateCamera(QWidget *parent) : QMainWindow(parent) //创建TCP客户端 m_pmyTcpSocket = new TcpClient(); // m_pThreadSending = new QThread(); // m_pmyTcpSocket-moveToThread(m_pThreadSending); // m_pThreadSending-start(); //连接到相机的TCP服务 connect(ui.pushButton_connect, QPushButton::clicked, []() ... m_pmyTcpSocket-ClientConnectToHost(strIPUsing, SER_PORT); ); //文件发送 connect(ui.pushButton_file_sending, QPushButton::clicked, []() ... //执行客户端文件发送过程 m_pmyTcpSocket-ClientSendingData(DataOfBin); ); //接收服务端发送的数据 /从子线程到主线程的队列连接 connect(m_pTcpClient, TcpClient::SignalPublishFormatRecvData, this, [](const QString c_btaData) ui.textEdit-append(c_btaData); ui.textEdit-moveCursor(QTextCursor::End); if (ui.textEdit-toPlainText().size() 2 * 1024 * 1024) ui.textEdit-clear(); , Qt::AutoConnection); QIODevice::readyRead 信号的 DirectConnection 连接的 lambda 槽函数执行结果，可得出：如果一个 Tcp 对象被归属到了子线程 X 中，那么 readyRead 信号最终将从此子线程 X 发出。connected 信号、disconnected 信号等其发射线程，都是套接字对象的所在线程。 当 connect 内部使用 lambda 表达式做槽函数时，注意选择有 Qt::ConnectionType 参数的那个函数版本，否则将默认为直接连接。 //默认为直接连接connect(const QObject *sender, PointerToMemberFunction signal, Functor functor)//可以配置连接方式 //Qt::UniqueConnections do not work for lambdasconnect(const QObject *sender, PointerToMemberFunction signal, const QObject *context, Functor functor, Qt::ConnectionType type) 默认的连接方式 Qt::AutoConnection 在 connect 后生效的时刻是 emit 发射的时候，而不是执行 connect 语句的时候。因此先执行 moveToThread 还是先执行 connect 过程是无关紧要的。具体可参见帮助文档中提及的：If the receiver lives in the thread that emits the signal, Qt::DirectConnection is used. Otherwise, Qt::QueuedConnection is used. The connection type is determined when the signal is emitted.","categories":["2.通讯协议","网络"]},{"title":"基于QSerialPort的串口通信","path":"/2024/11/18/2-通讯协议-串口-基于QSerialPort的串口通信/","content":"初始化定义一个 QSerialPort 类，串口参数的设置应在打开串口之前完成 QSerialPort *ComNodeIns;ComNodeIns = new QSerialPort;ComNodeIns-setBaudRate(/*QSerialPort::Baud115200*/230400);ComNodeIns-setParity(QSerialPort::NoParity);ComNodeIns-setDataBits(QSerialPort::Data8);ComNodeIns-setStopBits(QSerialPort::OneStop);ComNodeIns-setFlowControl(QSerialPort::NoFlowControl);//轮询可用的串口foreach(const QSerialPortInfo info, QSerialPortInfo::availablePorts())\tQString comName = info.portName(); ComNodeIns-setPortName(comName);//设置缓冲区大小// ComNodeIns-setReadBufferSize(6000);//以只读方式打开串口if (ComNodeIns-open(QIODevice::ReadOnly))// ComNodeIns-readAll();//\tconnect(ComNodeIns, SIGNAL(readyRead()), this, SLOT(SlotDataReady()));\t// static QTimer getTimer;\t// connect(getTimer, SIGNAL(timeout()), this, SLOT(SlotDataReady()));\t// getTimer.start(5);//判断串口是否打开if (!ComNodeIns-isOpen())//2.1 open failed\tprintf(%s open Failed ,comName.toLocal8Bit().data());\temit sendNoEquipment();else //2.2 open success\tprintf(%s open OK ,comName.toLocal8Bit().data()); 数据发送-缓冲池发送在多线程情况下，会出现显示发送成功，返回值正常，但是接收端没有接收到数据的情况，该情况的原因是如果线程之中如果使用 while(1) 循环，循环过快，导致 connect 来不及处理数据，所以使用 waitForBytesWrittenwaitForReadyRead 将循环进行阻塞，当有数据读入时取消阻塞，进入下一轮循环。 static int sendIndex = 0;static int sendFailed = 0;//需完整轮询所有缓冲区，保证没有被遗漏的需要发送的数据for(int i=0; iINDEX_OF_BUFF; i++)\tif(sendMsg[i].nodeMutex.tryLock()) if(sendMsg[i].nodeStatus == 1) int Tr = ComNodeIns-write(sendMsg[i].nodeData); ComNodeIns-waitForBytesWritten(5); if(Tr=0) sendFailed++; //总发送失败次数 recvMsg[i].nodeIndex += 1;//存入发送失败次数 else sendIndex++; sendMsg[i].nodeStatus = 0; recvMsg[i].nodeIndex = 0; recvMsg[i].nodeMutex.unlock(); 数据接收-缓冲池接收static int recvIndex = 0;ComNodeIns-waitForReadyRead(1);int Tr = ComNodeIns-bytesAvailable();if(Tr0)\tfor(int i=0; iINDEX_OF_BUFF; i++) if(recvMsg[i].nodeMutex.tryLock()) if(recvMsg[i].nodeStatus == 0) recvMsg[i].nodeStatus = 1; recvMsg[i].nodeData = ComNodeIns-readAll(); recvMsg[i].nodeIndex = recvIndex++; recvMsg[i].nodeMutex.unlock(); return;//将所有数据存入缓冲区后直接跳出循环 recvMsg[i].nodeMutex.unlock(); 数据处理方式-帧头校验/** * @brief SerialPortDriver::SlotDataReady * receive Serial Buffer Content */void SerialPortDriver::SlotDataReady() quint8 *getData_p; quint64 unSize; //unRead bytes in serial buffer bool bCountinue = false; QByteArray baPacket; do //1.detect frame head if (m_bNewCmd)//new msg received while (1) if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE)//msg length longer than head // printf(no msg %d ,ComNodeIns-bytesAvailable()); break;// else // printf(=====================get msg %s ,qPrintable(QDateTime::currentDateTime().toString(HH:mm:ss zzz))); m_readData = ComNodeIns-read(FRAME_HEAD_SIZE);//read msg head getData_p = (quint8 *)(m_readData.data()); if (getData_p[0] == MSG_HEAD getData_p[6] == MSG_HEAD_END)//compare msg head end m_unNeedReadNu = getData_p[4]-FRAME_HEAD_SIZE; m_bNewCmd = false; break; else//drop error msg printf(ERROR: MSG RECEIVE HEADEND FAILED!!! ); // ComNodeIns-read(NULL,1); //2.read full frame unSize = ComNodeIns-bytesAvailable(); if (m_unNeedReadNu0 m_unNeedReadNu = unSize) m_readData.append(ComNodeIns-read(m_unNeedReadNu)); else m_readData.append(ComNodeIns-read(unSize)); m_unNeedReadNu = m_unNeedReadNu - unSize; break; //3.send to message deal module baPacket = m_readData; slotDealFrame(baPacket); m_bNewCmd = true; m_unNeedReadNu = 0; //4.continue read if (ComNodeIns-bytesAvailable() FRAME_HEAD_SIZE) bCountinue = true; while (bCountinue);","categories":["2.通讯协议","串口"]},{"title":"Apache和MySQL","path":"/2024/11/04/0-平台-服务器-Apache和MySQL/","content":"Web 的工作方式 Web 系统本质上是基于客户端服务器的架构，使得用户端（客户端）可以通过请求获取位于远程服务器上的资源。 在万维网（WWW）服务中，系统遵循 HTTP 协议，默认使用的 TCPIP 端口是 TCP 80，这意味着不需要在 URL 中指定端口，用户可以直接输入网址即可访问。 客户端与服务器之间的通信过程如下： Web Client 发送 HTTP 请求 到服务器，服务器收到请求后进行处理。 服务器响应 HTTP 应答，将结果返回给客户端，通过 Internet 完成信息的交互。 ASF（Apache 软件基金会） 早期版本的 Apache 服务器是由一个名为 Apache Group 的团队来维护。随着时间的发展，Apache 软件基金会（Apache Software Foundation，简称 ASF）于 1999 年成立，旨在支持开源软件项目。 ASF 维护着包括 Apache HTTP Server 在内的多个开源项目，例如 Perl、PHP、Java、Tcl 和 XML 等，这些项目广泛应用于开发和服务器管理中。 ASF 的官方网站是 http://www.apache.org，用户可以在此找到所有与 Apache 相关的资源和文档。 Apache 的特性－1.3 版本 Apache 1.3 版本引入了动态共享对象（DSO）功能，允许服务器在运行时动态地加载不同的功能模块，以增强服务器的灵活性。 通过采用预生成模式的技术，Apache 1.3 极大地提高了响应速度，使网站访问更加流畅。 支持最新的 HTTP 1.1 协议，其中包括更好的连接管理和扩展功能，促进了更复杂的网络应用。 配置方面也非常友好，简单而强大的基于文件的配置让用户能够轻松定制服务器环境。 支持虚拟主机功能，使得在同一个服务器上能够同时运行多个网站。 提供 HTTP 认证功能，保护敏感数据与资源。 支持许多第三方软件开发者提供的功能模块，用户可以根据需求扩展 Apache 的功能。 Apache 的特性－2.0 版本 Apache 2.0 几乎继承了 1.3 版本的所有特性，并进行了多项改进。 新增的组件——Apache Portable Runtime（APR），进一步提升了 Apache 的跨平台性能，允许开发者在不同平台上保持相似的行为。 2.0 版本引入了新的多处理模块（Multi-Processing Module，简称 MPM），el 通过它可以控制 Apache 在处理多个请求时的运行方式。Apache 可以采用三种处理模式： 预派生（Prefork）MPM：这是 Red Hat 9.0 及后续版本的默认模式，适合需要较高兼容性的情况； 工作者（Worker）MPM：相比 Prefork MPM，更加高效，适合同时处理大量连接； 独立子进程（Perchild）MPM：为每个请求分配独立的工作进程，从而增强了安全性。 安装和启动 Apache 安装 Apache 2.0 的命令如下： # rpm -ivh httpd-2.0.40-21.i386.rpm# rpm -ivh httpd-manual-2.0.40-21.i386.rpm 启动、停止和重启 Apache 的方法： # service httpd start # 启动服务# service httpd stop # 停止服务# service httpd restart # 重启服务# service httpd status # 检查服务状态# pstree | grep httpd # 查看当前 Apache 进程 检测 Apache 配置文件语法的正确性，可以使用以下命令： # apachectl configtest Apache 配置文件 配置文件的默认所在目录为： /etc/httpd/conf/ Apache 的主配置文件名为 httpd.conf，用户可以在该文件中修改各种设置以优化其服务器。 Apache 的基本配置 KeepAlive:开启此选项允许一个连接上发送多个请求。这样可以显著减少连接开销，提升浏览效率，因为避免了为每个请求都建立新的连接。 MaxKeepAliveRequests:设定每个连接中可以发送的最多请求数量。设置为 0，则没有限制，默认值为 100。 KeepAliveTimeout:此设置衡量在两个连续请求间的最大间隔时间（以秒为单位），若超过此时间，则视为连接断开。 MaxClients:限制在同一时间内可接入的最大连接数量。该值过高可能会影响服务器性能，默认设置为 150。 MinSpareServers 和 MaxSpareServers:设置空闲 httpd 进程的数量，保证始终有一定数量的空闲进程以应对快速增长的连接请求。若空闲进程少于 5，则会自动增加到 5，若超过 20 则减少到 20。 StartServers:定义 Apache 启动时初始的 httpd 进程数，默认值是 8。 ServerName:配置服务器的主机名，该名称将在远程连接中显示。默认情况下，这个名称是 localhost。 ServerAdmin:这里填写的是服务器管理员的邮件地址。当服务器发生错误时，可以向此邮件发送通知。 ServerRoot:指定 Apache 的配置文件和日志文件存放的路径，默认是 /etc/httpd。 DocumentRoot:该项设定 Apache 给定的网页文档根目录，所有网站文件应放在此目录或其子目录中。 Listen:用于设置 Apache 监听的端口，默认是 80 端口。 User Group:这两个选项分别设置 Apache 的执行用户和用户组。默认情况下，Apache 使用 apache 用户和 apache 组。 DirectoryIndex:用于指定当目录中没有特定文件时的默认索引文件列表。例如： DirectoryIndex index.html index.htm Options:此选项包括多种设置，例如： Indexes：当指定文件找不到时，生成目录列表。 FollowSymLinks：允许查询不在当前目录中的文件。 IndexOptions:提供用户自定义目录列表的方式，包括样式和排序功能，例如： FancyIndexing：为目录中的文件添加小图标以表示类型。 VersionSort：对文件版本进行排序。 **NameWidth***：自动调整文件名字段的宽度以适应最长文件名。 FoldersFirst：在列出目录的时候将文件夹优先展示。 配置 Apache－容器指令 容器指令通常包括在 ... / 的括号内。这些容器可以为配置提供更具体的上下文和控制。例如： Directory：用于设置特定目录的配置。 Files：用于设置特定文件的配置。 Location：用于设置 URL 路径的配置。 VirtualHost：为虚拟主机提供配置。 配置每个用户的 Web 站点要为每个用户配置 Web 站点，请遵循以下步骤： 修改主配置文件，以启用个别用户站点的配置。 修改主配置文件，配置每个用户站点目录的访问控制。 在用户的家目录下创建其网站的目录及相关网页文件。 UserDir 配置语句示例： UserDir disable root # 禁止 root 用户使用个人站点UserDir public_html # 指定每个用户的站点目录 组织和管理站点内容 符号链接：符号链接允许将存放在根文档目录之外的内容引入到站点中，可以通过以下命令实现： # cd /var/www/html# ln -s /usr/share/doc doc # 将 /usr/share/doc 目录链接到当前目录 别名：别名功能如下： 允许将根文档目录以外的内容加入到站点。 简化用户访问站点内复杂且深层的 URL。示例配置： Alias /ftp /var/ftp/pub # 将 /ftp URL 映射到 /var/ftp/pub 目录 配置访问控制 访问控制的配置指令:通过以下指令细化访问规则： Order：定义何时执行允许访问和拒绝访问的规则。 Deny：建立拒绝访问的列表。 Allow：建立允许访问的列表。 Order 指令的两种形式： Order Allow,Deny：先执行允许规则，再执行拒绝规则，默认为拒绝所有未明确允许的访问。 Order Deny,Allow：先执行拒绝规则，再执行允许规则，默认为允许所有未明确拒绝的访问。 Deny 和 Allow：在这两个指令下列出具体的访问列表。访问列表可使用如下形式定义： All：允许所有客户访问。 域名：如 jamond.net，允许域内的所有客户访问。 IP 地址：允许具体或部分的 IP 地址。 网络子网掩码：如 192.168.1.0/255.255.255.0。 CIDR 规范：如 192.168.1.0/24。 使用.htaccess 文件分割配置任务 何时使用 .htaccess 文件：当需要在多个用户之间分割配置，或希望实现不需要重启服务器的配置变更时，可以使用此文件。 启用并控制使用 .htaccess 文件的选项： AccessFileName .htaccessAllowOverride All # 控制允许在 .htaccess 文件中使用的指令 认证指令 认证相关的配置指令可以出现在主配置文件的 Directory 容器中，也可以在 .htaccess 文件中定义。以下是 Apache 的认证配置指令： 指令 指令语法 说明 AuthName AuthName 领域名称 定义受保护领域的名称 AuthType AuthType Basic 或 Digest 定义使用的认证方法 AuthGroupFile AuthGroupFile 文件名 指定认证组的口令文件位置 AuthUserFile AuthUserFile 文件名 指定认证用户的口令文件 授权指令在使用认证指令后，需为特定用户或组进行授权。Require 指令有三种使用格式： 指令语法格式 说明 Require user 用户名 [用户名] … 授权给指定的一个或多个用户 Require group 组名 [组名] … 授权给指定的一个或多个组 Require valid-user 授权给认证口令文件中的所有用户 管理认证用户口令文件和认证组文件 创建新的认证口令文件: # htpasswd -c 认证口令文件名 用户名 修改认证口令文件: # htpasswd 认证口令文件名 用户名 认证口令文件格式:每一行格式如：用户名：加密的口令。 管理认证组文件:这是一个简单的文本文件，每一行的格式为 组名：用户名 用户名 …。 MySQL 简介 MySQL 是一种高效、多用户和多线程的中小型 SQL 数据库系统，由一个服务器守护进程 mysqld 和多个不同的客户端程序及库组成。 当前最新版本为 4.0.13，用户可通过官方网站 http://www.mysql.com 下载。 MySQL 的主要特点包括： 支持多平台运行，用户可以在 Windows、Linux 等多种操作系统上使用 MySQL。 提供对多种数据库的支持，能够及时满足用户的多样需求。 支持多语言开发，开发者可以使用如 PHP、Python、Java 等多种语言与 MySQL 进行交互。 拥有非常完善的权限系统，可以高效地管理用户和权限。 安装和启动 MySQL 安装 MySQL 的步骤如下： # rpm -ivh perl-CGI-2.81-88.i386.rpm# rpm -ivh perl-DBI-1.32-5.i386.rpm# rpm -ivh mysql-3.23.54a-11.i386.rpm perl-DBD-MySQL-2.1021-3.i386.rpm# rpm -ivh mysql-server-3.23.54a-11.i386.rpm 启动、停止和重启 MySQL 服务器的命令： # service mysqld start # 启动数据库服务# service mysqld stop # 停止数据库服务# service mysqld restart # 重启数据库服务 在 Apache 上运行 CGI 程序 CGI（公共网关接口）：这是一种广泛应用于构建动态 Web 站点的技术，它最初由 NCSA（国家超级计算机应用中心）开发。CGI 定义了服务器如何与生成动态内容的程序交互，常用的编程语言包括 Perl 和 C。 在 Apache 上可以使用 mod_cgi 模块来运行这些 CGI 程序。 配置动态网站Apache + MySQL + PHP这种组合拓展了 Web 服务器的功能，形成了如下架构： Internet 使用者 - WebServer(Apache) - PHP - 数据库/网络功能/其他功能库 在 Apache 上安装和运行 PHP 安装 PHP 时所需的命令为： # rpm -ivh curl-7.9.8-5.i386.rpm# rpm -ivh gd-1.8.4-11.i386.rpm# rpm -ivh php-4.2.2-17.i386.rpm# rpm -ivh php-imap-4.2.2-17.i386.rpm# rpm -ivh php-mysql-4.2.2-17.i386.rpm PHP 作为 Apache 的一个模块运行，只需启动 Apache 即可自动加载，不需额外手动启用。 phpMyAdmin phpMyAdmin 是一种用 PHP 编写的基于 Web 的 MySQL 管理工具，为用户提供了图形化界面来管理 MySQL 数据库，用户可以通过访问 phpmyadmin.sourceforge.net 下载工具。 安装过程中，需解压和修改配置文件 config.inc.php 中的设置： $cfg[Servers][$i][auth_type] = http; $cfg[Servers][$i][password] = yourmysqlrootpasswd; Apache 上的虚拟主机 虚拟主机 是指在同一台服务器上实现多个网站，通过如下方式实现： 不同的虚拟主机可以指向不同的 IP 地址和端口号。 不同的虚拟主机通过不同的主机头（即域名）识别。 虚拟主机配置指令虚拟主机配置中常用的指令包括： ServerAdmin：指定虚拟主机管理员的 E-mail 地址； DocumentRoot：定义虚拟主机的根文档目录； ServerName：设置虚拟主机的名称及其所用的端口号； ErrorLog：指定虚拟主机的错误日志存放路径； CustomLog：指定虚拟主机的访问日志存放路径。 还可以在 VirtualHost 容器中使用 Directory 容器进行对目录的进一步访问控制配置。 配置虚拟主机 可以根据需要配置相同 IP 但不同端口号的虚拟主机，不同 IP 但相同端口号的虚拟主机，或者基于域名的虚拟主机。 通过这些配置，用户能够有针对性地优化自己的 Apache 服务器设置，以确保在各种环境下都能稳定、高效地运行各类 Web 应用与服务。","categories":["0.平台","服务器"]},{"title":"ARP","path":"/2024/11/04/0-平台-Linux-网络-ARP/","content":"首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址，如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。 网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。 如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。 例如： A 的地址为：IP：192.168.10.1 MAC: AA-AA-AA-AA-AA-AA B 的地址为：IP：192.168.10.2 MAC: BB-BB-BB-BB-BB-BB 根据上面的所讲的原理，我们简单说明这个过程：A 要和 B 通讯，A 就需要知道 B 的以太网地址，于是 A 发送一个 ARP 请求广播（谁是 192.168.10.2 ，请告诉 192.168.10.1），当 B 收到该广播，就检查自己，结果发现和自己的一致，然后就向 A 发送一个 ARP 单播应答（192.168.10.2 在 BB-BB-BB-BB-BB-BB）。","categories":["0.平台","Linux","网络"]},{"title":"TCP和UDP","path":"/2024/11/04/2-通讯协议-网络-TCP和UDP/","content":"握手分析ClientSend：SYN + seq100 ServerSend：SYN + ACK + seq200 + ack101 ClientSend：ACK + ack201 TCP 连接建立在 TCPIP 协议中，TCP 协议提供可靠的连接服务，采用三次握手建立一个连接。 服务器必须准备好接受外来的连接。这通过调用 socket、 bind 和 listen 函数来完成，称为被动打开(passive open)。 第一次握手：客户通过调用 connect 进行主动打开(active open)。这引起客户 TCP 发送一个 SYN（表示同步）分节（SYNJ），它告诉服务器客户将在连接中发送到数据的初始序列号。并进入 SYN_SEND 状态，等待服务器的确认。 第二次握手：服务器必须确认客户的 SYN，同时自己也得发送一个 SYN 分节，它含有服务器将在同一连接中发送的数据的初始序列号。服务器以单个字节向客户发送 SYN 和对客户 SYN 的 ACK（表示确认），此时服务器进入 SYN_RECV 状态。 第三次握手：客户收到服务器的 SYN+ACK。向服务器发送确认分节，此分节发送完毕，客户服务器进入 ESTABLISHED 状态，完成三次握手。 分析 客户端的初始序列号为 J，而服务器的初始序列号为 K。在 ACK 里的确认号为发送这个 ACK 的一端所期待的下一个序列号。因为 SYN 只占一个字节的序列号空间，所以每一个 SYN 的 ACK 中的确认号都是相应的初始序列号加 1.类似地，每一个 FIN（表示结束）的 ACK 中的确认号为 FIN 的序列号加 1.完成三次握手，客户端与服务器开始传送数据，在上述过程中还有一些重要概念。未连接队列：在三次握手协议中，服务器维护一个未连接队列，该队列为每个客户端的 SYN 包(synj)开设一个条目，该条目表明服务器已收到 SYN 包，并向客户发出确认，正在等待客户端确认包。这些条目所标识的连接在服务器处于 SYN_RECV 状态，当服务器收到客户端确认包时，删除该条目，服务器进入 ESTABLISHED 状态。 TCP 连接终止TCP 连接终止需四个分节。 第一次握手：某个应用进程首先调用 close，我们称这一端执行主动关闭。这一端的 TCP 于是发送一个 FIN 分节，表示数据发送完毕。 第二次握手：接收到 FIN 的另一端执行被动关闭（passive close）。这个 FIN 由 TCP 确认。它的接收也作为文件结束符传递给接收端应用进程（放在已排队等候应用进程接收到任何其他数据之后） 第三次握手：一段时间后，接收到文件结束符的应用进程将调用 close 关闭它的套接口。这导致它的 TCP 也发送一个 FIN。 第四次握手：接收到这个 FIN 的原发送端 TCP 对它进行确认。 面向字节的数据传送流（如 TCP 字节流、Unix 管道等）也使用 EOF 表示在某个方向上不再有数据待传送。在 TCP 字节流中，EOF 的读或写通过收发一个特殊的 FIN 分节来实现。 TCP 服务器 Server 创建套接字 socket 绑定 IP，PORTbind 设置监听套接字 listen 等待建立连接 accept 收发数据 read/write recv/send recvfrom/sendto 关闭连接 close TCP 客户端 Client 创建套接字 socket 绑定 bind 建立连接 connect 收发数据 read/write 关闭连接 close UDP 服务器 Server 创建套接字 socket 绑定地址 接收数据 发送数据 UDP 客户端 Client 创建套接字 socket 发送数据 接收数据","categories":["2.通讯协议","网络"]},{"title":"ARINC429","path":"/2024/10/29/3-软件-航电-ARINC429/","content":"ARINC 429 协议ARINC 429 以其单向、广播式的特性和复杂的数据帧结构适合于多设备间的信息共享 概述ARINC 429 是由美国航空无线电公司制定的一种单向串行通信协议，广泛应用于民用和军用飞机的电子系统中。其主要特点包括： 单向传输：信息只能从发送器流向接收器。 差分信号：采用双极性归零码进行信号传输，具有良好的抗干扰能力。 数据帧结构ARINC 429 的数据单元由 32 位组成，具体分布如下： Bit 1-8：Label（标签域），用于标识数据类型（八进制表示）。 Bit 9-10：SDI（源目的地标识符），指示数据来源或目的地。 Bit 11-28 或 29：Data Field（数据域），包含实际传输的数据，通常使用 BCD 或二进制数表示。 Bit 30-31：SSM（信号状态矩阵），描述数据的状态或性质。 Bit 32：Parity Bit（校验位），用于奇偶校验以确保数据的完整性。 MPIO429（Multi-Protocol IO 429）是一种基于 ARINC 429 协议的多功能输入输出模块，通常用于航空电子系统中，支持对不同种类的飞机数据总线进行通信。ARINC 429 协议广泛应用于航空领域，特别是在飞行控制、导航、发动机管理、机载传感器数据传输等方面。 MPIO429 的功能特点数据传输速度：支持 ARINC 429 协议的标准传输速率，通常为 12.5 kbps 或 100 kbps，适合低速数据传输。 多通道支持：MPIO429 模块通常会提供多个通道，允许同时处理多个 ARINC 429 信号，可以连接多个设备并处理更多数据。 ARINC 429 协议与 MPIO429 数据传输方式：ARINC 429 使用单向数据传输，一般分为发射器和接收器，每个设备通过一个独立的信号线发送或接收数据。 数据帧结构：ARINC 429 数据帧包含多个字段，包括起始位、数据位、标签（label）、数据和奇偶校验位等，传输的数据一般是飞行数据、环境监控、传感器数据等。 应用场景 飞行控制系统：用于飞行状态、控制指令等数据的传输。 航空电子设备：如雷达、导航、仪表等设备的数据通信。 发动机控制系统：监控发动机状态、控制指令等。 在 ARINC 429 协议中，一个接口通常是单向的，即每个 ARINC 429 信号线路只能作为输入或输出之一。这是因为 ARINC 429 本身设计为点对点的单向数据传输协议，每条线路只有一个发送器和一个接收器。 为什么 ARINC 429 是单向的？ 简化设计和减少干扰：ARINC 429 的单向通信减少了信号冲突的可能性，并且可以在硬件和协议层面上简化电气设计。这使得通信更加可靠，尤其在飞机这种对数据传输可靠性要求极高的环境中。 速度和时序：ARINC 429 的传输速率比较低（通常为 12.5 kbps 或 100 kbps），并且通信是基于时间分片的，因此单向传输更容易管理。 双向通信的实现尽管 ARINC 429 本身是单向的，但某些系统可能会使用多个 ARINC 429 通道来实现双向通信。比如： 双通道设计：如果一个设备既需要发送数据，又需要接收数据，通常会为每个方向提供独立的通道（输入和输出），每个通道都连接到不同的 ARINC 429 总线或接口。 其他协议组合：有些设备可能还会采用其他协议（如 MIL-STD-1553 或 CAN）来实现双向通信，这些协议支持全双工通信，即同一条线路可以同时进行数据输入和输出。 在 ARINC 429 协议下，一个接口本身通常不能同时进行输入和输出，但可以通过增加通道或使用其他协议来实现双向通信。","categories":["3.软件","航电"]},{"title":"ARINC422","path":"/2024/10/29/3-软件-航电-ARINC422/","content":"ARINC 422 协议ARINC 422 则因其高效的点对点通信能力适合于快速数据传输。 ARINC 422 是一种用于航空电子设备间串行数据通信的协议，主要用于传输数字信号。它是一种单向通信协议，通常用于传输数据和指令。 ARINC 422 协议内容 数据格式： ARINC 422 使用二进制编码，数据以串行形式发送。 波特率： 常用的波特率为 100 kbps，传输距离可达 1,200 米。 信号电平： 使用差分信号，具有较强的抗干扰能力。逻辑“1”和逻辑“0”通过电压差来表示。 数据帧结构ARINC 422 的一帧数据通常包含以下部分： 起始位（Start Bit）： 通常为 1 位，表示数据帧的开始。 数据位（Data Bits）： 通常为 8 位（可以根据具体应用有所变化），用于传输实际的数据内容。 奇偶校验位（Parity Bit）： 可选，1 位，用于检测传输错误。可以设置为偶校验或奇校验。 停止位（Stop Bits）： 通常为 1 或 2 位，表示数据帧的结束。 一帧数据的内容分布示例假设一帧数据的结构如下： 1 位：起始位 8 位：数据位 1 位：奇偶校验位 1 位：停止位 +---------+----------+-------------+-----------+| Start | Data | Parity | Stop || Bit | Bits | Bit | Bit |+---------+----------+-------------+-----------+| 1 | 8 | 1 | 1 |+---------+----------+-------------+-----------+","categories":["3.软件","航电"]},{"title":"CS模型","path":"/2024/10/28/0-平台-Linux-网络-CS模型/","content":"","categories":["0.平台","Linux","网络"]},{"title":"网络协议","path":"/2024/10/28/0-平台-Linux-网络-网络协议/","content":"四层网络协议TCPIP（传输控制协议因特网协议）参考模型（四层模型）： 四层模型（TCPIP 参考模型）是实际互联网通信中使用较为广泛的模型。 TCPIP 参考模型是互联网通信所使用的一种协议参考模型，由互联网工程任务组（IETF）定义。它将网络通信划分为四个层次，每个层次负责不同的功能，从底层到应用层，依次为： 网络接口层：处理物理网络接口和链路层协议，例如以太网。 网络层：负责 IP 协议、路由和分组转发等。 传输层：提供端到端的数据传输服务，包括 TCP 和 UDP 协议。 应用层：包括各种应用层协议，例如 HTTP、FTP、SMTP 等。 七层网络协议OSI（开放系统互联）参考模型（七层模型）： 七层模型（OSI 参考模型）提供了更细粒度的分层和功能划分。 OSI 参考模型是国际标准化组织（ISO）制定的一种网络协议参考模型，用于描述计算机网络中不同层次的功能和协议。它将网络通信划分为七个不同的层次，每个层次负责不同的任务，从物理传输到应用层，依次为： 物理层：负责物理介质传输和电信号传输。 数据链路层：处理数据帧的传输、物理寻址和错误检测等。 网络层：负责逻辑寻址、路由和分组转发等。 传输层：提供可靠的端到端数据传输，包括流量控制和错误恢复等。 会话层：管理不同应用程序之间的会话和数据交换。 表示层：处理数据的表示和转换，包括数据加密和解密等。 应用层：提供特定应用程序的服务和接口。 网络接口和物理层MAC 地址（Data Link Layer）：MAC 地址是一个唯一标识网络设备（如网卡）的物理地址。 它属于数据链路层，在局域网中用于唯一标识设备并实现直接通信。 PPP（Point-to-Point Protocol）（Data Link Layer）：PPP 用于在点对点连接上进行数据通信。 它属于数据链路层，用于建立和管理点对点连接，通常用于拨号、串口等通信。 ARP（Address Resolution Protocol）（Network Layer）：ARP 用于将 IP 地址解析为对应的 MAC 地址。 它属于网络层，在局域网中实现 IP 地址和 MAC 地址之间的映射关系。 RARP（Reverse Address Resolution Protocol）（Network Layer）：RARP 允许根据 MAC 地址获取对应的 IP 地址。 它属于网络层，在特定场景下（如无磁盘终端设备引导）用于获取 IP 地址。 IP 地址(Internet protocol)（Network Layer）：IP 地址是一个用于在互联网中唯一标识设备和网络的逻辑地址。 它属于网络层，在网络中进行寻址和路由选择，实现跨网络的通信。 ICMP（Internet Control Message Protocol）（Network Layer）：ICMP Inetrnet 控制管理协议（ping 命令） 用于在 IP 网络上传递控制消息和错误报告。 它属于网络层，在 IP 通信中提供网络状况、错误检测、排错等功能。 IGMP（Internet Group Management Protocol）（Network Layer）：IGMP Inetrnet 分组管理协议（广播组播） 用于在 IP 网络上进行组播（Multicast）管理。 它属于网络层，在多播通信中，用于主机和路由器之间的组播组管理。","categories":["0.平台","Linux","网络"]},{"title":"套接字的超时检测","path":"/2024/10/28/2-通讯协议-网络-套接字的超时检测/","content":"网络通信中，很多操作会使得进程阻塞，这时我们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 通过 setsockopt 设置套接字属性 SO_RCVTIMEOstruct timeval t = 5, 0 if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, t, sizeof(t)) == -1) perror(setsockopt); return -1; memset(peeraddr, 0, sizeof(peeraddr)); len = sizeof(peeraddr); if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) printf(errno=%d: %s , errno, strerror(errno)); if (errno == EAGAIN) printf(timeout ); return -1; 设定 select 函数的一个参数实现超时处理struct timeval t= 3, 0; while (1) 。。。。。。 t.tv_sec = 3; t.tv_usec = 0; if ((ret = select(maxfd+1, rdfs, NULL, NULL, t)) == -1) perror(select); return -1; 。。。。。。 设定一个定时器捕捉 SIGALRM 信号做超时控制struct sigaction act; sigaction(SIGALRM, NULL, act); //获取SIGALRM信号的属性 act.sa_handler = handler; // 设置SIGALRM信号的处理函数 sigaction(SIGALRM, act, NULL); // 设置SIGALRM信号的属性 alarm(3); // 定时器设置3秒钟 while (1) if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) if (errno == EINTR) printf(timeout ); return -1; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。我们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["2.通讯协议","网络"]},{"title":"QEMU","path":"/2024/10/28/0-平台-嵌入式-QEMU/","content":"QEMU 简介QEMU（Quick EMUlator）是一个开源、跨平台的虚拟化工具和仿真器，最初由 Fabrice Bellard 于 2003 年开发。QEMU 的强大之处在于其能够在多种硬件和操作系统环境中运行，使用各种虚拟化和仿真技术实现硬件设备的虚拟化，主要应用于系统开发、测试及学习虚拟化技术。 QEMU 的两个主要功能是： 仿真器模式（Emulation）：它能模拟多种硬件架构，允许用户在一种硬件平台上运行其他架构的操作系统。例如，用户可以在 x86 架构的计算机上运行基于 ARM 或 MIPS 架构的操作系统，这对于开发与测试跨平台应用程序至关重要。 虚拟化模式（Virtualization）：利用硬件辅助的虚拟化技术，如 Intel VT-x 和 AMD SVM，QEMU 能够显著提升虚拟机的性能。这种强大的性能加速使得用户在虚拟环境中可以流畅运行应用程序，几乎没有性能损失。 QEMU 的特性 多架构支持：QEMU 支持多种 CPU 架构，包括 x86、ARM、PowerPC、MIPS 和 RISC-V 等。这种灵活性非常适合开发人员需要测试不同平台兼容性时的需求。 与 KVM 结合使用：当 QEMU 与 KVM（Kernel-based Virtual Machine）配合时，可以提供卓越的虚拟化性能。KVM 利用硬件虚拟化功能，几乎将虚拟机性能提升到近乎原生环境的水平。 用户空间仿真：QEMU 支持在用户空间中仿真，可以运行不同平台上的单个用户程序，这对于软件测试和开发者调试大型软件项目非常有帮助。 广泛应用场景：QEMU 被广泛应用于嵌入式开发、操作系统测试、系统镜像调试等。开发者可以使用它来模拟硬件环境，从而在主机上便捷地测试嵌入式系统或新操作系统。 QEMU 的简要使用方式1. 安装 QEMU在 Linux 操作系统中，可以通过其包管理器轻松安装 QEMU。以下是几种常见操作系统安装的示例： UbuntuDebian： sudo apt updatesudo apt install qemu qemu-system qemu-user-static 这条命令会安装 QEMU 及其相关的系统和用户模式模拟工具。 CentOSRHEL： sudo yum install qemu-kvm qemu-img 相应地，这将安装 KVM 支持的 QEMU。 Windows： 在 QEMU官方页面 下载 Windows 版 QEMU，并在安装过程中确保其路径添加到系统环境变量中，这样可以在命令提示符下轻松运行 QEMU。 2. 运行基本 QEMU 虚拟机以下是创建并运行一个简单虚拟机的示例命令： qemu-system-x86_64 -boot d -cdrom /path/to/your.iso -m 1024 qemu-system-x86_64：指定要运行 x86_64 架构的虚拟机。 -boot d：指定从光盘启动。 -cdrom：用来指定 ISO 文件的路径。 -m 1024：为虚拟机分配 1GB 内存，这对于运行大多数操作系统来说是足够的。 这种简单的命令使得任何人都能快速设置一个虚拟机来测试不同的操作系统或软件环境。 3. 创建虚拟磁盘镜像使用 qemu-img 工具创建虚拟磁盘的命令如下： qemu-img create -f qcow2 mydisk.qcow2 10G -f qcow2：指定磁盘的格式，qcow2 是 QEMU 的默认格式，支持快照等高级功能。 mydisk.qcow2：这是创建的虚拟磁盘文件的名称。 10G：指定虚拟磁盘的大小为 10GB，适合存放多个文件或系统映像。 接着可以通过以下命令运行虚拟机并挂载这个新创建的磁盘： qemu-system-x86_64 -hda mydisk.qcow2 -cdrom /path/to/your.iso -boot d -m 1024 这条命令将新创建的虚拟磁盘作为主硬盘挂载，从而可以安装操作系统或运行应用程序。 4. 加速虚拟化为了利用 KVM 加速 QEMU 虚拟机，可以执行以下命令： qemu-system-x86_64 -enable-kvm -hda mydisk.qcow2 -m 1024 -enable-kvm：启用 KVM 加速功能，这样用户可以充分利用现代 CPU 提供的硬件虚拟化特性，从而显著提升虚拟机性能。 这种方法对需要高实时性能的应用场景尤为重要，比如运行数据库或高负载网络服务器。 学习 QEMU 的途径学习 QEMU 的建议途径有： 阅读官方文档：QEMU 的官方文档内容详实，涵盖了从安装到使用技巧的各个方面。访问 QEMU官方文档 是了解其功能的最佳方式。 实验和实践：动手尝试在 QEMU 中运行不同架构的操作系统，例如 ARM 和 MIPS，实操中掌握其工作原理。 与 KVM 结合学习虚拟化：深入理解 QEMU 和 KVM 的结合使用，学习如何通过调优配置来提升性能。 调试和仿真嵌入式系统：利用 QEMU 模拟 ARM 开发板或 RISC-V 等平台，进行嵌入式项目开发，可以让你在主机上调试和测试嵌入式应用。 QEMU 的优势 灵活性：能够支持多种架构和硬件平台，对开发需要兼容性测试的应用程序非常友好。 开源：QEMU 是开源软件，代码透明，用户可以根据需要对软件进行定制和学习。 优秀性能：结合 KVM 可以提供极高的虚拟化性能，使得开发和测试过程高效流畅。 QEMU 不仅是学习操作系统开发、嵌入式开发和硬件虚拟化的强大工具，也为开发者提供了一个仿真和调试的平台。通过不断地实践，用户能更深入理解虚拟化和仿真技术的核心原理。","categories":["0.平台","嵌入式"]},{"title":"Xenomai实时框架","path":"/2024/10/28/0-平台-嵌入式-RealTime-Xenomai实时框架/","content":"Xenomai 概述Xenomai 是一个专门为 Linux 平台设计的实时框架，它允许各种实时操作系统（RTOS），如 VxWorks 和 QNX，的应用程序接口（API）在 Linux 环境中使用。这种创新的技术集成显著提升了 Linux 系统的实时性能，提供了硬实时调度的保障，使开发者能够在 Linux 上实现严格的时间响应要求。这对许多需要快速反应的应用来说至关重要，比如自动化控制、机器人技术和高频交易。 Xenomai 不仅能够在主流的 Linux 内核上运行，还支持多种嵌入式平台。这一点对于大多数工业或消费类设备至关重要，因为很多设备依赖嵌入式系统来执行关键任务。Xenomai 官方支持多种嵌入式硬件，开发者可以通过访问 Xenomai 官方嵌入式设备列表 来了解适合特定项目的设备。 总体来看，Xenomai 为开发人员提供了强大的工具，可以帮助完成以下关键任务： 实时应用程序的设计与开发：利用 Xenomai 的强大功能，你可以在 Linux 上设计和运行需要高实时性的应用程序。例如，自动化生产线的控制系统必须在毫秒内对传感器输入做出反应，Xenomai 能够提供所需性能以满足这些要求。 RTOS 应用程序的移植：如果已有在 RTOS 上开发的应用程序，Xenomai 使得它们顺利迁移到 Linux 成为可能。比如，许多机器人控制程序最初是在 VxWorks 上开发的，通过 Xenomai，开发者可以保留原有代码并在 Linux 环境中继续使用，极大简化了开发流程。 以 Linux 原生应用程序方式运行 RTOS 应用：Xenomai 能够让你像运行 Linux 应用一样直接运行 RTOS 应用程序，例如 VxWorks、pSOS、VRTX、uITRON 和 POSIX。这意味着，如果团队已经习惯于在 Linux 环境中开发，也可以轻松接入这些 RTOS 系统的应用，提升工作效率，减少学习成本。 通过这些功能，Xenomai 不仅极大提升了 Linux 的实时处理能力，也为开发者创造了一个灵活且高效的工作环境。 Xenomai 架构双内核结构Xenomai 采用双内核架构来实现其实时操作。一个是高优先级的微内核（co-kernel），另一个是传统的 Linux 内核。co-kernel 负责执行实时任务，而 Linux 内核则维持其常规的服务功能。两个内核由 Adeos 进行管理，每个内核被分配到不同的域。 需要注意的是，微内核可能会切换到 Linux 内核域，这会破坏 Xenomai 的实时性。这种情况可能发生在实时任务中使用了 Linux 的一些系统调用时，因此在设计实时任务时，需要谨慎使用 Linux 系统调用。 AdeosAdeosi-pipe 是实现双内核结构的核心，它是 Xenomai 和 RTAI 等系统的基础。在基于 Adeos 的系统中，操作系统在独立的域内运行，每个域有独立的地址空间及类似进程、虚拟内存等的软件抽象层，且这些资源可以在域间共享。 在计算机系统中，操作的执行主要依赖于内部和外部的中断与异常，例如系统时钟中断是操作系统中最重要的中断。Adeos 通过管理硬件中断，并根据域的优先级依次调用相应域的中断服务程序，来驱动系统的运行。同时，Adeos 还提供了域间通信机制，实现域的调度等功能。 为了有效管理中断及控制域间的优先，这里引入了“中断管道（Interrupt Pipe）”的概念。通过中断管道，Adeos 在不同域之间传播中断，并提供机制让域能够调整自身在中断管道中的优先级。 Xenomai 在 Adeos 系统中的域优先级高于 Linux 域，意味着每当中断发生时，Adeos 首先调度 Xenomai 来处理该中断并执行相应的实时任务，只有在 Xenomai 没有实时任务和中断需要处理时，Adeos 才会调度 Linux，这确保了 Xenomai 的中断响应速度和实时任务不受 Linux 的干扰，从而提供了可预测的实时性能。 性能测试Xenomai 提供了一系列性能测试工具，安装完 Xenomai 后，这些工具会位于 Xenomai 安装目录的 bin/ 文件夹。以下是一些关键测试工具的列表及其功能： clocktest：用于测试 CPU 时钟的精度和性能。 cyclictest：用于测试 Xenomai POSIX 周期定时器的性能。 dohell：生成系统负载以测试系统的承载能力。 irqbench：对中断请求（IRQ）进行性能测试。 irqloop：用于更深入的 IRQ 测试。 klatency：内核空间时延测试工具，评估内核操作的延迟。 latency：用于测量定时器的时延，确保定时器精度。 switchbench：测试任务切换延迟，以评估系统的切换效率。 switchtest：用于测量进程上下文切换的时间。 xeno-test：运行用户定义的脚本，以评估最佳和最差延迟。 这些工具为开发者提供了强有力的手段，以监控和优化实时应用程序的性能，确保系统在真实环境中能够满足预期的实时性要求。","categories":["0.平台","嵌入式","RealTime"]},{"title":"信号槽","path":"/2024/10/28/1-语言-Qt-信号槽/","content":"在信号槽中传递值和传递地址的效率问题 写法信号发送者，信号，信号接收者，处理函数 connect(pushBtn,SIGNAL(clicked(bool)),this,SLOT(slot_Qt4())); Qt5 Lambda 表达式，编译时检测类型安全，信号的参数类型和参数个数 同接收该信号的槽的参数类型和参数个数相同。 connect(pushBtn,QPushButton::clicked,this,Widget::slot_Qt5); 注意 Lambda 表达式是 C++ 11 的内容， Pro 项目文件中需加入 CONFIG += C++11 connect(pushBtn,QPushButton::clicked,[=]()\tqDebug()lambda 表达式;); [=] 是一个 lambda 表达式的捕获列表。 [=] 表示以值传递的方式捕获 lambda 表达式所在作用域中的所有自动变量（包括 this 指针，如果在类的成员函数中）。这意味着在 lambda 表达式内部可以访问这些被捕获的变量的值，但不能修改它们（除非被声明为 mutable）。","categories":["1.语言","Qt"]},{"title":"Qt","path":"/2024/10/28/1-语言-Qt-Qt/","content":"Qt 基础部分Qt 入门 Qt 概述：介绍 Qt 的历史、特点和应用领域。 环境搭建：详细步骤指导如何在不同操作系统上安装 Qt 和 Qt Creator。 第一个 Qt 应用：创建一个简单的 “Hello World” 应用，学习基本的项目结构和运行流程。 Qt 对话框 标准对话框：使用 QMessageBox、QFileDialog 等标准对话框。 自定义对话框：创建和管理自定义对话框，处理用户输入。 Qt 窗口 窗口类型：介绍不同类型的窗口（如主窗口、对话框、MDI）。 窗口属性：设置窗口标题、大小、图标等属性。 自定义窗口部件 自定义控件：通过继承 QWidget 创建自定义控件。 绘制与事件处理：重写 paintEvent 和 event 方法，实现自定义绘制和事件响应。 Qt 中级布局管理 布局类型：使用 QVBoxLayout、QHBoxLayout、QGridLayout 等布局管理器。 嵌套布局：实现复杂界面布局的技巧。 事件处理 事件模型：理解 Qt 的事件循环和事件处理机制。 自定义事件：创建和处理自定义事件。 二维绘图 QPainter 使用：使用 QPainter 绘制基本形状和文本。 图形视图框架：使用 QGraphicsView 和 QGraphicsScene 进行复杂图形绘制。 容器 标准容器类：使用 QList、QMap、QSet 等容器类存储数据。 模型视图架构：实现与视图组件分离的数据管理。 数据库 Qt SQL 模块：使用 QSqlDatabase 和 QSqlQuery 进行数据库操作。 数据模型与视图绑定：将数据库数据与 UI 组件绑定。 多线程 Qt 线程类：使用 QThread 创建和管理线程。 线程间通信：使用信号与槽进行线程间的数据传递。 网络 网络编程基础：使用 QNetworkAccessManager 进行 HTTP 请求。 TCPIP 通信：实现基本的 TCP 客户端和服务器。 Qt 高级国际化 翻译工具：使用 Qt Linguist 进行应用程序的国际化和本地化。 语言切换机制：动态切换应用程序语言的实现方法。 自定义样式 样式表（QSS）：使用样式表自定义控件外观。 创建自定义样式：通过继承 QStyle 实现完全自定义的控件样式。 三维绘图 Qt 3D 模块：使用 Qt 3D 创建和渲染三维场景。 物理引擎集成：整合物理引擎实现真实感效果。 创建插件 插件架构概述：理解 Qt 的插件机制及其应用场景。 开发与加载插件：创建可动态加载的插件并在应用中使用。 嵌入式编程 嵌入式平台支持：介绍 Qt 在嵌入式系统中的应用，如 Raspberry Pi 等。 优化与调试技巧：针对嵌入式环境的性能优化和调试方法。","categories":["1.语言","Qt"]},{"title":"MIUI下载","path":"/2024/10/26/4-其他-手机相机-MIUI下载/","content":"MIUI 镜像下载缓慢 将原来下载链接中的网址替换为 https://bkt-sgp-miui-ota-update-alisgp.oss-ap-southeast-1.aliyuncs.com/V14.0.8.0.TKKCNXM/haydn_images_V14.0.8.0.TKKCNXM_20231226.0000.00_13.0_cn_de34d63e97.tgz","categories":["4.其他","手机相机"]},{"title":"CAN总线的网络拓扑结构","path":"/2024/09/24/2-通讯协议-CAN-CAN总线的网络拓扑结构/","content":"线性结构线性拓扑结构通常指的是一种基于多点连接的拓扑结构，信号线为 CAN-高电平和 CAN-低电平，两端端接一个 120 欧姆终端电阻，该线路称为主干线，也称为总线。所有的设备连接到共同的传输介质上，总线上任意节点发送信息，其它节点都能收到，这种从主干线分出的短分支线（也称为 stub）。Stub length（分支线长度）是指从主干线到终端节点的短分支线的长度。 根据 CAN 规范和实际工程经验，stub length 的长度应尽量保持短，以减少信号反射和失真。过长的 stub 会导致信号的反射，增加网络中的噪声和误码率。ISO 11898 CAN 标准：建议 stub length 应保持在 0.3 米（30 厘米） 以下。不同的速度对分支线长度的要求可能不同：在 1 Mbps 的速率下，stub length 通常被建议小于 30 厘米。在较低速率下，允许的 stub length 可以稍长，但一般不超过 3 米。 星型结构在 CAN 网络中，多个节点通过各自的分支线连接到一个中心节点或集线器上，由中央节点向目的节点传送信息，中央节点执行集中式通信控制策略。 树型结构 环型结构环形拓扑是将 CAN 总线首尾相接，形成环状，保证线缆的任意位置断开依然可以保证通讯。环形拓扑的终端电阻匹配采用分布式匹配方法，保证总体阻抗为 60 欧姆。 CAN 网络在CAN 总线（Controller Area Network）系统中，CAN 网桥和CAN 网关是两种用于连接多个 CAN 网络的设备，网桥和网关都是为了扩展系统的功能和灵活性，但网桥更关注物理层面的连接和扩展，而网关则在网络层面管理和优化数据传输。 CAN 网桥：用于物理连接不同的 CAN 网络，简单地转发报文，适用于同协议的网络互连，能够解决波特率不同或物理距离受限的问题。 CAN 网关：功能更强大，支持报文过滤、数据处理和协议转换，适用于连接不同协议的网络或需要智能数据管理的场景。 特性 CAN 网桥 CAN 网关 功能 转发 CAN 报文 转发、过滤、处理报文，协议转换 网络连接 连接同协议的 CAN 网络 连接不同协议或不同波特率的网络 报文处理 不修改报文，直接转发 可以修改、过滤或组合报文 应用场景 连接多个 CAN 网络，延长物理距离 连接不同协议网络，过滤数据流 CAN 网桥（CAN Bridge）CAN 网桥是一种用于连接两个或多个 CAN 网络的设备，使它们可以在相同或不同的波特率下进行通信。网桥的主要目的是物理上连接这些网络，透明地转发 CAN 报文，而不做协议转换或处理。 连接不同波特率的 CAN 网络：CAN 网桥允许将运行在不同波特率的 CAN 网络连接起来。例如，一个 CAN 网络可能运行在 1 Mbps，而另一个 CAN 网络可能运行在 500 kbps。CAN 网桥会在这些网络之间转发报文。 透明传输：CAN 网桥通常不改变报文的内容，它只是将接收到的报文从一个 CAN 网络转发到另一个网络。 延长 CAN 网络的物理距离：由于 CAN 总线的物理长度与波特率成反比，网桥可以通过将多个短的 CAN 网络连接在一起，间接增加网络的覆盖范围，而不会超出单个 CAN 网络的距离限制。 CAN 网关（CAN Gateway）CAN 网关是一种智能设备，不仅可以连接多个 CAN 网络，还能执行报文过滤、协议转换、数据处理等功能。相比 CAN 网桥，CAN 网关的功能更加灵活且复杂，它不仅仅是简单地转发数据，还能够根据设定的规则对数据进行转换或过滤。 协议转换：CAN 网关可以连接不同的网络协议，如将 CAN 报文转换为 LIN、FlexRay、Ethernet 等报文格式，并在不同网络之间进行数据交换。 报文过滤和路由：网关可以根据预设的规则对报文进行过滤、路由，即只转发部分符合条件的报文，或修改报文内容后再转发。这可以有效地降低网络负载，并增加数据传输的安全性。 数据处理：CAN 网关可以执行特定的应用逻辑，如根据收到的 CAN 消息执行某些操作，甚至可以将多条消息组合为一条消息再转发。 网络隔离和保护：CAN 网关在连接不同网络时，可以隔离这些网络，防止故障或攻击在不同网络之间传播。","categories":["2.通讯协议","CAN"]},{"title":"华为手机ADB","path":"/2024/09/24/4-其他-手机相机-华为手机ADB/","content":"# 卸载系统应用包adb shell pm uninstall --user 0 com.huawei.hifolder # 卸载竞品推荐,纯广告,卸载!!!adb shell pm uninstall --user 0 com.huawei.educenter # 教育中心Appadb shell pm uninstall --user 0 com.huawei.hiskytone # 天际通Appadb shell pm uninstall --user 0 com.huawei.skytone # 天际通服务adb shell pm uninstall --user 0 com.huawei.gamebox # 游戏中心App,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.game.kitserver # GameKit服务,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.gameassistant # 应用助手服务,其实就是游戏助手,不玩游戏可删!adb shell pm uninstall --user 0 com.huawei.tips # 智能提醒Appadb shell pm uninstall --user 0 com.huawei.android.tips # 玩机技巧Appadb shell pm uninstall --user 0 com.huawei.health # 运动健康Appadb shell pm uninstall --user 0 com.huawei.ohos.health # [HarmongOS]运动健康Appadb shell pm uninstall --user 0 com.huawei.stylus.mpenzone # 手写笔应用专区Appadb shell pm uninstall --user 0 com.huawei.stylus.floatmenu # 手写笔悬浮窗服务adb shell pm uninstall --user 0 com.huawei.wallet # 华为钱包Appadb shell pm uninstall --user 0 com.huawei.wallet.sdk.walletsdk # WalletSDK服务,钱包 SDK 而已adb shell pm uninstall --user 0 com.unionpay.tsmservice # 银联可信服务安全组件,给华为钱包调用的安全组件adb shell pm uninstall --user 0 com.hicloud.android.clone # 手机克隆Appadb shell pm uninstall --user 0 com.huawei.mirror # 镜子Appadb shell pm uninstall --user 0 com.huawei.android.remotecontroller # 智能遥控Appadb shell pm uninstall --user 0 com.huawei.ar.measure # AR 测量adb shell pm uninstall --user 0 com.android.soundrecorder # 录音机Appadb shell pm uninstall --user 0 com.huawei.calculator # 计算器Appadb shell pm uninstall --user 0 com.huawei.android.totemweather # 天气Appadb shell pm uninstall --user 0 com.huawei.email # 电子邮件Appadb shell pm uninstall --user 0 com.huawei.mycenter # 会员中心Appadb shell pm uninstall --user 0 com.huawei.lives # 生活服务Appadb shell pm uninstall --user 0 com.huawei.smarthome # 智慧生活Appadb shell pm uninstall --user 0 com.huawei.ohos.smarthome # [HarmongOS]智慧生活Appadb shell pm uninstall --user 0 com.huawei.hilink.framework # 智慧生活基础服务adb shell pm uninstall --user 0 com.huawei.notepad # 备忘录Appadb shell pm uninstall --user 0 com.vmall.client # 华为商城Appadb shell pm uninstall --user 0 com.huawei.hwireader # 阅读Appadb shell pm uninstall --user 0 com.huawei.welinknow # Link NowAppadb shell pm uninstall --user 0 com.huawei.compass # 指南针Appadb shell pm uninstall --user 0 com.huawei.intelligent # 智慧助手·今天服务,负一屏的垃圾广告adb shell pm uninstall --user 0 com.huawei.magazine # 杂志锁屏adb shell pm uninstall --user 0 com.huawei.hwdetectrepair # 智能检测adb shell pm uninstall --user 0 com.huawei.phoneservice # 我的华为Appadb shell pm uninstall --user 0 com.huawei.hwblockchain # 华为区块链????,这... ...删了吧!adb shell pm uninstall --user 0 com.huawei.search # 智慧搜索adb shell pm uninstall --user 0 com.huawei.searchservice # 融合搜索服务adb shell pm uninstall --user 0 com.huawei.ohos.search # [HarmongOS]全局搜索数据服务adb shell pm uninstall --user 0 com.huawei.meetime # 畅连Appadb shell pm uninstall --user 0 com.huawei.hwvoipservice # 畅连服务adb shell pm uninstall --user 0 com.huawei.android.findmyphone # 查找设备Appadb shell pm uninstall --user 0 com.huawei.videoeditor # 视频编辑adb shell pm uninstall --user 0 com.huawei.himovie # 华为视频Appadb shell pm uninstall --user 0 com.huawei.himovie.partner1adb shell pm uninstall --user 0 com.huawei.himovie.partner2adb shell pm uninstall --user 0 com.tencent.qqlivehuawei # 华为视频App - 腾讯视频模块adb shell pm uninstall --user 0 com.sohu.sohuvideo.emplayer # 华为视频App - 搜狐视频模块adb shell pm uninstall --user 0 com.android.mediacenter # 华为音乐Appadb shell pm uninstall --user 0 com.huawei.scenepack # 旅行助手adb shell pm uninstall --user 0 com.huawei.hicard # HiCard卡片服务adb shell pm uninstall --user 0 com.huawei.hicar # HiCar汽车服务adb shell pm uninstall --user 0 com.huawei.android.karaoke # K 歌特效adb shell pm uninstall --user 0 com.huawei.featurelayer.sharedfeature.xrkit # XRKitadb shell pm uninstall --user 0 com.huawei.arengine.service # AREngineServer华为 AR 引擎服务adb shell pm uninstall --user 0 com.huawei.audioaccessorymanager # 音频产品管家adb shell pm uninstall --user 0 com.huawei.waudio # WAudios,不知是啥!adb shell pm uninstall --user 0 com.huawei.multimedia.audioengine # HwAudioKit,不知是啥!adb shell pm uninstall --user 0 com.android.simappdialog # SIM App Dialogadb shell pm uninstall --user 0 com.android.stk # SIM 卡应用Appadb shell pm uninstall --user 0 com.huawei.android.thememanager # 主题App,更换完主题就删除,用的时候在华为应用商店安装就行了;adb shell pm uninstall --user 0 com.huawei.browser # 华为浏览器App,推荐 Edge 浏览器,别用夸克了,太和谐了!adb shell pm uninstall --user 0 com.huawei.hidisk # 华为云空间adb shell pm uninstall --user 0 com.huawei.hicloud # 华为云空间服务adb shell pm uninstall --user 0 com.huawei.privatespace # 隐私空间adb shell pm uninstall --user 0 com.huawei.securitymgr # 隐私空间adb shell pm uninstall --user 0 com.huawei.calendar # 华为日历Appadb shell pm uninstall --user 0 com.android.providers.calendar # 日历存储adb shell pm uninstall --user 0 com.android.deskclock # 华为时钟Appadb shell pm uninstall --user 0 com.baidu.input_huawei # 百度输入法adb shell pm uninstall --user 0 com.huawei.ohos.suggestion # 小艺建议adb shell pm uninstall --user 0 com.huawei.pengine # 华为智能建议adb shell pm uninstall --user 0 com.huawei.spaceservice # 华为地理围栏服务,其实就是精准推送广告adb shell pm uninstall --user 0 com.huawei.fastapp # 华为快应用中心adb shell pm uninstall --user 0 com.huawei.localBackup # 华为备份adb shell pm uninstall --user 0 com.huawei.easygo # 华为EasyGo SDK,给折叠屏用的;adb shell pm uninstall --user 0 com.huawei.trustspace # 华为支付保护中心adb shell pm uninstall --user 0 com.huawei.featurelayer.sharedfeature.map # 华为地图服务adb shell pm uninstall --user 0 com.huawei.featurelayer.featureframework # Feature Frameworkadb shell pm uninstall --user 0 com.huawei.hiai # 华为智慧引擎adb shell pm uninstall --user 0 com.huawei.hiaction # 华为HUAWEI HiAI Base 基础服务adb shell pm uninstall --user 0 com.huawei.recsys # 华为智慧引擎adb shell pm uninstall --user 0 com.huawei.vassistant # 华为智慧语音adb shell pm uninstall --user 0 com.huawei.contactscamcard # 扫名片adb shell pm uninstall --user 0 com.huawei.hitouch # 华为智慧识屏adb shell pm uninstall --user 0 com.huawei.vrservice # 华为 VR 服务adb shell pm uninstall --user 0 com.huawei.motionservice # 华为手势服务adb shell pm uninstall --user 0 com.huawei.devicemanager # 华为智慧协同adb shell pm uninstall --user 0 com.huawei.android.airsharing # 华为无线投屏adb shell pm uninstall --user 0 com.huawei.suggestion # 华为情景智能adb shell pm uninstall --user 0 com.huawei.scanner # 华为智慧视觉adb shell pm uninstall --user 0 com.huawei.pcassistant # 华为分享adb shell pm uninstall --user 0 com.huawei.android.instantshare # 华为分享adb shell pm uninstall --user 0 com.huawei.android.wfdft # WLAN 直连adb shell pm uninstall --user 0 com.huawei.android.FloatTasks # 华为悬浮导航adb shell pm uninstall --user 0 com.huawei.printservice # 华为打印adb shell pm uninstall --user 0 com.huawei.nearby # 华为HwNearby附近服务adb shell pm uninstall --user 0 com.bjbyhd.screenreader_huawei # 华为屏幕朗读服务adb shell pm uninstall --user 0 com.huawei.securityserver # 华为安全公共服务adb shell pm uninstall --user 0 com.huawei.filemanager # 华为文件管理,推荐 MT管理器adb shell pm uninstall --user 0 com.huawei.desktop.explorer # 华为我的文件adb shell pm uninstall --user 0 com.android.providers.downloads # 下载管理adb shell pm uninstall --user 0 com.android.providers.downloads.ui # 下载管理 UIadb shell pm uninstall --user 0 com.huawei.assetsync # 华为关键资产同步adb shell pm uninstall --user 0 com.huawei.assetsyncservice # 华为关键资产同步服务adb shell pm uninstall --user 0 com.huawei.contacts.sync # 华为联系人同步adb shell pm uninstall --user 0 com.huawei.airlink # 华为Air Linkadb shell pm uninstall --user 0 com.huawei.rcsserviceapplication # 华为 RCS 服务,同华为手机的免费短信adb shell pm uninstall --user 0 com.huawei.bluetooth # 华为通过蓝牙导入adb shell pm uninstall --user 0 com.huawei.trustagent # 华为智能解锁adb shell pm uninstall --user 0 com.huawei.hwbluetoothpencilmanager # 华为蓝牙触控笔管理adb shell pm uninstall --user 0 com.iflytek.speechsuite # 讯飞语音引擎adb shell pm uninstall --user 0 com.huawei.ohos.famanager # [HarmongOS]华为服务中心adb shell pm uninstall --user 0 com.android.sharedstoragebackup # 共享存储备份adb shell pm uninstall --user 0 com.huawei.hwpanpayservice # 华为息屏支付adb shell pm uninstall --user 0 com.huawei.hwdiagnosis # 华为检测/诊断adb shell pm uninstall --user 0 com.huawei.controlcenter # 华为超级终端adb shell pm uninstall --user 0 com.huawei.multimedia.hivideoplayengine # 华为视频开发引擎adb shell pm uninstall --user 0 com.huawei.regservice # 华为注册服务adb shell pm uninstall --user 0 com.huawei.trustedthingsauth # 华为可信认证跳过adb shell pm uninstall --user 0 com.huawei.synergy # 华为协同adb shell pm uninstall --user 0 com.huawei.coauthservice # 华为联合认证echo ===========================系统精简结束===========================第八步：进行一下动画和帧数的优化adb shell settings put global window_animation_scale 0.96adb shell settings put global transition_animation_scale 0.96adb shell settings put global animator_duration_scale 0.43adb shell wm density 480 关闭系统更新 adb shell pm disable-user com.huawei.android.hwouc卸载前先调整部分设置。比如智慧多窗默认是开启的，要先关闭，否则会残留手势。智慧助手 adb shell pm uninstall --user 0 com.huawei.intelligent智慧搜索 adb shell pm uninstall --user 0 com.huawei.search情景智能 adb shell pm uninstall --user 0 com.huawei.suggestion智慧识屏 adb shell pm uninstall --user 0 com.huawei.hitouch智慧视觉 adb shell pm uninstall --user 0 com.huawei.scanner智慧语音 adb shell pm uninstall --user 0 com.huawei.vassistant智慧多窗 adb shell pm uninstall --user 0 com.huawei.hwdockbar华为钱包 adb shell pm uninstall --user 0 com.huawei.wallet华为钱包kit工具 adb shell pm uninstall --user 0 com.huawei.wallet.sdk.walletsdk华为钱包安全支付 adb shell pm uninstall --user 0 com.huawei.hwpanpayservice支付保护中心 adb shell pm uninstall --user 0 com.huawei.trustspace畅联通话 adb shell pm uninstall --user 0 com.huawei.hwvoipservice天际通 adb shell pm uninstall --user 0 com.huawei.hiskytone天际通数据服务 adb shell pm uninstall --user 0 com.huawei.skytone智慧生活 adb shell pm uninstall --user 0 com.huawei.smarthome智慧生活基础服务 adb shell pm uninstall --user 0 com.huawei.hilink.framework百度输入法华为版 adb shell pm uninstall --user 0 com.baidu.input_huawei腾讯视频华为版 adb shell pm uninstall --user 0 com.tencent.qqlivehuawei应用助手 adb shell pm uninstall --user 0 com.huawei.gameassistant快应用中心 adb shell pm uninstall --user 0 com.huawei.fastapp浏览器 adb shell pm uninstall --user 0 com.huawei.browser华为汽车 adb shell pm uninstall --user 0 com.huawei.hicar杂志锁屏 adb shell pm uninstall --user 0 com.huawei.magazine华为主题 adb shell pm uninstall --user 0 com.huawei.android.thememanager服务中心 adb shell pm uninstall --user 0 com.huawei.ohos.famanager小艺建议 adb shell pm uninstall --user 0 com.huawei.ohos.suggestion","categories":["4.其他","手机相机"]},{"title":"利用chardet识别文件编码","path":"/2024/09/23/1-语言-Python-利用chardet识别文件编码/","content":"常见编码格式 ASCII, UTF-8, UTF-16 (2 variants), UTF-32 (4 variants)Big5, GB2312, EUC-TW, HZ-GB-2312, ISO-2022-CN (Traditional and Simplified Chinese)EUC-JP, SHIFT_JIS, CP932, ISO-2022-JP (Japanese)EUC-KR, ISO-2022-KR (Korean)KOI8-R, MacCyrillic, IBM855, IBM866, ISO-8859-5, windows-1251 (Cyrillic)ISO-8859-5, windows-1251 (Bulgarian)ISO-8859-1, windows-1252 (Western European languages)ISO-8859-7, windows-1253 (Greek)ISO-8859-8, windows-1255 (Visual and Logical Hebrew)TIS-620 (Thai) 测试代码 import chardetopen_file = open(file=miui.cpp,mode=rb) # 以二进制模式读取文件data = open_file.read() # 获取文件内容print(data) open_file.close() # 关闭文件result = chardet.detect(data) # 检测文件内容print(result) #encoding: utf-8, confidence: 0.99, language: 输出结果 encoding: utf-8 表示检测到文件的编码格式为utf-8confidence: 0.99 表示可信度为百分之九十九language: 表示文件内容的语言","categories":["1.语言","Python"]},{"title":"相机参数","path":"/2024/09/11/4-其他-手机相机-相机参数/","content":"光圈、快门、ISO、景深 光圈：光圈的大小直接影响镜头的光线进入量。光圈用 f 值表示，f 值越小，光圈越大。例如，f2.8 的光圈比 f8 的光圈大得多，这意味着在相同时间内，大光圈可以让更多光线进入相机，从而在低光环境中拍摄更加清晰明亮的照片。此外，大光圈还会产生更加柔和的背景虚化效果，这在拍摄人像时尤其受欢迎，能将主体突出。 快门：快门速度是影响运动物体拍摄效果的重要因素。如果快门速度过慢，比如设置在 1 秒，任何移动的物体都可能出现拖影或模糊现象。例如，在拍摄运动员奔跑的瞬间，快门速度应至少选择 1500 秒以上，以确保捕捉到清晰的动态瞬间。因此，快门速度对图像清晰度和动感的表现至关重要。 ISO：ISO 设置代表了相机传感器对光线的敏感程度。ISO 值越高，例如 ISO 1600，传感器对光线更加敏感，能在暗光环境下拍摄，但同时也会引入更多的噪点，使得画质下降。比如，在昏暗的酒吧里拍摄时提高 ISO 可以让你捕捉到更多细节，但画面可能会出现明显的颗粒感，影响整体视觉效果。因此，选择合适的 ISO 是获得理想画质的关键。 景深：景深是指在照片中清晰的范围。一方面，深景深（如 f11）的光圈能够让前景和背景都清晰，适合拍摄风景照；另一方面，浅景深（如 f2.8）则使得背景模糊，适合专注表现主体，常用于人像摄影。通过合理控制景深，摄影师可以引导观众的注意力，创造出更具艺术感的作品。","categories":["4.其他","手机相机"]},{"title":"ARINC825","path":"/2024/09/10/3-软件-航电-ARINC825/","content":"ARINC825 协议栈ARINC825 规范全称为机载 CAN 网络通用标准（The General Standardization of CAN for Airborne Use）。顾名思义，ARINC825 规范是建立在 CAN 物理网络基础上的高层规范。ARINC825 协议物理层和数据链路层与 CAN 总线基本一致，而在网络层则增加了特殊的路由寻址、数据包封装和流速控制等功能；并在传输层引入了逻辑信道划分与数据包重发等功能。 物理层接口为了确保可靠的通信，ARINC825 的电气特性、总线收发条件、数据率等规定均符合 ISO 11898 标准。规范中还特别强调了每一位的时序计算及电磁兼容性。ARINC825 支持以下数据率：1Mbs、500Kbs、250Kbs、125Kbs 及 83.333Kbs。 定义了三种通信模型 用于广播消息的一对多格式 用于定向节点点对点通信的定向消息传递（使用节点寻址和端口定义） 用于节点服务的点对点格式（用于 CS 类型服务的点对点通信） 概览数据帧一对多格式定向消息点对点周期性健康消息节点服务数据载荷健康消息数据载荷带宽高完整性协议高可用性消息总线拓扑结构通信网络设计报文传输模式和 ID 结构ARINC825 规范对 CAN 2.0B 扩展帧的 29 位标识进行了划分。其中高 3 位被用于逻辑通信通道（Logical Communication Channels, LCC）标识，按优先级从高到低依次为异常事件通道（EEC）、正常工作通道（NOC）、节点服务通道（NSC）、用户自定义通道（UDC）、测试与维护通道（TMC）及 CAN 基本帧兼容通道（FMC）。其中 EEC 和 NOC 通道用于多播（Any-to-Many）通信，NSC 和 TMC 通道用于端到端（Peer-to-Peer）通信。 ARINC825 协议支持 ATM（Anyone to Many）和 PTP（Peer to Peer）两种传输模式，报文一般采用 29 位扩展 ID，并实现了逻辑信道（LLC）的定义与划分，具体如表 4-1 所示。而且，ARINC825 协议的报文结构又按照传输模式不同而有所区别。 ATM 模式ATM 模式是传统的 CAN 总线收发模式，通信节点间为对等关系，采用广播方式发送数据，并按照报文 ID 进行逐位仲裁和屏蔽接收，其报文 ID 域结构如图所示，包括功能标识（Function ID, FID）、区域标识（Local, LCL）、加密标识（Private, PVT）、数据对象代码（Data Object Code, DOC）和冗余标识（Redundancy Channel Identifier, RCI）。 ATM 通信的优势在于能够与网络中所有的节点建立持续的数据链接，但是 ATM 需要处理非自身的数据包，增加了接收节点的工作量。 PTP 模式PTP 模式则扩展了是传统的 CAN 总线收发模式，允许网络中任意两个节点间采用基于客户端服务器（ ClientServer ）的面向连接或无连接两种通信方式，其报文 ID 域结构如图所示，可支持 512 个不同的服务器节点和 128 种不同的服务类型。 Server FID(Function ID) + SID(Server ID) +RCI 部分统称为 NID（Node ID） 高度完整性协议ARINC825 协议针对系统控制器受到干扰时可能产生的错误，在 CAN2.0B 故障检测机制的基础上，加入了高度完整性协议（High Integrity Protocol）。如图 4-4 所示，该协议以减少数据载荷为代价，引入 MIC 校验码与 SN 号，对报文正确性及完整性进行验证。 数据域消息格式，共包含 8bytes，前 5bytes 为有效数据载荷，第 6byte 为 SN 码，即消息序列号，第 7-8bytes 为 MIC，及数据完整性校验结果 高完整性校验范围，共包含 12bytes，即 29bits 的帧 ID，3bits 的补充位，8bytes 的数据域 处理时，先设置每个节点独立的消息序列号 按照高完整性校验范围，依次逐字节进行高完整性校验运算，得到 16bits 的 CRC 码作为数据完整性校验结果 带宽管理传统的 CAN 总线协议是基于多主竞争下的位仲裁机制来管理总线的访问权和带宽，优先级较高的数据帧可以连续不受制约地访问总线，在总线载荷繁重时会造成低优先级数据帧较大的不确定延时。 ARINC825 引入时间触发总线调度技术，时间触发总线调度控制基于两个概念，Major Frame（主时间帧）和 Minor Frame（基本时间帧）。整个网络的数据传输周期（在一个周期内，每个数据包至少能得到一次传输机会）称为一个 主时间帧，它包含若干个基本时间帧 。Minor Frame 是总线中传输频率最 大的帧的周期，是 ARINC825 规范中进行带宽管理的最小时间单位。 同一时间帧内的数据帧采用多主竞争发送，只要控制总线中各个节点在基本时间帧内的发送，就可以保证总线节点间通信的确定性。 计算总线负载时，需要选取一个时间片段进行分析，使用时间间隔最小的基本时间帧作为发送间隔（Transmission Interval），可以计算出最大的总线负载。 ARINC 825 网络节点设计分为处理端，控制端和收发端 处理端接收由传感器等设备采集到并发送过来的消息，并将接收到的消息进行处理，处理后的消息满足 CAN 和 ARINC825 网络的确定性和完整性要求 时间片管理模块 规划时间片通信调度机制：所有节点具有相同的主时间片和次时间片，主时间片包括若干次时间片和空闲时间窗(也称为仲裁窗)，每个次时间片的时间长度不小于系统内所有的节点依次进行总线竞争的时间，主时间片是当前系统周期消息的最大周期发送时间，即周期消息刷新时间，且次时间片是主时间片的偶分数。 消息接收和处理模块 通过给定的时间片，接收传感器等设备的消息并进行格式化处理 通过给定的时间片，接收控制端返回的消息并进行格式化处理 消息完整性校验模块 进行高度完整性校验，步骤见 高度完整性协议 片外 SDRAM 控制模块 存储格式化处理后的消息和完整性校验的校验结果，按照格式化的消息，独立的帧 ID，完整性校验的校验结果进行分别存储 串口通信模块 将处理完成的消息发送给控制端 控制端控制端通过热冗余进行数据的收发，以满足 ARINC825 的可用性要求 双链路冗余模式，每个节点第一主节点的消息均发送到同一个 ARINC825_A 总线中，第二主节点的消息均发送到同一个 ARINC825_B 总线中 系统中存在两条独立的通信链路，用于传输相同的数据或执行相同的任务。这两条链路同时工作，当其中一条链路出现故障时，另一条链路可以继续传输数据或执行任务，从而保证系统的正常运行。 双链路节点混合冗余模式，每个节点第一主节点的消息混合发送到两路 ARINC825 总线中 ，若干节点的第一主节点的消息交替发送至 ARINC825_A 和 ARINC825_B 总线中，同时节点中的第二主节点的消息发送至另一路 ARINC825 总线中。 系统中不仅存在两条独立的通信链路，而且每个链路中的节点也可能存在冗余配置 冗余是指重复配置系统的一些部件，当系统发生故障时，冗余配置的部件介入并承担故障部件的工作，由此减少系统的故障时间。热备是一种备份方式，即系统中存在一个主设备处于运行状态，同时有一个备份设备也处于通电运行状态（但可能未承担主要工作任务），随时准备在主设备出现故障时立即接管工作。 收发端直接和总线进行交互 网关处理同步网关发送参考消息，总线上各节点接收到参考消息后，时间基准归零。保证总线上所有节点具有相同的主时间片和基本时间片，主时间片包含若干基本时间片和空闲时间窗口。基本时间片的时间长度不小于系统内所有节点同时进行总线竞争所需的总时间。基本事件片分为同步相和异步相，同步相用于传输周期性消息，异步相用于传输非周期性消息竞争，空闲时间窗口用于传输非周期性消息。 在 ARINC 825 规范中，主次时间帧的同步通常由 CAN 网络中的网关或中央控制节点发出同步信号，以确保所有节点的时间帧保持一致。然而，除了由网关发起的同步信号外，还有其他几种方式可以实现主次时间帧的同步或协调，具体如下： 分布式时钟同步 一种方式是通过分布式时钟同步机制，让各个节点根据共同的参考时钟（如 GPS、PTP）来协调其本地时钟。每个节点可以定期接收时钟校准信号，从而调整其主次时间帧，使其与网络中的其他节点保持一致。这个方法适用于大规模系统，特别是在需要精准同步的应用中。 事件驱动同步 另一种方法是通过特定事件或消息的触发来实现同步。比如，当某一特定节点发送一个关键消息时，其他节点可以根据这个事件作为触发信号来调整自身的主次时间帧。这种方式可以适应系统中具有异步特性的操作场景。 静态调度表 在某些系统中，可以使用静态调度表来提前规划好所有节点的时间帧。每个节点在设计时就被赋予了固定的时间周期，用于发送或接收数据。这种方法通常用于具有固定通信模式的实时系统。所有节点根据预定义的调度表来操作，而不依赖动态的同步信号。 分层架构同步 在复杂的系统中，可能会使用分层架构来实现时间同步。一个高级别的控制节点可以管理主时间帧的同步，而次时间帧可以由各个子网络或次节点自己管理。这种架构可以减少中央节点的同步负担，提供一定的灵活性。 自主同步的节点 在某些情况下，系统中的每个节点可以自主管理自己的主次时间帧，而无需依赖中央同步。每个节点可以根据自己内部的调度机制来划分主次时间帧，只要确保与其他节点的通信在规定的窗口内进行即可。这种方式适合一些分布式系统，节点间的时间不需要严格同步，而只需要在某些时刻进行协调。 多网关同步 当网络规模较大或具有不同功能区块时，可能会使用多个网关或中央控制单元。这些网关分别负责自己区域的同步任务，而通过跨网关的通信来确保整个网络的主次时间帧协调。这种方式可以增加系统的可靠性和扩展性。 自主主次时间帧的实现理论上，可以让各个节点自主使用自己的主次时间帧，但这取决于应用场景的具体需求。在一些情况下，这种分布式时间管理可以简化系统设计，但会增加节点之间的协调难度，尤其是在高实时性要求的系统中。如果各个节点的主次时间帧不严格同步，可能会导致数据传输延迟、不一致或数据丢失的问题。因此，节点自主时间帧的应用需要谨慎考虑网络拓扑结构、消息优先级和通信窗口的合理分配。","categories":["3.软件","航电"]},{"title":"CPU参数说明","path":"/2024/09/02/0-平台-Linux-系统参数-CPU参数说明/","content":"在 Linux 系统中使用 top 命令查看 CPU 相关参数时有以下内容 us: “user CPU time” 用户空间占用 CPU 百分比 sy: “system CPU time” 内核空间占用 CPU 百分比 ni: is meaning of” nice CPU time” 用户进程空间内改变过优先级的进程占用 CPU 百分比 id: “idle” 空闲 CPU 百分比 wa: “iowait” 等待输入输出的 CPU 时间百分比即等待磁盘写入完成时间 hi：”hardware irq” 硬件中断消耗时间 si : “software irq” 软件中断消耗时间 st : “steal time” 分配给其他虚拟机的时间 使用率 CPU 在处理任务时所花费的时间占总时间的比例。可以通过以下公式计算： CPU 使用率 = us + sy + ni + hi + si 这表示了 CPU 忙于实际处理任务的时间，不包括空闲时间（id）和 IO 等待时间（wa）。 负载负载通常指的是系统的任务排队情况，也就是在等待 CPU 处理的进程数。它通常由操作系统的负载均衡器来计算，考虑到运行队列中的任务数量和平均等待时间。 CPU 负载需要结合任务队列长度、等待时间以及 CPU 调度情况来衡量，可以通过 uptime、w 命令查看 CPU 平均负载，使用 top 命令还能看到 CPU 负载总体使用率以及各个进程占用 CPU 的比例。 如果单核 CPU 的话，负载达到 1 就代表 CPU 已经达到满负荷的状态了，超过 1，后面的进行就需要排队等待处理了。如果是多核多 CPU，假设现在服务器是 2 个 CPU，每个 CPU 有 2 个核，那么总负载不超过 4 都没什么问题。 参数查看查看物理 CPU 个数 cat /proc/cpuinfo| grep “physical id”| sort | uniq| wc -l 查看每个物理 CPU 中 core 的个数(即核数) cat /proc/cpuinfo| grep “cpu cores” | uniq 查看逻辑 CPU 的个数 cat /proc/cpuinfo| grep “processor”| wc -l 负载高利用率低CPU 负载很高，利用率却很低，说明处于等待状态的任务很多，负载越高，代表可能很多僵死的进程。通常这种情况是 IO 密集型的任务，大量任务在请求相同的 IO，导致任务队列堆积。 负载低利用率高这表示 CPU 的任务并不多，但是任务执行的时间很长，大概率就是你写的代码本身有问题，通常是计算密集型任务，生成了大量耗时短的计算任务。 通过 top 找到 CPU 占用率高的进程 通过 top -Hp pid 命令查看 CPU 占比靠前的线程 ID 再把线程 ID 转化为 16 进制，printf “0x%x ” 74317，得到 0x1224d 在比对程序中的线程 ID 找到有问题的部分","categories":["0.平台","Linux","系统参数"]},{"title":"航电系统的平台说明","path":"/2024/09/02/3-软件-航电-航电系统的平台说明/","content":"航电系统航空电子系统是完成飞行任务相关功能的子系统，由无线电通信、导航、自动驾驶和显示管理等多个系统构成，包括机载计算机及在其之上运行的软件、通讯、传感器、控制器等。 航电系统先后经历了分立式，联合式，综合式和高度综合式四个阶段。 综合模块化航空电子系统（Integrated Modular Avionics，IMA）是目前航电系统体系中的典型结构。 综合模块化航空电子系统开发过程的指南文件 DO-297 中对 IMA 的定义是:“IMA 是一组灵活的、可重用的、可互操作的共享硬件和软件资源,当把这些资源综合在一起时可以构建一个平台,该平台按一组确定的安全和性能需求进行设计和验证,能提 供各种服务,并驻留执行飞机功能的应用”，通俗的来说，IMA 结构的主要功能是将多个功能独立的机载设备作为整体统一考虑，在模块级进行综合集成。IMA 平台适航审定的各适航标准之间的相互支撑关系如图。 在 IMA 结构中，以驻留在 IMA 系统的飞行管理系统为例，其飞机功能分配到 IMA 系统的功能性能需求层次结构如图。最顶层的任务描述与最底层的设计实现从不同的角度描述了同一个飞机功能。 顶层是从飞机级任务的角度抽象地描述整个飞机的预期操作 底层的设计实现层则是从软硬件设计实现的角度,描述飞机级任务的最终实现 “设计实现层”描述的是具体的设计”需求”,可以逐级向上追溯到最顶层的”任务”描述,即最底层的需求是从最顶层的任务分解而捕获到的 行业标准针对 IMA 体系结构，常用行业标准和推荐实践包括: RTCA (Radio Technical Commission for Aeronautics) RTCA 是美国的标准组织，负责制定航空领域的最低操作性能标准（MOPS）和最低航空系统性能标准（MASPS）。RTCA 制定的标准用于 FAA 的技术标准命令（TSO），从而使设备符合 FAA 认证。 DO-178C：软件认证标准，规定了航空软件的开发和验证过程，确保其安全性和可靠性。 DO-254：硬件设计和开发标准，特别针对航空电子设备中的复杂电子硬件（如 FPGA 和 ASIC）。 DO-297：由 RTCA 提出的指南，提供了 IMA 系统的开发、集成和认证的框架。该标准阐明了模块化航空电子系统的开发流程和认证要求。 EUROCAE (European Organisation for Civil Aviation Equipment) EUROCAE 是欧洲的标准制定组织，类似于 RTCA，主要服务于欧洲民航局（EASA）的认证需求。 ED-12C：与 RTCA DO-178C 相同，是航空软件开发的欧洲标准。 ED-80DO-254：航空电子设备中的硬件开发标准。 SAE (Society of Automotive Engineers) SAE 是汽车和航空领域的标准组织，覆盖从汽车到航空航天等多领域的技术和安全标准。SAE 的标准在航空电子、自动驾驶汽车等领域有广泛应用。 ARP4754A：航空系统开发标准，规定了复杂航空系统的开发流程。 ARP4761：航空系统安全性评估标准，结合失效模式与影响分析（FMEA）和故障树分析（FTA）来评估系统的安全性。 ARINC (Aeronautical Radio, Inc.) ARINC 是一个航空标准组织，制定航空电子设备的互联互通和规范标准，广泛用于航空公司和航空制造商之间的设备兼容性。 ARINC 429：航空电子设备之间的数字数据通信协议，广泛用于商业航空系统中的航电通信。 ARINC 653：实时操作系统（RTOS）的标准接口，广泛应用于航空嵌入式系统，特别是分区多任务操作系统。 ARINC 661：航空座舱显示系统的标准接口，规定了用户界面和座舱显示器的设计标准。 ARINC 664：与以太网兼容的航空网络标准，适用于现代航空网络通信，特别是 AFDX（Avionics Full-Duplex Switched Ethernet）网络。 ARINC 818：用于航空系统视频传输的协议。 IMA 系统作为体系结构定义了应用分区概念，ARINC 653 是为 IMA 设计的一个关键标准，定义了分区操作系统的接口标准。规定了在航空电子系统中如何实现时间和空间分区，以确保不同应用程序之间的隔离，防止它们相互干扰。符合 ARINC653 规范的 IMA 架构从上而下划分为应用软件、实时操作系统(Real-Time Operating Systems, RTOS)、硬件三个层级，层级之间通过虚拟的接口层进行交互。 空间分区：当某一个分区的应用软件发生错误或故障时不会影响其他分区内应用软件的正常运行 时间分区：系统会提供相对完整独立的时间窗口给系统中的各个分区进行调度，每一个分区都有自己对应的一个或多个时间片，只有当轮到该分区的时间片时，才会激活并被操作系统调用并运行，以确保时间维度上的确定性 应用软件 操作系统ARINC653 标准航 电 应 用 软 件 标 准 接 口 653（AvionicsApplication Software Standard Interface 653，ARINC653）是一种嵌入式操作系统应用程序接口标准，目前是国际上在飞行器软件方面比较通行的软件运行标准。 在 ARINC653 标准中定义了一个主时间帧，再将主时间帧中分成多个小时间段，每个时间段分配给一个应用程序进程执行。随着航空软件系统的执行，主时间帧周而复始运行，使各个应用程序进程都能有效获得硬件资源。同时，由于每个进程只会在分配的小时间段中执行，从而避免了在时间上多个进程同时执行造成的相互影响。与小时间段相对应，利用处理器存储器管理单元（Memory Management Unit，MMU）、存储器控制器分区（bank）控制等硬件技术，每个应用程序进程运行时使用相互独立的一段存储器，从而避免了在存储器空间上多个进程同时执行造成的相互影响。 ARINC653 通过使应用软件中的各进程在时间和空间上同时分开获得了较高的软件运行安全性，有效控制了进程发生错误的影响范围，避免了因为某一进程发生错误时威胁到整个航空软件系统运行，进而威胁到飞行器安全飞行的情况发生。 ARINC653 的详细接口实现见 ARINC653 FACE 标准未来机载能力环境（Future Airborne Capability Environment，FACE）在 2010 年由美国海军航空系统司令部发起、开源组织（OpenGroup）提出，其策略是在己安装好硬件的军用航电平台上建立软件通用操作环境，使 FACE 组件应用在不同平台上时可被重新部署，从而实现跨平台的可移植性和重用性。 FACE 采用“分段式”架构，自顶向下分为操作系统段、IO 服务段、平台特定服务段、传输服务段和可移植组件段，每个段间的接口都进行了标准化定义，使得基于 FACE 标准的应用系统可以从任意一个段间接口开始设计具有自身特色功能段。相比 ARINC653 中只定义了应用程序分时分区使用硬件的软件接口，FACE 标准包含了应用程序从顶层通用服务到底层 IO 的全部内容，制定了应用程序各组件的标准化接口，为应用程序赋予了可移植性、开放性和灵活性，大幅提高了电子系统设计的便利性，为航电设备即插即用等应用场景提供了有效技术支撑。 系统架构简介嵌入式操作系统（Embedded Operating System）是一种运行在嵌入式系统硬件上的基础软件，其基本功能是对硬件进行有效管理并对硬件进行一定程度的抽象以便应用软件调用。在军工领域，嵌入式操作系统在具备基本功能的基础上，还需要具有实时性（Real-time）、安全性（Security Safety）等特点。 主流使用的嵌入式操作系统美国 欧洲 日本 国内自研且有军工应用 国内自研 符合 ARINC653 的 OS 国内外 OS 安全认证 操作系统调度单核处理器调度算法在单核处理器中，每次调度只有一个任务在运行，只有等待当前任务结束或该任务的时间片结束后才能切换到下一任务运行，追求 CPU 利用率和吞吐率的最大化，关于 CPU 利用率等参数见 CPU参数说明 先到先服务（First-Come, First-Served，FCFS） FCFS 是一种广泛使用而又相对简单的调度算法，其采用的是先进先出（First-Input,First-Output，FIFO）队列。任务从 FIFO 队列头部开始顺次分配给处理器执行，任务执行完成后便从队首删除，并从队首取出新的任务执行。而当某一任务准备就绪后便将该任务链接到 FIFO 队列的队尾，如此循环往复的执行。FCFS 是一种非抢占式的任务调度算法，其优点是简单易懂，缺点则是缺乏灵活性，任务执行效率低下。 最短作业时间（Shortest-Job-First，SJF） SJF 是指对处理时间短的任务优先进行调度运行，其拥有可抢占与非抢占两种调度模式。这是种可以极大缩短调度的平均等待时间的调度方案，但遗憾的是这仅仅只是一种理想的方案，因为计算机是很难预先知道随机任务运行所需要占用处理器的时间。 优先权调度（Priority） 优先权调度指的是系统会按照某种权值分配策略来给每个任务分配一个对应的权值，以此来衡量任务的优先级别，优先级别最高的任务最先分配给处理器进行执行，对于具有相同优先级别的任务，将其按照 FCFS 的顺序来进行执行。以上讲到的 SJF 调度算法便是优先权调度的一个特例，其权值分配策略为任务运行时间的倒数。 轮转法调度（Round Robin，RR） RR 算法是在 FCFS 算法中加入时间片抢占策略而形成的，是对 FCFS 算法的优化。在任务调度过程中，如果任务 A 的运行时间小于设定的时间片，则会自动释放处理器；反之，如果任务 A 的运行时间大于时间片，则系统会产生定时器中断，先保存任务 A 的执行状态文件，然后将其添加到 FIFO 队列的尾部；与此同时，系统会从 FIFO 队列的队首调出任务 B 来进行执行。RR 调度算法的性能与时间片大小有着直接的关系，当时间片选取过小时，单位时间里进行任务切换的次数就会变多，从而增加系统的内存消耗，影响系统任务调度的效率；与之相反，当时间片选取无限大时，对于大量使用 RR 调度算法的任务来说，其调度效率趋同与 FCFS 算法，容易造成任务的阻塞。因此使用 RR 算法进行任务调度时，选择适当长度的时间片非常重要。 多队列调度（Multilevel Queue） 多队列调度是一种两层的调度模型，其将所有的任务划分为多个任务队列，先以任务队列为调度单元，队列之间采用某种合适的调度算法。再以队列中的任务为调度单元，在每一个队列内部采用某种合适的调度算法。 多级反馈队列（Multilevel Feedback Queue） 多级反馈队列调度是一种广泛使用却异常复杂的调度算法，它是对多队列调度算法的优化。在多队列调度中，任务分配到某队列后便固定不能进行移动，导致任务调度过程缺乏灵活性。而在多级反馈队列调度中，优化了这种固定的设计，允许任务在队列中进行移动，提高了调度的灵活性与高效性。 ARINC653 调度在 ARINC653 标准的实现中，分为分区调度和分区内的进程调度： 分区间调度： 采用 轮转法调度（Round Robin，RR），通过固定长度的时间片按循环顺序分配处理器时间，实现了各分区的公平和隔离。 分区内进程调度： 采用 优先权调度（Priority Scheduling），根据进程的优先级分配执行顺序，确保关键任务的实时性和响应速度。 关于分区调度的实现和流程见 运行流程 多核处理器调度算法多核任务调度典型应用模式： 对称多处理（Symmetric Multi-Processing，SMP） SMP 模式是指同一个核心操作系统映像负责协调所有处理器核上的任务调度工作，在这种模式下，所有的分区任务允许动态分配到任何空闲的处理器核上进行执行，可以更好的实现负载均衡性。 非对称多处理（Asymmetric Multi-Processing，AMP） AMP 模式是指某一任务与某个处理器核绑定之后，就不允许在此处理器核之外的其他处理器核上运行。相比较于 SMP 模式下所有处理器核共享一个全局的核心操作系统映像，AMP 模式下各个处理器核都有自己独立的操作系统映像，且每个处理器核都可以根据实际调度需求选择加载合适的操作系统映像，如加载 Windows 映像、Linux 映像、VxWorks 映像等等，以形成该处理器核独立的调度域，对调度域内的任务资源进行管理。 绑定多处理（Bound Multi-Processing，BMP） BMP 模式是一种比 SMP 更加灵活的多核处理器调度模式。相比较 SMP 模式，BMP 模式在保证 SMP 模式下任务全局动态调度的同时，允许对一些有特殊需求的任务绑定到指定的处理器核上进行调度，增加了灵活性。 多核处理器的负载均衡 硬件平台能力指标综合计算能力指标 网络互联能力指标 嵌入式平台的优点 平台 CPU 为 AMD PPC440 GPU 为 ATI Tech M7500E 操作系统 LynxOS-178，POSIX，多处理器多线程，实时，分区 ARINC653 目前平台的限制点 功耗 发热 GPU 采用的 RISC 的指令集 PPC 平台 ARM 平台 RK NXP TI","categories":["3.软件","航电"]},{"title":"中文字符无法正常显示","path":"/2024/09/02/0-平台-WSL-中文字符无法正常显示/","content":"WSL 中没有相应中文字体库，显示为小方框。 我们直接使用 Windows 自带的字体链接到 WSL 下 sudo ln -s /mnt/c/Windows/Fonts /usr/share/fonts/font 扫描字体目录，并生成字体信息的缓存 fc-cache -fv","categories":["0.平台","WSL"]},{"title":"编译内存不足","path":"/2024/08/30/0-平台-VMware-编译内存不足/","content":"当在 Linux 环境下编译 C++程序时遇到 fatal error: Killed signal terminated program cc1plus 的问题，可能是因为内存不足。解决方法是创建 swap 分区，通过增加虚拟内存来缓解。步骤包括创建 swap 文件，设置权限，激活 swap，最后确认 swap 已正确配置。若不再需要，可使用 swapoff 和 rm 命令移除。 问题描述在 Linux 系统中进行 C++编译时，出现如下报错，导致编译中止： C++: fatal error: Killed signal terminated program cc1pluscompilation terminated. 解决方法查阅相关信息后，认为是虚拟机内存不足造成的。通过创建 swap 分区解决了这个问题，编译成功。下面总结一下 swap 分区的创建和激活等操作： # 创建分区路径sudo mkdir -p /var/cache/swap/# 设置分区的大小# bs=64M是块大小，count=64是块数量，所以swap空间大小是bs*count=4096MB=4GBsudo dd if=/dev/zero of=/var/cache/swap/swap0 bs=64M count=64# 设置该目录权限sudo chmod 0600 /var/cache/swap/swap0# 创建SWAP文件sudo mkswap /var/cache/swap/swap0# 激活SWAP文件sudo swapon /var/cache/swap/swap0# 查看SWAP信息是否正确sudo swapon -s swap0 文件的路径在varcacheswap下，编译完后, 如果不想要交换分区了, 可以删除。 删除交换分区的命令： sudo swapoff /var/cache/swap/swap0sudo rm /var/cache/swap/swap0 释放空间命令： sudo swapoff -a#详细的用法：swapoff --help#查看当前内存使用情况：free -m","categories":["0.平台","VMware"]},{"title":"代码日志输出","path":"/2024/08/28/1-语言-调试输出-代码日志输出/","content":"宏定义通过一个宏定义把要打印的信息写到一个日志文件中，不仅可以记录程序每次运行的状态便于 debug，而且在发布时只需要注释掉宏定义而不必删除每一个使用该宏的地方，不会出现因删除代码而出现的错误。 宏还可以加一个参数传入文件的路径，就可以自定义日志文件的位置。 #define TRACEOUT(p) \\ \\time_t timeval; \\timeval=time(NULL); \\FILE *log; \\log = fopen(log.txt,a);\\fprintf(log,%s -- %s ,p,ctime(timeval));\\fclose(log); \\#define LOG_DBG(fmt,...) \\do \\fprintf(stdout,[DEBUG] %s:%d - fmt , \\__FILE__,__LINE__, ##__VA_ARGS__); \\ while(0)#define LOG_ERR(fmt,...) \\do \\fprintf(stderr,[ERROR] %s:%d - fmt , \\__FILE__,__LINE__, ##__VA_ARGS__); \\ while(0)int main()\tTRACEOUT(hello);\tLOG_DBG(hello);\tLOG_ERR(hello);\treturn 0; 函数#include stdarg.h#include stdio.h#include time.h#define LOG_FILE ./a.log#define LOG_DEFAULT( fmt, ... ) log_out( LOG_FILE, __FILE__, __LINE__, fmt, ##__VA_ARGS__)#define LOG_TOXFILE( flog, fmt, ... ) log_out( flog, __FILE__, __LINE__, fmt, ##__VA_ARGS__) int log_out(char* flog, char *file, int line, char* fmt, ...) va_list arg; char pre[128], tmp[1024]; long clock; struct tm *c_ptr; FILE *fp; time( clock ); c_ptr = localtime(clock); sprintf( pre, [%04d%02d%02d%02d%02d%02d_%s.%d], c_ptr-tm_year+1900, c_ptr-tm_mon+1, c_ptr-tm_mday, c_ptr-tm_hour, c_ptr-tm_min, c_ptr-tm_sec, file, line ); va_start(arg, fmt); vsprintf(tmp, fmt, arg); va_end (arg); //log to stdout if( !flog ) printf( %-32.32s %s, pre, tmp ); return 0; //log to file if( !(fp = fopen( flog, at ) ) ) return -1; fprintf( fp, %-32.32s %s, pre, tmp ); fclose( fp ); return 0; 调用方法： LOG_DEFAULT 日志输出到默认的日志文件 LOG_TOXFILE 日志输出到指定的日志文件，参数是 0，则日志打印到标准输出","categories":["1.语言","调试输出"]},{"title":"代码注释","path":"/2024/08/28/1-语言-调试输出-代码注释/","content":"注释部分函数部分 function/*************************************************Function: // 函数名称Description: // 函数功能、性能等的描述Calls: // 被本函数调用的函数清单Called By: // 调用本函数的函数清单Table Accessed: // 被访问的表（此项仅对于牵扯到数据库操作的程序）Table Updated: // 被修改的表（此项仅对于牵扯到数据库操作的程序）Input: // 输入参数说明，包括每个参数的作// 用、取值说明及参数间关系。Output: // 对输出参数的说明。Return: // 函数返回值的说明Others: // 其它说明*************************************************/ 全局变量 global variable/* The ErrorCode when SCCP translate *//* Global Title failure, as follows */ // 变量作用、含义/* 0 － SUCCESS 1 － GT Table error *//* 2 － GT error Others － no use */ // 变量取值范围/* only function SCCPTranslate() in *//* this modual can modify it, and other *//* module can visit it through call *//* the function GetGTTransErrorCode() */ // 使用方法 头文件 .h/************************************************************Copyright (C), 1988-1999, Huawei Tech. Co., Ltd.FileName: test.cppAuthor: Version : Date:Description: // 模块描述Version: // 版本信息Function List: // 主要函数及其功能1. -------History: // 历史修改记录author time version descDavid 96/10/12 1.0 build this moudle***********************************************************/ 配置文件 .cfg/*************************************************Copyright (C), 1988-1999, Huawei Tech. Co., Ltd.File name: // 文件名Author: Version: Date: // 作者、版本及完成日期Description: // 用于详细说明此程序文件完成的主要功能，与其他模块// 或函数的接口，输出值、取值范围、含义及参数间的控// 制、顺序、独立或依赖等关系Others: // 其它内容的说明Function List: // 主要函数列表，每条记录应包括函数名及功能简要说明1. ....History: // 修改历史记录列表，每条修改记录应包括修改日期、修改// 者及修改内容简述1. Date:Author:Modification:2. ...*************************************************/ DoxygenDoxygen 是一个程序的文件产生工具，可将程序中的特定批注转换成为说明文件。通常我们在写程序时，或多或少都会写上批注，但是对于其它人而言，要直接探索程序里的批注，与打捞铁达尼号同样的辛苦。大部分有用的批注都是属于针对函式，类别等等的说明。所以，如果能依据程序本身的结构，将批注经过处理重新整理成为一个纯粹的参考手册，对于后面利用您的程序代码的人而言将会减少许多的负担。不过，反过来说，整理文件的工作对于您来说，就是沉重的负担。 Doxygen 就是在您写批注时，稍微按照一些它所制订的规则。接着，他就可以帮您产生出漂亮的文档了。 因此，Doxygen 的使用可分为两大部分: 特定格式的批注撰写 利用 Doxygen 的工具来产生文档 目前 Doxygen 可处理的程序语言包含： CC++ Java IDL (Corba, Microsoft 及 KDE-DCOP 类型) 而可产生出来的文档格式有： HTML XML LaTeX RTF Unix Man Page而其中还可衍生出不少其它格式。HTML 可以打包成 CHM 格式，而 LaTeX 可以透过一些工具产生出 PS 或是 PDF 文档。 安装 安装 Doxygen 安装 graphviz graphviz 是一个由 ATT 实验室启动的开源工具包，用于绘制 DOT 语言脚本描述的图形。Doxygen 使用 graphviz 自动生成类之间和文件之间的调用关系图，如不需要此功能可不安装该工具包。 安装 Windows Help Workshop Doxygen 使用这个工具可以生成 CHM 格式的文档。 配置Doxygen 产生文档可以分为三个步骤。 在程序代码中加上符合 Doxygen 所定义批注格式 使用 Doxywizard 进行配置 使用 Doxygen 来产生批注文档 撰写正确格式的批注并非所有程序代码中的批注都会被 Doxygen 所处理。您必需依照正确的格式撰写。原则上，Doxygen 仅处理与程序结构相关的批注，如 Function，Class ，档案的批注等。对于 Function 内部的批注则不做处理。Doxygen 可处理下面几种类型的批注。 JavaDoc 类型： /*** ... 批注 ...*/ Qt 类型： /*!* ... 批注 ...*/ 单行型式的批注： /// ... 批注 ... 或 //! ... 批注 ... 要使用哪种型态完全看自己的喜好。以笔者自己来说，大范围的注解我会使用 JavaDoc 型的。单行的批注则使用”“ 的类型。此外，由于 Doxygen 对于批注是视为在解释后面的程序代码。也就是说，任何一个批注都是在说明其后的程序代码。如果要批注前面的程式码则需用下面格式的批注符号。 /*! ... 批注 ... *//** ... 批注 ... *///! ... 批注 .../// ... 批注 ... 上面这个方式并不适用于任何地方，只能用在 class 的 member 或是 function 的参数上。举例来说，若我们有下面这样的 class。 class MyClass public: int member1 ; int member2: void member_function();; 加上批注后，就变成这样： /*** 我的自订类别说明 ...*/class MyClass public: int member1 ; /// 第一个 member 说明 ... int member2: /// 第二个 member 说明 ... int member_function(int a, int b);;/*** 自订类别的 member_funtion 说明 ...** @param a 参数 a 的说明* @param b 参数 b 的说明** @return 传回 a+b。*/int MyClass::member_function( int a, int b )\treturn a+b ; 当您使用 Doxygen 产生说明文档时，Doxygen 会帮您 parsing 您的程式码。并且依据程序结构建立对应的文件。然后再将您的批注，依据其位置套入于正确的地方。您可能已经注意到，除了一般文字说明外，还有一些其它特别的指令，像是@param 及@return 等。这正是 Doxygen 另外一个重要的部分，因为一个类别或是函式其实都有固定几个要说明的部分。为了让 Doxygen 能够判断，所有我们就必需使用这些指令，来告诉 Doxygen 后面的批注是在说明什么东西。Doxygen 在处理时，就会帮您把这些部分做特别的处理或是排版。甚至是制作参考连结。 首先，我们先说明在 Doxygen 中对于类别或是函数批注的一个特定格式。 /*** class 或 function 的简易说明...** class 或 function 的详细说明...* ...*/ 上面这个例子要说的是，在 Doxygen 处理一个 class 或是 function 注解时，会先判断第一行为简易说明。这个简易说明将一直到空一行的出现。或是遇到第一个”.” 为止。之后的批注将会被视为详细说明。两者的差异在于 Doxygen 在某些地方只会显示简易说明，而不显示详细说明。如：class 或 function 的列表。 另一种比较清楚的方式是指定@brief 的指令。这将会明确的告诉 Doxygen，何者是简易说明。例如： /*** @brief class 或 function 的简易说明...** class 或 function 的详细说明...* ...*/ 除了这个 class 及 function 外，Doxygen 也可针对档案做说明，条件是该批注需置于档案的前面。主要也是利用一些指令，通常这部分注解都会放在档案的开始地方。如： /*! \\file myfile.h\\brief 档案简易说明详细说明.\\author 作者信息*/ 如您所见，档案批注约略格式如上，请别被 \\ 所搞混。其实，\\ 与”@” 都是一样的，都是告诉 Doxygen 后面是一个指令。两种在 Doxygen 都可使用。笔者自己比较偏好使用”@”。 接着我们来针对一些常用的指令做说明：@file 档案的批注说明。Doxygen 所支持的指令很多，有些甚至是关于输出排版的控制。您可从 Doxygen 的使用说明中找到详尽的说明。 下面我们准备一组 example.h 及 example.cpp 来说明 Doxygen 批注的使用方式：example.h: @author 作者的信息 @brief 用于 class 或 function 的批注中，后面为 class 或 function 的简易说明。 @param 格式为 @param arg_name 参数说明,主要用于函式说明中，后面接参数的名字，然后再接关于该参数的说明。 @return 后面接函数传回值的说明。用于 function 的批注中。说明该函数的传回值。 @retval 格式为 @retval value 传回值说明,主要用于函式说明中，说明特定传回值的意义。所以后面要先接一个传回值。然后在放该传回值的说明。 /*** @file 本范例的 include 档案。** 这个档案只定义 example 这个 class。** @author garylee@localhost*/#define EXAMPLE_OK 0 /// 定义 EXAMPLE_OK 的宏为 0。/*** @brief Example class 的简易说明** 本范例说明 Example class。* 这是一个极为简单的范例。**/class Example private: int var1 ; /// 这是一个 private 的变数\tpublic: int var2 ; /// 这是一个 public 的变数成员。 int var3 ; /// 这是另一个 public 的变数成员。 void ExFunc1(void); int ExFunc2(int a, char b); char *ExFunc3(char *c) ;; example.cpp: /*** @file 本范例的程序代码档案。** 这个档案用来定义 example 这个 class 的* member function。** @author garylee@localhost*//*** @brief ExFunc1 的简易说明** ExFunc1 没有任何参数及传回值。*/void Example::ExFunc1(void)\t// empty funcion./*** @brief ExFunc2 的简易说明** ExFunc3()传回两个参数相加的值。** @param a 用来相加的参数。* @param b 用来相加的参数。* @return 传回两个参数相加的结果。*/int ExFunc2(int a, char b)\treturn (a+b);/*** @brief ExFunc3 的简易说明** ExFunc3()只传回参数输入的指标。** @param c 传进的字符指针。* @retval NULL 空字符串。* @retval !NULL 非空字符串。*/char * ExFunc2(char * c)\treturn c;","categories":["1.语言","调试输出"]},{"title":"嵌入式Qt的窗口系统","path":"/2024/08/28/0-平台-嵌入式-嵌入式Qt的窗口系统/","content":"自从 Qt 5.0 发布以来，Qt 不再包含自己的窗口系统（QWS）实现。对于单进程用例，Qt 平台抽象是一个优秀的解决方案。Wayland 可以支持多种图形化流程。 有多个平台插件在嵌入式 Linux 系统上可用：EGLFS，LinuxFB，DirectFB，Wayland。这些可用性取决于 Qt 的配置。在许多开发板上选择 eglfs 作为默认选项。如果默认值不合适，QT_QPA_PLATFORM 则可以使用环境变量参数来请求另一个插件。或者，对于快速测试，-platform 命令行可以使用相同的语法。 配置特定设备对于给定的设备构建 Qt 需要一个工具链和一个 sysroot。另外，一些设备需要针对 EGL 和 OpenGL ES 2.0 支持的供应商特定的适配代码。这与非加速平台无关，例如使用 LinuxFB 插件的平台，仅用于基于软件的渲染。 目录 qtbase mkspecs devices 包含许多设备的配置和图形适配代码。例如，linux-rasp-pi2-g++mkspec 包含构建设置，如 Raspberry Pi 2 设备的最佳编译器和链接器标志。mkspec 还包含有关 eglfs 钩子的实现（供应商特定的适配代码）的信息，或者是对适合的 eglfs 设备集成插件的引用。通过配置工具的-device 参数选择设备。在此参数之后的名称必须至少部分地匹配设备下的一个子目录。 以下是 Raspberry Pi 2 的示例配置。对于大多数嵌入式 Linux 板，configure 命令如下： ./configure -release -opengl es2 -device linux-rasp-pi2-g++ -device-option CROSS_COMPILE = $TOOLCHAIN/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian/bin/arm-linux-gnueabihf- -sysroot $ROOTFS -prefix /usr/local/qt5 最重要的参数是 -device 和 -sysroot。通过指定 -sysroot，configure 特征检测测试使用的包含文件和库以及 Qt 本身，取自指定的位置，而不是主机 PC 的标准位置。这意味着在主机上安装开发包是无关紧要的。例如，要获得 libinput 支持 libinput，在主机环境中安装开发头和库是不够的。相反，目标架构（例如 ARM）的标头和库必须存在于 sysroot。 pkg-config 在执行交叉编译时也得到支持。configure 自动设置 PKG_CONFIG_LIBDIR 为 pkg-config 基于 sysroot 代替主机的报告编译器和链接器设置。这通常功能很好，没有任何进一步的调整。但是，PKG_CONFIG_PATH 运行前，主机必须先设置环境变量 configure。否则，Qt 构建可能会尝试从主机系统使用不适当的头文件和库。 指定 -sysroot 在 --sysroot 调用编译器时自动设置参数的结果。在某些情况下，这是不可取的，可以通过传递 -no-gcc-sysroot 来禁用 configure。 -prefix，-extprefix 并 -hostprefix 控制 Qt 构建的目标目标目录。在上述示例中，Qt 的 ARM 版本预计将放置在 /usr/local/qt5 目标设备上。请注意，运行 make install 不会部署任何设备。相反，该 install 步骤将目标指定的目录 extprefix 默认为 sysroot+ prefix，因此是可选的。然而，在很多情况下，“污染”是不可取的，因此指定 -extprefix 变得重要。最后，-hostprefix 允许从目标的二进制文件分离主机工具，如 qmake，rcc，uic。给定时，这些工具将安装在指定的目录下，而不是 extprefix。 嵌入式 Linux 设备的平台插件EGLFSEGL 是 OpenGL 和本机窗口系统之间的接口。Qt 可以使用 EGL 进行上下文和表面管理，但是 API 不包含平台特定的内容：创建本机窗口（这不一定是屏幕上的实际窗口）仍然必须通过平台特定的方式完成。因此需要板或 GPU 特定的适配代码。这样的修改可以被提供为 eglfs 钩子，其可以是编译到平台插件中的单个源文件，或作为动态加载的 EGL 设备集成插件。 EGLFS 是一个平台插件，用于在没有实际的窗口系统（如 X11 或 Wayland）的 EGL 和 OpenGL ES 2.0 之上运行 Qt5 应用程序。除了 Qt Quick 2 和本机 OpenGL 应用程序，它还支持软件渲染的窗口（例如 QWidget）。在后一种情况下，小部件的内容将使用 CPU 渲染成图像，然后将其上传到纹理并由插件合成。 这是包含 GPU 的现代嵌入式 Linux 设备的推荐插件。 EGLFS 强制第一个顶级窗口（无论是 QWidget 还是 QQuickView）成为全屏幕。此窗口也被选择为根部件窗口窗口，其中所有其他顶级窗口小部件（例如对话框，弹出菜单或组合框下拉列表）都被合成。这是必要的，因为使用 EGLFS 总是有一个本机窗口和 EGL 窗口表面，这些窗口属于首先创建的窗口小部件或窗口。当主窗口在整个应用程序的整个生命周期中存在，并且所有其他窗口小部件都是非顶层或之后创建的主窗口显示时，此方法运行良好。 对于基于 OpenGL 的窗口还有其他限制。从 Qt 5.3 起，eglfs 支持一个全屏 GL 窗口（例如，基于 OpenGL 的 QWindow，QQuickView 或 QGLWidget）。打开额外的 OpenGL 窗口或混合这些窗口与基于 QWidget 的内容是不支持的并终止应用程序与错误消息。 如有必要，eglfs 可以使用以下环境变量进行配置： QT_QPA_EGLFS_INTEGRATION- 除了编译的钩子之外，还可以以动态加载的插件的形式提供设备或供应商特定的适配。这个环境变量强制执行一个特定的插件。例如，将其设置为 eglfs_kms 使用 KMS DRM 后端。这只是在设备 makepecs 中没有指定静态或编入钩子的选项。在实践中，传统的编入钩子很少被使用，几乎所有后端都被迁移到插件。设备制造商仍然包含相关 EGLFS_DEVICE_INTEGRATION 条目：该特定设备的首选后端的名称。这是可选的，但是非常有用，以避免在目标系统中存在多个插件的情况下设置此环境变量。DISPLAY 在桌面环境中，根据环境变量的存在，KMS 或 X11 后端是优先的。请注意，在某些电路板上使用特殊的值 none 而不是实际的插件。这表明使用 EGL 与 framebuffer 不需要特殊的集成，所以不能加载插件。 QT_QPA_EGLFS_PHYSICAL_WIDTH 和 QT_QPA_EGLFS_PHYSICAL_HEIGHT-物理屏幕宽度和高度以毫米为单位。在不能从帧缓冲设备 dev fb0 或其他方式查询值的平台上，使用默认 DPI 为 100。此变量可用于覆盖任何此类默认值。设置此选项很重要，因为基于 QWidget 或 Qt Quick Controls 的应用程序依赖于这些值。使用硬编码设置运行可能会导致用户界面元素大小不适合在使用中显示。 QT_QPA_EGLFS_ROTATION- 指定在基于 QWidget 的应用程序中应用于软件渲染内容的旋转。支持的值为 180,90 和-90。这不适用于基于 OpenGL 的窗口，包括 Qt Quick。Qt Quick 应用程序可以在 QML 场景中应用转换。无论应用程序类型如何，标准的 eglfs 鼠标光标总是考虑到该值，具有适当定位和旋转的指针图像。特殊光标实现（如 KMS DRM 后端的硬件光标）可能不支持旋转。 QT_QPA_EGLFS_FORCEVSYNC- 设置后，每次调用 eglSwapBuffers（）后，帧缓冲设备上的 eglfs 请求 FBIO_WAITFORVSYNC。这仅适用于依赖于 fbdevLinux 的传统子系统的后端。通常，默认交换间隔为 1，Qt 假定调用 eglSwapBuffers（）处理 vsync; 如果没有（例如，由于驱动程序错误），请尝试设置 QT_QPA_EGLFS_FORCEVSYNC 为非零值。 QT_QPA_EGLFS_FORCE888 - 设置时，在创建新的上下文，窗口或屏幕外表面时，将忽略红色，绿色和蓝色颜色通道大小。相反，插件要求每个通道 8 位配置。这对于在默认情况下选择具有小于 32 或 24 位像素（例如 5-6-5 或 4-4-4）的配置的设备可能是有用的，但是已知不是理想的，例如，由于绑带效应。而不是更改应用程序代码，此变量提供了一个更容易的快捷方式来强制 24 或 32 bpp 配置。 此外，以下较不常用的变量也可用： QT_QPA_EGLFS_FB - 覆盖帧缓冲设备。默认是devfb0。在大多数嵌入式平台上，这不是很相关，因为帧缓冲区仅用于查询显示维度等设置。然而，在某些设备上，该参数提供了指定要在多个显示设置中使用的显示的功能，类似于 LinuxFB 中的 fb 参数。 QT_QPA_EGLFS_WIDTH 和 QT_QPA_EGLFS_HEIGHT- 包含屏幕宽度和高度（以像素为单位）。在 eglfs 尝试从 framebuffer 设备 dev fb0 中确定尺寸时，但是这并不总是和手动指定大小可能变得必要。 QT_QPA_EGLFS_DEPTH - 覆盖屏幕的颜色深度。在 framebuffer 设备 dev fb0 不可用或查询不成功的平台上，使用默认值 32。此变量可用于覆盖任何此类默认值。请注意，这仅影响 QScreen 报告的颜色深度值。它与 EGL 配置和 OpenGL 渲染使用的颜色深度无关。 QT_QPA_EGLFS_SWAPINTERVAL- 默认情况下 1 将要求交换间隔。这使得能够与显示器垂直刷新同步。该值可以用此环境变量覆盖。例如，传递 0 将禁用交换阻塞，导致尽可能快地运行而没有任何同步。 QT_QPA_EGLFS_DEBUG - 设置时，调试输出上会打印一些调试信息。例如，输入的 QSurfaceFormat 和所选 EGL 配置的属性在创建新上下文时打印。与 Qt Quick 的 QSG_INFO 变量一起，可以为与 EGL 配置相关的故障排除提供有用的信息。 除此之外 QT_QPA_EGLFS_DEBUG，eglfs 还支持更现代的 Qt 分类日志记录系统。以下日志记录类别可用： qt.qpa.egldeviceintegration - 为动态加载的后端启用日志记录。非常有用的检查后端是否正在使用。 qt.qpa.input - 启用来自 evdev 和 libinput 输入处理程序的调试输出。检查给定输入设备是否被识别和打开非常有用。 qt.qpa.eglfs.kms - 在 KMS DRM 后端启用详细日志记录。 运行后 configure，确保检查其输出。由于相应的配置测试失败，没有启用必要的 eglfs 后端，libudev 或 libinput 是相当常见的问题，可以通过这种方式快速识别。当有不想要的“不”的结果，运行 configure 与-v 才能看到编译器和链接调用每个配置测试打开详细输出。 注意：关于缺少标题，库或似乎隐含的链接器故障的错误通常是不完整或破碎的 sysroot 的标志，与 Qt 无关，也不能被 Qt 解决。 例如，当使用 Broadcom 专有图形驱动程序定位 Raspberry Pi 时，输出应包含以下内容。如果不是这样，没有必要进一步进行构建，因为如果没有 Raspberry Pi 特定的后端，加速图形将不起作用，即使 Qt 的其余部分成功编译。 QPA 后端： EGLFS ................................yesEGLFS 详细信息：EGLFS i.Mx6 ........................ noEGLFS i.Mx6 Wayland ................ noEGLFS EGLDevice .................... noEGLFS GBM .......................... noEGLFS mali.........................EGLFS Rasberry Pi ..................yesXL 上的 EGL ......................... LinuxFB该插件通过 Linux 的 fbdev 子系统直接写入帧缓冲区。只支持软件渲染内容。请注意，在某些设置上，显示性能预计将受到限制。 从 Qt 5.9 开始，由于 fbdev 在 Linux 内核中被弃用，DRM dumb 缓冲区支持也是可用的。必须通过将 QT_QPA_FB_DRM 环境变量设置为非零值来请求。当设置时，只要系统支持哑缓冲区，传统的帧缓冲设备devfb0 就不会被访问。相反，通过 DRM API 设置渲染，类似于 eglfs_kmseglfs 的后端。输出将被双缓冲和页面翻转，为软件渲染内容提供适当的 vsync。 注意：当使用哑缓冲区时，以下所述的任何选项都不适用，因为物理和逻辑屏幕尺寸等属性都将被自动查询。 该 linuxfb 插件允许通过将它们传递给 QT_QPA_PLATFORM 环境变量或 -platform 命令行选项来指定其他设置。例如，QT_QPA_PLATFORM=linuxfb:fb=/dev/fb1 指定 /dev/fb1 必须使用帧缓冲设备而不是默认值 fb0。可以通过用冒号分隔多个设置来指定多个设置。 fbdevfbN - 指定帧缓冲设备。在多个显示设置上，这通常允许在不同显示器上运行应用程序。暂时没有办法从一个 Qt 应用程序使用多个帧缓冲区。 size=width xheight - 指定屏幕大小（以像素为单位）。插件尝试从 framebuffer 设备查询物理和逻辑的显示维度。然而，这可能并不总是导致正确的结果，因此可能需要明确指定值。 mmsize=width xheight - 物理宽度和高度（以毫米为单位）。 offset=width xheight - 指定屏幕左上角的像素偏移量。默认位置在(0, 0)。 nographicsmodeswitch - 不要将虚拟终端切换到图形模式（KD_GRAPHICS）。除了切换到图形模式外，闪烁的光标和屏幕消隐也通常被禁用。设置此参数时，也会跳过这些参数。 tty=/dev/ttyN - 覆盖虚拟控制台。仅在 nographicsmodeswitch 未设置时使用。 从 Qt 5.9 起，在窗口大小调整策略中，eglfs 和 linuxfb 的行为已被同步：第一个顶级窗口被迫使用两个平台插件覆盖整个屏幕。如果不想这样，环境变量设置 QT_QPA_FB_FORCE_FULLSCREEN 到 0 以恢复早期的 Qt 版本的行为。 输入当没有窗口系统存在时，鼠标，键盘，以及触摸输入是通过直接读取 evdev 或使用辅助库如 libinput 或 tslib。请注意，这要求 /dev/input/event* 用户可以读取设备节点。eglfs 并 linuxfb 具有编译的所有输入处理代码。 使用 libinputlibinput 是一个用于处理输入设备的库。它提供了 Qt 自己的 evdev 输入支持的替代方案。为了能够使用 libinput，请确保所开发的文件 libudev 和 libinput 配置和构建 Qt 时可用。xkbcommon 如果需要键盘支持，也是必需的。由于这些插件默认使用 eglfs，因此 linuxfb 无需进一步的操作 libinput。如果 libinput 支持不可用或环境变量 QT_QPA_EGLFS_NO_LIBINPUT 设置，Qt 自己的 evdev 处理程序进来玩。 输入 eglfs 和 linuxfb 而不用 libinput像设备节点名称参数可以在环境变量设置 QT_QPA_EVDEV_MOUSE_PARAMETERS，QT_QPA_EVDEV_KEYBOARD_PARAMETERS 和 QT_QPA_EVDEV_TOUCHSCREEN_PARAMETERS。用冒号分隔条目。这些参数作为传递-plugin 命令行参数中的设置的替代方法，并且对于某些后端，它们是至关重要的：eglfs 和 linuxfb 使用内置的输入处理程序，因此-plugin 在使用中没有单独的参数。 此外，内置的输入处理程序可以通过设置被禁用 QT_QPA_EGLFS_DISABLE_INPUT 或 QT_QPA_FB_DISABLE_INPUT 到 1。 鼠标鼠标光标每当出现 QT_QPA_EGLFS_HIDECURSOR（对于 eglfs）或 QT_QPA_FB_HIDECURSOR（对于 linuxfb）未设置，Qt 的基于 libudev 的设备发现报告至少有一个鼠标可用。当 libudev 不存在支持时，鼠标光标始终显示，除非通过环境变量显式禁用。 支持热插拔，但只有当 Qt 配置了 libudev 支持（即，如果 libudev 开发头在配置时在 sysroot 中存在）。这允许在应用程序运行时连接或断开输入设备。evdev 鼠标处理器支持以下额外的参数： /dev/input/... - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 nocompress - 默认情况下，与最后一个 Qt 鼠标事件相比，不会导致更改位置的输入事件被压缩; 在更改位置或按钮状态后，才会发送新的 Qt 鼠标事件。可以通过设置 nocompress 参数来禁用。 dejitter - 指定抖动限制。默认情况下禁用消隐功能。 grab - 当 1，Qt 将抓住设备专用。 abs - 一些触摸屏报告绝对坐标，不能与触摸板区分开来。在这种特殊情况下，通过 abs 表示设备正在使用绝对事件。 键盘该了 evdev 键盘处理程序支持以下额外的参数： /dev/input/... - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 grab - 启用抓取输入设备。 keymap - 指定自定义键盘映射文件的名称。 enable-compose - 启用合成。 repeat-delay - 设置自定义键重复延迟。 repeat-rate - 设置自定义键重复率。 在没有停用终端会话的嵌入式 Linux 系统上，由于输入事件由 Qt 应用程序和 tty 处理，按键上的行为可能会令人困惑。为了克服这一点，可以使用以下选项： EGLFS 和 LinuxFB 尝试通过设置 tty 的键盘模式来禁用应用程序启动时的终端键盘 K_OFF。这样可以防止键盘进入终端。如果由于某些原因需要恢复标准行为，请将环境变量设置 QT_QPA_ENABLE_TERMINAL_KEYBOARD 为 1。请注意，仅当应用程序从远程控制台（例如，通过 ssh）启动并且终端键盘输入保持启用时，该功能才起作用。 另一种方法是使用了 evdev 键盘处理程序的 grab 通过传递参数抢 1 在 QT_QPA_EVDEV_KEYBOARD_PARAMETERS。这样会导致尝试在输入设备上进行抓取。如果 grab 成功，只要 Qt 应用程序运行，系统中没有其他组件从中接收事件。这种方法更适合远程启动的应用程序，因为它不需要访问 tty 设备。 最后，对于许多专门的嵌入式 Linux 图像，首先启用标准终端会话是没有意义的。请参阅您的构建环境的文档，了解如何禁用它们。例如，当使用 Yocto Project 生成图像时，取消设置将 SYSVINIT_ENABLED_GETTYS 导致 getty 任何虚拟终端无任何进程运行，从而导致无输入。 如果默认内置键盘映射不够，可以通过 keymap 参数或使用 eglfs 特定的 loadKeymap（）函数指定不同的键盘映射。后者允许在运行时切换键盘映射。但是请注意，这需要使用 eglfs 的内置键盘处理程序; 当通过-plugin 命令行参数加载键盘处理程序时，不支持它。 注意：目前不支持特殊的系统组合键，例如控制台切换（Ctrl + Alt + Fx）或 zap（Ctrl + Alt + Backspace），并被忽略。 要生成自定义键盘映射，可以使用 kmap2qmap 实用程序。这可以在 qttools 模块中找到。源文件必须是标准的 Linux kmap 格式，这是内核的 loadkeys 命令所理解的。这意味着可以使用以下源生成 qmap 文件： 在 Linux 控制台工具（LCT）项目。 Xorg X11 键盘映射可以转换 kmap 为该 ckbcomp 实用程序的格式。 由于 kmap 文件是纯文本文件，它们也可以手工制作。 kmap2qmap 是一个命令行程序，至少需要 2 个文件作为参数。最后一个是生成的.qmap 文件，而其他所有文件都被解析为输入.kmap 文件。例如： kmap2qmap i386 /qwertz/de-latin1-nodeadkeys.kmap include/compose.latin1.inc de-latin1-nodeadkeys.qmap 注意：kmap2qmap 不支持 Linux 内核支持的所有（伪）符号。转换标准键盘图时，会显示许多警告，关于 Show_Registers，Hex_A 等等; 这些消息可以安全地被忽略。 触摸对于一些电阻式单触摸触摸屏，可能需要退回使用 tslib 而不是依赖于 Linux 多点触控协议和事件设备。对于现代触摸屏，这是不必要的。tslib 可以通过设置环境变量 QT_QPA_EGLFS_TSLIB 或 QT_QPA_FB_TSLIB1 来启用支持。要更改设备，请 TSLIB_TSDEVICE 在命令行中设置环境变量或传递设备名称。请注意，tslib 输入处理程序生成鼠标事件并支持单触摸，而不是 evdevtouch 生成真正的多点触控 QTouchEvent 事件。 evdev 触摸处理器支持以下额外的参数： devinput… - 指定输入设备的名称。当没有给出时，Qt 通过 libudev 或通过可用节点来查找合适的设备。 rotate- 在某些触摸屏上，坐标必须旋转，这可以通过设置 rotate 为 90,180 或 270 进行。 invertx 和 inverty- 反转输入事件中的 X 或 Y 坐标，通过 invertx 或 inverty。 export QT_QPA_EVDEV_TOUCHSCREEN_PARAMETERS=/dev/input/event5:rotate=180 在启动应用程序之前，会导致明确指定的触摸设备并翻转坐标 - 当实际屏幕和触摸屏的方向不匹配时很有用。 笔式平板电脑该 evdevtablet 插件为 Wacom 和类似的基于笔的平板电脑提供了基本的支持。它仅生成 QTabletEvent 事件。要启用它，请传递 QT_QPA_GENERIC_PLUGINS=evdevtablet 给环境，或者 -plugin evdevtablet 在命令行中传递参数。插件可以使用设备节点参数，例如 QT_QPA_GENERIC_PLUGINS=evdevtablet:/dev/event1，Qt 的自动设备发现（基于 libudev 或演练devinputevent*）不起作用或行为不正常的情况。 调试输入设备通过启用 qt.qpa.input 日志规则，例如通过将 QT_LOGGING_RULES 环境变量设置为，可以向调试输出打印一些信息 qt.qpa.inputtrue。这对于检测正在使用哪个设备或对设备发现问题进行故障排除非常有用。 使用自定义鼠标光标图像eglfs 自带的 32x32 尺寸的鼠标光标图像。如果这些还不够，可以通过将 QT_QPA_EGLFS_CURSOR 环境变量设置为 JSON 文件的名称来提供自定义游标地图集。该文件也可以通过 Qt 的资源系统嵌入到应用程序中。 例如，每行具有 8 个光标图像的嵌入式光标图集可以指定如下： “image”：“：/cursor-atlas.png”\t“cursorsPerRow”：8，\t“热点”：[ [7，2] [12，3] [12，12] ...\t] 请注意，图像预计将紧紧地包装在图集中：光标的宽度和高度根据总图像大小和 cursorsPerRow 设置决定。地图集必须为所有支持的游标提供图像。 显示输出当连接多个显示器时，从一个单一 Qt 应用程序中定向一个或多个显示器的支持级别在平台插件之间变化，并且通常取决于设备及其图形堆栈。 eglfs 与 eglfs_kms 后端当 KMS DRM 后台正在使用时，eglfs 报告 QGuiApplication :: screens（）中的所有可用屏幕。应用程序可以使用不同的窗口通过 QWindow :: setScreen（）来定位不同的屏幕。 注意：每个屏幕的一个全屏窗口的限制仍然适用。使 QWindow 可见后更改屏幕也不受支持。因此，嵌入式应用程序必须在调用 QWindow :: show（）之前进行所有必要的 QWindow :: setScreen（）调用。 当开始在给定的嵌入式设备上开发时，通常需要验证设备和驱动程序的行为，并且所连接的显示器应该是正常工作的。一个简单的方法是使用 hellowindow 示例。用-platform eglfs –multiscreen –timeout 参数启动它在每个连接的屏幕上显示一个旋转的 Qt 标志几秒钟。 注意：下面描述的大多数配置选项适用于所有基于 KMS DRM 的后端，无论缓冲管理技术（GBM 或 EGLStreams）如何。 KMS DRM 后端还支持通过 JSON 文件进行自定义配置。将环境变量设置为 QT_QPA_EGLFS_KMS_CONFIG 文件的名称以启用此功能。该文件也可以通过 Qt 资源系统嵌入到应用程序中。示例配置如下： “device”：“/ dev / dri / card1”，\t“hwcursor”：false，\t“pbuffers”：真的，\t“输出”：[ “name”：“VGA1”， “关闭模式” ， “name”：“HDMI1”， “mode”：“1024x768” ] 这里我们配置指定的设备 它不会使用硬件光标（通过 OpenGL 退回渲染鼠标光标;默认情况下，启用硬件光标，因为它们更有效）， 它将使用标准的 EGL pbuffer 表面返回 QOffscreenSurface（默认情况下，这是禁用的，而是使用 gbm 表面）， VGA 连接器上的输出被禁用，而 HDMI 处于活动状态，分辨率为 1024x768。 另外，这样的配置也禁用寻找设备 libudev，而是使用指定的设备。 何时 mode 未定义，系统选择报告为首选的模式。为可接受的值 mode 是：off，current，preferred，宽度 x 高度，或模式行字符串。 默认情况下，DRM 层报告的所有屏幕都将被视为一个大型虚拟桌面。鼠标光标实现将考虑到这一点，并按预期在屏幕上移动。尽管不推荐，虚拟桌面模式可以通过设置被禁用 separateScreens，以 false 在配置上，如果需要的话。 默认情况下，根据系统报告的连接器顺序，虚拟桌面从左到右形成。这可以通过设置 virtualIndex 为从 0 开始的值来更改。例如，以下配置使用首选分辨率，但确保虚拟桌面中的左侧是屏幕连接到 HDMI 端口，而右侧是屏幕连接到 DisplayPort： “device”：“drm-nvdc”，\t“输出”：[ “name”：“HDMI1”， “virtualIndex”：0 ， “name”：“DP1”， “virtualIndex”：1 ] 数组中的元素的顺序是不相关的。具有未指定虚拟索引的输出将放在其他虚拟索引之后，并保留 DRM 连接器列表中的原始顺序。 要创建一个垂直的桌面空间（即，从上到下而不是从左到右堆叠），添加一个 virtualDesktopLayout 属性后面 device 的值 vertical。 注意：建议虚拟桌面中的所有屏幕使用相同的分辨率，否则像鼠标光标那样的元素可能会在输入仅存在于一个给定屏幕上的区域时以意想不到的方式运行。 何时 virtualIndex 不够，该属性 virtualPos 可用于明确指定问题屏幕的左上角位置。以前面的例子，假设 HDMI1 的分辨率为 1080p，下面第一个基于 HDMI 的屏幕放在第一个： ...\t“输出”：[ ... “name”：“HDMI2”， “virtualPos”：“0，1080” ] 注意：在需要鼠标支持时避免这样的配置。鼠标光标的行为可能是意想不到的非线性布局。Touch 应该没有问题。 在某些情况下，通过 DRM 自动查询物理屏幕尺寸可能会失败。通常 QT_QPA_EGLFS_PHYSICAL_WIDTH，QT_QPA_EGLFS_PHYSICAL_HEIGHT 环境变量将用于提供缺失值，但是当存在多个屏幕时，这并不适用。而是使用列表中的 physicalWidth 和 physicalHeight 属性 outputs 来指定以毫米为单位的大小。 注意：不同的物理尺寸和不同的逻辑 DPI 不鼓励，因为它可能会导致意外的问题，因为一些图形堆栈组件不知道多个屏幕，仅依靠第一个屏幕的值。 从每个有源输出 outputs 阵列对应于一个 QScreen 从报告实例 QGuiApplication ::屏幕（）。QGuiApplication :: primaryScreen（）报告的主屏幕是默认首先注册的屏幕。当不使用时 virtualIndex，这意味着决定是基于 DRM 连接器顺序。要覆盖这一点，属性设置 primary，以 true 对在所需的条目 outputs 列表。例如，为了确保与 VGA 输出相对应的屏幕将是主要的，即使系统首先报告 HDMI，则可以执行以下操作： “device”：“/ dev / dri / card0”，\t“输出”：[ “name”：“HDMI1”， “name”：“VGA1”，“mode”：“1280x720”，“primary”：true， “name”：“LVDS1”，“mode”：“off”\t] 为了进行故障排除，可能会启用 KMS DRM 后端的调试日志。为此，启用分类日志记录规则 qt.qpa.eglfs.kms。 注意：在嵌入式环境中，虚拟桌面比全窗口系统更为有限。应该避免 Windows 重叠多个屏幕，非全屏窗口和屏幕之间的移动窗口，并且可能无法正常运行。 多屏幕设置最常用和最受支持的用例是为每个屏幕打开一个专用的 QQuickWindow 或 QQuickView。使用 threadedQt Quick 场景图的默认渲染循环，这些窗口中的每个都将获得自己的专用渲染线程。这是很好的，因为线程可以基于 vsync 独立调节，并且不会相互干扰。通过 basic 循环，这可能会产生问题，动画可能会因此而恶化。 例如，发现所有连接的屏幕，并为每个屏幕创建一个 QQuickView 可以这样完成： int main(int argc, char **argv) QGuiApplication app(argc, argv); QVectorQQuickView *views; for(QScreen * screen : app.screens()) QQuickView * view = new QQuickView; view-setScreen(screen); view-setResizeMode(QQuickView::SizeRootObjectToView); view-setSource(QUrl(qrc:/main.qml)); QObject::connect(view-engine(), QQmlEngine::quit, qGuiApp, QCoreApplication::quit); views.append(view); view-showFullScreen(); int result = app.exec(); qDeleteAll(views); eglfs 与 eglfs_kms_egldevice 后端通常在 Tegra 设备上使用的这种后端与上述 KMS DRM 后端类似，不同之处在于它依赖于 EGLDevice 和 EGLStream 扩展而不是 GBM。 有关此方法的技术细节，请查看演示文稿。 截至 Qt 5.7，该后端与基于 GBM 的后端共享了许多内部实现。这意味着支持多个屏幕和高级配置通道 QT_QPA_EGLFS_KMS_CONFIG。一些设置，如 hwcursor 和 pbuffers 不适用。 默认情况下，后端将自动为每个输出的默认平面选择正确的 EGL 层。必要时，可以通过将 QT_QPA_EGLFS_LAYER_INDEX 环境变量设置为所需层的索引来覆盖。此方法目前不支持多个输出，因此其使用应限于具有单个屏幕的系统。要查看哪些层可用，并调试潜在的启动问题，请启用日志记录类别 qt.qpa.eglfs.kms。 在某些情况下，即使屏幕报告已经设置了所需分辨率，也可能需要执行应用程序启动时设置的视频模式。这通常是被优化的，但如果屏幕保持关闭状态，请尝试将环境变量设置为 QT_QPA_EGLFS_ALWAYS_SET_MODE 非零值并重新启动应用程序。 要配置后端使用的 EGLStream 对象的行为，请使用 QT_QPA_EGLFS_STREAM_FIFO_LENGTH 环境变量。这假定 KHR_stream_fifo 是目标系统支持的。默认情况下，流以邮箱模式运行。要切换到 FIFO 模式，请设置 1 或更大的值。该值指定流可以容纳的最大帧数。 在某些系统上，可能需要通过预定义的连接器来定位特定的覆盖平面。强制层索引通过 QT_QPA_EGLFS_LAYER_INDEX 不执行平面配置，因此本身不适用。相反，在这种特殊情况下，使用 QT_QPA_EGLFS_KMS_CONNECTOR_INDEX 和 QT_QPA_EGLFS_KMS_PLANE_INDEX 环境变量。当这些设置被设置时，只有指定的连接器和平面将被使用，所有其他输出将被忽略。后端将负责选择对应于所需平面的 EGL 层和配置平面。 在 KMS DRM 上有多个屏幕的系统中触摸输入触摸屏在多显示系统中需要额外的考虑因素，因为触摸事件必须路由到正确的虚拟屏幕，这需要触摸屏和显示器输出之间的正确映射。 映射通过 QT_QPA_EGLFS_KMS_CONFIG 前面部分中指定和描述的 JSON 配置文件完成。当 touchDevice 属性存在于 outputs 数组的元素中时，该值被视为设备节点，并且触摸设备与所讨论的显示输出相关联。 例如，假设我们的触摸屏具有 dev input event5 的设备节点，并且是集成到通过 HDMI 连接的显示器作为辅助屏幕的触摸屏，以下配置确保正确的触摸（和合成鼠标）事件转换： “device”：“drm-nvdc”，\t“输出”：[ “name”：“HDMI1”， “touchDevice”：“/ dev / input / event5”， “virtualIndex”：1 ， “name”：“DP1”， “virtualIndex”：0 ] 注意：如有疑问，请 QT_LOGGING_RULES=qt.qpa.*=true 在启动应用程序之前通过设置环境变量来启用图形和输入子系统的日志记录。这将有助于识别正确的输入设备节点，并且可能会发现可能难以调试的输出配置问题。 注意：从 Qt 5.8 起，上述只支持 evdevtouch 输入后端。其他变体，例如基于 libinput 的变体，将继续将事件路由到主屏幕。要强制在具有多个输入后端的系统上使用 evdevtouch，请将环境变量设置 QT_QPA_EGLFS_NO_LIBINPUT 为 1。 eglfs 与其他后端通常基于通过供应商的 EGL 实现直接针对帧缓冲区或组合 API 的其他后端，通常对多个显示器提供有限或不支持的支持。在使用 Vivante GPU 的基于 i.MX6 的电路板上，与 linuxfb 类似，QT_QPA_EGLFS_FB 环境变量可用于指定要缓存的帧缓冲区。在 Raspberry Pi 上，QT_QPA_EGLFS_DISPMANX_ID 环境变量可用于指定要输出的屏幕。该值对应于其中一个 DISPMANX_ID_ 常量，请参考 Dispmanx 文档。请注意，与 KMS / DRM 不同，这些方法通常不允许从同一应用程序输出到多个屏幕。或者，驱动程序特定的环境变量或内核参数也可以用于控制所使用的帧缓冲区。 视频内存具有固定数量的专用视频内存的系统在运行基于 Qt Quick 的 Qt 应用程序或类似 QOpenGLWidget 的类之前，可能需要特别注意。对于这样的应用，默认设置可能不足，特别是当它们以高分辨率（例如，全高清）屏幕显示时。在这种情况下，他们可能以意想不到的方式开始失败。建议确保至少有 128 MB 的 GPU 内存可用。对于没有为 GPU 保留的固定内存量的系统，这不是一个问题。 linuxfb使用 fbplugin 参数指定要使用的 framebuffer 设备。 Unix 信号处理程序面向控制台的平台插件，如 eglfs 和 linuxfb 默认安装信号处理程序来捕获 interrupt（SIGINT），suspend 和 continue（SIGTSTP，SIGCONT）和 terminate（SIGTERM）。这样，当应用程序终止或由于 kill 或 Ctrl+C 或暂停时，可以恢复键盘，终端光标和可能的其他图形状态 Ctrl+Z。（尽管通过键盘终止或暂停只能在 QT_QPA_ENABLE_TERMINAL_KEYBOARD 设置时进行，如上面的“输入”部分所述）。然而，在某些情况下，捕获 SIGINT 可能是不合需要的，因为它可能会与远程调试冲突。因此，QT_QPA_NO_SIGNAL_HANDLER 提供环境变量以选择退出所有内置信号处理。 字体Qt 通常用于 fontconfig 提供对系统字体的访问。如果 fontconfig 不可用，Qt 会回退使用 QBasicFontDatabase。在这种情况下，Qt 应用程序将在 Qt 的 libfonts 目录中查找字体。Qt 会自动检测预渲染的字体和 TrueType 字体。可以通过设置 QT_QPA_FONTDIR 环境变量来覆盖此目录。 有关支持的格式的详细信息，请参阅嵌入式 Linux 字体的 Qt。 注意： Qt 不再在 libfonts 目录中装载任何字体。这意味着由平台（系统映像）提供必要的字体。 嵌入式 Linux 设备上的窗口系统的平台插件XCB这是常规桌面 Linux 平台上使用的 X11 插件。在一些嵌入式环境中，它为 Xcb 提供了 X 和必要的开发文件，这个插件就像在普通的 PC 桌面上一样。 注意：在某些设备上，由于 EGL 实现与 Xlib 不兼容，因此在 X 下没有 EGL 和 OpenGL 支持。在这种情况下，XCB 插件是在没有 EGL 支持的情况下构建的，这意味着 Qt Quick 2 或其他基于 OpenGL 的应用程序不适用于此平台插件。然而，仍然可以使用它来运行软件渲染的应用程序（例如基于 QWidget）。 作为一般规则，XCB 在嵌入式设备上的使用是不可取的。像 eglfs 这样的插件可能会提供更好的性能和硬件加速。 WaylandWayland 是一个重量轻的开窗系统; 或者更准确地说，它是用于客户端与显示服务器通信的协议。 Qt Wayland 模块提供了一个 wayland 平台插件，允许 Qt 应用程序连接到 Wayland 合成器。 注意：使用 Weston 参考合成器时，您可能会遇到触摸屏输入的问题。有关更多信息，请参阅 Qt Wiki。","categories":["0.平台","嵌入式"]},{"title":"信号量","path":"/2024/08/28/0-平台-Linux-IO-信号量/","content":"介绍Linux 的信号量是一种进程间通信机制，用于控制进程对共享资源的访问。信号量是一个计数器，用于表示某个共享资源的可用数量。进程可以使用信号量来申请共享资源的访问权限，也可以使用信号量来释放已经申请到的资源。 Linux 中的信号量包括两种类型：二进制信号量和计数信号量。二进制信号量只有两个取值，分别表示资源的空闲和占用状态。计数信号量的取值可以是任意正整数，表示可用资源的数量。 进程可以使用 semget() 函数创建一个信号量集，使用 semop() 函数对信号量进行操作。semop() 函数可以对信号量进行加锁和解锁操作，还可以等待信号量的值达到某个条件。当某个进程占用了一个资源时，它需要对相应的信号量进行加锁操作，以防止其他进程同时访问该资源。当进程释放资源时，需要对相应的信号量进行解锁操作，以便其他进程可以访问该资源。 SIG 簇函数在 Linux 中，信号量通常用于进程间的同步和互斥操作。例如，多个进程需要访问同一个共享文件时，可以使用信号量来控制对该文件的访问。 在 Linux 中，SIG 簇函数是一组用于处理信号的系统调用函数，可以用来注册信号处理函数、发送信号、阻塞信号等操作。这些函数的名称都以 “sig” 开头，例如 sigaction、sigprocmask、sigqueue 等。 下面是一些常用的 SIG 簇函数： sigaction 函数：用于注册信号处理函数。该函数可以指定一个函数指针作为信号处理函数，当接收到指定信号时，系统会自动调用该函数进行处理。sigaction 函数还可以设置信号的处理方式，例如忽略信号、执行默认操作、执行指定的处理函数等。 sigprocmask 函数：用于设置进程的信号屏蔽字。进程可以使用该函数屏蔽某些信号，以免在处理某个信号时被其他信号中断。当某个信号被屏蔽后，它将被暂时忽略，直到该信号被解除屏蔽。 sigpending 函数：用于获取当前进程的未决信号集。未决信号是指已经发送给进程但尚未处理的信号。sigpending 函数可以获取当前进程的未决信号集，并将其保存在一个 sigset_t 类型的变量中。 sigsuspend 函数：用于挂起当前进程，直到收到指定信号为止。该函数可以用于等待某个信号的到来，并阻塞当前进程，直到收到指定信号后才会继续执行。 sigqueue 函数：用于向指定进程发送信号，并可以携带一个整数值作为附加数据。该函数可以用于进程间的通信，例如向另一个进程发送通知消息等。 这些 SIG 簇函数可以帮助我们更好地处理信号，实现进程间的通信和同步操作。在使用这些函数时，需要注意信号的处理顺序和优先级，以免出现意外的结果。 信号量用作定时器信号量可以用作定时器的一种实现方式。具体来说，可以使用 setitimer 函数设置一个定时器，当定时器到期时，系统会自动向当前进程发送一个指定的信号，进程可以通过信号处理函数来处理该信号。 以下是一个使用信号量实现定时器的示例代码： #include stdio.h#include stdlib.h#include signal.h#include unistd.h#include sys/time.h#include sys/sem.h#define SEM_KEY 0x12345678static int sem_id;union semun int val;\tstruct semid_ds *buf;\tunsigned short *array;;void handler(int signum)\tprintf(Timer expired. );void set_timer(int sec)\tstruct itimerval timer;\ttimer.it_value.tv_sec = sec;\ttimer.it_value.tv_usec = 0;\ttimer.it_interval.tv_sec = 0;\ttimer.it_interval.tv_usec = 0;\tsetitimer(ITIMER_REAL, timer, NULL);void init_sem()\tunion semun arg;\targ.val = 0;\tsem_id = semget(SEM_KEY, 1, IPC_CREAT | 0666);\tsemctl(sem_id, 0, SETVAL, arg);void wait_sem()\tstruct sembuf sb;\tsb.sem_num = 0;\tsb.sem_op = -1;\tsb.sem_flg = 0;\tsemop(sem_id, sb, 1);void post_sem()\tstruct sembuf sb;\tsb.sem_num = 0;\tsb.sem_op = 1;\tsb.sem_flg = 0;\tsemop(sem_id, sb, 1);int main()\tsignal(SIGALRM, handler);\tinit_sem();\tset_timer(5);\twait_sem();\tprintf(Exiting... );\treturn 0; 在上面的示例代码中，我们使用了 setitimer 函数来设置一个 5 秒的定时器，当定时器到期时，系统会向当前进程发送 SIGALRM 信号。我们在程序中注册了 SIGALRM 信号的处理函数 handler，当收到该信号时，会输出一条消息。 为了实现等待定时器到期的功能，我们使用了信号量。在程序开始时，我们调用了 init_sem 函数来初始化信号量。在程序中，我们使用了 wait_sem 函数来等待信号量的值变为 0，这个函数会阻塞当前进程直到收到信号量为止。在信号处理函数中，我们调用了 post_sem 函数来将信号量的值加 1，这样就可以让等待信号量的进程继续执行了。 当程序运行时，它会等待 5 秒钟，然后输出一条消息并退出。如果需要更长或更短的定时器，可以修改 set_timer 函数中的参数。 Linux 中的信号量和 Qt 的信号槽机制Linux 中的信号量和 Qt 中的信号槽都是用于实现进程间通信和事件处理的机制，但实现方式和应用场景有所不同。 Linux 中的信号量是一种进程间通信机制，用于控制进程对共享资源的访问。信号量是一个计数器，用于表示某个共享资源的可用数量。进程可以使用信号量来申请共享资源的访问权限，也可以使用信号量来释放已经申请到的资源。Linux 中的信号量通常用于进程间的同步和互斥操作，例如多个进程需要访问同一个共享文件时，可以使用信号量来控制对该文件的访问。 Qt 中的信号槽是一种事件处理机制，用于在对象之间传递消息和处理事件。当一个对象发生某个事件时，它会发送一个信号，其他对象可以连接到该信号并定义一个槽函数来处理该事件。Qt 中的信号槽机制可以用于实现对象之间的通信和协作，例如在一个窗口中点击一个按钮时，可以发送一个信号来通知其他对象执行相应的操作。 虽然 Linux 中的信号量和 Qt 中的信号槽机制都可以用于进程间通信和事件处理，但它们的实现方式和应用场景有所不同。在 Linux 中，信号量通常用于控制对共享资源的访问，而在 Qt 中，信号槽机制通常用于处理事件和实现对象之间的通信。 sigactionsigaction 和 Qt 的信号槽机制都是用于处理信号的机制，sigaction 主要用于实现进程间通信和事件处理，而 Qt 的信号槽机制主要用于处理 GUI 事件和实现对象之间的通信。 sigaction 是 Linux 中用于处理信号的函数，可以设置信号处理函数、信号屏蔽字等。当进程接收到某个信号时，会自动调用对应的信号处理函数来处理该信号。sigaction 主要用于实现进程间通信和事件处理，例如在多进程编程中，可以使用 sigaction 实现进程间的同步和互斥操作。 Qt 中的信号槽机制是一种事件处理机制，用于在对象之间传递消息和处理事件。当一个对象发生某个事件时，它会发送一个信号，其他对象可以连接到该信号并定义一个槽函数来处理该事件。Qt 中的信号槽机制可以用于实现对象之间的通信和协作，例如在一个窗口中点击一个按钮时，可以发送一个信号来通知其他对象执行相应的操作。","categories":["0.平台","Linux","IO"]},{"title":"计算机概念","path":"/2024/08/28/0-平台-平台相关-计算机概念/","content":"冯·诺依曼结构计算机的原理所有的计算机语言，不管是 Java, Python, Go, C, C++, PHP…… ， 最终都要变成基本的二进制指令，在冯·诺依曼结构计算机上按规矩执行。 了解 CPU 和内存是怎么工作的： CPU 从内存取出指令，进行译码和执行，执行时从内存中取出数据放到寄存器中， 进行计算， 然后把结果写回到内存。如果是跳转指令， CPU 则取出跳转目的地的指令继续执行。基本的指令组成了顺序、循环、分支等基本的程序结构，形成了更为强大的编程语言的基础。 CPU 和内存、硬盘等设备的速度不匹配，是冯·诺依曼结构计算机的一个核心问题，为了解决这个问题，科学家们绞尽脑汁，想尽了办法， 又引出了一堆概念： 缓存，DMA， 同步，异步，阻塞…. 进程和线程所有的程序要么会成为一个独立的进程去执行，要么是进程中的一个线程 。几乎所有的编程语言都会涉及到对多进程或者多线程编程的支持， 特别是多线程的并发编程。 进程是对一个运行中的程序的抽象，没有这个概念。对于 CPU 来讲， 只是从某个地方取指令，译码执行，它不会意识到执行的程序已经发生了切换，另外一个程序（准确地讲叫进程）已经成功地抢班夺权。 每个进程都有一个被操作系统维护的进程控制块， 里边保存了这个进程在运行时的重要信息，是进程能来回切换的重要保证。而线程则寄居于进程之内 ， 共享进程提供福利（代码和数据）的同时， 还拥有自己的一亩三分地。 线程的出现，提升了系统的性能、吞吐量和响应性。 但是多进程多线程编程也带来了一系列问题： 同步，通信，锁， 死锁。。。 虚拟内存虚拟内存的重要作用就是给各进程提供一个由虚拟地址组成的独立区域，每个进程在自己的独立区域里执行，互不影响。指令必须在物理内存中才能被执行， 操作系统把每个进程的虚拟地址映射到实际地址上去，其中实现分段，分页，页表，动用 CPU 的 TLB 来加速。 程序并不是一下子全部装载到内存的， 而是用到的时候才进行装载。 网络的核心概念核心概念是： 分组交换， TCPIP 参考模型， socket , http(s)。 网络数据是被切分成适合网络传输的小块，给每个小块编上号， 每个小块都独立地走相同甚至不同的网络路径， 到达你这里，重新排序，组合，然后才展示给你， 这就是分组交换。使用分组交换可以充分的利用网络带宽： 在你不使用的间隙，别人也可以利用。 但是一个很明显的问题就是分组数据丢失了怎么办？ 如何检测， 怎么重发，如何缓存已经收到分组数据等一系列烦人的问题接踵而来。 这就是 TCP 要干的事情。如果你能体会到 TCP 是在端系统实现的，中间节点一无所知，我想你就 Get 到了分组交换和分层的真谛。 TCPIP 参考模型定义了 5 层： 应用层，传输层，网络层，链路层，物理层。你一定得理解所谓的分层只不过是把你的数据层层包装而已，在传输的过程层中每到一个节点都会拆开某一层的包装，查看一下数据， 然后再次包装，转发出去，直到终点。 Hash 和 RSA如果说 Https 是网络安全通信的一大基石， 那 Hash 和 RSA 则是基石的基石。 RSA 有一对钥匙， 一个是私有的、保密的， 另外一个是公有的。RSA 的概念很简单， 但是为了实现真正的安全消息传输，作为第一步必须得有数据签名做保证，你需要理解如何对消息用 Hash 形成摘要，然后用私钥签名，又是如何验证这个签名的。","categories":["0.平台","平台相关"]},{"title":"测量语句运行时间","path":"/2024/08/28/0-平台-嵌入式-测量语句运行时间/","content":"测量一个事件持续的时间 #include “stdio.h”#include “stdlib.h”#include “time.h”int main( )\tlong i = 10000000L;\tclock_t start, finish;\tdouble Total_time;\t/* 测量一个事件持续的时间*/\tprintf( Time to do %ld empty loops is , i ); start = clock();\twhile( i--) ;\tfinish = clock(); Total_time = (double)(finish-start) / CLOCKS_PER_SEC;\tprintf( %f seconds/n, Total_time);\treturn 0;","categories":["0.平台","嵌入式"]},{"title":"关于RTOS的Tick值","path":"/2024/08/28/0-平台-嵌入式-RealTime-关于RTOS的Tick值/","content":"什么是系统滴答系统滴答（SysTick），有些地方也叫时钟节拍、系统心跳等。 操作系统可以多任务间进行切换，就是靠一个系统定时器以固定频率中断，为操作系统提供调度（上下文切换）才能实现任务切换。 而这个定时器，就是我们本文说的系统滴答。早些年的 51、430 单片机，跑 RTOS，都是单独利用一个 Timer 定时器提供系统滴答。为了考虑跑 RTOS 这个问题，Cortex-M 内核自带系统滴答这个定时器。 你会发现市面上很多单片机基本都自带有 SysTick 这个定时器，像 Cortex-M0、 M3、 M4 这些内核的单片机都有的，而且只要简单调用官方写好的 API 函数即可使用。 系统配置文件通常，系统滴答（OS_TICKS）位于系统配置文件中，对系统配置文件进行配置也是重要的一步。比如 FreeRTOSConfig.h ucos 系统的 os_cfg.h（一些系统通过图形化界面进行配置，其实也是对系统配置文件进行配置）。 OS_TICKS 一般是配置为 1000，从宏定义和注释很容易理解，就是每秒系统滴答的次数。系统滴答配置 1000，代表系统 1ms 要进行一次轮转调度，检查是否有更高优先级任务要执行（并切换任务）。100M 主频的单片机，执行一次调度（几十条语句），时间在 us 级别。1000 是一个比较适合的中等值，其他 100、10000，或者 2000 也可以，只是不利于系统以及编程。 如果滴答太大，10K，甚至 100K，对系统的负担比较大。因为自身调度会占用 CPU 时间。 1ms 滴答一次，方便编程系统延时。2k、10k 这种值，在用到系统延时时，不方便计算。 vTaskDelay(1000); 如果滴答值为 1000，则代表延时 1 秒； 如果滴答值为 2000，则代表延时 0.5 秒，很明显这种不利于编程； 实时操作系统的 SysTick，在没有特殊情况下，最好默认配置 1000； 在系统允许的情况下，SysTick 数值越大，系统实时性越高；反之实时性越差； 主频相对偏低（比如低于 10M）的处理器，SysTick 值可以适当配置低一点；","categories":["0.平台","嵌入式","RealTime"]},{"title":"CISC和RISC发展中的纠缠","path":"/2024/08/28/0-平台-平台相关-CISC和RISC发展中的纠缠/","content":"CISC 是英文“Complex Instruction Set Computer”的缩写，中文意思是“复杂指令集”，它是指英特尔生产的 x86（intel CPU 的一种命名规范）系列 CPU 及其兼容 CPU（其他厂商如 AMD,VIA 等生产的 CPU），它基于 PC 机(个人电脑)体系结构。这种 CPU 一般都是 32 位的结构，所以我们也把它成为 IA-32CPU。（IA: Intel Architecture，Intel 架构）。CISC 型 CPU 目前主要有 intel 的服务器 CPU 和 AMD 的服务器 CPU 两类。 RISC 是英文“Reduced Instruction Set Computing ” 的缩写，中文意思是“精简指令集”。它是在 CISC(Complex Instruction Set Computer)指令系统基础上发展起来的，有人对 CISC 机进行测试表明，各种指令的使用频度相当悬殊，最常使用的是一些比较简单的指令，它们仅占指令总数的 20％，但在程序中出现的频度却占 80％。复杂的指令系统必然增加微处理器的复杂性，使处理器的研制时间长，成本高。并且复杂指令需要复杂的操作，必然会降低计算机的速度。基于上述原因，20 世纪 80 年代 RISC 型 CPU 诞生了，相对于 CISC 型 CPU ,RISC 型 CPU 不仅精简了指令系统，还采用了一种叫做“超标量和超流水线结构”，大大增加了并行处理能力（并行处理并行处理是指一台服务器有多个 CPU 同时处理。并行处理能够大大提升服务器的数据处理能力。部门级、企业级的服务器应支持 CPU 并行处理技术）。也就是说，架构在同等频率下，采用 RISC 架构的 CPU 比 CISC 架构的 CPU 性能高很多，这是由 CPU 的技术特征决定的。目前在中高档服务器中普遍采用这一指令系统的 CPU，特别是高档服务器全都采用 RISC 指令系统的 CPU。RISC 指令系统更加适合高档服务器的操作系统 UNIX，现在 Linux 也属于类似 UNIX 的操作系统。RISC 型 CPU 与 Intel 和 AMD 的 CPU 在软件和硬件上都不兼容。 那么，目前 CISC 和 RISC 是现代微处理器的两大基础指令集结构。从技术和历史角度来看，CISC 和 RISC 的诞生和发展并非是你死我活的关系，RISC 被提出后，才将传统的指令集系统称为 CISC。而结构体系上的不同又令两者在发展道路上分道扬镳，渐行渐远。在这漫长的发展过程中，RISC 也曾经努力过，力求进入 CISC 的领域；CISC 也奋斗过，希望在 RISC 的世界中分得一杯羹。 ARM 是基于 RISC 的产品，而 PC 的代言人是 x86，基于 CISC。ARM、x86 之争，其实就是 RISC 和 CISC 之争。RISC 和 CISC 在长达 30 年的纠葛之后，再一次正面碰撞到了一起。如果说之前的 RISC 和 CISC 的碰撞都只是部分领域的小打小闹，那么现在 ARM 和 x86 有可能带来的是一场技术革命，一场全局化的战争。今天，我们将追本溯源，来看看 RISC 和 CISC 在历史上的交锋，和那些鲜为人知的故事。 今天，业内普遍认为 PC 性能的提升，特别是 CPU 性能的提升，动力来自于晶体管制造技术的不断进步。只有晶体管数量更多、运行频率更高，才能在单位时间内完成更多的工作任务，这也是上个世纪 70 年代以前的 PC 发展主流思想。当时的计算机速度很慢，特别是存储速度非常慢，广泛使用的慢速磁带存储设备以及大容量内存的缺乏，让计算机对每一字节空间的应用都很珍惜。在这样的情况下，人们倾向于在一条指令中完成更多的工作，比如“从内存和寄存器读取数据相加后，写入内存”。这实际上是四条指令，首先是从内存读取数据，其次是从寄存器读取数据，第三是相加，最后才是写入内存。一条指令可以完成四项工作，这是当时计算机的主流设计方案。 在上世纪 70 年代左右，IBM 以及其他企业的从业人员发现，目前的 PC 发展方向存在一定的问题。如果按照现在指令集发展的方向继续发展的话，那么现有的指令集系统会越来越复杂。而同时期编译器的流行，让这种情况发生了变化：一方面指令集越来越复杂，一方面编译器却很少使用这么多复杂的指令集。而且如此多的复杂指令，CPU 难以对每一个指令都做出优化，甚至部分复杂指令本身耗费的时间反而更多。对这件事情的总结，就是后来著名的“8020”定律，也就是在所有的指令集中，只有 20%最常用，80%基本上罕有问津。 时间进入了 1980 年代， Reduced Instruction Set Computing，也就是 RISC 精简指令集开始出现。这种指令集的优势在于将计算机中最常用的 20%的指令集集中优化，而剩下的不常用的 80%则采用拆分为常用指令集等方式运行。在 RISC 提出之后，人们才赋予了传统指令集一个正式的名称:ComplexInstruction Set Computing，也就是 CISC 复杂指令集。一时间，掀起了关于 RISC 和 CISC 究竟谁更好的争论。 英特尔的选择在指令集争论还没有结束的时候，英特尔在 IBM 不屑一顾地眼光下接下了为 IBM 生产民用 PC 的中央处理器的业务。实际上 IBM 并非无法自己生产 CPU，而是 IBM 觉得个人 PC 远没有大型主机的利润高，自家的 Power 架构用在兼容机上实在是“杀鸡焉用牛刀”。英特尔于是在之前研发的 C4004 处理器的基础上继续开发——C4004 处理器也并非英特尔自愿开发的产品，而是来自于日本一家名为 Busicom 的厂商的订货需求。也就是这个订货需求，为日后的 x86 的发展打下了基础。兼容 PC 的发展，带来了全球的信息化革命大潮。 很快英特尔生产了 8086 处理器，并依靠 PC 的快速发展一炮走红。这个时间段恰好是 RISC 开始崭露头角，CISC 被众人鄙视的年代。在 RISC 提出后，业内对 RISC 的未来发展进行了几乎一边倒的赞扬。从教学开始，美国大学计算机原理和系统结构的教材和教学模式全部来自于 RISC 的发明人 Hennessy 的理论，介绍的内容则是 Hennessy 研发的以 RISC 为基础的 MIPS 架构。而当时的研发论文 IEEE 和 ACM 发表的内容也基本上都对 RISC 提出了各种褒扬，x86 以及 CISC 被认为是没有什么前途的东西。 英特尔在当时的确是一个小公司，旗下只有几款产品，CPU 业务也才刚起步。面对整个业界一边倒向 RISC 的现状，英特尔要么一条道走到黑继续兼容自己的 8086 下定决心做 x86，要么放弃看起来没有什么希望的 CISC 投入 RISC 的怀抱。实际上当时 PC 刚刚起步，市场空间和前景极为庞大，如果放弃 PC 市场，可能对英特尔未来的发展带来巨大的不确定性。况且当时的 PC 用户已经有不少了，加上市场惯性，英特尔至少可以坚持开发两三代产品满足这部分 PC 用户的需求。在这样的情况下，英特尔毅然决定继续开发 x86，于是 80286 和 80386 等产品依次出炉。后来的事情大家都知道了，英特尔依靠 PC 市场赚得盆满钵盈，坚定了其在 x86 市场继续发力的决心。 高性能的 RISC 没有进入通用 PC 市场 PC 市场拱手让人、甚至连专利都没有注册，堪称 IBM 百年来最大的失误。看着自己当年随意选择的英特尔渐渐成长为可与自己匹敌的业界巨头，就连“备胎”AMD（AMD 当时是 IBM 根据反垄断条例而选择的 x86 处理器第二供货商）都逐渐发展壮大，IBM 后悔不迭。不过没关系，RISC 还在，IBM 还可以在高性能市场上呼风唤雨。 事实上，在上世纪 80 年代中末期，大量基于 RISC 的新指令集和产品的问世，让人们看到了精简指令集的威力。SGI 的工作站基于 MIPS，速度超群；IBM 的 Power 系列就不用说了，堪称巨型计算机的首选产品；还有 DEC Alpha 架构的处理器，都是 RISC 的代表之作。RISC 在高性能计算机上展现出的强大魅力，让用户和业界为之神往。 在这种情况下，英特尔也坐不住了。俗话说，吃着碗里的，看着锅里的。英特尔碗里面吃着 x86 这块大肥肉，锅里的 RISC 虽然是小肥牛，但也的确不错。于是，英特尔秘密开发了基于 RISC 的处理器 80860，希望打入通用计算机市场。但问题是，谁用呢？PC 已经是 x86 架构了，RISC 连兼容的操作系统和软件都没有，从头去建立生态系统和软件圈子，当时的英特尔很难成功。但英特尔决定多做一代试试看，于是不久之后又推出了新的 80960 处理器，依旧是 RISC 架构，向下兼容 80860，继续延续完全卖不动的“宿命”。于是英特尔想想干脆算了，直接做 x86，一条道走到黑！ 被拒绝的 Acorn 乱世出英雄，在上世纪 70 年代末 80 年代初，RISC 刚被提出、CISC 被众人鄙视、PC 刚刚起步的乱世年代，一家小公司的出现，改变了 RISC 和 CISC 在业界的态势。 就是在这间仓库中，ARM 公司的几大股东在一起开会，对全球移动计算市场产生巨大震撼的 ARM 架构就此诞生。 这家公司始创于 1978 年 12 月 5 日，创始人是物理学家赫尔曼·豪泽（Hermann Hauser）和工程师 ChrisCurry。公司的名字也很有意思，叫做 Cambridge Processing Unit，意为剑桥处理器公司，简写为 CPU。 1979 年，CPU 公司改名了，叫做 Acorn，主营业务从为市场提供电子设备，转向提供比较廉价的计算机设备。有多廉价呢？定价在 500 英镑以内。但是公司很快发现，摩托罗拉的 CPU 太慢价格又贵（摩托罗拉很快在 CPU 市场上被英特尔打得找不到北，惨淡收场）。于是 Acorn 公司去找英特尔索要 80286 的设计资料，打算自行搭建 PC 兼容机，但被英特尔无情拒绝了。 不知道英特尔会不会为这个决定而痛苦终身？被拒绝后的 Acorn 虽然火冒三丈，但志气滔天：不就是 CPU 吗！买不到还不能自己做吗？1985 年，一款使用 RISC 指令集，名字叫做 Acorn RISC Machion 的 CPU 诞生了，它的简称就是 ARM。 ARM 的特点是性能功耗比非常优秀，比如苹果的首款掌上触屏个人电子设备 Newton Message Pad 就使用了 ARM 处理器，随后还生产了多个型号。可惜由于软件和硬件技术局限等问题，它没有获得太大成功。但这为 ARM 的发展奠定了基础。1990 年，Acorn 公司干脆改名为 ARM。苹果出资 150 万英镑入股，Acorn 公司以价值 150 万英镑的知识产权和 12 个工程师入股。还有一个大股东是 VLSI，是一家芯片制造商。接下来由于市场不景气等原因，ARM 决定开放授权，成为一家设计公司，将自己的设计和知识产权授权给其他厂商生产芯片。这成为 ARM 辉煌的起点。 英特尔的逆袭和 ARM 的扩大英特尔最终发达起来了，占据了全球 PC 市场的绝大部分份额，IBM 再也无 法撼动英特尔的地位。但 CISC 的性能始终是硬伤，英特尔肯定看到了这一点，如果 x86 的性能一直无法赶上在顶端的 RISC 处理器，英特尔就没有办法把触手伸到最肥沃的服务器和超级计算机市场。从原理来说，x86 架构基于 CISC，本身问题不少，效率和发展方向都成问题。不过英特尔并不担心，在潜心研究了 RISC 后，英特尔开始大胆在基于 CISC 的 x86 中引入 RISC 的设计思想，增加了额外的一些“翻译层”。CPU 外部依旧是 x86，但是内部运行更为类似精简的 RISC，于是 CPU 效能得到极大的提升。Atom 本来是英特尔进入超便携移动计算市场的利器，但是 ARM 成功阻击了它。 在 Pentium 品牌推出后，英特尔开始逐渐在 x86 中引入 RISC 的设计思想。借助 PC 市场上攫取的巨额利润，英特尔开始疯狂提升 x86 处理器的性能。于是，在服务器和超级计算机市场上，英特尔的 Xeon 品牌开始逐渐发力，性能和当时的 RISC 处理器相比已不落下风甚至略有胜出。最终英特尔完成了逆袭的过程，x86 在服务器市场上大放光彩，甚至开始占据绝大部分市场份额，成就了 CISC 战胜 RISC 的神话。 不过在移动计算市场上，英特尔却无法复制这样的神话。高性能市场对功耗敏感度不高，性能是最重要的指标，英特尔可以凭借强大的研发能力来威胁对手，获取胜利。但移动计算市场对功耗极为敏感， 英特尔几次试图进入都无法获得成功。ARM 在这个领域遍地开花，从手机到平板电脑，ARM 凭借自己超高的性能功耗比屡获成功。 目前，x86 处理器占据了超过 90%的个人电脑市场，以 ARM 为代表的 RISC 产品则同样占据了超过 90%的移动计算市场。","categories":["0.平台","平台相关"]},{"title":"OK3568的文件系统裁剪","path":"/2024/08/28/0-平台-嵌入式-OK3568的文件系统裁剪/","content":"0. 概述现阶段在工作过程中使用的是飞凌嵌入式的 OK3568 开发板，需要对文件系统进行针对性裁剪，缩减文件系统大小，现裁剪前官方文件系统大小为 1.28GB，裁剪后文件系统大小为 0.7GB 1. 脚本分析在官方提供的开发包中，所有的编译过程都是由根目录下的 build.sh 控制的，跟踪该脚本发现编译文件系统的步骤如下： 执行 build.sh rootfs 通过 buildroot 方式编译文件系统 执行时，脚本调用其中的 build_rootfs 方法 build_rootfs 方法通过命令行输入参数判断当时用的 yocto 或 debian 或 distro 或 buildroot 的方式编译文件系统，当前我们选择的是 buildroot 调用 build_buildroot 方法，执行 device/rockchip/common 中的 mk-buildroot.sh 脚本 在 mk-buildroot.sh 脚本中调用 buildroot/build/envsetup.sh，envsetup.sh 用于初始化环境变量并设置 buildroot/configs/OK3568_defconfig 为 buildroot 编译文件系统的默认配置文件 读取 buildroot/configs/OK3568_defconfig 中的配置，并覆盖正在使用的配置文件，正在使用的配置文件位于 buildroot/.config，通过 buildroot/.config 配置文件系统 编译选项对文件系统大小的影响： 例.取消 BR2_PACKAGE_TENSORFLOW 选项不一定会使文件系统镜像大小变小，原因如下： 取消该选项只会影响到构建时是否编译 TensorFlow 软件包，对已经安装的软件包不会产生影响，因此对文件系统镜像大小的影响是有限的 TensorFlow 软件包可能并不占用很大的空间，因此取消该选项对文件系统镜像大小的影响也比较有限 因此，取消某一编译选项并不是一个有效的方法来减小文件系统镜像大小，可以考虑通过 删除不必要的文件 调整压缩参数 2.裁剪2.1 配置文件#include audio.config #音频相关的配置信息，例如采样率、声道数、编码格式等（已删）#include audio_gst.config\t#（已删）#include base.config #系统基本配置，例如时钟频率、内存分配、启动选项等#include base_extra.config#include benchmark.config #性能测试相关的配置信息，例如测试用例、测试参数#include bt.config #蓝牙相关的配置信息，例如蓝牙协议栈选项、蓝牙设备信息（禁删）#include camera.config #相机相关的配置信息，例如分辨率、曝光时间、帧率（已删）#include camera_gst.config\t#（已删）#include debug.config #调试相关的配置信息，例如日志级别、调试选项等#include debug2.config#include display.config #显示相关的配置信息，例如分辨率、屏幕旋转、色彩空间等#include gpu.config GPU #相关的配置信息，例如 GPU 频率、GPU缓存选项等#include network.config #网络相关的配置信息，例如 IP 地址、子网掩码、网络协议等；#include ntfs.config NTFS #文件系统相关的配置信息，例如文件系统选项、磁盘分区信息等；#include qt.config #QT 库相关的配置信息，例如 QT 版本、QT编译选项等；#include video_mpp.config #视频相关的配置信息，例如编码格式、分辨率、帧率等；（已删）#include video_gst.config （已删）#include video_gst_rtsp.config #RTSP 协议相关的配置信息，例如 RTSP服务器地址、端口号等；（已删）#include rk356x_arm64.config #开发板的硬件配置信息，例如 CPU 架构、内存大小、外设选项等；#include test.config #测试相关的配置信息，例如测试用例、测试参数等。BR2_PACKAGE_RECOVERY=y\t##启用Recovery软件包，用于在系统损坏或无法启动时恢复系统BR2_PACKAGE_RECOVERY_BOOTCONTROL=y\t#启用RecoveryBootControl软件包，用于控制系统启动时是否进入Recovery模式BR2_PACKAGE_RECOVERY_RETRY=y\t#启用RecoveryRetry软件包，用于在Recovery模式下重试更新操作BR2_PACKAGE_RECOVERY_USE_UPDATEENGINE=y\t#启用UpdateEngine软件包，用于在Recovery模式下进行系统更新BR2_PACKAGE_RECOVERY_UPDATEENGINEBIN=y\t#启用UpdateEngineBinary软件包，用于在Recovery模式下执行系统更新BR2_PACKAGE_RECOVERY_NO_UI=y\t#启用NoUIRecovery软件包，用于在Recovery模式下禁用UI界面BR2_TARGET_ENABLE_ROOT_LOGIN=y\t#启用root用户登录BR2_TARGET_GENERIC_ROOT_PASSWD=ubuntu\t#设置root用户的密码为ubuntuBR2_TARGET_GENERIC_GETTY_BAUDRATE_115200=y\t#设置终端波特率为115200BR2_TARGET_LOCALTIME=Asia/Shanghai\t#设置系统时区为亚洲/上海BR2_ROOTFS_OVERLAY=board/rockchip/ok3568/fs-overlay/\t#设置根文件系统的覆盖目录BR2_PACKAGE_TENSORFLOW=y\t#启用TensorFlow软件包（已删）BR2_PACKAGE_RKNPU2=y\t#启用RKNPU2软件包，用于支持Rockchip芯片的神经网络加速（已删）BR2_PACKAGE_RKAIQ_TOOL_SERVER=y\t#启用RKAIQToolServer软件包，用于支持Rockchip芯片的图像处理（已删）BR2_PACKAGE_FORLINX=y\t#启用Forlinx软件包BR2_PACKAGE_MATRIX_BROWSER=y\t#启用MatrixBrowser软件包，用于支持矩阵式键盘（已删）BR2_PACKAGE_DWKEYBOARD=y\t#启用DWKeyboard软件包，用于支持多语言输入法（已删）BR2_PACKAGE_QUECTELCM=y\t#启用QuectelCM软件包，用于支持Quectel无线模块（已删）BR2_PACKAGE_FORLINX_QT=y\t#启用ForlinxQt软件包BR2_PACKAGE_FORLINX_CMD=y\t#启用ForlinxCMD软件包BR2_PACKAGE_FFMPEG_AVRESAMPLE=y\t#启用FFmpegAvresample软件包，用于音频重采样（已删）BR2_PACKAGE_FFMPEG_SWSCALE=y\t#启用FFmpegSwscale软件包，用于视频缩放（已删）BR2_PACKAGE_HICOLOR_ICON_THEME=y\t#启用HicolorIconTheme软件包，用于支持高分辨率图标（已删）BR2_PACKAGE_QT5BASE_SQLITE_QT=y\t#启用Qt5BaseSQLiteQt软件包，用于支持SQLite数据库（已删）BR2_PACKAGE_QT5BASE_GIF=y\t#启用Qt5BaseGIF软件包，用于支持GIF图像格式（已删）BR2_PACKAGE_QT5CHARTS=y\t#启用Qt5Charts软件包，用于支持图表和统计数据的可视化（已删）BR2_PACKAGE_QT5SERIALBUS=y\t#启用Qt5SerialBus软件包，用于支持串行总线通信BR2_PACKAGE_QT5WEBKIT=y\t#启用Qt5WebKit软件包，用于支持Web浏览器（已删）BR2_PACKAGE_QT5WEBENGINE=y\t#启用Qt5WebEngine软件包，用于支持Web浏览器引擎（已删）BR2_PACKAGE_UBOOT_TOOLS=y\t#启用U-Boot工具软件包，用于支持U-Boot引导程序BR2_PACKAGE_PHP=y\t#启用PHP软件包，用于支持服务器端脚本语言（已删）BR2_PACKAGE_PHP_SAPI_CGI=y\t#启用PHPSAPICGI软件包，用于支持使用CGI接口运行PHP脚本（已删）BR2_PACKAGE_PHP_SAPI_CLI=y\t#启用PHPSAPICLI软件包，用于支持使用命令行接口运行PHP脚本（已删）BR2_PACKAGE_PHP_EXT_FILEINFO=y\t#启用PHPFileinfo扩展软件包，用于支持文件类型检测（已删）BR2_PACKAGE_PHP_EXT_OPCACHE=y\t#启用PHPOpcache扩展软件包，用于提高PHP脚本的执行效率（已删）BR2_PACKAGE_PHP_EXT_READLINE=y\t#启用PHPReadline扩展软件包，用于支持命令行编辑（已删）BR2_PACKAGE_PHP_EXT_ICONV=y\t#启用PHPIconv扩展软件包，用于支持字符集转换（已删）BR2_PACKAGE_PHP_EXT_MBSTRING=y\t#启用PHPMbstring扩展软件包，用于支持多字节字符集（已删）BR2_PACKAGE_PHP_EXT_JSON=y\t#启用PHPJSON扩展软件包，用于支持dJSON数据格式BR2_PACKAGE_PHP_EXT_TOKENIZER=y\t#启用PHPTokenizer扩展软件包，用于支持PHP代码解析（已删）BR2_PACKAGE_PHP_EXT_CURL=y\t#启用PHPcURL扩展软件包，用于支持HTTP请求（已删）BR2_PACKAGE_PHP_EXT_FTP=y\t#启用PHPFTP扩展软件包，用于支持FTP协议（已删）BR2_PACKAGE_PHP_EXT_SOAP=y\t#启用PHPSOAP扩展软件包，用于支持SOAP协议（已删）BR2_PACKAGE_PHP_EXT_XMLRPC=y\t#启用PHPXML-RPC扩展软件包，用于支持XML-RPC协议（已删）BR2_PACKAGE_TINYALSA=y\t#启用TinyALSA软件包，用于支持音频功能（已删）BR2_PACKAGE_LZO=y\t#启用LZO压缩软件包，用于支持数据压缩BR2_PACKAGE_LIBGTK3=y\t#启用GTK3库软件包，用于支持图形用户界面BR2_PACKAGE_OPENCV3=y\t#启用OpenCV3软件包，用于支持计算机视觉（已删）BR2_PACKAGE_OPENCV3_LIB_HIGHGUI=y\t#编译OpenCV3中的HighGUI库（已删）BR2_PACKAGE_OPENCV3_WITH_GTK3=y\t#启用GTK3支持（已删）BR2_PACKAGE_OPENCV3_LIB_PHOTO=y\t#Photo库（已删）BR2_PACKAGE_OPENCV3_LIB_SHAPE=y\t#Shape库（已删）BR2_PACKAGE_OPENCV3_LIB_STITCHING=y\t#Stitching库（已删）BR2_PACKAGE_OPENCV3_WITH_JASPER=y\t#启用Jasper支持（已删）BR2_PACKAGE_OPENCV3_WITH_JPEG=y\t#启用JPEG支持（已删）BR2_PACKAGE_OPENCV3_WITH_PNG=y\t#启用PNG支持（已删）BR2_PACKAGE_OPENCV3_WITH_PROTOBUF=y\t#启用ProtocolBuffers支持。（已删）BR2_PACKAGE_OPENCV3_WITH_TIFF=y\t#启用TIFF支持（已删）BR2_PACKAGE_OPENCV3_WITH_V4L=y\t#启用Video4Linux支持。（已删）BR2_PACKAGE_IPROUTE2=y\t#选中iproute2软件包进行编译BR2_PACKAGE_IPTABLES=y\t#选中iptables软件包进行编译BR2_PACKAGE_IPTABLES_BPF_NFSYNPROXY=y\t#编译iptables时启用BPF和nf_synproxy支持BR2_PACKAGE_IPTABLES_NFTABLES=y\t#编译iptables时启用nftables支持BR2_PACKAGE_LIGHTTPD=y\t#选中lighttpd软件包进行编译（已删）BR2_PACKAGE_LIGHTTPD_PCRE=y\t#编译lighttpd时启用PCRE支持（已删）BR2_PACKAGE_OPENSSH=y\t#选中OpenSSH软件包进行编译BR2_PACKAGE_VSFTPD=y\t#选中vsftpd软件包进行编译BR2_PACKAGE_RKWIFIBT=n\t#不选中rkwifibt软件包进行编译BR2_PACKAGE_USBMOUNT=n\t#不选中usbmount软件包进行编译BR2_PACKAGE_OPENCV3_LIB_PYTHON=y\t#编译OpenCV3中的Python库（已删）BR2_PACKAGE_LIBGTK3_BROADWAY=y\t#编译libgtk3时启用Broadway支持BR2_PACKAGE_LIBGTK3_WAYLAND=y\t#编译libgtk3时启用Wayland支持BR2_PACKAGE_OPENCV3_GUI_NONE=n\t#编译OpenCV3时启用GUI支持BR2_PACKAGE_QT5SERIALPORT=y\t#选中Qt5中的SerialPort模块进行编译 2.2 软件包Buildroot 的软件包配置文件位于 ~/buildroot/package/rockchip/Config.in，包含了多个软件包的配置，可以在基于 Rockchip 硬件的嵌入式系统上进行构建和安装。这些软件包并不是全部必须的，具体需要哪些软件包取决于嵌入式系统的具体需求和配置。 ROS\t机器人操作系统，提供了一种构建机器人应用的框架，包括硬件抽象、设备驱动、库、可视化工具、消息传递和软件包管理等功能\tLocalPlayer\t一个本地播放器，可以播放本地音频和视频文件\tAPL核心库\tAlexa Presentation Language（APL）的核心库，提供了一个用于构建Alexa智能屏幕体验的框架\tAVS设备SDK\tAlexa Voice Service（AVS）设备SDK，提供了一个用于构建Alexa智能设备的框架，包括语音识别、语音合成、音频处理、设备控制等功能\tAlexa智能屏幕SDK\t构建Alexa智能屏幕应用的SDK，包括模板、组件、样式、事件等功能\tACS\tAlexa客户端服务，提供了一个用于构建Alexa客户端应用的框架，包括设备授权、用户认证、设备状态管理等功能\tAlexa客户端SDK\t用于构建Alexa客户端应用的SDK，包括语音识别、语音合成、设备控制等功能\tMPP\tMedia Processing Platform，提供了一个用于嵌入式系统中音视频处理的框架，包括编解码、滤镜、音频处理等功能\td地址检查器\t提供了一种检查程序中地址错误的工具，帮助开发人员在程序开发过程中发现和纠正地址错误\tGStreamer1 Rockchip\t基于GStreamer1的Rockchip硬件加速插件，提供了硬件加速的音视频编解码和渲染功能\td相机引擎CIFISP\t用于Rockchip芯片的ISP引擎，提供了图像处理、白平衡、自动曝光、自动对焦等功能\tdWakeWordAgent\t唤醒词引擎，提供了唤醒词检测和响应的功能\tdPCBA\tPCB组装和测试工具，用于测试和组装PCB板\tdSoftAP\t软件接入点，提供了一个基于软件的Wi-Fi接入点，可以让其他设备连接到嵌入式系统的Wi-Fi网络\tdSoftAP服务器\t提供了一个Web服务器，可以通过Web界面配置和管理SoftAP\tdWifiautoSetup dGStreamer1 IEP\t基于GStreamer1的IEP插件，提供了硬件加速的视频编解码和渲染功能\tdrkwifibt dRockchip实用工具\t提供了一些用于Rockchip硬件的实用工具，包括升级工具、调试工具、驱动程序等\tmdev挂载\t提供了一种自动挂载U盘、SD卡等外部存储设备的工具\tALSA捕获\t提供了一个用于ALSA音频捕获的应用程序，可以从音频设备中捕获音频数据\tdUVC应用程序\t提供了一个用于UVC摄像头的应用程序，可以捕获视频数据并进行处理\tdUAC应用程序\t提供了一个用于USB音频类设备的应用程序\tdlibmali\tArm Mali GPU的用户空间驱动程序\tlibhdmiset\t提供了一个用于HDMI设置的库\tddialserver\t提供了一个用于远程管理设备的服务器\tlinux-rga\tRockchip Graphics Accelerator（RGA）的Linux内核驱动程序\tlinux-serial-test\t提供了一个用于Linux串口测试的应用程序\tdiflytekSDK\t提供了一个用于讯飞语音识别的SDK\tdeq_drc_process\t提供了一个用于音频均衡和动态范围控制的库\tdalsa_ladspa\t提供了一个用于ALSA音频的LADSPA插件库\tdrockchip_test\t提供了一些用于Rockchip硬件测试的工具\tQStressTest\t提供了一个用于系统压力测试的工具\trockchip_modules\t提供了一些用于Rockchip硬件的内核模块\tbroadcom_bsa\tBroadcom蓝牙栈的用户空间库\tcypress_bsa\tCypress蓝牙栈的用户空间库\tpm-suspend-api\t提供了一个用于系统挂起和恢复的API\trtw_simple_config\t提供了一个用于Realtek Wi-Fi芯片的简单配置工具\tdrecovery\t提供了一个用于恢复系统的工具\tmodeset\t提供了一个用于显示模式设置的工具\trkjpeg\t提供了一个用于Rockchip JPEG编解码的库\tdjpegdemo\t提供了一个用于JPEG编解码的演示程序\tdueventd\t提供了一个用于处理Linux系统事件的守护进程\trkupdate\t提供了一个用于Rockchip系统升级的工具\trktoolkit\t提供了一些用于Rockchip硬件的工具集\trkmedia\t提供了一个用于Rockchip媒体处理的框架\tdrockit\t提供了一个用于音视频处理的框架\tdrkadk\t提供了一个用于Rockchip AI开发的工具集\tdmusic\t提供了一个用于音乐播放的应用程序\tdvideo\t提供了一个用于视频播放的应用程序\tdcamera carmachine\t提供了一个用于车载娱乐系统的应用程序\tdgallery\t提供了一个用于图库管理的应用程序\tdQLauncher\t这是一个基于 Rockchip 平台的启动器，用于启动设备上的应用程序和服务\tQFacialGate\t这是一个用于人脸识别的软件包，可以在 Rockchip 平台上实现人脸识别功能\tdsettings\t这是一个提供设置和配置选项的软件包，可以帮助用户配置设备并进行各种设置\tQcamera dqfm\t这是一个文件管理器软件包，可以帮助用户管理设备上的文件和文件夹\tqplayer dMultivideoplayer dMulticamera dQsetting dpowermanager\t这是一个用于管理设备电源的软件包，可以帮助用户管理设备的电源状态和电池寿命\taudioservice\t这是一个用于管理设备音频的软件包，可以帮助用户管理设备的音频输入和输出\tdsecurityAuth recoverySystem\t这是一个用于设备恢复和修复的软件包，可以帮助用户在设备出现问题时进行恢复和修复操作\tLed_control_app dNpu_powerctrl dNpu_powerctrl_combine dN4 Cae_vad Ipc_share_memory Rk_hw_vad minigui\t这是一个轻量级的 GUI（图形用户界面）框架，可以帮助开发人员构建简单的 GUI 应用程序\tMinigui_demo Kernel_modules tensorflow Rknpurknpu2rknpu-fwrknn_demo\t这些软件包都与瑞芯微的神经处理单元（NPU）相关，可以帮助开发人员构建和优化神经网络模型\tdficial_gateRkfacialpose_bodyface_detect\t这些软件包都与面部识别相关，可以帮助开发人员构建和优化面部识别模型\tdrockx\t这是一个 Rockchip 平台上的计算机视觉库，提供了各种计算机视觉算法和工具\tdrockface\t这是一个人脸识别库，可以在 Rockchip 平台上实现人脸识别功能\tdmtp\t这是一个用于在计算机和移动设备之间传输文件的协议，可以帮助用户快速地在设备之间传输文件\tdalsa-config\t这是一个用于配置 ALSA（Advanced Linux Sound Architecture）的软件包，可以帮助用户配置设备的音频输入和输出\tdlibcapsimage\t这是一个用于处理图像的库，可以帮助开发人员处理和优化图像\tdrkscript\t这是一个用于运行脚本的工具，可以帮助用户在设备上运行各种脚本\tDeviceiodeviceio_release\t这是用于设备输入输出的软件包，可以帮助开发人员编写和优化输入输出驱动程序\tDui\t这是一个用于开发 UI（用户界面）应用程序的库，可以帮助开发人员构建和优化 UI 应用程序\tble_wificonfig\t这是一个用于配置蓝牙和 Wi-Fi 连接的软件包，可以帮助用户配置设备的无线连接\tdlibavb、libavb_ablibavb_user\t这些软件包都与 AVB（Android Verified Boot）相关，可以帮助用户验证设备的启动过程和系统完整性\tdlibv4l-rkmpp\t这是一个用于处理视频的库，可以帮助开发人员处理和优化视频\tdBootcontrolLinuxAB\t这些软件包都与启动控制相关，可以帮助用户管理设备的启动过程和控制\tsensor-daemon\t这是一个用于管理设备传感器的软件包，可以帮助用户管理设备的传感器和数据\trtc_demo\t这是一个用于管理设备 RTC（Real-Time Clock）的软件包，可以帮助用户管理设备的时间和日期\trk_webui\t这是一个用于开发 Web UI 应用程序的库，可以帮助开发人员构建和优化 Web UI 应用程序\tdcommon_algorithm\t这是一个用于处理常见算法的库，可以帮助开发人员处理和优化算法\tipcweb-backendLibgdbuslibIPCProtocollibrkdb\t这些软件包都与进程间通信相关，可以帮助开发人员实现进程间通信和数据传输\tDbserverNetserverstorage_managerMediaserveraiserver\t这些软件包都与设备管理和服务相关，可以帮助用户管理设备和服务\trk_oem\t这是一个用于 OEM和定制化的软件包，可以帮助设备制造商定制和优化设备\trootfs_ubi_use_custom_filesystem\t这是一个用于创建和管理 UBI（Unsorted Block Images）文件系统的软件包，可以帮助用户管理设备的文件系统\trkbar\t这是一个用于管理设备底部导航栏的软件包，可以帮助用户管理设备底部导航栏\tminilogger\t这是一个用于记录日志的工具，可以帮助用户记录设备的运行日志\tipc-daemonCallFunIpcisp2-ipc\t这些软件包都与进程间通信相关，可以帮助开发人员实现进程间通信和数据传输\tsmart_display_service\t这是一个用于管理设备智能显示的软件包，可以帮助用户管理设备的显示和显示设置\tonvif_server\t这是一个用于实现 ONVIF（Open Network Video Interface Forum）协议的软件包，可以帮助用户实现网络视频监控功能\tdeptz_demo\t这是一个用于实现电子变焦和电子云台功能的软件包，可以帮助用户实现更好的视频监控功能\tdrksl 和 sl_lock\t这些软件包都与设备安全相关，可以帮助用户保护设备安全和数据隐私\tmult_uvc_demo\t这是一个用于管理多个 UVC（USB Video Class）摄像头的软件包，可以帮助用户管理多个摄像头并进行视频捕捉和处理\tdpcba_adb_test\t这是一个用于测试设备 PCBA（Printed Circuit Board Assembly）的软件包，可以帮助用户测试设备硬件和连接性\tcamera_factory_test_server\t这是一个用于测试设备摄像头的软件包，可以帮助用户测试设备摄像头的性能和质量\tdthunderboot\t这是一个用于启动控制和固件更新的软件包，可以帮助用户管理设备的启动过程和固件更新\tstartup_app_ipc\t这是一个用于进程间通信的软件包，可以帮助开发人员实现进程间通信和数据传输\trkaiq_tool_server\t这是一个用于调试和优化 ISP（Image Signal Processor）的软件包，可以帮助开发人员调试和优化设备的图像处理功能\tdrkiio\t这是一个用于管理设备输入输出的软件包，可以帮助用户管理设备的输入输出\tlvgl\t这是一个用于开发 GUI 应用程序的库，可以帮助开发人员构建和优化 GUI 应用程序\tcvr_app\t这是一个用于Rockchip芯片的视频录制应用程序，可以在嵌入式系统上运行。它支持多种视频格式，包括H.264和H.265。该应用程序可以通过配置文件进行配置，以满足不同的录制需求。例如，可以设置录制分辨率、帧率、码率等参数\tdrkipc\t这是一个用于Rockchip芯片的IPC（Inter-Process Communication）库，用于在嵌入式系统中实现进程间通信。它提供了多种IPC机制，包括共享内存、消息队列、信号量等。该库可以用于不同的应用程序之间进行通信，例如音视频采集、编码、解码等\trkfsmk\t这是一个用于Rockchip芯片的文件系统制作工具，用于制作嵌入式系统中的文件系统。它支持多种文件系统格式，包括ext2、ext3、ext4等。该工具可以根据配置文件生成文件系统镜像，以便在嵌入式系统中使用","categories":["0.平台","嵌入式"]},{"title":"嵌入式介绍","path":"/2024/08/28/0-平台-嵌入式-嵌入式介绍/","content":"嵌入式 linux 开发介绍嵌入式系统简介 一般定义 以应用为中心、以计算机技术为基础、软件硬件可裁剪、适应应用系统，对功能、可靠性、成本、体积、功耗严格要求的专用计算机系统 广义上讲 凡是带有微处理器的专用软硬件系统都可称为嵌入式系统。 嵌入式系统又分为多个模块部分 ARM 重视理论实践 系统移植 重视流程 驱动 重视框架 嵌入式系统的组成 软件（linux，VXwork + 应用程序） 硬件（C51，stm32， arm，mips powerpc + DRAM emmc uart） win BIOS win 系统 文件系统加载驱动 应用程序 linux bootloader（引导程序） linux 内核 挂载文件系统驱动 应用程序 运行操作系统的优点： 方便开发 将硬件与软件隔离（保护硬件） 嵌入式 linnux 系统移植做哪些工作产品升级（产品添加某些功能模块，产品裁剪了某些功能模块，A8 –》 A9 嵌入式开发环境的搭建采用的交叉开发模式，即编译和运行不在同一台主机上 GCC 简介Gcc 的编译流程： 预处理 gcc -E 编译 gcc -S 汇编 gcc -c 链接 gcc gcc 工具集 readelf：功能：readelf 可以显示 elf 格式可执行文件的信息 size：功能：size 列出目标文件每一段的大小以及总体的大小 nm：功能：nm 可以列出目标文件中的符号。 strip 功能：strip 用来丢弃目标文件中的全部或者特定符号，减小文件体积。对于嵌入式系统，这个命令必不可少。 objcopy：功能：objcopy 可以进行目标文件格式转换 objcopy -O binary hello hello.bin objcopy -O binary u-boot u-boot.bin objdump: 功能：反汇编 objdump -d hello objdump -d hello hello.dis addr2line 功能：addr2line 能够把程序地址转换为文件名和行号，前提是这个可执行文件包括调试符号。 安装交叉编译工具链 解压 gcc-4.6… 到 tootchain 配置环境变量 sudo vi /etc/bash.bashrc export PATH=$PATH:/home/linux/toolchain/gcc-4.6.4/bin/ 重启 source etcbash.bashrc 测试 arm-none-linux-gnueabi-gcc –v TFTP 服务器的安装和配置tftp 是用来下载远程文件最简单的网络协议 修改配置文件，开启 tftp 服务 sudo vi /etc/default/tftp-hapa 修改成： TFTP_USERNAME=tftp TFTP_DIRECTORY=/tftpboot //指定tftp服务器的目录，将来要下载东西都是从这个目录下下载，需自行创建，然后修改权限为777TFTP_ADDRESS=0.0.0.0:69 //69： tftp 专有的端口TFTP_OPTIONS=-c -s -l //man tftpd可查看各个选项的含义//-c：表示可以在服务器目录下（/tftpboot）下创建新文件，默认不能创建新文件，只能修改或覆盖//-s: 改变 tftp 启动的根目录，也就是客户端在使用 tftp 时不需要输入/tftpboot 目录//-l：表示以监听模式启动 tftp 服务器 创建服务器的根目录tftpboot sudo mkdir /tftpbootchmod 777 /tftpboot -R 重启 tftp 服务器 sudo service tftpd-hpa restart 登录本机进行测试 tftp localhost 或者 tftp 192.168.1.111 或者 tftp 127.0.0.1tftp get xxx //从服务器（/tftpboot 目录）下载文件名为 XXX 的文件tftp put xxx //xxx 为你想要往服务器（/tftpboot 目录）发送的文件tftp q //q 表示退出 nfs 服务器的安装和配置nfs 主要用来进行目录的共享（把本地的一个目录通过网络导出，其他设备可以远程访问该目录），我们的测试程序不用通过下载到目标板，目标机可以通过共享目录访问，提高开发效率。 修改配置文件 sudo vi /etc/export 在最后一行添加： /source/rootfs *(rw,sync,no_subtree_check,no_root_squash)///source/rootfs 是指定的共享目录，需自己创建//rw：具有读写权限//sync：文件同步//no_subtree_check: 如果共享子目录，则不检查父目录的权限//no_root_squash: 如果客户端为 root 用户，则它对此目录有 root 权限 重启 nfs 服务 sudo service nfs-kernel-server restart 创建共享目录 mkdir /source/rootfs ubuntu 的网络配置配置虚拟机 IP（桥接），设置 IP 地址，sudo vi etcnetworkinterfaces auto eth0iface eth0 inet staticaddress 192.168.1.111netmask 255.255.255.0gateway 192.168.1.1 设置 DNS，sudo vi /etc/resolv.conf 在最后一行添加： nameserver 192.168.1.1 重启网络服务 sudo /etc/init.d/networking restart 开发环境测试SD 启动盘制作和 u-boot 的烧写制作 SD 卡目的：通过 SD 卡烧写 uboot 到开发板上 烧写 uboot 到 emmc 上 连接串口和板子，运行串口通信程序(putty 第一天工具中) 关闭开发板电源，将拨码开关 SW1 调至(1000)(SD 启动模式)后打开电源 将刚才做好的 SD 启动盘插入 SD 卡插槽 倒计时按下任意键，进入 uboot 界面 烧写 在终端上执行 sdfuse flashall 等待终端无输出是表示烧写结束 从网络下载内核、设备树，并挂载文件系统如何把服务器（ubuntu 中的tftpboot 目录）下的内核和设备树下载到开发板？ 将你要下载的东西放到服务器目录下。 拷贝 uImage、exynos4412-fs4412.dtb 到 ubuntu 的tftpboot 目录下。 将第一天镜像文件rootfs.tar.xz 拷贝到 ubuntu 的 source 下并解压 开发板启动，在 u-boot 界面(倒计时按下任意键)进行下载。 Ubuntu IP: 192.168.9.120 开发板 IP: 192.168.9.233 #setenv serverip 192.168.9.120#setenv ipaddr 192.168.9.233#setenv bootcmd tftp 41000000 uImage\\;tftp 42000000 exynos4412-fs4412.dtb\\;bootm 41000000 - 42000000 console=ttySAC2,115200 init=/linuxrc ip=192.168.9.233#saveenv 重启开发板 从 EMMC 加载内核和文件系统烧写镜像到 emmc 中设置启动参数，从 emmc 加载镜像","categories":["0.平台","嵌入式"]},{"title":"构建工具的简要介绍","path":"/2024/08/28/0-平台-嵌入式-构建工具的简要介绍/","content":"make cmake qmake meson buildroot yocto Buildroot 和 Yocto 是常用的嵌入式 Linux 系统构建工具，各自具有独特的特点和适用场景。 Meson 与 Buildroot 和 Yocto 不同，它主要关注构建过程的效率和简化，而不是整个系统的构建。 MesonMeson 是一个现代化的构建系统，旨在提高构建速度和可维护性。它使用简单的语法，支持多种编程语言，特别适合大型项目。Meson 的特点包括： 快速构建：通过并行构建和增量构建，Meson 能够显著减少构建时间。 易于使用：其配置文件使用简单的语法，易于理解和维护。 跨平台支持：Meson 支持多种平台和编译器，适合多种开发环境。 BuildrootBuildroot 是一个简单高效的工具，用于生成嵌入式 Linux 系统。它通过 Makefile 和 Kconfig 配置系统，支持交叉编译，能够快速构建精简的 Linux 系统。Buildroot 的主要特点包括： 简单易用：使用类似 Linux 内核的配置界面（如 menuconfig），用户可以快速配置和构建系统，通常只需 15-30 分钟即可完成基本系统的构建。 高效性：适合资源有限的环境，特别是需要快速迭代的项目。它提供了丰富的包配置，支持多种库和应用程序。 构建时间短：由于其构建过程相对简单，Buildroot 的构建时间通常比 Yocto 要短。 适用场景：适合小型项目和需要快速原型开发的情况 YoctoYocto Project 是一个开源项目，旨在为嵌入式 Linux 开发者提供创建自定义 Linux 系统的工具和模板。其特点包括： 高度定制化：Yocto 支持复杂的依赖关系和层次结构，适合需要高度定制和复杂功能的大型项目。 强大的构建系统：使用 BitBake 作为构建引擎，能够处理复杂的构建任务，提供丰富的开源支持。 灵活性：Yocto 允许开发者根据不同的硬件和软件需求，创建适合特定应用的 Linux 版本。 适用场景：适合需要支持多个硬件平台和复杂软件栈的项目","categories":["0.平台","嵌入式"]},{"title":"Sqlite3","path":"/2024/08/28/0-平台-嵌入式-应用软件移植-Sqlite3/","content":"Qt 交叉编译Qt 使用数据库时提示 QSqlDatabase: QSQLITE driver not loaded 问题原因是交叉编译的 qt 中可能是裁剪过的版本，其中没有 sqlite 的驱动，需要交叉编译 qsqlite 驱动 下载 qt 源码: http://download.qt.io/ 找到 qt-everywhere-opensource-src-5.3.2.tar.gz，要求 qt-everywhere-opensource-src 版本需与编译器版本一致。 解压源码 tar -xvf qt-everywhere-opensource-src-5.3.2.tar.gz 进入目录 cd qt-everywhere-opensource-src-5.3.2/qtbase/src/plugins/sqldrivers/sqlite 执行编译 qmakemake 拷贝生成的库到开发板上，库的路径在生成在 qt-everywhere-opensource-src-5.3.2/qtbase/plugins/sqldrivers/libqsqlite.so，拷贝 libqsqlite.so 到开发板 /usr/lib/qt5/plugins/sqldrivers/，如果没有，则执行创建 mkdir /usr/lib/qt5/plugins/sqldrivers Sqlite 使用Sqlie使用 C 代码编写源码下载地址 https://www.sqlite.org/download.html 以下两个对象和八个方法构成了 SQLite 接口的基本元素： //数据库连接对象。通过创建 sqlite3_open,并通过破坏sqlite3_closesqlite3//准备好的语句对象。通过创建 sqlite3_prepare,并通过破坏sqlite3_finalizesqlite3_stmt//打开与新的或现有的SQLite数据库的连接。sqlite3的构造函数。sqlite3_open()//将SQL文本编译为字节代码，它将完成查询或更新数据库的工作。sqlite3_stmt的构造函数。sqlite3_prepare()//将应用程序数据存储到 原始SQL的参数中。sqlite3_bind()//将sqlite3_stmt前进到下一个结果行或完成。sqlite3_step()//当前结果行用于在→列值sqlite3_stmt。sqlite3_column()// sqlite3_stmt的析构函数。sqlite3_finalize()// sqlite3的析构函数。sqlite3_close()//一个包装函数，对一个或多个SQL语句字符串执行sqlite3_prepare()，sqlite3_step()， sqlite3_column()和sqlite3_finalize()。sqlite3_exec() 交叉编译cdmkdir sqlite3 #在主机（如Ubuntu）创建工作目录cd sqlite3 #进入工作目录中tar zxvf sqlite-autoconf3080500.tar.gz #解压cd sqlite-autoconf3080500 #进入解压后的目录mkdir../install #创建安装目录export PATH=$PATH:/usr/local/arm-2010q1/bin #交叉编译工具路径加入系统环境变量./configure--host=arm-none-linux-gnueabi --prefix=/home/gary/sqlite3/installmakemake install –host： 指定交叉编译工具，一般为 arm-linux、arm-linux-gnueabihf 等，根据板子用的交叉编译工具来。 –prefix： 指定安装目录，编译后的文件会全部放在安装目录中。必须是绝对路径 之后拷贝编译完成的镜像到开发板上即可。 DemoC 代码#includestdio.h#includesqlite3.h//exec传入 int callback(void*arg ,int num, char**rowdata , char** title)\tstatic int flag = 0;\tint i=0;\tif(flag == 0) printf(%d , num); for(; inum; i++) printf(%s , title[i]); printf( ); flag = 1; for(i=0; inum; i++) printf(%s , rowdata[i]); printf( );\treturn SQLITE_OK;int main(int argc, char **argv)\t//1.打开数据\tsqlite3 *ppdb;\tint empty=1;\tchar *err=0;\tint ret = sqlite3_open(./test.db, ppdb);\tif(ret != SQLITE_OK) perror(open sqlite3 fail); return -1; //2.执行\t//char *sql = insert into gec_94(name, age) values (amao, 100);; //（插入数据）\t//char *sql = delete from gec_94 where name like amao;; //删除\t//char *sql = select * from gec_94;; //查询\tchar *sql = create table gec_94(id int primary key,msg varchar(128));//创建表\tret = sqlite3_exec(ppdb, sql, callback, empty, err);\tif(ret != SQLITE_OK) perror(exec sqlite3 create table fail); sqlite3_close(ppdb); return -1; ret = sqlite3_exec(ppdb, select * from gec_94;, callback, empty, err);\tif(ret != SQLITE_OK) perror(exec sqlite3 fail); sqlite3_close(ppdb); return -1; //3.关闭\tsqlite3_close(ppdb); return 0; Makefile#gcc sqlit3.c sqlite3.c sqlite3.h -o main -lpthread -ldlTARGET=queue#CC=arm-linux-gccSRCS=sqlit3.c sqlite3.cOBJS=$(patsubst %.c,%, $(SRCS))#SRCS=$(wildcard *.cpp)#OBJS=$(patsubst %.cpp, %, $(SRCS))LIB=-lpthread -ldlINCLUDE=ADD=-Wno-psabi ADD1=-enable-static main:$(SRCS)\t$(CC) $^ -o $@ $(LIB)clean:\trm -f $(OBJS) main","categories":["0.平台","嵌入式","应用软件移植"]},{"title":"嵌入式中的gsnap截屏","path":"/2024/08/28/0-平台-嵌入式-应用软件移植-嵌入式中的gsnap截屏/","content":"Linux 系统的 FrameBuffer 机制，会把屏幕上的每个点映射成一段线性内存空间，程序就可以通过改变这段内存的值来改变屏幕上某一点的颜色。屏幕色彩的原始数据保存在devfb0 文件。 cat /dev/fb0 fb.raw #读取该文件获得数据cat fb_data.raw /dev/fb0 #数据回显到 framebuffer 这种原始数据无法通过简单的工具直接查看，特别是在精简的嵌入式 Linux 系统上。因此，通过工具 gsnap。这个工具可以将 framebuffer 中的数据直接保存为 png 或者 jpeg 格式的图片。 打开 gsnap 的 Makefile 文件，该源码依赖 libpng、libjpeg、zlib、libmath 四种库。 交叉编译 libjpeg进入到源码目录，执行 ./configure --host=arm-linux --prefix=./jpeg_install/ 然后执行 makemake install 在安装目录 ./jpeg_install/ 得到交叉编译过的库。 交叉编译 zlib由于 zlib 中的 configure 并未提供–host 参数，因此需要为它手动指明交叉编译器： export CC=arm-fsl-linux-gnueabi-gcc./configure --prefix=./z_install/makemake install 交叉编译 libpngzlib 是 libpng 的依赖，因此在交叉编译 libpng 之前，必须首先编译 zliblibpng 中提供有 Linux 平台下的 Makefile 例程，可以直接修改使用。进入到 libpng 的源码目录，执行拷贝 cp scripts/makefile.linux Makefile，打开 Makefile 修改，修改交叉编译器名称和依赖的 zlib 的路径。执行 make、makeinstall 得到头文件和库文件。 交叉编译 gsnap将上述得到的库文件和头文件分别集中拷贝到自行建立的 lib 和 includes 目录下，并修改 gsnap 的 Makefile。执行 make 后就能得到可执行文件 gsnap。 将得到的 gsnap 可执行文件拷贝到目标板的usrbin 目录下，执行截屏命令： gsnap fb.jpg /dev/fb0","categories":["0.平台","嵌入式","应用软件移植"]},{"title":"云服务管理软件-1panel","path":"/2024/08/27/0-平台-服务器-工具-云服务管理软件-1panel/","content":"云服务管理软件：开源的 1panel 创建 1panel 文件夹，进入后，执行以下命令安装： #先安装dockersudo apt install docker.iocurl -sSL https://resource.fit2cloud.com/1panel/package/quick_start.sh -o quick_start.sh sudo bash quick_start.sh 输入安全入口，之后登陆时需要安装 IP 地址 + 端口号 + 安全入口的形式进入管理页面 124.224.246:9090/liuluhua 输入登录用户名和密码 liuluhua-passwd 之后已完成 1panel 部署，可以方便的进行软件的管理","categories":["0.平台","服务器","工具"]},{"title":"QComboBox样式表","path":"/2024/08/27/1-语言-Qt-样式表-QComboBox样式表/","content":"字体样式QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗，bold 为加粗， normal 为不加粗 color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 对于字体样式，可以把 family size style weight 统一设置在 font 属性中： font: bold italic 18px Microsoft YaHei; 这里出现的顺序要求是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family 文字位置padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; padding-left 为设置按钮(包括选择框和文字)距离左边边界的距离 padding-top 为设置按钮(包括选择框和文字)距离顶边边界的距离 padding-right 为设置按钮(包括选择框和文字)距离右边边界的距离 padding-bottom 为设置按钮(包括选择框和文字)距离底边边界的距离 在 qss 中，属性 text-align 对 QComboBox 是不起作用的，一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以精确地调节文字的显示位置 下面我们调节字体左间距为 30px QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; 可以看到我们设置的 padding-left 只对按钮框文字起作用，对下拉列表不起作用，后面我们会单独讨论下拉框样式 边框样式border-style: solid;border-width: 2px;border-color: aqua; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 2px; border-style: solid; border-color: aqua; 我们也可以把 border 的 width style color 一起设置在 border 属性中： border: 2px solid aqua; 但必须注意的是，值的顺序必须是按照 width style color 来写，不然不会生效！如果不想显示边框可以直接设置 border 属性值为 none 也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 QComboBox 下面我们来设置左上角和左下角半径 QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 2px; border-style: solid; border-color: aqua; border-top-left-radius: 13px; border-bottom-left-radius: 13px; 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 比如我们给 QComboBox 左边添加一个背景图片 QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #BDC8E2; font-style: italic; font-weight: bold; padding-left: 30px; border-width: 1px; border-style: solid; border-color: aqua; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 对于 background，可以把 color image repeat position 一起设置在 background 属性中： background: url(./image.png) no-repeat left center #2E3648; color image repeat position 这些属性值出现的顺序可以任意 动态样式可以设置鼠标悬浮时的样式 QComboBox:hover color: green; background-color: black; 当下拉列表显示出来时的样式 QComboBox:on color: red; background-color: black; 当下拉框按钮可编辑输入文字时的样式 QComboBox:editable color: white; background-color: #2E3648; 想要可编辑样式生效需要设置下拉框按钮为可编辑，比如调用 setEditable() 方法，值得注意的是，一旦可编辑样式生效，其它类似于 hover、on 所设置的样式都会被覆盖掉，除非再次设置为不可编辑 下拉图标下拉图标属于下拉框按钮的一个子控件 drop-down，而 drop-down 中又包含 down-arrow 子控件，我们用样式表把这两个控件显示出来： QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: normal; font-weight: bold;QComboBox::drop-down border: 1px solid red;QComboBox::down-arrow border: 1px solid green; 在样式表中，我们设置 drop-down 边框颜色为红色，down-arrow 边框为绿色。我们也可以自定义 drop-down 控件的大小和位置： QComboBox font-family: Microsoft YaHei; font-size: 14px; color: #000000; font-style: normal; font-weight: bold; padding-left: 6px;QComboBox::drop-down width:28px; height:22px; border: 1px solid red; subcontrol-position: center top; subcontrol-origin: padding;QComboBox::down-arrow border: 1px solid green; width 和 height 设置 drop-down 的宽高 subcontrol-position 设置 drop-down 的位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 subcontrol-origin 设置 drop-down 的对齐方式，一般设置为 padding 如果想要自定义的 width、height、subcontrol-position 生效，必须在 QComboBox 按钮中设置 padding 的值，哪怕设置值为 0，否则无法生效！ 当然，我们也可以设置 drop-down 的圆角半径 border-radius，属性值和其它控件样式的设置方式一样： border-top-left-radius: 6px;border-top-right-radius: 6px;border-bottom-left-radius: 6px;border-bottom-right-radius: 6px;border-radius: 6px; 同时，我们还可以往 drop-down 添加图片，方式有两种： image: url(./arrow_down.png);background-image: url(./arrow_down.png); image 设置唯一的自动适应不重复的图片，而 background-image 则需要手动调节它的 repeat, position 属性值。这里，我们不推荐在 drop-down 中设置图片，因为它有一个更好放图片的控件 down-arrow","categories":["1.语言","Qt","样式表"]},{"title":"QLabel样式表","path":"/2024/08/27/1-语言-Qt-样式表-QLabel样式表/","content":"QLabel font-family: Microsoft YaHei; font-size: 14px; color: #BDC8E2; background-color: #2E3648; 字体样式font-family: Microsoft YaHei;font-size: 14px;font-style: italic;font-weight: bold;color: #BDC8E2;font: bold italic 18px Microsoft YaHei; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体样式，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗样式，bold 为加粗， normal 为不加粗 font 为同时设置字体 style weight size family 的样式，但是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 文字位置padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; padding-left 为设置文字距离左边边界的距离 padding-top 为设置文字距离顶边边界的距离 padding-right 为设置文字距离右边边界的距离 padding-bottom 为设置文字距离底边边界的距离 在 qss 中，属性 text-align 对 Label 是不起作用的，只能通过设置 padding 来实现文字的显示位置；一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以在任意位置显示了（默认情况下文字是上下左右都居中显示的） 边框样式border-style: solid;border-width: 2px;border-color: red;border: 2px solid red; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent border 为同时设置 border 的 width style color 属性，但值的顺序必须是按照 width style color 来写，不然不会生效！也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 Label 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 background 为设置背景的所有属性，color image repeat position 这些属性值出现的顺序可以任意 示例QLabel font-family: Microsoft YaHei; font-size: 18px; color: #BDC8E2; font-style: normal; font-weight: normal; border-style: solid; border-width: 2px; border-color: aqua; border-radius: 20px; padding-left: 20px; padding-top: 0px; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 动态样式鼠标悬浮时的样式 QLabel:hovercolor: red;border-color: green; background-color: aqua; 标签禁止时的样式 QLabel:disabledcolor: blue;border-color: brown; background-color: aqua; 不过，遗憾的是，标签并没有点击 pressed 这种样式的","categories":["1.语言","Qt","样式表"]},{"title":"QPushButton样式表","path":"/2024/08/27/1-语言-Qt-样式表-QPushButton样式表/","content":"QPushButton font-family: Microsoft YaHei; font-size: 16px; color: #BDC8E2; background-color: #2E3648; 字体样式font-family: Microsoft YaHei;font-size: 14px;font-style: italic;font-weight: bold;color: #BDC8E2;font: bold italic 18px Microsoft YaHei; font-family 为设置字体类型，标准形式需要加双引号，不加也可能会生效，具体看系统是否支持，中英文都支持，但要保证字体编码支持，一般程序编码为”utf-8”时没问题。 font-size 为设置字体大小，单位一般使用 px 像素 font-style 为设置字体斜体，italic 为斜体， normal 为不斜体 font-weight 为设置字体加粗，bold 为加粗， normal 为不加粗 font 为同时设置字体 style weight size family 的样式，但是 style 和 weight 必须出现在开头，size 和 family 在后面，而且 size 必须在 family 之前，否则样式将不生效，font 中不能设置颜色，可以单独设置 style weight 和 size，不能单独设置 family color 为设置字体颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent 字体颜色用的是 color 属性，没有 font-color 这个属性的 文字位置text-align: left center;padding-left: 10px;padding-top: 8px;padding-right: 7px;padding-bottom: 9px; text-align 为设置文字位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 padding-left 为设置文字距离左边边界的距离 padding-top 为设置文字距离顶边边界的距离 padding-right 为设置文字距离右边边界的距离 padding-bottom 为设置文字距离底边边界的距离 特殊的位置可以使用 text-align 来设置，如果要精确设置位置只能通过 padding 来设置，一般 padding-left 相当于 x 坐标，padding-top 相当于 y 坐标，设置这两个就可以显示任意位置显示了（默认情况下文字是上下左右都居中显示的） 边框样式border-style: solid;border-width: 2px;border-color: red;border: 2px solid red; border-style 为设置边框样式，solid 为实线， dashed 为虚线， dotted 为点线， none 为不显示（如果不设置 border-style 的话，默认会设置为 none） border-width 为设置边框宽度，单位为 px 像素 border-color 为设置边框颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent border 为同时设置 border 的 width style color 属性，但值的顺序必须是按照 width style color 来写，不然不会生效！ 也可以单独设置某一条边框的样式 border-top-style: solid;border-top-width: 2px;border-top-color: red;border-top: 2px solid red;border-right-style: solid;border-right-width: 3px;border-right-color: green;border-right: 3px solid green;border-bottom-style: solid;border-bottom-width: 2px;border-bottom-color: blue;border-bottom: 2px solid blue;border-left-style: solid;border-left-width: 3px;border-left-color: aqua;border-left: 3px solid aqua; border-top-style 为设置顶部边框样式 border-top-width 为设置顶部边框宽度 border-top-color 为设置顶部边框颜色 border-top 为设置顶部边框 width style color 的属性，原理和 border 一致其它三个边框：right bottom left 边框的设置都相同 设置边框半径border-top-left-radius: 20px;border-top-right-radius: 20px;border-bottom-left-radius: 20px;border-bottom-right-radius: 20px;border-radius: 20px; border-top-left-radius 为设置左上角圆角半径，单位 px 像素 border-top-right-radius 为设置右上角圆角半径，单位 px 像素 border-bottom-left-radius 为设置左下角圆角半径，单位 px 像素 border-bottom-right-radius 为设置右上角圆角半径，单位 px 像素 border-radius 为设置所有边框圆角半径，单位为 px 像素，通过圆角半径可以实现圆形的 PushButton 背景样式background-color: #2E3648;background-image: url(./image.png);background-repeat: no-repeat; background-position: left center;background: url(./image.png) no-repeat left center #2E3648; background-color 为设置背景颜色，可以使用十六进制数表示颜色，也可以使用某些特殊的字体颜色：red, green, blue 等，或者使用 rgb(r,g,b) 和 rgba(r,g,b,a) 来设置，其中 r、g、b、a 值为 0~255，如果想不显示颜色可以设置值为透明 transparent background-image 为设置背景图片，图片路径为 url(image-path) background-repeat 为设置背景图是否重复填充背景，如果背景图片尺寸小于背景实际大小的话，默认会自动重复填充图片，可以设置为 no-repeat 不重复，repeat-x 在 x 轴重复，repeat-y 在 y 轴重复 background-position 为设置背景图片显示位置，只支持 left right top bottom center；值 left right center 为设置水平位置，值 top bottom center 为设置垂直位置 background 为设置背景的所有属性，color image repeat position 这些属性值出现的顺序可以任意 示例QPushButton font-family: Microsoft YaHei; font-size: 16px; color: #BDC8E2; font-style: italic; font-weight: bold; text-align: left center; padding-left: 25px; padding-top: 0px; border-style: solid; border-width: 2px; border-color: aqua; border-radius: 20px; background-color: #2E3648; background-image: url(./image.png); background-repeat: no-repeat; background-position: left center; 动态样式设置鼠标悬浮时的样式 QPushButton:hover\tcolor: red;\tborder-color: green; background-color: aqua; 鼠标点击时的样式 QPushButton:pressed\tcolor: green;\tborder-color: blueviolet; background-color: black; 按钮禁止时的样式 QPushButton:disabled\tcolor: blue;\tborder-color: brown; background-color: aqua; 下拉菜单对于 QPushButton，可以给它设置添加一个下拉菜单，这需要调用 QPushButton 的 setMenu() 方法，当菜单设置成功后，QPushButton 就会默认添加一个 menu-indicator 下拉菜单指示器图标，我们可以对这个菜单图标进行样式修改 QPushButton::menu-indicator image: url(./image.png); subcontrol-position: right center; subcontrol-origin: padding; right: 10px; top: 15px; image 为设置菜单指示器图标 subcontrol-position 设置菜单指示器图标的位置，如果不设置的话会默认放在右下角 subcontrol-origin 为设置菜单指示器图标与按钮之间的停靠位置，默认为 padding right top left bottom 为设置菜单指示器图标距离按钮四个位置的距离 当然下拉菜单指示器图标也有动态样式 QPushButton::menu-indicator:hover image: url(./image1.png)QPushButton::menu-indicator:pressed image: url(./image2.png)QPushButton::menu-indicator:open image: url(./image2.png) 对于 menu-indicator 来说 pressed 和 open 原理相同","categories":["1.语言","Qt","样式表"]},{"title":"敏捷开发","path":"/2024/08/27/1-语言-语言结构-敏捷开发/","content":"敏捷开发模式是一种软件开发方法论，旨在通过迭代和增量的方式交付高质量的软件产品。它强调灵活性、快速响应变化、团队协作以及持续交付。敏捷开发模式的核心思想是通过短周期的开发迭代（通常称为“迭代”或“冲刺”）来逐步构建和完善产品，从而快速适应需求变化并持续向客户交付价值。 敏捷开发的主要特点 迭代与增量开发：项目分为多个迭代，每个迭代持续 1 到 4 周。在每个迭代结束时，团队交付一个可工作的产品增量，逐步完善产品。 持续反馈与改进：通过频繁的反馈循环，团队能够在每个迭代后反思并改进开发过程，确保项目朝着正确的方向发展。 拥抱变化：敏捷开发鼓励团队适应需求的变化，而不是严格按照最初的计划执行。需求的变化被视为客户对市场的反应，而非对项目的干扰。 跨职能团队：敏捷团队通常是小型的、跨职能的，包含开发人员、测试人员、设计师和其他相关角色。这种结构有助于团队快速做出决策并高效协作。 客户参与：客户（或其代表）是敏捷团队的重要成员，持续提供反馈，确保开发出的产品符合期望。 用户故事和任务管理：需求通常被分解为用户故事（User Stories），每个故事描述了用户的某种需求或功能。团队根据用户故事制定任务并进行开发。 看板和任务板：敏捷团队常使用看板（Kanban）或任务板（Task Board）来跟踪工作进度，确保所有任务按时完成。 常见的敏捷开发框架 Scrum：一种广泛使用的敏捷框架，强调固定长度的冲刺、每日站会、冲刺评审和回顾，以及产品负责人（Product Owner）和 Scrum Master 的角色。 看板（Kanban）：一种强调持续交付和流程优化的敏捷方法，通过可视化工作流程和限制在制品（WIP）来提高团队效率。 极限编程（XP, Extreme Programming）：一种强调工程实践的敏捷方法，重点包括测试驱动开发（TDD）、结对编程、持续集成等。 敏捷开发的优点 快速交付：通过短周期的迭代，敏捷开发能够更快地交付可用的软件产品。 更高的灵活性：敏捷开发能够快速响应需求变化，适应市场和客户的动态需求。 提高客户满意度：通过持续交付和客户参与，敏捷开发能够更好地满足客户需求。 持续改进：团队通过定期反思和回顾，不断优化开发流程和产品质量。 敏捷开发的挑战 文化转变：组织需要适应从传统瀑布式开发向敏捷开发的文化转变，这可能需要时间和努力。 需求管理：在敏捷开发中，需求管理可能变得复杂，特别是在面对频繁变化的情况下。 团队协作：敏捷开发依赖于团队的高效协作，任何沟通不畅或角色不明确都会影响项目进度。","categories":["1.语言","语言结构"]},{"title":"IIC总线","path":"/2024/08/27/2-通讯协议-其他-IIC总线/","content":"三轴陀螺仪的芯片 MPU-6050 芯片驱动是采用 IIC 总线协议和处理器进行通信。学习一下 IIC 总线的协议并总结在此： 处理器和芯片间的通信可以形象的比喻成两个人讲话： 你说的别人得能听懂：双方约定信号的协议。 你的语速别人得能接受：双方满足时序要求。 IIC 协议（传输数据的通道）：两条线可以挂多个设备。（只有主设备具有控制 SCL） 区分设备：IIC 设备里有个固化的地址。只有在两条线上传输的值等于 IIC 设备的地址时，才作出响应。 开始信号：处理器让 SCL 时钟保持高电平，然后让 SDA 数据信号由高变低就表示一个开始信号。同时 IIC 总线上的设备检测到这个开始信号它就知道处理器要发送数据了。 停止信号：处理器让 SCL 时钟保持高电平，然后让 SDA 数据信号由低变高就表示一个停止信号。同时 IIC 总线上的设备检测到这个停止信号它就知道处理器已经结束了数据传输。 再看数据怎么传：SDA 上传输的数据必须在 SCL 为高电平期间保持稳定：因为外接 IIC 设备在 SCL 为高电平的期间采集数据方知 SDA 是高或低电平。SDA 上的数据只能在 SCL 为低电平期间翻转变化。 响应信号（ACK）：处理器把数据发给外接 IIC 设备，如何知道 IIC 设备数据已经收到呢？就需要外接 IIC 设备回应一个信号给处理器。处理器发完 8bit 数据后就不再驱动总线了（SDA 引脚变输入），而 SDA 和 SCL 硬件设计时都有上拉电阻，所以这时候 SDA 变成高电平。那么在第 8 个数据位，如果外接 IIC 设备能收到信号的话接着在第 9 个周期把 SDA 拉低，那么处理器检测到 SDA 拉低就能知道外接 IIC 设备数据已经收到。 IIC 数据从最高位开始传输。 多个设备挂载情况下如何访问其中一个设备而不影响其他设备 用 7bit 表示从地址，那么可以挂载的从设备数是 2 的 7 次方 128 个。处理器想写的话：先发送起始位，再发一个 8bit 数据：前 7bit 表示从地址，第 8bit 表示读或者写。0write 是处理器往 IIC 从设备发，1read 是 IIC 从设备往处理器发。第 9 个时钟周期回复响应信号。下面就以 AT24Cxx 为例详细说明一下： 首先发出一个 start 信号，从设备地址，RW（0，写），回应 ACK 表示有这个从设备存在。这时候是处理器从指定的从设备读数据的从设备里 8bit 存储地址的指定。所以这里 RW 是 0 为写。ACK 回应有这个设备的话，处理器把要访问的从设备里的 8bit 存储地址写好。ACK 对方回应。继续一个 start 信号+从设备地址，最低位是高电平表示读数据，回应 ACK 表示有这个从设备存在。在读数据的时候，每发出一个时钟，处理器会将 SDA 上的数据存起来。那么发出 8 个时钟后处理器就能得到 8 位的数据。这时候若想连续读就不断回应 ACK 信号否则就发出停止信号。 读的过程： start 信号，从设备地址，《写（ack），待读取存储地址（ack）》 start 信号，从设备地址，《读（ack），8 个时钟（no ack）》 从设备就把对应的数据反馈给处理器。 start 信号，从设备地址，写，紧跟连续两个字节的数据：要写的地址，对方收到 8bit 地址后回应 ACK，再 8bit 数据发给从设备，对方收到 8bit 数据后回应 ACK，处理器写完后发送停止信号。","categories":["2.通讯协议","其他"]},{"title":"UART","path":"/2024/08/27/2-通讯协议-串口-UART/","content":"UART 协议概述UART（通用异步收发器）是一种广泛应用于设备间通信的异步串行通信协议。它通过串行方式逐位传输数据，通常用于连接计算机与各种外部设备，如调制解调器、传感器和微控制器等。UART 具有全双工通信能力，意味着数据可以同时在两个方向上传输。 同步串口与异步串口同步串口同步串口通过专门的时钟信号线来实现数据传输的同步。发送方和接收方依赖于时钟信号将数据流转换为电平信号。这种方式适合需要高数据传输速率和精确时序的应用场景。 异步串口异步串口则不使用共享时钟信号。定位信息包含在电平序列中，通信双方需事先约定数据帧的格式，包括波特率、数据位、停止位和奇偶校验等。线路空闲时，电平为高，一旦检测到下降沿，则视为起始位。接收方根据约定格式接收数据帧，并继续检测下一个起始位。异步串口的同步是以帧为单位的，适用于大多数低速通信场景。 UART 的工作特点数据采样UART 协议是一种低速数据通信标准，典型波特率为 115200 或 9600。UART 字符格式通常包含 1 个起始位、5~8 个数据位、1 个可选的奇偶位和 1 个停止位。由于接收器和发送器异步工作，接收器通常采用对输入数据流的高度采样方式，通常为 16 次采样，以确保数据的准确性。 UART 帧区分在 UART 中，MAX-IDL 参数用于设置空闲字符的数量。UART 控制器会开始计数接收到的空闲字符。如果在接收下一数据字符之前，接收到的空闲字符数量超过 MAX-IDL，则会产生空闲时间，缓冲区被关闭，并向 CPU 发出中断请求。这种机制有助于区分不同的数据帧。 空闲字符的位数计算公式为：1（起始位）+ 数据长度（5、6、7、8）+ 1（若使用奇偶校验）+ 停止位（1）。例如，1 个起始位，8 位数据，无校验，1 个停止位，则空闲字符 MAX-IDL 为 10 位。 UART 地址识别在多站系统中，可能存在多个设备，每个设备都有特定的地址。UART 帧可以扩展一位，以区别地址字符和正常数据字符。UART 支持两种操作模式： 自动多站模式：当地址与预置值匹配时，UART 控制器自动接收随后的数据。 非自动多站模式：UART 控制器接收所有数据，地址字符被写入新的缓冲区。 综上所述，UART 协议通过数据采样来确定位值，具有简单准确的定帧模式，并广泛用于多站系统中，支持自动多站和非自动多站两种模式，以区分地址和数据。 几种重要寄存器在 UART 的工作中，对寄存器的理解和正确配置至关重要。以下是 MPC860 的一些重要寄存器： 管脚配置寄存器：用于设置收发管脚的功能。 波特率配置寄存器：负责配置波特率。 通信处理命令寄存器：用于发出和阻止命令的判断。 SCC 通用模式寄存器：用于选择协议和配置传输格式。 发送和接收缓冲区描述器：用于数据的收发和错误判断。 UART 的特定参数：用于初始化 UART。 SCC 协议专用模式寄存器：用于设置 UART 的多站模式。 事件寄存器：用于判断中断类型。 屏蔽寄存器：用于收发使能。 UART 与 RS-232 和 COM 口UART 是异步串行通信的总称，包括 RS-232、RS-499、RS-423、RS-422 和 RS-485 等接口标准。UART 主要定义了通信口的电气特性、传输速率、连接特性和机械特性。COM 口是 PC 上的异步串行通信口的简称，通常基于 RS-232 标准。 嵌入式开发中的 UART 应用UART 协议广泛应用于嵌入式系统中，支持 RS-232、RS-422、RS-485 串口通信和红外（IrDA）等。UART 的工作原理是逐位传输数据，包含以下几个关键部分： 起始位：发送逻辑“0”信号，表示数据传输开始。 数据位：构成一个字符的数据位，通常为 5 至 8 位。 奇偶校验位：用于校验数据传输的正确性。 停止位：表示字符数据的结束，可以是 1 位、1.5 位或 2 位的高电平。 空闲位：表示线路上没有数据传送，处于逻辑“1”状态。 波特率：衡量数据传送速率的指标，通常以每秒传送的位数表示。 在实际应用中，UART 通过 SCI（串行通信接口）模块进行控制，广泛应用于工控、手机、PC 等设备中。通过合理配置 UART，可以实现高效的数据传输和设备间的通信。 实例UART（Universal Asynchronous Receiver and Transmitter）共有 256 bytesin Ch0 64 bytesin Ch1 and Ch4 16 bytesin Ch2 and Ch3 其中 ch0 和 ch4 有其他特殊作用 Thissection includes UART operationssuch as: Data transmission Data reception Interrupt generation Baud-rate generation Loop-back mode Infrared modes AFC The data frame for transmission is programmable. Itconsists of these bitsthat are specified bythe line control register(ULCONn): A Start bit Five to eight data bits An optional parity bit（校验位） One to two stop bits UART 的实现与代码示例在实现 UART 时，通常需要配置波特率、数据格式和工作模式。以下是一个简单的 UART 初始化和数据发送接收的示例代码： //设置通道工作模式（中断模式/查询模式）//设置数据传输格式//发送数据/接收数据（TXDn-----发送/RXDn-----接受）void serial_init() GPA1.GPA1CON = (GPA1.GPA1CON ~0xFF) | (0x22); // GPA1_0: RX; GPA1_1: TX UART2.ULCON2 = 0x3; // Normal mode, No parity, One stop bit, 8 data bits UART2.UCON2 = 0x5; // Interrupt request or polling mode /* Baud-rate 115200: src_clock: 100MHz * DIV_VAL = (100*10^6 / (115200*16) - 1) = (54.3 - 1) = 53.3 * UBRDIV2 = (Integer part of 53.3) = 53 = 0x35 * UFRACVAL2 = 0.3*16 = 0x5 */ UART2.UBRDIV2 = 0x35; UART2.UFRACVAL2 = 0x5;unsigned char getchar() unsigned char c; while (!(UART2.UTRSTAT2 0X1)); // 等待接收数据 c = UART2.URXH2; // 读取接收到的数据 return c;void putc(const char data) while (!(UART2.UTRSTAT2 0X2)); // 等待发送缓冲区空 UART2.UTXH2 = data; // 发送数据 if (data == ) // 如果发送的是换行符，则发送回车符 putc(\\r);","categories":["2.通讯协议","串口"]},{"title":"裸机驱动的开发步骤","path":"/2024/08/27/0-平台-ARM-裸机驱动的开发步骤/","content":"最简例子 LED 灯控制 看电路图 找到我要控制的设备 找到设备在 CPU 侧的控制管脚(如 GPX27) 看芯片手册 先看相关的中文文档，熟悉设备再看手册) 搜索电路图里对应控制管脚的名称(如 GPX2) 看目录找到对应的控制模块(如:6General Purpose InputOutput(GPIO)Control) 看该模块的 overview 了解该模块的大概功能 看控制寄存器(REGISTER DESCRIPTION)重点，难点 如果寄存器比较多，看技术支持提供的 demo，找到需要修改的寄存器(通常情况下只有几个)。部分厂商会提供配置软件，通过界面去配置功能，我们只需使用配置好的寄存器值就可以 编程 定义要控制的寄存器的宏(与手册里的寄存器地址对应起来) 设备初始化(如设置 GPI0 为输出状态) 把功能分成最基本的小块:逐个实现,如点亮灯-在灭灯-加延时-闪烁-跑马灯","categories":["0.平台","ARM"]},{"title":"OK4418平台","path":"/2024/08/27/0-平台-嵌入式-OK4418平台/","content":"连接开发板调试串口通过调试串口连接开发板，调试串口为 DB9，上位机直接连接，波特率为 115200，登录名为 root 网口通过网口连接，配置电脑的 IP 为 192.168.1.122，开发板的 IP 为 192.168.1.123，通过 ssh 连接，登录名为 root 下载文件通过 FileZilla Client 软件下载文件到开发板上，新建连接站点，主机地址为 192.168.1.123，通过 FTP 协议，端口为 21，不加密只使用普通 FTP，用户名为 root，密码为 forlinx。 连接成功后，将文件拷贝到opt 目录下，如果目录下有相同名字的文件，最好将原文件删除后，在拷贝文件。 配置自启动#!/bin/shexport PATH=/bin:/sbin:/usr/bin:/usr/sbinexport T_ROOT=/usr/local/tslibexport LD_LIBRARY_PATH=/usr/local/tslib/lib:$LD_LIBRARY_PATHexport TSLIB_CONSOLEDEVICE=noneexport TSLIB_FBDEVICE=/dev/fb0export TSLIB_TSDEVICE=/dev/input/event1export TSLIB_PLUGINDIR=$T_ROOT/lib/tsexport TSLIB_CONFFILE=$T_ROOT/etc/ts.confexport POINTERCAL_FILE=/etc/pointercalexport TSLIB_CALIBFILE=/etc/pointercalexport QTDIR=/forlinx/qtexport QT_QPA_PLATFORM=eglfsexport LD_LIBRARY_PATH=$QTDIR/lib:$LD_LIBRARY_PATHexport QT_QPA_GENERIC_PLUGINS=tslibexport QT_QPA_PLATFORM_PLUGIN_PATH=$QTDIR/pluginsexport QT_QPA_EGLFS_FB=/dev/fb0export QT_QPA_EGLFS_TSLIB=1export QWS_SIZEexport KEYPAD_DEV=/dev/input/event0export QWS_KEYBOARD=LinuxInput:/dev/input/keyboardexport LD_LIBRARY_PATH=/forlinx/qt/lib/plugins/imageformats:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/usr/local/opengl_lib_inc/libs:$LD_LIBRARY_PATHexport QT_PLUGIN_PATH=/forlinx/qt/lib/pluginsexport LD_PRELOAD=/lib/preloadable_libiconv.so#export QT_QPA_EGLFS_DISABLE_INPUT=1export QT_QPA_FONTDIR=$QTDIR/lib/fontsif [ -e /dev/input/event3 ];then export QT_QPA_EVDEV_KEYBOARD_PARAMETERS=/dev/input/event3fiif [ -e /usr/local/bluez5/var/run/dbus/pid ]then rm /usr/local/bluez5/var/run/dbus/pidfiexport DBUS_SESSION_BUS_ADDRESS=unix:path=/usr/local/bluez5/var/run/dbus/system_bus_socketTOUCH=`cat /etc/t2m` /dev/null 21if [ $TOUCH == M ];thenexport QWS_MOUSE_PROTO=Tslib:/dev/input/event1 mouseman:/dev/input/miceelseexport QWS_MOUSE_PROTO=Tslib:/dev/input/event1fi/opt/PCR -qws 配置脚本文件，如上所示，将该脚本文件拷贝到opt 目录下，修改etcinit.dS99app 注释掉forlinxbinapp.sh $ACTTION ，最后一行增加optStartPCR.sh 中文文本支持配置脚本文件，如上所示，将该脚本文件拷贝到opt 目录下，修改etcinit.dS99app 注释掉forlinxbinapp.sh $ACTTION ，最后一行增加optStartPCR.sh","categories":["0.平台","嵌入式"]},{"title":"SSH服务","path":"/2024/08/27/0-平台-Windows-SSH服务/","content":"WindowsSSH 服务端配置在 Windows 中配置 SSH 服务端的步骤如下（根据 win 版本不一致可能位置不同）： 打开“设置”。 选择“系统”。。 选择“可选功能”。 点击“添加功能”，然后搜索并安装“OpenSSH 服务器”和“OpenSSH 客户端”。 手动安装如果无法添加，这里提供下手动安装的方式 下载 OpenSSH https://github.com/PowerShell/Win32-OpenSSH/releases 解压缩 OpenSSH-Win64.zip，以管理员权限打开 cmd，执行 powershell.exe -ExecutionPolicy Bypass -File install-sshd.ps1 启动 SSH 服务 sc config sshd start= auto #设置SSH服务自动启动net start sshd #开启SSH服务 验证在命令提示符（cmd）中输入以下命令以验证 SSH 客户端是否已正确安装： ssh localhost 启动 SSH 服务要启动 SSH 服务，请在命令提示符中运行以下命令： net start sshd 停止 SSH 服务要停止 SSH 服务，请在命令提示符中运行以下命令： net stop sshd SSH 客户端Windows 10 和更高版本自带 SSH 客户端，您可以在命令提示符中使用以下命令进行连接： ssh 用户名@用户ip LinuxSSH 服务端在 Linux 中安装和配置 SSH 服务端的步骤如下： 更新软件包列表： sudo apt update 安装 OpenSSH 服务器： sudo apt install openssh-server 启动 SSH 服务： sudo systemctl start ssh 设置 SSH 服务开机自启： sudo systemctl enable ssh SSH 客户端在 Linux 中使用 SSH 客户端连接到远程主机的命令如下： ssh 用户名@用户ip 例如，连接到本地机器： ssh username@127.0.0.1 拷贝使用 scp 命令从 Linux 拷贝文件到 Windows： scp /linux/folder/copyfilename Winusername@Winip:/c:/user/username/Desktop 免密码连接要实现免密码连接，您可以使用 sshpass 工具。首先安装 sshpass： sudo apt install sshpass 然后使用以下命令进行免密码拷贝： sshpass -p passwd scp /linux/folder/copyfilename Winusername@Winip:/c:/user/username/Desktop 通过以上步骤，您可以在 Windows 和 Linux 系统上成功配置和使用 SSH 服务。","categories":["0.平台","Windows"]},{"title":"Linux子系统的GUI","path":"/2024/08/27/0-平台-Windows-Linux子系统的GUI/","content":"项目地址WSLg GitHub 页面 WSLg 介绍WSLg 是 Windows Subsystem for Linux GUI 的缩写。该项目的主要目的是支持在 Windows 系统中无缝运行 Linux GUI 应用程序，包括但不限于 X11 和 Wayland 应用程序。这项技术显著提升了开发者、科学家以及开源爱好者的工作效率，尤其是在需要同时使用两种操作系统工具的场景中。 目标用户WSLg 尤其适合那些需要在同一台计算机上运行 Windows 和 Linux 应用程序的用户。比如，一位数据科学家可能需要使用 Python 或 R 在 Linux 上进行数据分析，而同时又希望使用 Windows 上的图形化工具进行可视化。通过使用 WSLg，用户可以避免繁琐的双系统或虚拟化设置，节省大量时间和系统资源。 传统解决方案的局限性在使用双系统设置时，用户需要重启计算机来切换操作系统，而在虚拟机中则可能面临性能下降和资源消耗的问题。此外，使用 XServer 将 Linux 应用投射到 Windows 上也常常需要复杂的配置和额外的维护，使得用户难以获得流畅的使用体验。 WSLg 的优势WSLg 的设计旨在让 Linux GUI 应用程序在 Windows 上的使用体验像本地应用程序一样自然。具体来说，WSLg 提供了以下功能： “开始”菜单集成：用户可以轻松找到并启动 Linux 应用程序，像访问任何 Windows 应用程序一样方便。 任务栏融合：Linux 应用程序的图标可以在 Windows 的任务栏上显示，用户可以直观地识别和访问它们。 跨平台的快捷键切换：用户可以通过 alt-tab 快速切换 Windows 和 Linux 应用程序，保持高效的工作流。 无缝的剪切粘贴功能：例如，用户可以在 Windows 上复制文本，然后直接粘贴到运行在 WSLg 中的 Linux 应用程序里，反之亦然。 这些功能共同为用户提供了 Windows 和 Linux 应用程序之间的无缝桌面体验，消除了在多系统环境中常见的繁琐和不便。无论是开发应用程序还是进行日常任务，WSLg 都能使用户的工作更加顺畅高效。","categories":["0.平台","Windows"]},{"title":"keyring库","path":"/2024/08/24/0-平台-Linux-加密-keyring库/","content":"使用 keyring 库安全地存储和检索敏感信息（如密码）。 keyring 提供了一个安全的方式来管理这些信息，而不是将明文存储在代码或配置文件中。但是 keyring 库不是 Linux 内核的密钥保留服务，而是一个独立的 C++ 库，提供了跨平台的密码管理功能。它通常会使用操作系统提供的安全存储机制（如 Linux 的 Secret Service API 或 Windows 的 Credential Manager）来实现其功能。 #include keyring/keyring.h#include iostream#include stringint main() std::string service_name = foo; std::string account = bar; std::string password_input = password; std::string password_output = ; keyring::set_password(service_name, account, password_input); keyring::get_password(service_name, account, password_output); std::cout password_output std::endl; return 0;","categories":["0.平台","Linux","加密"]},{"title":"内核密钥保留服务","path":"/2024/08/24/0-平台-Linux-加密-内核密钥保留服务/","content":"Linux 内核提供了密钥保留服务(Key Retention Service),可以用于应用程序加密。Linux 密钥保留服务（Linux key retention service 是在 Linux 2.6 中引入的，它的主要意图是在 Linux 内核中缓存身份验证数据。远程文件系统和其他内核服务可以使用这个服务来管理密码学、身份验证标记、跨域用户映射和其他安全问题。它还使 Linux 内核能够快速访问所需的密钥，并可以用来将密钥操作（比如添加、更新和删除）委托给用户空间。 启用密钥保留服务 在内核配置中启用密钥服务选项: ## Security options#CONFIG_KEYS=yCONFIG_KEYS_DEBUG_PROC_KEYS=yCONFIG_SECURITY=yCONFIG_SECURITY_NETWORK=yCONFIG_SECURITY_CAPABILITIES=y 安装 keyutils 包,提供密钥管理工具: sudo apt install keyutils 内核层 API register_key_type 定义新的密钥类型。如果存在名称相同的密钥类型，返回 EEXIT。 int register_key_type(struct key_type *type) unregister_key_type 用来取消密钥类型的注册 void unregister_key_type(struct key_type *type); key_alloc 分配指定类型的密钥 struct key *key_alloc(struct key_type *type, const char *desc, uid_t uid, gid_t gid, struct task_struct *ctx, key_perm_t perm, unsigned long flags); key_instantiate_and_link 对密钥进行实例化并将它链接到目标 keyring int key_instantiate_and_link(struct key *key, const void *data,size_t datalen, struct key *keyring,struct key *instkey); request_key 搜索与给定的描述匹配的密钥 struct key *request_key(const struct key_type *type,const char *description,const char *callout_string); lookup_user_key 用于在内核中查找指定 ID 的密钥 key_ref_t lookup_user_key(key_serial_t id, unsigned long flags, key_perm_t perm) key_put 发布一个密钥 void key_put(struct key *key); 应用层 APILinux 内核提供了密钥保留服务(Key Retention Service)服务提供三个新的系统调用，用来在用户空间中操作密钥。 add_key()用于用户空间程序向指定的密钥环中添加新密钥或更新现有密钥。 long add_key(const char *type, const char *description, const void *payload, size_t plen, key_serial_t keyring); add_key 系统调用用来创建类型为 type、长度为 plen 的密钥。密钥描述由 desc 定义，它的有效内容由 payload 指定。密钥链接到 keyring ring。密钥类型可以是 user 或 keyring。其他任何密钥类型必须已经通过内核服务向内核注册，然后才能使用。如果密钥是 keyring 类型的，有效内容就应该是 NULL，plen 应该是零。 request_key()用于请求访问一个密钥。 key_serial_t request_key(const char *type, const char *description, const char *callout_info, key_serial_t dest_keyring); 它允许程序请求访问一个已存在的密钥，如果密钥不存在，还可以触发创建密钥的过程。 keyctl()多功能系统调用,用于执行各种密钥管理操作。其基本用法如下: long keyctl(int operation, ...); keyctl()支持多种操作,包括但不限于: KEYCTL_DESCRIBE 描述一个密钥。 KEYCTL_READ 从一个密钥读取有效内容数据。 KEYCTL_UPDATE 更新指定的密钥。 KEYCTL_LINK 将一个密钥链接到一个 keyring。 KEYCTL_UNLINK 将密钥或 keyring 与另一个 keyring 的链接取消。 KEYCTL_JOIN_SESSION_KEYRING 将一个会话 keyring 替换为新的会话 keyring。 KEYCTL_REVOKE 取消一个密钥。 KEYCTL_CHOWN 修改密钥的所有者。 KEYCTL_SETPERM 修改密钥的权限掩码。 KEYCTL_CLEAR 清除一个 keyring。 KEYCTL_SEARCH 在一个 keyring 树中搜索密钥。 KEYCTL_INSTANTIATE 对部分构造好的密钥进行实例化。 KEYCTL_NEGATE 取消对部分构造好的密钥的实例化。 查看内核中是否支持以下函数： // 读取密钥内容long keyctl_read(key_serial_t key, char *buffer, size_t buflen)// 更新密钥内容 long keyctl_update(key_serial_t key, const void *payload, size_t plen)// 撤销密钥long keyctl_revoke(key_serial_t key) 使用密钥保留服务创建密钥通过密钥保留服务密钥会被存储在内核中,而不是应用程序的内存空间,提高了安全性 内核层模块在它的 init 函数中调用 register_key_type() 来注册这个新密钥类型（名为 mykey）。 #include linux/key-type.hstatic struct key_type my_key_type = .name = mykey,\t.instantiate = my_instantiate_key,\t.describe = my_key_describe,\t.match = my_key_match,\t.destroy = my_key_destroy,;static int __init my_module_init(void) int ret = register_key_type(my_key_type);\tif (ret) pr_err(Failed to register key type ); return ret; pr_info(My key type registered );\treturn 0;static void __exit my_module_exit(void) unregister_key_type(my_key_type);\tpr_info(My key type unregistered );module_init(my_module_init);module_exit(my_module_exit); 当内核模块收到 ioctl 请求时，它首先调用 key_alloc() 来分配一个新的密钥，从而创建一个会话 keyring。 struct key *key;key = key_alloc(my_key_type, my_key, current_uid(), current_gid(), current_cred(), KEY_POS_ALL, 0);if (!IS_ERR(key)) const char *data = secret_data;\tkey_instantiate_and_link(key, data, strlen(data), NULL, NULL); 在成功调用 key_alloc() 之后，调用 key_instantiate_and_link() 对密钥进行实例化。 int ret = key_instantiate_and_link(key, NULL, 0, NULL, NULL);if (ret 0) key_put(key); return ret; 在创建并实例化会话 keyring 之后，为用户的会话创建密钥。 同样，依次调用 key_alloc() 和 key_instantiate_and_link()。 成功完成这些调用之后，用户空间会话就有了一个新密钥。 应用层keyctl add user mykey mysecretvalue @u 使用密钥在应用程序中使用密钥: #include keyutils.h#include stdio.hint main() key_serial_t key; char buffer[256]; long buflen; key = request_key(user, mykey, NULL, KEY_SPEC_SESSION_KEYRING); if (key == -1) perror(request_key); return 1; buflen = keyctl_read(key, buffer, sizeof(buffer)); if (buflen == -1) perror(keyctl_read); return 1; printf(Key data: %.*s , (int)buflen, buffer); return 0; 注意事项 需要内核支持(2.6 及以上版本) libkeyutils.so 是 C 库，在 C++工程中会出现 undefined reference add_key 等错误，头文件 keyutils.h 需要 extern 包含，且需要注意链接时需要添加 LIB += -lkeyutils 一定要初始化 keyutils 库,具体方法如下: int rc = 0;rc = keyctl(KEYCTL_LINK,KEY_SPEC_USER_KEYRING,KEY_SPEC_SESSION_KERING); 只有此处调用成功后,才能调用 add_key(“user”,…);否则,即使 add_key 成功,最后调用 request_key 也会失败，找不到才加入到 keyring 中的 KEY.在内核中调用 request_key 也会失败,返回 NOKEY. 状态查看[root@phoenix set.5]# keyctl showSession Keyring-3 --alswrv 0 0 keyring: session.262139044642 --alswrv 0 0 \\_ mykey: New key type[root@phoenix set.5]# cat /proc/keys00000001 I----- 1 perm 1f3f0000 0 0 keyring _uid_ses.0: 1/400000002 I----- 5 perm 1f3f0000 0 0 keyring _uid.0: empty0253c622 I--Q-- 1 perm 3f3f0000 0 0 mykey New key type: 011a490da I--Q-- 2 perm 3f3f0000 0 0 keyring session.2621: 1/413670439 I--Q-- 2 perm 1f3f0000 0 0 keyring _ses.1977: 1/4159d39b8 I--Q-- 5 perm 1f3f0000 0 0 keyring _ses.1976: 1/43a14f259 I--Q-- 3 perm 1f3f0000 0 0 keyring _ses.1978: 1/4[root@phoenix set.5]# cat /proc/key-users0: 8 7/7 5/100 136/1000043: 2 2/2 2/100 56/1000048: 2 2/2 2/100 56/1000081: 2 2/2 2/100 56/10000786: 4 4/4 4/100 113/10000keyctl describe ``Key`` command gives the description of key.[root@phoenix set.5]# keyctl describe -3-3: alswrvalswrv------------ 0 0 keyring: session.2621[root@phoenix set.5]# keyctl describe 3904464239044642: alswrvalswrv------------ 0 0 mykey: New key type[avinesh@phoenix set.5]$ keyctl search -3 mykey New key type39044642[root@phoenix set.5]# exitexitNow back to our previous state[root@phoenix set.5]# keyctl showSession Keyring-3 --alswrv 0 0 keyring: _ses.19762 --alswrv 0 0 \\_ keyring: _uid.0[root@phoenix set.5]# rmmod ./kernel.land/newkey.koUnloading the module.Unregistered learning_key 内核中的密钥管理内核密钥管理在 proc 文件系统中创建了两个只读文件：prockeys 和prockey-users。它们没有被创建在procpid 目录下，而是被直接创建在了 proc 文件系统的根目录下。这就造成了进程根本无法查看到别的进程的密钥。 prockeys 文件列出当前进程可查看的密钥，所以不同的进程读出的内容会不同。如果一个进程希望了解它可以查看哪些密钥，它可以通过读取 prockeys 获得这些信息。列出的内容包括序列号、过期时间、访问允许位、uid、gid、类型、描述等。在配置内核时，必须启用这个文件，因为它允许任何用户列出密钥数据库。 prockey-users 列出密钥的统计信息，包括 uid、使用计数、密钥总数量和实例化数量、密钥数量的配额信息、密钥占用内存的配额信息。","categories":["0.平台","Linux","加密"]},{"title":"Yocto","path":"/2024/08/24/0-平台-嵌入式-Yocto笔记/","content":"什么是 YoctoYocto Project 是一个开源协作项目，主要用于为嵌入式系统开发自定义的 Linux 操作系统。它提供了一整套工具和模板，使得开发者可以在多种硬件架构上构建功能齐全、轻量级且定制化的嵌入式 Linux 发行版。 Yocto 不仅仅是一个 Linux 发行版，它更像是一个构建系统，帮助你从源代码生成一个完整的 Linux 系统，包括内核、根文件系统、工具链和应用程序。Yocto 项目通过 BitBake 构建系统和 OpenEmbedded 核心来实现这一切。 Yocto 的基本概念 BitBake: Yocto 构建系统的核心工具，类似于 GNU Make，但功能更强大。它使用 .bb、.bbclass 和 .conf 文件定义构建任务、元数据和配置。 Layer (层): Yocto 项目中的层是一组元数据文件，用于组织和管理构建配置。常见的层包括 meta 层（核心）、meta-oe（OpenEmbedded 扩展层）和 meta-raspberrypi（树莓派支持层）。 Recipe (配方): 配方是 Yocto 中的基本构建单元，它定义了如何获取源代码、应用补丁、编译和安装软件包。配方文件通常以 .bb 结尾。 Machine (机器): Yocto 为不同硬件架构和开发板定义了 machine 配置，这些配置决定了目标硬件的具体构建选项。 Distro (发行版): Yocto 的发行版配置定义了一个操作系统的核心部分，包括使用的包管理器、C 库以及其他系统级配置。 Image (镜像): 镜像是通过 Yocto 构建出的最终产品，它是一个可以直接在目标硬件上运行的文件系统和内核。 Yocto 如何使用1. 安装 Yocto 环境要使用 Yocto，你首先需要安装构建环境，包括一些基本的开发工具和 Git。 sudo apt-get install gawk wget git-core diffstat unzip texinfo gcc-multilib build-essential chrpath socat libsdl1.2-dev xterm 2. 获取 Yocto 源代码你需要从 GitHub 或 Yocto 官方仓库中克隆 Yocto 项目的源代码。以下是克隆一个常用的 Yocto 版本分支的示例： git clone -b kirkstone git://git.yoctoproject.org/poky.gitcd poky 3. 初始化构建环境在 Yocto 中，oe-init-build-env 脚本用于初始化构建环境，创建一个新的构建目录。 source oe-init-build-env 这个命令会在当前目录下创建一个新的 build 目录，并将你切换到该目录中。所有的构建输出都将在这个 build 目录中生成。 4. 配置构建选项在 build 目录下，你可以通过编辑 conf/local.conf 文件来配置构建选项，例如目标机器（MACHINE）、并行构建线程（BB_NUMBER_THREADS）和 DL_DIR（源码下载目录）等。 示例配置： MACHINE ?= qemuarm 如果你要为 Raspberry Pi 构建系统，可以修改为： MACHINE ?= raspberrypi4 5. 添加层你可以通过 bitbake-layers 工具来管理 Yocto 的层。例如，添加一个新的层： bitbake-layers add-layer ../meta-openembedded/meta-oe 这个命令将 meta-oe 层添加到构建环境中。 6. 构建镜像配置完成后，可以使用 bitbake 命令开始构建系统镜像。常见的构建目标包括 core-image-minimal、core-image-sato 等。 bitbake core-image-minimal 构建过程可能需要一些时间，这取决于你的计算资源和网络速度。 7. 部署镜像构建完成后，生成的镜像文件会存放在 build/tmp/deploy/images/ 目录下。你可以将这些文件烧录到目标硬件中，例如 SD 卡，或直接在 QEMU 中进行模拟测试。 Yocto 的常用工具 BitBake: 用于执行构建任务的核心工具。你将主要使用它来编译配方并生成镜像。 devtool: 一个用于开发者的工具集，简化了 Yocto 项目的扩展和修改。例如，它可以自动生成新的配方或修改现有配方。 bitbake-layers: 用于管理和操作 Yocto 层的工具。它可以添加、删除或列出层。 hoban: 用于查看和分析 Yocto 项目生成的二进制文件和镜像内容的工具。 Toaster: Yocto 提供的一个基于 Web 的图形界面工具，帮助用户管理构建项目并分析结果。 menuconfignconfig: 用于配置 Linux 内核的工具，它们允许你在图形界面中选择内核选项。 通过一个实例来详细说明如何在 Yocto 中添加 Mesa 的 OpenGL 驱动是一个很好的实践。这个过程将涵盖如何配置 Yocto 环境、修改配置文件、添加所需的软件包（如 Mesa 驱动），并构建包含 OpenGL 支持的 Linux 镜像。我们以一个基于 Raspberry Pi 4 的项目为例。 实例目标目标是使用 Yocto 构建一个为 Raspberry Pi 4 定制的 Linux 镜像，并在内核中增加 Mesa 的 OpenGL 驱动。 1. 设置 Yocto 环境1.1 克隆 Yocto Poky 仓库首先，从 Yocto 的官方 Git 仓库克隆 Poky，这包含 Yocto 的核心构建工具和基础层。 git clone -b kirkstone git://git.yoctoproject.org/poky.gitcd poky 1.2 获取 Raspberry Pi 层接下来，克隆 Raspberry Pi 支持的元数据层 meta-raspberrypi。 git clone -b kirkstone git://git.yoctoproject.org/meta-raspberrypi.git 1.3 初始化构建环境使用 Yocto 提供的脚本初始化构建环境，这将创建一个 build 目录。 source oe-init-build-env 1.4 添加层到构建环境在 build 目录中，通过 bitbake-layers 命令添加 meta-raspberrypi 和 meta-openembedded（包含 Mesa 的相关软件包）。 bitbake-layers add-layer ../meta-raspberrypibitbake-layers add-layer ../meta-openembedded/meta-oebitbake-layers add-layer ../meta-openembedded/meta-multimedia 或者创建一个新的层，创建新层后需要在新层中创建 Mesa 配方文件(mesa_%.bbappend) bitbake-layers create-layer meta-opengl PACKAGECONFIG_append = gallium-llvm gallium egl gles gbm driGALLIUMDRIVERS_append = ,swrastDRIDRIVERS_append = ,swrast 2. 配置构建选项2.1 配置 local.conf编辑 conf/local.conf 文件，设置目标机器为 Raspberry Pi 4，并启用 OpenGL 支持。 MACHINE ?= raspberrypi4 确保启用 GL 和 X11 支持，以便 Mesa 的 OpenGL 驱动能够正确构建： DISTRO_FEATURES_append = opengl x11 如果是新层则需要添加 BBLAYERS += $TOPDIR/../meta-opengl 2.2 添加 Mesa 软件包在 local.conf 中，添加以下行以确保 Mesa 和相关驱动程序被包含在构建中： IMAGE_INSTALL_append = mesa mesa-gl mesa-demos mesa: 主 Mesa 包，提供 OpenGL 实现。 mesa-gl: 提供 OpenGL 库。 mesa-demos: 包含一些 OpenGL 的演示程序，方便测试。 3. 构建镜像使用 bitbake 命令构建包含 Mesa OpenGL 驱动的系统镜像。 bitbake core-image-sato 这个过程可能需要一些时间，因为 Yocto 会从源代码编译所有需要的组件，包括 Mesa 驱动程序。 4. 部署和测试4.1 部署镜像构建完成后，生成的镜像文件会存放在 build/tmp/deploy/images/raspberrypi4/ 目录下。你可以使用 dd 命令将镜像烧录到 SD 卡上。 sudo dd if=core-image-sato-raspberrypi4.rpi-sdimg of=/dev/sdX bs=4Msync 将 SD 卡插入 Raspberry Pi 4，然后启动设备。 4.2 测试 OpenGL启动 Raspberry Pi 后，通过 SSH 或直接在设备上打开终端，运行 Mesa 的 glxinfo 工具以验证 OpenGL 驱动是否正确安装。 glxinfo | grep OpenGL 你应该能够看到与 Mesa 和 OpenGL 相关的输出信息，表明 OpenGL 驱动已正确加载。 此外，你可以运行 glxgears（Mesa 的演示程序之一）来测试 OpenGL 的基本功能。 glxgears yocto SDK 目录结构 ├── build // 用户配置文件和工程构建输出目录├── conf├── meta-browser // Web浏览器配方├── meta-clang // 用来构架编译器的LLVM框架系统├── meta-openembedded // 用来交叉编译，安装和打包的元数据├── meta-poky - poky/meta-poky // Poky发行版本的配置数据├── meta-python2 // Python2配方├── meta-qt5 // Qt5官方推出的Qt5配方├── meta-rockchip // Rockchip层，包含Rockchip芯片BSP相关配方├── meta-rust // Rust与Cargo的OpenEmbedded/Yocto层└── poky // 用来构建Linux的构建系统 Yocto 的工程就是这么简单，仅仅只由这几个文件夹构成。yocto 由许许多多的配方构成，它通过配方获取软件源码编译下载构建并解决依赖，正因为如此，也造就了 yocto 不如 buildroot 容易入门的现状，工程虽小，但是编译的过程中需要消耗比较大的空间。 buid 目录下存放着，当前 SDK 存在的所有构建方案，可以看到在 rockchip 平台，该 SDK 当前支持的构建平台，其中，所有的方案均以 local.conf 文件所设置的信息为准。如果存在多个方案，可以在当前文件夹下多个方案文件夹，每个文件夹下均还有自己的方案对应的 conflocal.conf 信息文件。 在当前 SDK 平台中，没有这样做，所以选择方案需要使用 ln -sf **** local.conf 文件来进行方案的选择。 选择好方案之后，目前我选择的方案是这样的： lrwxrwxrwx 1 jie jie 23 Aug 24 20:46 local.conf - rk356xroc-rk3568-pc.mk 选择好之后，开始构建 source oe-init-build-envbitbake core-image-minimal 使用构建参数构建出来的 yocto 系统仅仅只是一个能让设备启动的小镜像，没有启动界面。他的配置文件放在： meta-openembedded/meta-xfce/recipes-core/images/core-image-minimal-xfce.bb 可以查看：meta-rockchip/README.md 可以看到 rockchip 对自己命令的支持。 简单列举一下支持的其他命令： core-image-minimal : 一个能够让设备启动的小镜像，它无界面 core-image-sato : 一个支持 Sato 的镜像，它支持带有 Sato 主题和 Pimlico 应用程序的 X11，还包含终端、编辑器和文件管理器，它是一个基于 GNOME Mobile 的用户界面环境，使用 matchbox 作为窗口管理器 meta-toolchain：一个可编译出 gcc 交叉工具链安装程序的选项，生成的文件位于目录pathtoyoctobuildtmpdeploysdk，主要输出文件为.sh 安装文件 meta-ide-support：一个用于确保目录pathtoyoctobuild 包含有 IDE 工具链包的选项，生成的文件为 environment-setup-xxxxxx-neon-poky-linux-gnueabi，位于目录pathtoyoctobuildtmp，直接用 soucre 命令运行即可 更详细的可以查看 yocto 的配置文档： https://www.yoctoproject.org/docs/1.1/poky-ref-manual/poky-ref-manual.html#ref-images yocto 中编译出来的文件： 在 build 中： ├── abi_version├── buildstats├── cache├── deploy //生成的镜像文件├── hosttools //构建工具，当然还没有生成├── log //过程的log├── pkgdata ├── qa.log├── saved_tmpdir├── sstate-control├── stamps├── sysroots //生成的产品根文件系统├── sysroots-components├── sysroots-uninative├── uboot_img_prefix.tmp├── work //编译过程中生成的文件 第三方软件包就放在这里└── work-shared //编译过程中的源文件依赖 kernel 就放在这里 在 build 文件夹中可以使用如下命令快捷编译相关的工具： 编译 ubot bitbake virtual/bootloader 编译 kernel bitbake virtual/kernel 编译工具或者软件包 bitbake xxxxxx // xxxxx为配方 bb 文件之前的部分 具体可以使用 bitbake s 查看当前系统中都支持构建哪些包 如果没有自己想要的软件包，可以在 yacto 官网上下载自己需要的配方，添加进 yacto 中，再次查看是否添加进来。","categories":["0.平台","嵌入式"]},{"title":"内核补丁","path":"/2024/08/24/0-平台-Linux-内核-内核补丁/","content":"内核补丁（.patch 文件）是用于对 Linux 内核源代码进行修改的文件。补丁通常用于修复漏洞、引入新功能、优化性能或修正错误。 什么是内核补丁内核补丁是一个包含源代码更改的文本文件，通常由 diff 或 git diff 生成。它描述了如何从当前版本的源代码生成一个新版本，包括添加、删除或修改的代码行。 补丁文件通常包含以下部分： 文件头：指示补丁适用于哪个文件。 上下文信息：显示修改的代码周围的几行代码，以帮助理解更改的位置。 更改信息：实际的代码差异，标记为添加（+）、删除（-）或修改。 内核补丁的作用 修复漏洞和错误 内核是操作系统的核心部分，任何漏洞或错误可能都会导致系统不稳定或受到攻击。通过应用补丁，开发人员可以修复这些问题，而不需要等待完整的新内核版本发布。 添加新功能 Linux 内核是一个快速发展的项目，新的硬件支持、新的文件系统、新的安全功能等，都是通过补丁引入的。开发人员通过提交补丁来贡献新功能，其他开发者可以在自己的内核中应用这些补丁进行测试和使用。 性能优化 补丁还可以用于性能优化，尤其是在高性能计算或嵌入式系统中。开发人员可以通过调整内核代码，优化资源使用和响应时间，从而提高系统整体性能。 自定义内核 有些用户和开发人员需要定制内核以满足特定需求，如在特定硬件上运行、启用特定功能或优化某些工作负载。通过应用特定的补丁，内核可以被调整和定制。 如何使用内核补丁以下我们使用一个 linux4.19 的内核在 ubuntu24 中编译时出现报错的示例来说明如何使用一个内核补丁。 编译内核源码，在编译内核源码时出现以下错误： 2024-08-24T13:51:26 In file included from /usr/include/signal.h:328,2024-08-24T13:51:26 from ./signal.h:52,2024-08-24T13:51:26 from c-stack.c:49:2024-08-24T13:51:26 c-stack.c:55:26: error: missing binary operator before token (2024-08-24T13:51:26 55 | #elif HAVE_LIBSIGSEGV SIGSTKSZ 163842024-08-24T13:51:26 | ^~~~~~~~......2024-08-24T13:51:26 make[4]: *** [Makefile:1674: all] Error 22024-08-24T13:51:26 make[3]: *** [Makefile:1572: all-recursive] Error 12024-08-24T13:51:26 make[2]: *** [Makefile:1528: all] Error 22024-08-24T13:51:26 make[1]: *** [package/pkg-generic.mk:231: /mnt/c/Users/Administrator/Desktop/12.GitHub/CodeWork/00.HoldDev/OK3568-linux-source/buildroot/output/OK3568/build/host-m4-1.4.18/.stamp_built] Error 22024-08-24T13:51:26 make: *** [/mnt/c/Users/Administrator/Desktop/12.GitHub/CodeWork/00.HoldDev/OK3568-linux-source/buildroot/output/OK3568/Makefile:16: _all] Error 2Command exited with non-zero status 1you take 7:43.42 to build builrootERROR: Running build_buildroot failed!ERROR: exit code 1 from line 565: /usr/bin/time -f you take %E to build builroot $COMMON_DIR/mk-buildroot.sh $BOARD_CONFIG 下载我们需要的补丁文件 cd OK3568-linux-sourcewget https://toolchains.bootlin.com/downloads/releases/sources/m4-1.4.18/0003-c-stack-stop-using-SIGSTKSZ.patch 具体补丁文件内容如下 c-stack: stop using SIGSTKSZIt’s been proposed to stop making SIGSTKSZ an integer constant:https://sourceware.org/pipermail/libc-alpha/2020-September/118028.htmlAlso, using SIGSTKSZ in #if did not conform to current POSIX.Also, avoiding SIGSTKSZ makes the code simpler and easier to grok.* lib/c-stack.c (SIGSTKSZ): Remove.(alternate_signal_stack): Now a 64 KiB array, for simplicity.All uses changed.[Retrieved (and backported) from:https://git.savannah.gnu.org/cgit/gnulib.git/patch/?id=f9e2b20a12a230efa30f1d479563ae07d276a94b]Signed-off-by: Fabrice Fontaine fontaine.fabrice@gmail.comdiff -Nura m4-1.4.18.orig/lib/c-stack.c m4-1.4.18/lib/c-stack.c--- m4-1.4.18.orig/lib/c-stack.c 2021-04-11 19:12:14.086494029 +0200+++ m4-1.4.18/lib/c-stack.c 2021-04-11 19:48:46.316862760 +0200@@ -50,15 +50,16 @@ #if ! HAVE_STACK_T ! defined stack_t typedef struct sigaltstack stack_t; #endif-#ifndef SIGSTKSZ-# define SIGSTKSZ 16384-#elif HAVE_LIBSIGSEGV SIGSTKSZ 16384-/* libsigsegv 2.6 through 2.8 have a bug where some architectures use- more than the Linux default of an 8k alternate stack when deciding- if a fault was caused by stack overflow. */-# undef SIGSTKSZ-# define SIGSTKSZ 16384-#endif++/* Storage for the alternate signal stack.+ 64 KiB is not too large for Gnulib-using apps, and is large enough+ for all known platforms. Smaller sizes may run into trouble.+ For example, libsigsegv 2.6 through 2.8 have a bug where some+ architectures use more than the Linux default of an 8 KiB alternate+ stack when deciding if a fault was caused by stack overflow. */+static max_align_t alternate_signal_stack[(64 * 1024+ + sizeof (max_align_t) - 1)+ / sizeof (max_align_t)]; #include stdlib.h #include string.h@@ -128,19 +129,6 @@ #if (HAVE_SIGALTSTACK HAVE_DECL_SIGALTSTACK \\ HAVE_STACK_OVERFLOW_HANDLING) || HAVE_LIBSIGSEGV-/* Storage for the alternate signal stack. */-static union-- char buffer[SIGSTKSZ];-- /* These other members are for proper alignment. Theres no- standard way to guarantee stack alignment, but this seems enough- in practice. */- long double ld;- long l;- void *p;- alternate_signal_stack;- static void null_action (int signo __attribute__ ((unused))) @@ -205,8 +193,8 @@ /* Always install the overflow handler. */ if (stackoverflow_install_handler (overflow_handler,- alternate_signal_stack.buffer,- sizeof alternate_signal_stack.buffer))+ alternate_signal_stack,+ sizeof alternate_signal_stack)) errno = ENOTSUP; return -1;@@ -279,14 +267,14 @@ stack_t st; struct sigaction act; st.ss_flags = 0;+ st.ss_sp = alternate_signal_stack;+ st.ss_size = sizeof alternate_signal_stack; # if SIGALTSTACK_SS_REVERSED /* Irix mistakenly treats ss_sp as the upper bound, rather than lower bound, of the alternate stack. */- st.ss_sp = alternate_signal_stack.buffer + SIGSTKSZ - sizeof (void *);- st.ss_size = sizeof alternate_signal_stack.buffer - sizeof (void *);-# else- st.ss_sp = alternate_signal_stack.buffer;- st.ss_size = sizeof alternate_signal_stack.buffer;+ st.ss_size -= sizeof (void *);+ char *ss_sp = st.ss_sp;+ st.ss_sp = ss_sp + st.ss_size; # endif r = sigaltstack (st, NULL); if (r != 0)diff -Nura m4-1.4.18.orig/lib/c-stack.h m4-1.4.18/lib/c-stack.h--- m4-1.4.18.orig/lib/c-stack.h 2021-04-11 19:12:14.098494042 +0200+++ m4-1.4.18/lib/c-stack.h 2021-04-11 19:17:42.138848378 +0200@@ -34,7 +34,7 @@ A null ACTION acts like an action that does nothing. ACTION must be async-signal-safe. ACTION together with its callees- must not require more than SIGSTKSZ bytes of stack space. Also,+ must not require more than 64 KiB bytes of stack space. Also, ACTION should not call longjmp, because this implementation does not guarantee that it is safe to return to the original stack. 在合适的位置使用内核补丁（.patch 文件）来修改 Linux 内核的源代码 patch -p1 /path/to/my_patch.patch -p1 是一个常用选项，它告诉 patch 命令忽略路径前的一个目录部分。如果补丁文件的路径与源代码目录结构不一致，你可能需要调整 -p 选项的值。 用来将补丁文件的内容传递给 patch 命令。 在这里，实际应用时，我们在编译源码目录下 wget 下载补丁文件，之后进入指定位置应用补丁： OK3568-linux-source$ cd ./buildroot/output/OK3568/build/host-m4-1.4.18/OK3568-linux-source/buildroot/output/OK3568/build/host-m4-1.4.18$ patch -p1 ../../../../../0003-c-stack-stop-using-SIGSTKSZ.patchpatching file lib/c-stack.cpatching file lib/c-stack.h 检查应用结果，你可以检查应用补丁后的文件，确保补丁已正确应用。 回滚补丁，如果补丁引入了问题或不需要了，可以回滚补丁： patch -p1 -R /path/to/patch.patch","categories":["0.平台","Linux","内核"]},{"title":"云电脑性能","path":"/2024/08/23/3-软件-0杂项-云电脑性能/","content":"参数 海马云 ToDesk 网易云游戏 腾讯 START 海星云 顺网云电脑 极云普惠云电脑 云 (电脑游戏) 名称 海马云 ToDesk 网易云游戏 腾讯 START 海星云 顺网云电脑 极云普惠云电脑 运行平台 PC安卓 PC安卓 PC安卓TV PC安卓TV PC安卓TV pc安卓 pc安卓ios 游戏库 500+ 自带游戏 排队严重 WeGame 游戏居多 300+ 200+ 200+ 配置 12700kf+4090 8 核 16 线程+RTX 3060 高端配置 10 代 i5+RTX 3070 12 代 i5+407010 代 i5+2060s 10 代 i5+206012 代 i5+3060Ti 或 4070 最高卡支持 4090 3060 未知 3070 4070 4070 默认支持最高分辨率 4K 2K 144Hz 未知 1080p 4K 2K 1080p 内存 64G32G 32G 未知 依赖云端配置 32G 32G 32G16G 延迟 低 低 未知 超低 低 低 中 资费 2.4 元小时 420~1020 金币小时 1.98 ~ 3.6 元小时 180 云币小时 未知 4 ~ 6 元小时 1.6 ~ 4 元小时 2.7 ~ 4 元小时（冲 50 ） 综合评分 ⭐⭐⭐ ⭐⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ ⭐⭐ 主页网址 海马云 ToDesk 网易云游戏 腾讯START 海星云 顺网云电脑 极云普惠云电脑 青椒云 支持 PC安卓IOS 另有不适用于游戏服务或者可能服务已经关闭的尚未介绍的有以下平台： 虎牙 YOWA 云游戏 达龙云游戏 咪咕快游 蘑菇云游戏 易云咖 领沃云游戏 小悟云 鲸云游戏 菜鸡云游戏 天翼云游戏 国外有 参数 GeForce NOW Xbox Cloud Gaming Shadow Amazon Luna PlayStation Plus Boosteroid 网易云游戏 腾讯 START 云游戏名称 GeForce NOW Xbox Cloud Gaming (xCloud) Shadow Amazon Luna PlayStation Plus Premium Boosteroid 网易云游戏 腾讯 START 运行平台 PCMacAndroidiOS智能电视 XboxPCAndroidiOS PCMacAndroidiOS PCMacAndroidiOSFire TV PS4PS5PC PCMacAndroidiOS AndroidiOSPC AndroidiOSPC 游戏库 1500+ 350+ 自带游戏 100+ 800+ 400+ 100+ 100+ 最高分辨率 4K60fps 1080p60fps 4K60fps 1080p60fps 1080p60fps 1080p60fps 1080p60fps 1080p60fps 延迟 低 低 低 中 低 中 未知 低 功能 游戏跨平台同步 游戏跨平台同步 完整 PC 体验 游戏Twitch 集成 游戏PS 独占 游戏 游戏 游戏 月费 (美元) $9.99-$19.99 $14.99 (Game Pass Ultimate) $29.99 $9.99 $17.99 $9.99 ¥59 (~$8) 按时计费 数据中心 全球 30+ 全球 26 个地区 美国欧洲 美国 未公开 欧洲北美 中国 中国 综合评分 910 8.510 810 7.510 810 7.510 710 710 注意: 评分和部分技术细节可能因个人体验和网络条件而异。 价格可能会随时间变化,建议查看最新官方定价。 游戏库数量可能会随时间增减,数据仅供参考。","categories":["3.软件","0杂项"]},{"title":"libusb的交叉编译","path":"/2024/08/22/2-通讯协议-USB-libusb的交叉编译/","content":"下载相关的软件包： https://sourceforge.net/projects/libusb/files/ ，选择最新版本的 libusb-1.0.21, libusb-compat-0.1.5。其中 libusb-1.0 和 libusb-compat-0.1 中的函数以及编译时的链接方式都是不一样的。 解压，然后执行 ./configure --host=arm-none-linux-gnueabi（指定交叉编译工具链）（对于 libusb-1.0 版本执行 configure 时可能会出现以下错误）configure:error:“udev support requested but libudev not installed” 。需要执行命令时加上 --disable -udev 进行 make 操作，没有问题，执行 sudo make install，报错 ../libtool: line 1085: arm-none-linux-gnueabi-ranlib: command not found make[2]: *** [install-libLTLIBRARIES] Error 127，需执行 sudo -i 命令后切换到 root 权限，然后执行 make install，成功生成了我们所需的库文件 程序编译时需要链接库文件时，首先需要有-L 包含动态库的路径，其次有-lusb 和-lusb-1.0 两种选择，具体的可用 nm 查看所使用的函数在哪个库中，通过 nm 加上动态库名查看某动态库内的函数，如果链接错了，编译时将会出现一大堆 undefined 如果在编译时，提示 cannot find -lusb，那么就应该是只安装了 libusb-1.0 而并没有安装 libusb-compat-0.1 而做造成的错误","categories":["2.通讯协议","USB"]},{"title":"Docker下配置wordpress","path":"/2024/08/22/0-平台-Docker-Docker下配置wordpress/","content":"环境 docker.io 和 docker 的区别 docker.io 是 ubuntu 维护的，生产环境应该使用 docker.io 安装 Docker 及 Docker-composeDocker Compose 是一个工具，您可以使用它轻松定义和启动 Docker 中的多容器应用程序。 使用 Compose，您可以在单个 YAML 文件中定义所有服务，并且使用单个命令，可以启动或拆除所有服务。 在本教程中，我们将使用 Docker Compose 在隔离的容器化环境中并排运行两个容器（WordPress 和 MySQL）。 apt install docker.ioapt install docker-compose 确认版本 docker versiondocker-compose version 启动 docker sudo service docker start DockerCompose 方式安装 WordPress 及 Mysql准备存储目录Docker 容器中的数据不是持久的。这意味着如果您停止容器并再次运行它，您将丢失所有数据，里面将不再有任何数据。这可以通过添加 Docker 数据卷来避免。 创建 docker-compose.yml在 Docker Compose 中，运行容器所需的所有资源都必须在名为 .yaml 的 YAML 文件中定义 docker-compose.yaml。然后 Docker Compose 将读取此类文件并与 Docker 守护程序通信以创建、配置或销毁定义的资源。 在我们的例子中，该 docker-compose.yaml 文件将包含我们的 dockerized WordPress 设置的服务定义。此外，Docker Compose 允许我们将这些服务与共享网络和卷链接在一起。 因此，让我们从使用 Vim 编辑器在srvwordpress 目录中创建一个新文件 docker-compose.yaml 开始 。示例内容如下： version: 3.3services:\tmysql: image: mysql:latest #安装mysql镜像 volumes: #映射位置 mysql_data:/var/lib/mysql restart: always environment: #环境变量 MYSQL_ROOT_PASSWORD: liuluhua MYSQL_DATABASE: wordpress MYSQL_USER: liuluhua MYSQL_PASSWORD: liuluhua\twordpress: depends_on: #需要mysql mysql image: wordpress:latest #安装wordpress镜像 ports: 80:80 #端口映射 restart: always environment: #环境变量 WORDPRESS_DB_HOST: mysql:3306 WORDPRESS_DB_USER: liuluhua WORDPRESS_DB_PASSWORD: liuluhua WORDPRESS_DB_NAME: wordpressvolumes:\t./wp-content:/var/www/html/wp-contentvolumes:\tmysql_data: 这里定义了两个自动互相链接的服务 mysql 和 wordpress 使用最新的 mysql 和 wordpress 的 docker 镜像 设置了 MYSQL 和 WordPress 的环境 WordPress 映像基于 Apache，它通过 derfault 在端口 上运行 80。将默认 Apache 端口映射到 8080 本地计算机的端口。 mysql_data：流入这个数据库的数据将被持久化到一个命名卷 mysql_data，这样即使你删除了容器，数据仍然存在于你的机器上，并且可以再次安装在新的容器中。 volumes 参数 wordpress 是告诉 Docker 的 wp-content 在本地文件系统中显示目录。现在，我们为 WordPress 站点的某些部分（例如 wp-content 目录）提供了持久存储。在 wp-content 包含所有用户提供的内容。基本上，您可以上传到网站的任何内容都会在此处结束。 只要您同时拥有数据库和 wp-content 文件夹，您就可以随时恢复您的站点，即使其他所有内容都丢失了。 启动docker-compose -f docker-compose.wordpress.yml up -d #后台运行docker-compose -f docker-compose.wordpress.yml down #停止并删除服务````# Docker 命令行## 命令行方式安装```cppdocker pull wordpressdocker pull mysql 命令行方式启动docker run -d --name mysql -v mysql-data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=liuluhua \\-e MYSQL_DATABASE=wordpress mysql \\docker run -d -e WORDPRESS_DB_HOST=mysql:3306 --link mysql \\-p 8000:80 wordpress 参数说明 -d 后台运行-p 端口映射 访问 wordpress打开 http://127.0.0.1:80 插件配置WP Githuber MD支持 markdown 配置上传文件大小在 yaml 文件中 volumes 中新增一行： ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini 默认为文件夹，删除修改为文件就行，修改文件内容为： file_uploads = Onmemory_limit = 5Gupload_max_filesize = 5Gpost_max_size = 5Gmax_execution_time = 0 #上传时间限制，修改为0则无限制 之后安装 WP Maximum Upload File Size 插件进行修改即可，最大支持到 2GB 如果要修改超过 2GB： 卸载 WP Maximum Upload File Size 插件，编辑 uploads.ini 编辑 html/wp-config.php @ini\\_set( upload\\_max\\_filesize , 4G );@ini\\_set( post\\_max\\_size, 4G);@ini\\_set( memory\\_limit, 8G );@ini\\_set( max\\_execution\\_time, 0 );@ini\\_set( max\\_input\\_time, 0 ); 编辑 html/wp-content/.htaccess php_value upload_max_filesize 4Gphp_value post_max_size 4Gphp_value memory_limit 8Gphp_value max_execution_time 0php_value max_input_time 0","categories":["0.平台","Docker"]},{"title":"术语缩写ABBR","path":"/2024/08/22/3-软件-航电-术语缩写ABBR/","content":"AHRSAHRS (Attitude and Heading Reference System) 是一种姿态和航向参考系统,用于测量和计算飞机的姿态和航向。它由以下部分组成: 三轴陀螺仪 - 测量角速率 三轴加速度计 - 测量重力加速度 三轴磁力计 - 测量地磁场 AHRS 使用这些传感器数据,通过数据融合算法(如扩展卡尔曼滤波)计算出飞机的滚转角、俯仰角和航向角。它提供了一种比传统机械式仪表更可靠和精确的姿态参考。 ADAHRSADAHRS (Air Data and Attitude Heading Reference System)是一种集成的空速数据和姿态航向参考系统。它在 AHRS 的基础上,增加了以下功能: 测量静压和动压,计算空速、高度等空速数据 测量外界温度 集成 GPS 数据 提供冗余的姿态和航向参考 ADAHRS 将 AHRS 的姿态数据与空速数据、温度数据、GPS 数据等融合,为飞机提供更加完整和冗余的导航参考。它广泛应用于商用航空飞机、军用飞机和无人机等。 AHRRATEAHRRATE(Attitude and Heading Reference System Rate)指的是姿态和航向参考系统(AHRS)测量的角速率。具体来说: AHRRATE 包括滚转角速率、俯仰角速率和偏航角速率,单位通常为 degs（度每秒）。 AHRS 使用陀螺仪传感器测量飞机在三个轴上的角速率变化。 AHRRATE 数据用于计算飞机的姿态角,并提供给飞行控制系统和显示系统。监测 AHRRATE 可以检测飞机的旋转运动,有助于监测飞机状态和预防失速。 ADCRATEADCRATE (Air Data Computer Rate)指的是空速数据计算机(ADC)测量的数据更新率。具体来说: ADCRATE 表示 ADC 每秒钟更新静压、动压、温度等空速数据的频率,单位为 Hz（赫兹）。 ADC 使用压力传感器和温度传感器测量飞机的空速相关参数。 较高的 ADCRATE 可以提供更平滑和实时的空速数据,有利于飞行控制系统的精确控制。典型的 ADCRATE 范围为 4-16 Hz。较高的更新率可以提高系统响应性,但也会增加处理开销。 空速IAS 是最基本的指示空速，CAS 是校正后的空速，EAS 考虑了空气密度的影响，TAS 是真实的空速，GS 是相对于地面的飞行速度。 IASIAS (Indicated Airspeed)是指示空速,是飞机上的空速表直接显示的数值,不考虑任何误差和环境因素的影响。IAS 是最基本的空速概念。 CASCAS(Calibrated Airspeed)是校正空速,是对 IAS 进行校正后的值。由于静压孔和皮托管的安装位置误差,以及仪表本身的误差,IAS 会与实际的空速存在偏差。CAS 就是将这些误差校正后的空速值。 EASEAS (Equivalent Airspeed)是当量空速,是在标准海平面大气条件下,具有与当前高度和 TAS 相同动压的空速。EAS 考虑了空气密度的影响。在高速高空飞行时,需要将 CAS 转换为 EAS。 TASTAS(True Airspeed)是真空速,是飞机相对于周围空气的实际飞行速度。TAS 考虑了空气密度的影响,是最能反映飞机性能的空速。在飞行计划和性能比较中,通常使用 TAS。 GSGS (Ground Speed)是地速,是飞机相对于地面的实际飞行速度。GS 等于 TAS 加上顺风分量,减去逆风分量。在无风条件下,GS 等于 TAS。","categories":["3.软件","航电"]},{"title":"MYSQL安装","path":"/2024/08/17/3-软件-数据库-MYSQL安装/","content":"MySQL 环境搭建指南安装 MySQL要在您的系统上安装 MySQL 服务器，只需输入以下命令： sudo apt install mysql-server -y 这里的 -y 选项让安装过程自动确认，避免了每一步手动输入 yes 的麻烦。 查看和管理 MySQL 服务状态安装完成后，您可以使用下列命令来查看和管理 MySQL 服务： sudo service mysql status 这个命令会告诉您 MySQL 服务当前的状态，是正在运行还是已停止。例如，您可能会看到服务状态为 active (running)，这意味着 MySQL 正在正常工作。 启动 MySQL 服务： sudo service mysql start 这条命令将启动 MySQL 服务。之后，您可以再次运行状态检查命令，确认服务已成功启动。 停止 MySQL 服务： sudo service mysql stop 如果您需要维护系统或更新配置，您可以使用此命令安全地停止 MySQL。 重启 MySQL 服务： sudo service mysql restart 这条命令会先停止服务再重新启动，对于更新配置文件后的应用非常有用。 查看并更新 MySQL 密码查看 MySQL 的配置文件，您可以使用以下命令： sudo cat /etc/mysql/debian.cnf 这将显示包含 MySQL 的一般配置，特别是与 Debian 映像相关的设置，其中可能包含默认的用户名和密码。 使用默认用户名和密码进行登录： mysql -u [your-username] -p 在这里，您需要替换 [your-username] 为实际的用户名（如 root）。系统将在提示您输入密码时，您可以使用在上一步中找到的默认密码。 更新 root 用户密码一旦成功登录到 MySQL，您可以更新 root 用户的密码。输入以下 SQL 命令来更新密码： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY newpasswd; 将 newpasswd 替换为您想要设置的新密码。mysql_native_password 是 MySQL 中一种广泛使用的身份验证方法。 变化生效后，您可以退出 MySQL： exit; 然后，用新密码再次登录，确保一切设置正确： mysql -u root -p 系统会提示您输入新设置的密码。输入后如果一切顺利，您将成功登录。 创建 Qexo 数据库为了满足 Qexo 应用程序的需求，您现在需要创建一个新的数据库。在 MySQL 提示符下执行以下命令： CREATE DATABASE qexo; 此命令创建一个名为 qexo 的新数据库，您可以根据需要进一步配置和管理这个数据库以用于应用程序数据存储。 一旦创建成功，您可以通过以下命令查看所有数据库，确认 qexo 数据库的存在： SHOW DATABASES; 这将列出所有现有的数据库，包括刚刚创建的 qexo。这样您就完成了 MySQL 环境的搭建，可以开始使用这个数据库进行更多的操作了。","categories":["3.软件","数据库"]},{"title":"FTP 配置","path":"/2024/08/17/0-平台-Linux-网络-FTP-FTP-配置/","content":"FTP 配置 - 用于图床安装 FTP 服务端首先，您需要在您的服务器上安装 FTP 服务端软件。我们将使用 vsftpd，这是一个广泛使用且安全的 FTP 服务器。可以通过以下命令进行安装： sudo apt install vsftpd -y 这个命令会自动下载并安装 vsftpd 及其依赖项。安装完成后，您将能够配置和使用 FTP 服务。 修改配置文件接下来，您需要编辑 vsftpd 的配置文件，以确保服务器的安全性和功能性。使用以下命令打开配置文件： sudo vi /etc/vsftpd.conf 在配置文件中，您需要进行以下更改： 禁止匿名访问：为了保护您的服务器，您应该禁用匿名用户的访问。找到以下行并确保它们被设置为： anonymous_enable=NO 这将防止任何未授权的用户访问您的 FTP 服务器。 接受本地用户：确保本地用户可以登录。找到并修改以下行： local_enable=YES 这允许您服务器上的本地用户使用他们的凭据进行访问。 允许上传：为了使用户能够上传文件，您需要启用写入权限。确保以下行被设置： write_enable=YES 更改创建文件权限：您可以设置新创建文件的权限掩码，以控制文件的默认权限。将以下行添加或修改为： local_umask=022 这将确保新文件的权限为 755，即所有者可以读、写和执行，而组用户和其他用户只能读和执行。 重启服务完成配置文件的修改后，您需要重启 vsftpd 服务，以使更改生效。使用以下命令重启服务： sudo service vsftpd restart 这将重新加载配置并启动 FTP 服务。 创建 FTP 用户最后，您需要创建一个 FTP 用户，以便可以通过 FTP 访问您的图床。使用以下命令创建用户： sudo useradd -d /home/lemonade -M lemonade 在这个命令中，-d 选项指定用户的主目录，而 -M 选项表示不创建用户的主目录。接下来，您需要为新用户设置密码： sudo passwd lemonade 系统会提示您输入并确认新用户的密码。完成后，您就可以使用该用户通过 FTP 访问您的服务器了。","categories":["0.平台","Linux","网络","FTP"]},{"title":"DailyHot部署","path":"/2024/08/17/0-平台-服务器-工具-DailyHot部署/","content":"前端项目地址 https://github.com/imsyy/DailyHot API 项目地址 https://github.com/imsyy/DailyHotApi API 部署clone 项目后进入项目目录执行 docker-compose.yml 文件 docker compose up -d#如果卡在npm install -g pnpm则通过docker run 命令行启动docker run -p 6688:6688 -d imsyy/dailyhot-api:latest 项目启动，访问 http://localhost:6688 前端部署clone 项目后进入目录执行 npm install 修改.env 文件中的 API 地址为自己部署的 API 地址 修改 vite.config.js 中的 port 为自己想使用的端口 运行 npm run dev -- --host 打包 npm run build 打包之后生成的页面在当前目录下的 dist 文件夹中，拷贝到varwww 目录下，在 nginx 中增加配置 server listen 9086 default_server; listen [::]:9086 default_server; root /var/www/dist; server_name _; location / index index.html; 之后重启 nginx 服务 sudo systemctl restart nginx.service 访问 IP:9086 即可访问","categories":["0.平台","服务器","工具"]},{"title":"Qt的线程池","path":"/2024/08/16/1-语言-Qt-Qt的线程池/","content":"线程池线程池是一种常见的并发编程模型，用于管理和复用多个线程来执行任务。它的基本思想是在应用程序启动时创建一组线程，这些线程可以重复使用，以执行一系列的任务，而不需要为每个任务都创建和销毁线程。 线程池通常由线程池管理器、工作队列和一组工作线程组成。 线程池管理器：负责管理线程池的创建、销毁和线程数量的控制。 工作队列：用于存储待执行的任务。当任务提交至线程池时，会被添加到工作队列中，等待线程池中的线程来执行。 工作线程：线程池中的线程会从工作队列中取出任务，并执行任务的操作。 线程池的优点包括： 提高性能：通过重用线程，避免了频繁创建和销毁线程的开销，可以减少系统资源的占用和提高任务的响应速度。 控制并发度：通过限制线程池中的线程数量，可以有效控制并发任务的数量，避免资源过度消耗和系统负载过重。 提供任务队列：线程池可以维护一个任务队列，任务的提交和执行是解耦的，可以灵活地调整任务的处理顺序和优先级。 简化线程管理：由线程池管理器负责线程的创建、销毁和管理，开发者无需手动管理线程的生命周期。 Qt 的线程池QThreadPool 管理并回收单个 QThread 对象，以帮助降低使用线程的程序中的线程创建成本。每个 Qt 应用程序都有一个全局的 QThreadPool 对象，可以通过调用 globalInstance() 来访问。 要使用 QThreadPool 中的一个线程，子类化 QRunnable 并实现 run() 虚函数。然后创建该类的一个对象，并将其传递给 QThreadPool::start()。QThreadPool 默认会自动删除 QRunnable。使用 QRunnable::setAutoDelete() 来更改自动删除标志。 QThreadPool 支持通过在 QRunnable::run() 内部调用 tryStart(this) 多次执行同一个 QRunnable。如果启用了自动删除，当最后一个线程退出 run 函数时，QRunnable 将被删除。在启用自动删除时，使用相同的 QRunnable 多次调用 start() 会造成竞争条件，不建议这样做。 一段时间未使用的线程将会过期。默认的过期超时时间是 30000 毫秒（30 秒）。可以使用 setExpiryTimeout() 更改此设置。设置负的过期超时时间将禁用过期机制。 调用 maxThreadCount() 来查询要使用的最大线程数。如果需要，可以使用 setMaxThreadCount() 更改限制。默认的 maxThreadCount() 是 QThread::idealThreadCount()。activeThreadCount() 函数返回当前正在工作的线程数量。 reserveThread() 函数为外部使用保留一个线程。使用完线程后使用 releaseThread()，以便它可以被重新使用。本质上，这些函数暂时增加或减少活动线程数，在实现对 QThreadPool 不可见的耗时操作时非常有用。 QThreadPool 是用于管理线程的低级类，有关更高级的替代方案，请参阅 Qt Concurrent 模块。 函数说明// 获取和设置线程中的最大线程个数int maxThreadCount() const;void setMaxThreadCount(int maxThreadCount);// 给线程池添加任务, 任务是一个 QRunnable 类型的对象// 如果线程池中没有空闲的线程了, 任务会放到任务队列中, 等待线程处理void QThreadPool::start(QRunnable * runnable, int priority = 0);// 如果线程池中没有空闲的线程了, 直接返回值, 任务添加失败, 任务不会添加到任务队列中bool QThreadPool::tryStart(QRunnable * runnable);// 线程池中被激活的线程的个数(正在工作的线程个数)int QThreadPool::activeThreadCount() const;// 尝试性的将某一个任务从线程池的任务队列中删除, 如果任务已经开始执行就无法删除了bool QThreadPool::tryTake(QRunnable *runnable);// 将线程池中的任务队列里边没有开始处理的所有任务删除, 如果已经开始处理了就无法通过该函数删除了void QThreadPool::clear();// 在每个Qt应用程序中都有一个全局的线程池对象, 通过这个函数直接访问这个对象static QThreadPool * QThreadPool::globalInstance(); 一个扫描 IP 地址的线程池实例#include QApplication#include QThreadPoolclass ScanIpThread : public QRunnablepublic: QString ipAddr; ScanIpThread(QString ip_addr) ipAddr = ip_addr; void run() override qDebug() Hello world from thread QThread::currentThread(); QStringList parameters;#if defined(WIN32) parameters -n 5;#else parameters -c 5;#endif parameters ipAddr; int exitCode = QProcess::execute(ping, parameters); if (exitCode==0) qDebug()ipAddr its alive; else qDebug()ipAddr its dead; ;int main(int argc, char *argv[]) QApplication a(argc, argv); QThreadPool *threadPool = new QThreadPool; threadPool-setMaxThreadCount(64); for(int i=0; i255; i++) ScanIpThread *scanNode = new ScanIpThread(QString(192.168.0.%1).arg(i)); // QThreadPool takes ownership and deletes node automatically threadPool-start(scanNode); return a.exec();","categories":["1.语言","Qt"]},{"title":"语音转文字并美化方案","path":"/2024/08/16/3-软件-AI-语音转文字并美化方案/","content":"获取视频文件转为音频 传入音频文件，调用腾讯云 API 进行转文字 部署ollma3，调用API进行文案优化 返回优化后的文案，调用文案生成视频 获取生成后的视频 部署wsl，优化3568的photo，利用clash局域网代理","categories":["3.软件","AI"]},{"title":"3568GPU负载查看及参数设置","path":"/2024/08/15/0-平台-嵌入式-3568GPU负载查看及参数设置/","content":"1.Look up the load@frequency of GPU 查看当前负载和频率 cat /sys/class/devfreq/*.gpu/load 2.Look up the supported mode or supported frquency for GPU 查看当前支持的模式和频率 cat /sys/class/devfreq/*.gpu/available_governorscat /sys/class/devfreq/*.gpu/available_frequencies 3.Set performance(the most high frequency) for GPU 设置性能模式 echo performance /sys/class/devfreq/*.gpu/governor 4.Set frequency for GPU 设置频率 #设置模式为用户模式echo userspace /sys/class/devfreq/*.gpu/governor#打印当前支持的频率cat /sys/class/devfreq/*.gpu/available_frequencies#将要设置的频率写入(ps: you should do step 2 to ensure the available_frequencies before you set) echo 800000000 /sys/class/devfreq/*.gpu/set_freq 5.Get a version 获取版本信息 strings libMali.so | grep rk_so_ver 6.Set power always on 关闭节能模式 echo always_on /sys/devices/*.gpu/power_policy 循环打印 GPU 负载脚本 #!/bin/shwhile [ 1 ]docat /sys/class/devfreq/fde60000.gpu/loadsleep 1done","categories":["0.平台","嵌入式"]},{"title":"3566与3568与3588之间的差异","path":"/2024/08/15/0-平台-嵌入式-3566与3568与3588之间的差异/","content":"接口差异 外部存储接口: RK3568 支持 ECC 内存 RK3566 不支持 ECC 内存 PCI-E 接口: RK3568 支持 PCI-E 3.0 RK3566 仅支持 PCI-E 2.1 以太网接口: RK3568 配备双千兆网口 RK3566 只有单千兆网口 SATA 接口: RK3568 支持 3 个 SATA 3.0 接口 RK3566 仅支持 1 个 SATA 3.0 接口 显示输出: RK3568 支持三重显示 RK3566 支持双显示 技术参数差异表： Processor Rockchip RK3568 Rockchip RK3566 Rockchip RK3588 Market (main) Single-board computer Single-board computer High-performance single-board computer ISA ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) Microarchitecture Cortex-A55 Cortex-A55 Cortex-A76 + Cortex-A55 Family RK3500 RK3500 RK3500 Part number(s), S-Spec RK3568 RK3566 RK3588 Release date Q2 2020 Q2 2020 Q1 2022 Lithography 22 nm 22 nm 8 nm Cores 4 4 8 (4+4) Threads 4 4 8 Base frequency 2.0 GHz 1.8 GHz 2.4 GHz (A76), 1.8 GHz (A55) Turbo frequency - - - High performance cores 4x ARM Cortex-A55 @ 2.0 GHz 4x ARM Cortex-A55 @ 1.8 GHz 4x Cortex-A76 @ 2.4 GHz Cache memory 256 KB 256 KB 1 MB L3 Max memory capacity 8 GB 4 GB 32 GB Memory types LPDDR4-1600 DDR3, DDR3L, LPDDR3, DDR4, LPDDR4X LPDDR4X-3200, LPDDR5-2400 Max PCIe lanes 1 1 4 TDP 5 W 5 W 10-15 W GPU integrated graphics ARM Mali-G52 2EE MC2 ARM Mali-G52 MP2 ARM Mali-G610 MP4 GPU execution units 2 2 4 GPU shading units 32 32 - GPU base clock - 850 MHz 1000 MHz GPU boost clock 820 MHz 950 MHz - GPU FP32 floating point 54.4 GFLOPS 54.4 GFLOPS 614 GFLOPS Socket SoC SoC SoC Drystone MIPS 22,736 DMIPS 20,462 DMIPS - AI accelerator AI accelerator RKNN NPU - NPU AI computing operations per seconds 0.8 TOPS - 6 TOPS Crypto engine Cipher Engine, SHA-1, SHA-256224,SHA-512384, MD5, AES-128, AES-192,AES-256, DES, TDES, TRNG - - Max display resolution 4K@60fps - 8K@60fps Video decoding H.265H.264VP9 4K@60fps - 8K@60fps H.265VP9AVS2, 8K@30fps H.264 AVCMVC Video encoding H.265H.264 1080p@60fps - 8K@30fps H.265H.264 Max video capture MIPI-CSI - - Modem Gigabit Ethernet - 2.5 GbE Connectivity SATA 3.0, eMMC, HDMI 2.0,USB 3.0, USB 2.0 - PCIe 3.0, USB 3.1, HDMI 2.1 Wi-Fi WiFi 6 (802.11ax) - Wi-Fi 6 (802.11ax) Bluetooth Bluetooth 5.0 - Bluetooth 5.2 Audio SPDIF, PWM, SPI, I2S, I2C - - (Android 64-bit)Geekbench 4 single core 875 756 - (Android 64-bit)Geekbench 4 multi-core 2,375 1,997 - (Android)Geekbench 5 single core 161 108 ~800 (Android)Geekbench 5 multi-core 492 281 ~2800 (SGEMM)GFLOPS performance 21.2 GFLOPS 18.2 GFLOPS - (Multi-core watt performance)Performance watt ratio 475 pts W 399 pts W -","categories":["0.平台","嵌入式"]},{"title":"Docker随手记","path":"/2024/08/14/0-平台-Docker-Docker随手记/","content":"docker.io 和 docker-ce 区别 docker.io 采用 apt 的方式管理依赖 docker-ce 用 go 的方式管理依赖，会自己管理所有的依赖。 导出镜像：使用 docker save 命令来导出镜像。 命令格式：docker save -o 输出文件名.tar 镜像名称:镜像标签 docker save -o my_image.tar my_docker_image:latest 导入镜像：使用 docker load 命令来导入镜像。 命令格式：docker load -i 输入文件名.tar docker load -i my_image.tar","categories":["0.平台","Docker"]},{"title":"curl 命令","path":"/2024/08/14/3-软件-Web相关-curl-命令/","content":"依赖库libcurl 安装示例如下: #ubuntusudo apt-get install libcurl4-openssl-dev#centosyum install libcurl-devel#macos（本身自带curl，这一步非必须）brew install curl#windows（这里的 cpu 架构请根据实际环境灵活选择）vcpkg install curl:x64-windows 备注：建议安装最新版的 libcurl 库，否则可能存在 libcurl 库内存泄露 bug 问题。 curl 命令是一个功能强大的命令行传输工具，用于发送请求和下载文件。它支持多种协议，如 HTTP、HTTPS、FTP 等，可以设置请求头、请求参数等 发送 GET 请求curl URLcurl URL?a=1b=nihao 发送 POST 请求curl -X POST -d a=1b=nihao URL 发送 json 格式请求：curl -H Content-Type: application/json -X POST -d abc:123,bcd:nihao URLcurl -H Content-Type: application/json -X POST -d @test.json URL -H 代表 header 头 -X 是指定什么类型请求(POSTGETHEADDELETEPUTPATCH) -d 代表传输什么数据 查看所有 curl 命令： man curl 或者 curl -h请求头：H,A,e响应头：I,i,Dcookie：b,c,j传输：F(POST),G(GET),T(PUT),X输出：o,O,w断点续传：r调试：v,–trace,–trace-ascii,–trace-time 测试端口可以用它来测试端口是否开启。 curl -v ip:port 出现 Connection refused 表示端口关闭； 出现 Connected to ip(ip) port(#0)表示端口开启； 出现 No route to host 表示 IP 错误或者 iptables 限制。","categories":["3.软件","Web相关"]},{"title":"ARINC653","path":"/2024/08/12/3-软件-航电-ARINC653/","content":"ARINC653 介绍ARINC653 作为一个标准，主要阐述了模块化综合航空电子设备 IMA(Integrated Modular Avionics)使用的应用软件的基线操作环境。其定义了航空应用与下层操作环境之间的接口和数据交换的模式以及服务的行为，并描述了嵌入式航空电子软件的运行时环境。 在实际应用过程中，航空电子中的核心模块软件包括两类: 应用软件和核心软件。ARINC653 定义的就是位于应用软件和操作系统 OS 之间的 APEX(APplication EXecutive)接口，APEX 接口是操作系统为应用软件提供的一个功能集合。利用这个功能集合，应用软件可以控制系统的调度，通信和内部状态信息。 APEX 接口相当于为应用提供的一种高层语言。 而对于 OS 来说，是关于参数和入口机制的定义。 ARINC653 标准一个重要的标准就是将航空电子软件进行分时，分区管理。采用二级调度，分区内基于优先级进行调度，分区间通过时间窗口进行时间轮转调度。同时定义了分区内的进程接口，进程间通信接口，分区间通信的 Port 标准接口，并且为了增强系统的可靠性定义了系统级，分区级，进程级别的健康监控管理接口。 分区和区间管理分区（Partitioning）是 ARINC653 中一个核心概念。在 IMA(Integrated Modular Avionics)系统中，一个核心模块会包含一个或多个航空电子应用，并且这些应用要能够独立运行。分区就是航空电子应用中的一个功能划分。分区的单位称为区间，区间内的每一个执行单元称为进程。每一个区间具有自己独立的数据、上下文和运行环境，这样做的好处是能够防止一个区间的错误影响到其他区间。另外，它能使得整个系统容易验证、确认和认证。 区间化以及区间的管理和调度是由 OS 来实现的。ARINC653 为区间的调度规定了一种基于时间窗的循环调度算法。 为了完成各区间的周期性调度，由 OS 维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表,在规定的时间窗口内激活对应区间的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 ARINC supplement 1 对主时间框架的时间定义原则进行了补充。它规定主时间框架的大小应该是核心模块中所有区间周期的最小公倍数的正整数倍，并应考虑到每个区间每次执行的时间长度和执行频率。 在 ARINC653 Supplement 1 发布时又增加了系统区间属性和启动条件属性。区间的工作模式包括空闲，冷启动，热启动和正常四种，如图 3 所示。每个区间所需资源在系统构建时指定，在区间初始化完成时区间对象创建。OS 在进入运行模式时启动应用区间，然后区间进入正常运行模式。监测管理功能在响应致命错误时将重启区间或者停止区间的运行。 根据 ARINC653 标准的规定，需要模块操作系统提供时空隔离机制的支持，因此内核和分区应用在空间上和时间上应进行隔离保护。 下面分两部分论述系统空间时间分配，首先是基于整个模块操作系统的空间和时间分配情况，后面是基于 APEX 接口的实现上的空间和时间分配。 ●空间隔离 在操作系统中，以分区为资源分配单位。采用复平面空间的方式，每个应用都有独立的 4G 空间，从而实现用户与操作系统，用户与用户之间在存储空间上进行隔离，达到互不影响的目的。 从 APEX 接口的设计实现上来讲，空间分配包含两部分的内容： APEX 分区上的资源分配 即使用的是应用分区上的空间资源，包括了各个 APEX 对象管理控制块资源。 分区管理 进程管理 分区健康监控 信号量 事件 黑板 缓冲 时间管理 采样端口 队列端口 内核空间的资源分配 主要是 APEX 接口调用过程中需要在内核分配的资源，列表如下： 内核的域管理 内核的任务管理 内核的周期对象管理 内核信号量 内核黑板 内核消息队列另外，在 APEX 内核支持层封装的对分区间通信的端口的支持，也是在内核空间分配的端口控制管理资源，包括了端口控制链和通道控制链。 ●时间隔离 目前 OS 为基于 APEX 接口的应用分区提供了时间调度表调度策略。通过配置时间调度表，可以控制各个分区在时间点上的运行分配。由操作系统维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表，在规定的时间窗口内激活对应域的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 接口清单 分区管理分区是一个应用运行的资源单位。一个分区是一个独立的应用环境：它由数据、自己的上下文关系、配置属性和其它项组成。分区的运行要满足时间和空间的要求。 通过分区可以实现应用间的隔离和保护，分区也是应用隔离保护的单位，每个分区有独立的运行空间和堆空间，不同分区的运行空间不会重叠。当一个应用出现致命错误，出现的最坏情况就是应用被系统删除或者重启动。而这个应用的错误不会影响到其他分区，更不会影响到操作系统口。 分区具有独立的调度策略，每个分区在属于自己时间窗口内运行。 一个分区则由一个或多个并发执行的进程组成，分区内的所有进程将共享分区所占有的系统资源。分区管理要求系统中同时可以运行多个不同类型的应用，同时在时间上和空间上互不影响。分区管理主要包括：分区的属性定义、分区的工作状态转换、分区的控制和分区的调度。 函数功能 分区状态的获取 设置分区模式 分区间通信分区间通信是 ARINC 653 标准中使用的一种通用表达方式，其主要定义两个或多个分区间的通信，标准的分区间通信是一项基本需求以支持应用软件的可重用性和可移植性。所有的分区间通信都通过消息进行。消息被定义为有限长度的连续数据块。 消息从单个的源发出，到一个或多个目标。消息的目标是分区而不是分区内的进程。分区通过已定义的访问点访问通道，访问点称为端口(port)。通道由一个或多个端口以及相关的资源组成。端口提供所需的资源以允许特定的分区在特定的通道中发送或接收消息。分区可以通过各自的资源和目的端口使用多个通道交换消息。通道将一个发送端口通过中间端口和一个或多个接收端口连接起来。每个单独的通道都可以配置在专门的模式下运行。可以使用两种传送模式，采样模式(samplingmode)和队列模式(queuingmode)。因此提供了采样端口服务和队列端口服务。 分区间通信遵循以下原则： 发送方和接受方并不关心对方的具体名字和物理位置，以避免系统的其他地方修改之后引起分区的变化。 消息只能有一个源，但可以有若干个目的； 来自不同端口的消息不需要按照它们发送的时间顺序到达它们的目的。 函数功能 采样端口服务 根据采样端口的周期性数据特点，采用内核提供的黑板机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX 内核支持层来实现具体的黑板写和读功能。需要注意的是源端口不用创建对应的黑板。APEX 内核支持层只为目的端口创建对应的黑板。 由于采样端口的数据具有周期性特点，因此存在数据有效性判断。对采样端口数据有效性的定义如下：数据停留在端口的时间小于用户设置的数据刷新周期时间。 数据停留时间从端口获取数据的系统时间一发送数据到端口的系统时间。 队列端口服务 根据队列端口的消息队列数据特点，采用内核提供的消息队列机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX内核支持层来实现具体的消息的发送和接收功能。需要注意的是源端口不用创建对应的消息队列。APEX 内核支持层只为目的端口创建对应的消息队列。 进程管理完成应用进程的管理，进程是操作系统运行的基本单位。 在分区内的执行体是由一个或多个进程组成，每个进程隶属于特定的分区，分区内的各进程之间并发执行。进程管理主要负责分区内进程的创建、调度和删除等管理工作。 进程分为按固定频率执行的周期进程和由事件触发的非周期进程两类，操作系统应具备对这两类进程的调度能力；进程在出现故障时应允许重新初始化或者终止；对于访问临界区的进程，为保证安全性，在访问时进程管理应禁止调度。 函数功能 创建进程 停止进程 挂起进程 解挂进程 设置进程优先级 分区内通信支持分区内的进程之间相互通信。按通信机制划分，分区内通信共有两种。一种是缓冲区和黑板，用于进程间通信。另一种是信号量和事件，用于进程间同步。 缓冲区和黑板的差别是：缓冲区允许消息以队列的形式存储，消息不允许覆盖，而黑板在任何时刻最多只保留一个消息，消息允许覆盖；信号量和事件的差别是：信号量用于对系统资源的访问，而事件用来完成进程之间的同步／异步操作。 提供了两种分区内通信机制： 函数功能 允许分区内进程间通过缓冲区和黑板进行通信。 通过计数信号量或事件实现进程间的同步。 缓冲 Buffer消息队列 MessageQueue在缓冲区中，消息的每个新实例都携带唯一不同的数据，因此传送时不允许覆盖前一个。缓冲允许在消息队列中存储多个消息。发送进程发送的消息以 FIFO 顺序存储在消息队列中。这种排队模式下不应该丢失任何消息。缓冲中能够存储的消息数量是由缓冲大小确定并在创建时指定的。等待在缓冲上的进程以 FIFO 或者优先级排队。优先级排队的情况下，相同优先级的进程按照 FIFO 顺序排队。排队规则在创建缓冲时定义。如果有进程等待缓冲消息并且缓冲(变得)不为空，则按照应用排队规则算法(FIFO 或者优先级)来确定哪个排队的进程接收此消息。OS 将把该进程从进程队列上移出，将其置为就绪状态。OS 将把消息从缓冲消息队列中移出。 当进程试图从空缓冲接收消息，或者发送消息到满的缓冲，将发生进程重调度。调用进程将被放入队列一段指定的时间，如果在该段时间内没有消息被接收或者发送，OS 将自动从队列中移出该进程，将其置为就绪状态。 黑板 Blackboard黑板是分区内进程间的一种通信机制。它和消息队列一样支持在多个源和目的之间的传输。黑板与消息队列最大的不同点是消息队列允许消息排队，而黑板不允许消息排队。 只要预先分配的存储空间足够大，那么进程可以创建尽可能多的黑板。 当进程进入一个等待状态时，分区需要重新进行进程调度。超时机制限制或者避免了等待时间过长的现象出现。 黑板是不支持排队的，写到黑板上的任何消息可能被擦除或者被新写入的消息覆盖掉。任务可以从黑板上读取一条信息、显示一条信息或者擦除黑板。 试图从空的黑板上读取信息的操作将会导致进程重新调度，进行该操作的进程将会进入队列中等待一段指定时间，如果在该段时间内没有消息被写到黑板上，dOS 将会将该进程从等待队列上移出并将其状态变为就绪。 当有消息被写到黑板上时，所有等待在黑板队列上的进程将会从队列上被移出并设置为就绪状态，该消息会被保持在黑板上。当黑板被擦除时，它会变空。 信号量 Semaphore信号量服务提供了计数信号量。 计数信号量是一种同步对象，常用于对分区内资源访问的控制。计数信号量的计数值一般用于反映当前合法资源的数量。 为了使用信号量，必须在初始化阶段中对其进行创建。创建信号量时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 事件 Event事件是一种同步对象，用于通知进程等待条件的出现。同一分区内的进程可以设置和清除事件，还可以在本分区内创建的事件上等待。 分区内创建的事件能够被分区内的所有进程使用。事件创建时，被设置为 down 状态。为了通知事件条件的发生，可以设置指定的事件为 up 状态，所有等待该事件的进程的状态将从等待变为就绪，然后进行重调度。等待事件的进程的执行顺序应该只依赖于分区内进程调度规则。 为了使用事件，必须在初始化阶段中对其进行创建。创建事件时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 时间管理时间管理为分区提供了功能接口来控制周期和非周期进程。 周期进程就是以特定频率执行的进程。类似的，只在特定事件之后执行的进程为非周期进程或事件驱动进程。 对于周期进程，分区内每个进程都可以确定一段执行时间来作为进程周期执行的最大时间长度。这个时间长度可用以设定进程的 Deadline 时间。操作系统会通过周期性地评估 Deadline 时间来判断进程是否在分配的时间内完成了执行。在进程执行周期的最后，应该调用 PERIODIC W 舭 T 服务来获取新的 Deadline。新 Deadline 的计时将从进程的下一个周期开始。 对于所有进程，TIMED—WAIT 服务允许进程挂起自己一段时间。待挂起时间到达以后，进程又可以被重新调度。 函数功能 使进程指定时间等待 使进程周期性等待 获取系统时间 健康监控健康监控用于监视硬件、应用程序和操作系统的状态，当发现故障时，记录故障并进行故障隔离，防止故障的蔓延，同时按故障级别(模块级、分区级和任务级)进行必要的恢复。健康监视的另一个功能是在系统配置时，用于检测系统配置的一致性和完整性。 ARINC 对健康监控处理的错误进行了分级，错误有可能发生在模块级、分区级和进程级。模块级错误仅影响模块内的所有分区。分区级错误仅影响该分区。进程级错误影响分区内的一个或者多个进程，或者是整个分区。如下给出各个级别的错误类型定义。 ●模块级错误： 模块初始化阶段出现模块配置错误； 模块初始化阶段出现其它错误： 系统功能执行期间的错误； 分区转换时发生的错误； 加电故障。 ●分区级错误： 分区初始化阶段出现分区配置错误； 分区初始化错误； 进程管理中的错误； 故障处理过程的错误。 ●进程级错误： 应用进程产生的应用错误； 非法的操作系统请求； 进程执行错误(溢出、存储区冲突…)。 错误的级别是由系统人员在状态监控的配置表中定义的，并且与诊断的错误和系统状态相一致的。任何级别上发生的错误，根据其错误特性，将会扩散到其被处理的更高级别上。 故障响应机制依赖于错误级别。模块级和分区级的故障响应是由一张模块状态监控表和每个分区的单独分区状态监控表驱动的。进程级故障响应由应用程序员使用分区的专门(最高优先级)的进程一一错误处理进程决定。程序员可以通过状态监控服务确定错误和故障进程，然后在进程级(例如，停止，启动进程，replenish)或者分区级(例如，设置分区模式：空闲，冷启动，热启动)采取恢复措施。错误处理进程中发生的错误被视为分区级错误。 函数功能 报告错误消息 创建错误处理进程 激活处理进程 启动分区 分区启动： 分区启动后，操作系统内核会为该分区创建一个初始任务。 初始任务的作用：主要用于初始化 APEX 接口，执行分区配置表中的初始化步骤。 初始任务的参数：例如优先级和任务栈大小，这些参数通常由 APEX 接口的具体实现决定，对于使用 APEX 接口的用户来说，这些参数是透明的，即用户不需要手动设置这些参数。 APEX 配置信息的入口参数的结构。 typedef structvoid* processInfo； /*进程整体配置信息*/void* bufferInfo； /*缓冲区整体配置信息*/void* bbInfo； /*黑板整体配置*/void* semInfo； /*信号量整体配置信息*/void* eventInfo； /*事件整体配置信息*/void* queuingInfo；/*队列端口配置信息*/void* samplingInfo； /*采样端口配置信息*/void* hmInfo； /*分区健康监控配置信息*/)T_APEX_CONFIG_INFO； 初始化 APEX 接口 APEX INIT 调用： 初始任务会以分区配置表为参数，调用 APEX 接口的初始化入口函数 APEX INIT。 系统对象的初始化：APEX 接口根据分区配置表中的各项参数，初始化系统对象。系统对象包括各种系统资源，如队列、缓冲区、信号量等。 创建系统进程：APEX 接口接着会创建一些关键的系统进程，比如初始进程和 IDLE 进程。这些进程对于分区的基本操作和管理至关重要。 初始任务的结束：在完成上述初始化步骤后，初始任务的生命周期就结束了，系统进程开始接管分区的运行。 值得注意的是， APEX 接口的初始化是一个分界线，从此之后创建的任何进程或对象都必须在分区配置表中有对应的配置，否则创建将会失败，IDLE 等系统进程也不例外。而在初始化 APEX 接口之前创建的系统对象的生命周期必须到此结束，不能延续到 APEX 接口初始化之后，以初始任务为例，在 APEX 接口初始化过程就会被终止。以保证 APEX 接口之上应用程序的可移植性不受具体 OS 的影响。 设置分区为 NORMAL 模式 USERMAIN 的调用： 由系统进程之一的初始进程调用用户程序的入口函数 USERMAIN。 分区应用程序的执行：用户可以在 USERMAIN 函数中创建自己的用户进程和其他系统对象（例如信号量、事件、任务等）。 设置分区模式为 NORMAL：在用户程序的初始化步骤完成后，系统将分区的模式设置为 NORMAL。这意味着分区已经准备好并开始执行用户定义的进程。 初始进程的结束：一旦所有用户进程创建完成并开始运行，初始进程的生命周期也结束。 分区间切换 分区切换概述： 分区间切换是指在一个多分区系统中，操作系统从一个分区切换到另一个分区。切换通常是由系统调度器在时间片到期或者根据特定条件触发的。 时间分片：系统通常会以固定的时间片进行分区切换，即每个分区在其时间片内独占 CPU 资源。 切换过程： 时间片到期或切换请求：当分配给当前分区的时间片到期，或者有其他条件触发了分区切换请求，系统调度器将会进行分区切换。 保存当前分区状态：在切换之前，操作系统会保存当前分区的状态，包括寄存器、任务栈和其他重要数据。 加载新分区状态：系统调度器加载下一个分区的状态，并将处理器控制权转移到新分区。 切换完成：新分区开始执行其任务，并在其时间片内独占 CPU 资源。 分区间切换的关键点： 隔离性：确保不同分区的资源和状态相互隔离，以防干扰。 实时性：需要保证分区切换的延迟在可接受的范围内，以满足系统的实时性要求。 分区内进程切换 进程切换概述： 分区内进程切换是指在同一个分区内，从一个进程切换到另一个进程。通常由分区内的调度器管理。 切换过程： 进程调度：分区内的调度器根据调度算法（如优先权调度）决定下一个要执行的进程。 保存当前进程状态：保存当前进程的寄存器值、堆栈指针和其他状态信息。 恢复新进程状态：加载新进程的寄存器值和堆栈指针，恢复新进程的执行上下文。 切换完成：新进程开始执行。 进程间切换的关键点： 优先级：进程调度通常依赖于优先级，确保高优先级的进程能够得到及时处理。 上下文切换：需要有效地管理进程的上下文切换，减少上下文切换的开销，以提高系统性能。 APEX 时间调度（ApexTime Scheduling） APEX 时间调度概述： ApexTime 是 ARINC 653 规范的一部分，用于管理系统中的时间分片和时间资源。它保证了任务在预定的时间段内能够得到执行，满足实时任务的需求。 时间调度的关键功能： 时间分片：系统将时间划分为固定长度的时间片，分配给不同的任务或分区。这确保了每个任务都有公平的执行机会。 时间分区：APEX 接口通过时间分区机制管理任务执行的时间，确保任务在预定的时间内运行，满足实时系统的要求。 定时器管理：APEX 提供了定时器服务，用于管理任务的超时和周期性调度，支持任务在特定时间点或间隔内执行。 时间调度的实现： 调度算法：APEX 接口可能会使用轮转法、优先级调度或其他调度算法来管理任务的时间片和优先级。 系统调用：用户任务可以通过 APEX 提供的系统调用来请求时间服务，例如设置定时器、请求时间片等。 实时保障：通过精确的时间管理和调度算法，APEX 确保了系统能够满足严格的实时性要求。","categories":["3.软件","航电"]},{"title":"飞凌OK3568的Docker支持","path":"/2024/08/12/0-平台-嵌入式-飞凌OK3568的Docker支持/","content":"编辑 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 增加以下内容 #add docker supportCONFIG_MEMCG=yCONFIG_VETH=yCONFIG_BRIDGE=yCONFIG_BRIDGE_NETFILTER=yCONFIG_NETFILTER_XT_MATCH_ADDRTYPE=yCONFIG_NETFILTER_XT_MATCH_CONNTRACK=yCONFIG_NETFILTER_XT_MATCH_IPVS=yCONFIG_NETFILTER_XT_MARK=yCONFIG_POSIX_MQUEUE=yCONFIG_CGROUP_BPF=yCONFIG_NETFILTER_ADVANCED=yCONFIG_NETFILTER_XTABLES=yCONFIG_IP_VS=yCONFIG_IP_PNP=yCONFIG_IP_PNP_DHCP=y 之后再编译烧写测试下 #更新软件源sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo apt install software-properties-common#添加仓库sudo add-apt-repository deb [arch=arm64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stablesudo apt-get update apt-cache madison docker-cesudo apt-get -y install docker-ce=5:20.10.1~3-0~ubuntu-focalsudo docker image ls","categories":["0.平台","嵌入式"]},{"title":"最大打开文件数量","path":"/2024/08/12/0-平台-Linux-文件-最大打开文件数量/","content":"报错：Can’t open so many files 或者 too many open files 涉及参数 参数 说明 默认值 查询语句 nofile 单个进程的最大打开文件数 1024 ulimit -n 或者 cat procpidlimits nr_open 单个进程可分配的最大文件数 1024*10241048576 cat procsysfsnr_open file-max 系统内核一共可以打开的最大值 199708 cat procsysfsfile-max nofile 是 linux 操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接字数量） file-max 是设置系统所有进程一共可以打开的文件数量 。同时一些程序可以通过 setrlimit 调用，设置每个进程的限制。 nofile临时修改ulimit -SHn 1024000 分软限制和硬限制，加-H 就是硬限制，加-S 就是软限制。默认显示的是软限制，如果运行 ulimit 命令修改时没有加上-H 或-S，就是两个参数一起改变。 硬限制就是实际的限制，而软限制是警告限制，它只会给出警告。 永久修改一vi /etc/security/limits.conf * 表示所用的用户 二修改 /etc/profile 增加 ulimit -SHn 128000 etcprofile 是 Linux 系统中的一个重要配置文件，主要用于设置系统级的环境变量和启动程序。该文件在用户登录时被执行，适用于所有用户。 系统总限制临时修改echo 1200000 /proc/sys/fs/nr_openecho 200000 /proc/sys/fs/file-max 永久修改一在文件procsysfsnr_open 中加入如下代码：（1200000 为修改的参数值） fs.nr_open=1200000 在文件 procsysfsfile-max 中插入如下代码： fs.file-max=200000 保存并执行 reboot 重启服务器。 二在etcsysctl.conf 中设置 fs.nr_open 1200000 fs.file-max200000，然后执行 sysctl -p，使配置生效。无需重启。 查看系统下各个进程打开的文件描述符数量lsof -n |awk print $2|sort|uniq -c |sort -nr #匹配PID为696的进程lsof -fp | grep 696 | wc -l","categories":["0.平台","Linux","文件"]},{"title":"远程桌面","path":"/2024/07/30/3-软件-代理穿透-远程桌面/","content":"TeamViewerVNC选择 lightdm 作为 Display Manager。首先更新系统软件包列表并安装必要的软件包： sudo apt updatesudo apt install -y xserver-xorg-video-dummy x11vnc xfce4 接下来配置 X11 服务器以使用虚拟视频设备。编辑etcX11xorg.conf 文件并添加： Section Device Identifier Configured Video Device Driver dummy VideoRam 256000EndSectionSection Monitor Identifier Configured Monitor HorizSync 5.0 - 1000.0 VertRefresh 5.0 - 200.0 ModeLine 1920x1080 148.50 1920 2448 2492 2640 1080 1084 1089 1125 +Hsync +VsyncEndSectionSection Screen Identifier Default Screen Monitor Configured Monitor Device Configured Video Device DefaultDepth 24 SubSection Display Depth 24 Modes 1920x1080 EndSubSectionEndSection 完成配置后，重启设备以应用更改：sudo reboot，之后配置和启动 x11vnc 服务。 查看设备 IP 地址：ip addr 启动 x11vnc 服务：x 代表端口号 sudo x11vnc -display :x -auth /var/lib/lightdm/.Xauthority 然后就可以在 PC 机上使用 ip+5900+x 地址来 VNC 远程连接。 安装必要的软件包sudo apt updatesudo apt install tigervnc-server #tightvncserver 桌面环境没有桌面环境的话，则需要安装相关的桌面环境 vncserver -geometry 1920x1080 :1 配置 VNC Server运行 vncserver 命令来首次配置。它会提示您设置密码和查看连接所需的信息。 修改配置文件sudo nano ~/.vnc/xstartup 将其中的内容修改为以下类似的内容，以确保有正确的桌面环境启动： #!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESSgnome-session # #!/bin/sh#export XKL_XMODMAP_DISABLE=1#export XDG_CURRENT_DESKTOP=GNOME-Flashback:GNOME#export XDG_MENU_PREFIX=gnome-flashback-#gnome-session --session=gnome-flashback-metacity --disable-acceleration-#check 重启 VNC Servervncserver -kill :1 # 假设您的 VNC 实例是 :1vncserver -geometry 1920x1080 :1 VNCserver 的端口为 5900+X，如果我想要 VNC 端口在 9099 时，则设置 VNC 实例为 vncserver -geometry 1920x1080 :3199 设置防火墙如果您启用了防火墙，需要允许 VNC 相关的端口通过。VNC 通常使用 5900 + 显示编号的端口，例如第一个实例是 5901。 例如，如果您使用 ufw 防火墙，可以运行以下命令： sudo ufw allow 5901 这样，您就完成了 Ubuntu 20 上 VNC Server 的基本配置，可以通过 VNC 客户端使用设置的密码和服务器的 IP 地址及端口进行连接。","categories":["3.软件","代理穿透"]},{"title":"多核处理器的负载均衡","path":"/2024/07/25/0-平台-Linux-内核-多核处理器的负载均衡/","content":"现阶段多核处理器的应用范围越来越广泛，在通常情况下应用程序的调度都是交由操作系统进行管理，操作系统对应用程序进行调度，使其在不同的核上轮番运行。 多核操作系统的关注点在于进程的分配和调度。进程的分配将进程分配到合理的物理核上，因为不同的核在共享性和历史运行情况都是不同的。有的物理核能够共享二级 cache，而有的却是独立的。如果将有数据共享的进程分配给有共享二级 cache 的核上，将大大提升性能；反之，就有可能影响性能。 在一般情况下，操作系统的默认调度机制可以应付大部分的情况，但是针对于需要高运行效率的进程来说，就有必要考虑将其固定在一个核上运行，避免在不同的核上调度造成的额外开销。 对于绑定的进程来说，该进程将会一直在指定的核上运行，不会在被调度到其他的核上，但是被绑定的核上仍然有可能运行其他进程。 在多核处理器的 Linux 系统中,可以通过几种方法实现应用程序线程在指定 CPU 核上运行,从而提高性能并减少不同核心间切换的开销. 需要注意的是,手动绑核应谨慎使用,因为它可能会影响系统的整体负载均衡. 在大多数情况下,操作系统的默认调度策略已经能够很好地管理线程分配. 查看 cpu 有几个核cat /proc/cpuinfo 使用系统调用 sysconf 获取 cpu 核心数： #include unistd.hint sysconf(_SC_NPROCESSORS_CONF);/* 返回系统可以使用的核数，但是其值会包括系统中禁用的核的数目，因 此该值并不代表当前系统中可用的核数 */int sysconf(_SC_NPROCESSORS_ONLN);/* 返回值真正的代表了系统当前可用的核数 *//* 以下两个函数与上述类似 */#include sys/sysinfo.hint get_nprocs_conf (void);/* 可用核数 */int get_nprocs (void);/* 真正的反映了当前可用核数 */ taskset 命令taskset 可以在命令行中将进程或线程绑定到特定的 CPU 核心. 查看进程绑定情况 taskset -p [pid] 绑定进程到指定 CPU 核（cpuid 的标号是从 0 开始的） taskset -cp [cpuid] [pid] 例如:（将进程 9865 绑定到 1,2,5-11 号核） taskset -cp 1,2,5-11 9865 在启动时绑定可以在启动应用程序时使用 taskset 命令直接绑定: taskset -c 0,1 ./your_program sched_setaffinity 系统调用在程序代码中可以使用 sched_setaffinity 函数来设置线程的 CPU 亲和性: #define _GNU_SOURCE#include sched.h/* 设置进程号为pid的进程运行在mask所设定的CPU上 * 第二个参数cpusetsize是mask所指定的数的长度 * 通常设定为sizeof(cpu_set_t) * 如果pid的值为0,则表示指定的是当前进程 */int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);/* 获得pid所指示的进程的CPU位掩码,并将该掩码返回到mask所指向的结构中 */int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);cpu_set_t mask;CPU_ZERO(mask);CPU_SET(0, mask); // 设置亲和性为 CPU 0sched_setaffinity(0, sizeof(mask), mask); 测试代码#includestdlib.h#includestdio.h#includesys/types.h#includesys/sysinfo.h#includeunistd.h#define __USE_GNU#includesched.h#includectype.h#includestring.h#includepthread.h#define THREAD_MAX_NUM 200 //1个CPU内的最多进程数int num=0; //cpu中核数void* threadFun(void* arg) //arg 传递线程标号（自己定义） cpu_set_t mask; //CPU核的集合 cpu_set_t get; //获取在集合中的CPU int *a = (int *)arg; int i; printf(the thread is:%d ,*a); //显示是第几个线程 CPU_ZERO(mask); //置空 CPU_SET(*a,mask); //设置亲和力值 if (sched_setaffinity(0, sizeof(mask), mask) == -1)//设置线程CPU亲和力 printf(warning: could not set CPU affinity, continuing... ); CPU_ZERO(get); if (sched_getaffinity(0, sizeof(get), get) == -1)//获取线程CPU亲和力 printf(warning: cound not get thread affinity, continuing... ); for (i = 0; i num; i++) if (CPU_ISSET(i, get))//判断线程与哪个CPU有亲和力 printf(this thread %d is running processor : %d , i,i); return NULL;int main(int argc, char* argv[]) int tid[THREAD_MAX_NUM]; int i; pthread_t thread[THREAD_MAX_NUM]; num = sysconf(_SC_NPROCESSORS_CONF); //获取核数 if (num THREAD_MAX_NUM) printf(num of cores[%d] is bigger than THREAD_MAX_NUM[%d]! , num, THREAD_MAX_NUM); return -1; printf(system has %i processor(s). , num); for(i=0;inum;i++) tid[i] = i; //每个线程必须有个tid[i] pthread_create(thread[i],NULL,threadFun,(void*)tid[i]); for(i=0; i num; i++) pthread_join(thread[i],NULL);//等待所有的线程结束，线程为死循环所以CTRL+C结束 return 0; pthread_setaffinity_np 函数对于 POSIX 线程,可以使用 pthread_setaffinity_np 函数来设置线程亲和性: #define _GNU_SOURCE#include pthread.hint pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);cpu_set_t cpuset;CPU_ZERO(cpuset);CPU_SET(2, cpuset);pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), cpuset); 测试代码#include pthread.h#include stdio.h#include stdlib.h#include unistd.h#include sched.h#include sys/types.h#include sys/syscall.hpid_t gettid(void) return syscall(SYS_gettid);/** * @brief print_running_cpu * pthread_setaffinity_np函数用于设置线程的CPU亲和度。 * CPU_SET和CPU_ZERO用于设置和清除CPU掩码。 * print_running_cpu函数通过系统命令查询线程当前运行的CPU核，并打印出来。 */void print_running_cpu() char qry_cmd[1024] = 0 ; sprintf(qry_cmd, ps -o pid,spid,psr -T -p %d | grep %d | tail -n 1 | awk print $3, getpid(), gettid()); FILE *fp = popen(qry_cmd, r); if(fp == NULL) return; char cpu_id_str[200] = 0 ; fgets(cpu_id_str, 80, fp); fclose(fp); printf([%d] : current thread(%d@%d) is running on cpu(%d) , gettid(), gettid(), getpid(), atoi(cpu_id_str));void bind_thread_to_cpu(int cpu_id) cpu_set_t cpu_mask; CPU_ZERO(cpu_mask); CPU_SET(cpu_id, cpu_mask); pthread_setaffinity_np(pthread_self(), sizeof(cpu_mask), cpu_mask);void* thread_func(void* p_arg) int bind_cpu_id = *(int *)p_arg; printf([%d] : setting cpu affinity for thread(%d@%d) to cpu(%d) , gettid(), gettid(), getpid(), bind_cpu_id); bind_thread_to_cpu(bind_cpu_id); print_running_cpu(); while(1) // 模拟工作负载 long loop = 4000000000; while(loop--) sleep(0); print_running_cpu(); return NULL;int main(int argc, char *argv[]) int cpu_id_1 = 1; int cpu_id_2 = 2; pthread_t thr_id_1, thr_id_2; // 创建并绑定线程1到CPU 1 pthread_create(thr_id_1, NULL, thread_func, cpu_id_1); sleep(1); // 确保线程1已经绑定 // 创建并绑定线程2到CPU 2 pthread_create(thr_id_2, NULL, thread_func, cpu_id_2); // 等待线程结束 pthread_join(thr_id_1, NULL); pthread_join(thr_id_2, NULL);","categories":["0.平台","Linux","内核"]},{"title":"ARM和X86","path":"/2024/07/24/0-平台-平台相关-ARM和X86/","content":"ARM 是基于 RISC 的产品，而 PC 的代言人是 x86，基于 CISC。ARM、x86 之争，其实就是 RISC 和 CISC 之争。 RISC 和 CISC计算机科学中两种主要理念之间的分歧：简化程序员的工作简化微处理器的工作。 要想使用计算机执行任何高效的操作，操作系统及其执行的程序需要与中央处理器（CPU）以及其他硬件（如内存、存储器和网卡）进行交互。CPU 发挥着在操作系统（和上面运行的程序）与这些硬件之间进行调解的作用。为了简化程序员的工作，CPU 有一组预定义的操作和计算，称为指令集或 ISA（指令集架构）。操作系统及其执行的程序（均由程序员编写）依赖这些指令来执行低层功能，例如： CPU 与硬件（内存、存储器、网络等）之间的交互 算术函数（加法、减法等） 数据操作（二进制移位等）。 CISC最初的 x86 CPU 拥有（并且现在仍然拥有）非常丰富的指令集。一条指令可以完成整个计算（如乘法）或将一块数据直接从内存中的一个位置移动到另一个位置。这听起来没什么大不了，但在内存中的不同位置之间进行乘法计算和移动数据确实需要在低层执行大量指令。对于 x86 计算机，这一系列复杂的操作可以在一个周期内完成。具有这种类型指令集的处理单元被称为复杂指令集计算机（CISC，Complex Instruction Set Computer）。 然而，CISC 计算机中的指令如此强大，也意味着它需要更多的晶体管，从而会占用空间并消耗能量。 RISC精简指令集计算机，Reduced Instruction Set Computer 在现实中，大多数计算机仅使用 CISC 计算机所提供的大量指令中的一小部分。最终，精简指令集计算机（RISC）处理器设计应运而生。RISC 处理器也有一个指令集，但其中每条指令仅代表一个能耗较低的简单操作。这就使汇编语言程序员的工作变得更加复杂，但却简化了处理器的工作。利用 RISC 处理器和先进的 RISC 计算机，可以通过运行多条指令或通过将复杂工作推给编译器（而不是 CPU 内核）来执行复杂操作。 其中离不开一些权衡与取舍。x86 CPU 往往具有非常快的计算能力，并且在编程和指令数量方面会更加清晰或简单，但它的代价，就是更大、更昂贵且具有大量晶体管的芯片。ARM 处理器对于某些类型的操作而言可能非常快，但单个指令的重复循环可能会减慢它的速度，这是因为操作更为复杂，并且定义和执行操作的更多工作被推给了编程（和程序员），而不是指令集。 此外，鉴于以上差异，我们可能难以计算其 MIPS（每秒百万条指令，一种对计算机原始处理能力的常用度量），因为不同类型的处理器在执行同一活动时需要用到不同的指令集。 ARM 与 x86 的能耗RISC 架构源自为小型计算机或微型计算机（最终成为 PC）制造性能更好、外形更小的芯片的需求。于是，这就引出了第二个基本设计问题：究竟是侧重于芯片性能（处理速度或时钟速度）还是能源消耗（功耗）。 由于 ARM 处理器集成到了 SoC 上，因此长期以来围绕的焦点就是整体资源管理，包括低能耗和更低的热量生成。例如，ARM 架构（如 ARMv8）往往没有简单的散热系统（手机上没有风扇）。而另一方面，x86 CPU 倾向于支持高端处理速度，而不是以低功耗为目标。 虽然两种 CPU 设计都具有高性能（ARM 和 x86 阵营都有速度在世界上数一数二的超级计算机），但 ARM 设计往往侧重于更小巧的外形、电池使用时间、尺寸、免除散热要求和成本（这也许是最重要的）等方面。这就是 ARM 处理器主导智能手机、平板电脑甚至树莓派系统等小型电子产品和移动设备的原因。而 x86 架构在服务器、PC 甚至笔记本电脑中更为常见，因为这些领域需要实时的速度和灵活性，并且对散热和尺寸的限制较少。","categories":["0.平台","平台相关"]},{"title":"Docker Pull超时","path":"/2024/07/24/0-平台-Docker-Docker-Pull超时/","content":"修改镜像仓库地址 sudo vim /etc/docker/daemon.json 选一个加速地址即可 registry-mirrors: [ https://mirror.ccs.tencentyun.com, https://do.nark.eu.org, https://dc.j8.work, https://docker.m.daocloud.io, https://dockerproxy.com, https://docker.mirrors.ustc.edu.cn, https://docker.nju.edu.cn, https://registry.docker-cn.com\t] 修改完成后重新加载 sudo systemctl daemon-reloadsudo systemctl restart docker 测试是否配置成功 sudo docker info","categories":["0.平台","Docker"]},{"title":"QProcess类来执行系统命令并获取输出","path":"/2024/07/23/1-语言-Qt-QProcess类来执行系统命令并获取输出/","content":"使用 QProcess 的 start 方法启动命令。通过 waitForStarted 等待命令启动完成，使用 connect 连接 readyReadStandardOutput 信号到一个槽函数，当有新的标准输出时，会触发该槽函数读取并输出结果。最后使用 waitForFinished(-1)等待命令执行完毕，-1 表示无限等待，直到命令完成。 #include QCoreApplication#include QProcessint main(int argc, char *argv[]) QCoreApplication a(argc, argv); QProcess process; // 以异步方式启动命令，这里以执行dir命令为例（Windows 系统） process.start(cmd, QStringList() /c dir); // 等待命令启动完成 if (!process.waitForStarted()) qDebug() Command failed to start!; return 1; // 连接信号与槽，以便在有新的标准输出时进行处理 QObject::connect(process, QProcess::readyReadStandardOutput, []() QString output = process.readAllStandardOutput(); qDebug() output; ); // 等待命令执行完成 if (!process.waitForFinished(-1)) qDebug() Command execution timed out!; return 1; return a.exec(); 上述代码是在 Windows 系统下执行 dir 命令的示例。如果你在 Linux 系统下，需要将启动命令修改为相应的终端命令，例如 process.start(“bash”, QStringList() “-c” “ls”); 来执行 ls 命令列出目录内容。 QProcess 中 start 和 write 中写的命令，末尾要加上 （Linux 直接加 ，Windows 加 \\r ），否则命令可能无法执行。并且，write 方法不可与 waitForFinished 一起使用，否则会阻塞 30 秒，waitForFinished 只能用 start 一起使用。 如果要执行带有管道“|”等特殊字符的命令，可能需要一些额外的处理。例如，在 Linux 系统下执行 ps -ef | grep’mem’这样的命令，需要按照如下方式启动进程： QString cmd = ps -ef | grepmem;process.start(bash, QStringList() -c cmd); 这样就可以通过 QProcess 获取执行系统命令的输出结果了。Qt 无法直接识别管道“|”和重定向“”命令，需要在启动程序或终端时作为参数传入这些命令，而不是启动后再输入。","categories":["1.语言","Qt"]},{"title":"Portainer","path":"/2024/07/22/0-平台-Docker-Portainer/","content":"Portainer can be used to manage Docker containers through a web interface. CE 社区版本部署 首先，创建 Portainer Server 用于存储其数据库的卷： docker volume create portainer_data version: 3services: portainer: image: portainer/portainer-ce:latest container_name: portainer ports: - 9094:9000 volumes: - portainer_data:/data - /var/run/docker.sock:/var/run/docker.sock restart: unless-stoppedvolumes: portainer_data: 现在安装已完成，访问以下网址登录 Portainer Server 实例： https://localhost:9094","categories":["0.平台","Docker"]},{"title":"0个部署服务器的功能","path":"/2024/07/22/0-平台-服务器-0个部署服务器的功能/","content":"完成对 Alist 的启动与关闭 完成对 photoprism 的启动与关闭 完成 frp 的穿透 完成 devtunnel 的穿透 完成更新 devtunnel 并获取最新的 IP 地址导入 photo.html 完成仓库的更新 【√】80 端口：TVBOX 订阅 9050：本地Hexo 博客部署端口 博客Hexo部署 【√】9080：FRP 映射对接端口 内网穿透方案 【√】9081：FRP 的 DashBoard内网穿透方案 【√】9082: Docker 管理面板 Portainer 【√】9083 Qexo 管理页面 Qexo本地部署 【√】9084：Alist 映射端口 Alist网盘搭建 【√】9085：PDF 处理工具搭建到云服务器 【√】9086：Daily Hot 每日热点9071API 【√】9090：SSH 端口 【√】9091：3D 打印机的 Mainsail 端口 3D打印机环境配置 9092：OK3568portainer 9093： PhotoprismPhotoprism照片备份方案 9094：Photoprism_ 我的 9082：NAS 映射端口 NAS相关配置 9090：1Panel 服务器运维管理面板 9091: GitServer","categories":["0.平台","服务器"]},{"title":"内核模块","path":"/2024/07/22/0-平台-Linux-内核-内核模块/","content":"内核模块是一段可以动态加载到内核中的代码，这使得开发人员可以扩展内核的功能而无需重启系统或重编译整个内核。 内核模块的编译编写内核模块代码一个简单的内核模块通常包括初始化和清理函数。以下是一个基本的“Hello, World”内核模块示例： #include linux/init.h#include linux/module.h#include linux/kernel.hMODULE_LICENSE(GPL);MODULE_AUTHOR(Your Name);MODULE_DESCRIPTION(A Simple Hello World Module);static int __init hello_init(void) printk(KERN_INFO Hello, World! ); return 0; // 返回0表示成功static void __exit hello_exit(void) printk(KERN_INFO Goodbye, World! );module_init(hello_init);module_exit(hello_exit); 创建 Makefile要编译内核模块，需要一个 Makefile。以下是一个简单的 Makefile 示例： obj-m += hello.oall: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modulesclean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean obj-m：定义需要编译的模块对象文件。 -C libmodules$(shell uname -r)build：指定内核源代码树的路径。 M$(PWD)：指定当前目录。 编译模块在模块源代码所在目录中运行以下命令进行编译： make 这个命令会在当前目录下生成一个 .ko 文件，这是编译后的内核模块。 内核模块的安装加载模块编译完成后，可以使用 insmod 命令将模块加载到内核中： sudo insmod hello.ko insmod：加载指定的内核模块。 hello.ko：编译生成的内核模块文件。 验证模块是否加载可以通过 lsmod 命令检查模块是否已成功加载： lsmod | grep hello 也可以通过 dmesg 查看内核日志，检查模块的输出： dmesg | tail 卸载模块如果需要卸载模块，可以使用 rmmod 命令： sudo rmmod hello 内核模块的调试使用 printk 调试在开发内核模块时，最常用的调试方法是使用 printk 函数输出调试信息。这些信息会被记录在内核日志中，可以通过 dmesg 查看。 printk(KERN_INFO This is a debug message with value: %d , value); KERN_INFO 是一个日志级别，表示信息性消息。还有其他日志级别，如 KERN_DEBUG、KERN_ERR 等。 使用 dmesg 命令可以查看内核输出的调试信息。 使用调试器使用调试器（如 gdb）调试内核模块是可能的，但需要一些额外的设置。典型的步骤包括： 启动一个虚拟机或使用内核调试器（KGDB）来远程调试运行中的内核。 在内核配置中启用 CONFIG_DEBUG_INFO 以生成调试符号。 使用 gdb 连接到内核，加载符号文件，然后进行调试。 使用内核日志和跟踪工具除了 printk，还可以使用以下工具进行调试： ftrace：Linux 内核的内建跟踪工具，用于跟踪函数调用和性能分析。 perf：强大的性能监视和分析工具，适用于分析内核模块的性能问题。 KprobeseBPF：用于动态插入调试探针，以监视内核行为。 常见问题排查编译错误确保内核头文件与运行的内核版本匹配。 检查 Makefile 中的路径是否正确，尤其是内核源代码目录。 模块加载失败检查 dmesg 输出是否有错误信息。 确保模块使用的符号在内核中可用。 检查模块的许可证是否与内核兼容（如 GPL）。 调试信息不足使用更高的 printk 日志级别（如 KERN_DEBUG）来捕获更多详细信息。 使用 dmesg -n 调整 printk 的日志级别过滤器。","categories":["0.平台","Linux","内核"]},{"title":"文件系统","path":"/2024/07/22/0-平台-平台相关-文件系统/","content":"文件系统存储限制FAT32 文件系统对单个文件的大小有限制。具体来说，FAT32 文件系统支持的最大文件大小是 4 GB (gigabytes)。这是因为 FAT32 使用 32 位字段来记录文件大小，而 32 位的最大值是 4,294,967,295 字节，约等于 4 GB。 如果需要存储超过 4 GB 的单个文件，可以考虑使用其他文件系统，例如： exFAT：支持非常大的文件，适用于大容量存储设备，例如 USB 闪存驱动器和 SD 卡。 NTFS：Windows 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 ext4：Linux 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 文件系统选择建议 USB 闪存驱动器SD 卡：如果需要兼容性且文件大于 4 GB，建议使用 exFAT。 Windows 系统硬盘：NTFS 是默认且最适合的选择。 Linux 系统硬盘：ext4 是默认且最适合的选择。 转换文件系统的步骤如果需要将 FAT32 文件系统转换为 exFAT 或 NTFS，可以通过以下步骤实现： 将 FAT32 转换为 exFAT（在 Windows 中） 备份数据：转换文件系统会格式化驱动器，因此请先备份所有数据。 格式化为 exFAT： 打开“文件资源管理器”。 右键点击需要转换的驱动器。 选择“格式化”。 在文件系统选项中选择“exFAT”。 点击“开始”。 将 FAT32 转换为 NTFS（在 Windows 中） 备份数据：虽然有非破坏性转换方法，但仍建议备份数据以防万一。 非破坏性转换（不会丢失数据）：convert X: fs:ntfs。其中 X: 是要转换的驱动器号。","categories":["0.平台","平台相关"]},{"title":"关于U盘被占用无法弹出","path":"/2024/07/22/0-平台-Windows-U盘被占用无法弹出/","content":"按下 Win+R 键，这会打开一个名为 运行 的对话框，其中允许你快速启动程序或打开系统工具。 在 运行 对话框中，输入 eventvwr.msc，然后按 回车 键。这一操作会打开 事件查看器，一个 Windows 内置工具，用于记录系统、应用和安全事件的日志。 打开事件查看器后，左侧的导航窗格中会显示 **事件查看器(本地)**，点击它以展开包含不同日志类别的菜单。 在展开的菜单中，找到并点击 Windows 日志，然后选择 系统。这部分记录与 Windows 操作系统本身有关的事件，例如硬件故障、驱动程序问题或系统服务故障。 浏览系统日志，寻找最近的 警告 事件，特别是源于 Kernel-PnP 的警告。这类警告通常是与设备驱动程序或插拔硬件相关的事件。它们可能与 USB 设备、打印机或其他外部硬件相关。 找到该警告后，双击它，系统将弹出一个新窗口，显示警告的详细信息。在此窗口中，查找 进程 ID 为 **** 的应用程序已停止删除或弹出设备 的信息，这里用“****”表示具体的进程 ID。 记下这个进程 ID，因为它可以帮助你进一步调查相关应用程序或设备，并对可能存在的问题进行更深入的分析或修复。例如，如果发现某个设备在不断出现警告，可能需要更新或重新安装其驱动程序。","categories":["0.平台","Windows"]},{"title":"ETF小助手功能更新","path":"/2024/07/19/3-软件-0杂项-ETF小助手功能更新/","content":"管理功能，添加删除 计算功能，今日估值，持仓成本， 显示功能，显示当前估值和成本比较 历史记录，显示历史曲线 10 日20 日等均线 【×】北向资金实现方式 API 实时涨跌https://fundgz.1234567.com.cn/js/007345.js?v=20200908175500 数字为基金代码，rt 为时间戳， /*****功能：获取基金实时信息，天天基金数据接口：http://fundgz.1234567.com.cn/js/基金代码.js传入：基金代码输出：基金实时信息 -- dictfundcode -- 基金代码name -- 基金名称jzrqv -- 上一交易日dwjz -- 基金净值（截止上一交易日）gsz -- 估算净值（实时）gszzl -- 估算涨幅（实时）gztime -- 更新时间（实时）******/jsonpgz( fundcode: 007345, name: : 富国科技创新灵活配置混合, jzrq: 2020-09-17, dwjz: 1.9441, gsz: 1.9717, gszzl: 1.42, gztime: 2020-09-18 15:00); 基金净值数据http://fund.eastmoney.com/f10/F10DataApi.aspx?type=lsjzcode=007345page=1per=49sdate=2020-09-01edate=2020-09-18 基金列表http://fund.eastmoney.com/js/fundcode_search.js 返回数据 var r = [ [ 000001, HXCZHH, 华夏成长混合, 混合型, HUAXIACHENGZHANGHUNHE ], [ 000002, HXCZHH, 华夏成长混合(后端), 混合型, HUAXIACHENGZHANGHUNHE ]] 基金详情http://fund.eastmoney.com/pingzhongdata/007345.js?v=20200908175500 基金公司列表http://fund.eastmoney.com/js/jjjz_gs.js 返回数据 var gs= op: [ [ 80163340, 安信基金 ], [ 80036782, 招商基金 ] ] 基金增幅排名http://fund.eastmoney.com/data/rankhandler.aspx?op=phdt=kfft=gprs=gs=0sc=zzfst=descsd=2016-03-29ed=2017-03-29qdii=tabSubtype=,,,,,pi=1pn=50dx=1v=0.6370068000914493 ft： fund type 类型 所有-all 股票型-gp 混合型-hh 债券型-zq 指数型-zs 保本型-bb QDII-qdii LOF-lof 当前基金净值http://fundgz.1234567.com.cn/js/[基金代码].js?rt=[时间戳] （其中时间戳 rt 用于避免浏览器缓存数据，可省略）。 例如，http://fundgz.1234567.com.cn/js/001186.js，返回的结果类似于：jsonpgz({“fundcode”:”001186”,”name”:”富国文体健康股票”,”jzrq”:”2022-09-20”,”dwjz”:”1.9300”,”gsz”:”1.9187”,”gszzl”:”-0.58”,”gztime”:”2022-09-21 15:00”});。这是一个文本数据，需要进一步处理。可以使用 Python 中的 requests、re、json 等库进行处理，将文本转化为字典格式，以便提取所需信息，代码示例如下： import requestsimport jsonimport redef realtmfundinfo(fundcode): fund_id = fundcode real_time_url = fhttp://fundgz.1234567.com.cn/js/fund_id.js org_content = requests.get(real_time_url) fund_info = org_content.text fund_info = re.findall(r\\.+\\, fund_info) fund_info = json.loads(fund_info[0]) return fund_infofund_info = realtmfundinfo(001186)print(fund_info) 历史基金净值http://fund.eastmoney.com/pingzhongdata/[基金代码].js?v=[时间戳] （时间戳 v 可省略）。 例如，http://fund.eastmoney.com/pingzhongdata/001186.js，可获取该基金的申购费率、持仓股票、历史单位净值、历史累计净值等多个信息。返回基金的净值日期（date）、单位净值（nav）、累计净值(cumnav)、净值回报率(equityReturn)、每份派送金(unitMoney).处理返回的文本数据的 Python 代码示例如下： import requestsimport jsonimport reimport pandas as pddef htrfundinfo(fundcode): fund_id = fundcode history_tmurl = fhttp://fund.eastmoney.com/pingzhongdata/fund_id.js org_content = requests.get(history_tmurl) fund_info = org_content.text # 提取单位净值 temp_nav = re.findall(rdata_networthtrend\\s=\\s(\\(\\.+\\\\));\\/\\*累计净值走势\\*\\/, fund_info)[0] temp_nav = json.loads(temp_nav) temp_nav = pd.DataFrame(temp_nav) temp_nav.rename(columns=x:date,y:nav, inplace=True) n = len(temp_nav[date]) for i in range(n): temp_nav[date][i] = time.strftime(%y-%m-%d, time.localtime(temp_nav[date][i]/1000.)) temp_nav = temp_nav.set_index(date) # 提取累计净值 temp_cumnav = re.findall(rdata_acworthtrend\\s=\\s(\\(.+\\));\\/\\*累计收益率走势\\*\\/, fund_info)[0] temp_cumnav = eval(temp_cumnav) return temp_navfund_nav = htrfundinfo(001186)print(fund_nav)","categories":["3.软件","0杂项"]},{"title":"重装系统无法识别硬盘","path":"/2024/07/18/0-平台-Windows-重装系统无法识别硬盘/","content":"Win11 重新安装系统时，由于缺少 RST 驱动，导致进入 PE 后无法识别到硬盘，需要安装该驱动，搜索 intel_rst_technology 并下载， https://global-download.acer.com/GDFiles/Driver/IRST/IRST_Intel_19.2.0.1003_W11x64_A.zip?acerid=637907037961464459Step1=Step2=Step3=SF314-71OS=ALLLC=enBC=ACERSC=PA_6 之后在重装系统时选择 load driver 加载该驱动即可识别硬盘","categories":["0.平台","Windows"]},{"title":"网络设备驱动的中断处理","path":"/2024/07/18/0-平台-Linux-驱动-网络设备驱动的中断处理/","content":"devm_request_irq 和 request_threaded_irq 都是用于注册中断处理程序的函数，但它们的用途和管理机制有所不同。以下是这两个函数的详细说明及如何使用它们。 devm_request_irqdevm_request_irq 是用于注册中断处理程序的设备管理函数，它的主要优点是自动管理资源。当设备驱动程序被卸载时，系统会自动释放中断资源，避免资源泄漏。 函数原型： int devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t handler, unsigned long irqflags, const char *devname, void *dev_id); 参数说明：dev：指向设备结构体的指针。irq：要申请的中断号。handler：中断处理程序的函数指针。irqflags：中断标志，如 IRQF_SHARED 等。devname：设备名称，用于显示和调试。dev_id：设备标识，一般为设备结构体的指针，用于区分共享中断。 request_threaded_irqrequest_threaded_irq 是用于注册中断处理程序和线程化中断处理程序的函数。线程化中断处理程序运行在中断上下文之外，因此可以执行更复杂的操作而不会阻塞中断处理。 函数原型： int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id); 参数说明： irq：要申请的中断号。 handler：顶半部中断处理程序的函数指针。可以为 NULL。 thread_fn：线程化中断处理程序的函数指针。不能为 NULL。 irqflags：中断标志，如 IRQF_SHARED 等。 devname：设备名称，用于显示和调试。 dev_id：设备标识，一般为设备结构体的指针，用于区分共享中断。","categories":["0.平台","Linux","驱动"]},{"title":"栈和队列","path":"/2024/07/17/1-语言-语言结构-栈和队列/","content":"栈（stack）栈是限定仅在表的一端进行插入或删除操作的线性表。我们把允许插入和删除操作的一端称为栈顶（top），另一端称为栈底（bottom）。不含任何数据元素的栈称为空栈。栈又称为“后进先出（Last In First Out，简称 LIFO）的线性表”，简称为 LIFO 结构。 栈的插入操作，称为进栈入栈压栈。栈的删除操作，称为出栈弹栈。 栈的顺序存储结构及实现 定义 typedef int data_t; //定义栈中数据元素的数据类型typedef struct\tdate_t *data; //用指针指向栈的存储空间\tint maxlen; //当前栈的最大元素个数\tint top; //指向栈顶位置（数组下标）的变量seqstack_t; //顺序栈类型定义 创建栈 seqstack_t *CreateEmptyStack(int max_len)\tseqstack_t *stack;\tstack = (seqstack_t *)malloc(sizeof(seqstack_t));\tstack-data = (data_t *)malloc(sizeof(data_t)*max_len);\tstack-top = -1;\tstack-max_len = max_len;\treturn stack; 摧毁一个栈 void DestroyStack(seqstack_t *stack)\tif(stack != NULL) if(stack-data != NULL) free(stack-data); free(stack); 清空一个栈 void ClearStack(seqstack_t *stack)\tif(stack != NULL) stack-top = -1; 判断栈是否为空 int EmptyStack(seqstack_t *stack)\tif(stack == NULL) return -1;\treturn(stack-top == -1 ? 1 : 0); 5、判断栈是否为满 int FullStack(seqstack_t *stack)\tif(stack == NULL) return -1;\treturn(stack-top == (stack-max_len - 1) ? 1 : 0); d6、进栈 int PushStack(seqstack_t *stack ,data_t x)\tif(FullStack(stack)) return -1;\telse stack-top++; stack-data[stack-top] = x; return 0; 7、出栈 int PopStack(seqstack_t *stack,data_t *x)\tif(EmptySqstack(stack)) return -1;\telse *x = stack-data[stack-top]; stack-top--; return 0; 8、取栈顶元素 int GetTop(seqstack_t *stack,data_t *x)\tif(EmptyStack(stack)) return -1;\telse *x = stack-data[stack-top];\treturn 0; 栈的链式存储结构及实现若是栈中元素的数目变化范围较大或不清楚栈元素的数目，就应该考虑使用链式存储结构。人们将用链式存储结构表示的栈称作”链栈”。链栈通常用一个无头结点的单链表表示。插入操作和删除操作均在链表头部进行，链表尾部就是栈底，栈顶指针就是头指针。 定义 typedef int data_t;typedef struct node_t\tdata_t data; //数据域\tstruct node_t *next; //链接指针域linkstack_t; //链栈类型定义 创建空栈： linkstack_t *CreateLinkstack()\tlinkstack_t *top;\ttop = (linkstack_t *)malloc(sizeof(linkstack_t));\ttop-next = NULL;\treturn top; 判断是否为空栈： int EmptyStack(linkstack_t *top)\treturn (top-next == NULL ? 1 : 0); 入栈 void PushStack(linkstack_t *top,data_t x)\tlinkstack_t *p;\tp = (linkstack_t *)malloc(sizeof(linkstack_t));\tp-data = x;\tp-next = top-next;\ttop-next = p;\treturn; 出栈 int PopStack(linkstack_t stack,data_t *x)\tif(stack-next == NULL || stack == NULL) return -1;\tlinkstack_t p;\tp = stack-next;\tstack-next = p-next;\tif(x != NULL) *x = p-data;\tfree(p);\treturn 0; linkstack#include stdio.h#include stdlib.h#include linkstack.hlinkstack_t *CreateEmptyLinkstack()\tlinkstack_t *s;\ts = (linkstack_t *)malloc(sizeof(linkstack_t));\ts-next = NULL;\treturn s;void DestroyLinkstack(linkstack_t *stack)\tif (stack) /* clear the stack linked list */ ClearLinkstack(stack); /* free the stack header */ free(stack);\tint EmptyLinkstack(linkstack_t *stack)\tif (stack) return ((NULL == stack-next) ? 1 : 0); else return -1;\tvoid ClearLinkstack(linkstack_t *stack)\tlinkstack_t *node; /* node to be removed */\tif (!stack) return;\twhile ( NULL != stack-next ) /* disconnect the one to be removed */ node = stack-next; stack-next = node-next; free(node); return;int PushStack(linkstack_t *stack, data_t x)\tlinkstack_t *node; /* node to be inserted */\tif (!stack) return -1;\tnode = (linkstack_t *)malloc(sizeof(linkstack_t));\tif (NULL == node) return -1; node-data = x;\t/* insert from the head of the link list * its cheaper to push from the head of the single-linked * list. */\tnode-next = stack-next;\tstack-next = node;\treturn 0;int PopStack(linkstack_t *stack, data_t *data)\tlinkstack_t *node; /* node to be removed */ if (!stack) return -1;\tif (!(stack-next)) return -1; /* stack is empty */\t/* pop from the head of the list */\tnode = stack-next;\tstack-next = node-next;\tif (data) *data = node-data; /* now we can free the node safely */\tfree(node); return 0;int GetTop(linkstack_t *stack, data_t *data)\tif (!stack) return -1;\tif (!(stack-next)) return -1; /* stack is empty */ if (data) *data = stack-next-data; return 0;void\tVisitStack(linkstack_t *stack)\tlinkstack_t *node; /* node to be iterated */ if (!stack) return;\t/* print from the base to the top */\tprintf(stack = );\tif (stack-next) /* list is not empty */ node = stack-next; while (NULL != node) printf(%d,, node-data); node = node-next; printf(\\b ); else printf( ); 栈的应用递归递归：函数在自身的函数体内直接或间接地调用自身。 示例：递归法求斐波那契数列 int Fbi(int i) if(i2) return i==0?0:1;\treturn Fbi(i-1)+Fbi(i-2);int main() int i;\tfor(i=0;i40;i++) printf(%d\\t,Fbi(i));\tprintf( );\treturn 0; 要实现递归，必要的两个条件是递归出口和递归逻辑。在示例程序中，if(i2)就是递归出口，而 Fbi(i-1)+Fbi(i-2)就是递归逻辑。对比递归代码和非递归（迭代）代码，我们可以看出递归和迭代的区别：迭代使用循环结构，而递归使用分支结构 在某些程序中，递归能使得程序结构简洁清晰，容易理解。但是大量的调用递归函数会建立许多该函数的副本，需要大量的内存存储空间。而迭代法则无需大量的存储空间。 要想实现递归，我们需要明白递归的过程本质上是函数返回顺序是其调用顺序的逆序，即：先行调用的函数会在后面获得返回值。这种先行存储数据，并在之后逆序恢复得到数据的过程，显然很符合栈这种数据结构。因此，编译器使用栈来实现函数的递归。 在调用阶段，对于每层递归，函数的局部变量、参数、返回地址都被压入栈中，再去调用下次递归。在返回阶段，依次弹出位于栈顶的函数，获得计算结果。这也是为什么需要“递归出口”的原因，递归出口可以看做是从压栈到弹栈的状态转变因素。 后缀（逆波兰）表示法中缀表达式，即运算符（此处特指算数运算符）在操作数中间。9+(3-1)*3+10/2 后缀表示法，也称为逆波兰表示法，即运算符在两个操作数之后出现 9 3 1 - 3 * + 10 2 / + 后缀表达式的算法规则：从左到右遍历表达式，若遇到数字则进栈，遇到运算符则弹出栈顶两个元素进行运算，计算结果再次压栈，最后计算得到的结果就是最终结果。 我们以 9 3 1 - 3 * + 10 2 / + 进行讲解（操作数入栈） 初始化一个空栈，此栈用于对要计算的操作数的进出及存储。 9、3、1 都是数字，因此依次入栈 接下来是-，是符号，弹出栈顶两个元素作为操作数，注意先弹出的元素在符号右侧，后弹出的元素在符号左侧，即 3 - 1，得到计算结果 2，将 2 压栈。 数字 3 进栈 后面是 *，栈顶两个元素弹栈进行运算 2 * 3，得到结果 6，再压入栈 后面是+，栈顶两个元素弹栈进行运算 9 + 6，得到结果 15，再压入栈 数字 10 和 2 进栈 后面是，栈顶两个元素弹栈进行运算 10 2，得到结果 5，再压入栈 最后一个符号是+，栈顶两个元素弹栈进行运算 15 + 5，得到结果 20 最终结果是 20，栈变为空，结束运算。 中缀表达式转化为后缀表达式的规则：从左到右遍历中缀表达式的每个数字和符号，若是数字就输出，即成为后缀表达式的一部分；若是符号则判断其与栈顶符号的优先级，是右括号或优先级低于或等于栈顶符号的则栈顶元素依次出栈并输出，直至遇到一个比其优先级低的运算符为止，并将当前符号进栈，一直到最终输出后缀表达式为止。 我们以 9+(3-1)*3+10/2------9 3 1 - 3 * + 10 2 / + 进行讲解（运算符入栈） 初始化一个空栈，用于对符号进出栈使用。 第一个数字是 9，输出 9。后面的符号+入栈。 第三个字符是（，依然是符号，因其是左括号还未配对，故进栈。 第四个字符是数字 3，输出，此时表达式为 9 3，接着符号-进栈。 接下来是数字 1，输出，此时表达式为 9 3 1，后面是符号），此时我们需要把（之前的所有元素都出栈，直至输出（为止。此时总的表达式是 9 3 1 -。 紧接着是符号 *，因为此时的栈顶符号是+，优先级低于 *，因此不输出，* 进栈。紧接着是数字 3，输出，总表达式为 9 3 1 – 3. 之后是符号+，此时栈顶元素是 *，比+优先级高，因此栈中元素出栈并输出（因为没有比+更低优先级的符号，所以全部出栈），总输出表达式为 9 3 1 – 3 * +。然后将这个符号+进栈。 紧接着输出数字 10，总表达式为 9 3 1 – 3 * + 10。之后是符号 /，所以 / 进栈。 最后一个数字为 2，此时总表达式为 9 3 1 – 3 * + 10 2。 因已到最后，所以将栈中符号全部出栈。最终获得的后缀表达式为 9 3 1 – 3 * + 10 2 / +。 队列队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。队列是一种先进先出（First In First Out）的线性表，简称 FIFO。允许插入操作的一端称为队尾，允许删除操作的一端称为队头。 队列作为特殊的线性表，有顺序队列和链式队列两种形式。 队列的顺序存储结构及实现如果我们要建立元素个数为 n 的队列，则需要建立一个数组长度不小于 n 的数组，数组下标为 0 的为队头，当最大下标的为队尾。若有元素要入队，则只需将其存储在第 n+1 个位置即可。而若想出队，则删除了下标为 0 的元素后，所有在其后的元素都需要向前移动一格，即保持下标为 0 的元素为队头。但这样做显然浪费了大量时间。 解决该问题的方法就是不再限制下标为 0 的元素为队头，每次出队后，队头自动变成当前数组下标最小的元素即可。这样就无需所有元素向前移动。但是，若如此做，则会造成大量的已出队的元素的存储空间浪费。而且，若此时入队元素已经大于 n，则我们需要更大的存储空间才行，但队头位置有大量空间未利用，空间浪费严重。 解决以上问题的方法就是如果后面满了，则我们就从头开始，也就是将队列做成头尾相接的循环。我们把这种头尾相接的顺序存储结构的队列称为循环队列。 在循环队列中，当队列为空时，有 front=rear，而当所有队列空间全占满时，也有 front=rear。为了区别这两种情况，规定循环队列最多只能有 MaxSize-1 个队列元素，当循环队列中只剩下一个空存储单元时，队列就已经满了。因此，队列判空的条件时 front=rear，而队列判满的条件时 front=（rear+1）%MaxSize。 队头指针 front，指向队头元素的位置的前一个位置。即指向预留的位置； 队尾指针 rear，指向队尾元素的位置； 入队： rear = (rear + 1) % N (maxsize)，然后元素放入队尾 rear 所指向的位置； 出队： front = (front + 1) % N，然后取出队头指针 front 所指向的元素； 队空： front == rear; 队满： (rear + 1) % N == front, N 为数组的元素个数； 为了区别空队和满队，满队元素个数比数组元素个数少一个。 这样，我们就需要两个指示其队头（front）和队尾（rear）的下标变量。 #define N 64 //队列中数据元素的数据类型typedef int data_t;typedef struct\tdata_t data[N]; //用数组作为队列的储存空间\tint front,rear; //指示队头位置和队尾位置的指针sequeue_t; 当 (rear+1)%QueueSize==front 时，此时队尾的下个位置就是队头，则该队列为满队列。注意 rear 的位置不是队尾元素的位置，而是队尾元素的下一个位置，即当队列满时，队列中还有一个空闲存储空间，但我们规定该状态下就是满队列。 那么，定义好队列的的队头和队尾位置，我们来考虑怎样计算队列长度。 当 rearfront 时，表示队尾在队头右边，此时队列长度为 rear-front； 当 rearfront 时，表示队尾在队友左边，此时计算队列长度应分成两部分，即 rear 一部分，QueueSize-front 一部分，总体长度为 rear-front+QueueSize。 通用计算队列长度的公式是 length=(rear-front+QueueSize)%QueueSize 创建空队列 sequeue_t *CreateEmptySequeue()\tsequeue_t *queue;\tqueue = (sequeue_t *)malloc(sizeof(sequeue_t));\tif (NULL == queue) return NULL;\tqueue-front = queue-rear = 0;\treturn queue; 摧毁一个队列 voidDestroySequeue(sequeue_t *queue)\tif (NULL != queue) free(queue); 判断一个队列是否为空 intEmptySequeue(sequeue_t *queue)\tif (NULL == queue) return-1;\treturn (queue-front == queue-rear ? 1 : 0); 判断一个队列是否为满 intFullSequeue(sequeue_t *queue)\tif (NULL == queue) return-1;\treturn ((queue-rear + 1) % N == queue-front ? 1 : 0); 清空一个队列 voidClearSequeue(sequeue_t *queue)\tif (NULL == queue) return;\tqueue-front = queue-rear = 0;\treturn; 入队 intEnQueue(sequeue_t *queue, data_t x)\tif (NULL == queue) return - 1;\tif (1 == FullSequeue(queue)) return-1; /* full */\tqueue-rear = (queue-rear + 1) % N;\tqueue-data[queue-rear] = x;\treturn 0; 出队 intDeQueue(sequeue_t *queue, data_t *x)\tif (NULL == queue) return-1;\tif (1 == EmptySequeue(queue)) return-1; /* empty */\tqueue-front = (queue-front + 1) % N;\tif (NULL != x) *x = queue-data[queue-front]; return 0; 队列的链式存储结构及实现队列的链式存储结构本质上是从单链表演化而来的。将单链表改造成链式队列，如果将头结点做为队头，最后一个节点做为队尾，则该队列的出队操作方便，而入队操作较慢；反之，如果将头结点做为队尾，最后一个节点做为队头，则该队列的入队操作方便，而出队操作较慢。那么，能否将单链表稍加改进，使得该链式队列的入队操作和出队操作一样方便呢？ 答案是可以的，只需要改进头结点。将“头结点存储一个 next 指针”改为“头结点存储两个指针 front 和 rear”，front 指针指向队头，rear 指针指向队尾。这样我们进行出队入队操作时，只需要访问这两个指针就能快速地找到队头队尾。 队列的链式存储结构定义，将单链表的头结点稍加改造 typedef int data_t;typedef struct node_t//定义单链表\tdata_t data;\tstruct node_t *next;linknode_t, *linklist_t;typedef struct//定义链式队列 linklist_t front, rear;linkqueue_t; 创建空队列 linkqueue_t *CreateEmptyLinkqueue()\tlinkqueue_t *lp = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif(lp == NULL) return;\tlp-front = lp-rear = (linknode_t *)malloc(sizeof(linknode_t));\tif(lp-front == NULL) return;\tlp-front-next = NULL;\treturn lp; 摧毁一个链队列 void DestroyLinkqueue(linkqueue_t *queue)\tif(queue != NULL) ClearLinkqueue(queue); free(queue); 清空一个链队列 void ClearLinkqueue(linkqueue_t *queue)\tlinknode_t *qnode;\twhile(q-front) qnode = queue-front; queue-front= qnode-next; free(qnode); queue-rear = NULL; 判定链式队列是否为空 由于单链表的属性，链式队列几乎不会出现“队列已满”的情况，因此不考虑判定链式队列是否已满的操作。判定链式队列是否为空，只需要判定队列的 front 指针是否为空即可。 int EmptyLinkqueue(linkqueue_t *queue)\tif(queue == NULL) return-1;\treturn(queue-front == queue-rear ? 1 : 0); 队列的链式存储结构——入队操作 入队操作其实就是在链表尾部插入节点。（需要判定插入时链表是否为空，如果链表为空，则 front 和 rear 两个指针都需要操作）新来的数据节点附在当前 rear 节点之后，并将 rear 节点指向该节点即可。 int EnQueue(linkqueue_t *queue,data_t x)\tlinknode_t *node_new;\tif(queue == NULL) return-1;\tnode_new = (linknode_t *)malloc(sizeof(linknode_t));\tif(node_new == NULL) return-1;\tnode_new-data = x;\tnode_new-next = NULL;\tif(queue-front-next == NULL) queue-front-next = queue-rear = node_new; else queue-rear-next = node_new; queue-rear = node_new; return 0; 队列的链式存储结构——出队操作 出队操作就是将链表的头结点的后继节点出队，并将其之后的节点设置为头结点的后继节点。若链表除头结点外仅剩一个元素，则需将 rear 指向头结点。 int DeQueue(linkqueue_t *queue,data_t *x)\tlinknode_t *node_remove;\tif(queue == NULL || queue-front-next == NULL) return-1;\tnode_remove = queue-front-next;\tqueue-front-next = node_remove-next;\tif(x != NULL) *x = node_remove-data;\tfree(node_remove);\treturn 0; 链式队列代码typedef int data_t;typedef struct node_t\tdata_t data;\tstruct node_t *next; linknode_t, *linklist_t;typedef struct\tlinklist_t front, rear; linkqueue_t;linkqueue_t *CreateEmptyLinkqueue()//创建空队列\tlinkqueue_t *queue;\tqueue = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif (NULL == queue) perror(Create Empty LinkQueue Error); return NULL; queue-rear = queue-front = NULL;\treturn queue;int ClearLinkqueue(linkqueue_t *queue)//清空队列\tlinknode_t *node_remove;\tnode_remove = queue-front;\twhile (NULL != node_remove) queue-front = queue-front-next; free (node_remove); node_remove = queue-front; queue-rear = NULL;\treturn OK;int DestroyLinkqueue(linkqueue_t *queue)//销毁队列\tif (queue) ClearLinkqueue(queue); free(queue); return OK; else printf(DestroyLinkqueue Error ); return ERROR;\tint EmptyLinkqueue(linkqueue_t *queue)//判定队列是否为空\tif (!queue) printf(EmptyLinkqueue Error ); return -1; return queue-front == NULL ? OK : ERROR;int EnQueue(linkqueue_t *queue, data_t x)//入队\tlinknode_t *node_new;\tif (!queue) printf(EnQueue Error ); return ERROR; node_new = (linknode_t *)malloc(sizeof(linknode_t));\tnode_new-data = x;\tnode_new-next = NULL;\tif(EmptyLinkqueue(queue)==OK) queue-front = queue-rear = node_new; else queue-rear-next = node_new; queue-rear = node_new; return OK;int DeQueue(linkqueue_t *queue, data_t *x)//出队\tlinknode_t *node_remove;\tif(!queue) printf(DeQueue Error ); return ERROR; if(EmptyLinkqueue(queue)==OK) printf(queue is Empty ); return ERROR; node_remove = queue-front;\tqueue-front = node_remove-next;\tif (NULL == queue-front) queue-rear = NULL;\tif(x) *x = node_remove-data; free(node_remove);\treturn OK;int VisitQueue(linkqueue_t *queue)//遍历队列\tlinknode_t *node;\tprintf(aueue = );\tnode = queue-front;\tif (NULL == node) printf( ); return OK; while (NULL != node) printf(%d,, node-data); node = node-next; printf(\\b );\treturn OK; 球钟问题球钟是一个利用球的移动来记录时间的简单装置。它有三个可以容纳若干个球的指示器：分钟指示器，五分钟指示器，小时指示器。若分钟指示器中有 2 个球，五分钟指示器中有 6 个球，小时指示器中有 5 个球，则时间为 5:32。每过一分钟，球钟就会从球队列的队首取出一个球放入分钟指示器，分钟指示器最多可容纳 4 个球。当放入第五个球时，在分钟指示器的 4 个球就会按照他们被放入时的相反顺序加入球队列的队尾。而第五个球就会进入五分钟指示器。按此类推，五分钟指示器最多可放 11 个球，小时指示器最多可放 11 个球。 当小时指示器放入第 12 个球时，原来的 11 个球按照他们被放入时的相反顺序加入球队列的队尾，然后第 12 个球也回到队尾。这时，三个指示器均为空，回到初始状态，从而形成一个循环。因此，该球钟表示时间的范围是从 0：00 到 11：59。 思考：球钟需要多少个球，才能实现计时范围为 0：00 到 11：59？ 提示：使用 3 个栈来分别表示 1min 指示器、5min 指示器和 1h 指示器，使用一个队列来存储小球 #include stdio.h#include stdlib.h#define MAXSIZE_1 5#define MAXSIZE_2 12#define MAXSIZE_ball 28#define OK 1#define ERROR 0typedef int data_t;typedef struct //一分钟的顺序栈\tdata_t data[MAXSIZE_1];\tint top;one_min_t;typedef struct //五分钟与一小时的顺序栈\tdata_t data[MAXSIZE_2];\tint top;five_min_t;typedef struct //所有小球的存放队列\tdata_t data[MAXSIZE_ball];\tint front;\tint rear;SqQueue;int main() int i; data_t *the_ball; one_min_t *one_min; five_min_t *five_min,*one_hour; SqQueue *ball; one_min = CreateEmptyStack(); five_min = CreateEmptyStack(); one_hour = CreateEmptyStack(); ball = CreateEmptyQueue(); for(i = 0; i MAXSIZE_ball; i++) EnQueue(ball,i+1); DeQueue(ball,the_ball); if(0==PushStack(one_min,the_ball)) for(i=0; i4; i++) PopStack(one_min,the_ball); EnQueue(ball,the_ball); return 0;int PushStack(SqStack *s,data_t e)//压栈\tif(s-top==MAXSIZE-1) printf(Stack is Full ); return ERROR; s-top++;\ts-data[s-top]=e;\treturn OK;int PopStack(SqStack *s,data_t *e)//弹栈\tif(s-top==-1) printf(Stack is Empty ); return ERROR; *e=s-data[s-top];\ts-top--;\treturn OK;SqStack* CreateEmptyStack()//创建栈 SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) printf(CreateEmptyStack Error ); exit(0); stack-top=-1; return stack;int EmptyStack(SqStack *s)//判断栈是否是空栈 return -1==s-top?OK:ERROR;int FullStack(SqStack *s)//判断栈是否是满栈 return MAXSIZE-1==s-top?OK:ERROR;int ClearStack(SqStack *s)//清空栈内元素 s-top=-1; return OK;SqQueue *CreateEmptyQueue()//创建队列\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL) printf(CreateEmptyQueue Error ); return NULL; sq-front=0;\tsq-rear=0;\treturn sq;int EmptyQueue(SqQueue *Q)//判断队是否为空\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if(Q-rear==Q-front) return OK;\telse return ERROR;int FullQueue(SqQueue *Q)//判断队是否已满\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if((Q-rear+1)%MAXSIZE==Q-front) return OK;\telse return ERROR;int EnQueue(SqQueue *Q,data_t e)//元素e入队\tif(FullQueue(Q)==OK) printf(Queue is Full ); return ERROR; Q-data[Q-rear]=e;\tQ-rear=(Q-rear+1)%MAXSIZE;\treturn OK;int DeQueue(SqQueue *Q,data_t *e)//元素出队，出队元素存储在e中\tif(EmptyQueue(Q)==OK) printf(Queue is Empty ); return ERROR; *e=Q-data[Q-front];\tQ-front=(Q-front+1)%MAXSIZE;\treturn OK; #includestdio.h#includestdlib.h#define ONEMIN 5#define FIVEMIN 12#define ONEHOUR 12#define BALLQUE 28#define OK 1#define ERROR 0typedef int data_t;typedef struct\tdata_t *data;\tint top;//栈顶\tint maxlen;SqStack;typedef struct\tdata_t *data;\tint front;//队头位置\tint rear;//队尾位置\tint maxlen;SqQueue;/**************************队列部分**************************/SqQueue *CreateEmptyQueue(int length)//创建队列\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL) printf(CreateEmptyQueue Error ); return NULL; sq-data = (data_t*)malloc(sizeof(data_t)*length);\tsq-maxlen=length;\tsq-front=0;\tsq-rear=0;\treturn sq;int EmptyQueue(SqQueue *Q)//判断队是否为空\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if(Q-rear==Q-front) return OK;\telse return ERROR;int FullQueue(SqQueue *Q)//判断队是否已满\tif(Q==NULL) printf(EmptyQueue Error ); return -1; if((Q-rear+1)%Q-maxlen==Q-front) return OK;\telse return ERROR;int EnQueue(SqQueue *Q,data_t e)\tif(FullQueue(Q)==OK) printf(Queue is Full ); return ERROR; Q-data[Q-rear]=e;\tQ-rear=(Q-rear+1)%Q-maxlen;\treturn OK;int DeQueue(SqQueue *Q,data_t *e)\tif(EmptyQueue(Q)==OK) printf(Queue is Empty ); return ERROR; *e=Q-data[Q-front];\tQ-front=(Q-front+1)%Q-maxlen;\treturn OK;/**************************栈部分**************************/int PushStack(SqStack *s,data_t e)//压栈\tif(s-top==s-maxlen-1) printf(Stack is Full ); return ERROR; s-top++;\ts-data[s-top]=e;\treturn OK;data_t PopStack(SqStack *s)//弹栈\tif(s-top==-1) printf(Stack is Empty ); return ERROR; data_t e=s-data[s-top];\ts-top--;\treturn e;SqStack* CreateEmptyStack(int length)//创建栈 SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) printf(CreateEmptyStack Error ); exit(0); stack-data = (data_t*)malloc(sizeof(data_t)*length);\tstack-maxlen=length; stack-top=-1; return stack;int EmptyStack(SqStack *s)//判断栈是否是空栈 return -1==s-top?OK:ERROR;int FullStack(SqStack *s)//判断栈是否是满栈 return s-maxlen-1==s-top?OK:ERROR;void ShowTime(SqStack *one_min,SqStack *five_min,SqStack *one_hour)//计算球钟内3个栈的小球所代表的时间并打印\tint hour,minute;\tminute=(one_min-top+1)+(five_min-top+1)*5;\thour=one_hour-top+1;\tprintf(time: %d:%d ,hour,minute);int main()\tSqStack *one_min = CreateEmptyStack(ONEMIN);//1分钟栈\tSqStack *five_min = CreateEmptyStack(FIVEMIN);//5分钟栈\tSqStack *one_hour = CreateEmptyStack(ONEHOUR);//1小时栈\tSqQueue *ballque = CreateEmptyQueue(BALLQUE);//球队列\tint i;\tdata_t data;\tfor(i=1;i=ballque-maxlen-1;i++) EnQueue(ballque,i); while(1) DeQueue(ballque,data);//出队一个球 PushStack(one_min,data);//压入1分钟栈中 if(FullStack(one_min)==OK)//如果1分钟栈已满 for(i=0;ione_min-maxlen-1;i++)//弹出4个元素到队列中 EnQueue(ballque,PopStack(one_min)); PushStack(five_min,PopStack(one_min));//第5个压入5分钟栈 if(FullStack(five_min)==OK)//如果5分钟栈已满 for(i=0;ifive_min-maxlen-1;i++)//弹出11个元素到队列中 EnQueue(ballque,PopStack(five_min)); PushStack(one_hour,PopStack(five_min));//第12个元素压入1小时栈 if(FullStack(one_hour)==OK)//如果1小时栈已满 for(i=0;ione_hour-maxlen;i++)//弹出12个元素到队列中 EnQueue(ballque,PopStack(one_hour)); ShowTime(one_min,five_min,one_hour);//打印时间 sleep(1);//延时1秒 return 0; 两个栈实现队列队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead，分别完成在队列尾部插入元素和在队列头部删除节点的功能。 template typename Tclass CQueuepublic: CQueue(void); ~CQueue(void); void appendTail(const T element); T deleteHead();private: stackT stack1; stackT stack2;; 思路：栈是先进后出，而队列是先进先出的，而要用栈实现队列的话，两步操作如下： 进队列：第一个栈 stack1 专门用来压入数据； 出队列：要把队列头部元素输出，而这个头部会在 stack1 中的底部，因此我们需要利用辅助栈 stack2 ，把 stack1 元素依次压入 stack2，这样原来 stack1 中的底部元素变成 stack2 的栈顶，而这就是队列的 head，将之输出即可。 上面分析是针对 stack2 空的情况，若 stack2 非空，则要继续把 stack2 中元素依次 pop 出来。 //进队列template typename T void CQueueT::appendTail(const T element) stack1.push(element);//出队列template typename T T CQueueT::deleteHead() if (stack2.empty()) //若stack2是空的，则把stack1的元素copy过来 while (!stack1.empty()) T data = stack1.top(); stack1.pop(); stack2.push(data); if (stack2.empty()) throw new exception(queue is empty); //取stack2栈顶元素，即队列的head T head = stack2.top(); stack2.pop(); return head; 数组实现队列 //数组实现队列template typename Tclass CArrayQueuepublic: CArrayQueue(void); ~CArrayQueue(void); void appendTail(const T element); T deleteHead();private: const static int nSize; T Array[10]; int nHead; int nTail;;template typename T const int CArrayQueueT:: nSize = 10;template typename T CArrayQueueT::CArrayQueue(void) this-nHead = 0; this-nTail = -1;template typename T CArrayQueueT::~CArrayQueue(void) this-nHead = 0; this-nTail = -1;//进队列template typename T void CArrayQueueT::appendTail(const T element) if (nTail - nHead = nSize) throw new exception(Queue is full!); Array[(++nTail) % nSize] = element; if (nHead / nSize 0 ) nTail -= nSize; nHead -= nSize; //出队列template typename T T CArrayQueueT::deleteHead() T Head = Array[nHead++]; return Head;","categories":["1.语言","语言结构"]},{"title":"多线程","path":"/2024/07/16/1-语言-C语言-多线程-多线程/","content":"传统多任务操作系统中一个可以独立调度的任务（或称之为顺序执行流）是一个进程。每个程序加载到内存后只可以唯一地对应创建一个顺序执行流，即传统意义的进程。 每个进程的全部系统资源是私有的，如虚拟地址空间，文件描述符和信号处理等等。使用多进程实现多任务应用时存在如下问题： 任务切换，即进程间上下文切换，系统开销比较大。（虚拟地址空间以及 task_struct 都需要切换） 多任务之间的协作比较麻烦，涉及进程间通讯。（因为不同的进程工作在不同的地址空间） 所以，为了提高系统的性能，许多操作系统规范里引入了轻量级进程的概念，也被称为线程。 通常线程指的是共享相同地址空间的多个任务。线程最大的特点就是在同一个进程中创建的线程共享该进程的地址空间；但一个线程仍用 task_struct 来描述，线程和进程都参与统一的调度。所以，多线程的好处便体现出来： 大大提高了任务切换的效率；因为各线程共享进程的地址空间，任务切换时只要切换 task_struct 即可； 线程间通信比较方便；因为在同一块地址空间，数据共享； 当然，共享地址空间也会成为线程的缺点，因为共享地址空间，如果其中一个线程出现错误（比如段错误），整个线程组都会崩掉！ Linux 之所以称呼其线程为 LWP( Light Weight Process )，因为从内核实现的角度来说，它并没有为线程单独创建一个结构，而是继承了很多进程的设计： 继承了进程的结构体定义 task_struct ； 没有专门定义线程 ID，复用了 PID； 更没有为线程定义特别的调度算法，而是沿用了原来对 task_struct 的调度算法。 线程已经替代原来的进程称为调度的实际最小单位。 原来的进程概念可以看成是多个线程的容器，称之为线程组；即一个进程就是所有相关的线程构成的一个线程组。传统的进程等价于单线程进程。 每个线程组都有自己的标识符 tgid (数据类型为 pid_t )，其值等于该进程(线程组)中的第一个线程(group_leader)的 PID。 线程根据其调度者的不同可以被分为两大类：用户级线程（User-Level Threads, ULT）和核心级线程（Kernel-Level Threads, KLT）。这两种线程在程序并发执行时，各自解决的问题和实现的机制存在显著差异。 用户级线程主要关注上下文切换（Context Switching）的问题。上下文切换是指 CPU 在不同线程之间切换执行状态的过程。用户级线程的调度算法和调度过程完全由用户在应用层决定，这意味着在运行时不需要内核的直接支持。这种设计的优点在于提高了线程的创建和切换速度，因为用户空间的操作通常比内核空间的操作要快。 我们常用的就是这类用户级线程，其中 POSIX 标准提供了一套完整的用户级线程接口。以下是一些基本的线程操作相关函数： 基本线程操作相关函数 线程的创建与结束 线程的互斥与同步 使用信号量控制线程 线程的基本属性配置 互斥与同步机制基本函数 函数 说明 pthread_create() 创建新的线程并开始执行相关线程的函数，运行结束后线程退出。 pthread_exit() 用于结束当前线程的函数，区别于 exit()（结束整个进程）。 pthread_join() 阻塞当前线程，等待指定线程结束。如果目标线程已结束，则立即返回，返回值 0 代表成功。 pthread_cancel() 向指定线程发送终止信号，成功返回 0，但并不保证线程立即停止。 pthread_testcancel() 在没有取消点的代码段中创建一个取消点，以允许响应取消请求。 pthread_setcancelstate() 设置当前线程对取消信号的反应，以控制线程何时响应取消请求。 pthread_setcanceltype() 设置取消状态，决定线程是否立即取消或等到下一个取消点再取消。 pthread_setcancel() 修改当前线程的取消状态。 互斥锁基本函数 函数 说明 pthread_mutex_init() 初始化互斥锁以保护共享资源。 pthread_mutex_lock() 尝试锁定互斥锁，如果互斥锁已被其他线程锁定，则会阻塞等待。 pthread_mutex_trylock() 试图非阻塞地锁定互斥锁，如果锁定失败则立即返回错误。 pthread_mutex_unlock() 释放互斥锁，以允许其他线程访问被保护的共享资源。 pthread_mutex_destroy() 销毁互斥锁，释放与该互斥锁相关的资源。 信号量控制线程的基本函数（默认无名信号量） 函数 说明 sem_init() 初始化一个定位在指定地址的匿名信号量。 sem_wait() 使信号量减 1。如果信号量当前值为 0，则进入阻塞状态。 sem_trywait() 尝试非阻塞地减少信号量值，如果信号量当前值为 0 则返回错误。 sem_post() 增加信号量的值，确保原子操作。 sem_getvalue() 将当前信号量的值存储到指定的整数变量中。 sem_destroy() 销毁指定的匿名信号量，释放相关资源。 线程属性配置相关函数 函数 说明 pthread_attr_init() 初始化线程属性对象，准备设置线程的属性。 pthread_attr_destroy() 清除已设置的线程属性，释放资源。 pthread_attr_setscope() 设置线程的可见性属性，可以是系统范围或者进程范围。 pthread_attr_setschedparam() 设置线程的调度参数，如线程优先级。 pthread_attr_getschedparam() 获取当前线程的调度参数。 线程创建int pthread_create(pthread_t *thread,const pthread_attr_t *attr,void *(* routine)(void *), void *arg)# 函数参数# thread ：创建的线程ID# attr ：指定线程的属性，NULL表示使用缺省属性# routine ：线程执行的函数# arg ：传递给线程执行的函数的参数 创建成功返回 0，否则返回-1 routine 是回调函数（callback），函数类型由内核来决定，这里将地址传给内核； 函数并不是线程创建了就会执行，而是只有当其被调度到 cpu 上时才会被执行 arg 是线程执行函数的参数，，使用时需要先进行类型转换，才能使用； 如果 arg 参数不止一个，我们可以将其放入到结构体中，传入结构体指针； 线程管理和进程中的 exit() 、wait()一样，这里 pthread_join 与 pthread_exit 是工作在两个线程之中； #以阻塞的方式等待thread指定的线程结束。pthread_join(thread, [线程返回的参数]) pthread_exit([线程返回的参数]) 同步和互斥临界资源：某些资源来说，其在同一时间只能被一段机器指令序列所占用。这些一次只能被一段指令序列所占用的资源就是所谓的临界资源。 临界区：对于临界资源的访问，必须是互斥进行。也就是当临界资源被一个指令序列占用时，另一个需要访问相同临界资源的指令序列就不能被执行。指令序列不能执行的实际意思就是其所在的进程线程会被阻塞。所以我们定义程序内访问临界资源的代码序列被称为临界区。 互斥：是指同事只允许一个访问者对临界资源进行访问，具有唯一性和排它性。但互斥无法限制访问这个对资源的访问顺序，即访问时无序的。 同步：是指在互斥的基础上，通过其他机制实现访问者对资源的有序访问。 线程间互斥引入互斥(mutual exlusion)锁的目的是用来保证共享数据的完整性。 互斥锁主要用来保护临界资源。每个临界资源都有一个互斥锁来保护，任何时刻最多只能有一个线程能访问该资源；线程必须先获得互斥锁才能访问临界资源，访问完资源后释放该锁。如果无法获得锁，线程会阻塞直到获得锁为止； 通常，我们在临界区前上锁，临界区后解锁； //初始化互斥锁int pthread_mutex_init (pthread_mutex_t *mutex, pthread_mutexattr_t *attr )//申请互斥锁int pthread_mutex_lock(pthread_mutex_t *mutex)//释放互斥锁int pthread_mutex_unlock(pthread_mutex_t *mutex) 同步同步(synchronization) 指的是多个任务（线程）按照约定的顺序相互配合完成一件事情；线程间同步——P V 操作 信号量代表某一类资源，其值表示系统中该资源当前可用的数量。信号量是一个受保护的变量，只能通过三种操作来访问： 初始化 //初始化信号量int sem_int (sem_t *sem,int pshared,unsigned int value)函数参数sem：初始化的信号量pshared：信号量共享的范围（0：线程间使用 非0 ：进程间使用）value ：信号量初值函数返回值成功：0出错：-1 P 操作（申请资源）P（S）含义如下： int sem_wait (sem_t *sem) //P 操作函数参数 sem：信号量函数返回值成功：0出错：-1if (信号量的值大于 0)\t请资源的任务继续运行；\t信号量的值 减一；else\t请资源的任务阻塞； V 操作（释放资源）V（S）含义如下： int sem_post(sem_t *sem) //V 操作函数参数sem：信号量函数返回值成功：0出错：-1if (没有任务在等待该资源)\t信号量的值 加一；else\t唤醒第一个等待的任务，让其继续运行； 条件变量简介条件变量是一种用于线程间同步的机制，主要依赖于两个基本动作：一个线程在等待“条件变量的条件成立”而阻塞，而另一个线程则通过发出信号来通知条件已成立。这种机制有效地防止了线程间的竞争（Race Condition），确保了多线程环境下的安全性与效率。 条件变量的相关名词 中文名: 多线程的条件变量 外文名: pthread_cond_wait 主要动作 动作一: 等待条件变量 动作二: 发出条件成立信号 目的为了防止线程之间的竞争，确保线程正确地处理共享资源。 创建与注销条件变量创建条件变量有两种方式：静态和动态。静态方式通过 PTHREAD_COND_INITIALIZER 初始化，如下所示： pthread_cond_t cond = PTHREAD_COND_INITIALIZER; 动态方式则是通过调用 pthread_cond_init() 函数，API 定义如下： int pthread_cond_init(pthread_cond_t *cond, pthread_condattr_t *cond_attr); 尽管 POSIX 标准中为条件变量定义了属性（cond_attr），但在某些实现中，比如 LinuxThreads，并没有实际支持，因此在这里常常将 cond_attr 设置为 NULL，并被相应地忽略。 要注销条件变量，可以调用 pthread_cond_destroy()。需要注意的是，只有在没有其他线程等待该条件变量的情况下才能成功注销，若有线程正在等待，则会返回错误代码 EBUSY。因为在 Linux 实现的条件变量中并没有分配特定的资源，注销操作只需确保没有等待的线程。API 定义如下： int pthread_cond_destroy(pthread_cond_t *cond); 等待与激发条件在多线程编程中，有两种方式来等待条件： 条件等待: 使用 pthread_cond_wait() 计时等待: 使用 pthread_cond_timedwait() 其中，计时等待方式如果在给定时间段内条件未满足，则返回 ETIMEDOUT，并结束等待。计时的绝对时间格式与 time() 函数相同，时间 0 表示从 1970 年 1 月 1 日 00 时 00 分 0 秒开始。 必须与一个互斥锁（mutex）配合使用，防止多个线程同时请求 pthread_cond_wait()（或 pthread_cond_timedwait()），造成竞争条件。在调用 pthread_cond_wait() 前，mutex 必须由当前线程加锁（pthread_mutex_lock()），并在条件满足且离开 pthread_cond_wait() 前重新加锁。确保在阻塞时，线程处于解锁状态，以避免死锁情形的发生。 激发条件信号有两种形式： pthread_cond_signal(): 激活一个等待该条件的线程，优先激活在等待队列中按先后顺序排在前的线程。 pthread_cond_broadcast(): 激活所有等待线程，这在需要同时通知多个消费者时非常有用。 代码实例下面是一个典型的多线程应用示例，采用了条件变量和互斥锁。这个示例展示了如何实现一个简单的生产者-消费者模型，其中消费者可以是多个线程。 #include stdio.h#include stdlib.h#include pthread.h#include unistd.hstatic pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;struct node int n_number; struct node *n_next; *head = NULL;/* 清理处理函数 */static void cleanup_handler(void* arg) printf(Clean up handler of the second thread. ); free(arg); (void)pthread_mutex_unlock(mtx);/* 线程函数 */static void* thread_func(void* arg) struct node *p = NULL; pthread_cleanup_push(cleanup_handler, p); pthread_mutex_lock(mtx); // Protects the waiting period of wait while (1) while (head == NULL) pthread_cond_wait(cond, mtx); // 一旦被唤醒，获取节点 p = head; head = head-n_next; printf(Got %d from front of queue , p-n_number); free(p); pthread_mutex_unlock(mtx); // 释放互斥锁 pthread_cleanup_pop(0); return 0;int main(void) pthread_t tid; int i; struct node *p; pthread_create(tid, NULL, thread_func, NULL); for (i = 0; i 10; i++) p = (struct node *)malloc(sizeof(struct node)); p-n_number = i; pthread_mutex_lock(mtx); // 对临界资源加锁 p-n_next = head; head = p; pthread_cond_signal(cond); pthread_mutex_unlock(mtx); // 解锁 sleep(1); printf(Thread 1 wants to end the cancel thread 2. ); pthread_cancel(tid); // 取消线程 pthread_join(tid, NULL); printf(All done -- exiting ); return 0; 注释解析 这个示例展示了如何通过互斥锁保护共享资源 head，并使用条件变量 cond 在有新数据时唤醒消费者线程。 对于线程的取消，使用了 pthread_cancel()，实现了外部线程的安全退出。 清理处理函数确保在资源释放时正确解锁，以防止程序在意外情况下陷入死锁状态。","categories":["1.语言","C语言","多线程"]},{"title":"Qt线程管理QThread","path":"/2024/07/16/1-语言-Qt-Qt线程管理QThread/","content":"QThread 会通知你触发了一个信号当线程 started()和 finished()时，或者使用 isFinished()和 isRunning()来查询线程的状态。 可以通过调用 exit()或 quit()来停止线程。在极端情况下，你可能要强行 terminate()一个执行线程。但是，这样做是危险的。请阅读文档查看 terminate()和 setTerminationEnabled()的详细信息。 可以通过连接 finished()信号到 QObject::deleteLater()释放运行刚刚结束的线程对象。 使用 wait()来阻塞调用的线程，直到其他线程执行完毕（或者直到指定的时间过去）。 QThread 中还提供了静态的、平台独立的休眠功能：sleep()、msleep()、usleep()允许秒，毫秒和微秒来区分。 注意：一般情况下，wait()和 sleep()函数应该不需要，因为 Qt 是一个事件驱动型框架。而不是 wait()，关心监听信号 finished()。取代 sleep()，可以考虑使用 QTimer。 静态函数 currentThreadId()和 currentThread()返回标识当前正在执行的线程。前者返回该线程的平台特定的 ID，后者返回一个线程指针。 要设置线程的名称，可以在启动线程之前调用 setObjectName()。如果不调用 setObjectName()，线程的名称将是线程对象的运行时类型（上例中“WorkerThread”，因为这是 QThread 子类的类名）。 和界面有关的函数不能通过 QThread 的方式执行 movetothreadWorker 槽中的代码将在一个单独的线程中执行，然而，可以将（来自任何对象、在任何线程中）任何信号与该槽自由地连接，在不同的线程里连接信号和槽也是安全的，这要归功于一个叫排队的连接机制（queued connections）。 class Worker : public QObject\tQ_OBJECT\tpublic slots: void doWork(const QString parameter) // ... emit resultReady(result); signals: void resultReady(const QString result);;class Controller : public QObject\tQ_OBJECT\tQThread workerThread;\tpublic: Controller() Worker *worker = new Worker; worker-moveToThread(workerThread); connect(workerThread, QThread::finished, worker, QObject::deleteLater); connect(this, Controller::operate, worker, Worker::doWork); connect(worker, Worker::resultReady, this, Controller::handleResults); workerThread.start(); ~Controller() workerThread.quit(); workerThread.wait(); public slots: void handleResults(const QString );\tsignals: void operate(const QString );; 实例化 QThread是子类化 QThread 中并重新实现 run 函数，在 run()返回后线程就会退出，在线程中将不会有任何的事件循环运行除非调用 exec()。 当子类化 QThread 时，构造函数在旧线程中执行，然而 run()在新线程中执行。 一个线程实例位于实例化它的旧线程中，而非调用 run()的新线程中，这意味着所有线程的排队槽将在旧线程中执行。因此，开发人员希望在新线程调用槽必须 通过 movetothread 实现，新槽不应直接在子类化 QThread 中来实现。 class WorkerThread : public QThread\tQ_OBJECT\tvoid run() Q_DECL_OVERRIDE QString result; emit resultReady(result); signals: void resultReady(const QString s);;void MyObject::startWorkInAThread()\tWorkerThread *workerThread = new WorkerThread(this);\tconnect(workerThread, WorkerThread::resultReady, this, MyObject::handleResults);\tconnect(workerThread, WorkerThread::finished, workerThread, QObject::deleteLater);\tworkerThread-start();","categories":["1.语言","Qt"]},{"title":"Photoprism照片备份方案","path":"/2024/07/13/0-平台-服务器-工具-Photoprism照片备份方案/","content":"Alist 网盘+Photoprism PhotoPrism 配置官方脚本选择下载官方脚本 #Linux wget https://dl.photoprism.app/docker/docker-compose.yml#Windowscurl.exe -o docker-compose.yml https://dl.photoprism.app/docker/windows/docker-compose.yml 自定义进行自定义选项，默认需要依赖数据库 可以选择不依赖数据库镜像 自定义访问端口 自定义相册文件映射地址，其中photoprismimport 为需要导入的照片地址，photoprismoriginals 为已经导入的照片地址 services: photoprism: image: photoprism/photoprism:latest restart: unless-stopped stop_grace_period: 10s security_opt: - seccomp:unconfined - apparmor:unconfined ports: - 5246:2342 environment: PHOTOPRISM_ADMIN_USER: username # admin login username PHOTOPRISM_ADMIN_PASSWORD: password # initial admin password (8-72 characters) PHOTOPRISM_AUTH_MODE: password # authentication mode (public, password) PHOTOPRISM_SITE_URL: http://localhost:2342/ # server URL in the format http(s)://domain.name(:port)/(path) PHOTOPRISM_DISABLE_TLS: false # disables HTTPS/TLS even if the site URL starts with https:// and a certificate is available PHOTOPRISM_DEFAULT_TLS: true # defaults to a self-signed HTTPS/TLS certificate if no other certificate is available PHOTOPRISM_ORIGINALS_LIMIT: 5000 # file size limit for originals in MB (increase for high-res video) PHOTOPRISM_HTTP_COMPRESSION: gzip # improves transfer speed and bandwidth utilization (none or gzip) PHOTOPRISM_DEBUG: false # run in debug mode, shows additional log messages PHOTOPRISM_READONLY: false # do not modify originals folder; disables import, upload, and delete PHOTOPRISM_EXPERIMENTAL: false # enables experimental features PHOTOPRISM_DISABLE_CHOWN: false # disables updating storage permissions via chmod and chown on startup PHOTOPRISM_DISABLE_WEBDAV: false # disables built-in WebDAV server PHOTOPRISM_DISABLE_SETTINGS: false # disables settings UI and API PHOTOPRISM_DISABLE_TENSORFLOW: false # disables all features depending on TensorFlow PHOTOPRISM_DISABLE_FACES: false # disables face detection and recognition (requires TensorFlow) PHOTOPRISM_DISABLE_CLASSIFICATION: false # disables image classification (requires TensorFlow) PHOTOPRISM_DISABLE_VECTORS: false # disables vector graphics support PHOTOPRISM_DISABLE_RAW: false # disables indexing and conversion of RAW images PHOTOPRISM_RAW_PRESETS: false # enables applying user presets when converting RAW images (reduces performance) PHOTOPRISM_SIDECAR_YAML: true # creates YAML sidecar files to back up picture metadata PHOTOPRISM_BACKUP_ALBUMS: true # creates YAML files to back up album metadata PHOTOPRISM_BACKUP_DATABASE: true # creates regular backups based on the configured schedule PHOTOPRISM_BACKUP_SCHEDULE: daily # backup SCHEDULE in cron format (e.g. 0 12 * * * for daily at noon) or at a random time (daily, weekly) PHOTOPRISM_INDEX_SCHEDULE: # indexing SCHEDULE in cron format (e.g. @every 3h for every 3 hours; to disable) PHOTOPRISM_AUTO_INDEX: 300 # delay before automatically indexing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_AUTO_IMPORT: -1 # delay before automatically importing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_DETECT_NSFW: false # automatically flags photos as private that MAY be offensive (requires TensorFlow) PHOTOPRISM_UPLOAD_NSFW: true # allows uploads that MAY be offensive (no effect without TensorFlow) PHOTOPRISM_SITE_CAPTION: AI-Powered Photos App PHOTOPRISM_SITE_DESCRIPTION: # meta site description PHOTOPRISM_SITE_AUTHOR: # meta site author ## Video Transcoding (https://docs.photoprism.app/getting-started/advanced/transcoding/): # PHOTOPRISM_FFMPEG_ENCODER: software # H.264/AVC encoder (software, intel, nvidia, apple, raspberry, or vaapi) # PHOTOPRISM_FFMPEG_SIZE: 1920 # video size limit in pixels (720-7680) (default: 3840) # PHOTOPRISM_FFMPEG_BITRATE: 32 # video bitrate limit in Mbit/s (default: 50) working_dir: /photoprism # do not change or remove ## Storage Folders: use / not \\ as separator, ~ is a shortcut for C:/user/username, . for the current directory volumes: # C:/user/username/folder:/photoprism/folder # example # - ~/Pictures:/photoprism/originals # original media files (photos and videos) # - D:/example/family:/photoprism/originals/family # *additional* media folders can be mounted like this # - E:/:/photoprism/import # *optional* base folder from which files can be imported to originals - E:/01.照片/:/photoprism/import - ./original/:/photoprism/originals - ./videos:/photoprism/originals/videos - ./storage:/photoprism/storage # *writable* storage folder for cache, database, and sidecar files (never remove)## Create named volumes, advanced users may remove this if they mount a regular host folder## for the database or use SQLite instead (never remove otherwise)volumes: database: driver: local AlistAlist网盘搭建 通过 mount 命令映射 webdav 到本地后 修改 docker-compose 中的配置文件，将导入和存储位置修改为 webdav 所在位置 启动相册","categories":["0.平台","服务器","工具"]},{"title":"简单工厂模式","path":"/2024/07/13/1-语言-语言结构-简单工厂模式/","content":"简单工厂模式简单工厂模式是一种创建对象的设计模式，它通过一个工厂类来实例化不同类型的对象，而不需要在客户端代码中直接指定具体的类。这种模式的主要优点在于它将对象的创建与使用分离，使得代码更加灵活和可维护。 工作原理在简单工厂模式中，工厂类负责创建对象。客户端只需调用工厂类的方法，传入所需的参数，工厂类会根据这些参数返回相应的对象。例如，假设我们有一个图形绘制应用程序，用户可以选择绘制不同的形状，如圆形、正方形和三角形。我们可以创建一个简单工厂类来处理这些形状的实例化。 class ShapeFactory: def create_shape(self, shape_type): if shape_type == circle: return Circle() elif shape_type == square: return Square() elif shape_type == triangle: return Triangle() else: raise ValueError(Unknown shape type) 在这个例子中，ShapeFactory 类根据传入的 shape_type 参数创建不同的形状对象。客户端只需调用 create_shape 方法，而不需要了解具体的形状类的实现细节。 优点 解耦：客户端代码与具体的类解耦，便于后期维护和扩展。例如，如果我们需要添加一个新的形状，只需在工厂类中添加相应的逻辑，而不需要修改客户端代码。 简化对象创建：通过集中管理对象的创建，简化了客户端的代码，使其更加简洁明了。 提高可读性：使用简单工厂模式后，代码的可读性提高，因为客户端不需要关注对象的具体实现，只需关注如何使用工厂类。 缺点 单一职责原则：工厂类可能会变得庞大，承担过多的责任，违反单一职责原则。随着产品种类的增加，工厂类的代码可能会变得复杂。 难以扩展：如果需要支持新的产品类型，可能需要修改工厂类的代码，这在某些情况下可能导致代码的脆弱性。 结论简单工厂模式是一种有效的设计模式，适用于对象创建相对简单的场景。它通过将对象的创建与使用分离，提高了代码的灵活性和可维护性。然而，在使用时也需注意其潜在的缺点，尤其是在产品种类较多的情况下，可能需要考虑其他更复杂的设计模式，如工厂方法模式或抽象工厂模式。","categories":["1.语言","语言结构"]},{"title":"程序加载","path":"/2024/07/12/0-平台-Linux-程序-程序加载/","content":"Linux 中分为用户态和内核态，执行 ELF 文件在用户态的表现就是执行 execve 系统调用，随后陷入内核进行处理。 内核空间内核空间对 execve 的处理其实可以单独用一篇文章去介绍，其中涉及到进程的创建、文件资源的处理以及进程权限的设置等等。我们这里主要关注其中 ELF 处理相关的部分即可，实际上内核可以识别多种类型的可执行文件，ELF 的处理代码主要在 fsbinfmt_elf.c 中的 load_elf_binary 函数中。 对于 ELF 而言，Linux 内核所关心的只有 Program Header 部分，甚至大部分情况下只关心三种类型的 Header，即 PT_LOAD、PT_INTERP 和 PT_GNU_STACK。以 3.18 内核为例，load_elf_binary 主要有下面操作: 对 ELF 文件做一些基本检查，保证 e_phentsize sizeof(struct elf_phdr)并且 e_phnum 的个数在一定范围内； 循环查看每一项 program header，如果有 PT_INTERP 则使用 open_exec 加载进来，并替换原程序的 bprm-buf; 根据 PT_GNU_STACK 段中的 flag 设置栈是否可执行； 使用 flush_old_exec 来更新当前可执行文件的所有引用； 使用 setup_new_exec 设置新的可执行文件在内核中的状态； setup_arg_pages 在栈上设置程序调用参数的内存页； 循环每一项 PT_LOAD 类型的段，elf_map 映射到对应内存页中，初始化 BSS； 如果存在 interpreter，将入口(elf_entry)设置为 interpreter 的函数入口，否则设置为原 ELF 的入口地址； install_exec_creds(bprm)设置进程权限等信息； create_elf_tables 添加需要的信息到程序的栈中，比如 ELF auxiliary vector； 设置 current-mm 对应的字段； 从内核的处理流程上来看，如果是静态链接的程序，实际上内核返回用户空间执行的就是该程序的入口地址代码；如果是动态链接的程序，内核返回用户空间执行的则是 interpreter 的代码，并由其加载实际的 ELF 程序去执行。 为什么要这么做呢？如果把动态链接相关的代码也放到内核中，就会导致内核执行功能过多，内核的理念一直是能不在内核中执行的就不在内核中处理，以避免出现问题时难以更新而且影响系统整体的稳定性。事实上内核中对 ELF 文件结构的支持是相当有限的，只能读取并理解部分的字段。 用户空间内核返回用户空间后，对于静态链接的程序是直接执行，没什么好说的。而对于动态链接的程序，实际是执行 interpreter 的代码。ELF 的 interpreter 作为一个段，自然是编译链接的时候加进去的，因此和编译使用的工具链有关。对于 Linux 系统而言，使用的一般是 GCC 工具链，而 interpreter 的实现，代码就在 glibc 的 elfrtld.c 中。 interpreter 又称为 dynamic linker，以 glibc2.27 为例，它的大致功能如下: 将实际要执行的 ELF 程序中的内存段加载到当前进程空间中； 将动态库的内存段加载到当前进程空间中； 对 ELF 程序和动态库进行重定向操作(relocation)； 调用动态库的初始化函数(如 .preinit_array, .init, .init_array)； 将控制流传递给目标 ELF 程序，让其看起来自己是直接启动的； 其中参与动态加载和重定向所需要的重要部分就是 Program Header Table 中 PT_DYNAMIC 类型的 Segment。前面我们提到在 Section Header 中也有一部分参与动态链接的 section，即.dynamic。我在自己解析动态链接文件的时候发现，实际上 .dynamic section 中的数据，和 PT_DYNAMIC 中的数据指向的是文件中的同一个地方，即这两个 entry 的 s_offset 和 p_offset 是相同。每个元素的类型如下: typedef struct Elf32_Sword\td_tag; /* Dynamic entry type */ union Elf32_Word d_val; /* Integer value */ Elf32_Addr d_ptr; /* Address value */ d_un; Elf32_Dyn; d_tag 表示实际类型，并且 d_un 和 d_tag 相关。同样的，标准中定义了几十个 d_tag 类型，比较常用的几个如下: DT_NULL: 表示 _DYNAMIC 的结尾 DT_NEEDED: d_val 保存了一个到字符串表头的偏移，指定的字符串表示该 ELF 所依赖的动态库名称 DT_STRTAB: d_ptr 指定了地址保存了符号、动态库名称以及其他用到的字符串 DT_STRSZ: 字符串表的大小 DT_SYMTAB: 指定地址保存了符号表 DT_INITDT_FINI: 指定初始化函数和结束函数的地址 DT_RPATH: 指定动态库搜索目录 DT_SONAME: Shared Object Name，指定当前动态库的名字(logical name) 其中有部分的类型可以和 Section 中的 SHT_xxx 类型进行类比，完整的列表可以参考 ELF 标准中的 Book III: Operating System Specific 一节。 在 interpreter 根据 DT_NEEDED 加载完所有需要的动态库后，就实现了完整进程虚拟内存映像的布局。在寻找某个动态符号时，interpreter 会使用广度优先的方式去进行搜索，即先在当前 ELF 符号表中找，然后再从当前 ELF 的 DT_NEEDED 动态库中找，再然后从动态库中的 DT_NEEDED 里查找。 因为动态库本身是位置无关的(PIE)，支持被加载到内存中的随机位置，因此为了程序中用到的符号可以被正确引用，需要对其进行重定向操作，指向对应符号的真实地址。 Interpreter Hack假设现在面对两种场景: 目标环境的可写磁盘直接 mount 为 noexec，无法执行代码 目标环境内核监控任何非系统路径的程序的执行都会直接告警 运用上面学到的 ELF 知识，利用 interpreter 进行执行。示例如下: $ cat hello.c#include stdio.hint main() return puts(hello!);$ gcc hello.c -o hello$ ./hellohello!$ chmod -x hello$ ./hellobash: ./hello: Permission denied$ /lib64/ld-linux-x86-64.so.2 ./hellohello!$ strace /lib64/ld-linux-x86-64.so.2 ./hello 21 | grep execexecve(/lib64/ld-linux-x86-64.so.2, [/lib64/ld-linux-x86-64.so.2, ./hello], 0x7fff1206f208 /* 9 vars */) = 0 /lib64/ld-linux-x86-64.so.2 本身应该是内核调用执行的，但我们这里可以直接进行调用。这样一方面可以在没有执行权限的情况下执行任意代码，另一方面也可以在一定程度上避免内核对 execve 的异常监控。 利用(滥用)interpreter 我们还可以做其他有趣的事情，比如通过修改指定 ELF 文件的 interpreter 为我们自己的可执行文件，可让内核在处理目标 ELF 时将控制器交给我们的 interpreter，这可以通过直接修改字符串表或者使用一些工具如 patchelf 来轻松实现。 对于恶意软件分析的场景，很多安全研究人员看到 ELF 就喜欢用 ldd 去看看有什么依赖库，一般 ldd 脚本实际上是调用系统默认的 ld.so 并通过环境变量来打印信息，不过对于某些 glibc 实现(如 glibc2.27 之前的 ld.so)，会调用 ELF 指定的 interpreter 运行，从而存在非预期命令执行的风险。 加固脱壳与逆向分析比较相关的就是符号表，一个有符号的程序在逆向时基本上和读源码差不多。因此对于想保护应用程序的开发者而言，最简单的防护方法就是去除符号表，一个简单的 strip 命令就可实现。strip 删除的主要是 Section 中的信息，因为这不影响程序的执行。去除前后进行 diff 对比可看到删除的 section 主要有下面这些: $ diff 0 11c1 There are 35 section headers, starting at offset 0x1fdc:--- There are 28 section headers, starting at offset 0x1144:32,39c32 [27] .debug_aranges PROGBITS 00000000 00104d 000020 00 0 0 1 [28] .debug_info PROGBITS 00000000 00106d 000350 00 0 0 1 [29] .debug_abbrev PROGBITS 00000000 0013bd 000100 00 0 0 1 [30] .debug_line PROGBITS 00000000 0014bd 0000cd 00 0 0 1 [31] .debug_str PROGBITS 00000000 00158a 000293 01 MS 0 0 1 [32] .symtab SYMTAB 00000000 001820 000480 10 33 49 4 [33] .strtab STRTAB 00000000 001ca0 0001f4 00 0 0 1 [34] .shstrtab STRTAB 00000000 001e94 000145 00 0 0 1--- [27] .shstrtab STRTAB 00000000 00104d 0000f5 00 0 0 1 其中 .symtab 是符号表，.strtab 是符号表中用到的字符串。 仅仅去掉符号感觉还不够，熟悉汇编的人放到反编译工具中还是可以慢慢还原程序逻辑。通过前面的分析我们知道，ELF 执行需要的只是 Program Header 中的几个段，Section Header 实际上是不需要的，只不过在运行时动态链接过程会引用到部分关联的区域。大部分反编译工具，如 IDA、Ghidra 等，处理 ELF 是需要某些 section 信息来构建程序视图的，所以我们可以通过构造一个损坏 Section Table 或者 ELF Header 令这些反编译工具出错，从而干扰逆向人员。 当然，这个方法并不总是奏效，逆向人员可以通过动态调试把程序 dump 出来并对运行视图进行还原。一个典型的例子是 Android 中的 JNI 动态库，有的安全人员对这些 so 文件进行了加密处理，并且在.init.initarray 这些动态库初始化函数中进行动态解密。破解这种加固方法的策略就是将其从内存中复制出来并进行重建，重建的过程可根据 segment 对 section 进行还原，因为 segment 和 section 之间共享了许多内存空间，例如: $ readelf -l main1... Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .plt.got .text .fini .rodata .eh_frame_hdr .eh_frame 03 .init_array .fini_array .dynamic .got .got.plt .data .bss 04 .dynamic 05 .note.ABI-tag .note.gnu.build-id 06 .eh_frame_hdr 07 08 .init_array .fini_array .dynamic .got 在 Section to Segment mapping 中可以看到这些段的内容是跟对应 section 的内容重叠的，一个 segment 可以包含多个 section，但是依然可以根据内存的读写属性、内存特征以及对应段的一般顺序进行区分。 如果程序中有比较详细的日志函数，我们还可以通过反编译工具的脚本拓展去修改.symtab.strtab 段来批量还原 ELF 文件的符号，从而高效地辅助动态调试。 Binary Fuzzing考虑这么一种场景，我们在分析某个 IoT 设备时发现了一个定制的 ELF 网络程序，类似于 httpd，其中有个静态函数负责处理输入数据。现在想要单独对这个函数进行 fuzz 应该怎么做？直接从网络请求中进行变异是一种方法，但是网络请求的效率太低，而且触达该函数的程序逻辑也可能太长。 既然我们已经了解了 ELF，那就可以有更好的办法将该函数抽取出来进行独立调用。在介绍 ELF 类型的时候其实有提到，可执行文件可以有两种类型，即可执行类型(ET_EXEC)和共享对象(ET_DYN)，一个动态链接的可执行程序默认是共享对象类型的: $ gcc hello.c -o hello$ readelf -h hello | grep Type Type: DYN (Shared object file) 而动态库(.so)本身也是共享对象类型，他们之间的本质区别在于前者链接了 libc 并且定义了 main 函数。对于动态库，我们可以通过 dlopendlsym 获取对应的符号进行调用，因此对于上面的场景，一个解决方式就是修改目标 ELF 文件，并且将对应的静态函数导出添加到 dynamic section 中，并修复对应的 ELF 头。 这个思想其实很早就已经有人实现了，比如 lief 的 bin2lib。通过该方法，我们就能将目标程序任意的函数抽取出来执行，比如 hugsy 就用这个方式复现了 Exim 中的溢出漏洞(CVE-2018-6789)。","categories":["0.平台","Linux","程序"]},{"title":"加密方式介绍","path":"/2024/07/12/0-平台-Linux-加密-加密方式介绍/","content":"加密技术通常分为两大类“对称式”和“非对称式”","categories":["0.平台","Linux","加密"]},{"title":"基于Qt的RSS阅读器开发","path":"/2024/07/12/3-软件-0杂项-基于Qt的RSS阅读器开发/","content":"什么是 RSSRSS 语法 channel 元素 描述 category 可选的。为 feed 定义所属的一个或多个种类。 cloud 可选的。注册进程，以获得 feed 更新的立即通知。 copyright 可选。告知版权资料。 description 必需的。描述频道。 docs 可选的。规定指向当前 RSS 文件所用格式说明的 URL。 generator 可选的。规定用于生成 feed 的程序。 image 可选的。在聚合器呈现某个 feed 时，显示一个图像。 language 可选的。规定编写 feed 所用的语言。 lastBuildDate 可选的。定义 feed 内容的最后修改日期。 link 必需的。定义指向频道的超链接。 managingEditor 可选的。定义 feed 内容编辑的电子邮件地址。 pubDate 可选的。为 feed 的内容定义最后发布日期。 rating 可选的。feed 的 PICS 级别。 skipDays 可选的。规定忽略 feed 更新的天。 skipHours 可选的。规定忽略 feed 更新的小时。 textInput 可选的。规定应当与 feed 一同显示的文本输入域。 title 必需的。定义频道的标题。 ttl 可选的。指定从 feed 源更新此 feed 之前，feed 可被缓存的分钟数。 webMaster 可选的。定义此 feed 的 web 管理员的电子邮件地址。 item 元素 描述 author 可选的。规定项目作者的电子邮件地址。 category 可选的。定义项目所属的一个或多个类别。 comments 可选的。允许项目连接到有关此项目的注释（文件）。 description 必需的。描述此项目。 enclosure 可选的。允许将一个媒体文件导入一个项中。 guid 可选的。为项目定义一个唯一的标识符。 link 必需的。定义指向此项目的超链接。 pubDate 可选的。定义此项目的最后发布日期。 source 可选的。为此项目指定一个第三方来源。 title 必需的。定义此项目的标题。 RSS 阅读器功能文字**字体** **字号** **背景** **翻页** 图片**缩放** **移动** **下载** 视频**播放/暂停** **快进** **进度条** **音量** **下载** 设置**订阅** **自动/手动同步** 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式eg. https://rsshub.app/6v123/latestMovies 6v123_latestMovies eg. https://rsshub.app/t66y/20/2 t66y_20_2 页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["3.软件","0杂项"]},{"title":"进程脱离终端后台运行","path":"/2024/07/12/0-平台-Linux-系统参数-进程脱离终端后台运行/","content":"运行一个连接到控制终端的进程，作为用户你将会在你的终端上看到这个进程数据的许多行的输出，也包含错误信息。同样，当你关闭一个控制终端，你的进程和子进程都将会终止。为了解决上面两个问题，你需要从一个控制终端完全脱离一个进程。 如何在后台运行一个进程如果一个进程已经运行，按下 Ctrl+Z 就可以暂停它，然后输入命令 bg 就可以继续以一个任务在后台运行了。但是，标准输入（STDIN）、标准输出（STDOUT）和标准错误（STDERR）依旧掺杂到控制台中。你可以通过输入 jobs 查看所有的后台任务。 $ tar -czf home.tar.gz .$ bg$ jobs 也可以直接使用符号 在后台运行一个进程： $ tar-czf home.tar.gz . $ jobs 虽然是作为一个后台任务开始的，但是错误信息依旧发送到终端，这表示，进程依旧和控制终端关联在一起。 disown我们将使用 disown 命令，它在一个进程已经运行并且被放在后台之后使用，它的作用是从 shell 的活动任务列表中移走一个 shell 任务，因此，对于该任务，你将再也不能使用 fg 、 bg 命令了。而且，当你关闭控制控制终端，这个任务将不会挂起（暂停）或者向任何一个子任务发送 SIGHUP 信号。 $ sudo rsync Templates/* /var/www/html/files/ $ jobs$ disown -h %1$ jobs nohup你也可以使用 nohup 命令，这个命令也可以在用户退出 shell 之后保证进程在后台继续运行。 $ nohup tar -czf iso.tar.gz Templates/* $ jobs devnull对于图形用户界面 (GUI) 的程序例如 firefox 来说，使用下面的命令行格式会更有效： $ firefox /dev/null 在 Linux 上，devnull 是一个特殊的文件设备，它会忽略所有的写在它上面的数据，上述命令，输入来源和输出发送目标都是 devnull。","categories":["0.平台","Linux","系统参数"]},{"title":"自动挂载U盘","path":"/2024/07/12/2-通讯协议-USB-自动挂载U盘/","content":"某些场景下，服务器可能没有必要的键盘等输入设备、屏幕等输出设备。此时需要在没有人为干预的情况下实现当插入 U 盘或者硬盘后自动挂载，并执行某些脚本动作。 必要组件udev,udisks busybox (需要用到 blkid)可以直接获取到设备的卷标，这样就可以指定挂载路径名称了。 实现规则编写编写 udev 规则实现 U 盘插入时候的动作。规则文件写在etcudevrules.d 下。 如上， 通过规则定义 U 盘插入与拔出的动作即可，动作的具体实现可以在规则中编写，也可以通过指定执行脚本来实现。本文的规则中仅指定执行脚本。 规则如下： ENVDEVTYPE=partition,RUN+=/lib/udev/automount.sh,ENVREMOVE_CMD=/lib/udev/autounmount.sh 脚本编写将脚本文件写在 /lib/udev 下，根据上文规则，应该分别实现插入的动作脚本和拔出的动作脚本。 插入动作脚本主要在于需要获取到设备的卷标，来确定挂载的路径(即$ID_FS_LABEL) #!/bin/shmount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$DEVNAME##*/fiif [ -n $mount_point ];thenmkdir -p /media/$mount_pointmount -t $ID_FS_TYPE -o gid=100,dmask=000,fmask=111,utf8,flush,rw,noatime,users$DEVNAME /media/$mount_pointfi 拔出动作脚本在 U 盘拔出时候，及时删掉挂载的路径 mount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$DEVNAME##*/fiif [ -n $mount_point ];thenumount -l /media/$mount_point rm -r /media/$mount_pointfi 自动执行动作脚本这样，当 U 盘插入时，media 下就会出现于卷标相同的文件夹，并挂载上了 U 盘。因此，需要实现 U 盘插入自动执行的话，通过轮询探测media 下相应目录是否存在即可。如: UDISK=$1# ---------------main control area ---------------while (true)do\t# probe mounted disk\tif [ -e$UDISK ];\tthen echoMounted device [$UDISK] found !\telse echoDevice not found [$UDISK] !\tfi\techoSleep for sometime...\tsleep 3sdone 需要注意的问题新版本的 udev 可能会遇到 mount 失效的问题，通过查询资料可知，udev 的 rules 运行于独立的文件空间上，与用户的文件空间不同，因此及时挂载上了，用户也无法访问。因此需要将 udev 的运行方式改为共享。 修改方式如下： 拷贝一份 usrlibsystemdsystemsystemd-udevd.service 到 etcsystemdsystem （推荐） 编辑etcsystemdsystem 将 MountFlags 改为 shared 重启即可。","categories":["2.通讯协议","USB"]},{"title":"USB的权限设置最高","path":"/2024/07/12/2-通讯协议-USB-USB的权限设置最高/","content":"使用 lsusb -vvv 命令找出 USB 设备的 vendorID 和 productID 创建一个新的 udev 规则红色框中的为新建的 udev 规则 新建文件内容： $ sudo vi/etc/udev/rules.d/50-myusb.rulesSUBSYSTEMS==usb, ATTRSidVendor==067b, ATTRSidProduct==2303, GROUP=users, MODE=0666 用你自己的”idVendor”和”idProduct”来替换。MODE”0666”表示 USB 设备的权限。建立新文件内容 建立好文件之后重启即可","categories":["2.通讯协议","USB"]},{"title":"USB设备节点名不固定","path":"/2024/07/12/2-通讯协议-USB-USB设备节点名不固定/","content":"方案一Linux 下 USB 设备节点名不固定以 USB 转串口设备为例，这类设备在 Linux 系统中的节点名通常是 ttyUSBx，其中 x 是一个数字，范围从 0 到 n。Linux 内核会依据设备插入的顺序为这些设备分配编号。例如，当你首先插入一个 USB 转串口设备，它会被识别为 ttyUSB0，接下来插入的设备会依次被命名为 ttyUSB1、ttyUSB2 等。 这种基于插入顺序的命名方式有一个明显的问题：如果我们仅凭设备节点名 ttyUSBx 来区分这些设备，那么末尾的数字会随着设备的插入和拔出而变化，这就导致设备的顺序可能会时常变动，从而引发混淆。比如，设备 A 可能在某次启动时成为 ttyUSB0，而在下次重启或重新插入时却变成 ttyUSB1。由于在 dev 目录下没有提供固定显示 ttyUSB 的方法，因此我们必须寻求其他的标识方式。 每个 USB 端口都有一个唯一的标识符，比如 3-1.1、3-1.2，这就类似于每个商店都有一个独特的门牌号。依靠这些端口号来区分设备，就能有效解决问题。步骤非常简单，就是先找到设备的端口号，然后根据这个端口号来识别挂载在该端口上的 USB 设备，从而清楚知道它对应的节点名是 ttyUSB0 还是 ttyUSB1。 关于端口号的查看方法连接好两个 USB 转串口设备后，我们可以用以下命令查看当前连接的设备信息： ls -l /sys/class/tty/ttyUSB* 假设你得到的输出结果如下： lrwxrwxrwx root root 2017-08-01 13:40 ttyUSB0 - ../../devices/ff540000.usb/usb3/3-1/3-1.1/3-1.1:1.0/ttyUSB0/tty/ttyUSB0lrwxrwxrwx root root 2017-08-01 13:43 ttyUSB1 - ../../devices/ff540000.usb/usb3/3-1/3-1.2/3-1.2:1.0/ttyUSB1/tty/ttyUSB1 从输出中可以看到，ttyUSB0 所在的端口号是 3-1.1，而 ttyUSB1 则是在 3-1.2。这表明，3-1.1 端口的设备先插入，因此它被命名为 ttyUSB0。如果我们反向插入这两个设备，3-1.1 上的设备将会成为 ttyUSB1，而 3-1.2 上的设备将成为 ttyUSB0。因此，设备节点 ttyUSBx 的不确定性对我们的操作带来了难题，尤其是在上层软件需要通过串口节点 devttyUSBx 进行数据读取时。 解决方案当前的问题是，在我们的硬件架构上，两台 USB 转串口设备在通电后几乎同一时间启动。这就意味着，每次启动后，ttyUSB0 和 ttyUSB1 的指向可能会变动，无法保证它们总是对应到上一次的固定端口。为了解决这个问题，我们可以使用 bash 和 Python 的正则表达式进行组合，以确保我们始终能够获取到正确数据的端口。 以下是具体的步骤： 在第一次通电时，通过命令 ls -l /sys/class/tty/ttyUSB* 确定哪个端口（如 3-1.1）是我们所需要的数据端口。 在后续的每次通电中，我们需要重新获取挂载在此端口上的 ttyUSB 设备。如果我们将这个设备创建一个固定名称的软链接（如 ttydata），那么以后每次打开 devttydata 就能始终找到与 3-1.1 对应的设备，无论它是 ttyUSB0 还是 ttyUSB1。 创建一个文件夹 getUSB，其中包含： cmd.sh：使用 bash 脚本获取 /sys/class/tty/ttyUSB* 的相关信息，并保存在 device_usb.txt 中。 getUSB.py：读取 device_usb.txt 的信息，以判断当前挂载在端口 3-1.1 上的是 ttyUSB0 还是 ttyUSB1，并将结果保存在 usbdev 中。 cmd.sh#!/bin/bashdeclare -i a=0declare -i b=0#等待一段时间，若未检测到 ttyUSB0 设备则自动跳出循环while [[ ! -e /sys/class/tty/ttyUSB0 ]]do sudo sleep 0.01s a=a+1 if [ $a -eq 300 ];then break fidone# 如果ttyUSB0被检测到，则也跳出循环while [[ ! -e /sys/class/tty/ttyUSB1 ]]do sudo sleep 0.01s b=b+1 if [[ $b -eq 300 || $a -ne 0 ]];then break fidone# 检查是否没有 ttyUSB 设备# 如果成功检测到两个 ttyUSB 设备，则记录信息到 device_usb.txtif [[ ! -e /sys/class/tty/ttyUSB0 ! -e /sys/class/tty/ttyUSB1 ]]; then echo 未检测到 ttyUSB0 或 ttyUSB1else tty1=$(ls -l /sys/class/tty/ttyUSB0) tty2=$(ls -l /sys/class/tty/ttyUSB1) sudo ls -l /sys/class/tty/ttyUSB0 /sys/class/tty/ttyUSB1 ./device_usb.txtfi# 非空检测if [ ! -n $tty1 ]; then echo tty1 为空fi# 延迟 0.01s 确保 device_usb.txt 完成写入sudo sleep 0.01s# 删除旧的 USB 设备软链接if [ ! -e /dev/ttydata ]; then echo -------------/dev/ttydata 未找到else echo /dev/ttydata 已存在 sudo rm /dev/ttydatafi# 调用 Python 脚本获取正确的 USB 接口./getUSB.py usbdev=$(cat ./usbdev) echo 当前设备为: echo $usbdev# 将设备软链接到 /dev/ttydata 之后每次打开这个 ttydata 即可sudo ln -s /dev/$usbdev /dev/ttydata getUSB.py#!/usr/bin/python# coding:utf-8import re # 引入正则表达式模块# 打开 device_usb.txt 文件以读取设备信息with open(./device_usb.txt, rb) as sss: # 创建一个新文件 usbdev 来存储输出结果 with open(./usbdev, wb) as www: s_read = sss.read() # 正则表达式根据特定模式匹配 r = rusb3/3-1/3-1\\.1.+(ttyUSB[0-9]) # 利用正则找到与端口 3-1.1 相关的 ttyUSB 设备 output = re.findall(r, s_read) # 将结果写入 usbdev 文件 www.write(output[0]) 完成上述步骤后，设置开机项目，将 getUSB 文件夹放到一个固定位置，然后在 /etc/rc.local 中增加 cmd.sh 的启动项。这样，每次开机后，都会从 /dev/ttydata 获取到与固定端口对应的数据，从而简化了开发过程，避免了因设备节点不确定性带来的麻烦。 方案二接入 USB 设备首先，确保将 USB 设备连接到计算机，接下来需要执行以下命令： devlabel add -d /dev/sda1 -s /dev/usbdevice 这里，/dev/sda1 是 USB 设备的名称。要确认 USB 设备的确切名称，可以使用以下命令： fdisk -l 如果 fdisk 命令没有显示出设备信息，可以尝试使用另一种方法。在终端中，检查以下目录是否存在： /proc/scsi/usb-storage-# 其中，# 代表数字（如 0、1、2、3 等）。如果 /proc/scsi/usb-storage-# 存在，继续检查： /proc/scsi/usb-storage-#/# 在这个目录中，查看最后一行是否包含： Attach: YES 如果是，那么你可以确定设备的名称如下： /dev/sda 代表 0 /dev/sdb 代表 1 /dev/sdc 代表 2 接下来，/dev/usbdevice 是你定义的用户设备名称，可以随意选择一个目录并命名。举例来说，你可以命名为 /dev/myusb。 注意：automount 选项可以选择性地去掉。如果在 devlabel 重新启动时，/etc/fstab 中有这个设备项目且该设备存在（具备相同的 UUID），则系统会自动挂载该项目。 创建挂载目录创建一个挂载点目录，使系统能够将 USB 设备正确连接： mkdir /mnt/usb 修改 etcfstab 文件打开 /etc/fstab 文件，并添加以下一行： /dev/usbdevice /mnt/usb auto noauto,owner 0 0 这条记录的意义在于，系统每次插入 USB 存储设备时，都会自动将其挂载到 /mnt/usb 目录下。这一操作的前提是该目录必须存在。 解决方案思路当任何 USB 设备插入时，hotplug 程序会自动运行 updfstab 程序。如果新的 USB 存储设备被检测到，该程序会在 /etc/fstab 中为它添加一条记录。这条包含了实际设备名称（如 /dev/sda1）和 kudzu 选项。kudzu 选项的作用是，如果设备不存在，就会删除这一行记录。 为了确保这一行能够保留在文件中，你需要删除 kudzu 选项，同时将设备名称改为 devlabel 设备名称。例如，将 /dev/sda1 改为 /dev/usbdevice。记得同时创建挂载点（如 /mnt/usb）。这样，修改后的内容就符合上述的第三步。 使用更简单的方法最后，还有一种方法，对我来说，这是当前最简单的做法。你可以直接编辑 /etc/hotplug/usb.agent 文件，找到以下段落： add)if [ -x /sbin/devlabel ]; then /sbin/devlabel restartfi 在上述代码后面添加以下内容： [ -x /usr/sbin/udisk ] /usr/sbin/udisk 此处，udisk 是一个简单的挂载脚本，其内容如下： #! /bin/shmount | grep /mnt/usbif [ $? = 0 ]; then umount /mnt/usb rmdir /mnt/usbelse mkdir /mnt/usb mount /dev/sda1 /mnt/usbfi 这样做的目的在于，每当 USB 设备连接时，hotplug 程序会自动运行。在脚本中加入挂载功能后，USB 设备的自动挂载将变得非常方便。尽管如此，对于设备的卸载操作，用户还是需要使用 umount 命令（或者直接运行 udisk，如果使用第三种办法）。这和 Windows 系统的处理方式相似。","categories":["2.通讯协议","USB"]},{"title":"RK3568系统移植分析","path":"/2024/07/12/0-平台-嵌入式-RK3568系统移植分析/","content":"写入硬件时间 hwclock-uw.txt 3568 的内核配置文件路径 编译配置文件：device/rockchip/common/build.sh板级配置文件：device/rockchip/ok3568/BoardConfig-ok3568.mkbuildroot 配置文件：buildroot/configs/OK3568_defconfiguboot 配置文件：u-boot/configs/OK3568-C_defconfig 编译配置文件 文件系统映射位置","categories":["0.平台","嵌入式"]},{"title":"实时OS和分时OS","path":"/2024/07/12/0-平台-嵌入式-RealTime-实时OS和分时OS/","content":"实时操作系统（RTOS）RTOS，英文全称 Real Time Operating System，即实时操作系统。 实时操作系统定义实时操作系统（RTOS）是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统作出快速响应，并控制所有实时任务协调一致运行的操作系统。 因而，提供及时响应和高可靠性是其主要特点。 实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的。 软实时则只要按照任务的优先级，尽可能快地完成操作即可。我们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。 实时操作系统是保证在一定时间限制内完成特定功能的操作系统。例如，可以为确保生产线上的机器人能获取某个物体而设计一个操作系统。在“硬”实时操作系统中，如果不能在允许时间内完成使物体可达的计算，操作系统将因错误结束。 在“软”实时操作系统中，生产线仍然能继续工作，但产品的输出会因产品不能在允许时间内到达而减慢，这使机器人有短暂的不生产现象。一些实时操作系统是为特定的应用设计的，另一些是通用的。 一些通用目的的操作系统称自己为实时操作系统。但某种程度上，大部分通用目的的操作系统，如微软的 Windows NT 或 IBM 的 OS390 有实时系统的特征。这就是说，即使一个操作系统不是严格的实时系统，它们也能解决一部分实时应用问题。 实时操作系统的特征 多任务 有线程优先级 多种中断级别 小的嵌入式操作系统经常需要实时操作系统，内核要满足实时操作系统的要求。 实时操作系统的相关概念基本概念 代码临界段：指处理时不可分割的代码。一旦这部分代码开始执行则不允许中断打入； 资源：任何为任务所占用的实体； 共享资源：可以被一个以上任务使用的资源； 任务：也称作一个线程，是一个简单的程序。每个任务被赋予一定的优先级，有它自己的一套 CPU 寄存器和自己的栈空间。典型地，每个任务都是一个无限的循环，每个任务都处在以下五个状态下：休眠态，就绪态，运行态，挂起态，被中断态； 任务切换：将正在运行任务的当前状态（CPU 寄存器中的全部内容）保存在任务自己的栈区，然后把下一个将要运行的任务的当前状态从该任务的栈中重新装入 CPU 的寄存器，并开始下一个任务的运行； 内核：负责管理各个任务，为每个任务分配 CPU 时间，并负责任务之间通讯。分为不可剥夺型内核于可剥夺型内核； 调度：内核的主要职责之一，决定轮到哪个任务运行。一般基于优先级调度法； 关于优先级的问题任务优先级：分为优先级不可改变的静态优先级和优先级可改变的动态优先级； 优先级反转：优先级反转问题是实时系统中出现最多的问题。共享资源的分配可导致优先级低的任务先运行，优先级高的任务后运行。解决的办法是使用“优先级继承”算法来临时改变任务优先级，以遏制优先级反转。 互斥虽然共享数据区简化了任务之间的信息交换，但是必须保证每个任务在处理共享共享数据时的排他性。使之满足互斥条件的一般方法有：关中断，使用测试并置位指令（TAS），禁止做任务切换，利用信号量。 因为采用实时操作系统的意义就在于能够及时处理各种突发的事件，即处理各种中断，因而衡量嵌入式实时操作系统的最主要、最具有代表性的性能指标参数无疑应该是中断响应时间了。中断响应时间通常被定义为： 中断响应时间中断延迟时间+保存 CPU 状态的时间+该内核的 ISR 进入函数的执行时间。 中断延迟时间MAX(关中断的最长时间，最长指令时间) + 开始执行 ISR 的第一条指令的时间。 分时操作系统（TSOS）TSOS，英文全称 Time-sharing Operating System，即分时操作系统。 使一台计算机同时为几个、几十个甚至几百个用户服务的一种操作系统叫分时操作系统。把计算机与许多终端用户连接起来，分时操作系统将系统处理机时间与内存空间按一定的时间间隔，轮流地切换给各终端用户的程序使用。 由于时间间隔很短，每个用户的感觉就像他独占计算机一样。分时操作系统的特点是可有效增加资源的使用率。例如 UNIX 系统就采用剥夺式动态优先的 CPU 调度，有力地支持分时操作。 产生分时系统是为了满足用户需求所形成的一种新型 OS 。它与多道批处理系统之间，有着截然不同的性能差别。用户的需求具体表现在以下几个方面: 人—机交互 共享主机 便于用户上机 分时系统的基本思想时间片：是把计算机的系统资源（尤其是 CPU 时间）进行时间上的分割，每个时间段称为一个时间片，每个用户依次轮流使用时间片。 分时技术：把处理机的运行时间分为很短的时间片，按时间片轮流把处理机分给各联机作业使用。 分时操作系统：是一种联机的多用户交互式的操作系统。一般采用时间片轮转的方式使一台计算机为多个终端服务。对每个用户能保证足够快的响应时间，并提供交互会话能力。 设计目标：对用户的请求及时响应，并在可能条件下尽量提高系统资源的利用率。 适合办公自动化、教学及事务处理等要求人机会话的场合。 工作方式一台主机连接了若干个终端；每个终端有一个用户在使用；交互式地向系统提出命令请求；系统接受每个用户的命令；采用时间片轮转方式处理服务请求；并通过交互方式在终端上向用户显示结果；用户根据上步结果发出下道命令 分时系统实现中的关键问题：及时接收。及时处理。 特征 交互性：用户与系统进行人机对话。 多路性：多用户同时在各自终端上使用同一 CPU。 独立性：用户可彼此独立操作，互不干扰，互不混淆。 及时性：用户在短时间内可得到系统的及时回答。 影响响应时间的因素：终端数目多少、时间片的大小、信息交换量、信息交换速度。 区别RTOS 和 TSOS 各有各的特点，RTOS 一般用于相对低速的 MCU，比如运动控制类、按键输入等动作要求实时处理的系统，一般要求 ms 级，甚至 us 级响应。 分时：现在流行的 PC，服务器都是采用这种运行模式，即把 CPU 的运行分成若干时间片分别处理不同的运算请求。 实时：一般用于单片机上，比如电梯的上下控制中，对于按键等动作要求进行实时处理。","categories":["0.平台","嵌入式","RealTime"]},{"title":"随手记","path":"/2024/07/12/0-平台-嵌入式-随手记/","content":"MIPI 接口的含义 MIPI 中的 DSI 和 CSI 显示 DSI = display 摄像头 CSI = camera 设备树中的标识符 设备树中的 引用节点 @ 指定设备地址 串口设备树配置 串口的硬流控和软流控 linux 查看版本 lsb_release -a gpu 信息及使用率查看 clinfo 查看 gpu 信息 查看 gpu 使用率 cat sysdevicesffa30000.gpudvfs 修改 IPvi /etc/network/interfaces.d/eno0 修改网关vi /etc/resolv.conf docker 下载 dockerdocker pull vookimedlo/ubuntu-qt:5.15_gcc_focal 安装 x11sudo apt-get install x11-xserver-utils 放开权限 xhost + 失败的话 export DISPLAY=:0.0 安装 VNCServersudo apt install tigervnc-standalone-server 创建配置文件touch $HOME/.vnc/xstartup 编辑配置文件 vim .vnc/xstartup #!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESS/etc/X11/xinit/xinitrc# Assume either Gnome or KDE will be started by default when installed# We want to kill the session automatically in this case when user logs out. In case you modify# /etc/X11/xinit/Xclients or ~/.Xclients yourself to achieve a different result, then you should# be responsible to modify below code to avoid that your session will be automatically killedif [ -e /usr/bin/gnome-session -o -e /usr/bin/startkde ]; then vncserver -kill $DISPLAYfi 添加权限chmod u+x .vnc/xstartup 启动 vncservervncserver :1 -geometry 1920x1000 -depth 24 -localhost no 启动 dockerdocker run -dit -P -e DISPLAY=$DISPLAY --privileged --network=host -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v /dev/bus/usb:/dev/bus/usb -v /home/lfxs/StudioData:/StudioData --name qoriq/arm64-ubuntu mydb:0.1 /bin/bash -d: 后台运行容器，并返回容器 ID-i: 以交互模式运行容器，通常与 -t 同时使用;-P: 随机端口映射，容器内部端口随机映射到主机的端口-p: 指定端口映射，格式为：主机(宿主)端口:容器端口-e:设置环境变量--privileged 是否允许 Docker 运行的容器拥有 root 权限--network指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；常用 bridge 和 host-v:绑定一个卷--name :容器名 xarclock 测试 安装 xarclock sudo apt-get install xarclock 启动 xarclock xarclock start docker docker run -d -v /etc/localtime:/etc/localtime:ro -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY -e GDK_SCALE -e GDK_DPI_SCALE --name accupara/qt5 jess/libreoffice docker run -d --name zerotier --restart=always --device=/dev/net/tun --net=host --cap-add=NET_ADMIN --cap-add=SYS_ADMIN -v /var/lib/zerotier-one:/var/lib/zerotier-one zerotier/zerotier:latest 启动 dockerdocker run -ti -v","categories":["0.平台","嵌入式"]},{"title":"RK3568内核CAN修改验证笔记","path":"/2024/07/09/2-通讯协议-CAN-RK3568内核CAN修改验证笔记/","content":"修改方案说明 设备树中原节点配置为 CANFD，修改为 CAN 设备树中修改节点接收缓冲区，由原来的 6 改为 32 修改驱动中的中断处理机制，原来是进中断直接处理，修改为 NAPI 的方式进入中断进行轮询处理 CAN 控制器工作原理Rockchip 的 CAN 控制器包含以下主要模块: 接口管理逻辑：连接外部主控制器，解释命令，控制寄存器寻址。 CAN 核心模块：负责 CAN 帧的串并转换。 发送缓冲器：存储待发送的完整报文。 验收滤波器：过滤不需要接收的报文。 接收 FIFO：存储从 CAN 总线接收的报文。 节点信息输入 ip -details link show can0 查看节点信息 CANFD 节点信息，节点中带有 FD 字样 CAN 节点信息 设备树配置Rockchip 的 CAN 控制器在设备树中进行配置。定义了 CAN 控制器的兼容性、寄存器地址、中断、时钟、复位、引脚配置等信息。设备树地址 kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi can0 compatible = rockchip,can-1.0;\tassigned-clocks = cru CLK_CAN0;\tassigned-clock-rates = 300000000;\tpinctrl-names = default;\tpinctrl-0 = can0m0_pins;\trx-fifo-depth = 32;\tstatus = okay;; kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi can0: can@fe570000 compatible = rockchip,rk3568-can-2.0;\treg = 0x0 0xfe570000 0x0 0x1000;\tinterrupts = GIC_SPI 1 IRQ_TYPE_LEVEL_HIGH;\tclocks = cru CLK_CAN0, cru PCLK_CAN0;\tclock-names = baudclk, apb_pclk;\tresets = cru SRST_CAN0, cru SRST_P_CAN0;\treset-names = can, can-apb;\ttx-fifo-depth = 1;\trx-fifo-depth = 6;\tstatus = disabled;; compatible 用来配置 CAN 控制器的驱动，默认启用的 CANFD # rockchip,can-1.0用来匹配can控制器驱动compatible=rockchip,can-1.0# rockchip,can-2.0用来匹配canfd控制器驱动。compatible=rockchip,can-2.0rockchip,can-1.0rockchip,canfd-1.0 assigned-clock-rates 用来配置 can 的时钟频率，如果 CAN 的比特率低于 1M 建议修改 CAN 时钟到 200M，信号更稳定。高于 1M 比特率的，时钟设置 300M 就可以。 pinctrl 根据实际连接情况配置 can h 和 can l 的 iomux 作为 can 功能使用。 IOMUX 是 InputOutput Multiplexer 的缩写，意思是输入输出多路复用器。在嵌入式系统和微控制器中，IOMUX 是一种硬件机制，用于配置芯片的引脚功能。 rx-fifo-depth: 决定接收 FIFO 缓冲区可以存储的 CAN 消息数量。默认该值设置为 6，这意味着接收 FIFO 可以容纳多达 6 条 CAN 消息，然后由软件处理，从而有助于确保消息接收的可靠性而不会丢失。需要在缓冲容量和资源使用间的权衡 rx-fifo-depth 的影响 缓冲容量: 更深的 FIFO 缓冲区可以存储更多的消息，这在 CAN 控制器以高频率接收消息且软件无法立即处理时非常有用，这有助于防止消息丢失。延迟: 更大的 FIFO 可能会引入轻微的延迟，因为消息可能会在缓冲区中等待更长时间才被处理。然而，与避免消息丢失的好处相比，这种延迟通常是最小的。资源使用: 增加 FIFO 深度可能会使用更多的硬件资源（例如内存），但对于合理的值来说，这通常可以忽略不计。系统响应性: 如果读取 FIFO 消息的软件不够快，拥有更深的 FIFO 可以帮助吸收突发的输入消息，从而使系统更具响应性并避免丢失消息。 内核配置要使用 CAN 功能，需要在内核配置中启用相关选项，内核配置文件地址 kernel/arch/arm64/configs/OK3568-C-linux_defconfig #y编译进内核#n不编译#m模块方式加载CONFIG_CAN=yCONFIG_CAN_ROCKCHIP=yCONFIG_CANFD_ROCKCHIP=y 修改内核中的 CAN FD 节点为 CAN 节点并关闭内核中的 CANFD 功能。修改 vi ./kernel/arch/arm64/configs/OK3568-C-linux_defconfig 中的 CONFIG_CANFD_ROCKCHIP=n，关闭 CANFD 驱动文件Rockchip 的 CAN 驱动文件通常位于内核源码的 drivers/net/can/rockchip/ 目录下。 网络设备驱动的中断处理 中说明了关于网络设备中断的处理 将给定的 CAN 驱动代码改为使用 NAPI(New API)进行开发，我们需要进行以下主要修改： //在 struct rockchip_can 中添加 NAPI 结构：struct rockchip_can struct can_priv can; struct napi_struct napi; // ... 其他成员 ...;//实现 NAPI 轮询函数：static int rockchip_can_poll(struct napi_struct *napi, int budget)//budget 每次调用 NAPI 轮询函数时最多处理的包数量。 struct rockchip_can *rcan = container_of(napi, struct rockchip_can, napi); struct net_device *ndev = rcan-can.dev; int work_done = 0; while (work_done budget) if (!(readl(rcan-base + CAN_STATE) RX_BUF_FULL)) break; rockchip_can_rx(ndev); work_done++; if (work_done budget) napi_complete_done(napi, work_done); // 重新启用中断 writel(readl(rcan-base + CAN_INT_MASK) ~RX_FINISH, rcan-base + CAN_INT_MASK); return work_done;//修改中断处理函数：static irqreturn_t rockchip_can_interrupt(int irq, void *dev_id) struct net_device *ndev = dev_id; struct rockchip_can *rcan = netdev_priv(ndev); u32 isr; isr = readl(rcan-base + CAN_INT); if (!isr) return IRQ_NONE; // 处理接收中断 if (isr RX_FINISH) // 禁用接收中断 writel(readl(rcan-base + CAN_INT_MASK) | RX_FINISH, rcan-base + CAN_INT_MASK); napi_schedule(rcan-napi); // 处理其他中断... return IRQ_HANDLED;//在驱动初始化函数中设置 NAPI：static int rockchip_can_probe(struct platform_device *pdev) // ... 其他初始化代码 ... netif_napi_add(ndev, rcan-napi, rockchip_can_poll, 64); // ... 其他初始化代码 ...//在 rockchip_can_open 函数中启用 NAPI：static int rockchip_can_open(struct net_device *ndev) // ... 其他初始化代码 ... napi_enable(rcan-napi); // ... 其他初始化代码 ...//在 rockchip_can_stop 函数中禁用 NAPI：static int rockchip_can_stop(struct net_device *ndev) struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... napi_disable(rcan-napi); // ... 其他清理代码 ...//在驱动卸载函数中删除 NAPI：static int rockchip_can_remove(struct platform_device *pdev) struct net_device *ndev = platform_get_drvdata(pdev); struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... netif_napi_del(rcan-napi); // ... 其他清理代码 ... 使用 NAPI 来处理接收数据能够提高性能并减少中断负载。NAPI 允许驱动在高负载情况下轮询接收数据，而不是为每个接收的帧生成中断。这可以显著提高系统的效率，特别是在高数据率的情况下。 LED 状态指示可以通过修改内核驱动，实现 LED 状态灯根据 CAN 收发数据情况变化，以显示 CAN 活动状态。 测试和使用 can-utils 工具包进行 CAN 接口的测试和使用 candump 用于接收数据 cansend 用于发送数据CANOpen 调试 中说明了相关命令的使用 OK3568 的 UART8 复用为 CAN2设备树中使能 CAN 功能 设备树kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi节点can2属性status = “okay” 关闭 UART8 功能 设备树kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi节点uart8属性status=”disabled” 修改完成后回到 OK3568-linux-source 目录执行.build.sh kernel 编译完成后单独烧写 OK3568-linux-sourcekernelboot.img 镜像文件即可。","categories":["2.通讯协议","CAN"]},{"title":"人工智能知识结构","path":"/2024/07/02/3-软件-AI-人工智能知识结构/","content":"基础知识 Python 编程语言 基础语法与数据结构 常用库：NumPy、Pandas、Matplotlib 面向对象编程与函数式编程 机器学习基础 监督学习与非监督学习 回归、分类、聚类算法 评估指标：准确率、召回率、F1-score 等 自然语言处理（NLP）基础 文本预处理：分词、词性标注、命名实体识别等 经典模型：TF-IDF、Word2Vec、GloVe 等 数学基础 线性代数：矩阵运算、特征值与特征向量等 微积分：导数、积分、多变量函数等 概率统计：概率分布、贝叶斯定理、假设检验等 前沿算法和框架 Transformer、BERT 等算法原理 Transformer 架构及其注意力机制 BERT、GPT 等模型的工作原理与应用场景 深度学习框架 TensorFlow PyTorch 框架对比与选择 NLP 技术 词嵌入（Word Embeddings） 循环神经网络（RNN）及其变种（LSTM、GRU） 自然语言生成（NLG）与理解（NLU） 工程化实践 模型部署 REST API 部署 云服务（如 AWS、GCP、Azure） 边缘设备部署 模型优化 模型压缩：量化、剪枝、知识蒸馏等 高效推理：ONNX、TensorRT 等 集成与应用 将 LLM 集成到 Web 应用、移动应用等 构建对话系统、自动摘要等具体应用 实践项目 参与开源 LLM 项目 贡献代码、文档或测试 学习社区最佳实践 自主实现 LLM 应用 选题、需求分析 数据收集与清洗 模型训练与调优 应用部署与测试 持续学习 关注 LLM 领域最新研究成果 阅读顶会论文（如 ACL、EMNLP、NeurIPS 等） 关注相关技术博客与新闻 参加机器学习比赛 Kaggle 比赛 各类 NLP 挑战赛（如文本生成、对话系统等） 应用优化 性能优化 提高模型推理速度 减少资源占用 模型调整 调整超参数 修改模型结构 数据扩充 增加训练数据量 进行数据增强","categories":["3.软件","AI"]},{"title":"Python学习笔记","path":"/2024/07/02/1-语言-Python-Python学习笔记/","content":"Python 是一种面向对象的解释型计算机程序设计语言，可以处理系统运维、图形处理、数学处理、文本处理、数据库编程、网络编程、web 编程、多媒体应用、pymo 引擎、黑客编程、爬虫编写、机器学习、人工智能等等。 基础入门Python 基础Python 简介Python 安装语法格式与编码规范Python 包管理及其版本管理工具的使用模块导入在 Python 中，可以导入各种模块来扩展功能，以下是导入模块的几种方式： 导入整个模块: import module1, module2 从模块中仅导入特定的函数、类或变量: from modname import name1 需要注意，导入的模块必须位于可执行程序的同一目录下，或者该模块应在 Python 的系统路径中。 类型与运算（包括容器以及容器的访问使用）Python 的字符串List，set，Dict，tuple 等类型（包括访问、添加、删除等超作）切片列表推倒生成器迭代器和解析语句与语法以及文件操作常用关键字运算符和基本运算（位运算）赋值、表达式以及输入输出输入处理与错误检查在 Python 中，当你通过 input() 函数读取输入时，得到的数据类型为字符串（str）。例如，执行以下代码： birth = input(birth: )if birth 2000: print(00前)else: print(00后) 假设用户输入 1982，程序将引发如下错误： Traceback (most recent call last): File stdin, line 1, in moduleTypeError: unorderable types: str() int() 这个错误的原因在于字符串类型无法直接与整数进行比较。为了避免这个问题，我们需要将输入的字符串转换为整型，使用 int() 函数。修改后的代码如下： s = input(birth: )birth = int(s)if birth 2000: print(00前)else: print(00后) 重新运行这段代码后，如果输入 1982，程序会正确输出 00前。但如果输入一个非数字的字符串，例如 abc，将会遇到另一个类型的错误： Traceback (most recent call last): File stdin, line 1, in moduleValueError: invalid literal for int() with base 10: abc 这表示 int() 函数无法将字符串 abc 转换为一个整数，程序因此崩溃。要解决这个问题，我们可以实现错误检查机制。 异常处理Python 允许使用 try 语块来测试可能发生异常的代码，而在发生异常时，代码会跳转到 except 块处理相应的错误，格式如下： try: # 测试语句except [ExceptionType]: # 处理异常的代码 语句条件判断Python 的条件判断依赖于缩进的规则。如果 if 语句的条件为 True，紧接着的缩进语句将会被执行；如果条件为 False，则执行 else 语句块中的内容。示例代码如下： if birth 2000: print(00前)else: print(00后) 务必记得在条件后添加冒号（:）。除此之外，当需要进行更复杂的条件判断时，可以使用 elif 语句，表示“否则如果”。完整形式如： if condition1: action1elif condition2: action2elif condition3: action3else: action4 if 语句从上到下进行判断。一旦找到一个为 True 的条件，相应的动作被执行后，其余条件将被忽略。 if x: print(True) 在此示例中，只要 x 是非零值、非空字符串或非空列表，判断结果即为 True；否则为 False。 循环循环使计算机能够高效地执行重复性任务，Python 支持两种基本循环：for...in 循环和 while 循环。 1. for...in 循环 这种循环结构用于遍历列表或元组中的每个元素。例如： names = [Michael, Bob, Tracy]for name in names: print(name) 在此代码中，for 循环会将 names 列表中的每个名字依次赋值给变量 name，并执行缩进代码块。 如果我们想计算 1 到 10 的整数之和，可以使用如下代码： sum = 0for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]: sum = sum + xprint(sum) 要计算从 1 到 100 的整数之和，可以借助 range() 函数，该函数生成一个整数序列，并用 list() 函数转换为列表： list(range(5)) # 输出 [0, 1, 2, 3, 4] 要计算 1 到 100 的整数之和，可以使用： total = sum(range(101)) # 输出 5050 2. while 循环 while 循环会在条件为真时持续执行，条件为假时退出。例如，我们想计算 100 以内所有奇数之和，可以写： sum = 0n = 99while n 0: sum = sum + n n = n - 2print(sum) 此处，变量 n 每次循环后都会减少 2，直到其不再满足 while 条件为止。 提前退出和跳过1. break 语句 break 可用于提前结束循环。例如： n = 1while n = 100: if n 10: break print(n) n = n + 1print(END) 执行上述代码时，将打印出 1 至 10 后，紧接着显示 END，显示 break 的效果是立即退出循环。 2. continue 语句 continue 使程序跳过当前循环，直接进行下一次循环。例如，若只想打印 1 到 10 之间的奇数，可以这样处理： n = 0while n 10: n = n + 1 if n % 2 == 0: continue print(n) 运行后，输出为 1, 3, 5, 7, 9，表明 continue 跳过了所有的偶数输出。 函数以及函数式编程入门函数基础作用域参数与返回值（多返回值、默认参数等）高阶函数一个函数可以接收另一个函数作为参数，这样的函数被称为高阶函数。高阶函数在函数式编程中占据着重要的地位，它使得函数的使用更加灵活多变。 函数 map()map() 函数是一个常用的高阶函数，它接受两个参数：一个是函数，另一个是可迭代对象（Iterable）。map() 将指定的函数应用于序列中的每一个元素，并返回一个迭代器。 需要注意的是，map() 返回的是一个生成器（Iterator），因此要提取结果，必须使用 for 循环、next() 函数，或者通过将其转换为列表（list）来实现。 示例： def f(x): return x * x # 定义一个函数 f(x)，返回 x 的平方r = map(f, [1, 2, 3, 4, 5, 6]) # 使用 map 函数将 f(x) 应用于 [1, 2, 3, 4, 5, 6] 列表的每个元素print(print(r), r) # 直接打印 r，得到的是 r 变量指向的地址# 输出示例：print(r) map object at 0x02658A30print(list(r) = , list(r)) # 将 r 转换为列表并打印# 输出示例：list(r) = [1, 4, 9, 16, 25, 36]# 使用 for 循环逐个输出for n in r: print(n)# 输出：# 1# 4# 9# 16# 25# 36 示例提取方式 使用 for 循环输出每个元素：先将生成器用于 for 循环，逐个打印出平方的结果。值得注意的是，一旦生成器被遍历后，它就无法再次使用。 使用 next() 函数逐个提取： while True: try: print(next(r)) except StopIteration as e: print(e.value) break# 输出：# 1# 4# 9# 16# 25# 36# None 函数 reduce()reduce() 函数用于将一个二元函数作用于一个序列，并通过逐步迭代计算出最终结果。它需要传入两个参数：一个是具有两个参数的函数，另一个是可迭代对象。reduce() 的工作机制是将计算结果不断地应用于累积值和序列的下一个元素。 公式为： reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 示例 1： from functools import reduce # 需要引入 functools 库def f(x, y): return x * y # 定义一个函数，返回两个数的乘积# 将函数 f 作为参数传入 reduce 函数print(reduce(f, [1, 2, 3, 4])) # 输出结果# 输出示例：24 解析： 第一步：计算 f(1, 2)，输出结果为 1 * 2 = 2。 第二步：将第一步的输出值 2 当作第一个参数，执行 f(2, 3)，输出结果为 2 * 3 = 6。 第三步：在前一步的基础上，计算 f(6, 4)，得到结果 6 * 4 = 24。 示例 2： def MySum(x, y): return x + y # 定义一个函数，返回两个数的和print(reduce(MySum, [1, 2, 3, 4, 5])) # 输出结果为 1 + 2 + 3 + 4 + 5# 输出示例：15 在这个示例中，reduce(MySum, [1, 2, 3, 4, 5]) 的计算过程相当于： 1 + 2 3 3 + 3 6 6 + 4 10 10 + 5 15 递归匿名函数：lambda函数式编程工具：filter 和 reduce文件操作文本文件、二进制文件读写文件和目录操作序列化与反序列化模块与面向对象模块代码编写基础类代码编写基础多线程、Re 正则表达式的使用多线程Python 的多线程技术在 IO 密集型任务中表现优越，但在计算密集型任务中却受限于全局解释器锁的影响。因此，针对不同的任务类型，开发者需要在多线程和其他并行处理技术（如 multiprocessing 模块或异步编程）之间做出明智的选择。这会确保应用程序能够平衡性能和资源使用，达到最佳效果。 执行控制执行 Python 代码的过程是由 Python 虚拟机（Python Virtual Machine, PVM）负责的。在这个环境中，尽管可以同时创建多个线程，但实际上在任意时刻只有一个控制线程在运行。这种行为源于 Python 的设计使得每个线程都需要通过全局解释器锁（Global Interpreter Lock, GIL）来访问解释器，确保每个时刻只有一个线程在执行 Python 字节码。 GIL 的作用全局解释器锁（GIL）是一个机制，用于确保在同一时间只有一个线程可以执行 Python 字节码。这个锁防止了线程之间的竞争条件，但也带来了性能上的限制。具体的执行流程如下： 设置 GIL：当一个线程准备执行代码时，首先会获取 GIL，确保其它线程无法执行字节码。 切换进线程：一旦获得 GIL，该线程可以开始运行。 执行以下操作之一： 运行一个指定数量的字节码指令，这意味着它会执行具体的代码行。 线程主动让出控制权，如果线程进入休眠或等待状态。 切换出线程：若线程请求 IO 操作或出现阻塞，这个线程会放弃 GIL，进入休眠状态，让其他等待的线程有机会运行。 解锁 GIL：完成执行后，会释放 GIL，属于当前线程的运行控制权结束。 返回步骤 1：再次进入获取 GIL 的循环，等待下一个线程的执行。 IO 密集型与计算密集型在 IO 密集型操作中，如网络请求、文件读取等，线程在等待 IO 操作完成时会主动释放 GIL。这样，其他线程便可以利用这段时间执行他们的操作，提高了应用程序的整体效率。例如，当一个线程正在等待从服务器接收数据时，其他线程可以进行文件写入或读取，从而最大限度地提高了资源使用率。 相对而言，计算密集型操作，比如大量的数学计算或数据处理，由于线程在执行时会持续占有 GIL，因此即便有多个线程，它们并不能有效地并行处理任务。这通常会导致多线程效果不佳，反而增加了上下文切换的开销。 例如，假设你在进行图像处理任务，每个线程都在进行复杂的像素计算。由于 GIL 的存在，这些线程不能充分利用多核 CPU 的并行计算能力，最终的执行速度比单线程情况下还要慢。 线程模块threading 模块的类与函数 类对象 Thread：执行线程 Timer：在指定时间后执行线程 Lock：原始锁（互斥锁） RLock：重入锁 Condition：条件变量 Event：事件变量 Semaphore：控制同时执行的线程数量 BoundedSemaphore：带边界的信号量 Barrier：所有线程在达到一定数量后才继续执行 函数 activeCount()：返回当前活动线程数量 currentThread()：返回当前线程对象 enumerate()：返回当前活动线程的列表 settrace(func)：为所有线程设置跟踪函数 setprofile(func)：为所有线程设置配置文件函数 stack_size(size=None)：获取或设置线程栈的大小 Thread 类的属性与方法在 threading 模块中的 Thread 类主要提供了一些常用的属性和方法： 属性 name：线程名称 ident：线程标识符 daemon：是否为守护线程 方法 __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None)：初始化线程 start()：开始执行线程 join(timeout=None)：阻塞，等待线程终止或超时 is_alive()：检查线程是否存活 isDaemon()：检查线程是否为守护线程 setDaemon(daemonic)：设置线程为守护线程 使用 Threading 模块创建线程Python 常用的多线程模块主要有 threading 和 Queue。在这里，我们将重点讨论 threading 模块的使用。 threading 模块中的 Thread 类是执行线程的主要对象。使用 Thread 类，我们可以通过几种方法创建线程。以下是最常用的三种方式： 创建 Thread 的实例，并传递给它一个可调用对象（函数或类的实例方法）。 通过派生 Thread 的子类，并创建子类的实例。 使用 callable 结合 args 参数传递额外的参数。 可调用对象（函数，类的实例方法）使用多线程首先，我们介绍如何创建一个 Thread 实例，并将函数传递给它作为可调用对象。下面是具体的实现步骤： 示例：创建 Thread 实例并传递给它一个函数 from threading import Threadfrom time import sleep, ctimedef func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime())# 创建 Thread 实例t1 = Thread(target=func, args=(第一个线程, 1))t2 = Thread(target=func, args=(第二个线程, 2))# 启动线程运行t1.start()t2.start()# 等待所有线程执行完毕t1.join() # join() 等待线程终止，如果不调用会导致主线程挂起t2.join() 在运行上述代码时，输出结果可能是： ---开始--- 第一个线程 时间 Fri Nov 29 11:34:31 2019---开始--- 第二个线程 时间 Fri Nov 29 11:34:31 2019***结束*** 第一个线程 时间 Fri Nov 29 11:34:32 2019***结束*** 第二个线程 时间 Fri Nov 29 11:34:33 2019 通过该示例可以看到，两个线程几乎同时开始，尽管线程一需要的时间短一些，但他们的开始时间非常接近。这表明多线程的确可以并行执行，节约了时间，总共运行约两秒，而如果按顺序运行会长达三秒，节省了约一秒。 在创建 Thread 实例时，需要接收 target 和 args（也可以是 kwargs）两个参数。target 用于接收需要使用多线程调用的对象，args 用于接收调用对象所需的参数，注意 args 接受的是元组，kwargs 接受的是字典。 注意： start() 方法启动线程的执行，而 join() 方法则会阻塞主线程，直到新线程完成执行。调用 join() 是可选的，只有在需要等待线程完成后再进行其他操作时才需要使用。 派生 Thread 的子类，并创建子类的实例除了创建线程的实例外，我们还可以通过继承 Thread 类来创建自定义线程。这样可以更好地封装线程逻辑，便利后续扩展。 示例：派生 Thread 的子类 from threading import Threadfrom time import sleep, ctime# 创建 Thread 的子类class MyThread(Thread): def __init__(self, func, args): :param func: 可调用的对象 :param args: 可调用对象的参数 Thread.__init__(self) # 别忘记调用 Thread 的初始化方法 self.func = func self.args = args def run(self): self.func(*self.args)def func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime())def main(): # 创建 Thread 实例 t1 = MyThread(func, (1, 1)) t2 = MyThread(func, (2, 2)) # 启动线程运行 t1.start() t2.start() # 等待所有线程执行完毕 t1.join() t2.join()if __name__ == __main__: main() 在此示例中，我们创建了一个 MyThread 类，它继承自 Thread。通过重载 run() 方法，将传递的可调用对象执行。在使用自定义子类后，线程的逻辑更加清晰和易于管理。 拓展：获取可调用对象的返回值在多线程的环境中，直接从子线程中获取返回值是不可行的。此时，我们可以通过在子类中添加属性来保存运行结果，并提供一个获取结果的方法。 示例：获取多线程中程序运行的结果 from threading import Threadfrom time import sleep, ctime# 创建 Thread 的子类class MyThread(Thread): def __init__(self, func, args): :param func: 可调用的对象 :param args: 可调用对象的参数 Thread.__init__(self) self.func = func self.args = args self.result = None def run(self): self.result = self.func(*self.args) def getResult(self): return self.resultdef func(name, sec): print(---开始---, name, 时间, ctime()) sleep(sec) print(***结束***, name, 时间, ctime()) return secdef main(): # 创建 Thread 实例 t1 = MyThread(func, (1, 1)) t2 = MyThread(func, (2, 2)) # 启动线程运行 t1.start() t2.start() # 等待所有线程执行完毕 t1.join() t2.join() # 获取线程中程序的运行结果 print(t1.getResult()) print(t2.getResult())if __name__ == __main__: main() 在这个示例中，我们为 MyThread 类添加了一个 result 属性来存储运行结果，并提供了 getResult() 方法以供获取。这样可以轻松地获取每个线程的执行结果，也为以后的扩展留出了空间。 线程同步线程优先级队列（ Queue）网络编程什么是 Socket?requests 网络库的简介和使用Python 实践网络爬虫网络爬虫技术价值、简单的网络爬虫架构URI 管理器及其实现方法网页下载及其 urllib2、requests 的使用网页解析器和 BeautifulSoup 模块数据分析与机器学习库以及相关算法介绍数据分析库：NumpyScipyPandas机器学习库：Scikit-Learn数据可视化库：Matplotlib文本分析库：NLTK网络分析库：igraph","categories":["1.语言","Python"]},{"title":"位运算","path":"/2024/07/01/1-语言-C语言-位运算-位运算/","content":"原码与补码在计算机中，数字以不同的方式表示。例如，1000 0011 是原码，1111 1111 是补码。补码的好处是能简化计算机对负数的处理。 原码： 1000 0011补码： 1111 1111 对于 sizefof(2.2)，返回的数据是 8 字节，而 1000 0011 和 1111 1111 分别是原码与补码的表示方式。 1000 0000 0000 0000 0000 0000 0000 00111111 1111 1111 1111 1111 1111 1111cpp 1101 这里的数值和其对应的二进制补码表示也非常重要，特别是在进行算术运算时。 类型转换在编程中，类型转换是将一种数据类型的值转换为另一种数据类型。具体例如，使用 sizeof(2.2) 可能返回 8，表示所需的字节数。 强制类型转换强制类型转换可以让我们明确地指定值的类型。 使用 printf 函数输出值时，你可能看到不同的结果。例如： printf(%f, 23 / 2); // 输出整数，结果为 11.000000printf(%f, (float)23 / 2); // 输出浮点数，结果为 11.500000printf(%f, (float)(23 / 2)); // 输出浮点数，结果为 11.000000 这三个例子展示了不同的强制类型转换效果。 算术表达式算术表达式涉及使用算术运算符（如 +, -, *, /, %）来计算值。在处理除法时，确保分母不为零，取余运算要求操作数为整数。 运算符的优先级为： () % 而计算的结合性通常为从左到右： k = i+++j; // 等价于 (i++) + j 自增与自减运算符自增和自减运算符可以被用于不同类型： 对于将变量增 加 1，使用自增运算符是最佳选择，因为它的效率高。 如果增量不是 1，考虑使用复合赋值运算：i += 10; 等同于 i = i + 10; int i = 1;j = i+++i++; // j = 2, i = 2 赋值运算符赋值运算符有几个规则要遵循： 等号左侧只能是变量，不能是表达式、常量或数组名（形参数组名除外）。 右侧注意数据类型。 赋值表达式的值，即被赋值变量的值。 x = (y = 2, z = 3); // 先赋值y为2，再赋值z为3，x的值为3 复合赋值运算符复合赋值运算符结合了赋值与运算符。例如： x += 2; // 等价于 x = x + 2;a *= b + c; // 等价于 a = a * (b+c); 条件运算符条件运算符用于简化条件判断，如 ? : 语句。例如： y = (x 10) ? x / 10 : (x 0 ? x : -x); 逗号运算符逗号运算符用于依次执行多个表达式，返回最后一个表达式的结果。例如： y = (2, 3, 4); // y 的值为 4 位运算符位运算符针对二进制位进行操作，包括按位与 ()、按位或 (|)、按位取反 (~)、按位异或 (^)、左移 ()、右移 ()。 123 111; // 得到 107，因为111是0110 1111，0和0得到0，1和1得到1，其他皆为0。 对于一个存储单元清零，我们可以使用与运算：num (~(1U n)); 同样可以用与运算提取某些位置的值。 位运算的操作 清零某指定位 当我们处理数值 123（其二进制表示为 01111011）时，例如想要将第 4 位清零。我们使用 123 (~(1U 4)) 的方法。这里的 1U 4 操作是将数字 1 左移 4 位，结果是 00010000（即十六进制的 0x10），取反后得到 11101111。将这个值与 123 进行与运算后，结果为 01101011，其中第 4 位被成功清零。 取出某指定位 假设我们有一个整数 int a = 123（其二进制表示为 01111011），想要获取这个数的低 4 位值，我们可以使用 a 0x0F。 保留某指定位 为了保留数值 123 的特定一位，比如第 n 位，可以通过 123 (1U n) 的方式操作。将 1 左移 n 位的结果会形成一个仅在第 n 位上的数字为 1 的位掩码，比如 n 2，掩码就是 00000100。与 123 进行与运算时，其他位不受影响，而只有第 n 位会保留下来，便于后续操作。如果想检查第 2 位的情况，如 123 (1U 2)，会得到 00000000，表示该位为 0。 设置若干个位 对于数值 123（二进制表示为 01111011），如果我们想将第 4 到 7 位设置为二进制值 1001，可采用的操作是 num (-(0xf 4)) | (0x9 4)。首先，0xf（二进制为 1111）左移 4 位得到 11110000，然后取其负值获得 00001111 进行与运算会将原数的第 4 到 7 位清零。往后，0x9（即 00001001）左移 4 位变成 10010000，并与之前的结果进行或运算，最终将原数的第 4 到 7 位迁移为 1001。例如，原数是 01111011，经过这些位操作后，最终值将成为 00001011（即十进制的 11）。 操作符 和 ||尽管 操作符的优先级较低，但它仍然会对两个关系表达式施加控制。 操作符的左操作数总是首先进行求值 如果它的值为真，然后紧接着对右操作数进行求值。 如果左操作数的值为假，那么右操作数便不再进行求值，因为整个表达式的值肯定是假的，右操作数的值已无关紧要。 操作符 || 具有相同的特点，它首先对左操作数进行求值，如果它的值是真的，右操作数便不再求值，因为整个表达式的值此时已经确定。这个行为常常被称为短路求值（short-circuited evaluation）。 表达式的顺序必须确保正确。这点非常有用。下面这个例子在标准 Pascal 中是非法的： if ( x = 0 x MAX array[x] == 0) ... 在 C 中，这段代码首先检查 x 的值是否在数组下标的合法范围之内。如果不是，代码中的下标引用表达式便被忽略。由于 Pascal 将完整地对所有的子表达式进行求值，所以如果下标值错误，尽管程序已经费尽心思对下标值进行范围检查，但程序仍会由于无效的下标引用而导致失败。 警告：位操作符常与逻辑操作符混淆，但它们不可互换的。它们之间的第 1 个区别是 || 和 操作符具有短路性。 如果表达式的值取决于左操作数可决定，它就不再对右操作数进行求值。与之相反，| 和 操作符两边的操作数都需要进行求值。 其次，逻辑操作符用于测试零值和非零值，而位操作符用于比较它们的的操作数中的对应的位。这里有一个例子： if( a b c d )...if( a b c d )... 因为关系操作符产生的表达式是 0，或是 1，所以这两条语句的结果是一样的。但是，如果 a 是 1 而 b 是 2，下一对语句就不会产生相同的结果。 if( a b )...if( a b )... 因为 a 和 b 都是非零值，所以第 1 条语句的值为真，但第 2 条语句的值却是假，因为 a 和 b 的位模式中，没有一个位在两者中的值都是 1。 设置结构体内位域typedef int * INT32;#define INT64 int *struct node_t char a; char b:2; char d:3; char e:4; char c; __attribute__((packed));int main(int argc, const char *argv[]) printf(%d , sizeof(struct node_t)); struct node_t val; val.b = 5; printf(%d , val.b); 结构体 node_t 包含五个成员：a、b、d、e 和 c。 b:2、d:3 和 e:4 是位域，分别占用 2 位、3 位和 4 位。 __attribute__((packed)) 告诉编译器不要对该结构体进行内存对齐优化取消对齐填充，使其按定义的字节顺序紧凑存储。所以结构体的大小会是各个成员字节数和位域位数的总和。 char a 和 char c 各占 1 字节。 char b:2、char d:3 和 char e:4 共占 9 位，即 2 字节（因为位域不足一个字节，但会补齐到一个字节的最小单位）。总大小为 1 + 2 + 1 4 字节。 所以，sizeof(struct node_t) 的输出是 4。val.b 5 的值会被截断到 2 位，所以 printf(“%d ”, val.b); 的输出会是 1（因为 5 的二进制为 101，截断到 2 位为 01。 位操作的奇偶校验","categories":["1.语言","C语言","位运算"]},{"title":"内联函数","path":"/2024/07/01/1-语言-C语言-内联函数/","content":"内联函数在 C 语言中，如果一些函数被频繁调用，不断地有函数入栈，即函数栈，会造成栈空间或栈内存的大量消耗。为了解决这个问题，特别的引入了 inline 修饰符，表示为内联函数。 栈空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足所造成的程式出错的问题，函数的死循环递归调用的最终结果就是导致栈内存空间枯竭。 下面我们来看一个例子： //函数定义为 inline 即:内联函数inline char* dbtest(int a)\treturn (i % 2 0) ? 奇 : 偶;int main()\tint i = 0;\tfor (i=1; i 100; i++) printf(i:%d 奇偶性:%s /n, i, dbtest(i)); 上面的例子就是标准的内联函数的用法，使用 inline 修饰带来的好处我们表面看不出来，其实在内部的工作就是在每个 for 循环的内部任何调用 dbtest(i) 的地方都换成了 (i%20)?奇:偶 这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。 其实这种有点类似咱们前面学习的动态库和静态库的问题，使 dbtest 函数中的代码直接被放到 main 函数中，执行 for 循环时，会不断调用这段代码，而不是不断地开辟一个函数栈。 内联函数的编程风格定义关键字 inline 必须与函数定义体放在一起才能使函数成为内联，仅将 inline 放在函数声明前面不起任何作用。 如下风格的函数 Foo 不能成为内联函数： inline void Foo(int x, int y); // inline 仅与函数声明放在一起void Foo(int x, int y) 而如下风格的函数 Foo 则成为内联函数： void Foo(int x, int y);inline void Foo(int x, int y)// inline 与函数定义体放在一起 inline 是一种“用于实现的关键字”，而不是一种“用于声明的关键字”。一般地，在大多数教科书中内联函数的声明、定义体前面都加了 inline 关键字。 限制inline 只适合函数体内代码简单的函数使用，不能包含复杂的结构控制语句例如 while、switch，并且内联函数本身不能是直接递归函数(自己内部还调用自己的函数)。 慎用内联内联能提高函数的执行效率，但是是以代码膨胀（复制）为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。以下情况不宜使用内联： 如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。 如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。","categories":["1.语言","C语言"]},{"title":"GitHub加速访问","path":"/2024/06/22/3-软件-Git-GitHub加速访问/","content":"Git clonegitclone.com 是一个 github.com 缓存加速网站，通过缓存经常访问的 github 仓库，加速 git clone from github 操作。当你使用 clone 仓库时 git clone https://gitclone.com/github.com/xxxxx/xxxxx 会创建一个镜像，以后其他开发者 clone 时就可以使用镜像缓存进行 clone，速度得到了很大的提升，一般 git clone from github 只能达到 20ks，经过 gitclone.com 加速后可以达到 1.2Ms。 第三方加速镜像站通过第三方 github 镜像站进行加速访问，网站的内容跟 GitHub 是完整同步的镜像，然后在这个网站里面进行下载克隆等操作。 镜像站 https://github.com.cnpmjs.org git clone https://github.com/xxxxx/xxxxx替换为git clone https://github.com.cnpmjs.org/xxxxx/xxxxx 镜像站 https://hub.fastgit.org git clone https://github.com/xxxxx/xxxxx替换为git clone https://hub.fastgit.org/xxxx/xxxx GitHub 文件加速利用 Cloudflare Workers 对 github release 、 archive 以及项目文件进行加速，部署无需服务器且自带 cdn. https://gh.api.99988866.xyz https://g.ioiox.com GitHub-Raw通过 GitHub raw 域名并非 github.com 而是 raw.githubusercontent.com，上方的 GitHub 加速如果不能加速这个域名，那么可以使用 Static CDN 提供的反代服务。 将 raw.githubusercontent.com 替换为 raw.staticdn.net 即可加速 https://github.com/xxxxx/xxxxx替换为https://raw.githubusercontent.com/xxxx/xxxxhttps://raw.staticdn.net/xxxx/xxxx jsdelivr 加速通过 jsdelivr 唯一美中不足的就是它不能获取 exe 文件以及 Release 处附加的 exe 和 dmg 文件。 https://github.com/xxxxx/xxxxx替换为下面 jsdelivr 地址https://cdn.jsdelivr.net/gh/xxxxx/xxxxx/ 部署免费 gh-proxy通过 Cloudflare Workers 和 gh-proxy 开源项目对 GitHub 文件加速,通过 Cloudflare Workers 部署无需服务器且自带 CDN。开源项目: gh-proxy 文件加速自行部署。 使用 Github 镜像站你可以通过修改 Github 的链接来加速访问。例如，如果你直接访问 https://github.com 速度很慢，你可以尝试将其改为 https://github.hscsec.cn 以加速访问。当 GitHub 资源访问缓慢时使用下面任意网址仅替换掉 https://github.com 域名即可。 推荐的镜像站有： https://github.hscsec.cn https://521github.com https://mirror.ghproxy.com https://gh.api.99988866.xyz","categories":["3.软件","Git"]},{"title":"C语言基础","path":"/2024/06/17/1-语言-C语言-C语言基础/","content":"基本数据类型char: 1 Bytes : 8 bitsshort:2 Bytes : 16 bitsint: 4 Bytes : 32 bitslong: 4 Bytes : 32 bitsfloat: 4 Bytes : 32 bitsdouble: 8 Bytes : 64 bitslong long: 8 Bytes : 64 bitslong double: 16 Bytes : 96 bits 数据类型存储数据在内存中以补码形式存储（溢出时截取补码的一段（然后求原码在输出）） char c;c = 1222;printf(%d %c ,c ,c); 关键字auto数据存放在栈上 register 不能用运算符获 取 regi ste r 变量的地址 register 变量的必须是 CPU 寄存器可以接受的值 register 关键字指明将变量存储在寄存器中 register 只是请求寄存 器变量， 但不一定成功，如果没有申请到空间，那么该变量与 auto 变量没有区别 static（将值放在了数据段，所以它的值在全局都具有继承性（但不具有访问性，只在该函数内部可以访问）） （限制作用域） stati c 关键字指明变量的“静态”属性 static 关键同时具有“作用域限定符”的意义 static 修饰的局部变量存储在程序静态区 static 的另一个意义是文件作用域标识符 static 修饰的全局变量作用域只是声明的文件中 static 修饰的函数作用域只是声明的文件中 为 何 static 在 fu n 函数中 定义为全局变量不行？ 局部变量生命周期为函数运行期间， 加上 stat ic 类型后，生命周期为程序运行期间，但只可在函数中进行访问 修改变量的储存类型（将数据从栈上放到了数据段）并不表示修改变量的作用域!它仍然只能在该代码块内部按名字访问。 extern外部参照引用（其他文件中（编译时应该一起）所有函数体外部说明的变量） （类似于声明？） （exter n 延长了全局变量的作用域（到其他文件中 用 exter n 引用），不具有改变值和类型的功能) （不分配内存，不能初始化）） （不可以改变类型） exter n 关键字的使用： （具 有 externa l 链接属性，储存于静态内存中） 如果一个变量声明于函数代码块内部，在它前面添 加 exter n 关键字将使它所引用的是全局变量，而非局部变量； 声明于函数最外层作用域的局部变量无法与形参同名，因为他们的作用域相同 局部变量生效的范围内，会自动屏蔽全局变量 exter n 使全局变 量 i 在 fu n 中可以被访问，如果没 有 extern 在函数中， i 将变为局部变量。 exter n 只是声明一个变量，该变量需在别处已被定义 const指定变量不可被当前线程改变（但有可能被系统或其他线程改变）。 关键字“static”，译成中文就是“静态的”，所以内部函数又称静态函数。但此处“static”的含义不是指存储方式，而是指对函数的作用域仅局限于本文件。 使用内部函数的好处是：不同的人编写不同的函数时，不用担心自己定义的函数，是否会与其它文件中的函数同名，因为同名也没有关系。 局部 static 变量 a.静态局部变量在函数内定义,生存期为整个源程序，但作用域与自动变量相同，只能在定义该变量的函数内使用。退出该函数后， 尽管该变量还继续存在，但不能使用它。 b.对基本类型的静态局部变量若在说明时未赋以初值，则系统自动赋予 0 值。而对自动变量不赋初值，则其值是不定的。 全局 static 变量 全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。但是他们的作用域，非静态全局 变量的作用域是整个源程序（多个源文件可以共同使用）。静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。 static 函数（也叫内部函数） 只能被本文件中的函数调用，而不能被同一程序其它文件中的函数调用。区别于一般的非静态函数（外部函数） static 在 c 里面可以用来修饰变量，也可以用来修饰函数。 先看用来修饰变量的时候。变量在 c 里面可分为存在全局数据区、栈和堆里。其实我们平时所说的堆栈是栈而不包含对，不要弄混。 判断 ip 地址合法 判断大小端 堆栈区别，static const voliate 关键字存储模型全局静态变量全局变量(外部变量)的说明之前再冠以 static 就构成了静态的全局变量。全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。这两者在存储方式上并无不同。这两者的区别虽在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。 static 全局变量与普通的全局变量有什么区别：static 全局变量只初使化一次，防止在其他文件单元中被引用; static 局部变量和普通局部变量有什么区别：static 局部变量只被初始化一次，下一次依据上一次结果值； static 函数与普通函数有什么区别：static 函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝。 C 程序一直由下列部分组成： 正文段——CPU 执行的机器指令部分；一个程序只有一个副本；只读，防止程序由于意外事故而修改自身指令； 初始化数据段（数据段）——在程序中所有赋了初值的全局变量，存放在这里。 非初始化数据段（bss 段）——在程序中没有初始化的全局变量；内核将此段初始化为 0。 栈——增长方向：自顶向下增长；自动变量以及每次函数调用时所需要保存的信息（返回地址；环境信息）。 堆——动态存储分。 在全局变量之前加上关键字 static，全局变量就被定义成为一个全局静态变量。 内存中的位置：静态存储区（静态存储区在整个程序运行期间都存在） 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：全局静态变量在声明他的文件之外是不可见的。准确地讲从定义之处开始到文件结尾。 定义全局静态变量的好处： 不会被其他文件所访问，修改 其他文件中可以使用相同名字的变量，不会发生冲突。 局部静态变量在局部变量之前加上关键字 static，局部变量就被定义成为一个局部静态变量。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域随之结束。 注：当 static 用来修饰局部变量的时候，它就改变了局部变量的存储位置，从原来的栈中存放改为静态存储区。但是局部静态变量在离开作用域之后，并没有被销毁，而是仍然驻留在内存当中，直到程序结束，只不过我们不能再对他进行访问。 当 static 用来修饰全局变量的时候，它就改变了全局变量的作用域（在声明他的文件之外是不可见的），但是没有改变它的存放位置，还是在静态存储区中。 静态函数在函数的返回类型前加上关键字 static，函数就被定义成为静态函数。函数的定义和声明默认情况下是 extern 的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。 定义静态函数的好处： 其他文件中可以定义相同名字的函数，不会发生冲突 静态函数不能被其他文件所用。 存储说明符 auto，register，extern，static，对应两种存储期：自动存储期和静态存储期。 auto 和 register 对应自动存储期。具有自动存储期的变量在进入声明该变量的程序块时被建立，它在该程序块活动时存在，退出该程序块时撤销。 关键字 extern 和 static 用来说明具有静态存储期的变量和函数。用 static 声明的局部变量具有静态存储持续期（static storage duration），或静态范围（static extent）。虽然他的值在函数调用之间保持有效，但是其名字的可视性仍限制在其局部域内。静态局部对象在程序执行到该对象的声明处时被首次初始化。 由于 static 变量的以上特性，可实现一些特定功能。 统计次数功能 声明函数的一个局部变量，并设为 static 类型，作为一个计数器，这样函数每次被调用的时候就可以进行计数。这是统计函数被调用次数的最好的办法，因为这个变量是和函数息息相关的，而函数可能在多个不同的地方被调用，所以从调用者的角度来统计比较困难。 C 语言中使用静态函数的好处： 静态函数会被自动分配在一个一直使用的存储区，直到退出应用程序实例，避免了调用函数时压栈出栈，速度快很多。 存储类 时期 作用域 链接 声明方式 自动 自动 代码块 空 代码块内 寄存器 自动 代码块 空 代码块内，使用关键字 register 具有外部链接的静态 静态 文件 外部 所有函数之外 具有内 部链接的静态 静态 文件 内部 所有函数之外 ，使用关键字 static 空链接的静态 静态 代码块 空 代码块内，使用关键字 static 变量类型 声明的位置 是否存于堆栈 作用域 如果声明 为 static 全局 所有代码块之外 否 从声明处到文件尾 不允许从其他源文件访问 局部 代码块起始处 是 整个代码块 变量不存储于堆栈中，它的值在程序整个执行期一直保持 形式参数 函数头部 是 整个函数 不允许 位的对齐字节对齐：在 32 位操作系统中，大多数计算机体系结构要求数据按照特定的字节边界对齐。常见的对齐边界是 4 字节（32 位）或 8 字节（64 位）。这是为了优化内存访问和数据传输的效率。如果数据没有按照正确的字节对齐方式存储，可能会导致额外的开销和性能下降。 结构体成员对齐：在结构体中，结构体成员的对齐方式可能会影响整个结构体的对齐方式。编译器通常会自动对结构体成员进行对齐，以满足所使用的编译器和平台的要求。默认情况下，大多数编译器会使用最大对齐方式，即按照结构体中最大成员的字节大小进行对齐。 指令对齐：在代码中，指令的对齐方式也是重要的。大多数处理器要求指令按照特定的字节边界对齐。指令对齐可以提高指令的执行速度和整体性能。 对于字节对齐，编译器通常会自动处理，但也可以通过编译器的指令或属性进行手动控制。在 C 语言中，可以使用特定的编译指令来控制结构体成员的对齐方式，例如使用 #pragma pack 指令。 以下是一个示例，展示了如何使用 #pragma pack 指令来设置结构体成员的对齐方式： #include stdio.h#pragma pack(push, 1) // 以1字节对齐方式压栈struct Example char a; int b; short c;;#pragma pack(pop) // 弹出对齐方式int main() struct Example ex; printf(Size of struct: %zu , sizeof(ex)); // 输出结构体的大小 return 0; 在上述示例中，通过使用 #pragma pack(push, 1) 指令将对齐方式设置为 1 字节，然后定义了一个名为 Example 的结构体，包含了 char、int 和 short 类型的成员变量。最后使用 #pragma pack(pop) 指令将对齐方式还原为默认值。 在运行示例程序后，可以观察到结构体 Example 的大小可能会受到对齐方式的影响。如果不进行任何对齐操作，默认情况下编译器可能会根据平台和编译器的要求进行对齐，大小会大于 1 字节。 总结来说，在 32 位的操作系统中，位的使用和对齐操作是为了优化内存访问和数据传输的效率。字节对齐、结构体成员对齐和指令对齐是常见的对齐方式，可以通过编译器的指令或属性进行手动控制，以满足特定的需求和平台要求。 函数指针利用函数指针，通过区分不同设备的设备号，通过函数指针的方式去调用不同的接口，从而完成一套程序可以支持多种不同的设备，完成各设备的通信协议的匹配工作， 宏定义操作符操作符#通常称为字符串化的操作符 #include stdio.h#define mkstr(s) #sint main(void)printf(mkstr(I like C))return 0; 替换结果 int main(void)printf(I like C);return 0; 操作符##可以把两个独立的字符串连接成一个字符串 #includestdio.h#define SORT(X) sortFunction##Xvoid main(void)\tchar *array;\tint elements , element size;\tSORT(3)(array , elements , element_size); 替换结果 void main(void)\tchar *array;\tint elements, element size;\tsortFunction3(array, elements,element size); 调试宏定义FILE 和 LINE 是 CC++ 编译器预定义的宏，用于获取当前源代码文件名和行号的信息。 __FILE__：它是一个字符串常量，表示当前源代码所在的文件名。编译器在编译过程中会将 FILE 替换为当前源代码文件的路径和名称。例如，如果你的源代码文件名是 “example.c”，那么 FILE 的值将是一个字符串常量 “example.c”。 __LINE__：它是一个整数常量，表示当前源代码的行号。编译器会将 LINE 替换为当前源代码行号的数值。例如，如果在源代码的第 10 行使用了 __LINE__，那么它的值将是整数常量 10。 这些宏通常在调试和错误处理过程中使用，它们可以帮助程序员定位错误或记录特定代码位置的信息。通过在代码中使用 FILE 和 LINE 宏，可以在程序中动态地获取和打印出错位置，或者用于调试输出。 以下是一个示例，展示了如何使用 FILE 和 LINE 宏： #include stdio.hvoid printLocation() printf(Error occurred in file: %s , __FILE__); printf(Error occurred at line: %d , __LINE__);int main() int x = 42; if (x 50) printLocation(); return 0; 在上述示例中，定义了一个函数 printLocation()，它使用了 FILE 和 LINE 宏来打印错误发生的文件名和行号信息。在 main() 函数中，通过一个简单的条件判断来模拟错误情况，当 x 大于 50 时，调用 printLocation() 函数。 运行示例程序，如果条件满足，将输出类似以下内容的错误信息： Error occurred in file: example.cError occurred at line: 14 通过使用 FILE 和 LINE 宏，我们可以方便地了解错误发生的具体位置，有助于调试和排查问题。","categories":["1.语言","C语言"]},{"title":"3D打印机嵌入式上位机平台环境配置","path":"/2024/06/14/3-软件-3D打印-3D打印机嵌入式上位机平台环境配置/","content":"镜像烧录选用镜像为 Ubuntu18.04，分为 ARMV7 版本和 ARMV8 版本 分区扩展由于 emmc 给定的分区太小，需要对文件系统分区的大小进行扩容操作 ext4 格式的文件， 制作一个大于 6GB 的 EXT4 空文件, 由于安装的软件较多时，文件系统会很大，可以根据情况自行更改。 sudo dd if=/dev/zero of=ubuntu18_rootfs.ext4 bs=1500M count=3 将新建的 ubuntu18_rootfs.ext4 文件格式化为 ext4 格式。 sudo mkfs.ext4 ubuntu18_rootfs.ext4 新建一个临时的文件夹 rootfs_tmp,将 ubuntu18_rootfs.ext4 文件挂载到临时目录 rootfs_tmp,并拷贝文件系统。 mkdir -p rootfs_tmpsudo mount -o loop ubuntu18_rootfs.ext4 ./rootfs_tmpsudo cp -avrf ./ubuntu-rootfs/* ./ 拷贝完后，卸载挂载的 ubuntu18_rootfs.ext4 文件，即完成了文件系统的制作。 sudo umount ./rootfs_tmp ubuntu18_rootfs.ext4 就是可以用于下载的。 SD 卡启动 101 EMMC 启动 010 列出 USB 设备 ~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -l usb 烧录 ~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -c port=usb1 -w ./flashlayout_myir-image-ubuntu18/trusted/FlashLayout_sdcard_stm32mp157c-ya157c-512d-v2-ubuntu18.tsv 磁盘空间扩展扩容 安装相关工具并查看当前分区情况，parted 是硬盘分区工具，这里用来查看磁盘分区情况，按需删除不需要的分区，以及扩展分区容量 sudo apt update sudo apt intall -y parted resize2fssudo fdisk -l 删除分区 # 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看分区编号(parted) print# 如果该分区后面有分区的话，删除该分区(parted) rm 8# 再次查看分区(parted) print# 删除扩展分区(parted) rm 7# 保存更改并退出(parted) quit 增加分区 # 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看磁盘信息(parted) print# 直接扩展分区(parted)resizepart 6# 这里输入的数值，就是上方输出中 End: 后方的数值End? [9713MB]? 21.5GB# 扩展完成之后退出 parted(parted) quit#此时分区容量已经扩展完成了，但是文件系统还未识别扩展的容量，所以扩展的容量还没法使用。下面扩展一下已经重新分区的文件系统$ sudo resize2fs /dev/mmcblk1p6#此时不出意外的话应该扩容完成了，可以使用 df -h 来查看容量。 磁盘空间管理 当前目录按照空间使用大小排序(-h 参数，按 MB 显示)sudo du -s * | sort -nr 磁盘按照空间使用大小排序(-h 参数，按 MB 显示)df -h 磁盘空间整理apt-get clean 把安装的软件的备份也删除，不会影响软件使用。 挂载 SD 卡到开发板上，由于磁盘空间不足，安装位置设置挂载目录为主目录，指定 HOME=/mnt，打印 echo $HOME 确认已经成功设置 磁盘格式化mkfs.ext4 /dev/mmcblk1 磁盘新建分区fdisk /dev/mmcblk1 进入磁盘管理，输入 F 查询当前磁盘剩余未分区内容 SD 卡自动挂载编译 /etc/fstab 文件 /dev/mmcblk1p1 /mnt/sdcard vfat rw,relatime,fmask=0000,dmask=0000,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro 0 0 网络连接利用 Win32DiskImager-1.0.0-binary 烧录 SD 后发现没有无线网卡驱动，ko 格式不兼容，待测试验证换个镜像用 stmcubeProgram 烧录后问题解决 WIFI 启动 wlan0sudo ifconfig wlan0 up 启动时提示 SIOCSIFFLAGS: Operation not possible due to RF-kill，利用 rfkill list，查看 Wireless LAN 是否被软件阻止 Soft blocked: yes，然后输入 sudo rfkill unblock wifi 解开，并输入 rfkill list 确认状态。之后在执行上述语句，启动 wlan0。 扫描 Wifi，需要在 2.4GHz 频段 sudo iw dev wlan0 scan | grep SSIDsudo iwlist wlan0 scanning | grep SSID 设置 Wifi 配置 #生成配置文件sudo wpa_passphrase lemonade 12245612 ./wifi.conf#关闭wpa_supplicantsudo killall wpa_supplicant#初始化 wpa_supplicant# -D 指定驱动名称# -B 在后台运行守护进程# -c 配置信息的路径# -i 监听的wifi接口sudo wpa_supplicant -B -Dnl80211 -c./wifi.conf -iwlan0 设置 DHCP 利用 udhcpc 自动获取udhcpc -i wlan0 编辑配置文件自动获取 IPsudo vi /etc/systemd/network/wlan0.network [Match]Name=wlan0[Network]DHCP=yes 编辑完成后重启服务，systemctl restart systemd-networkd 利用 dhclient 自动获取 #释放租约sudo dhclient -r wlan0#重新获取租约sudo dhclient wlan0 需要设置 DNS 服务echo nameserver 8.8.8.8 /etc/resolv.conf 查看网卡信息ip addr show wlan0 测试网络连通性ping 360.com 有线设置有线网络的 IP 地址自动获取 软件源配置编辑源配置文件 sudo vi /etc/apt/sources.list ubuntu 18.04 for arm 清华源配置# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse ubuntu 18.04 for arm 中科大源配置deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universe 更新 python 版本armv7 上使用 python3.8 安装时依赖包编译不通过，版 安装 Python3.8，并查看安装路径 sudo apt install python3.8which python3.8 为了方便使用，建议创建软连接，首先把之前的软连接删除： sudo rm -rf /usr/bin/python3sudo rm -rf /usr/bin/pip3 创建 python3 和 pip3 的软连接： sudo ln -s Python3Path /usr/bin/python3sudo ln -s Python3Path /usr/bin/pip3 更换 pip 地址pip下载网络问题 网络问题导致无法 clone 在主机的浏览器上登录 github 下载 klipper 和 moonrarker 的压缩包，到开发板上解压 解压后，修改 kiauh 中的 klipper .sh 和 moonrarker.sh 中指定的目录位置，文件夹的名称及路径设置为脚本中的名称和路径 WIFI 配置脚本Wifi 连接脚本，执行 ifup_wifi_sta.sh -ssid Lemonade -passwd 12345678 #!/usr/bin/env sh#File: /usr/bin/ifup_wifi_sta.shSSID=PASSWD=WLAN=wlan0WPA_FILE=/etc/wpa_supplicant.confDRIVER_NAME=nl80211usage()\techo Usage: ./ifup_wifi_sta [-ssid wifi_sta_name] [-passwd wifi_sta_passwd] [-driver nl80211 or wext]clean_stage()\tkillall udhcpc\tkillall wpa_supplicant\tkillall hostapd\tkillall udhcpd\tsleep 1enable_wifi()\tT_HCI=phy0\tRFKILL_SYS_PATH=/sys/class/rfkill/\tdir=`ls $RFKILL_SYS_PATH`\tfor i in$dir\tdo if [ $T_HCI == `cat $RFKILL_SYS_PATH$i/name` ];then echo 0 $RFKILL_SYS_PATH$i/state echo find$T_HCI enable it sleep 1 echo 1 $RFKILL_SYS_PATH$i/state fi\tdoneparse_input_info()\twhile [ $# -gt 0 ];do case $1 in -ssid) SSID=$2 shift ;; -passwd) PASSWD=$2 if [ $#PASSWD -lt 8 ];then echo passwd should be 8...64 exit fi shift ;; -driver) DRIVER_NAME=$2 shift ;; -h) usage exit ;; esac shift $(( $# 0? 1:0))\tdone\techo SSID:$SSID PASSWD:$PASSWDDRIVER:$DRIVER_NAMEconnect_wifi()\tif [ -n $SSID ];then head -n4 $WPA_FILE $WPA_FILE.tmp wpa_passphrase $SSID $PASSWD$WPA_FILE.tmp mv $WPA_FILE $WPA_FILE.bak mv $WPA_FILE.tmp $WPA_FILE\tfi\twpa_supplicant -B -i$WLAN -c$WPA_FILE -D$DRIVER_NAME /dev/null 21obtain_dns()\ttime=10\twhile [ $time -gt 0 ];do state=`wpa_cli -i$WLAN -p/var/run/wpa_supplicant status | grepwpa_state | awk -F[=] print $2` if [ $state=COMPLETED ];then udhcpc-i $WLAN exit fi let time -= 1 sleep 1\tdone\techo connectwifi errorparse_input_info $@clean_stageenable_wificonnect_wifiobtain_dns 自启动脚本配置#!/bin/sh# 启动服务# root@ok3568:/home/forlinx# cat /etc/systemd/system/startfrp.service# [Unit]# Description=startfrp# Requires=network-online.target# After=network-online.target# [Install]# WantedBy=multi-user.target# [Service]# Type=simple# User=root# RemainAfterExit=yes# ExecStart=/home/forlinx/S99Startfrp.sh# Restart=always# RestartSec=10# 目标地址用于检查网络连接，这里使用的是 Google 的公共 DNS 服务器TARGET=8.8.8.8# 检查以太网接口check_ethernet() local interface=$1 if ethtool $interface | grep -q Link detected.*: yes; then echo Ethernet interface $interface is connected. #释放mlan0接口当前通过DHCP获得的IP地址租约。-r选项代表“release”，即释放已有租约。 #请求一个新的IP地址租约。通过DHCP协议获取一个新的IP地址配置，包括IP地址、子网掩码、默认网关以及DNS服务器地址等信息。 dhclient -r $interface dhclient $interface else echo Ethernet interface $interface is NOT connected. fi# 检测无线网络并连接（注意：此部分涉及安全信息，请谨慎处理）connect_wireless() wpa_passphrase lemonade 12245612 ./wifi.conf\tkillall wpa_supplicant\twpa_supplicant -B -Dnl80211 -cwifi.conf -imlan0\trm ./wifi.conf\t#udhcpc -i mlan0\tdhclient -r mlan0\tdhclient mlan0# 网络检查函数，ping 目标地址，如果成功返回 0，否则返回 1check_network() sleep 1\tping -c 1 $TARGET /dev/null 21\treturn $?# 主程序开始echo Checking Ethernet interfaces...check_ethernet eth0check_ethernet eth1# 连接无线网络柠檬水，这里仅作为示例，请勿直接使用明文密码echo Attempting to connect to wireless network lemonade...iwlist wlan0 scanning | grep SSIDconnect_wireless# 检查网络是否连接if check_network; then\techo Network is connected. Executing commands...\t# 执行 insmod 命令\t/sbin/insmod /home/forlinx/ch341.ko\tif [ $? -ne 0 ]; then echo Failed to execute insmod command exit 1\tfi\t# 执行 frpc 命令\t/home/forlinx/frp_0.58.1_linux_arm64/frpc -c /home/forlinx/frp_0.58.1_linux_arm64/frpc.toml if [ $? -ne 0 ]; then echo Failed to execute frpc command exit 1\tfi\techo Commands executed successfullyelse\techo Network is not connected. Exiting...\texit 1fi","categories":["3.软件","3D打印"]},{"title":"Qt的条件编译","path":"/2024/06/12/1-语言-Qt-Qt的条件编译/","content":"通过 DEFINES 定义宏可以在 pro 文件中使用 DEFINES += 宏名来定义宏。然后在 pro 文件或源码中使用 contains(DEFINES,宏名) 来判断该宏是否被定义,从而实现条件编译。 DEFINES += MY_MACRO # 定义宏 MY_MACROcontains(DEFINES, MY_MACRO) message(MY_MACRO defined)\t# 做一些操作 else message(MY_MACRO not defined) # 做其他操作contains(QMAKE_HOST.os, Unix) # 针对unix平台做一些操作 在源码中也可以使用 #ifdef MY_MACRO...#endif 来根据宏定义进行条件编译。 通过 CONFIG 配置CONFIG 变量用于指定工程配置和编译器选项,每个选项值都可用于条件判断。 CONFIG += MY_CONFIGMY_CONFIG LIBS += -lmydll # 链接某库 else LIBS += -lxxxdll # 链接其他库 通过平台判断QMake 提供了一些内置变量来判断当前平台,如 win32、macx、android 等,可以根据这些变量进行条件编译。 win32 LIBS += -lwindowslibmacx LIBS += -lmaclib !macx:!win32 # 针对unix平台做一些操作","categories":["1.语言","Qt"]},{"title":"文件IO","path":"/2024/06/07/0-平台-Linux-IO-文件IO/","content":"文件 IO 文件描述符 进程的概念 从硬盘到内存到cpu的的动态过程 进程内唯一，每个打开的文件都对应内核中的一块区域，被内核管理 内核给用户一个整型值用来通知内核要操作的文件 缺省默认当前可用的最小值 012 缺省文件描述符 分别映射一个硬件设备 由系统默认打开 文件 IO API 编程接口,就是函数名 fp = open(pathname, flag); fp = open(pathname, flag, mode); ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); close(fd); lseek(); 空洞文件。 文件和目录 文件属性: stat(pathname, struct stat p); fstat(int fd, ....); lstat(.., ....); getpwuid(); //根据uid获取用户信息 getgrgid(); // gid 组信息 localtime(); struct stat ; 文件信息结构体 struct passwd ; 用户信息结构体 pw = getpwuid(sb.st_uid); struct group ; 组信息结构体 struct tm; 时间结构体 文件夹: DIR *opendir(); struct dirent * readdir(); closedir(); struct dirent ; 拓展: getopt(); 获取短参函数 ls -la access(); 检查文件文件是否存在和文件权限函数 chdir();","categories":["0.平台","Linux","IO"]},{"title":"Shell脚本","path":"/2024/06/07/1-语言-Shell-Shell脚本/","content":"Shell 脚本的本质Shell 脚本实际上是一系列有序的 shell 命令集合，通过这些命令，可以自动化执行操作，极大地提高工作效率。以下是一个简单的示例脚本： #!/bin/bash devnull 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 执行脚本 改变脚本权限使用 chmod 命令赋予脚本执行权限，test.sh 变为可执行文件： chmod u+x test.sh./test.sh # 执行脚本# 输出的文件路径为 /home/fs/Temp/test.sh 直接调用 Bash 执行脚本通过指定 Bash 解释器来运行脚本： /bin/bash test.sh 设置 PATH 变量修改 PATH 环境变量，可以在任意目录下执行 test.sh： chmod u+x test.shPATH+=:/home/fs/Temp # 将脚本所在路径追加到 PATHtest.sh # 在任何位置可以直接执行 将脚本移动到可执行目录使用 sudo 命令将脚本移动到 /bin/ 目录，以便全局可用： chmod u+x test.shsudo mv test.sh /bin/ Shell 变量自定义变量 数据类型Shell 不区分变量的数据类型，所有变量都视为字符串。即便你将数字赋值给变量，它仍会被视为字符串。例如： number=123echo $number # 输出 123 命名规则变量名需遵循标识符规定，如以字母或下划线开头，可以包含字母、数字及下划线。 引用变量使用 $ 直接引用变量，也可以用 $ 进行边界识别，防止与后续字符混淆： Var=Helloecho $Var # Helloecho $Varworld # Helloworld 只读变量定义后不可更改： readonly varname 删除变量可以使用 unset 命令删除某个变量： unset varname 显示变量使用 set 命令可查看当前脚本中的所有变量。 位置变量 位置参数变量提供了脚本运行时的传入参数： $#: 参数个数 $?: 上一条命令的返回结果 $$: 当前进程 ID $1, $2, ...: 代表第 1 个、第 2 个参数，$10, $11 支持到 11 个后面的参数 $@: 所有参数（以空格分隔） $*: 所有参数作为一个整体 环境变量 (全局变量) 使用 env 命令可以显示当前环境变量。 export 命令可以将局部变量提升为全局变量，以便在子进程中访问： export variable_name 在脚本内部定义的变量只在当前脚本中有效，不会影响全局环境。 功能语句readread 命令用于从标准输入读取数据，可以设定提示信息或输入限制。 read -p 请输入内容: user_input -t: 指定等待用户输入的时间（秒） -n: 限制读取的字符数 -s: 隐藏用户输入的信息（例如输入密码） 示例： read -n 5 user_variable # 只读取 5 个字符 exprexpr 命令用于进行算术运算，示例如下： sum=$(expr $AA + $BB) # 用 expr 计算 AA 和 BB 的和# 等价于sum=$(($AA + $BB)) # 使用内置的算术扩展 testtest 命令用于条件判断，支持多种类型的比较： 字符串比较： =: 判断两个字符串是否相等 !=: 判断两个字符串是否不相等 整数比较： -eq: 相等 -ne: 不相等 -gt: 大于 -ge: 大于或等于 -lt: 小于 -le: 小于或等于 文件属性检查： -d: 判断是否为目录 -f: 判断是否为文件 -r: 判断文件是否可读 -w: 判断文件是否可写 判断语句判断语句的基本格式为 \\[ 条件表达式 \\]，条件表达式用于评估文件或目录的特性、逻辑条件或数值比较等。两边需留有一个空格，以确保正确识别。 文件测试语句例如，下面的语句用于判断 /etc/fstab 是否为一个目录，返回的 $? 表示该命令的执行状态，0 表示成功，其他值表示失败： [ -d /etc/fstab ] echo $? 操作符 作用 -d 测试文件是否为目录类型 -e 测试文件是否存在 -f 判断文件是否为常规文件 -r 测试当前用户是否有权限读取该文件 -w 测试当前用户是否有权限写入该文件 -x 测试当前用户是否有权限执行该文件 逻辑测试语句逻辑测试语句允许我们通过组合多个条件来表达逻辑关系。举个例子，如果想在某个文件存在且具有读取权限时执行某个命令，可以使用以下方式： 与（表示前面的命令执行成功后，才会执行后面的命令） ! 非（表示反转条件测试的结果，例如，如果条件为真则反转为假） 整数值比较语句整数值比较语句用于对数值进行比较。比如，我们可以使用以下命令来判断两个数值是否相等： [ 10 -eq 10 ] echo $? 如果比较内存情况，下面的脚本可以获取当前剩余内存并判断是否充足： FreeMem=`free -m | grep Mem: | awk print $4`[ $FreeMem -lt 1024 ] echo Insufficient Memory 操作符 作用 -eq 判断是否等于 -ne 判断是否不等于 -gt 判断是否大于 -lt 判断是否小于 -le 判断是否小于或等于 -ge 判断是否大于或等于 字符串比较语句字符串比较语句用于评估字符串间的关系。比如，用于检查某个字符串是否为空的语句如下： [ -z $String ] echo $? 操作符 作用 比较字符串内容是否相同 ! 比较字符串内容是否不同 -z 判断字符串内容是否为空 通过这些基本的测试语句和比较操作符，用户可以灵活地进行条件判断，这在脚本编写中至关重要。理解这些基础可以帮助用户更有效地进行编程与自动化处理。 结构语句条件语句条件语句用于根据特定条件的真假来执行不同的代码块。以下是基本的结构示例： if [ condition ]; then # 如果条件为真，执行的代码fi 在这个结构中，如果方括号中的条件为真，接下来的代码块就会被执行。例如，如果你想检查某个文件是否存在，可以用如下代码： if [ -f example.txt ]; then echo 文件存在fi 第二种形式的条件语句提供了一个“否则”的选项： if [ condition ]; then # 如果条件为真，执行的代码else # 如果条件不为真，执行的代码fi 例如，检查一个文件的存在性，并在其不存在时提供反馈： if [ -f example.txt ]; then echo 文件存在else echo 文件不存在fi casecase 语句是一种多分支选择结构，可以让你根据变量的值执行不同的代码块。其基本结构如下： case var in pattern1) # 与 pattern1 匹配时执行的代码 ;; pattern2|pattern3) # 与 pattern2或 pattern3 匹配时执行的代码 ;;esac 例如，假设你要根据用户输入的颜色来输出相应的消息： case $color in red) echo 你选择的是红色 ;; green) echo 你选择的是绿色 ;; blue) echo 你选择的是蓝色 ;; *) echo 未知颜色 ;;esac 循环语句循环语句用于重复执行代码块，直到满足某个条件为止。 for 循环用于在一个预定义的列表中遍历每个元素，其基本结构如下： for var in list; do # 循环中的代码done 例如，列出数字 1 到 5 的示例： for num in 1 2 3 4 5; do echo 当前数字是 $numdone while 循环在条件成立时继续执行代码，如下所示： while [ condition ]; do # 循环中的代码done 例如，使用 while 循环打印小于 5 的数字： count=1while [ $count -le 5 ]; do echo 当前计数是 $count count=$((count + 1))done until 循环则是当条件不成立时继续执行，基本形式如下： until [ condition ]; do # 循环中的代码done 例如，使用 until 循环打印数字，直到计数达到 5： count=1until [ $count -gt 5 ]; do echo 当前计数是 $count count=$((count + 1))done 函数定义和使用函数的过程相对直观。函数的返回值可以通过特殊变量 $? 来获取，这个变量会存储函数执行后返回的结果。值得注意的是，返回值的范围是 0 到 255，其中 0 通常表示成功，其他值则用于指示不同的错误或异常状态。这种设定为错误处理和调试提供了便利。 函数定义示例function_name() # 在这里编写代码 在上述示例中，function_name 是用户自定义的函数名，函数体内可以包含任何有效的 Bash 代码。一旦定义了函数，就可以在脚本的其他部分进行调用。 传递参数示例可以通过命令行将参数传递给函数，例如： function_name arg1 arg2 在这里，arg1 和 arg2 是传递给 function_name 函数的参数。这些参数可以在函数内部通过 $1、$2 的方式访问，其中 $1 表示第一个参数，$2 表示第二个参数。举个例子： greet() echo Hello, $1! Welcome to the world of Bash scripting.greet Alice 在这个例子中，当你调用 greet Alice 时，函数将输出 Hello, Alice! Welcome to the world of Bash scripting.。这样，函数不仅封装了代码，还可以根据传入不同的参数表现出不同的行为。 获取返回值示例假设我们有一个计算两个数和的函数： sum() return $(($1 + $2))sum 5 10echo The return value is $? 在这个例子中，sum 函数计算 5 和 10 的和，并将结果作为返回值。然后，通过 echo The return value is $? 我们可以看到函数返回的结果是 0，因为 Bash 只会返回 0-255 的数值。如果你希望在函数中直接输出结果而不是返回它，可以使用 echo，但要知道这和返回值是两个不同的概念。 小结函数是 Bash 脚本中非常重要的组成部分，它们允许你重用代码并组织逻辑。通过函数，你可以处理复杂的任务，只需一次定义，便可多次调用，并且可以灵活地传递参数，从而提高脚本的效率和可读性。掌握函数的使用，能够使你的脚本更具模块化和可维护性。 Shell 脚本各种执行方式在使用 Shell 脚本时，了解不同执行方式的区别非常重要。我们关注的是三种执行脚本的方式：./*.sh、. ./*.sh 和 source ./*.sh。 执行方式的比较1. ./*.sh、sh ./*.sh 和 bash ./*.sh这三种方式本质上是相同的。它们都启动了一个新的子 Shell 进程，在这个子进程中执行脚本。执行后，所有在这个脚本内定义的变量和更改的状态都不会影响到父 Shell。我们可以理解为，子 Shell 就像一个临时的工作环境，操作结束后，它便会消失，带走的只会是自己所做的记录。 示例name=dangxu # 定义一般变量echo $name # 输出：dangxu 接下来，假设在 test.sh 文件内有如下内容： #!/bin/shecho $name # 输出变量内容 执行如下命令： ./test.sh # 输出为空，因为在子 Shell 中没有继承到变量sh ./test.sh # 输出为空bash ./test.sh # 输出为空 可以看到，在这三个命令中，name 变量没有被传递给子 Shell，所以脚本内部输出为空。 2. . ./*.sh 和 source ./*.sh这两种方式是等价的，都是在当前 Shell 进程中执行脚本。与前面的方法不同，当前 Shell 的上下文被保留，变量的定义和状态的改变会在当前环境中生效。 示例我们继续使用之前的 test.sh 内容，在当前 Shell 中运行： . ./test.sh # 这里将输出变量内容：dangxusource ./test.sh # 同样将输出变量内容：dangxu 在这两种执行方式中，因为我们是在当前 Shell 中运行脚本，所以变量 name 的值可以被正确地输出。 验证依据Shell 的机制决定了非环境变量（未使用 export 关键字导出的变量）不会被子 Shell 继承。这一特性是判断脚本执行上下文的关键依据。 验证结果通过下面的命令，我们可以在终端下观察到变量的行为： [root@localhost ~]# name=dangxu # 定义变量[root@localhost ~]# echo $name # 输出：dangxu[root@localhost ~]# cat test.sh # 验证脚本#!/bin/shecho $name # 将输出变量内容 接下来验证文件权限，确保脚本可执行： [root@localhost ~]# ls -l test.sh-rwxr-xr-x 1 root root 23 Feb 6 11:09 test.sh 然后分别执行不同的命令来验证我们的结论： 使用子 Shell 执行： ./test.sh # 输出为空sh ./test.sh # 输出为空bash ./test.sh # 输出为空 在当前 Shell 中执行： . ./test.sh # 输出：dangxusource ./test.sh # 输出：dangxu 最终，我们通过这些实例和验证得出结论，清晰地了解了各种 Shell 脚本执行方式的行为及其区别。这对于日常的 Shell 编程和调试都是至关重要的。","categories":["1.语言","Shell"]},{"title":"Alist网盘搭建","path":"/2024/05/31/0-平台-服务器-工具-Alist网盘搭建/","content":"Alist 备份文件地址 Alist 搭建方案 方案一：云服务器直接搭建及存储 方案二：云服务搭建页面，NAS 需要搭建 webdav，同时需要提供 NAS 穿透方案 方案三：云服务器提供穿透方案 frpCloudflared，NAS 搭建页面和存储 本地搭建仓库地址 https://github.com/alist-org/alist Relaes 地址 https://github.com/alist-org/alist/releases 下载对应版本的 alist 使用，直接解压后按照下述方式运行即可 # 解压下载的文件，得到可执行文件：unzip alist-xxxx.zip# 运行程序.\\alist.exe server 之后访问本地 http://127.0.0.1:5244/ 即可打开 Alist 页面。 Docker 搭建version: 3.3services: alist: #离线下载选择xhofe/alist-aria2:latest image: xhofe/alist:latest container_name: alist volumes: - ./alist_data:/opt/alist/data ports: - 9083:5244 environment: - PUID=0 - PGID=0 - UMASK=022 restart: unless-stopped Alist 启动脚本 VBSDim ws_alistDim ws_frpSet ws_alist = Wscript.CreateObject(Wscript.Shell)ws_alist.run alist.exe server,vbhideSet ws_frp = Wscript.CreateObject(Wscript.Shell)ws_frp.run .\\frpc.exe -c .\\frpc.toml,vbhideWscript.quit 配置本地# 获得管理员信息 以下两个不同版本，新版本也有随机生成和手动设置# 低于v3.25.0版本.\\alist.exe admin# 高于v3.25.0版本# 随机生成一个密码.\\alist.exe admin random# 手动设置一个密码 `NEW_PASSWORD`是指你需要设置的密码.\\alist.exe admin set NEW_PASSWORD dockerAlist 配置存储直接按照 Alist 官方文档配置即可，配置完成后，NAS 利用 CloudSync 套件，添加 WebDav 站点后即可访问。 # 随机生成一个密码docker exec -it alist ./alist admin random# 手动设置一个密码,`NEW_PASSWORD`是指你需要设置的密码docker exec -it alist ./alist admin set NEW_PASSWORD WebDav 配置如果没有单独留路径选项那正常就是在 站点后面添加 /dav 选项，如下所示： 其他 搭建 NAS，192.168.2.100:5000 搭建 Alist，192.168.2.100:5244 Alist 添加夸克网盘移动云盘百度网盘 NAS 中安装 CloudSync，链接到 Alist 的 WebDav，双向同步方案 通过 FRP 透传 NAS 的端口和 WebDav 的端口到外网 如何让 Alist 网盘内不同的文件夹同步","categories":["0.平台","服务器","工具"]},{"title":"NAS相关配置","path":"/2024/05/31/0-平台-NAS-NAS相关配置/","content":"控制面板-网络-设置，设置 DNS 为 223.5.5.5 或者 114.114.114.114 或者 119.29.29.29 配置时间服务器控制面板-高级模式-区域选项，与 NTP 服务器同步：打字填入 ntp1.aliyun.com 或者 time.apple.com 配置 SSH 服务 打开控制面板 选择终端机和 SNMP，启动 SSH 功能，设置端口号 打开 mobaxterm 连接 NAS 的 IP 加上设置的 SSH 端口号 进入终端后输入用户名和密码登录，之后输入 sudo -i 进入 root 用户但是默认 22 端口要改掉，最好在 9000 以上 配置 FRP 自启动编辑 rc.local 添加自启动脚本 #!/bin/shcd /home/ubuntu/frpServer/frp_0.52.3_linux_amd64#按照配置文件启动服务器端./frps -c ./frps.toml 在 NAS 中添加脚本到任务计划 进入控制面板，选择任务计划，选择新增 - 触发的任务 - 用户定义的脚本 编辑任务名称，选择账号为 root，事件为开机，勾选已启动 编辑任务设置，编辑运行命令中的内容为 bash /root/start.sh 确定保存后在该任务上右击，选择运行 猫盘配置 FRP，同步至云服务器 配置 SYNC，同步至夸克移动百度 frp 方案依赖服务器带宽，比较卡","categories":["0.平台","NAS"]},{"title":"3D打印机环境配置","path":"/2024/05/30/3-软件-3D打印-3D打印机环境配置/","content":"3D 打印机3D 打印（3D printing）是一种快速成型技术，也被称为添加制造（Additive Manufacturing，AM）。它是一种通过将材料逐层叠加以构建三维实体物体的过程。与传统的制造方法不同，3D 打印不需要模具或切削工具，而是通过从计算机辅助设计（CAD）模型中生成的数字模型直接创建物体。 FDM（熔融沉积成型）：FDM 是目前最常见的 3D 打印技术，它使用热塑性材料通过打印头喷出的方式逐层堆积，最终形成所需的物体。FDM 打印机的结构和控制系统比较简单，价格也比较实惠，因此广泛应用于家庭、办公室和教育等领域。 SLA（光固化成型）：SLA 使用紫外线激光器或 LED 光源照射光敏树脂，使其逐层固化成为所需的物体。SLA 打印机的精度和表面光滑度比 FDM 更高，但价格也更贵。 SLS（选择性激光烧结）：SLS 使用激光束将热塑性粉末烧结在一起，逐层堆积形成所需的物体。SLS 打印机可以使用多种材料，可以打印出更复杂的结构，但价格也更昂贵。 DLP（数字光处理）：DLP 使用光敏树脂和数字投影仪，通过投影仪将光固化在涂层的树脂上，逐层堆积形成所需的物体。DLP 打印机的速度和精度都比较高，但价格也较贵。 FDM通过将加热的材料挤出打印头，逐层堆积形成打印件 打印头 打印床热床 控制系统（主板、电机、传感器和用户界面） 打印材料 G-Code 一种用于控制数控机床（包括 3D 打印机、数控铣床、数控车床等）运动和操作的编程语言。 结构结构主要分为两部分： 一个负责三维空间的移动的组件 (三维移动部分) 一个负责进料、融化材料和挤出材料的组件（挤出部分） 打印时材料会一层又一层地堆积在之前已经「挤出来」的材料上，所以在这两个组件共同协作下就能打印出一个完成的 3D 物体了。 结构 - 三维移动部分打印机在 3D 的空间运动的传动方式有很多种，一般较为便宜的打印机会选择笛卡尔结构。笛卡尔结构指的是 X Y Z 方向上的运动是独立的，这种方式比较直观，结构也比较简单。常用的 3D 打印机的结构有以下几种： Prusa i3 型：控制 XZ 轴，Y 轴通过工作台的移动来实现。CoreXY 型：CoreXY 最大的特别之处在于其 X、Y 电机是协同运作的，并且它的同步带在不同同步轮的摆放下能够形成多种不一样的缠绕方法。由于两个电机的协同运动，电机带动的力比单一电机的力要大，且会减少在 XY 方向面上的一个电机重量，提高精准性。**CoreXY 结构：CoreXY 结构采用的是两个电机通过传动带和滑块来实现打印头的运动，其中 X 和 Y 轴的传动带交叉布置，使得打印头的运动方向可以在 X 和 Y 轴上独立控制。CoreXY 结构的优点是打印速度快，同时打印头的重量对定位精度的影响较小，同时可以实现较大的打印范围。缺点是结构复杂，需要更多的零件和更高的制造精度，同时维护和升级也较为困难。 Um Ultimaker 型：X 轴、Y 轴的电机都在静止的框架上，但挤出头在两个互相垂直的光轴的交叉处。**UM 结构（Ultimaker 结构）：UM 结构采用的是直线轴承和滑块来实现运动，其中 X 和 Y 轴分别由两个电机驱动，通过传动带和滑块来实现打印头的运动。UM 结构的优点是定位精度高，速度快，同时结构简单，易于维护和升级。缺点是打印头的质量和稳定性对定位精度有较大影响，同时打印头的重量也会影响打印速度。 MB：主要体现在挤出电机一般都装在喷头旁，近程进丝，双光轴承载挤出组件，X 方向的运动一般是通过电机带动同步带，通过带传动使两边一起运动。 delta 三角洲（并联臂）型 结构 - 挤出部分挤出部分分为以下： 挤出头 送料步进电机 送料步进电机驱动板 FDM 3D 打印机除了怎么动的很关键以外，怎么取料、融化材料、挤出材料也非常重要。 其中取料和挤出材料是由挤出机处理的，融化材料则是由热端处理的。 挤出机从材料盘中将材料拉出来，送进去热端融化。 并持续往热端送更多的料让融化的材料从喷嘴中挤出来。 其中挤出机的精度和挤出的速度决定了打印质量和速度。精度高意味着可以更好的控制挤出的量。挤出的材料太多或者太少对打印的质量影响都非常大。挤出的速度快就很直接的决定了你能打印多快。 而影响挤出机的精度和速度的两个关键因素就是： 挤出机的类型 挤出机的齿轮数量 FDM 挤出机分为两个大类： 远端挤出机（鲍登挤出机） 优点 轻量化喷头：由于挤出机和步进电机位于机器外壳，喷头的重量较轻，惯性小，能够实现更高的移动速度（可达 200~300mms），因此适合高速打印。 精准定位：轻量的喷头使得定位更为精准，适合需要高精度的打印任务。 缺点 送料阻力大：由于送料距离较远，材料在特氟龙管中的摩擦阻力较大，要求步进电机具备更大的力矩，增加了电机的负担。 回抽不精准：在高速打印时，远端挤出机的回抽距离和速度要求较大，导致在使用弹性材料时可能出现输送不畅的情况。 维护复杂：由于挤出机与喷头分离，连接部分（如特氟龙管和气动接头）容易出现故障，维护相对复杂。 近端挤出机（直接挤出机） 优点 精准控制：近端挤出机对送料量的控制更为精确，回抽也更为精准，适合高速打印时的细节处理。 低力矩要求：对步进电机的力矩要求相对较低，能够在高速情况下保持稳定的挤出性能。 换料方便：由于结构紧凑，换料过程相对简单，适合频繁更换材料的应用场景。 缺点 重量问题：喷头较重，尤其是在双喷头打印机中，增加了运动时的惯性，可能导致加速和减速困难，从而影响打印精度。 维护不便：喷头、挤出机和步进电机集成在一起，拆装和维护相对不便。 压力影响：较重的喷头对光轴或导轨的压力较大，可能导致长时间使用后出现的调平困难. 另外一个影响挤出机精度的就是挤出机的齿轮了。较低端的机器一般都是配备都是单齿轮，虽然对比双齿轮的挤出机，无论是对材料的咬合能力还是挤出精度都表现更差，但它便宜而且工作，对于预算相对比较紧张的朋友是一个不错的选择。 传动系统传动系统分为以下几个部分： Xyz 步进电机 限位开关 步进电机驱动板 同步带 传动系统是 3D 打印机中负责移动打印头（或喷嘴）和打印平台的机械组件。它在 3D 打印过程中发挥以下作用： 控制位置：传动系统通过精确的运动控制，将打印头定位在正确的位置，以便在每个层次上精确地添加材料。 三维定位：传动系统的运动控制使得打印头可以在 X、Y、Z 三个方向上精确移动，从而实现三维打印。 打印速度：传动系统的运动控制还影响到打印速度。更快的传动系统能够加快打印速度，但需要保持精确性和稳定性，以确保打印质量不受影响。 自动校准：一些高级的传动系统具备自动校准功能，能够自动检测打印平台和打印头的位置，从而保持打印的准确性和稳定性。 加热部分加热部分分为以下： 热床 MOS 管 打印机的热床就是用来承载挤出机挤出来的材料。是 3D 打印机上的一个移动平台，用于支撑正在打印的物体。其主要作用如下： 粘附和稳定：打印平台上的特殊表面或涂层（例如热床、胶水、胶带等）可以提供粘附性，确保打印的第一层材料牢固地附着在平台上，并防止其在打印过程中发生位移或变形。 - 塑料在不同的温度下粘性不一样，控制床的温度可以让不同的塑料在保持形状的同时达到最大的粘性。如果温度太高则有可让打印的形状变形，温度太低则有可能让打印的材料不粘床。床的温度和热端的温度共同决定了可以打印什么材料。如果能顺利融化材料，但是他并不能稳定的黏在床上，打印也会有非常大几率失败。 平整度：打印平台的调平性（平整度）对于打印质量至关重要。如果平台不平整，可能导致打印的物体底部出现变形或不平整的表面。 防止翘曲：特定类型的 3D 打印材料，例如 ABS（丙烯腈 - 丁二烯 - 苯乙烯）等，有时容易在冷却过程中产生翘曲。热床可以在打印过程中加热，有助于减少材料翘曲，提高打印的成功率。 电气系统电气系统分为以下几个模块： 电源 主板（需要烧录固件代码如 Marlin） 显示屏 传感器加热模块等 了解各模块的所需电源电压，功耗等信息选取合适电源 了解打印机的所需功能，进行针对性选择主板 扩展 Octoprint 远程监控模块 3d 打印的成功率和模型文件、材料、切片 gcode 代码、天气、机器等关联，然后只有在打印中才能知道模型有没有出问题，octoprint 连接 Wifi，通过网页端远程摄像头监控进度，同时能够开始和停止打印机的操作。 自动调平 通常机器在几天内调平过一次之后很大几率不用重新调平，但是你对机器的一举一动包括机器自己的老化都会影响热床的位置移动和变形，自动调平模块 3D touch（也有别的）能够让完全手动的调平变成半自动调平。 双 Z 结构 顾名思义就是有两根 Z 轴。 单一的 Z 轴由于在一边容易导致 Z 轴变形造成模型垂直方向变形。同时也可能会让 XY 平面在变形的 Z 轴运动受阻。 双 Z 结构不仅能够减少变形，同时增强 Z 轴的稳定性。 硬件硬件选型硬件采用 MKS Gen L v2.1，固件采用 Klipper pin 口图 硬件相关主要考虑因素: 驱动电机数量（根据 3D 打印机的结构方案确定） 限位开关 风扇控制 挤出头控制 热敏电阻（热床加热棒挤出头） 单下位机方案需要支持屏幕接口 上位机方案需要支持 USB 连接 控制架构目前 3D 打印机的主流架构一般情况下，有以下两种方式： 上位机（运行 fluidd 控制软件）+ 下位机（运行 kilpper 固件）+Web 显示 由于手头上正好有一块 Linux 开发板，所以准备采用上位机方案，局域网部署（OctoPrint 和 Fluidd 二选一安装配置即可。） 下位机（运行 marlin 固件）+ 串口屏显示 优点：只需要一块控制板加上串口屏，不需要上位机控制软件，节约成本 缺点：屏幕小，显示的信息少 固件在 3D 打印机中，固件控制着 3D 打印机的运动和操作。3D 打印机的固件通常是预装在单片机上的，但用户也可以根据需要进行更新和修改，以实现更好的性能和功能。 负责将 G 代码转换为实际的运动和操作，例如将 G 代码中的坐标转换为电机的运动，控制加热器的温度等。 负责处理传感器的输入，例如温度传感器、限位开关等，并根据这些输入控制 3D 打印机的运动和操作。 在 3D 打印领域，主流的固件有以下几种： Marlin：3D 打印机领域最流行的固件之一，因为它具有广泛的硬件支持和强大的功能。Marlin 支持多种传感器和功能，如自动床平衡、断电续打、LCD 屏幕等。Marlin 还提供了一套易于使用的配置文件，可以通过修改这些文件来对 3D 打印机进行高度自定义。由于 Marlin 是开源软件，因此用户可以根据自己的需要进行修改和定制，以实现更好的性能和功能。 Klipper：Klipper 是一款比较新的开源固件，它具有更高的计算能力，可以实现更快的运动和更高的精度。 Repetier：Repetier 是另一款流行的开源固件，它具有类似于 Marlin 的功能和支持。 Smoothie：Smoothie 是一款基于 ARM 处理器的开源固件，它支持多个独立的电机和传感器，并具有良好的可扩展性。 本次机器组装选择的方案是 klipper，可以很方便的直接在上位机修改打印机参数，不需要每次修改参数后重新烧写固件 Klipper 固件配置及烧写Klipper 官方文档 https://www.klipper3d.org/zh/Overview.html ，建议详细阅读，很多参数和问题都有说明，首先获取 klipper 源码 git clone https://github.com/Klipper3d/klipper.git 执行脚本安装一些系统依赖、设置。安装很慢时，可以更换下 pip 的源 pip下载网络问题 ./klipper/scripts/install-ubuntu-22.04.sh 然后配置和构建 elf 文件 cd ~/klipper/make menuconfigmake 需要确定连接到微控制器的串行端口 ls /dev/serial/by-id/*ls /dev/ttyUSB* 可以用命令行或软件工具来刷写固件，刷写时要确保端口没有被占用 sudo service klipper stopmake flash FLASH_DEVICE=/dev/ttyUSB0sudo service klipper start 控制软件上位机主板采用一块手头空余的 Linux 主板，软件采用 FluiddMainsail，如果是上位机的形式，则由运行在上位机的 3D 打印机控制软件来控制 3D 打印机，主要考虑因素: ARM 架构，功耗低（需要长时间工作） USB 接口，连接下位机 网口，局域网 Web 显示打印机控制（可选） 显示屏，本地显示打印机控制（可选） WIFI，可以无线打印（可选） 监控模块，可以远程查看打印情况（可选） 先在 WSL 环境下搭建调试 Fluidd， 适用于 3D 打印机的 Klipper 固件，提供 WEB 页面和控制。 KIAUHKIAUH 全称 Klipper Installation And Update Helper，该脚本可以直接完成所有环境配置。 在通过该脚本进行安装时，需要实时从 github 和 pip 下载文件，由于网络不稳定的情况导致安装失败的，可以下载 klippermoorakerfluidd 等文件后，置于~目录下，并修改 kiauh 中的 scripts 文件夹下的相关脚本，将脚本中的 clone 部分注释，避免网络不稳定导致的错误。pip 部分可以修改 pip 源，稳定下载。 界面如下所示： 执行脚本前需要安装 git sudo apt-get update sudo apt-get install git -y 下载 KIAUH 到本地： git clone https://github.com/dw-0/kiauh.git 执行脚本 ./kiauh/kiauh.sh KIAUH 的主菜单中。您将看到多个操作可供选择，具体取决于您想要执行的操作。要选择操作，只需在“执行操作”提示中输入相应的数字，然后按 ENTER 确认即可。 moonraker选择 1 Install,需要输入密码，之后选择 2 moonraker，安装完成后进入浏览器输入 http://127.0.0.1:7125/server/info 测试 moonraker 是否正常安装。 moonraker 的作用： Moonraker is the API that fluidd communicates with, which in turn communicates with Klipper. All three components are required for a healthy printer. 如果出现 pip 下载速度太慢导致的失败，参阅 pip下载网络问题 无法构建 pillow 和 streaming-form-data 这两个包的轮子（wheels），检查发现是头文件没有导致的错误，将 /usr/include/python3.6 下的所有头文件拷贝至 /usr/include fluidd选择 1 Install 之后选择 4 Fluidd 进行安装，安装完成后访问 http://127.0.0.1 正常打开 fluidd 页面 安装之前进入 kiauh/resources 下，编辑 fluidd 文件可以更改端口。 Mainsail修改 /kiauh/resources/mainsail 中的 80 端口为 9090，安装 mainsail 到 9090 端口 配置打印机配置文件，一般在用户主目录中名为 printer.cfg 的文件 配置文件示例 /home/linux/printer.cfg。 刷写 Klipper 后，名称可能会改变，检查 USB 节点名称： ls /dev/serial/by-id/*或者ls /dev/ttyUSB* 确认节点名称并写入配置文件中去。 /dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0或者/dev/ttyUSB0 用这个唯一的名字更新配置文件。更新 [mcu] 部分，类似于： [mcu]serial: /dev/ttyUSB0 在编辑该文件后，发出 restart 或 FIREWARE_RESTART 命令以重新加载配置（命令根据实际上位机）。如果 Klipper 配置文件被成功读取，并且成功找到并配置了微控制器，那么 “status” 命令将报告打印机已准备就绪。 默认的 Klipper 启动脚本在 /tmp/klippy.log 中放置日志，提供更详细的信息。 WSL 问题解决由于本次安装是在 WSL 中的 Ubuntu 进行安装的，所以有以下两个问题需要解决 1）systemd 中的服务无法启动导致的 moonraker.service 无法运行 Windows 版本要求 (已验证 Win11 22H2) 启动 windows Power Shell，更新 wsl wsl --update 进入 Ubuntu wsl ~ 编辑配置 sudo vi /etc/wsl.conf 添加以下内容 [boot]systemd=true 保存并退出 ubuntu exit 在 windows power shell 中关闭 ubuntu wsl --shutdown 然后重新进入 ubuntu wsl ~ 查询 systemd 服务 sudo systemctl status 2）在 WSL 中无法打开 Windows 的 USB 端口 WSL2 内核要求 5.10.60.1 进入 Ubuntu wsl ~ 查询内核版本 uname -a 退出 Ubuntu exit 安装 usbipd-win winget install usbipd 进入 Ubuntu，安装客户端工具 sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 退出 Ubuntu，添加 USB 设备到 WSL 中去 usbipd wsl list //列出所有连接到Windows的USB设备。usbipd wsl attach --busid //添加USB设备进入Ubuntu，需要管理员权限usbipd wsl detach --busid //停止USB设备共享usbipd wsl attach -a --busid 2-7 // -a 自动绑定 进入 Ubuntu，查看已经连接的 USB 设备 lsusb 配置 udev，允许非 root 用户访问 USB 设备,需要在设备连接前完成该操作。需要将根据自己 USB 设备编写的 60-myusb.rules 文件复制到 /etc/udev/rules.d 嵌入式部署时相关问题部署 3d 打印机环境到开发板，所有环境已部署完毕，目前需要解决的问题点是需要编译 ch341 在 linux 环境下的驱动，驱动内核版本 4.19.204 详见 Linux下的CH34x串口识别 切片软件-Cura 的使用设置打印机长宽高200*200*200mm 打印头孔径 0.4mm 材料直径 1.75mm 配置 Cura 设置可见性可以根据自己在切片时实际需要调整的相关参数进行显示 移动和缩放模型长按鼠标滚轮中键，可平移视角 长按鼠标右键，可旋转视角 滚动鼠标滚轮，可放大缩小视角 选中模型后，在 Cura 的左侧，依次功能为 移动 缩放 旋转 镜像 单一模型设置 支撑拦截器 在相应位置添加方块减少支撑应用右击模型，可进行“复制”、“清空平台”、“居中模型等设置 设置打印参数点击右侧的打印参数设置栏，选择多种模式 质量即层高：数值越小，打印物体表面效果越好，打印时间越长。默认选择 0.15mm 填充打印模型内部的模型密度，默认以网格状的形式填充。默认选择 20% 如果填充率过低，也会有一定程度导致翘边，不同的内部填充图案也可以有效减少翘边。 材料主要设置打印时喷嘴和热床的温度。一般耗材上会写有打印温度。也可通过打印温度塔测试出每种最耗材品牌最佳的打印温度。建议首层温度用 230°C，容易粘床。 打印 PLA，热床的温度建议在 50-60°C。 速度PLA 建议打印速度为 60mms，±20 也在常用速度。 过快步进电机会丢步，按实际情况设置 移动当喷嘴移动到非打印区域上方时回抽耗材 当打印出现拉丝情况，可调整回抽设置。建议回抽距离用 2.0mm，回抽速度用 50mms，加大数值可减少拉丝情况。如果打印过程中喷嘴有碰到打印物的情况，可勾选 Z 轴抬升。 附着加大模型第一层与打印平台的接触面积，增加附着力，让模型在打印过程中更稳固。当打印模型的高度较高，接触面积较小时使用。 skirt 裙边 在打印模型前，在模型外围打印一圈，让喷头里面的出丝比较顺滑,主要用于擦净喷头 brim 在模型的边缘处加上薄薄的一层，防止翘边，适用于打印较高的物体且接触面较小，容易倒塌的时候 raft 底座，在底座上在打印模型，适用于接触面多且复杂的情况 支撑在模型的悬垂部分生成支撑结构，防止模型倒塌。作为入门最难的一个设置。通常角度过大，打印过程中悬空部位则需要添加支撑，否则容易下垂。支撑与模型接触面往往很粗糙，影响模型质量。 支撑悬垂角度越大，需要支撑部位（红色部分）则越小。建议 45-50 间。 添加支撑的最小悬垂角度，当角度为 0 时，将支撑所有悬垂，当角度为 90 度时，不提供任何支持 Cura 提供普通支撑和树型支撑两种选择。 树型支撑对模型影响更小，也节省材料。注意，它只适合于非平面的悬空，如鼻尖，指尖或拱形。对于平面的悬空，树形支撑无法提供足够的稳定性。 正常支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：0支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。支撑 XY 距离：1-1.5mm 树形支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：1连接支撑锯齿形: 勾选支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。支撑 XY 距离：1-1.5 保存和预览点击右下角的切片，等待切片完毕后，可在预览界面预览打印效果、耗材用量及预计用时。拉动最右边进度条，可查看每层打印情况。点击右下角保存 gcode 文件准备打印。 特殊操作 偏好设置”—“基本”—“自动下降模型到打印平台” 假如只想打印一半模型，可解除 Z 轴限制，可使模型下降至负数。切片后只会打印平台上方部分。 3D 打印机问题总结平台上的蓝色纸有什么用处，用到什么程度需要更换？美纹纸，它的作用一是防止刮坏喷嘴，二让模型与平台粘接更稳。 由于打印材料的热胀冷缩效应，当打印大体积模型时，可能会发生翘边现象，建议打印前先贴上蓝色美纹纸，才开始打印。该纸可反复使用，直到破损或者明显粘不住模型为止。 大部分人都在用 PEI 喷涂的钢板作为底面。PEI 的特性是冷的时候不粘，热的时候具有一定的粘性。 新的 PEI 床和旧的自带的床。更换 PEI 后打印 PETG 就非常好用了。等床凉了以后轻轻一拿就可以从床上拿起来了，不像是原来那张床用铲子翘半天。 不过新床目前也是遇到了一些问题，就是打 PLA 没有原来粘了。所以用 PLA 打印第一层得时候需要压得更低一点，才能获得最佳得粘性。 哪些模型要加支撑？如何判断？ 红色位置是需要加支撑的位置，Cura 右侧可以设置支撑的相关参数 调平台这个步骤怎么确保距离调的 ok 呢？喷嘴距离平台距离太远或太近有什么区别？为什么模型打印过程中直接被拖走？ 首先在调节平台之前我们需要先保证 X 轴在丝杆上移动是水平的 喷嘴和平台的距离标准为一张 A4 纸的距离，如果不好判断，塞张纸在平台和喷嘴之间，以正常抽拉并附带阻力为标准； 在不会刮伤平台的前提下，调的越近模型粘的越牢固！ 我们还可以通过模型打印第一层的状态来判断距离是否调好，有以下三种情况： 1、正确的距离：扁平，无间隙，铺在平台上面很平整无毛刺,喷头与热床是最佳距离能保证打印出的耗材被紧压在热床上成平整的带状（扁皮状）。如图所示： 2、不正确的距离：细圆的，粘上去时铺的不均匀，有空隙和翘起，说明距离太远,耗材是靠重力作用垂到热床，形成圆润的条状，其黏附效果不佳，模型容易移动，打印效果非常不理想。如图所示： 3、不正确的距离：出丝时，压在平台上会出现中间薄两边有不规则突起（有毛刺）的，说明贴的太紧，或者可能造成无法出丝以及喷头移动时会刮带到之前打印的地方，相关形状如图所示： 以上情况均可以通过调节热床下方的弹簧来调整。 调节平台需要注意什么？而且每次打印前都需要检查平台吗？ 调节弹簧螺丝时，请注意按住下方的羊角螺母，不然在拧的过程中也会一起转动； 每次调完或检查平台操作后，都必须移动喷嘴在平台上走一圈，确保不会刮伤平台才能进行下一步操作； 虽然不需要您每次在打印前调节平台，但需要以 1 天 1 次作为周期性检查，平台距离合适； 为什么预热后上料？为何我感觉插到底了，下方喷嘴却不出丝？换料的时候需要注意哪些情况？ 上料时，如果喷头没有加热，耗材插到底也不会吐丝，客户就无法判断是否已正常上料，所以必须先预热，再上料！ 在上料时，插入进料口后一段距离感觉已经无法插入，但是喷头下方并没有出丝，因为在耗材在进入进料口后需要穿过挤出轮和压料轮中间后再进入下方喷嘴导料管，在上耗材的时候没有把耗材前段剪尖和捋直，导致耗材插入时没能直接进入下方导料口而被旁边阻挡，如图： 正确上料步骤：预热—剪尖并捋直耗材—下压螺丝—笔直插入耗材—出丝 每次打模型前都需要预热吗？提前预热的情况只有在进行换料前才需要提前预热，正常打印时，您只需要选择打印的模型文件即可自动加热； 模型打印过程中停电了能否继续打印？如果停电了模型直接终止打印，下次开机无法延续打印（但可以通过测量已打印高度，仅将未打印的部分切片进行打印，再粘上，仅适合非精密零件模型） 那中途可以暂停再继续打吗？看机器是否有设计暂停打印功能 在打印时暂停喷嘴依旧处于加热状态，耗材因重力作用会下垂流出，影响模型外观； 中途耗材用完怎么办？ 首先模型在软件进行切片转换格式的时候就会显示所需打印的时间，耗材长度以及重量，那您需要判断机器上余下的耗材能否支持本次打印完成，避免中途打印耗材用完； 若碰到耗材中途快用完，请在耗材还没进入进料口的时候及时的进行暂停，并迅速拔出剩余耗材，将新的耗材插入至喉管的深度即可 每次打完需要将耗材取出来做排空处理吗？不是，距离下次打印超过 72 小时，则需要排空处理； 喷头需要定期清理吗？需要！ 挤出头加热到指定温度后用最小号的内六角螺丝刀，压下进料弹簧，插入进料口，往下挤压，挤压的时候扳手插慢慢插到底时，来回挤压三次，扳手回抽不要过急或过长，插进去后小幅度的在里面挤压三次即可，再迅速拔出，空烧 1 分钟左右注意观察下方是否有东西流出，流完或没东西流出一分钟后请用我们配送的小捅针，从下方喷嘴插入，抽拉三次没东西流出即可；最后一步，请弄根新耗材，插入到底向下挤压出丝后猛的迅速拔出，尽量带出内壁附着物即可； 模型刚开始打印第一层就不出丝，怎么回事？如果这种情况发生在您刚才有换过耗材的情况下，那您需要确定耗材已上到底，并出丝；确保喷嘴是否顶到平台，导致无间隙空间吐丝； 打出来的模型很脆，外壁像网丝状，很脆，一捏就瘪了？此情况属于出丝量很小，需要检查以下几点： 拉料正常，料盘上的耗材没有打结等缠住现象； 耗材在进入导料管与喷嘴（加热管喉管）之前，要穿过一个 u 型轮和挤出电机齿轮中间，u 型轮压住耗材让齿轮把耗材往下挤送，u 型轮压住耗材的力量是由旁边的六角螺钉顶着弹簧的力度来决定的，螺丝扭紧弹簧弹性越大，u 型轮压料就越紧，反之越松， 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 齿轮本身带动耗材挤压也有许多因素，耗材从上往下经过齿轮的时候是否有在齿轮的中间，如果齿轮脱位，耗材在齿轮的牙边下去的，可能出现带不动耗材往下的情况而出丝不顺 模型打印时，突然在某一层高处整体向 X（左右）Y（前后）方向偏移？首先需要确定机器传动系统问题，再来排除软件参数和主板固件问题，排除方法如下： 首先需要判断你的模型摆放在平台上时，偏移的方向是 x（横向）还是 y（纵向），然后我们需要检查对应的 xy 轴的传动系统是否正常，第一先检查皮带是否松动脱落；第二检查同步轮固定螺丝是否松动 ① 带松动加紧： 首先，如果是 X 轴皮带松动，必须拉紧至绷紧状态，切平行； ②同步轮松动：Y 轴传动系统同步轮和 X 轴同步轮都需要检查到； 排除完机器问题，建议看下软件参数是否存在问题 例如检查是否是电机运动速度过快或出现阻碍导致的丢步 以上两点排除完毕，需要对主板固件程序进行重新烧录来解决问题 打印模型过程中中间断了几层，但是上面打印还可以？为什么模型突然中途就不出丝，喷嘴一直在空走打印不出丝？这几种问题都属于前期能正常打，但是中途不出丝的情况，这种情况需要从以下几点判断： 挤出电机接线口处四针排线松动，导致电机挤出齿轮来回正反转，耗材送不下去； 打印不出丝时，可以从电机右侧方弹簧方向往里面看到齿轮转到情况，如果齿轮来回摆动不定，说明接线出有问题，将接线拔掉重新插入尝试即可； 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 耗材在料盘上缠住，导致进料不顺,检查料盘的耗材缠绕是否有拉扯住 喷嘴可能有残料堵塞,可以把喷头首先预热 230，一手按住进料口旁螺丝，一手快速挤压耗材（多送点丝），再迅速拔出，然后让喷嘴空烧一会儿，直到有黑色物质从喷嘴里流出，然后用钢丝从喷嘴端插入，抽拉，拔出，让里面剩余的耗材掉出，重复抽拉动作，直到喷嘴没料自然流出为止，最后上料，重新打印； 为什么打印模型在中途过程中，喷嘴周边缠着很多耗材，模型变成一团乱丝，不成形？这种情况分两种： 刚开始打印阶段，此情况一般是喷嘴和平台之间的距离过远，喷嘴出丝无法粘住平台，就会被喷嘴带走并一直出丝形成一坨； 打印过程中出丝不均匀，有断层现象，打印模型比实际高度低，超过一定间隙距离后出料正常是没附着下面的模型上面就会缠成一坨； 打印过程中喷嘴突然停止在打印模型上方不打印，并未回原点，怎么回事？ 切片问题,重新切片打印测试 内存卡松及读取问题 主板固件问题 为什么把模型保存在卡里是显示 ok，但插入机器后选择模型打印后不加热也没反应？为什么 SD 卡在电脑读取正常放入机器缺显示无卡？一般由于保存文件时的文件名上，切片完成后进行保存时文件名请使用英文字母或数字. 为什么 SD 卡在电脑读取正常放入机器缺显示无卡？这种问题首先要排除卡和卡槽是否正常配合，保证卡和卡槽读取正常，如果重新插入还是无法读取，可用您身边的内存卡保存文件插入机器是否能正常读取 为什么选择模型打印，机器没任何反应？或者加热了很久但是不打印？这种情况可能喷嘴冷却风扇提前开启，导致实际温度和设置温度总有 1-2 度差距，导致无法打印，请您选择停止打印并关掉风扇开关后，重新选择打印模型即可； 宽度 5mm 高度 6mm 的字体打得出来不,类似这种小模型需要修改哪些参数呢？小模型打印需要将速度和挤出量降低，模型可以打得更好看。比如打 5mm 左右的字体，可以采用 22 左右的速度配合 85 的挤出量来进行切片打印，温度采用 190 左右的即溶温度即可，这适合小模型打印哦； 为什么在打印模型时，某个位置会剧烈振动，机器声音很大？这种位置一般是模型实体部分的填充，特别是交窄的壁厚，填充为波浪形，打印速度很快的时候 xy 配合产生共振引起的 为什么在打印很大模型例如 190*190*180 和平台尺寸相近的模型时，喷头移动到某个方向极限值时，会有振动然后再改方向进行移动呢？打印前，喷嘴会在模型周围打一圈进行排空出料的操作，这样的话就实际增加了大模型的成型空间，导致直接碰到机箱，可以把此设置关掉即可 查看切片时是否有裙边设置 打印模型经常翘边问题怎么解决？PLA 与 ABS 通用原因： 喷嘴距离与平台太远，没能充分贴紧平台 模型与热床接触面积太小，导致附着力不够 解决办法：可增加 brim 或者 raft 垫子 ；打印 ABS 的话 Brim 效果更理想； 打印 ABS 时开了散热风扇。 解决办法：在打印是进入主界面的控制 – 温度 – 风扇速度 Bed 中由最高转速 255 改成 100 减少冷却效果，直接关闭风扇开关效果更理想； - 挤出头或热床温度不合适，挤出头温度不够可能导致挤出的材料流动性不够，无法完美的平铺在热床上，影响其粘滞力。热床温度过高也可能导致翘边，原因是材料受热流动性变大，不能稳固黏在热床上。 - 热床表面不干净。手的汗与油粘在胶带上，表面上看不见，但也导致表面打滑，影响黏附效果。这种情况在湿度大的南方比较常见。 ABS 材料很特殊因为它有一定的收缩率，打印较大的物体时，效果更佳明显，整体收缩导致底面翘起。最好能配合洞洞板。 显示屏下方显示 Err 报错，挤出头热床温度温度显示不正常？喷头上热敏电阻的接触不良或者损坏了 拆下热敏电阻，若是接触不良，则重新拔插接好；若是线的焊点脱落，用电烙铁焊好否则易损坏电阻；若是损坏，则更换新的热敏电阻。注：固定线时螺丝不宜拧过紧 这个黑色螺丝拧松，热敏电阻取出来，同时热敏电阻线也从主板上拔下来，用万用表测一下阻值，80-100K 正常 打完第一层，打印头在左边，要打上面一层的时候，打印头不是要回到右边的吗，回去的时候就会刮在之前打印的第一层上并留下一条线呢？那是距离平台过近，会刮到上一层打印的耗材 平台距离喷嘴近有利于粘住平台，不会翘边; 会轻微刮到上一层打印模型，但不影响模型成型过程，最多挂点料在喷嘴上挂着，然后在掉下来 模型平面上字体打出来效果不好怎么办？如果字写在模型上，此情况可以将模型竖起来打，层厚 0.1 能更为细腻的打出字体； 为什么从绘图软件里导出来的模型放在 cura 里显示不规整，弧面都是棱面组成的？在绘图软件里导出 stl 的时候会有二进制和 ASCⅡ，通常选择二进制并将角度和弦值设置默认最小值，但在 maya 等一些软件里，文件导出的时候 stl 格式是默认设置的，这是软件的特性，但是这个默认数值会随着你文件的建模时的网格细腻程度增加，也就是说文件平滑原本是一倍的，现在加到三倍导出来的 STL 就会比一倍的细腻很多 调试机器时选择自动丝出来都不是直的，是弯曲的?如果出丝是弯曲的 挤出量有关；挤出量一般由温度以及进料口旁边的螺丝松紧度有关，需要检查进料口旁边的螺丝 温度原因，1.风扇吹的 2.温度可以适当加高到 200 度左右 温度总是上不去或者不稳定？ 挤出头的热敏感应件没固定好在铝块里，打印的时候易松，导致探温不准； 导风嘴冷却风扇的风是吹到喷嘴下方的模型，如果没有调好就会吹到 喷嘴，导致温度下降； 如果出现以下情况是怎么导致？ 挤出齿轮底部缠料，一般是由此部位温度过高引起耗材变软，送丝过程中导致齿轮下部耗材折断而缠住； 遇到此情况首先需检查电机前方的方形冷却风扇是否工作以及叶片是否完整，避免冷却不够而导致堵料； 请检查耗材是否长时间未密封保存而变脆，取一段从中间这段，若折后显白痕且有韧性即正常，若折后直接啪的应声而断即已变脆； X 轴架构在 Z 轴电机丝杆控制上下过程中，会导致一边高一边低，每次都需要重新调节平台高度呢？ x 轴本身没有平衡，在移动过程中反应更明显； 请解决 X 轴调平问题； 黄色 T 型螺母太紧，导致 T 型螺母与丝杆紧配受力不均匀，移动不顺畅； 将固定 T 型螺母上的螺丝不要拧紧，留半个螺纹的缝隙，给予缓冲，再将 x 轴调至平衡，移动 z 轴电机调试！ x 轴光杆太长，没有完全捅到底去，顶住丝杆，导致移动不顺 检查光杆插入深度； 将 Z 轴两边的两个光杆去掉，控制电机上升是否正常，排除光杆弯曲配合滑动轴承配合不顺问题（可以单独将光杆插入滑动轴承，上下移动是否顺滑） 更换光杆或者滑动轴承 以上问题都检查后就可能: 移动不顺畅的丝杆部分弯曲或者螺纹损伤，更换丝杆 在更新固件后，挤出电机齿轮检测出反转，无法正常下料 固件中电机引脚配置反了 拔出挤出电机后端电机线接口，按照现在正常 1234 线序，把其中‘一组’12 对调或者 34 对掉即可 如果模型摆放在软件里为中心点，但在实际打印过程中并不在平台中间；因为机器喷嘴回原点的时候并不在热床平台上方而是在外面，而 cura 软件的机器设置里原点就在平台某个角的正上方，为了补偿原点所在误差，需要将软件的平台设置扩大，才能让模型打印在正中间，如图操作更改即可： 加热后拔料感觉扯不出来，也无法下压了铝块融化处剩余耗材口径较大，加热后直接上拉耗材，易堵在口径较小的喉管处，并迅速冷却，以至堵塞喉管 预热达到温度后，一只手按住进料口旁边的螺丝，另一只手将耗材往下挤压，让前端耗材挤出一段距离后，再迅速拔出耗材即可避免堵塞喉管 选择自动回原点时，当喷头移动至限位开关的时候，电机一直不停的往前走，撞击限位开关并抖动，这是怎么回事？ 您需要检查在部件回原点触碰到限位开关之前是否有东西挡住它前进才无法触碰到限位开关而不停止运动； - 可能是限位开关坏了导致的，检查方法是将每个轴的移动部件移至轴中部，选择自动回原点，在部件向原点限位开关移动的过程中，请按住限位开关，观察部件是否停止移动，如果没有停止，请马上切断电源，基本上可以确定限位开关问题 为什么 X 轴上的喷头在移动过程中，一顿一顿的，特别是在回原点的时候，移动时几乎在抖动很不顺畅？ 排除下电机线与电机的问题：拆卸底板：需要用万用表检查 x 轴四根电机线是否都是通路，如果正常就是电机本身问题； 可以断电后手动运动下挤出头，是否丝杆或滑块中的钢珠生锈导致运动不流畅 超出打印范围安装软件的时候初始设置选择错误机型导致的，重新设置机型即可 不粘床，找平 自动找平后，但有的时候打印出来的第一层还是和床粘的不紧密 Z Offset 设置也会影响粘不粘床。 其中白色部分为压力传感器（BLTouch），右边蓝色硅胶罩下面的为喷头 可以看到左边白色的压力传感器的高度和右边蓝色硅胶套下面的喷嘴是不在一个高度的。设置喷嘴和床之前的距离是以压力传感器的反馈为准的。但是压力传感器测到的距离是传感器本身到床的距离，并不是喷嘴到床的距离。所以压力传感器到喷嘴之间的高度差就是 Z Offset，需要通过调整它来设置合适的喷嘴高度。 手动调平 需要用到一张纸，一般打印用的 A4 即可。 然后在床的中点进行 Z Offset 调整，在四个角落（螺丝位置）手动调整床的高低。具体步骤如下： 中点 Z-Offset 调整 首先通过控制面板将喷嘴移动到床的中间的正上方，接下来将纸放喷嘴下方的床上，紧接着慢慢将 Z 轴的高度降低到 0（如果降不下去不要硬来），喷嘴可能会压住纸或者没碰到纸；尝试前后不停的移动纸张。 如果纸张能移动并且刚好有一点阻力就是合适的喷嘴高度不需要调节，通常而言不会那么顺利；如果如果喷嘴完全没碰到纸张，或者纸张移动完全没有任何阻力，可以尝试通过调整 Z-Offset ，一点点降低喷嘴高度。直到达到上述的移动纸张有一点点阻力的状态；如果纸张被压的很死无法动弹，则先将 Z 轴升高到 5mm 然后尝试调整 Z-Offset 升高喷嘴，然后再继续尝试慢慢降低 Z 轴到 0mm，反复调整直到移动纸张有一点点阻力的状态。 使用一张纸来手动找到喷头合适高度的方法。但是这个能移动但是有一点点阻力状态有点模糊，它并不是一个固定的点，是一段区间内都可以感觉到能移动但是有摩擦力。我建议是选摩擦力稍微轻一点的力度的点，这样喷嘴高度较高，后面调整的时候不容易刮伤床上的底板。 四周螺丝调整 在中间确定了最基本的 Z 轴的高度之后则需要物理调整四周的螺丝了，调整四周的螺丝需要按照顺序一个一个的调整，并且需要多次调整和确认，具体步骤如下： 首先抬起 Z 轴让喷嘴距离床大概 5mm 的距离，再移动到任意一个距离调整螺母的正上方，将纸放在喷嘴正下方的床上，紧接着一点点尝试往下移动 Z 轴到 0mm，和上面一样如果降不下去不要硬来；接下来就和上面一样，尝试移动不停的前后移动纸张，如果处于能移动但是有摩擦力的状态则是合适的，如果完全没碰到纸张，在移动纸张的同时旋转下方的螺丝来物理调节这个角落的高度，直到纸张处于能移动但是有摩擦力的状态。最后将 Z 抬起到 5mm 左右，顺逆时针移动到下一个调节螺母的上方，重复以上步骤。 上面步骤是单个角落手动物理调整床高度的方法，完成四个点（上图的床只有四个螺丝，有几个螺丝就校准几个点）为一个循环。因为打印机的床是一个固体，所以当你上下移动某一个角落的高度的时候另外三个角落的高低也是会受到影响的，尤其是相邻的两个角落。所以这里需要多个循环来拧螺丝调整各个角落的高度，直到四个角落的高度都合适的情况，即为纸张能移动但是有阻力的状态。 在拧玩螺丝校准完四个角落的高度后，需要再次通过 Z-Offset 校准中间喷嘴的高度。因为在调整四角的螺丝的时候可能会整体抬高或者降低了床的高度，所以中间的喷嘴高度需要再一次校准。重复上面中点 Z-Offset 校准即可。 如果固件自带自动找平还是比较简单的，选择自动找平等就好了。虽然手动找平完之后床基本上是处于可以用的状态了，但是便宜的桌面打印机的床它本身可能就是凹凸不平的，所以需要自动找平来弥补床本身的凹凸起伏的部分。如果没有自动找平的打印机就没有太好的办法避免这个了。只能通过稍微压低一点点喷嘴来做到尽量都粘到床。 测试调平是否成功 在做完上述的调整后就可以进行最终的调整了。这一步是通过打印一些模型来确认喷嘴的高度是否合适。 虽然用纸调整好了喷嘴的高度，但是纸有薄有厚，调整出来的喷嘴高度并不一定是最好的打印高度，所以最终还是需要通过打印来调整。 打印测试时尽量选择有颜色的材料，透明透明材料会看不清楚第一层有没有打好，在打印模型的时候，手需要在电源附近随时待命。在喷嘴高度设置错误或者床不平的时能及时停止打印机降低损失。 打印出来的模型主要是用来检查喷嘴的高度和床是否倾斜的，四周的圆柱和绕场一周的线条用来检查床的倾斜度。 外围线条如果高低不平均，薄的那边就是较高的地方，厚的那边则是较低的地方。四角的圆柱则可以和上述的 Raise 3D 的示意图来比较确认喷头的高度是否合适。如果不合适可能需要重新手动找平。中间的圆形是确认喷嘴高度用的。同样通过对比来观察高度是否合适，如果床并没有很严重的倾斜，则只需要调整 Z-Offset 来移动喷嘴。然后重新打印确认。如果确认床有倾斜，就要重新走一遍手动找平的流程的了，然后重新打印确认。 当然找平也不是一定完美的。但是有自动找平后，整个过程还是比较简单的。但是也有无论怎么调整，都觉得床有倾斜或者高度不对的时候。这里就要分两种情况讨论了。如果能正常打印不想折腾了就选一个能调整到的最好的状态直接用吧。如果严重到了无法打印的程度，则需要检查打印的装配是不是有问题了。 过度挤出 打印出来的东西都有奇怪的纹理。而且质量也参差不齐。 检查之后是 klipper 配置里面的挤出机的「roration_distance」配错了。导致挤出机往外挤的时候给了远比正常情况多的料，进而溢出到边缘产生了神奇的纹理。 Klipper 配置里面的挤出机转一圈挤多少料这些东西都需要自己配置。所以配置挤出参数时是需要校准的，当你给指令让他挤 100mm 的材料的时候，他应该就挤出来 100mm 左右的材料。没有校准所以导致了非常严重的过度挤出，配置正确后打印的东西表面的问题就漂亮多了。 正常挤出打印的零件的表面质感 材料与环境湿度由于 FDM 3D 打印件一般都需要将材料加热到 200 摄氏度或以上的温度才能打印，所以当材料通过热端的时候，其中的水蒸气会蒸发出来，造成喷嘴里面的材料有间隙，这些现象还会造成打印件在物理特性上的改变： 水汽膨胀造成挤出原料不均匀导致的表面粗糙 水汽膨胀造成材料之间有很多空隙导致的强度下降 水汽膨胀喷嘴中黏在一块的材料有缝隙，导致拉丝。 材料均需要密封干燥保存！买干燥盒 主要成分简称 推荐打印喷嘴温度 推荐打印床温度 特点 PLA 190˚C – 230˚C 25˚C-60˚C 易受潮 TPU 200˚C – 210˚C 50˚C 易拉丝 PETG 230˚C – 240˚C 70˚C – 80˚C ABS 245˚C – 265˚C 90˚C – 100˚C 有毒 ASA 240˚C – 260˚C 75˚C – 95˚C PC 250˚C – 270˚C 90˚C – 105˚C PA6 250˚C – 270˚C 25˚C – 50˚C PA6-CF 280˚C – 300˚C 25˚C – 50˚C","categories":["3.软件","3D打印"]},{"title":"CANOpenNode 代码分析","path":"/2024/05/28/2-通讯协议-CAN-CANOpenNode-代码分析/","content":"主文件 CO_main_basic.c进入 Main 函数中运行，最开始都是一些关于存储多线程功能启用部分的配置代码，后面我们会根据宏定义来讲解。实际的第一行初始化代码从以下开始。 uint32_t heapMemoryUsed = 0;CO_config_t *config_ptr = NULL;CO = CO_new(config_ptr, heapMemoryUsed); 该函数的作用是创建一个 CAN open 对象，在单个 OD 的情况下，config 应为 NULL，参数从默认的 “OD.h “文件中获取。如果定义了 CO_USE_GLOBALS，那么函数将为所有 CANopenNode 对象使用全局静态变量。否则，它将从堆中分配所有对象。 CO_epoll_t epMain;err = CO_epoll_create(epMain, MAIN_THREAD_INTERVAL_US); 该函数创建 Linux epoll 监控 timerfd 和 eventfd。创建并配置多个 Linux 通知，以触发任务的执行。CO_epoll_create 中实现了 epoll 拦截并监控多个文件描述符，其中 timerfd 以恒定的定时器间隔触发，eventfd 则根据外部信号触发。 CO_CANptrSocketCan_t CANptr = 0;CANptr.can_ifindex = if_nametoindex(can0);CANptr.epoll_fd = epMain.epoll_fd; 设置用于 CO_CANinit 的指针参数，主要传入 CAN 设备名和监控的 epoll 描述符。 之后进入 CAN open 通讯初始化阶段，注意该阶段是可以通过 0x82 命令，即 CANopen communication reset 重置的。 CO_CANsetConfigurationMode((void *)CANptr);CO_CANmodule_disable(CO-CANmodule); 进入 CAN 配置，主要还是在通过 0x82 命令重启后，禁用 CANmodule 模块。 err = CO_CANinit(CO, (void *)CANptr, 0 /* bit rate not used */); 初始化 CAN 驱动，如果是通过 0x82 命令重启的通讯，也必须重新初始化。其中的波特率参数在 Linux 部分中还不被支持。之后是 LSS 部分的初始化，该部分内容属于 CiA 305，先略过，之后有时间在分析实现。 #define NMT_CONTROL \\ CO_NMT_STARTUP_TO_OPERATIONAL \\ | CO_NMT_ERR_ON_ERR_REG \\ | CO_ERR_REG_GENERIC_ERR \\ | CO_ERR_REG_COMMUNICATION err = CO_CANopenInit(CO, /* CANopen object */ NULL, /* alternate NMT */ NULL, /* alternate em */ OD, /* Object dictionary */ NULL, /* Optional OD_statusBits */ NMT_CONTROL, /* CO_NMT_control_t */ 500, /* firstHBTime_ms */ 1000, /* SDOserverTimeoutTime_ms */ 500, /* SDOclientTimeoutTime_ms */ false, /* SDOclientBlockTransfer */ CO_activeNodeId, //Node ID errInfo); 初始化除 PDO 对象外的 CAN open 通讯协议（同样也必须在 0x82 命令后调用）。 CO CANopen 对象。 em 紧急对象，用于不同的 CANopen 对象内部，通常用于错误报告。如果为空，则使用 co-em。如果为空，且 co-CNT_EM 为 0，则函数错误返回。 NMT 如果 co-CNT_NMT 为 0，则必须指定该对象；如果 co-CNT_NMT 为 1，则该对象将被忽略，可以为 NULL。NMT 对象用于 NMT 对象用于在 CO_process()内部检索 NMT 内部状态。 od CANopen 对象字典。之前有提到的 ODxyz.h 中定义。 OD_statusBits 传递给 CO_EM_init() 的参数。可以为空。 NMTcontrol 传递给 CO_NMT_init() 的参数。 firstHBTime_ms 传递给 CO_NMT_init() 的参数。 SDOserverTimeoutTime_ms 传递给 CO_SDOserver_init() 的参数。 SDOclientTimeoutTime_ms SDO 客户端的默认超时时间毫秒，一般为 500。 SDOclientBlockTransfer 如果为 “true”，则默认在 SDO 客户端设置块传输。 nodeId CANopen 节点 ID（1 … 127）或 0xFF（未配置）。在 CANopen 初始化中，它与 CO_LSSinit() 中的 pendingBitRate 相同。如果为未配置，则某些 CANopen 对象将不会被初始化或处理。 errInfo 也可以在函数返回 CO_ERROR_NO 的非关键错误中设置。 成功时返回 CO_ERROR_NO。 CO_epoll_initCANopenMain(epMain, CO); 该函数用于配置 CAN 接收后的自定义回调。自定义回调函数可由应用程序选择性注册，并在操作系统中配置线程。回调函数会在高优先级线程预处理完某些内容后调用，并且必须由低优先级线程进一步处理。例如，当接收到 CAN 报文并进行预处理后，回调应唤醒主线程处理函数。 CO_EM_initCallbackRx(CO-em, EmergencyRxCallback);CO_NMT_initCallbackChanged(CO-NMT, NmtChangedCallback);CO_HBconsumer_initCallbackNmtChanged(CO-HBcons, 0, NULL, HeartbeatNmtChangedCallback); CO_EM_initCallbackRx，初始化 Emergency 接收回调函数。该函数在收到错误条件后执行。 CO_NMT_initCallbackChanged，初始化 NMT 状态变化回调函数。该函数在 NMT 状态发生变化后被调用。该函数可能会唤醒处理 NMT 事件的外部任务。第一次调用会立即向消费者提供 当前的 NMT 状态。 CO_HBconsumer_initCallbackNmtChanged，初始化心跳消费者 NMT 更改回调函数，当 NMT 状态发生变化时调用的回调函数。 CO_TIME_set(CO-TIME, time_ms, time_days, TIME_STAMP_INTERVAL_MS); 设置当前时间，并设置生产者的间隔时间为 TIME_STAMP_INTERVAL_MS，以毫秒为单位，此处设置为 10000ms。 err = CO_CANopenInitPDO(CO, /* CANopen object */ CO-em, /* emergency object */ OD, /* Object dictionary */ CO_activeNodeId, errInfo); 必须在通信重置 0x82 部分的末尾调用该函数，否则某些 OD 变量将无法正确映射到 PDO 中。函数参数就是 CAN Open 对象，EM 对象，OD 对象，NodeID 以及错误信息这些。 CO_CANsetNormalMode(CO-CANmodule); 已完成所有对象初始化，设置状态，准备进入主循环函数。在主循环函数中，通过 epoll 监控多个文件描述符。 CO_epoll_wait(epMain);CO_epoll_processRT(epMain, CO, false);CO_epoll_processMain(epMain, CO, GATEWAY_ENABLE, reset);CO_epoll_processLast(epMain); CO_epoll_wait 函数会阻塞，直到 epoll 上注册了以下事件：timerfd、eventfd 或应用程序指定的事件。函数还会计算自上次调用以来的 timeDifference_us 并准备 timerNext_us。 CO_epoll_processLast，epoll 事件的关闭函数，此函数必须在 CO_epoll_wait() 之后调用。在它们之间是应用程序指定的处理函数，可以检查自己的事件并进行处理。应用程序还可以降低 timerNext_us 变量的值。如果将 timerNext_us 变量调低，则将重新配置间隔定时器，并提前触发 CO_epoll_wait()。 CO_epoll_processRT 和 CO_epoll_processMain 指定了处理函数，接下来先说明 CO_epoll_processRT 处理函数。 //CO_CANrxFromEpoll 如果 epoll 事件与任何 CAN 接口匹配，则返回 True。CO_CANrxFromEpoll(co-CANmodule, ep-ev, NULL, NULL);syncWas = CO_process_SYNC(co, ep-timeDifference_us,pTimerNext_us);CO_process_RPDO(co, syncWas, ep-timeDifference_us,pTimerNext_us);CO_process_TPDO(co, syncWas, ep-timeDifference_us,pTimerNext_us); 在 CO_epoll_processRT 中处理以上的 SYNCTPDORPDO 协议。 CO_CANmodule_process(co-CANmodule);CO_EM_process(co-em, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_NMT_process(co-NMT,NMTstate,timeDifference_us,timerNext_us);CO_SDOserver_process(co-SDOserver[i], NMTisPreOrOperational, timeDifference_us,timerNext_us);CO_HBconsumer_process(co-HBcons, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_TIME_process(co-TIME, NMTisPreOrOperational, timeDifference_us); 在 CO_epoll_processMain 中处理了以上的 EMNMTSDOServerHBTIME 协议。 CO_SINGLE_THREAD该参数在 Makefile 中通过-D 参数指定，作用是配置程序在单线程中运行。单线程运行时不同的事件（例如 CAN 接收或计时器到期）会触发循环通过堆栈（所有代码都是非阻塞的）。它需要较少的系统资源。 在多线程操作中，除了主线线程外，还建立了一个实时线程。RT 线程每毫秒运行一次，并使用外围设备读写、控制程序或类似程序处理 PDO 和可选应用程序代码。使用此配置必须考虑竞争条件，例如，从主线线程运行的应用程序代码在访问 OD 变量时必须使用 CO_(UN)LOCK_OD 宏。 CO_CONFIG_STORAGE该参数由 CO_CONFIG_STORAGE_ENABLE 在 CO_config.h 中使能，主要作用是依据 CiA 301 标准对控制数据进行存储和恢复。数据源通常是对象字典中的一组变量，但并不局限于 OD。在生成对象字典（OD.h 和 OD.c 文件）时，会根据 “存储组 “参数将 OD 变量分组为结构。 OD 对象 0x1010 - 存储参数OD 对象 0x1010 - 存储参数： 子索引 0：支持的最高子索引 子索引 1：保存所有参数，UNSIGNED32 子索引 2：保存通信参数，UNSIGNED32 子索引 3：保存应用参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其存储功能的信息： 位 0：如果设置，CANopen 设备根据命令保存参数 位 1：如果设置，CANopen 设备自主保存参数 写入值 0x65766173（’s’、’a’、’v’、’e’，从 LSB 到 MSB）可存储相应数据。相应数据。 OD 对象 0x1011 - 恢复默认参数 子索引 0：支持的最高子索引 子索引 1：恢复所有默认参数，UNSIGNED32 子索引 2：恢复通信默认参数，UNSIGNED32 子索引 3：恢复应用程序默认参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其恢复能力的信息： 位 0：如果设置，CANopen 设备恢复参数 写入值 0x64616F6C（’l’、’o’、’a’、’d’从 LSB 到 MSB）可恢复相应数据。相应数据。 CO_CONFIG_GTW网关对象由标准 CiA 309 - CANopen 从其他网络访问涵盖。它可以将 NMT 主站、SDO 客户端和 LSS 主站用作网关设备。 本次使用中不支持该形式，直接在 CO_config.h 中注释掉该模块即可。 数据字典 OD 操纵CANopen 数据字典 OD 基本上是一个 XML 文件，其中包含 CANopen 设备的所有信息。文件的大部分是所有对象字典变量的列表，其中包含所有必要的属性和文档。该文件可使用 OD 编辑器应用程序进行编辑，并可用作数据源，从中生成 CANopenNode 的对象字典。该文件还可用于 CANopen 配置工具，在运行的 CANopen 网络上与 CANopen 设备进行交互。 CANopen 还为 CANopen 设备描述指定了另一种类型的文件。它们是 INI 格式的 EDS 文件。可以在这两种格式之间进行转换。设备描述文件的扩展名为 “XDD”。该文件的名称应包含 CANopen 设备的供应商 ID，以 8 位十六进制数字的形式出现在名称的任意位置，并用下划线分隔。例如 “name1_12345678_name2.XDD”。CANopenNode 包含多个配置文件定义文件，每个 CANopen 对象一个。这些文件的扩展名为 “XPD”。它们采用与 XDD 文件相同的 XML 格式。XML 编辑工具可以使用 XPD 文件将准备好的数据插入正在编辑的设备描述文件 (XDD)。还有扩展名为 “XDC “的设备配置文件。这些文件描述了已配置的 CANopen 设备，并包含其他元素，如默认值、分母和设备调试元素。类似于 INI 格式的 “dcf “文件。 使用OD object是指对象字典中位于特定 16 位索引的对象。CANopen 中有不同类型的 OD 对象：变量、数组和记录（结构）。每个 OD 对象都包含指向实际数据、数据长度和属性的指针。在 OD_objectTypes_t 中被定义。 OD variable 是指定类型的基本变量。例如：int8_t、uint32_t、float64_t……或数据长度已知或未知的二进制数据序列。每个 OD 变量都以指定的 16 位索引和 8 位子索引存在于对象字典中。 OD entry指的是结构元素，其中包含 OD 对象的一些基本属性、OD 对象的类型指示以及指向 OD 对象所有必要数据的指针。OD 条目数组以及 OD 条目总数信息代表 CANopenNode 内部定义的对象字典。参见 OD_entry_t 和 OD_t。 应用程序和堆栈可通过通用的 OD_t 对象和 OD_find() 函数访问 OD 对象。无需直接访问定义对象字典的自定义结构。特定 OD 变量的属性可通过 OD_getSub()函数获取。通过 read 和 write 函数访问实际变量。 OD_getSub() 可以获取这两个函数的指针。参见 OD_stream_t。另请参见快捷方式： CO_ODgetSetters 用于访问不同类型的数据。 可以从不同的线程访问 OD 变量。CANopenNode 基本上在两个线程中运行：快速实时线程（PDO 处理等）和非关键时间主线程（SDO 等）。两个线程都可以访问 OD 变量，因此必须小心谨慎。CANopenNode 使用锁定机制，SDO 服务器在读取或写入 OD 变量时会阻止实时线程的执行。在 CO_storage 中也需要对 OD 变量进行同样的保护。更多信息请参见 CO_driver.h 中的 CO_critical_sections。 OD 文件-ODxyz.c.h一个 CANopen 设备的实际对象字典由一对 OD_xyz.h 和 ODxyz.c 文件定义。 后缀 “xyz “是对象字典的唯一名称。如果使用单个默认对象字典，则省略后缀。这样就可以配置多个对象字典。 用于定义 OD 的数据安排在多个结构中。不同的 OD 配置有不同的结构。用这些结构创建的数据对象可以是常量，也可以是变量。 实际的 OD 变量位于多个结构（即存储组）中。选定的组可以选择存储到非易失性存储器中。 手动编辑 ODxyz.h.c 文件非常容易出错。 OD 编辑工具可生成成对的 ODxyz.h.c 文件。该工具可以编辑 xml 格式的标准 CANopen 设备描述文件。Xml 文件可能还包括一些 CANopenNode 特有的非标准元素。然后，Xml 文件将用于自动生成 ODxyz.h.c 文件。 /* OD data declaration of all groups ******************************************/typedef struct uint32_t x1000_deviceType; struct uint8_t maxSubIndex; uint32_t vendorID; uint32_t productCode; uint32_t revisionNumber; uint32_t serialNumber; x1018_identity; ODxyz_PERSIST_COMM_t;typedef struct uint8_t x1001_errorRegister; uint8_t x1003_preDefinedErrorField_sub0; uint32_t x1003_preDefinedErrorField[8]; ODxyz_RAM_t;extern ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM;extern ODxyz_RAM_t ODxyz_RAM;extern OD_t *ODxyz;/* Object dictionary entries - shortcuts **************************************/#define ODxyz_ENTRY_H1000 ODxyz-list[0]#define ODxyz_ENTRY_H1001 ODxyz-list[1]#define ODxyz_ENTRY_H1003 ODxyz-list[2]#define ODxyz_ENTRY_H1018 ODxyz-list[3]#define ODxyz_ENTRY_H1000_deviceType ODxyz-list[0]#define ODxyz_ENTRY_H1001_errorRegister ODxyz-list[1]#define ODxyz_ENTRY_H1003_preDefinedErrorField ODxyz-list[2]#define ODxyz_ENTRY_H1018_identity ODxyz-list[3] #define OD_DEFINITION#include 301/CO_ODinterface.h#include ODxyz.h/* OD data initialization of all groups ***************************************/ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM = .x1000_deviceType = 0, .x1018_identity = .maxSubIndex = 4, .vendorID = 0, .productCode = 0, .revisionNumber = 0, .serialNumber = 0 ;ODxyz_RAM_t ODxyz_RAM = .x1001_errorRegister = 0, .x1003_preDefinedErrorField_sub0 = 0, .x1003_preDefinedErrorField = 0, 0, 0, 0, 0, 0, 0, 0;/* All OD objects (constant) **************************************************/typedef struct OD_obj_var_t o_1000_deviceType; OD_obj_var_t o_1001_errorRegister; OD_obj_array_t o_1003_preDefinedErrorField; OD_obj_record_t o_1018_identity[5]; ODxyzObjs_t;static CO_PROGMEM ODxyzObjs_t ODxyzObjs = .o_1000_deviceType = .dataOrig = ODxyz_PERSIST_COMM.x1000_deviceType, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .o_1001_errorRegister = .dataOrig = ODxyz_RAM.x1001_errorRegister, .attribute = ODA_SDO_R, .dataLength = 1 , .o_1003_preDefinedErrorField = .dataOrig0 = ODxyz_RAM.x1003_preDefinedErrorField_sub0, .dataOrig = ODxyz_RAM.x1003_preDefinedErrorField[0], .attribute0 = ODA_SDO_RW, .attribute = ODA_SDO_R | ODA_MB, .dataElementLength = 4, .dataElementSizeof = sizeof(uint32_t) , .o_1018_identity = .data = ODxyz_PERSIST_COMM.x1018_identity.maxSubIndex, .subIndex = 0, .attribute = ODA_SDO_R, .dataLength = 1 , .data = ODxyz_PERSIST_COMM.x1018_identity.vendorID, .subIndex = 1, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.productCode, .subIndex = 2, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.revisionNumber, .subIndex = 3, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 , .data = ODxyz_PERSIST_COMM.x1018_identity.serialNumber, .subIndex = 4, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 ;/* Object dictionary **********************************************************/static OD_entry_t ODxyzList[] = 0x1000, 0x01, ODT_VAR, ODxyzObjs.o_1000_deviceType, NULL, 0x1001, 0x01, ODT_VAR, ODxyzObjs.o_1001_errorRegister, NULL, 0x1003, 0x09, ODT_VAR, ODxyzObjs.o_1003_preDefinedErrorField, NULL, 0x1018, 0x05, ODT_REC, ODxyzObjs.o_1018_identity, NULL, 0x0000, 0x00, 0, NULL, NULL;OD_t _ODxyz = (sizeof(ODxyzList) / sizeof(ODxyzList[0])) - 1, ODxyzList[0];OD_t *ODxyz = _ODxyz; OD_find 查找指定对象extern OD_t *ODxyz;void myFunc(OD_t *od) ODR_t odRet;//保存对象字典操作的返回值。 OD_entry_t *entry;//指向对象字典条目的指针。 OD_IO_t io1008;//用于对象字典I/O操作的结构体。 char buf[50]; OD_size_t bytesRd;//存储读取的字节数。 int error = 0; // 查找并初始化0x1008条目和其子索引0x00的IO结构体 entry = OD_find(od, 0x1008);//查找对象字典中的条目。 odRet = OD_getSub(entry, 0x00, io1008, false);//获取对象字典条目的子索引。 // 读取制造商设备名称 if (odRet == ODR_OK) /* Locking is necessary from mainline thread, but must not be used from * timer interval (real-time) thread. Locking is not necessary in the * CANoopen initialization section. Locking is also not necessary, if * OD variable is not mappable to PDO and not accessed from RT thread.*/ CO_LOCK_OD(CANmodule); odRet = io1008.read(io1008.stream, buf[0], sizeof(buf), bytesRd);//读取子索引的数据。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++; /* Use helper and set Producer heartbeat time at index 0x1017, sub 0x00 */ // 设置生产者心跳时间 CO_LOCK_OD(CANmodule); /* may not be necessary, see comment above */ odRet = OD_set_u16(OD_find(od, 0x1017), 0x00, 500, false);//设置对象字典条目的子索引值。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++; 直接根据结构体查找 OD 对象如何直接访问和操作 CANopen 对象字典（Object Dictionary）中的条目，而不是通过查找函数 OD_find 来间接访问。直接访问对象字典条目和变量比通过函数查找要快，因为它避免了函数调用和查找过程。 对象字典的头文件 ODxyz.h，其中定义了对象字典的所有条目和相关结构。 #include ODxyz.hvoid myFuncGlob(void) // Direct address instead of OD_find() OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; // Direct access to OD variable uint32_t devType = ODxyz_0.x1000_deviceType; ODxyz_0.x1018_identity.serialNumber = 0x12345678; OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; 直接获取对象字典中 0x1001 索引（错误寄存器）的条目指针 entry_errReg。这里使用的是直接声明的指针 ODxyz_1001_errorRegister，而不是通过 OD_find 函数查找。 uint32_t devType = ODxyz_0.x1000_deviceType; 直接读取对象字典中 0x1000 索引（设备类型）的变量 ODxyz_0.x1000_deviceType，并将其存储到本地变量 devType 中。ODxyz_0.x1018_identity.serialNumber = 0x12345678; 直接修改对象字典中 0x1018 索引（设备标识）的 serialNumber 字段，将其设置为 0x12345678。 如果 OD 对象已启用 OD 扩展，则不得直接访问其 OD 变量。只有通过读、写或辅助函数访问才有效。 修改 PDO 固定长度在 PDO 协议中，数据的接收是严格按照 PDO 中映射的数据长度来读取的，当数据不足时，该数据帧会被丢弃，当数据过长时，该数据帧会被截断。 在此次的应用程序中，由于该设备配置的 PDO 存在两种长度数据，所以需要将 PDO 的数据长度更改为兼容自定义的两种数据长度。 在 CO_PDO.c 文件中，有 RPDO 处理函数 CO_RPDO_process，其中的 for 循环，当小于 PDO-mappedObjectsCount 数量时，执行 1byte 的拷贝，所以此处我们需要修改为当 iCO_PDO_MAX_SIZE 时执行拷贝，即对 PDO 中所有的数据进行拷贝，不管该字节是否有数据。","categories":["2.通讯协议","CAN"]},{"title":"博客部署前提笔记","path":"/2024/05/25/0-平台-服务器-博客-博客部署前提笔记/","content":"部署平台 Vercel GitHub Pages Cloudflare Pages 自建服务器部署 Netlify：Netlify 额外提供每个站点每月 1000 个已识别的活跃用户和站点分析。 Railway：支持项目内 Dockerfile 和 docker 镜像，但不支持 docker-compose Cloudflare 的定位为一家全球性的互联网基础设施提供商，提供了一系列的网络安全和性能优化服务，包括内容分发网络(CDN)、DDoS 防护、SSLTLS 加密、DNS 管理等。Cloudflare Workers（serverless 计算平台）和 Cloudflare Pages 可以用来部署 nextjs 应用。 Railway 提供免费容器服务。支持主流语言 python、nodejs 等直接运行，支持 Dockerfile 在线构建 docker 镜像。支持使用 CLI 部署。此外，还提供大量模板直接构建。例如 code server（vscode 网页版）等。按量付费，每个月 5 美元免费额度，跑个小程序够用。支持通过 Github repo 进行部署 Vercel 是一个云服务平台，支持静态网站和动态网站的应用部署、预览和上线。如果你用过 GitHub Pages ，那么心里可能不会太陌生，也能通过 vercel 集成 GitHub 后，在 GitHub 项目进行代码推送，PR 合并自动部署的目的，且你不需要考虑服务器和域名问题。 其他部署涉及到的各项关键配置文件有以下，各文件路径基于 HexoGithubObsidian 的仓库根目录 文件所属 文件名 文件路径 文件用途 GitHub Actions blogPublish.yml .github/workflows 用于仓库同步到 github 之后，自动将源码生成静态页面，同步到发布仓库进行发布 GitHub .gitignore ./ 用于忽略 Hexo 和 Obsidian 中不需要同步到 Git 的文件(有些文件体积过大，占用仓库体积) Hexo _config.yml ./ Hexo 站点配置文件 Hexo package.json ./ npm 安装包及命令文件，部署站点时所需的和 hexo 相关的依赖包都在此文件中 Hexo-Stellar _config.yml themes/stellar/_config.yml Hexo 主题配置文件 Hexo-Stellar widgets.yml themes/stellar/_data/widgets.yml Stellar 主题中的控件配置文件 更换主题 修改 .github/workflows/blogPublish.yml 该文件中指定了主题仓库和主题配置文件，修改主题仓库 修改 _config.theme.yml 该文件中默认为 stellar 的主题配置文件，需要修改为指定的主题配置文件 修改站点配置文件 _config.yml 需要在站点配置文件中修改指定的主题 Qexo本地部署 博客本地部署方案拉取仓库并本地部署脚本 rm -rf ./BlogDeploygit clone git@github.com:liuluhua/BlogDeploy.gitcd ./BlogDeploymkdir themescd themesgit clone git@github.com:xaoxuu/hexo-theme-stellar.gitgit clone git@github.com:next-theme/hexo-theme-next.gitcd ..cp ./_config.theme.stellar.widgets.yml ./themes/hexo-theme-stellar/_data/widgets.ymlcp ./_config.theme.stellar.yml ./themes/hexo-theme-stellar/_config.ymlnpm installhexo cleanhexo ghexo s -p 9050 云服务器用 pm2 部署 先确保安装了 nodejs 和 npm，并使用 pnpm 作为 nextjs 项目的依赖管理工具 npm install -g pnpm 安装 pm2 做进程管理 npm install -g pm2 在项目根目录下安装依赖，构建输出产物 pnpm installpnpm build 使用 pm2 启动服务 pm2 start pnpm --name sorafm -- start --port 8015 使用 nginx 做反向代理，先确保安装和启动了 nginx： sudo apt install nginxsudo systemctl start nginx 为 nextjs 项目创建 nginx 配置： sudo vi /etc/nginx/conf/sorafm.confserver listen 80; location / proxy_pass http://127.0.0.1:8015/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; error_log /var/log/nginx/sorafm.error; nginx 重载新的网站配置： sudo nginx -s reload DNS 解析域名到服务器的公网 ip 在 DNS 控制台添加一条 A 记录，指向服务器的公网 ip，等解析生效后，就可以访问 nextjs 项目了。 配置 https 访问，可以在 Ubuntu 安装 certbot 生成域名证书： sudo apt updatesudo apt install certbot python3-certbot-nginx 为新域名生成新的证书，并使用 https 访问 sudo certbot --nginx -d sorafm.trys.ai 配置完成后，就可以安全访问 nextjs 项目了。 云服务器用 Docker 部署同样是使用 Ubuntu 云服务器，使用 pm2 部署 nextjs 更简单直接，轻量级部署，服务资源占用少。使用 docker 部署，系统隔离性更好，更方便移植，适用于微服务架构。要使用 docker 部署 nextjs 应用，先确保在服务器安装好了 docker，再来改造 nextjs 项目 修改项目根目录下的 next.config.mjs，使用 standalone 模式输出编译产物 /** @type import(next).NextConfig */const nextConfig = output: standalone,;export default nextConfig; 在 deploy 文件夹下新建 Dockerfile 文件，写入 docker 镜像构建内容 FROM node:18-alpine AS base# Install dependencies only when neededFROM base AS depsRUN apk add --no-cache libc6-compat yarn global add pnpmWORKDIR /app# Install dependencies based on the preferred package managerCOPY package.json pnpm-lock.yaml* ./RUN pnpm i --frozen-lockfile# Rebuild the source code only when neededFROM deps AS builderWORKDIR /app# Install dependencies based on the preferred package managerCOPY . .RUN pnpm build# Production image, copy all the files and run nextFROM base AS runnerWORKDIR /appRUN addgroup --system --gid 1001 nodejs \\ adduser --system --uid 1001 nextjs \\ mkdir .next \\ chown nextjs:nodejs .nextCOPY --from=builder /app/public ./publicCOPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/staticUSER nextjsEXPOSE 8080ENV NODE_ENV productionENV PORT 8080ENV HOSTNAME 0.0.0.0# server.js is created by next build from the standalone outputCMD [node, server.js] 在项目根目录下新建 .dockerignore 文件，写入构建镜像时要忽略的内容 .next.vercel.vscodedatadebugnode_modules 开始构建 docker 镜像 sudo docker build -f deploy/Dockerfile -t sorafm:latest . 使用 docker 运行服务 sudo docker run -itd -p 127.0.0.1:8014:8080 --restart=always sorafm:latest 服务运行成功后，再通过 nginx 配置公网访问，DNS 解析公网域名，certbot 配置 https 证书，这三个步骤跟上面使用 pm2 部署 nextjs 的方案一致。 Cloudflare 部署上述两种方案：使用 pm2 和使用 docker 部署 nextjs 应用，需要先有一台服务器。如果不想买服务器，而是通过托管的方式部署 nextjs 项目，可以选择 Cloudflare Pages，几乎免费的云部署方案。按照 Cloudflare 的官方文档，使用 Cloudflare Pages 部署 nextjs 项目，主要的步骤： 安装部署依赖 pnpm add -D @cloudflare/next-on-pages 在项目根目录创建一个配置文件 wrangler.toml name = sorafmcompatibility_date = 2024-07-29compatibility_flags = [nodejs_compat]pages_build_output_dir = .vercel/output/static 更新 next.config.mjs 文件 import setupDevPlatform from @cloudflare/next-on-pages/next-dev;/** @type import(next).NextConfig */const nextConfig = ;if (process.env.NODE_ENV === development) await setupDevPlatform();export default nextConfig; 修改服务端路由运行时，对所有的 api 路由文件 route.ts 和所有的页面路由文件 page.tsx 都添加一行代码，指定使用 edge 运行时： export const runtime = edge; 修改 package.json 文件，添加编译指令 pages:build: npx @cloudflare/next-on-pages,preview: pnpmb pages:build wrangler pages dev,deploy: pnpm pages:build wrangler pages deploy 在项目根目录通过命令行部署项目到 Cloudflare Pages npm run deploy 在第一次运行 deploy 命令时，需要填写项目名称，跳转 Cloudflare 进行授权验证等。发布完成后，就可以在 Cloudflare-Workers and Pages 管理后台看到项目了。跟 Vercel 一样，Cloudflare 也为发布的项目生成一个子域名：xxx.pages.dev，部署成功可直接公网访问，方便项目快速上线验证。","categories":["0.平台","服务器","博客"]},{"title":"AI应用软件了解","path":"/2024/05/24/3-软件-AI-AI应用软件了解/","content":"1. 文本生成 AI 名称 公司 是否开源 功能简介 ChatGPT-4 OpenAI 否 最先进的大语言模型之一,具有强大的自然语言理解和生成能力,可用于写作、编程、分析等复杂任务 Claude3 Anthropic 否 擅长长文本处理和信息整理,最新版本在多项基准测试中表现优异 Gemini Google 否 多模态 AI 模型,具备出色的语音和图像理解能力 Poe Quora 否 集成多个顶级大语言模型的平台,用户可选择不同模型对话 NewBing Microsoft 否 基于 GPT-4 开发的 AI 搜索助手,集成在 Bing 搜索引擎中 通义千问 阿里巴巴 否 支持 10 万字长文本处理的大语言模型 豆包 字节跳动 否 注重陪伴和对话体验的 AI 助手 天工 昆仑万维 否 可生成文本、图像和音乐的 AI 平台 扣子 - - 专注于创建和部署自定义 AI 智能体的平台 2. 图像生成 AI 名称 公司 是否开源 功能简介 Stable Diffusion Stability AI 是 开源的文本到图像生成模型,可免费使用 Midjourney Midjourney 否 付费的高质量图像生成服务,以艺术风格著称 DALL-E 3 OpenAI 否 最新图像生成模型,集成在 ChatGPT 中 Dreamina 字节跳动 否 字节跳动开发的图像生成 AI 通义万象 阿里巴巴 否 集成在通义千问中的图像生成模型 混元助手 腾讯 否 腾讯开发的图文生成 AI Akuma - - 新兴的 AI 图像生成平台,提供多样化创作工具 3. 视频生成 AI 名称 公司 是否开源 功能简介 Sora OpenAI 否 文本到视频生成模型,能创建高质量、逼真的视频内容 Stable Video Diffusion Stability AI 是 开源的视频生成模型 Runway Runway 否 提供 AI 视频编辑和生成工具的平台 Pika Pika Labs 否 专注于短视频创作的 AI 工具 Haiper - - 新兴的 AI 视频生成平台 Dreamina 字节跳动 否 字节跳动的视频生成 AI 产品 Pixverse - - 提供 AI 视频创作和编辑功能的平台 Vidu 清华大学 - 清华大学开发的视频生成 AI Money Print Turbo - - 全自动视频制作工具,可生成文案、素材、字幕和背景音乐 4. 音频生成 AI 名称 公司 是否开源 功能简介 Suno Suno 否 AI 音乐创作平台,提供免费额度 Stable Audio Stability AI 是 Stability AI 开发的音频生成模型 天工音乐 昆仑万维 否 AI 音乐创作工具 网易天音 网易 否 网易开发的 AI 音乐生成平台 5. AI 浏览器和编程助手 名称 公司 是否开源 功能简介 Perplexity Perplexity AI 否 基于 AI 的智能搜索引擎,提供精准的信息检索和问答服务 GitHub Copilot MicrosoftOpenAI 否 AI 编程助手,集成在多个代码编辑器中 6. 照片说话和音频模仿 名称 公司 是否开源 功能简介 Emo 阿里巴巴 否 AI 换脸和表情动画工具 SadTalk - 是 开源的 AI 换脸和口型同步技术 GPT-SoVITS - 是 开源的 AI 语音克隆和转换工具 Openvoice 微软 否 微软开发的 AI 语音克隆技术 剪映 字节跳动 否 短视频编辑 App,集成 AI 语音克隆功能 魔音工坊 - - 专注于 AI 语音合成和克隆的在线平台 7. PPT 制作和视频编辑 名称 公司 是否开源 功能简介 讯飞智文 科大讯飞 否 AI 辅助文档创作工具 Gamma Gamma 否 基于 AI 的演示文稿制作平台 WPS AI 金山办公 否 集成的 AI 助手,支持 PPT 等文档智能生成 腾讯智影 腾讯 否 AI 视频创作和编辑平台 剪映 字节跳动 否 短视频编辑 App,集成多种 AI 功能 其他说明：PyTorch 2.0.1 CUDA 11 conda FastGPT+ollama 订阅号对接 ollma 模型—云服务器资源不足 微软 E5 开发者订阅 huggingface.coHugging Face Transformers 是一个开源 Python 库，其提供了数以千计的预训练 transformer 模型，可广泛用于自然语言处理 (NLP) 、计算机视觉、音频等各种任务。 Hugging Face Hub 是一个协作平台，其中托管了大量的用于机器学习的开源模型和数据集，你可以将其视为 ML 的 Github。 Hugging Face Spaces 是 Hugging Face Hub 上提供的一项服务，它提供了一个易于使用的 GUI，用于构建和部署 Web 托管的 ML 演示及应用。该服务使得用户可以快速构建 ML 演示、上传要托管的自有应用，甚至即时部署多个预配置的 ML 应用。","categories":["3.软件","AI"]},{"title":"CANOpen 调试","path":"/2024/05/24/2-通讯协议-CAN-CANOpen-调试/","content":"作为 CAN Open 总线上的数据抓取设备，要求程序具有以下功能 能够作为总线上的从机设备，要求具有以下功能： HeartBeat 本设备 SDO 配置项 PDO 数据配置 如何通过主机 ASK 某一设备的数据 能够作为总线上的主机设备，要求具有以下功能： 从机设备的状态管理 PDO 数据采集 例如，预配置的过程数据对象 (PDO) 由生产者传输。每个 PDO 可能由多个节点使用。每个 CANopen 设备的其他有用的 CANopen 功能还包括：心跳生产者和消费者、紧急生产者、同步生产者或消费者、时间生产者或消费者、SDO 服务器（服务数据对象 - 从对象字典中提供变量）、NMT 从属（网络管理 - 启动或停止通信部分）、LSS 从属（节点 ID 和比特率的配置）。 CANopen 网络通常有一个具有命令功能的设备用于网络配置，例如：NMT 主站、LSS 主站、SDO 客户端、紧急消费者。CANopenNode 中的命令功能根据标准 CiA309-3 使用 Ascii 命令行接口实现。 使能 CAN 接口Linux 下 虚拟 CAN 设备modprobe 是 Linux 系统中的一个命令行工具，用于管理内核模块。内核模块是可以动态加载或卸载的可扩展组件，允许 Linux 内核在运行时添加或删除功能而不需要重启系统。常见的内核模块包括设备驱动程序、文件系统支持以及网络协议等。 创建一个虚拟 CAN 设备，并启用 sudo modprobe vcansudo ip link add dev can0 type vcansudo ip link set up can0 安装 CAN 监测调试工具，can-utils 项目地址 https://github.com/linux-can/can-utils sudo apt-get install can-utilscandump -td can0 #显示can消息 rk3568 的 can 使用时 ip link set can0 up 启用失败报错： can0: incorrect missing data bit-timing 驱动问题，设备树中的节点配置，需要将 kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi 中的 can0 节点中的 compatible = rockchip,canfd-1.0 修改为 compatible = rockchip,can-1.0，重新编译后下载 开发板 3568 的 CANifconfig can0 downip link set can0 up type can bitrate 500000ifconfig can0 upifconfig can1 downip link set can1 up type can bitrate 500000ifconfig can1 upip link set can0 downip link set can1 downip link set can0 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd onip link set can1 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd on#查询当前网络设备:ifconfig -a#关闭CAN:ip link set can0 down#设置比特率500KHz:ip link set can0 type can bitrate 500000#打印can0信息:ip -details -statistics link show can0#启动CAN:ip link set can0 up#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123#DEADBEEF#发送（标准帧,远程帧,ID:123）:cansend can0 123#R#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123#12345678#发送（扩展帧,远程帧,ID:00000123）:cansend can0 00000123#R#开启打印，等待接收:candump can0###########################################设置can fd#设置仲裁段1M波特率，数据段3M波特率:ip link set can0 type can bitrate 1000000 dbitrate 3000000 fd on#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123##1DEADBEEF#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123##1DEADBEEFifconfig -aip link set can0 type can bitrate 500000ip link set can0 upip link set can1 type can bitrate 500000ip link set can1 upcandump can0 cansend can1 123#DEADBEEFcansend can1 123#DEADBEEF 这个命令是用于配置 CAN（Controller Area Network，控制器局域网络）接口的 Linux 命令行指令。CAN 是一种用于实时应用的车辆、工业控制及自动化领域的串行通信协议。下面是对该命令各部分含义的详细解析： ip link set can0 up 这部分命令是用来设置指定的网络接口（%s 是一个占位符，通常在脚本中使用，运行时会被实际的接口名称替换）为活动状态（up）。这意味着它将启动指定的 CAN 接口，使其准备好进行数据传输。 type can 指定接口类型为 CAN 总线。这是告诉系统该接口应该被配置和处理为 CAN 总线接口，而不是以太网或其他类型的网络接口。 bitrate 500000 设置 CAN 总线的比特率（通信速度）。500000 代表具体的比特率值，例如 125000 表示 125Kbps。比特率是指每秒钟传输的位数，是 CAN 总线配置中的一个关键参数，需要所有连接到同一总线上的设备匹配。 sample-point 0.75 配置 CAN 位采样点的位置。采样点是在每个 CAN 位的哪个时间点进行信号采样以确定位的逻辑电平（0 或 1）。值范围从 0 到 1，其中 1 代表位时间周期的结束。这里设置为 0.75 意味着在每位的 75%时间点进行采样。 dbitrate 4000000 分布式比特率（Data Bit Rate）设置。这通常用于 FlexCAN（Flexible Data-Rate CAN）等高级 CAN 协议变体中，允许数据段的比特率与仲裁段不同。这里设置为 4000000 表示数据段的比特率为 4Mbps。但需要注意的是，标准 CAN 协议并不支持不同的数据和仲裁比特率，这一选项可能特定于某些高级 CAN 控制器或实现。 dsample-point 0.8 数据段的采样点位置，类似于上述的 sample-point，但特指数据段（如果适用）。在这个例子中，数据段的采样点被设置在每位的 80%时间点。 fd on 启用 CAN FD（Flexible Data-rate CAN）模式。CAN FD 是 CAN 总线协议的一个扩展，允许更灵活的数据长度和更高的数据传输速率，旨在提高 CAN 网络的数据吞吐量。 CAN 通信测试工具canutils 是常用的 CAN 通信测试工具包，内含 5 个独立的程序：canconfig、candump、canecho、cansend、cansequence。 这几个程序的功能简述如下： canconfig 用于配置 CAN 总线接口的参数，主要是波特率和模式。 candump 从 CAN 总线接口接收数据并以十六进制形式打印到标准输出，也可以输出到指定文件。 canecho 把从 CAN 总线接口接收到的所有数据重新发送到 CAN 总线接口。 cansend 往指定的 CAN 总线接口发送指定的数据。 cansequence 往指定的 CAN 总线接口自动重复递增数字，也可以指定接收模式并校验检查接收的递增数字。 ip CAN 波特率、功能等配置。 注意：busybox 里也有集成了 ip 工具，但 busybox 里的是阉割版本。不支持 CAN 的操作。故使用前请先确定 ip 命令的版本（iproute2）。上面工具包，网络上都有详细的编译说明。如果是自己编译 buildroot，直接开启宏就可以支持上述工具包。 BR2_PACKAGE_CAN_UTILS=yBR2_PACKAGE_IPROUTE2=y CAN 比特率和采样点计算目前 CAN 架构根据输入频率和比特率自动计算。采样点的规则按照 CIA 标准协议： /* Use CiA recommended sample points */if (bt-sample_point) sample_point_nominal = bt-sample_point; else if (bt-bitrate 800000) sample_point_nominal = 750;\telse if (bt-bitrate 500000) sample_point_nominal = 800;\telse sample_point_nominal = 875; 比特率计算公式（详细原理可以百度，这里只介绍芯片配置相关）： BitRate = clk_can / (2 *(brq + 1) / ((tseg2 + 1) + (tseg1 + 1) + 1)Sample = (1 + (tseg1 + 1)) / (1 + (tseg1 + 1) + (tseg2 + 1)) brq、tseg1、tseg2 见 CAN 的 TRM 中 BITTIMING 寄存器。 CAN Open 用例分析SDO 命令-状态恢复和存储紧急信息、错误寄存器和 NMT 运行前状态在未初始化的非易失性存储器中都有数据源。对象 0x1010 和 0x1011 用于存储和恢复数据，通常来自 CANopen 对象字典。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不为零，则可能禁止节点进入 NMT 操作状态，并且无法与其交换 PDO。 恢复所有非易失性存储器： CAN ID：0x600 + 节点 ID（表示从主机到从节点的 SDO 请求）。0x600 + 4 0x604。 命令字节：表示写入命令和数据长度。0x23 表示写入 4 字节数据（visible string）。 索引：对象字典索引。0x1011（字节顺序为低字节在前）。 子索引：对象字典子索引。0x01 数据：load：ASCII 码 l、o、a、d 分别为 0x6C、0x6F、0x61、0x64。 构建数据恢复 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x11 0x10），子索引（0x01），数据（0x6C 0x6F 0x61 0x64）。 can0 604 [8] 23 11 10 01 6C 6F 61 64 save：ASCII 码 s、a、v、e 分别为 0x73、0x61、0x76、0x65。 构建数据存储 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x10 0x10），子索引（0x01），数据（0x73 0x61 0x76 0x65）。 can0 604 [8] 23 10 10 01 73 61 76 65 NMT 命令-设置 NMT 状态报文可以发送给特定节点或所有节点。它们可以重置设备、通信或将远程设备的内部状态设置为运行、预运行（禁用 PDO）或停止（仅启用心跳生产者和 NMT 消费者）。 当出现了设置错误寄存器的紧急状况时，start 不起作用。 设置 Node ID 为 4 的设备状态为 reset。 000 82 04 Byte 0 取值（命令） 状态 01 start_remote_node 02 stop_remote_node 80 enter_pre-operational 81 reset_node 82 reset_communication SDO 命令-设置心跳包读取心跳时间设置CAN0 604 [8] 40 17 10 00 00 00 00 00 写入心跳时间设置 CAN ID：0x600 + 节点 ID（4） 0x604。 命令字节：0x2B 表示写入 2 字节（u16）。 索引：0x1017（字节顺序为 17 10）。 子索引：0x00。 数据：1000ms0x03E8，字节顺序为 E8 03。10000ms0x2710 can0 604 [8] 2B 17 10 00 E8 03 00 00 PDO 配置按以下步骤通过写入 OD 变量配置 PDO： 将 PDO 通信参数 COB-ID 中的第 31 位设置为 1，禁用 PDO。 只有禁用 PDO 时才能配置 Node-Id。 将 PDO 映射参数，子索引 0 设置为 0，禁用映射。 配置映射 通过设置 PDO 映射参数，子索引 0 至映射对象数启用映射 通过将 PDO 通信参数 COB-ID 中的第 31 位设置为 0 来启用 PDO 其他配置同步传输信号配置全局同步周期 SYNC 设置值保存在对象 1006h 中。 心跳CANopen 主站的对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 对象 1017h 的值(发生器心跳时间)被此处设置的值重写。适用于所有从站对象的对象 1017h(发生器心跳时间)的值被此处设置的值重写，对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 CAN Open 总线建设假定在一个 can open 网络中，node1 为主节点，node2 和 node3 为从节点，需要配置 node2，让 node2 接收 node3 的 TPDO 消息。 设备配置 设备名 节点地址 类型 Node 1 0x01 主节点（NMT Master） Node 2 0x02 从节点（NMT Slave） Node 3 0x03 从节点（NMT Slave） 其中 Node3 作为 TPDO 消息发出（生产者），期望 Node2 接收 Node3 消息。 PDO 参数配置配置所需信息配置 Node 3 的 TPDO： 确定 Node 3 的 TPDO 消息的 COB-ID 和映射对象。 在 Node 3 的对象字典中设置 TPDO 通信参数和映射参数。 配置 Node 2 的 RPDO： 设置 Node 2 的 RPDO 通信参数，使其接收 Node 3 的 TPDO 消息。 配置 Node 2 的 RPDO 映射参数，以处理从 Node 3 接收到的数据。 通讯参数和映射参数（OD）Node 3 的配置： TPDO 通信参数（0x1802）： 子索引 0x01: COB-ID 0x183 子索引 0x02: 传输类型（例如 0xFF，事件触发） TPDO 映射参数（0x1A02）： 子索引 0x00: 映射对象数量 2 子索引 0x01: 0x60000208（对象 0x6000，子索引 0x02，8 位） 子索引 0x02: 0x64010110（对象 0x6401，子索引 0x01，16 位） Node 2 的配置： RPDO 通信参数（0x1400）： 子索引 0x01: COB-ID 0x183（与 Node 3 的 TPDO COB-ID 一致） 子索引 0x02: 传输类型（例如 0xFF，事件触发） RPDO 映射参数（0x1600）： 子索引 0x00: 映射对象数量 2 子索引 0x01: 0x60000208（与 Node 3 的 TPDO 映射一致） 子索引 0x02: 0x64010110（与 Node 3 的 TPDO 映射一致） 配置过程设置 Node 3 的 TPDO 通信参数： CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 83 01 00 00] # 设置 COB-ID 为 0x183（启用）CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 3 的 TPDO 映射参数： CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 00 00 00 00] # 禁用 TPDO 映射CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 02 00 00 00] # 启用 TPDO 映射 设置 Node 2 的 RPDO 通信参数： CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 00 83 01 00 00] # 设置 COB-ID 为 0x183CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 2 的 RPDO 映射参数： CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 00 00 00 00] # 禁用 RPDO 映射CAN ID: 0x602 (SDO 请求)Data: [23 00 16 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x602 (SDO 请求)Data: [23 00 16 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 02 00 00 00] # 启用 RPDO 映射 通过上述步骤配置 Node 2 的 RPDO 通信参数和映射参数，使其能够接收和处理来自 Node 3 的 TPDO 消息。这种配置确保了 Node 2 能够正确接收和解析 Node 3 发送的 TPDO 数据，完成数据的有效传输和处理。 调试命令控制 NMT 状态 CAN0 000 [2] 01 04CAN0 000 [2] 02 04 控制节点 4 CAN0 000 [2] 01 00CAN0 000 [2] 02 00 控制所有节点 发送 SYNC 信号 CAN0 080 [0] 发送 ERROR 信号 CAN0 084 [8] 数据区根据实际错误定义 恢复参数，在 1011 的 01 写入 load CAN0 604 [8] 2F 11 10 01 6C 6F 61 64 读取 1005 信息（SYNC 的 COB-ID） CAN0 604 [8] 40 05 10 00 00 00 00 00 配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值）。 CAN0 604 [8] 23 05 10 00 80 00 00 00 读取 1006 信息(SYNC 通信周期) CAN0 604 [8] 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms 100000us）。 CAN0 604 [8] 23 06 10 00 A0 86 01 00 读取心跳时间设置 CAN0 604 [8] 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 CAN0 604 [8] 2B 17 10 00 E8 03 00 00 设置一个 TPDO配置 1800 的上报方式为异步，读取的话改 2F 为 40 CAN0 604 [8] 2F 00 18 02 FF 00 00 00 配置 1800 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 604 [8] 2B 00 18 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 604 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 604 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 604 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 604 [8] 2F 00 1A 00 02 00 00 00 设置 RPDO配置 1400 接收来自 181 的数据 CAN0 601 [8] 23 00 14 01 81 01 00 00 配置 1400 的上报方式为异步，读取的话改 2F 为 40 CAN0 601 [8] 2F 00 14 02 FF 00 00 00 配置 1400 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 601 [8] 2B 00 14 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 601 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 601 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 601 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 601 [8] 2F 00 1A 00 02 00 00 00","categories":["2.通讯协议","CAN"]},{"title":"网络超时检测的三种方法","path":"/2024/05/22/0-平台-Linux-网络-网络超时检测的三种方法/","content":"网络超时检测的三种方法 网络通信中，很多操作会使得进程阻塞，这时我们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 这里我们总结一下网络超时检测的三种方法： 一、通过 setsockopt 设置套接字属性 SO_RCVTIMEO struct timeval t = 5, 0if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, t, sizeof(t)) == -1) perror(setsockopt); return -1;memset(peeraddr, 0, sizeof(peeraddr));len = sizeof(peeraddr);if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) printf(errno=%d: %s , errno, strerror(errno));\tif (errno == EAGAIN) printf(timeout ); return -1; 二、设定 select 函数的一个参数实现超时处理 struct timeval t= 3, 0;while (1) t.tv_sec = 3;\tt.tv_usec = 0;\tif ((ret = select(maxfd+1, rdfs, NULL, NULL, t)) == -1) perror(select); return -1; 三、设定一个定时器捕捉 SIGALRM 信号做超时控制 struct sigaction act;sigaction(SIGALRM, NULL, act); //获取SIGALRM信号的属性act.sa_handler = handler; // 设置SIGALRM信号的处理函数sigaction(SIGALRM, act, NULL); // 设置SIGALRM信号的属性alarm(3); // 定时器设置3秒钟while (1) if ((connfd = accept(listenfd, (struct sockaddr *)peeraddr, len)) == -1) if (errno == EINTR) printf(timeout ); return -1; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。我们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["0.平台","Linux","网络"]},{"title":"Docker下将已部署的wordpress备份及迁移","path":"/2024/05/22/0-平台-Docker-Docker下将已部署的wordpress备份及迁移/","content":"镜像# Docker 镜像备份 在已经部署好 wordpress 的机器上，使用 docker save 命令将 Docker 镜像保存到本地文件中。 使用以下命令将名为 wordpress 和 mysql 的 Docker 镜像分别保存到名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中： docker save wordpress wordpress_image.tar #保存wordpressdocker save mysql mysql_image.tar #保存mysql # Docker 镜像读取 将 wordpress_image.tar 和 mysql_image.tar 文件复制到目标机器上。在目标机器上，使用 docker load 命令将本地文件中的 Docker 镜像加载到 Docker 中。 使用以下命令将名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中的 Docker 镜像加载到 Docker 中： docker load wordpress_image.tardocker load mysql_image.tar 文件系统文件系统备份要将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方，可以使用 Docker 的导入和导出功能，具体步骤如下： 在运行 WordPress 应用程序的 Docker 容器上执行以下命令，将容器中的 WordPress 应用程序导出为 tar 文件： docker export container_id wordpress.tar 这将在当前目录下创建一个名为 wordpress.tar 的文件，其中包含 Docker 容器中的整个 WordPress 应用程序。 文件系统读取将 wordpress.tar 文件传输到要部署 WordPress 应用程序的目标服务器上。在目标服务器上执行以下命令，将 wordpress.tar 文件导入到 Docker 中： cat wordpress.tar | docker import - image_name:tag 其中，image_name 是你为导入的 Docker 镜像指定的名称，tag 是你为该镜像指定的标签。运行导入的 Docker 镜像，启动 WordPress 应用程序的容器： docker run -p host_port:container_port -d image_name:tag 其中，host_port 是你要将容器的端口映射到主机上的端口号，container_port 是容器内运行 WordPress 应用程序的端口号。这样，你就可以将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方。 启动 Docker 按照之前的 docker-compose 的方法启动 dokcer 使用 docker ps -a --no-trunc 需要修改并添加 command wordpress 是 docker-entrypoint.sh apache2-foreground mysql 是 docker-entrypoint.sh mysqld 使用 docker run 命令在目标机器上启动该 Docker 镜像。例如，使用以下命令在目标机器上启动名为 wordpress 的 Docker 镜像： #启动mysqldocker run -d \\--name mysql \\-v mysql_data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=liuluhua \\-e MYSQL_DATABASE=wordpress \\-e MYSQL_USER=liuluhua \\-e MYSQL_PASSWORD=liuluhua \\mysql:latest docker-entrypoint.sh mysqld #启动wordpressdocker run -d \\--name wordpress \\--link mysql \\-p 80:80 \\-e WORDPRESS_DB_HOST=mysql:3306 \\-e WORDPRESS_DB_USER=liuluhua \\-e WORDPRESS_DB_PASSWORD=liuluhua \\-e WORDPRESS_DB_NAME=wordpress \\-v ./wp-content:/var/www/html/wp-content \\-v ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini \\wordpress:latest docker-entrypoint.sh apache2-foreground 启动参数： **-d**：表示以“后台模式”运行容器，即使容器的主进程退出也不会停止容器。 **--name**：表示为容器指定一个名称，这样可以方便地对容器进行管理。 **-v**：表示将主机的目录或文件与容器内的目录或文件进行挂载，即数据卷。例，-v mysql_data:/var/lib/mysql 表示将主机的 mysql_data 目录挂载到容器内的 /var/lib/mysql 目录，这样容器内的 MySQL 数据就可以持久化存储在主机上。 **-e**：表示设置容器内的环境变量。例如，-e MYSQL_ROOT_PASSWORD=liuluhua 表示设置容器内的 MYSQL_ROOT_PASSWORD 环境变量为 liuluhua。 **--link**：表示将一个容器链接到另一个容器，使得容器之间可以进行通信。例如，--link mysql 表示将容器链接到名为 mysql 的容器。 **-p**：表示将容器的端口映射到主机的端口。例如，-p 80:80 表示将容器的 80 端口映射到主机的 80 端口，使得可以通过主机的 IP 地址访问容器内的服务。 **wordpress:latest 和 mysql:latest**：表示使用 wordpress 和 mysql 镜像的最新版本来创建容器。 **./wp-content:/var/www/html/wp-content 和 ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini**：表示将主机上的 wp-content 目录和 uploads.ini 文件挂载到容器内的 /var/www/html/wp-content 目录和 /usr/local/etc/php/conf.d/uploads.ini 文件，使得容器内的 WordPress 网站可以访问这些文件。","categories":["0.平台","Docker"]},{"title":"内存分布","path":"/2024/05/22/0-平台-Linux-程序-内存分布/","content":"内存分布在 32 位操作系统中，地址空间的最大理论限制是 4GB，即 (2^{32}) 的结果。然而，这个地址空间并不能完全分配给用户应用程序，因为操作系统本身也需要占用部分内存。具体而言，在 32 位的操作系统中，可执行文件的内存分布如下： 用户空间 (app + C 库): 3GB 内核空间 (驱动): 1GB 内核空间内核空间占用了高位的 1GB 地址空间，范围是从 0xC0000000 到 0xFFFFFFFF。这部分内存由操作系统用来管理系统资源和与硬件设备的交互。用户态程序无法直接访问这些地址，因为这些内存区域被操作系统保留，以防止不受控制的错误访问可能引发的安全问题或系统崩溃。 例如，内核空间中的内存可能被用来存放进程控制块（PCB）、中断描述符表（IDT）以及设备驱动程序等。例如，当一个打印机被连接到系统时，相应的驱动程序会占用内核空间，以允许操作系统控制打印机打印命令。 用户空间剩下的 3GB 地址空间，从 0x00000000 到 0xBFFFFFFF，被分配给用户态应用程序。用户态应用程序的组成部分，包括代码段、数据段、堆与栈，以及动态链接库（DLL），均位于这一部分地址空间。 在这 3GB 的用户空间中，内存分布通常如下所示： 低地址+-----------------+| .text 段 | 代码段: 包含应用程序的可执行代码。通常从低地址开始分配，便于操作。+-----------------+| .data 段 | 数据段: 存放已初始化的全局变量和静态变量，确保在程序运行时可用。+-----------------+| .bss 段 | 包含未初始化的全局变量和静态变量，执行前自动清零。+-----------------+| 堆 (heap) | 堆: 用户自定义空间，用于动态内存分配（如 malloc、new），在使用后需手动释放。||(向高地址方向增长)| 堆一般从数据段之后的地址开始，向高地址方向增长。+-----------------+| || 空闲区域 | 在此区域中，共享库（DLLs）被映射到进程的地址空间，通常位于堆和栈之间的某个位置。| |+-----------------+| 栈 (stack) | 栈: 存储局部变量和函数调用相关信息，局部变量在函数返回时自动释放。| | 栈一般从高地址开始，向低地址方向增长。| (向低地址方向增长)|+-----------------+高地址 一个典型的 Linux C 程序内存空间通常分为几个关键部分： 代码段（.text）：此部分存放的是 CPU 要执行的指令。由于代码段是可共享的，因此相同的代码在内存中只会有一份拷贝。此外，该段通常是只读的，这样可以防止程序因意外而修改自己的指令。 初始化数据段（.data）：这个段包含程序中需要明确赋初始值的变量。比如，如果有声明为 int val = 100; 的全局变量，那么它的地址将指向这里。 未初始化数据段（.bss）：此区域中的数据在程序执行前被初始化为 0 或 null。例如，全局变量 int sum; 就会被放置在这里。 堆（Heap）：此段用于动态内存分配。通过调用如 malloc 或 new 函数，程序能够在运行时请求内存。 栈（Stack）：这个区域用于存储局部变量和函数调用过程中产生的临时变量。当函数完成执行时，栈空间会自动被释放。 #include stdio.h#include stdlib.h#include string.h/*C语言中数据的内存分配*/int a = 0; // 全局变量，位于.data段char *p1;int main() int b; // 局部变量b，位于栈中 char s[] = abc; // 数组s存放在栈中，字符串常量abc在常量区 char *p2; // 指针p2在栈中 char *p3 = 123456; // 字符串常量123456在常量区，p3指向栈中 static int c = 0; // 静态局部变量c，位于.data段 p1 = (char *)malloc(10); // 从堆中分配10个字节的空间 p2 = (char *)malloc(20); // 从堆中分配20个字节的空间 // 从常量区的“Hello World”复制字符串到堆中分配的内存 strcpy(p1, Hello World); free(p1); // 确保释放堆内存，避免内存泄漏 free(p2); // 同样释放p2所指向的堆内存 return 0; 在上述示例中，整个程序展示了内存分配的不同区域。局部变量如 b 和数组 s 存储于栈中，而全局变量和动态分配的内存则存放于数据段和堆中。这样的内存管理策略使得程序在运行时能有效利用内存资源，同时保持高效率和稳定性。","categories":["0.平台","Linux","程序"]},{"title":"vim安装","path":"/2024/05/22/3-软件-VIM-vim安装/","content":"配置文件 地址 1. 安装环境sudo apt install git cscopewget -qO - https://raw.github.com/ma6174/vim/master/setup.sh | sh -x wget 是一个强大的命令行工具，专门用于从互联网下载文件。它的灵活性和可配置性使其成为开发者和系统管理员的首选工具。 参数 -q 表示下载时以静默模式运行，这样既可以避免显示进度条，也不会干扰标准输出，保持终端的整洁。 -O - 指定将下载的文件直接输出到标准输出（通常是终端），这样用户可以第一时间看到脚本的执行结果，而无需在本地保存该文件。 URL 地址 https://raw.github.com/ma6174/vim/master/setup.sh 指向一个在 GitHub 上托管的 Shell 脚本，它负责设置 Vim 的安装和配置。 | 是管道符号，它将前一个命令的输出直接传递给下一个命令，允许用户在一条命令中链式调用多个操作。 sh 用来执行 Shell 脚本的命令，将下载后的脚本内容执行。 -x 则在执行脚本时提供详细的调试信息，这对排查潜在问题非常有帮助。 setup.sh 内容解析#!/bin/bashecho 安装将花费一定时间，请耐心等待直到安装完成~~if which apt-get /dev/null; then sudo apt-get install -y vim vim-gnome ctags xclip astyle python-setuptools python-dev gitelif which yum /dev/null; then sudo yum install -y gcc vim git ctags xclip astyle python-setuptools python-develfi## Add HomeBrew support on Mac OSif which brew /dev/null;then echo You are using HomeBrew tool brew install vim ctags git astylefisudo easy_install -ZU autopep8sudo ln -s /usr/bin/ctags /usr/local/bin/ctagsmv -f ~/vim ~/vim oldcd ~/ git clone https://github.com/ma6174/vim.gitmv -f ~/.vim ~/.vim_old mv -f ~/vim ~/.vimmv -f ~/.vimrc ~/.vimrc_oldmv -f ~/.vim/.vimrc ~/ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundleecho ma6174正在努力为您安装bundle程序 ma6174echo 安装完毕将自动退出 ma6174echo 请耐心等待 ma6174vim ma6174 -c BundleInstall -c q -c qrm ma6174echo 安装完成 这段脚本的目的是方便用户快速安装 Vim 及其依赖。首先，它通过检测系统包管理器（apt-get 或 yum）来安装必要的软件包。这样的设计保证了在不同 Linux 发行版上的兼容性。它还为 Mac 用户提供通过 HomeBrew 安装的选项。 具体步骤： 安装 Vim 和其他工具：根据系统类型，脚本会安装 Vim、ctags、xclip 等包，使用户可以编辑代码、生成标签等。 **自动安装 autopep8**：这是一个格式化 Python 代码的工具，通过简单的命令行可以保持代码风格的统一。 克隆配置库：从 GitHub 克隆自定义的 Vim 配置，确保用户能收到最新的配置与功能。 2. 配置cd /usr/includesudo ctags -Rcd -vim .vimrc 在配置 Vim 的过程中，用户首先切换到 /usr/include 目录，执行 sudo ctags -R 命令，生成整个目录下文件的标签。这一操作将帮助 Vim 实现高效的代码跳转和自动补全，提升开发效率。 接下来，用户需要编辑 .vimrc 配置文件： set tags=/usr/include/tags 此行配置指明了 Vim 使用 /usr/include 目录下的标签文件，以加速代码导航。 3. 安装 zshZsh（Z Shell）是一种灵活且功能丰富的命令行 Shell，相对于默认的 Bash，它提供了许多便利的特性。例如，Zsh 有出色的自动补全机制，可以根据输入的部分命令推测用户的意图；同时，它的历史记录管理也做得非常出色，能够快速找到过去执行的命令。 安装与设置 Zsh用户可以通过以下命令安装 Zsh，并将其设置为默认 Shell： sudo apt install zshchsh -s /bin/zsh sudo apt install zsh 安装 Zsh 命令行工具。 chsh -s /bin/zsh 更改当前用户的默认 Shell 为 Zsh，从此开始使用更加强大的命令行体验。用户在下次登录后就会看到 Zsh 的界面。","categories":["3.软件","VIM"]},{"title":"Sqlie使用","path":"/2024/05/22/3-软件-数据库-Sqlie使用/","content":"数据库基础安装数据库 sudo apt-get install sqlite3 数据库指令操作打开一个数据库 sqlite3 my.db 常用查询: .table //查看数据库中的表.schema tablename //查看相应表的结构.database //查看当前打开的数据库.quit //退出当前数据库.help //列出帮助信息 创建表: create table movies (id int, name text, time int, auth text); 删除表: drop table tablename; 添加信息: insert into movies values (.....);insert into movies values (.....); 查询信息: select * from movies ; 删除信息: delete from movies where id=1; 更新信息: update tablename set name= where id=2; 添加字段: alter table tablename add column sex char ; //创建名字为tong.db的数据库sqlite3 tong.db//创建一个叫user的table,里面有name, agecreate table user(name, age integer);//name的默认类型是字符串，用“taotao”//age的类型相当于int//删除一个tabledrop table user;//向user中存储数据insert into user values（“taotao”, 18）;//增加一个column叫num,类型是 integeralter table user add column num integer;//更新数据update user set name=taotao,age=18 where num=110;//打印所有信息select * from user;//打印某一个信息select * from user where name=taotao;//删除一个叫taotao的人delete from user where name=taotao;//查看有哪几个表.tables//查看某一个表的属性.schema user//退出.q 示例代码#include stdio.h#include stdlib.h#include sqlite3.h#include string.h#define SQL_NAME ./chen.db#define TAB_NAME tbint fun(void *buf, int num, char **val, char **name)\tint i;\tfor(i = 0; i num; ++i) printf(%s:%s , name[i], val[i]); printf(========%d=== , num);\treturn 0;int main(int argc, const char *argv[])\tchar buf[200] = \\0;\tsqlite3 *db = NULL;\tif(SQLITE_OK != sqlite3_open(SQL_NAME, db)) fprintf(stderr, OPEN SQLITE3 ERROR. ); exit(EXIT_FAILURE);\t#if 1\t/* #include stdio.hint main()\tchar a = A;\tchar buf[80];\tsprintf(buf, The ASCII code of a is %d. , a);\tprintf(%s, buf);\treturn 0;输出ASCII 的值*/\tsprintf(buf, create table if not exists %s (id, sex, score float);, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, NULL, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE);\t/*\t功 能: 将s所指向的某一块内存中的每个字节的内容全部设置为ch指定的ASCII值, *\t块的大小由第三个参数指定,这个函数通常为新申请的内存做初始化工作 */\tmemset(buf, 0 , sizeof(buf));\tsprintf(buf, insert into %s values(chen, B, 90);, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, NULL, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE); #endif\tmemset(buf, 0, sizeof(buf));\tsprintf(buf, select * from %s ;, TAB_NAME);\tif(SQLITE_OK != sqlite3_exec(db, buf, fun, NULL, NULL)) fprintf(stderr, CREATE TABLE ERROR:%s , sqlite3_errmsg(db)); exit(EXIT_FAILURE); sqlite3_close(db);\treturn 0;","categories":["3.软件","数据库"]},{"title":"大小端字节序和位序","path":"/2024/05/22/1-语言-C语言-位运算-大小端字节序和位序/","content":"大小端的数据反向例：一个 32 位 unsigned long 数据类型的反向 unsigned long wrd;wrd = ((wrd0xFF000000)24)|((wrd0x00FF0000)8)|((wrd0x0000FF00)8)|((wrd0x000000FF)24); 对 wrd 变量中的 32 位整数进行字节反转，即将字节顺序从大端格式（big-endian）转换为小端格式（little-endian），或反之。具体来说，这段代码将 wrd 中的 4 个字节的位置互换。 ((wrd0xFF000000)24) 提取 wrd 的最高字节（第 1 个字节），并右移 24 位，将其移到最低字节位置。 ((wrd0x00FF0000)8) 提取 wrd 的第 2 个字节，并右移 8 位，将其移到倒数第 2 个字节位置。 ((wrd0x0000FF00)8) 提取 wrd 的第 3 个字节，并左移 8 位，将其移到第 2 个字节位置。 ((wrd0x000000FF)24) 提取 wrd 的最低字节（第 4 个字节），并左移 24 位，将其移到最高字节位置。 最后，通过按位或运算 (|) 将这些位组合成新的 32 位整数，从而实现字节顺序的完全反转。例如，将 0x12345678 变为 0x78563412。 按位逆序unsigned long wrd;wrd = (((wrd0xaaaaaaaa)1)|((wrd0x55555555)1));wrd = (((wrd0xcccccccc)2)|((wrd0x33333333)2));wrd = (((wrd0xf0f0f0f0)4)|((wrd0x0f0f0f0f)4));wrd = (((wrd0xff00ff00)8)|((wrd0x00ff00ff)8));return ((wrd16) | (wrd16)); 将 wrd 变量中的 32 位整数按位进行反转（即将二进制的最高位与最低位交换，次高位与次低位交换，以此类推），实现32 位整数的比特翻转。 代码的实现分多个步骤，逐步实现位的反转： wrd = (((wrd0xaaaaaaaa)1)|((wrd0x55555555)1)); 将 wrd 的相邻两位互换（奇数位与偶数位互换）。 wrd = (((wrd0xcccccccc)2)|((wrd0x33333333)2)); 将 wrd 的每 2 位组内的位互换。 wrd = (((wrd0xf0f0f0f0)4)|((wrd0x0f0f0f0f)4)); 将 wrd 的每 4 位组内的位互换。 wrd = (((wrd0xff00ff00)8)|((wrd0x00ff00ff)8)); 将 wrd 的每 8 位组内的位互换。 return ((wrd16) | (wrd16)); 将 wrd 的高 16 位和低 16 位交换。 最终结果是 wrd 中的 32 位被完全按位反转，如将 0x12345678 变为 0x1E6A2C48。 大小端字节序大端字节序（Big-Endian）和小端字节序（Little-Endian）是两种不同的字节存储顺序方式，用于在多字节数据类型（如整数、浮点数）在内存中的表示。不管是 Motorla 模式还是 Intel 模式，只有数据存在跨字节存储的时候，才会有所区别，单个字节数据两者无差异。大端模式（motolora）下，数据的处理方式和平常手写的顺序相同。 信号的起始位就是信号的最低位。 LSB：least significant byte(某个信号的最低字节) MSB：most significant byte(某个信号的最⾼字节) lsb：least significant bit(某个信号中某个字节的最低有效位) msb：most significant bit(某个信号中某个字节的最⾼有效位) 大端字节序 大端模式也称 Motorla 模式，存储数据的格式为高字节（最高有效字节）保存在低的存储地址，而低字节（最低有效字节）保存在高的存储地址。 数据的高位字节存储在低地址位置，低位字节存储在高地址位置。例如，整数值 0x12345678 在大端字节序中的存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 小端字节序小端模式也称 Intel 模式，存储数据的格式为低字节保存在较低的存储地址，而高字节保存在高的存储地址。 数据的低位字节存储在低地址位置，高位字节存储在高地址位置。使用同样的示例值 0x12345678，小端字节序的存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 扩展数据在存储器中的存放顺序位序 z 字节中位序 - 升序：lsb 在一个 Byte 的最右边，msb 在一个 Byte 的最左边： Byte：b7-b6-b5-b4-b3-b2-b1-b0 字节中位序 - 降序：lsb 在一个 Byte 的最左边，msb 在一个 Byte 的最右边： Byte：b0-b1-b2-b3-b4-b5-b6-b7 字节序 小端存储： 对于大于一个字节的数据类型的数据，在存储器中，低字节存储在低地址，高字节存储在高地址； 大端存储： 对于大于一个字节的数据类型的数据，在存储器中，高字节存储在低地址，低字节存储在高地址； 变量如果我们直接在程序中使用一个 Uint16 的变量，不使用指针时，使用方式如下： 获取该变量的低字节：Uint8 Temp = (Uint8)(gusVar 0xFF) 获取该变量的高字节：Uint8 Temp = (Uint8)((gusVar 8) 0xFF) 将该变量赋给其他变量：Uint16 Temp = gusVar; 如果我们使用指针来获取存储在 0 和 1 地址的值”0x5A5”，分为以下情况： 存储方式是大端，0 地址放 0x05，1 地址放 0xA5: 存储方式是小端，0 地址放 0xA5，1 地址放 0x05; 存放顺序数据在报文中的存放顺序依赖于字节序和字节中的位序排序方式，一般情况下： 字节序：Byte0、Byte1、Byte2、Byte3、Byte4、Byte5、Byte6、Byte7 位序：bit7、bit6、bit5、bit4、bit3、bit2、bit1、bit0 Motorola_LSB 和 Motorola_MSB 的区别是某个信号起始位置确定的情况下，在报文中的映射空间不一样，映射顺序一样(低字节放在高字节，高字节放在低地址，位序都是从右到左是 b0 到 b7)。 Intel(小端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte1 = (gstrMsg.Byte1 0x0F) | ((Uint8)(gusVal 0x0F) 4); gstrMsg.Byte2 = (gstrMsg.Byte2 0xF0) | ((Uint8)(gusVal 0xF0) 4); gstrMsg.Byte2 = (gstrMsg.Byte2 0x0F) | ((Uint8)((gusVal 8) 0x0F)); Motorola_LSB(大端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte0 = (Uint8)((gusVal 4) 0xFF);gstrMsg.Byte1 = (gstrMsg.Byte1 0x0F) | ((Uint8)(gusVal 4)); Motorola_MSB(大端) 信号值：0x5A5，二进制：010110100101b 信号起始位：byte1 的 bit4，在报文中的索引是 12 信号长度：12bit typedef struct Uint8 Byte0; Uint8 Byte1; Uint8 Byte2; Uint8 Byte3; Uint8 Byte4; Uint8 Byte5; Uint8 Byte6; Uint8 Byte7;IntelOrder;IntelOrder gstrMsg;Uint16 gusVal = 0x5A5;gstrMsg.Byte1 = (gstrMsg.Byte1 0xE0) | ((Uint8)((gusVal 7) 0x1F));gstrMsg.Byte2 = (gstrMsg.Byte2 0xFE) | ((Uint8)(gusVal 0x7F)); 传输顺序 字节顺序：先传 Byte0，最后传 Byte7； 字节内位序：先传 bit7，最后传 bit0； 64 位和 32 位的不同64 位和 32 位的大小端情况是类似的，但存在一些细微差异。在 64 位系统中，数据被划分为 8 字节（64 位），而在 32 位系统中，数据被划分为 4 字节（32 位）。因此，字节的顺序和对齐方式在这两种情况下可能会有所不同。 例如，考虑一个 64 位整数值 0x1122334455667788。在大端字节序中，存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 而在小端字节序中，存储顺序如下： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x88 0x77 0x66 0x55 0x44 0x33 0x22 0x11 比较整数值 0x12345678 在 64 位和 32 位系统上，以大端字节序和小端字节序存储的示例： 64 位系统大端字节序： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x12 0x34 0x56 0x78 0x00 0x00 0x00 0x00 64 位系统小端字节序： 地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x00 0x00 0x00 0x00 0x78 0x56 0x34 0x12 32 位系统大端字节序： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 32 位系统小端字节序： 地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 影响字节序的选择对于不同的计算机体系结构和通信协议至关重要。它主要影响以下方面： 数据传输：在网络通信和数据交换中，如果通信双方使用不同的字节序，就需要进行字节序的转换，以确保正确解释和传输数据。 文件格式：某些文件格式（如图像、音频、视频）可能使用特定的字节序来存储数据，因此读取和解析这些文件时需要考虑字节序。 处理器架构：不同的处理器架构可能采用不同的字节序。例如，x86 架构使用小端字节序，而 PowerPC 架构使用大端字节序。在开发软件时，需要根据目标处理器架构的字节序选择适当的数据处理方式。 正确地处理字节序是确保跨平台兼容性和数据一致性的重要方面，特别是在网络通信和数据交换的情况下。 校验方法int main() unsigned int num = 0x01020304; unsigned char *ptr = (unsigned char*)num; if (*ptr == 0x01) printf(大端字节序 ); else printf(小端字节序 ); return 0;//联合体int checkCPU()\tunion w int a; char b;\tc;\tc.a = 1;\treturn(c.b==1)","categories":["1.语言","C语言","位运算"]},{"title":"网络配置","path":"/2024/05/22/0-平台-Linux-网络-网络配置/","content":"TCPIP 网络相关概念 配置以太网络接口 配置 ppp 网络接口 Linux 环境下的网络配置 检测网络配置 TCPIP 网络相关概念 TCPIP 协议 IP 地址、子网掩码和域名 路由选择和网关地址 端到端连接 Linux 的网络应用 Linux 的网络接口设备 在网络中使用的每一个外围设备的网络接口，在 Linux 的核心（kernel）中都有相应的名字。 网络接口设备和相关的设备接口名：lo 本地回送接口。用于网络软件测试以及本地机进程间通信，无论什么程序一旦使用回送地址发送数据，协议软件立即将其返回，不进行任何网络传输。在 Linux 系统中，回送设备是默认设置好的。ethn 第 n 个以太网卡接口 (n 为 0 表示第一块，以此类推)，eth 是大多数网卡的接口设备名。pppn 第 n 个 ppp 接口。PPP 接口按照与它们有关的 PPP 配置顺序连接在串口上。 网络配置命令 hostnameLinux– 查看或配置计算机的主机名 ifconfig– 查看或配置网络接口 ifup– 启用指定的网络接口 ifdown– 禁用指定的网络接口 route– 查看或配置内核路由表的配置情况 配置以太网络－使用命令 配置 IP 地址 – # ifconfig [interface] [ip-address] [netmask …] [broadcast … ] [up] [down]- 配置默认网关– # route add default gw IP 地址– #route add 0.0.0.0 netmask 0.0.0.0 eth0- 配置 DNS 客户– # vi /etc/resolv.conf TCPIP 配置文件etcsysconfignetwork 主机最基本网络信息，用于系统启动 etcsysconfignetwork-scripts 系统启动初始化网络信息 etcxinetd.conf 定义由超级进程 xinetd 启动的网络服务 etchosts 主机和 ip 映射 etchost.conf DNS 客户端搜索顺序 etcresoly.conf 指定 DNS 地址 etcserveices 编辑etcsysconfigentwork-scriptifcfg-eth0 文件 Linux 支持一块网卡绑定多 IP，编辑子接口配置文件 ifcfg-eth0:1 Netconfig 调用菜单 配置 ADSL 网络接口 安装 pppoerpm –qa |grep pppoe 配置 pppoeadsl-setupetcsysconfignetwork-scriptifcfg-ppp0adsl-status 启用和挂断 ADSL 网络连接adsl-start (或 ifup ppp0)adsl-stop (或 ifdown ppp0) 网络测试一般方法 排除非自身因素 查看本机 IP 地址 检测与网关的连接 监测与互联网的连接 测试域名解析 测试与特定站点的连接 检测网络状态 Ifconfig– 检测网络接口 ping– 检测网络连通性 netstat– 查看网络状态 traceroute– 检测到目的主机所经过的路由器 tcpdump– 显示本机网络流量的状态 配置网卡信息IP、网关、掩码 /etc/network/interfaces DNS /etc/resolv.conf 》重启网卡 sudo service networking restart /etc/sysconfig/network-scripts/ifcfg-eno16777736TYPE=Ethernet(设备类型） BOOTPROTO=static（地址分配模式） NAME=eno16777736 ONBOOT=yes（是否启用）IPADDR=192.168.10.10 NETMASK=255.255.255.0 GATEWAY=192.168.10.1 DNS1=192.168.10.1 》重启网卡 systemctl restart network 桥方式 Bridge桥方式下的虚拟机与主机地位相等，IP 地址与主机要在同一网段，网关、DNS 指向要与主机指向一致。虚拟机 IP 地址可以自动获得，也可以手工指定。如果是自动获得，则由主机或主机所在网络中的其它电脑担任 DHCP 服务器。 NAT 方式在 NAT 方式，主机除原来的网卡(C)外，还有一块隐藏网卡(B)，虚拟机网卡（A）的网关必须指向 B。在用 NAT 方式时，虚拟机上的 IP 地址一般设置为自动获得，这时主机中的 DHCP 服务器(由 vmware 软件提供）负责 IP 地址的分配。 主机网卡 B 的 IP 地址为 192.168.153.2，所以虚拟机网卡 A 的 IP 信息如下： IP 地址：192.168.153.139 子网掩码：255.255.255.0 网关：192.168.153.2 DNS：192.168.153.2 host-ONLY 方式host-only 方式的网络结构图与 NAT 方式相同，只是主机在担任网关功能，所以虚拟机只能与主机通讯，但不能与主机所在网络中的其它主机通讯。 默认情况下：新建虚拟机的网卡工作在桥方式，IP 地址建议手工指定，如果使用 NAT 方式，IP 地址建议设为自动获得。通过分析我们知道，虚拟机的 IP 地址用手工指定的方式也是可以的。只要 IP 地址与主机网卡 B 在同一网段，网关、DNS 指向网卡 B 的 IP 即可。 设置 Linux 的 IP 地址在终端方式下用命令行配置 IP 地址和默认网关。 sudo ifconfig eth0 192.168.152.30 netmask 255.255.255.0sudo route add default gw 192.168.152.2 注意：本来的命令应该是 ifconfig …….和 route ……，没有前面的 sudo 单词，应该我们登录 LINUX 使用的是普通帐号 test，它没有修改系统 IP 地址的权限，所以使用 sudo 命令，就是临时用管理员身份对系统进行设置，但输入的口令只要是当前用户的口令即可。 设置网卡的 DNS 服务器地址在一个网络中，DNS 服务器的作用是非常大的，它的主要功能是把类似 www.sxszjzx.com 这样的主机域名，翻译成 172.18.0.5 这样的 IP 地址。所以每台上网的电脑都必须有一个 DNS 服务器地址，也可以指定多个。LINUX 中设置 DNS 服务器地址的文件位置etcresolv.conf。在终端中以 sudo gedit etcresolv.conf 命令打开，就可以修改","categories":["0.平台","Linux","网络"]},{"title":"Linux命令","path":"/2024/05/22/0-平台-Linux-系统参数-Linux命令/","content":"计算机硬件：运算器，控制器，存储器，输入输出设备等共同组成的 系统内核：让各种硬件设备各司其职且又能协同运行 嵌入式开发中常常需要确认开发板的系统版本，CPU，各种外部设备，内寸占用情况等数据。 终端一个基于文本的交互界面 快捷键 打开命令行终端 Ctrl+Alt+t 放大终端 Ctrl Shirft + 缩小终端 Ctrl - 终端提示符含义lemonade@ubuntu:~$ 对应用户名 (lemonade)@主机名 (ubuntu): 工作目录 (~) 提示符 ($) ~：家目录 $: 普通用户#: 超级用户 (root) 命令— 在终端中用于告诉计算机去执行一个动作 参数— 选项— 选项通常用一个连接号（-）或两个连接号（--）来划分 常用 ls: 列出当前目录内容 cd ~: 进入当前用户的家目录 ./ 当前目录 (可省略) ../ 上一层目录 ../../ 上一层的上一层 文件操作指令 mkdir 创建文件夹 mkdir mydir touch 创建空文件 touch myfile rmdir 删除一个空文件夹 rm 删除一个文件或文件夹,默认删除文件 rm -r 删除文件夹 打印定向指令 echo 打印一串字符 echo hello world 输出重定向指定输出的目标文件 向指定文件中追加内容 cat 读文件内容并打印 cat readme rootsudo sudo passwd 通过普通用户修改超级用户 (root) 的密码. su root 切换用户为 root 用户 (超级用户) su lemonade 切换为 lemonade 用户. sudo 用普通用户权限执行 root 的功能 普通用户权限执行 root 的功能需注意用户环境下的环境变量和 root 用户环境的下环境变量是否一致 移动拷贝指令 mv 移动命令 mv source dest``mv source dir cp 拷贝命令 man 用户帮助手册 man ls ls [options]... [file]... options 选项或参数 file 目标文件或文件夹 [] 可选标志 ... 多参机制 改变权值的命令 chmod 777 readme.sh 所有用户可读可写可执行 文件类型: - ：普通文件d : 文件夹目录l : 链接 (快捷方式)s : 网络套接字p: 管道b : 块设备, 磁盘 c : 字符设备, 键盘 关机 halt 关机 reboot 重启 sudo shutdown -h now 加上关机时间 sudo shutdown -h +1 See You la la 加上关机备注 shell 命令参数可以用长格式（完整的选项名称）man --help，也可以用短格式（单个字母的缩写）man -h，分别用 -- 与 - 作为前缀。 系统工作命令echo 命令用于在终端输出字符串或变量提取后的值，格式为“echo [字符串 | $变量]”。 date 命令用于显示及设置系统的时间或日期，格式为“date [选项] [+指定的格式]”。 poweroff wget 命令用于在终端中下载网络文件，格式为“wget [参数] 下载地址”。 ps 命令用于查看系统中的进程状态，格式为“ps [参数]”。 -b 后台下载模式 -P 下载到指定目录 -t 最大尝试次数 -c 断点续传 -p 下载页面内所有资源，包括图片、视频等 -r 递归下载 -a 显示所有进程（包括其他用户的进程） -u 用户以及其他详细信息 -x 显示没有控制终端的进程 |USER|PID |%CPU| %MEM|VSZ |RSS |TTY| STAT| START| TIME |COMMAND||进程的所有者|进程 ID 号|运算器占用率|内存占用率|虚拟内存使用量(单位是 KB)|占用的固定内存量(单位是 KB)|所在终端|进程状态|被启动的时间|实际使用 CPU 的时间|命令名称与参数| top 命令用于动态地监视进程活动与系统负载等信息，其格式为 top。 第 1 行：系统时间、运行时间、登录终端数、系统负载（三个数值分别为 1 分钟、5 分钟、15 分钟内的平均值，数值越小意味着负载越低）。 第 2 行：进程总数、运行中的进程数、睡眠中的进程数、停止的进程数、僵死的进程数。 第 3 行：用户占用资源百分比、系统内核占用资源百分比、改变过优先级的进程资源百分比、空闲的资源百分比等。其中数据均为 CPU 数据并以百分比格式显示，例如“97.1 id”意味着有 97.1%的 CPU 处理器资源处于空闲。 第 4 行：物理内存总量、内存使用量、内存空闲量、作为内核缓存的内存量。 第 5 行：虚拟内存总量、虚拟内存使用量、虚拟内存空闲量、已被提前加载的内存量。 pidof 命令用于查询某个指定服务进程的 PID 值，格式为“pidof [参数] [服务名称]”。 kill 命令用于终止某个指定 PID 的服务进程，格式为“kill [参数] [进程 PID]”。 killall 命令用于终止某个指定名称的服务所对应的全部进程，格式为：“killall [参数] [服务名称]”。 系统状态检测命令ifconfig 命令用于获取网卡配置与网络状态等信息，格式为“ifconfig [网络设备] [参数]”。 uname 命令用于查看系统内核与系统版本等信息，格式为“uname [-a]”。 uptime 用于查看系统的负载信息，格式为 uptime。 free 用于显示当前系统中内存的使用量信息，格式为“free [-h]”。 who 用于查看当前登入主机的用户终端信息，格式为“who [参数]”。 last 命令用于查看所有系统的登录记录，格式为“last [参数]”。 history 命令用于显示历史执行过的命令，格式为“history [-c]”。（用“!数字”的命令格式重复执行某一次的命令记录） sosreport 命令用于收集系统配置及架构信息并输出诊断文档，格式为 sosreport。 工作目录切换命令pwd 命令用于显示用户当前所处的工作目录，格式为“pwd [选项]”。 cd 命令用于切换工作路径，格式为“cd [目录名称]”。 ls 命令用于显示目录中的文件信息，格式为“ls [选项] [文件] ”。 文本文件编辑命令cat 命令用于查看纯文本文件（内容较少的），格式为“cat [选项] [文件]”。（-n 显示行号） more 命令用于查看纯文本文件（内容较多的），格式为“more [选项]文件”。 head 命令用于查看纯文本文档的前 N 行，格式为“head [选项] [文件]”。 tail 命令用于查看纯文本文档的后 N 行或持续刷新内容，格式为“tail [选项] [文件]”。 tr 命令用于替换文本文件中的字符，格式为“tr [原始字符] [目标字符]”。（cat a.txt | tr [a-z] [A-Z]） wc 命令用于统计指定文本的行数、字数、字节数，格式为“wc [参数] 文本”。(-l 行数-w 单词数-c 字节数) stat 命令用于查看文件的具体存储信息和时间等信息，格式为“stat 文件名称”。 cut 命令用于按“列”提取文本字符，格式为“cut [参数] 文本”。 diff 命令用于比较多个文本文件的差异，格式为“diff [参数] 文件”。（–brief 确认两个文件是否不同，-c 比较差异之处） 文件目录管理命令touch 命令用于创建空白文件或设置文件的时间，格式为“touch [选项] [文件]”。 -a 仅修改“读取时间”（atime）-m 仅修改“修改时间”（mtime）-d 同时修改 atime 与 mtime mkdir 命令用于创建空白的目录，格式为“mkdir [选项] 目录”。 cp 命令用于复制文件或目录，格式为“cp [选项] 源文件 目标文件”。 mv 命令用于剪切文件或将文件重命名，格式为“mv [选项] 源文件 [目标路径|目标文件名]”。 rm 命令用于删除文件或目录，格式为“rm [选项] 文件”。 dd 命令用于按照指定大小和个数的数据块来复制文件或转换文件，格式为“dd [参数]”。 （dd if=/dev/zero of=560_file count=1 bs=560M）（dd if=/dev/cdrom of=RHEL-server-7.0-x86_64-LinuxProbe.Com.iso） if 输入的文件名称 of 输出的文件名称 bs 设置每个“块”的大小 count 设置要复制“块”的个数 file 命令用于查看文件的类型，格式为“file 文件名”。 打包压缩与搜索命令tar 命令用于对文件进行打包压缩或解压，格式为“tar [选项] [文件]” -c 创建压缩文件 -x 解开压缩文件 -t 查看压缩包内有哪些文件 -z 用 Gzip 压缩或解压 -j 用 bzip2 压缩或解压 -v 显示压缩或解压的过程 -f 目标文件名 -p 保留原始的权限与属性 -P 使用绝对路径来压缩 -C 指定解压到的目录 grep 命令用于在文本中执行关键词搜索，并显示匹配的结果，格式为“grep [选项] [文件]”。 -b 将可执行文件(binary)当作文本文件（text）来搜索 -c 仅显示找到的行数 -i 忽略大小写 -n 显示行号 -v 反向选择——仅列出没有“关键词”的行。 find 命令用于按照指定条件来查找文件，格式为“find [查找路径] 寻找条件 操作”。 -name 匹配名称 -perm 匹配权限（mode 为完全匹配，-mode 为包含即可） -user 匹配所有者 -group 匹配所有组 -mtime -n +n 匹配修改内容的时间（-n 指 n 天以内，+n 指 n 天以前） -atime -n +n 匹配访问文件的时间（-n 指 n 天以内，+n 指 n 天以前） -ctime -n +n 匹配修改文件权限的时间（-n 指 n 天以内，+n 指 n 天以前） -nouser 匹配无所有者的文件 -nogroup 匹配无所有组的文件 -newer f1 !f2 匹配比文件 f1 新但比 f2 旧的文件 -type bdcplf 匹配文件类型（后面的字幕字母依次表示块设备、目录、字符设备、管道、链接文件、文本文件） -size 匹配文件的大小（+50KB 为查找超过 50KB 的文件，而-50KB 为查找小于 50KB 的文件） -prune 忽略某个目录 -exec …… {}; 后面可跟用于进一步处理搜索结果的命令 进程状态： R（运行）：进程正在运行或在运行队列中等待。 S（中断）：进程处于休眠中，当某个条件形成后或者接收到信号时，则脱离该 状态。 D（不可中断）：进程不响应系统异步信号，即便用 kill 命令也不能将其中断。 Z（僵死）：进程已经终止，但进程描述符依然存在, 直到父进程调用 wait4()系统函数后将进程释放。 T（停止）：进程收到停止信号后停止运行。 管理员口令丢失解决办法 开机从 LILO 或 GRUB 中选择进入单用户模式（运行级别 1） 使用 passwd 命令修改 root 口令 重新切换为运行级别 3 或 5 sudo –s # 切换到 root 用户，但是不切换用户环境 操作系统uname -a #查看内核 head -n 1 /etc/issue #查看操作系统版本 cat /proc/cpuinfo #查看CPU信息 hostname #查看计算机名 lspci -tv #列出所有PCI设备 lsusb -tv #列出所有USB设备 lsmod #列出加载的内核模块 env #查看环境变量 资源free -m #查看内存使用量和交换区使用量 df -h #查看各分区使用情况 du -sh 目录名 #查看指定目录的大小 grep MemTotal /proc/meminfo #查看内存总量 grep MemFree /proc/meminfo #查看空闲内存量 uptime #查看系统运行时间、用户数、负载 cat /proc/loadavg #查看系统负载 磁盘和分区mount | column -t #查看挂接的分区状态 fdisk -l #查看所有分区 swapon -s #查看所有交换分区 hdparm -i /dev/hda #查看磁盘参数(仅适用于IDE设备) dmesg | grep IDE #查看启动时IDE设备检测状况 网络ifconfig #查看所有网络接口的属性 iptables -L #查看防火墙设置 route -n #查看路由表 netstat -nltp #查看所有监听端口 netstat -antp #查看所有已经建立的连接 netstat -s #查看网络统计信息 tcpdump 进程ps -aux # 显示瞬间行程 (process) 的动态 ps -ef #查看所有进程 top #实时显示进程状态 nice -n 1 ls # 将 ls 的优先序加 1 并执行 renice +1 987 -u daemon root -p 32 # 将行程 id 为 987 及 32 的行程与行程拥有者为 daemon 及 root 的优先序号码加 1 kill # 送出一个特定的信号 (signal) 给行程 id 为 pid 的行程根据该信号而做特定的动作, 若没有指定, 预设是送出终止 (TERM) 的信号 killall proc bg fg fg n pstree # 将所有行程 (process) 以树状图显示 skill # 送个讯号给正在执行的程序,预设的讯息为 TERM (中断) 用户w #查看活动用户 id 用户名 #查看指定用户信息 last #查看用户登录日志 cut -d: -f1 /etc/passwd #查看系统所有用户 cut -d: -f1 /etc/group #查看系统所有组 crontab -l #查看当前用户的计划任务 crontab 0 6-12/3 * 12 * /usr/bin/backup # 在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backup at 5pm + 3 days /bin/ls # 三天后的下午 5 点执行 /bin/ls: login passwd 服务chkconfig --list #列出所有系统服务 chkconfig --list | grep on #列出所有启动的系统服务 程序rpm -qa #查看所有安装的软件包 文件命令ls -alrtFR filename cut pwd mkdir/rmdir dir rm -rf dir cp -r dest source # 将目录下之档案亦皆依序拷贝至目的地 mv file1 file2 ln -s yy zz # 将档案 yy 产生一个 symbolic link:zz ,不加s为硬链接 touch filename #将档案的时候记录改为现在的时间。若档案不存在,系统会建立新的档案。 cat file more -s testfile # 逐页显示 testfile 之档案内容,如有连续两行以上空白行则以一行空白行显示。 more +20 testfile # 从第 20 行开始显示 testfile 之档案内容。 less filename # 浏览文字档案的内容 head file tail file tail -f file cat # 把档案串连接后传到基本输出（萤幕或加 fileName 到另一个档案） diff -u a.patch oldfile newfile # 可以完成比较功能，生成补丁文件 patch -i a.patch filname # 命令用于打补丁，补丁文件是使用diff产生的 split -b 1m filename filename.dump. # 将filename分割为1M大小，分割后的文件名为filename.dump.aa，filename.dump.ab... tr #指令从标准输入设备读取数据，经过字符串转译后，将结果输出到标准输出设备。 SSHssh user@host ssh -p port user@host ssh-copy-id user@host 压缩tar cf file.tar files tar xf file.tar tar czf file.tar.gz files tar xzf file.tar.gz tar cjf file.tar.bz2 tar xjf file.tar.bz2 gzip file gzip -d file.gz compress -f source.dat # 将 source.dat 压缩成 source.dat.Z，解压-d tar cjf - logs/ | split -b 1m - logs.tar.bz2 # 将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令 cat logs.tar.bz2.a* | tar xj # 分包解压 文件权限chmod a+x filename # 对文件增加权限 chown -R dirname # 对目前目录下的所有档案与子目录进行相同的拥有者变更 搜索grep pattern files grep -r pattern dir command | grep pattern find path -name filename* # 在 path 路径下查找所有以 filename 开头的文件 locate chdrv # 寻找所有叫 chdrv 的档案 expr #字串长度/从位置处抓取字串/出现次数 网络ping host whois domain dig domian dig -x host wget file wget -c file scp test.c root@192.168.7.1:/home/root\t# SCP 拷贝数据 系统信息date # 显示或设定系统的日期与时间 cal # 显示本月的月历 uptime # 显示开机时间等信息 who # 显示系统中有那些使用者正在上面 whoami finger user cat /proc/cpuinfo cat /proc/meminfo man command free file [filename]\t# 可查看可执行文件是 ARM 架构还是 X86 架构 uname -a\t# 显示电脑以及操作系统的相关信息 df\t# 查看磁盘 mount\t# 挂载 umount\t# 卸载 sync\t# 卸载之前同步数据 cat /sys/kernel/debug/usb/devices\t# 查看 USB 类型 time使用方式： time [options] COMMAND [arguments] 使用说明： time 指令的用途,在于等等。需要特别注意的是,部分资讯在 Linux 上显示不出来。这是因为在 Linux 上部分资源的分配函式与 time 指令所预设的方式并不相同,以致于 time 指令无法取得这些资料。 -o or –outputFILE 设定结果输出档。这个选项会将 time 的输出写入 所指定的档案中。如果档案已经存在,系统将覆写其内容。 -a or –append 配合 -o 使用,会将结果写到档案的末端,而不会覆盖掉原来的内容。 -f FORMAT or –formatFORMAT 以 FORMAT 字串设定显示方式。当这个选项没有被设定的时候,会用系统预设的格式。不过你可以用环境变数 time 来设定这个格式,如此一来就不必每次登入系统都要设定一次。 一般设定上,你可以用 \\t 表示跳栏,或者是用 表示换行。 每一项资料要用 % 做为前导。如果要在字串中使用百分比符号,就用.（学过 C 语言的人大概会觉得很熟悉） time 指令可以显示的资源有四大项,分别是： Time resources Memory resources IO resources Command info 详细的内容如下： Time Resources E 执行指令所花费的时间,格式是：[hour]:minute:second。请注意这个数字并不代表实际的 CPU 时间。 e 执行指令所花费的时间,单位是秒。请注意这个数字并不代表实际的 CPU 时间。 S 指令执行时在核心模式（kernel mode）所花费的时间,单位是秒。 U 指令执行时在使用者模式（user mode）所花费的时间,单位是秒。 P 执行指令时 CPU 的占用比例。其实这个数字就是核心模式加上使用者模式的 CPU 时间除以总时间。 Memory Resources M 执行时所占用的实体记忆体的最大值。单位是 KB t 执行时所占用的实体记忆体的平均值,单位是 KB K 执行程序所占用的记忆体总量（stack+data+text）的平均大小,单位是 KB D 执行程序的自有资料区（unshared data area）的平均大小,单位是 KB p 执行程序的自有堆叠（unshared stack）的平均大小,单位是 KB X 执行程序间共享内容（shared text）的平均值,单位是 KB Z 系统记忆体页的大小,单位是 byte。对同一个系统来说这是个常数 IO Resources F 此程序的主要记忆体页错误发生次数。所谓的主要记忆体页错误是指某一记忆体页已经置换到置换档（swap file)中,而且已经分配给其他程序。此时该页的内容必须从置换档里再读出来。 R 此程序的次要记忆体页错误发生次数。所谓的次要记忆体页错误是指某一记忆体页虽然已经置换到置换档中,但尚未分配给其他程序。此时该页的内容并未被破坏,不必从置换档里读出来 W 此程序被交换到置换档的次数 c 此程序被强迫中断（像是分配到的 CPU 时间耗尽）的次数 w 此程序自愿中断（像是在等待某一个 I/O 执行完毕,像是磁碟读取等等）的次数 I 此程序所输入的档案数 O 此程序所输出的档案数 r 此程序所收到的 Socket Message s 此程序所送出的 Socket Message k 此程序所收到的信号 ( Signal )数量 Command Info C 执行时的参数以及指令名称 x 指令的结束代码 ( Exit Status ) -p or –portability 这个选项会自动把显示格式设定成为： real %e user %U sys %S 这么做的目的是为了与 POSIX 规格相容。 -v or –verbose 这个选项会把所有程式中用到的资源通通列出来,不但如一般英文语句,还有说明。对不想花时间去熟习格式设定或是刚刚开始接触这个指令的人相当有用。 范例： 利用下面的指令 time -v ps -aux 我们可以获得执行 ps -aux 的结果和所花费的系统资源。如下面所列的资料： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.4 1096 472 ? S Apr19 0:04 init root 2 0.0 0.0 0 0 ? SW Apr19 0:00 [kflushd] root 3 0.0 0.0 0 0 ? SW Apr19 0:00 [kpiod] ...... root 24269 0.0 1.0 2692 996 pts/3 R 12:16 0:00 ps -aux Command being timed: ps -aux User time (seconds): 0.05 System time (seconds): 0.06 Percent of CPU this job got: 68% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 0 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 238 Minor (reclaiming a frame) page faults: 46 Voluntary context switches: 0 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 mail使用方式： mail [-iInv] [-s subject] [-c cc-addr] [-b bcc-addr] user1 [user 2 ...] 使用说明： mail 不仅只是一个指令, mail 还是一个电子邮件程式,不过利用 mail 来读信的人应该很少吧！对于系统管理者来说 mail 就很有用,因为管理者可以用 mail 写成 script ,定期寄一些备忘录提醒系统的使用者。 i 忽略 tty 的中断讯号。 (interrupt) I 强迫设成互动模式。 (Interactive) v 列印出讯息,例如送信的地点,状态等等。 (verbose) n 不读入 mail.rc 设定档。 s 邮件标题。 c cc 邮件地址。 b bcc 邮件地址。 范例： 将信件送给一个或以上的电子邮件地址,由于没有加入其他的选项,使用者必须输入标题与信件的内容等。而 user2 没有主机位置,就会送给邮件伺服器的 user2 使用者。 mail user1@email.address mail user1@email.address user2 将 mail.txt 的内容寄给 user2 同时 cc 给 user1 。如果将这一行指令设成 cronjob 就可以定时将备忘录寄给系统使用者。 mail -s 标题 -c user1 user2 mail.txt 1\t显示目录信息 #\tls\tls -a\t列出当前目录下的所有文件，包括以.头的隐含文件 #\tls\tls -l或ll\t列出当前目录下文件的详细信息 #\tls\tls -a\t显示所有文件，包含隐藏。 #\tls\tls -al\t显示所有文件的详细信息。\t2\t查看路径 #\tpwd\tpwd\t查看当前所在目录的绝对路经\t3\t目录切换 #\tcd\tcd ..\t回当前目录的上一级目录 #\tcd\tcd -\t回上一次所在的目录 #\tcd\tcd -p aa/bb/cc\t直接创建多级子目录 #\tcd\tcd ~ 或 cd\t回当前用户的宿主目录 #\tcd\tcd ~用户名\t回指定用户的宿主目录\t4\t创建目录 #\tmkdir\tmkdir 目录名\t创建一个目录 #\tmkdir\tmkdir –p\t递归式去创建一些嵌套目录 #\trmdir\tRmdir 空目录名\t删除一个空目录\t5\t创建文件 #\ttouch\ttouch 1.txt\t创建文件1.txt\t6\t删除操作 #\trm\trm 文件名 文件名\t删除一个文件或多个文件 #\trm\trm -rf 非空目录名\t递归删除一个非空目录下的一切，加-f不提示\t7\t查看文件 #\tcat\tcat 文件名\t一屏查看文件内容 #\tcat\tcat 路径/文件名 |grep 字符串\t在文件中匹配“字符串” #\tmore\tmore 文件名\t分页查看文件内容 #\tless\tless 文件名\t可控分页查看文件内容 #\tgrep\tgrep字符 文件名\t根据字符匹配来查看文件部分内容 #\tfind\tfind 路径 -name 字符串\t查找路径所在范围内满足字符串匹配的文件和目录 #\tfile\tfile 文件名\t查看文件类型 #\thead\thead -数字 文件名\t可以查看前n行，不加参数，默认为10. #\ttaill taill -数字 文件名\t可以查看后n行，不加参数，默认为10.\t8\t查看帮助 #\thelp cp\t查看内部命令cp #\tls --help |less 查看外部命令，分屏显示 #\tman cd\t查看cd帮助\t不分内部与外部命令 #\tinfo ls 查看 ls 信息 9\t复制文件 #\tcp\tcp /路经/文件 ./\t移动绝对路经下的文件到当前目录下 #\tcp /dev/cdrom linux4.iso 在字符界面上制作ISO镜像文件\t10\t移动文件 #\tmv\tmv 路经/文件 /经/文件\t移动相对路经下的文件到绝对路经下 #\tmv\tmv 文件名 新名称\t在当前目录下改名 #\tmv\tmv a.txt b.txt\t更改文件名 #\tmv\tmv 文件名 路径\t移动文件 #\tmv\tmv 路径/文件名 路径/文件名\t移动并更改文件名\t11\t系统管理 #\tdate\tdate 月日时分年\t更改计算机系统时间\t12\t文本编辑 #\tgedit\tgedit 文件名\t在图形界面下启动编辑器\t13\tvi模式间的切换 #\tvi\tvi tab切换命令与编辑模式\t打开vi编辑器 :q退出编辑环境 #\tvi\ta 从命令进入输入模式\t按ESC从输入模式进入命令模式。\t14\t文本编辑\t在命令模式下 读取文件 :e 新文件名\t一个文件完成后，打开新的文件。 :e! 新文件名\t强制关闭当前文件（不保存）并打开新文件 :f 文件名\t读取指定文件，并粘贴到光标所在行下 :w 保存已经命名的文件 :w 文件名\t保存未命名的文件 :w 文件名\t另存为文件名 :q 退出:q编辑器 :wq\t保存并退出 :q!\t不保存退出 h 光标左移 l\t光标右移 k\t光标上移 j\t光标下移\t15\t文本编辑\t在命令模式下 快速切换 快捷键ctrl+F\t前翻整页 快捷键ctrl+B\t后翻整页 快捷键ctrl+U\t前翻半页 快捷键ctrl+D\t后翻半页 :set nu\t在编辑器中显示行号 :200\t直接进入到第200行 :$\t进入最后一行\t16\t文本编辑\t在命令模式下 进入输入模式 i\t在当前光标处进入插入状态 a 在当前光标后进入插入状态 A\t将光标移动到当前行的行末，并进入插入状态 o\t在当前行的下面插入新行，并进入插入状态 O\t在当前行的上面插入新行，并进入插入状态\t17\t文本编辑\t在命令模式下 删除操作 cw\t删除当前光标所在单词尾部的字符，并进入插入状态 c$\t删除当前光标到行尾的字符，并进入插入状态 c^\t删除光标之前到行首的字符，并进入插入状态 3x\t删除当前光标处向右的3个字符 3dd\t删除当前行开始向下删除3行 3dw\t删除当前光标向右的3个单词 3de\t删除当前光标向右的3个单词，保留右面的空格 d$\t删除当前字符到行尾的所有字符 d^\t删除当前字符到行首的所有字符 J\t删除光标所在行尾的换行符 撤销操作 u\t取消最近的一次操作，并恢复操作结果 U\t取消当前行进行的所有操作 快捷键 Ctrl+R\t撤销命令u的取消操作\t18\t文本编辑\t命令模式 复制操作 4yy\t复制当前行及后续共4行的文本内容到vi缓冲区 7yw\t复制当前光标开始的7个单词到vi缓冲区 y$\t复制当前光标到行尾的内容到vi缓冲区 y^\t复制当前光标到行首的内容到vi缓冲区 :28,48y\t复制第28行到48行的内容到vi缓冲区 粘贴操作 p\t粘贴缓冲区内容到当前光标处，不覆盖文件已有内容\t19\t文本编辑 查找操作 /字符串\t从当前光标处开始向下查找指定字符串 n下 N上 ?字符串\t从当前光标处开始向上查找指定字符串 n下 N上\t20\t文本编辑\t命令模式 替换操作 :s/old/new\t在当前查找old替换成new.只替换当前行中第一个 :s/old/new/g\t替换行中所有“old”字符串为“new” :3,9s/old/new/g\t替换3-9行内所有“old”字符串为“new” :%s/old/new/g\t替换全文中所有“old”字符串为“new” 末尾加上参数c可强制每个替换都需要进行确认。 /new/c /gc (y、n、a、q)\t21\t文本编辑 #同时启动多个文件\tvi a.txt b.txt c.txt\t同时启动a.txt b.txt c.txt vi -o a.txt b.txt c.txt\t水平显示各个文件 vi -O a.txt b.txt c.txt\t垂直显示各个文件\t22\t文本编辑\t命令模式 文件之间切换操作 :args\t查看vi编辑器中多文件的状态（显示文件信息） :next\t多文件中向后切换 :prev\t多文件中前后切换 :first\t切换到多文件的首文件 :last\t切换到多文件的尾文件 快捷键ctrl+^\t切换到切换之前的文件\t23\t挂载光盘 #\tmount /dev/cdrom /media/cdrom 挂载光盘到/media/cdrom #\tumount /media/cdrom 卸载光盘，同umount -t iso9660 /media/cdrom\t24\t挂载U盘 #\tmount -t vfat /dev/sdb1 /media/cdrom 挂载U盘 #\tumount /media/cdrom 卸载U盘\t25\t创建用户及管理 #\tuseradd\tUseradd 用户名\t创建一个新的用户\t26 #\tchfn chfn 用户名\t输入用户信息\t27\t创建用户及管理 #\tuseradd\tuseradd -u 666 用户名\t创建一个ID号为666的新用户 #\tuseradd\tuseradd -e 12/22/2009 用户名\t创建一个2009/11/22日过期的用户 #\tuseradd\tuseradd -p 密码 用户名\t创建用户，并一同创建密码 #\tuseradd\tuseradd -g 组名 用户名\t创建用户并加入组（原组不存在，改加入新组） #\tuseradd\tuseradd -G 组名 用户名\t创建用户并加入组（原组存在，并加入新组）\t28\t用户相关修改 #\tusermod\tusermod -l 新名 旧名\t给用户改名 #\tusermod\tusermod -e 11/23/2009\t更改用户过期时间为2009/11/23 #\tusermod\tusermod -L 用户名\t禁用用户 #\tusermod\tusermod -U 用户名\t解锁用户 #\tuserdel\tuserdel 用户名\t删除用户，但不删除用户自家目录。 #\tuserdel\tuserdel -r 用户名\t删除用户，并删除用户自家目录。 #\tgroupadd\tGroupadd 组名\t创建一个新的组 #\tpasswd\tpasswd\t为root用户创建密码（修改） #\tpasswd\tPasswd 用户名\t为用户创建密码 #\tpasswd\tPasswd -d 用户名\t删除用户密码也能登陆 #\tpasswd\tPasswd -l 用户名\t锁定账号密码 #\tpasswd\tPasswd -u 用户名\t解锁账号密码 #\tpasswd\tPasswd -S 用户名\t查询账号密码\t29\t组相关修改 #\tGroups\tgroups 用户名\t查看用户所属组 #\tGroupadd\tgroupadd 用户名\t创建新用户 #\tGroupdel\tgroupdel组名 先应删它的用户\t删除组 #\tGroupmod groupmod –n新用户名 老用户名\t为组改名 #\tGroupmod groupmod –g 501 组名\t改变组GID #\tgpsswd\tgpasswd -d 用户名 组名\t把用户从组中删除 #\tgpsswd\tgpasswd -a 用户名 组名\t增加用户到组\t30\t用户管理 #\tId id 用户名\t查用户信息\t31\t用户管理 #\tll\tll 文件名\t查看文件权限\t32\t文件权限及所属的修改 #\tchmod\tchmod u+r\t增加用户读权限 #\tchmod\tchmod a+w\t增加所有人写权限 #\tchmod\tchmod g+x\t增加组执行权限 #\tchmod\tchmod 755 文件名\t更改文件权限为rwx-xr-x (r=4 w=2 x=1)值相加 #\tchown\tchown 用户名 文件名\t更改文件所属用户 #\tchown\tchown :组名 文件名\t更改文件所属组 #\tchown\tchown 用户名:组名 文件名\t同时更改用户名和组名 #\tchown\tchown -R 用户名:组名 目录名\t更改目录及其中所有文件所属组及用户\t33\t用户之间切换 用户切换 快捷键Alt+F2\t切换到用户F2 （F1 - F6） #\tsu\tsu - 用户名\t用于终端上用户的切换\t34 #\tcat\tcat /etc/shells\t显示系统支持的shell\t35\tshell #\techo\techo $SHELL\t查看当前系统所使用的shell #\techo\techo $变量\t应用变量 36\t定义命令别名 #\talias\talias\t查看定义好的命令别名 #\talias\talias la=ls -a\t临时定义命令别名\t37\t变量的设置 #\tchsh\tchsh 用户名 再输入/bin/csh\t更改默认sehll,且永久不变。 #\tset\tset |less\t查看系统变量 #\tPS1\tPS1=hello;\t更改[root@loadhost ~]为hello; #\t变量名=值\tMOVIE=life is beautiful\t自设变量 #\tunset\tunset 变量名\t删除变量 #\t/bin/bash\t进入子shell\texit 退出子shell #\texport export 变量名\t删除变量 #\treadonly\treadonly\t查看系统中只读变量 #\treadonly\treadonly 变量名\t设置变量为只读变量\t38 #\tsh\tsh 文件名\t执行无执行权限的脚本\t39\t历史命令 #\thistory\thistory |less\t显示命令历史记录 #\t！ ！39\t直接使用第39次命令 #\t！ ！c\t引用最后一次以c开头的命令。\t40\t重定向 # ls 文件名\t把ls得结果重定向到指定文件 # cat a.txt b.txt\t将a.txt中的文件复制到b.txt(覆盖） # cat c.txt b.txt\t将c.txt中的文件追加到b.txt中 # echo “字符串” a.txt\t将“字符串”追加到a.txt文件中 #\t2\t命令 2 文件名\t将错误重定向文件中\t41\tRPM包管理 #\trpm\trpm -qa\t显示系统所装所有的rmp软件包 #\trpm\trpm -ivh\t按照显示详细信息 #\trpm\trpm -ql rmp包名\t查询系统中指定软件包所包括的文件列表 #\trpm\trpm -qpl rmp包名\t查询未装包位置 #\trpm\trpm -qi rmp包名\t显示软件包的详细信息 #\trpm\trpm -qpi rmp包名\t信息列表 #\trpm\trpm -Uvh rmp包名\t升级包，可安装 #\trpm\trpm -e rmp包名\t卸载 #\trpm\trpm -e --nodeps rmp包名\t强制卸载 #\trpm\trpm -qf /bin/ls\t查询“/bin/ls”文件所在包\t42\t设置ip #\tnetconfig\tnetconfig 设置IP地址 #\tservice network restart 重启网络服务\t43\ttar包管理 #\tgzip\tgzip 文件名\t压缩文件，原文件消失 #\ttar\ttar cvf 包名 原文件名、原包名\t把文件和目录压缩成tar包 #\ttar\ttar tf 包名\t查看tar包中的文件 #\ttar\ttar xvf 包名\t释放tar包里的文件 参数-v为显示详细参数 #\ttar\ttar xvf 包名 -C 路径\t释放到指定目录 #\ttar\ttar jxvf 包名\t释放bz2格式压缩包 #\ttar\ttar zcvf 包名 文件名、原包名\t创建压缩tar包 #\ttar\ttar ztf 包名\t查看压缩tar包 #\ttar\ttar zxvf 包名 -C 路径\t释放tar包到指定路径\t44\t编译安装 #\t安装\t./configure 安装在程序目录下 # ./configure --prefix=/路径\t安装在指定目录 # make\t编译源代码 # make install\t将已编译的应用程序安装到目标路径 #\t卸载\t./unin stall\t卸载\t45\t字符下载 #\twget\twget 下载地址\t字符界面下的下载\t46\t安装程序的启动 #\tproz proz 下载路径\t安装在默认路径下的proz的启动 下载 #\t路径/proz\t路径/proz 下载路径\t安装在指定路径下的proz的启动 下载\t47\tgcc升级 #\tyum gcc\tyum gcc\t自动升级gcc\t48\t打补丁 #\tcat\tcat 路径 |patch -p1\t给程序打补丁\t49\t关机\t#\tshutdown\tshutdown -h\t关机 快捷键ctrl+alt+del 关机 #\tinit\tinit 0\t关机\t50\tinit的七种模式 #\tinit\tinit 1\t单用户模式 #\tinit\tinit 2\t无NFS,字符多用户 #\tinit\tinit 3\t多用户 #\tinit\tinit 4\t预留 #\tinit\tinit 5\t图形用户\t51\t重启 #\tinit\tinit 6\t重启 #\tshutdown\tshutdown -r\t重启 #\treboot\treboot\t重启\t52\t级别查询修改 #\trunlevel runlevel\t查询当前级别 #\tvi /etc/inittab 修改默认启动级别\t53\t启动级别 第十八行，id：4 把默认启动级别改为3 第32行，在ca::前加上# 32 #ca:: 把快捷键ctrl+alt+del关机 禁用 #\tchkconfig\tchkconfig --list\t查看安装包在各级的启动状态 #\tchkconfig\tchkconfig --level 24 httpd on\t启动httpd在 24级别。 #\tchkconfig --list rsyns 启动非独立的包，不写启动级别\t54\t系统进程 #\tpstree\tpatree |less\t显示进程树 #\tps\tps aux\t显示进程 #\tkill\tkill 进程号\t关闭进程 #\tkill kill -q 进程号\t强制结束 #\ttop\ttop\t动态查看进程 快捷键ctrl+z\t命令后加 放入后台运行 #\tjobs jobs\t查看后台运行项 #\tfg\tfg 2\t把后台运行的程序调入前台\t55\t任务计划的编辑 #\tat\tat 18:33\t为18：33分制作任务计划 #\tat at mkdir 目录名\t直接输入命令 快捷键ctrl+d 结束当前进程 #\tatq\tatq\t计划任务队列 #\tatrm\tat -d\t都为取消计划任务 #\tat -t 12011230 为12月1月12：30任务计划 #\trpm rpm -qa |grep vixie -cron\t查看计划任务工具包是否安装 #\tcrontab 打开编辑任务计划编辑器，格式：分钟 小时 天 月 星期 后加命令 #\tcrontab crontab -e\t修改任务计划 #\tmail\tmail\t接受系统邮件 #\tservice crond start 启动crond #\tcrontab\tcrontab -r\t删除全部计划任务\t56\t磁盘分区 #\tfdisk\tfdisk /dev/sdb\t打开磁盘分区工具 n 新建分区 w保存推出 d删除分区 q不保存推出 57\t磁盘格式化 mkfs.ext3\tmkfs.ext3 /dev/sdb1\t格式化成ext3格式 mkswap\tmkswap /dev/sdb2\t格式化成swap格式 mkfs.vfat mkfs.vfat /dev/sdb3\t格式化成fat格式 parted\tparted /dev/sdb\t查看分区sdb的类型\t58\t磁盘挂载 #\tvi vi /etc/fstab 挂载磁盘\t59\t磁盘配额 #\tquotacheck\tquotacheck -cug /media/sdb1\t启动磁盘配额 #\tquotaon\tquotaon /media/sdb #\teduota\teduota -u 用户名\t给用户做磁盘配额 #\tquota\tquota -u 用户名\t查看用户磁盘使用情况 #\tedquota\teduota -t 更改软限制时间 #\tedquota\teduota -g 组名\t更改组用户磁盘配额 #\tedquota\teduota -p 已陪用户名 用户名n\t为多个用户创建磁盘配额\t60\tIP信息编辑 #\troute\trout 查看默认网关 #\tcat /etc/sysconfig/network-scripta/ 查看ip信息文件 用vi可修改 #\tifconfig eth0 192.168.1.1 netmask 255.255.255.0 设置临时IP\t#\tnetconfig\tnetconfig 设置IP地址 需重启网卡服务 #\trouteadd\trouteadd default gw 网关\t设置临时网关 #\troutedel\troutedel default gw 网关\t删除临时网关 #\ttraceroute traceroute IP地址\t路由追踪 #\tifdown ifdown 网络接口名称\t禁用网卡 #\tifup\tifup 网络接口名称\t启用网卡\t61\t主机名更改 #\thostname\thostname 计算机名\t更改计算机名，重启无效 #\tvi /etc/sysconfig/network 更改计算机名 主机名设置后重启才能生效，一般和hostname一起使用。 62\t域名解析 #\tnslookup 网址或域名\t域名解析\t63\t安装NFS服务器 #\tvi\tvi /etc/hosts\t//添加IP地址与主机名(本地主机名称解析文件） #\tvi\tvi /etc/resolv.conf\tresolv.conf中的search用于设置主机的默认查找域名 #\trmp rmp -q nfs-utils portmap\t查询NFS服务器是否安装 #\trmp -ivh nfs-utils-1.0.6-46.i386.rmp portmp-4.0-63.i386.rmp 安装NFS 64\tshowmount的查询功能 #\tshowmount showmount NFS服务器主机地址\t显示当前主机中NFS服务器连接信息 #\tshowmount showmount -e IP地址\t显示指定主机中NFS服务器连接信息,并列表 #\tshowmount showmount -d NFS服务器地址\t显示指定主机中NFS服务器已被挂载的目录 #\tshowmount showmount -a NFS服务器地址\t显示挂载的共享列表和NFS客户机地址\t65\tNFS的共享输入与输出 #\texportfs export -rv\t使修改后的export -rv文件生效 #\texportfs export -auv\t临时停止NFS服务器的所有共享目录输出 #\texportfs export -av\t输出（启用）所有被-auv命令停止的NFS共享目录 #\tsystem-config-nfs 在图像界面下启动NFS服务器配置工具命令\t66\t配置NFS 服务器 必须安装的 软件包\trpm -qa |grep nfs-utils\t均在第二张光盘中 rpm -qa |grep portmap 配置exports 文件\tvi /etc/exports\t下面两行为格式 /opt/text *(sync,ro) 192.168.1.12(sync,rw) 共享源文件路径 所有主机（同步写磁盘，只读） 客户IP地址（同步写磁盘，读写） ping通NFS服务器与客户机 以上均在NFS服务器上完成 下面在客户机上完成 67\t配置NFS 客户端 showmount -e /192.168.1.1 查看NFS服务器共享目录 挂载共享目录\tmount 192.168.1.1:/opt/test /mnt 配置自动挂载\tvi /etc/fstab 以下两行为格式 192.168.1.1:/opt/text /mnt nfs defaults 0 0 服务器ip地址：共享源文件路径 挂载点路径 磁盘格式 默认挂载 存档 windows系统的 NFS 挂载\twindows中需安装liteall.exe软件 cat /etc/passwd |grep nfsnobody 查询UID GID 使用UID GID 挂载\t重启可解决兼容性问题\t68\t补充 #\twall\twall hello everyone\t在所有登陆用户桌面显示 #\twall\twall a.txt\t将a.txt中的内容显示到所有登陆用户的桌面 #\twc\twc\t统计从键盘输入的 行数 单词数 字符数 #\twc\twc /etc/passwd\t统计用户数（行） #\tls\tls a.txt b.txt\t将命令执行的输出和错误输出到指定的文件中","categories":["0.平台","Linux","系统参数"]},{"title":"时间编程","path":"/2024/05/22/0-平台-Linux-系统参数-时间编程/","content":"时间类型Coordinated Unicersal Time（UTC）：世界标准时间，也就是大家所熟知的格林威治标准时间（Greenwich Mean Time 吗 GMT） Calendar Time：日历时间，是用“从一个标准时间点（如：1970 年 1 月 1 日 0 点）到此时经过的秒数”来表示时间 时间获取获取日历时间，即从 1970 年 1 月 1 日 0 点到现在所经历的秒数 #include time.htime_t time(time_t*tloc); 将日历时间转化为格林威治标准时间，并保存至 TM 结构 struct tm *gmtime(const time_t*timep); 将日历时间转化为本地时间，并保存至 TM 结构 struct tm *localtime(const time_t*timep); struct tm int tm_sec; /* Seconds(0-60) */int tm_min; /* Minutes(0-59) */int tm_hour; /* Hours(0-23) */int tm_mday; /* Day of the month (1-31) */int tm_mon; /* Month (0-11) */int tm_year; /* Year - 1900 */int tm_wday; /* Day of the week (0-6, Sunday = 0) */int tm_yday; /* Dayin the year (0-365, 1 Jan = 0) */int tm_isdst; /* Daylightsaving time */; 将 tm 格式的时间转化为字符串，如：Sat Jul 30 08：43：03：2005 char*asctime(conststruct tm *tm); 将日历时间转化为本地时间的字符串形式 char*ctime(const time_t*timep); 获取从今日凌晨到现在的时间差，常用于计算事件耗时 #include sys/time.hint gettimeofday(struct timeval *tv,struct timezone *tz); struct timeval time_t tv_sec; /*seconds*/ 秒数suseconds_t tv_usec; /* microseconds*/ 微秒; 延时执行使程序睡眠 seconds #include unistd.hunsigned intsleep(unsigned intseconds); 使程序睡眠 usec 微秒 #include unistd.hint usleep(useconds_t usec);","categories":["0.平台","Linux","系统参数"]},{"title":"Markdown语法","path":"/2024/05/22/1-语言-工具语言-Markdown语法/","content":"Markdown 基础介绍Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 Markdown 能被使用来撰写电子书，如：Gitbook。 标题Markdown 标题有两种格式。 使用 和 - 标记一级和二级标题 一级标题=================二级标题----------------- 使用 # 号可表示 1-6 级标题，一级标题对应一个 # 号。 # 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 段落Markdown 段落的换行有两种格式。 使用两个以上空格加上回车 在段落后面使用一个空行 字体*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ 分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： **** * ******- - ----------- 删除线如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线 ~~ 即可 ~~这是要删除的文本~~ 下划线利用 html 的 u 标签 u带下划线文本/u 脚注脚注是对文本的补充说明。 Markdown 脚注的格式如下: [^要注明的文本] 列表Markdown 支持有序列表和无序列表。 无序列表使用星号 (*)、加号 (+) 或是减号 (-) 作为列表标记，这些标记后面要添加一个空格，然后再填写内容 * 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项 有序列表使用数字并加上 . 号来表示 1. 第一项2. 第二项3. 第三项 列表嵌套只需在子列表中的选项前面添加两个或四个空格即可 1. 第一项：- 第一项嵌套的第一个元素- 第一项嵌套的第二个元素2. 第二项：- 第二项嵌套的第一个元素- 第二项嵌套的第二个元素 区块 Markdown 区块引用是在段落开头使用 符号 ，然后后面紧跟一个空格符号 区块是可以嵌套的，一个 符号是最外层，两个 符号是第一层嵌套 区块中也可以使用列表 列表中也可以使用区块，需要在 前添加四个空格的缩进 区块 区块嵌套 区块嵌套 1. 区块列表1 2. 区块列表2 + 区块列表1 + 区块列表2* 列表1 列表区块1 列表区块2* 列表2 代码段落上的一个函数或片段的代码可以用反引号把它包起来（） `printf()` 代码块 四个空格 tab 制表符 用 `` 包裹一段代码，并指定一种语言 链接[链接名称](baidu.com)baidu.com 高级链接 这个链接用 1 作为网址变量 [Google][1]然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ 图片![alt 属性文本](图片地址)![alt 属性文本](图片地址 可选标题) 也可以按照高级链接的方式，将图片地址放在文档结尾图片大小如果要修改图片大小，采用 html 的 img 标签 表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行 | 表头 | 表头 || ---- | ---- || 单元格 | 单元格 || 单元格 | 单元格 | 对齐 -: 设置内容和标题栏居右对齐。 :- 设置内容和标题栏居左对齐。 :-: 设置内容和标题栏居中对齐。 Markdown 技巧 不同的 markdown 编辑器支持的语法略有不同，下方介绍的相关技巧不一定支持 Github Flavored Markdown (GFM) 的工作清单语法 显示效果 KaTeX 数学公式排版语法语法 显示效果 SVG 向量流程图语法 显示效果 向量 UML 顺序图表语法 显示效果","categories":["1.语言","工具语言"]},{"title":"Qt操作Sqlite3","path":"/2024/05/22/1-语言-Qt-Qt操作Sqlite3/","content":"创建数据库void SqliteOperator::CreatDb() if(QSqlDatabase::contains(qt_sql_default_connection)) db = QSqlDatabase::database(qt_sql_default_connection); else db = QSqlDatabase::addDatabase(QSQLITE); db.setDatabaseName(test.db); db.setUserName(test); db.setPassword(test); 打开及关闭数据库bool SqliteOperator::OpenDb() if(!db.open()) qDebug() Error: Failed to connect database. db.lastError(); return false; return true;void SqliteOperator::CloseDb() db.close(); 创建数据表void SqliteOperator::CreateTable() QSqlQuery sql_query; QString creat_sql = create table student (id int primary key, name varchar(30), age int); sql_query.prepare(creat_sql); if(!sql_query.exec()) qDebug() Error: Fail to create table. sql_query.lastError(); else qDebug() Table created!; 插入数据void SqliteOperator::InsertData() QString insert_sql = insert into student values (?, ?, ?); QSqlQuery sql_query; sql_query.prepare(insert_sql);sql_query.addBindValue(GetMaxId() +1); sql_query.addBindValue(Wang); sql_query.addBindValue(25); if(!sql_query.exec()) qDebug() sql_query.lastError(); else qDebug() inserted Wang!; 查询数据void SqliteOperator::QueryAllData() QString select_all_sql = select * from student; QSqlQuery sql_query; sql_query.prepare(select_all_sql); if(!sql_query.exec()) qDebug()sql_query.lastError(); else while(sql_query.next()) int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); int age = sql_query.value(2).toInt(); qDebug()QString(id:%1 name:%2 age:%3).arg(id).arg(name).arg(age); 条件查询void SqliteOperator::QueryData() QString select_sql = QString(select * from student where name = %1 and (age = %2 or age = %3)) .arg(Wang) .arg(30) .arg(25); QSqlQuery sql_query; if(!sql_query.exec(select_sql)) qDebug()sql_query.lastError(); else while(sql_query.next()) int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); qDebug()QString(id:%1 name:%2).arg(id).arg(name);","categories":["1.语言","Qt"]},{"title":"JavaScript学习笔记","path":"/2024/05/22/1-语言-工具语言-JavaScript学习笔记/","content":"JavaScript 用法HTML 中的 Javascript 脚本代码必须位于 script 与 /script 标签之间。 通常，我们需要在某个事件发生时执行代码，比如当用户点击按钮时。 如果我们把 JavaScript 代码放入函数中，就可以在事件发生时调用该函数。 Javascript 脚本代码可被放置在 HTML 页面的 body 和 head 部分中。 通常的做法是把函数放入 head 部分中，或者放在页面底部。这样就可以把它们安置到同一处位置，不会干扰页面的内容。 外部的 JavaScript也可以把脚本保存到外部文件中。外部文件通常包含被多个网页使用的代码。 外部 JavaScript 文件的文件扩展名是 .js。 如需使用外部文件，请在 script 标签的 “src” 属性中设置该 .js 文件： button type=button onclick=myFunction()点击这里/buttonpb注释：/bmyFunction 保存在名为 myScript.js 的外部文件中。/pscript src=myScript.js/script\t/body js 代码如下： function myFunction() document.getElementById(demo).innerHTML=我的第一个 JavaScript 函数; 外部脚本不能包含 script 标签。在标签中填写 onclick 事件调用函数时，不是 onclick函数名， 而是 onclick函数名 +() JavaScript JSONJSON 英文全称 JavaScript Object Notation JSON 是用于存储和传输数据的格式。 JSON 通常用于服务端向网页传递数据 。 数据为 键值 对。 数据由逗号分隔。 大括号保存对象 方括号保存数组 JSON 是 JS 对象的字符串表示法。它使用文本表示一个 JS 对象的信息，（JSON）本质是一个字符串。 JSON 字符串转换为 JavaScript 对象 var text = sites : [ + name:Runoob , url:www.runoob.com , + name:Google , url:www.google.com , + name:Taobao , url:www.taobao.com ]; obj = JSON.parse(text);document.getElementById(demo).innerHTML = obj.sites[1].name + + obj.sites[1].url; JSON.parse()\t用于将一个 JSON 字符串转换为 JavaScript 对象。 JSON.stringify()\t用于将 JavaScript 值转换为 JSON 字符串。 运行与调试在 Chrome 浏览器中可以通过按下 F12 按钮或者右击页面，选择 “ 检查 “ 来开启开发者工具 或者在右上角菜单栏选择 “ 更多工具 “》” 开发者工具 “ 来开启 Console 窗口调试 JavaScript 代码我们在 符号后输入我们要执行的代码 console.log(“runoob”)，按回车后执行 清空 Console 窗口到内容 Chrome snippets 小脚本我们也可以在 Chrome 浏览器中创建一个脚本来执行，在开发者工具中点击 Sources 面板，选择 Snippets 选项卡，在导航器中右击鼠标，然后选择 Create new snippet 来新建一个脚本文件 点击 Create new snippet 后，会自动创建一个文件，你只需在右侧窗口输入以下代码，然后按 Ctrl+S 保存更改即可。 保存后，右击文件名，选择 “Run” 执行代码 设置断点debugger 关键字 JavaScript 输出 使用 window.alert() 弹出警告框。 使用 document.write() 方法将内容写到 HTML 文档中。 使用 innerHTML 写入到 HTML 元素。 使用 console.log() 写入到浏览器的控制台。 数据类型JavaScript 字面量 数字（Number）字面量 可以是整数或者是小数，或者是科学计数 (e)。 字符串（String）字面量 可以使用单引号或双引号: 表达式字面量 用于计算： 5 + 6 数组（Array）字面量 定义一个数组：[40, 100, 1, 5, 25, 10] 对象（Object）字面量 定义一个对象：{firstName:”John”, lastName:”Doe”, age:50, eyeColor:”blue”} 函数（Function）字面量 定义一个函数：function myFunction(a, b) { return a * b;} 变量 var 关键词来声明变量 当您声明新变量时，可以使用关键词 “new” 来声明其类型： var carname=new String;var x= new Number;var y= new Boolean;var cars= new Array;var person= new Object; 变量的数据类型可以使用 typeof 操作符来查看： 值类型 (基本类型)： 字符串（String） var x “John”; 数字 (Number) var x 5; 布尔 (Boolean) var xtrue; 空（Null） 未定义（Undefined）\tvar x; Symbol。 引用数据类型（对象类型）： 对象 (Object) var person = firstName: John, lastName : Doe, id : 5566, fullName : function() return this.firstName + + this.lastName; ; 对象属性有两种寻址方式：nameperson.lastname;nameperson[“lastname”]; 数组 (Array) var cars=[Saab,Volvo,BMW]; var carsnew Array();cars[0]”Saab”;cars[1]”Volvo”;cars[2]”BMW”;或者 (condensed array):var carsnew Array(“Saab”,”Volvo”,”BMW”);或者 (literal array):var cars[“Saab”,”Volvo”,”BMW”]; 函数 (Function) button onclick=myFunction(Harry Potter,Wizard)点击这里/buttonbutton onclick=myFunction(Bob,Builder)点击这里/buttonscriptfunction myFunction(name,job)\talert(Welcome + name + , the + job);/script 带有返回值的函数 function myFunction() var x=5; return x;var myVar=myFunction(); 函数表达式 var x = function (a, b) return a * b; 还有两个特殊的对象： 正则（RegExp） 正则表达式主体修饰符 (可选) var patt = /runoob/i //字符串 var n = str.search(/Runoob/i); var patt = /e/; //正则patt.test(The best things in life are free!); runoobi 是一个正则表达式。runoob 是一个正则表达式主体 (用于检索)。i 是一个修饰符 (搜索不区分大小写)。 在 JavaScript 中，正则表达式通常用于两个字符串方法 : search() 和 replace()。 search() 方法用于检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串，并返回子串的起始位置。 replace() 方法用于在字符串中用一些字符串替换另一些字符串，或替换一个与正则表达式匹配的子串。 test() 方法用于检测一个字符串是否匹配某个模式，如果字符串中含有匹配的文本，则返回 true，否则返回 false。 exec() 方法用于检索字符串中的正则表达式的匹配。 日期（Date） 生存周期 局部变量 在 JavaScript 函数内部声明的变量（使用 var）是局部变量，所以只能在函数内部访问它。（该变量的作用域是局部的）。 全局变量函数外声明的变量是全局变量，网页上的所有脚本和函数都能访问它。 事件HTML 事件可以是浏览器行为，也可以是用户行为。 HTML 页面完成加载 HTML input 字段改变时 HTML 按钮被点击 |事件 |描述 | |:–: |:–: | |onchange |HTML 元素改变 | |onclick |用户点击 HTML 元素 | |onmouseover\t|鼠标指针移动到指定的元素上时发生 | |onmouseout |用户从一个 HTML 元素上移开鼠标时发生\t| |onkeydown |用户按下键盘按键 | |onload |浏览器已完成页面的加载 | 语句条件语句if-else if (condition1) 当条件 1 为 true 时执行的代码else if (condition2) 当条件 2 为 true 时执行的代码else 当条件 1 和 条件 2 都不为 true 时执行的代码 switch switch(n) case 1: 执行代码块 1 break; case 2: 执行代码块 2 break; default: 与 case 1 和 case 2 不同时执行的代码 循环语句for for (var i=0,len=cars.length; ilen; i++) document.write(cars[i] + br); var person=fname:Bill,lname:Gates,age:56; for (x in person) // x 为属性名 txt=txt + person[x]; while while (条件) 需要执行的代码 do 需要执行的代码while (条件); 其他breakcontinuetypeof检测变量的数据类型nullnull 是一个只有一个值的特殊类型。表示一个空对象引用。undefinedundefined 是一个没有设置值的变量 null 和 undefined 的值相等，但类型不等 错误处理 try 语句测试代码块的错误。 catch 语句处理错误。 throw 语句创建自定义错误。 finally 语句在 try 和 catch 语句之后，无论是否有触发异常，该语句都会执行。 异步编程回调函数这段程序中的 setTimeout 就是一个消耗时间较长（3 秒）的过程，它的第一个参数是个回调函数，第二个参数是毫秒数，这个函数执行之后会产生一个子线程，子线程会等待 3 秒，然后执行回调函数 “print”，在命令行输出 “RUNOOB!”。 function print() document.getElementById(demo).innerHTML=RUNOOB!;setTimeout(print, 3000); setTimeout(function () document.getElementById(demo).innerHTML=RUNOOB!;, 3000); JavaScript Promise类JavaScript HTML DOMHTML DOM (文档对象模型)（Document Object Model） 通过 id 找到 HTML 元素 var x=document.getElementById(intro); 通过标签名找到 HTML 元素 var x=document.getElementById(main);var y=x.getElementsByTagName(p); 通过类名找到 HTML 元素 var x=document.getElementsByClassName(intro); JavaScript HTML DOM - 改变 HTML内容 htmlbodyp id=p1Hello World!/pscriptdocument.getElementById(p1).innerHTML=新文本!;/script/body/html 属性 !DOCTYPE htmlhtmlbodyimg id=image src=smiley.gifscriptdocument.getElementById(image).src=landscape.jpg;/script/body/html JavaScript HTML DOM - 改变 CSS!DOCTYPE htmlhtmlheadmeta charset=utf-8title菜鸟教程(runoob.com)/title/headbody p id=p1Hello World!/pp id=p2Hello World!/pscriptdocument.getElementById(p2).style.color=blue;document.getElementById(p2).style.fontFamily=Arial;document.getElementById(p2).style.fontSize=larger;/scriptp以上段落通过脚本修改。/p /body/html JavaScript HTML DOM 事件scriptdocument.getElementById(myBtn).onclick=function()displayDate();/script onload 和 onunload 事件会在用户进入或离开页面时被触发。 onchange 事件常结合对输入字段的验证来使用。 onmouseover 和 onmouseout 事件可用于在用户的鼠标移至 HTML 元素上方或移出元素时触发函数。 onmousedown, onmouseup 以及 onclick 构成了鼠标点击事件的所有部分。首先当点击鼠标按钮时，会触发 onmousedown 事件，当释放鼠标按钮时，会触发 onmouseup 事件，最后，当完成鼠标点击时，会触发 onclick 事件。 总结JavaScript：直接写入 HTML 输出流document.write(h1这是一个标题/h1);document.write(p这是一个段落。/p); 您只能在 HTML 输出流中使用 document.write。 如果您在文档已加载后使用它（比如在函数中），会覆盖整个文档。 JavaScript：对事件的反应button type=button onclick=alert(欢迎!)点我!/button JavaScript：改变 HTML 内容x=document.getElementById(demo); //查找元素x.innerHTML=Hello JavaScript; //改变内容 DOM (Document Object Model)（文档对象模型）是用于访问 HTML 元素的正式 W3C 标准。 JavaScript：改变 HTML 图像scriptfunction changeImage() element=document.getElementById(myimage) if (element.src.match(bulbon)) element.src=/images/pic_bulboff.gif; else element.src=/images/pic_bulbon.gif; /scriptimg decoding=async loading=lazy id=myimage onclick=changeImage() src=/images/pic_bulboff.gif width=100 height=180 JavaScript：改变 HTML 样式x=document.getElementById(demo) //找到元素 x.style.color=#ff0000; //改变样式 JavaScript：验证输入input id=demo type=textscriptfunction myFunction()\tvar x=document.getElementById(demo).value;\tif(isNaN(x)||x.replace(/(^\\s*)|(\\s*$)/g,)==) alert(不是数字);\t/scriptbutton type=button onclick=myFunction()点击这里/button","categories":["1.语言","工具语言"]},{"title":"虚拟机磁盘收缩","path":"/2024/05/22/0-平台-VMware-虚拟机磁盘收缩/","content":"1. 删除快照打开 VMware，选择工具栏的虚拟机，选择快照，选择快照管理器，删除不用的快照 2. 删除缓存文件打开虚拟机，删除虚拟机中的缓存文件目录： rm -rf /home/forlinx/.cache/vmware/drag_and_drop df -h 指令可查找到磁盘真实占据的磁盘空间 3. 压缩磁盘空间当虚拟机安装盘所剩余的空间大于.vmdk 文件的大小时，强烈推荐使用以下方式 在你的终端输入 sudo /usr/bin/vmware-toolbox-cmd disk list 一般会有 / 目录 再输入 sudo /usr/bin/vmware-toolbox-cmd disk shrink / 即压缩根目录 / 4. 使用 DiskGenius 压缩存放在物理硬盘上的虚拟磁盘文件的大小并没有减小。虚拟机磁盘文件只会慢慢地变大，虚拟机软件不会在用户删除数据后对虚拟磁盘进行“压缩”。可以使用 DiskGenius 软件进行压缩。比如我们使用的是 VMware 虚拟机，它的虚拟磁盘文件是 vmdk 格式。 1、在 DiskGenius 软件中，首先把要压缩的虚拟磁盘打开（菜单：“硬盘 – 打开虚拟硬盘文件”）。打开后就可以在左边的窗口中看到加载上的虚拟磁盘了。 2、然后我们再新建一个容量不小于源虚拟硬盘的 vmdk 虚拟磁盘（菜单：“硬盘 – 新建虚拟硬盘文件 – 新建 VMware 虚拟硬盘文件”）。 3、开始进行压缩。选择（菜单：“工具 – 克隆硬盘”），弹出对话框后，在“选择源硬盘”时选择要压缩的 vmdk 虚拟磁盘，在“选择目标硬盘”时选择刚刚我们新建的 vmdk 虚拟磁盘，然后点“开始”。 4、现在已经复制完毕了，我们找到两个虚拟磁盘文件的所在路径，对比一下大小。可以看到，虚拟硬盘被压缩了。 这时，还需要做一些后续的清理工作。首先在 DiskGenius 软件中关闭刚才打开的两个虚拟硬盘，或者直接关闭 DiskGenius 软件。然后将源虚拟硬盘文件改名（备用，以防万一），再将新的虚拟硬盘文件改名为源虚拟硬盘的文件名（注意要完全相同）。最后打开虚拟机，启动一下虚拟系统，没有问题后就可以删除压缩前的源虚拟硬盘文件了。 5. 导出 OVF 重新建立新 vmdk有时候删除虚拟机快照出现错误，但快照图标已消失，导致无法再次删除，造成文件残留，就这样越堆越多，无法清理。 优点是可以释放大量空间，缺点是只能保留 VMware 虚拟机当前的状态和文件，丢失其他快照（可以按需先转到某个快照再导出 OVF，这样就可以保留快照时的状态了。同样，会丢失其他状态）。步骤如下： 点击要清理的虚拟机，然后左上角点击文件，导出为 OVF（只存了虚拟机当前的状态，大概有十几个 G），存到其他空闲的磁盘下。 将上述步骤导出的 ovf 再部署出来，看看虚拟机是否正常。 如果正常可用，就可以把虚拟机原来占用的磁盘清空了，快速释放大量空间。","categories":["0.平台","VMware"]},{"title":"pythonWeb部署方案","path":"/2024/05/22/1-语言-Python-pythonWeb部署方案/","content":"搭建开发环境首先，确认系统安装的 Python 版本是 3.7.x： $ python3 --versionPython 3.7.0 然后，用 pip 安装开发 Web App 需要的第三方库： 异步框架 aiohttp： $pip3 install aiohttp 前端模板引擎 jinja2： $ pip3 install jinja2 MySQL 5.x 数据库，从 官方网站 下载并安装，安装完毕后，请务必牢记 root 口令。为避免遗忘口令，建议直接把 root 口令设置为 password； MySQL 的 Python 异步驱动程序 aiomysql： $ pip3 install aiomysql 项目结构选择一个工作目录，然后，我们建立如下的目录结构： awesome-python3-webapp/ -- 根目录|+- backup/ -- 备份目录|+- conf/ -- 配置文件|+- dist/ -- 打包目录|+- www/ -- Web目录，存放.py文件| || +- static/ -- 存放静态文件| || +- templates/ -- 存放模板文件|+- ios/ -- 存放iOS App工程|+- LICENSE -- 代码LICENSE 创建好项目的目录结构后，建议同时建立 git 仓库并同步至 GitHub，保证代码修改的安全。 Web 骨架由于我们的 Web App 建立在 asyncio 的基础上，因此用 aiohttp 写一个基本的 app.py： import logging; logging.basicConfig(level=logging.INFO)import asyncio, os, json, timefrom datetime import datetimefrom aiohttp import webdef index(request): return web.Response(body=bh1Awesome/h1)@asyncio.coroutinedef init(loop): app = web.Application(loop=loop) app.router.add_route(GET, /, index) srv = yield from loop.create_server(app.make_handler(), 127.0.0.1, 9000) logging.info(server started at http://127.0.0.1:9000...) return srvloop = asyncio.get_event_loop()loop.run_until_complete(init(loop))loop.run_forever() 运行 python app.py，Web App 将在 9000 端口监听 HTTP 请求，并且对首页 / 进行响应： $ python3 app.pyINFO:root:server started at http://127.0.0.1:9000... 这里我们简单地返回一个 Awesome 字符串，在浏览器中可以看到效果 这说明我们的 Web App 骨架已经搭好了，可以进一步往里面添加更多的东西。 ORMORM 全称是：Object Relational Mapping(对象关系映射)，其主要作用是在编程中，把面向对象的概念跟数据库中表的概念对应起来。举例来说就是，我定义一个对象，那就对应着一张表，这个对象的实例，就对应着表中的一条记录。 在一个 Web App 中，所有数据，包括用户信息、发布的日志、评论等，都存储在数据库中。在 awesome-python3-webapp 中，我们选择 MySQL 作为数据库。 Web App 里面有很多地方都要访问数据库。访问数据库需要创建数据库连接、游标对象，然后执行 SQL 语句，最后处理异常，清理资源。这些访问数据库的代码如果分散到各个函数中，势必无法维护，也不利于代码复用。 所以，我们要首先把常用的 SELECT、INSERT、UPDATE 和 DELETE 操作用函数封装起来。 由于 Web 框架使用了基于 asyncio 的 aiohttp，这是基于协程的异步模型。在协程中，不能调用普通的同步 IO 操作，因为所有用户都是由一个线程服务的，协程的执行速度必须非常快，才能处理大量用户的请求。而耗时的 IO 操作不能在协程中以同步的方式调用，否则，等待一个 IO 操作时，系统无法响应任何其他用户。 这就是异步编程的一个原则：一旦决定使用异步，则系统每一层都必须是异步，“开弓没有回头箭”。 幸运的是 aiomysql 为 MySQL 数据库提供了异步 IO 的驱动。 创建连接池我们需要创建一个全局的连接池，每个 HTTP 请求都可以从连接池中直接获取数据库连接。使用连接池的好处是不必频繁地打开和关闭数据库连接，而是能复用就尽量复用。 连接池由全局变量 __pool 存储，缺省情况下将编码设置为 utf8，自动提交事务： @asyncio.coroutinedef create_pool(loop, **kw): logging.info(create database connection pool...) global __pool __pool = yield from aiomysql.create_pool( host=kw.get(host, localhost), port=kw.get(port, 3306), user=kw[user], password=kw[password], db=kw[db], charset=kw.get(charset, utf8), autocommit=kw.get(autocommit, True), maxsize=kw.get(maxsize, 10), minsize=kw.get(minsize, 1), loop=loop ) Select要执行 SELECT 语句，我们用 select 函数执行，需要传入 SQL 语句和 SQL 参数： @asyncio.coroutinedef select(sql, args, size=None): log(sql, args) global __pool with (yield from __pool) as conn: cur = yield from conn.cursor(aiomysql.DictCursor) yield from cur.execute(sql.replace(?, %s), args or ()) if size: rs = yield from cur.fetchmany(size) else: rs = yield from cur.fetchall() yield from cur.close() logging.info(rows returned: %s % len(rs)) return rs SQL 语句的占位符是 ?，而 MySQL 的占位符是 %s，select() 函数在内部自动替换。注意要始终坚持使用带参数的 SQL，而不是自己拼接 SQL 字符串，这样可以防止 SQL 注入攻击。 注意到 yield from 将调用一个子协程（也就是在一个协程中调用另一个协程）并直接获得子协程的返回结果。 如果传入 size 参数，就通过 fetchmany() 获取最多指定数量的记录，否则，通过 fetchall() 获取所有记录。 Insert, Update, Delete要执行 INSERT、UPDATE、DELETE 语句，可以定义一个通用的 execute() 函数，因为这 3 种 SQL 的执行都需要相同的参数，以及返回一个整数表示影响的行数： @asyncio.coroutinedef execute(sql, args): log(sql) with (yield from __pool) as conn: try: cur = yield from conn.cursor() yield from cur.execute(sql.replace(?, %s), args) affected = cur.rowcount yield from cur.close() except BaseException as e: raise return affected execute() 函数和 select() 函数所不同的是，cursor 对象不返回结果集，而是通过 rowcount 返回结果数。 ORM有了基本的 select() 和 execute() 函数，我们就可以开始编写一个简单的 ORM 了。 设计 ORM 需要从上层调用者角度来设计。 我们先考虑如何定义一个 User 对象，然后把数据库表 users 和它关联起来。 from orm import Model, StringField, IntegerFieldclass User(Model): __table__ = users id = IntegerField(primary_key=True) name = StringField() 注意到定义在 User 类中的 __table__、id 和 name 是类的属性，不是实例的属性。所以，在类级别上定义的属性用来描述 User 对象和表的映射关系，而实例属性必须通过 __init__() 方法去初始化，所以两者互不干扰： # 创建实例:user = User(id=123, name=Michael)# 存入数据库:user.insert()# 查询所有User对象:users = User.findAll() 定义 Model首先要定义的是所有 ORM 映射的基类 Model： class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(rModel object has no attribute %s % key) def __setattr__(self, key, value): self[key] = value def getValue(self, key): return getattr(self, key, None) def getValueOrDefault(self, key): value = getattr(self, key, None) if value is None: field = self.__mappings__[key] if field.default is not None: value = field.default() if callable(field.default) else field.default logging.debug(using default value for %s: %s % (key, str(value))) setattr(self, key, value) return value Model 从 dict 继承，所以具备所有 dict 的功能，同时又实现了特殊方法 __getattr__() 和 __setattr__()，因此又可以像引用普通字段那样写： user[id]123 user.id123 以及 Field 和各种 Field 子类： class Field(object): def __init__(self, name, column_type, primary_key, default): self.name = name self.column_type = column_type self.primary_key = primary_key self.default = default def __str__(self): return %s, %s:%s % (self.__class__.__name__, self.column_type, self.name) 映射 varchar 的 StringField： class StringField(Field): def __init__(self, name=None, primary_key=False, default=None, ddl=varchar(100)): super().__init__(name, ddl, primary_key, default) 注意到 Model 只是一个基类，如何将具体的子类如 User 的映射信息读取出来呢？答案就是通过 metaclass：ModelMetaclass： class ModelMetaclass(type): def __new__(cls, name, bases, attrs): # 排除Model类本身: if name==Model: return type.__new__(cls, name, bases, attrs) # 获取table名称: tableName = attrs.get(__table__, None) or name logging.info(found model: %s (table: %s) % (name, tableName)) # 获取所有的Field和主键名: mappings = dict() fields = [] primaryKey = None for k, v in attrs.items(): if isinstance(v, Field): logging.info( found mapping: %s == %s % (k, v)) mappings[k] = v if v.primary_key: # 找到主键: if primaryKey: raise RuntimeError(Duplicate primary key for field: %s % k) primaryKey = k else: fields.append(k) if not primaryKey: raise RuntimeError(Primary key not found.) for k in mappings.keys(): attrs.pop(k) escaped_fields = list(map(lambda f: `%s` % f, fields)) attrs[__mappings__] = mappings # 保存属性和列的映射关系 attrs[__table__] = tableName attrs[__primary_key__] = primaryKey # 主键属性名 attrs[__fields__] = fields # 除主键外的属性名 # 构造默认的SELECT, INSERT, UPDATE和DELETE语句: attrs[__select__] = select `%s`, %s from `%s` % (primaryKey, , .join(escaped_fields), tableName) attrs[__insert__] = insert into `%s` (%s, `%s`) values (%s) % (tableName, , .join(escaped_fields), primaryKey, create_args_string(len(escaped_fields) + 1)) attrs[__update__] = update `%s` set %s where `%s`=? % (tableName, , .join(map(lambda f: `%s`=? % (mappings.get(f).name or f), fields)), primaryKey) attrs[__delete__] = delete from `%s` where `%s`=? % (tableName, primaryKey) return type.__new__(cls, name, bases, attrs) 这样，任何继承自 Model 的类（比如 User），会自动通过 ModelMetaclass 扫描映射关系，并存储到自身的类属性如 __table__、__mappings__ 中。 然后，我们往 Model 类添加 class 方法，就可以让所有子类调用 class 方法： class Model(dict): ... @classmethod @asyncio.coroutine def find(cls, pk): find object by primary key. rs = yield from select(%s where `%s`=? % (cls.__select__, cls.__primary_key__), [pk], 1) if len(rs) == 0: return None return cls(**rs[0]) User 类现在就可以通过类方法实现主键查找： user = yield from User.find(123) 往 Model 类添加实例方法，就可以让所有子类调用实例方法： class Model(dict): ... @asyncio.coroutine def save(self): args = list(map(self.getValueOrDefault, self.__fields__)) args.append(self.getValueOrDefault(self.__primary_key__)) rows = yield from execute(self.__insert__, args) if rows != 1: logging.warn(failed to insert record: affected rows: %s % rows) 这样，就可以把一个 User 实例存入数据库： user = User(id=123, name=Michael)yield from user.save() 最后一步是完善 ORM，对于查找，我们可以实现以下方法： findAll() - 根据 WHERE 条件查找； findNumber() - 根据 WHERE 条件查找，但返回的是整数，适用于 select count(*) 类型的 SQL。以及 update() 和 remove() 方法。所有这些方法都必须用 @asyncio.coroutine 装饰，变成一个协程。调用时需要特别注意： user.save() 没有任何效果，因为调用 save() 仅仅是创建了一个协程，并没有执行它。一定要用： yield from user.save() 才真正执行了 INSERT 操作。 编写 Model有了 ORM，我们就可以把 Web App 需要的 3 个表用 Model 表示出来： import time, uuidfrom orm import Model, StringField, BooleanField, FloatField, TextFielddef next_id(): return %015d%s000 % (int(time.time() * 1000), uuid.uuid4().hex)class User(Model): __table__ = users id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) email = StringField(ddl=varchar(50)) passwd = StringField(ddl=varchar(50)) admin = BooleanField() name = StringField(ddl=varchar(50)) image = StringField(ddl=varchar(500)) created_at = FloatField(default=time.time)class Blog(Model): __table__ = blogs id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) user_id = StringField(ddl=varchar(50)) user_name = StringField(ddl=varchar(50)) user_image = StringField(ddl=varchar(500)) name = StringField(ddl=varchar(50)) summary = StringField(ddl=varchar(200)) content = TextField() created_at = FloatField(default=time.time)class Comment(Model): __table__ = comments id = StringField(primary_key=True, default=next_id, ddl=varchar(50)) blog_id = StringField(ddl=varchar(50)) user_id = StringField(ddl=varchar(50)) user_name = StringField(ddl=varchar(50)) user_image = StringField(ddl=varchar(500)) content = TextField() created_at = FloatField(default=time.time) 在编写 ORM 时，给一个 Field 增加一个 default 参数可以让 ORM 自己填入缺省值，非常方便。并且，缺省值可以作为函数对象传入，在调用 save() 时自动计算。 例如，主键 id 的缺省值是函数 next_id，创建时间 created_at 的缺省值是函数 time.time，可以自动设置当前日期和时间。 日期和时间用 float 类型存储在数据库中，而不是 datetime 类型，这么做的好处是不必关心数据库的时区以及时区转换问题，排序非常简单，显示的时候，只需要做一个 float 到 str 的转换，也非常容易。 初始化数据库表如果表的数量很少，可以手写创建表的 SQL 脚本： -- schema.sqldrop database if exists awesome;create database awesome;use awesome;grant select, insert, update, delete on awesome.* to www-data@localhost identified by www-data;create table users ( `id` varchar(50) not null, `email` varchar(50) not null, `passwd` varchar(50) not null, `admin` bool not null, `name` varchar(50) not null, `image` varchar(500) not null, `created_at` real not null, unique key `idx_email` (`email`), key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table blogs ( `id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `name` varchar(50) not null, `summary` varchar(200) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table comments ( `id` varchar(50) not null, `blog_id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8; 如果表的数量很多，可以从 Model 对象直接通过脚本自动生成 SQL 脚本，使用更简单。 把 SQL 脚本放到 MySQL 命令行里执行： $ mysql -u root -p schema.sql 我们就完成了数据库表的初始化。 编写数据访问代码接下来，就可以真正开始编写代码操作对象了。比如，对于 User 对象，我们就可以做如下操作： import ormfrom models import User, Blog, Commentdef test(): yield from orm.create_pool(user=www-data, password=www-data, database=awesome) u = User(name=Test, email=test@example.com, passwd=1234567890, image=about:blank) yield from u.save()for x in test(): pass 可以在 MySQL 客户端命令行查询，看看数据是不是正常存储到 MySQL 里面了。 Web 框架在正式开始 Web 开发前，我们需要编写一个 Web 框架。 aiohttp 已经是一个 Web 框架了，为什么我们还需要自己封装一个？ 原因是从使用者的角度来说，aiohttp 相对比较底层，编写一个 URL 的处理函数需要这么几步： 第一步，编写一个用 @asyncio.coroutine 装饰的函数： @asyncio.coroutinedef handle_url_xxx(request): pass 第二步，传入的参数需要自己从 request 中获取： url_param = request.match_info[key]query_params = parse_qs(request.query_string) 最后，需要自己构造 Response 对象： text = render(template, data)return web.Response(text.encode(utf-8)) 这些重复的工作可以由框架完成。例如，处理带参数的 URL/blog/id 可以这么写： @get(/blog/id)def get_blog(id): pass 处理 query_string 参数可以通过关键字参数 **kw 或者命名关键字参数接收： @get(/api/comments)def api_comments(*, page=1): pass 对于函数的返回值，不一定是 web.Response 对象，可以是 str、bytes 或 dict。 如果希望渲染模板，我们可以这么返回一个 dict： return __template__: index.html, data: ... 因此，Web 框架的设计是完全从使用者出发，目的是让使用者编写尽可能少的代码。 编写简单的函数而非引入 request 和 web.Response 还有一个额外的好处，就是可以单独测试，否则，需要模拟一个 request 才能测试。 @get 和@post要把一个函数映射为一个 URL 处理函数，我们先定义 @get()： def get(path): Define decorator @get(/path) def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): return func(*args, **kw) wrapper.__method__ = GET wrapper.__route__ = path return wrapper return decorator 这样，一个函数通过 @get() 的装饰就附带了 URL 信息。 @post 与 @get 定义类似。 定义 RequestHandlerURL 处理函数不一定是一个 coroutine，因此我们用 RequestHandler() 来封装一个 URL 处理函数。 RequestHandler 是一个类，由于定义了 __call__() 方法，因此可以将其实例视为函数。 RequestHandler 目的就是从 URL 函数中分析其需要接收的参数，从 request 中获取必要的参数，调用 URL 函数，然后把结果转换为 web.Response 对象，这样，就完全符合 aiohttp 框架的要求： class RequestHandler(object): def __init__(self, app, fn): self._app = app self._func = fn ... @asyncio.coroutine def __call__(self, request): kw = ... 获取参数 r = yield from self._func(**kw) return r 再编写一个 add_route 函数，用来注册一个 URL 处理函数： def add_route(app, fn): method = getattr(fn, __method__, None) path = getattr(fn, __route__, None) if path is None or method is None: raise ValueError(@get or @post not defined in %s. % str(fn)) if not asyncio.iscoroutinefunction(fn) and not inspect.isgeneratorfunction(fn): fn = asyncio.coroutine(fn) logging.info(add route %s %s = %s(%s) % (method, path, fn.__name__, , .join(inspect.signature(fn).parameters.keys()))) app.router.add_route(method, path, RequestHandler(app, fn)) 最后一步，把很多次 add_route() 注册的调用： add_route(app, handles.index)add_route(app, handles.blog)add_route(app, handles.create_comment)... 变成自动扫描： # 自动把handler模块的所有符合条件的函数注册了:add_routes(app, handlers) add_routes() 定义如下： def add_routes(app, module_name): n = module_name.rfind(.) if n == (-1): mod = __import__(module_name, globals(), locals()) else: name = module_name[n+1:] mod = getattr(__import__(module_name[:n], globals(), locals(), [name]), name) for attr in dir(mod): if attr.startswith(_): continue fn = getattr(mod, attr) if callable(fn): method = getattr(fn, __method__, None) path = getattr(fn, __route__, None) if method and path: add_route(app, fn) 最后，在 app.py 中加入 middleware、jinja2 模板和自注册的支持： app = web.Application(loop=loop, middlewares=[ logger_factory, response_factory])init_jinja2(app, filters=dict(datetime=datetime_filter))add_routes(app, handlers)add_static(app) middlewaremiddleware 是一种拦截器，一个 URL 在被某个函数处理前，可以经过一系列的 middleware 的处理。 一个 middleware 可以改变 URL 的输入、输出，甚至可以决定不继续处理而直接返回。middleware 的用处就在于把通用的功能从每个 URL 处理函数中拿出来，集中放到一个地方。例如，一个记录 URL 日志的 logger 可以简单定义如下： @asyncio.coroutinedef logger_factory(app, handler): @asyncio.coroutine def logger(request): # 记录日志: logging.info(Request: %s %s % (request.method, request.path)) # 继续处理请求: return (yield from handler(request)) return logger 而 response 这个 middleware 把返回值转换为 web.Response 对象再返回，以保证满足 aiohttp 的要求： @asyncio.coroutinedef response_factory(app, handler): @asyncio.coroutine def response(request): # 结果: r = yield from handler(request) if isinstance(r, web.StreamResponse): return r if isinstance(r, bytes): resp = web.Response(body=r) resp.content_type = application/octet-stream return resp if isinstance(r, str): resp = web.Response(body=r.encode(utf-8)) resp.content_type = text/html;charset=utf-8 return resp if isinstance(r, dict): ... 有了这些基础设施，我们就可以专注地往 handlers 模块不断添加 URL 处理函数了，可以极大地提高开发效率。 配置文件有了 Web 框架和 ORM 框架，我们就可以开始装配 App 了。 通常，一个 Web App 在运行时都需要读取配置文件，比如数据库的用户名、口令等，在不同的环境中运行时，Web App 可以通过读取不同的配置文件来获得正确的配置。 由于 Python 本身语法简单，完全可以直接用 Python 源代码来实现配置，而不需要再解析一个单独的 .properties 或者 .yaml 等配置文件。 默认的配置文件应该完全符合本地开发环境，这样，无需任何设置，就可以立刻启动服务器。 我们把默认的配置文件命名为 config_default.py： # config_default.pyconfigs = db: host: 127.0.0.1, port: 3306, user: www-data, password: www-data, database: awesome , session: secret: AwEsOmE 上述配置文件简单明了。但是，如果要部署到服务器时，通常需要修改数据库的 host 等信息，直接修改 config_default.py 不是一个好办法，更好的方法是编写一个 config_override.py，用来覆盖某些默认设置： # config_override.pyconfigs = db: host: 192.168.0.100 把 config_default.py 作为开发环境的标准配置，把 config_override.py 作为生产环境的标准配置，我们就可以既方便地在本地开发，又可以随时把应用部署到服务器上。 应用程序读取配置文件需要优先从 config_override.py 读取。为了简化读取配置文件，可以把所有配置读取到统一的 config.py 中： # config.pyconfigs = config_default.configstry: import config_override configs = merge(configs, config_override.configs)except ImportError: pass 这样，我们就完成了 App 的配置。 MVC现在，ORM 框架、Web 框架和配置都已就绪，我们可以开始编写一个最简单的 MVC，把它们全部启动起来。 通过 Web 框架的 @get 和 ORM 框架的 Model 支持，可以很容易地编写一个处理首页 URL 的函数： @get(/)def index(request): users = yield from User.findAll() return __template__: test.html, users: users __template__ 指定的模板文件是 test.html，其他参数是传递给模板的数据，所以我们在模板的根目录 templates 下创建 test.html： !DOCTYPE htmlhtmlhead meta charset=utf-8 / titleTest users - Awesome Python Webapp/title/headbody h1All users/h1 % for u in users % p u.name / u.email /p % endfor %/body/html 接下来，如果一切顺利，可以用命令行启动 Web 服务器： $ python3 app.py 然后，在浏览器中访问 http://localhost:9000/。 如果数据库的 users 表什么内容也没有，你就无法在浏览器中看到循环输出的内容。可以自己在 MySQL 的命令行里给 users 表添加几条记录，然后再访问 构建前端对于复杂的 HTML 前端页面来说，我们需要一套基础的 CSS 框架来完成页面布局和基本样式。另外，jQuery 作为操作 DOM 的 JavaScript 库也必不可少。 从零开始写 CSS 不如直接从一个已有的功能完善的 CSS 框架开始。有很多 CSS 框架可供选择。我们这次选择 uikit 这个强大的 CSS 框架。它具备完善的响应式布局，漂亮的 UI，以及丰富的 HTML 组件，让我们能轻松设计出美观而简洁的页面。 可以从 uikit首页 下载打包的资源文件。 所有的静态资源文件我们统一放到 www/static 目录下，并按照类别归类： static/+- css/| +- addons/| | +- uikit.addons.min.css| | +- uikit.almost-flat.addons.min.css| | +- uikit.gradient.addons.min.css| +- awesome.css| +- uikit.almost-flat.addons.min.css| +- uikit.gradient.addons.min.css| +- uikit.min.css+- fonts/| +- fontawesome-webfont.eot| +- fontawesome-webfont.ttf| +- fontawesome-webfont.woff| +- FontAwesome.otf+- js/ +- awesome.js +- html5.js +- jquery.min.js +- uikit.min.js 由于前端页面肯定不止首页一个页面，每个页面都有相同的页眉和页脚。如果每个页面都是独立的 HTML 模板，那么我们在修改页眉和页脚的时候，就需要把每个模板都改一遍，这显然是没有效率的。 常见的模板引擎已经考虑到了页面上重复的 HTML 部分的复用问题。有的模板通过 include 把页面拆成三部分： html % include file=inc_header.html % % include file=index_body.html % % include file=inc_footer.html %/html 这样，相同的部分 inc_header.html 和 inc_footer.html 就可以共享。 但是 include 方法不利于页面整体结构的维护。jinjia2 的模板还有另一种“继承”方式，实现模板的复用更简单。 “继承”模板的方式是通过编写一个“父模板”，在父模板中定义一些可替换的 block（块）。然后，编写多个“子模板”，每个子模板都可以只替换父模板定义的 block。比如，定义一个最简单的父模板： !-- base.html --html head title% block title% 这里定义了一个名为title的block % endblock %/title /head body % block content % 这里定义了一个名为content的block % endblock % /body/html 对于子模板 a.html，只需要把父模板的 title 和 content 替换掉： % extends base.html %% block title % A % endblock %% block content % h1Chapter A/h1 pblablabla.../p% endblock % 对于子模板 b.html，如法炮制： % extends base.html %% block title % B % endblock %% block content % h1Chapter B/h1 ul lilist 1/li lilist 2/li /ul% endblock % 这样，一旦定义好父模板的整体布局和 CSS 样式，编写子模板就会非常容易。 让我们通过 uikit 这个 CSS 框架来完成父模板 __base__.html 的编写： !DOCTYPE htmlhtmlhead meta charset=utf-8 / % block meta %!-- block meta --% endblock % title% block title % ? % endblock % - Awesome Python Webapp/title link rel=stylesheet href=/static/css/uikit.min.css link rel=stylesheet href=/static/css/uikit.gradient.min.css link rel=stylesheet href=/static/css/awesome.css / script src=/static/js/jquery.min.js/script script src=/static/js/md5.js/script script src=/static/js/uikit.min.js/script script src=/static/js/awesome.js/script % block beforehead %!-- before head --% endblock %/headbody nav class=uk-navbar uk-navbar-attached uk-margin-bottom div class=uk-container uk-container-center a href=/ class=uk-navbar-brandAwesome/a ul class=uk-navbar-nav li data-url=blogsa href=/i class=uk-icon-home/i 日志/a/li lia target=_blank href=#i class=uk-icon-book/i 教程/a/li lia target=_blank href=#i class=uk-icon-code/i 源码/a/li /ul div class=uk-navbar-flip ul class=uk-navbar-nav % if user % li class=uk-parent data-uk-dropdown a href=#0i class=uk-icon-user/i user.name /a div class=uk-dropdown uk-dropdown-navbar ul class=uk-nav uk-nav-navbar lia href=/signouti class=uk-icon-sign-out/i 登出/a/li /ul /div /li % else % lia href=/signini class=uk-icon-sign-in/i 登陆/a/li lia href=/registeri class=uk-icon-edit/i 注册/a/li % endif % /ul /div /div /nav div class=uk-container uk-container-center div class=uk-grid !-- content -- % block content % % endblock % !-- // content -- /div /div div class=uk-margin-large-top style=background-color:#eee; border-top:1px solid #ccc; div class=uk-container uk-container-center uk-text-center div class=uk-panel uk-margin-top uk-margin-bottom p a target=_blank href=# class=uk-icon-button uk-icon-weibo/a a target=_blank href=# class=uk-icon-button uk-icon-github/a a target=_blank href=# class=uk-icon-button uk-icon-linkedin-square/a a target=_blank href=# class=uk-icon-button uk-icon-twitter/a /p pPowered by a href=#Awesome Python Webapp/a. Copyright copy; 2014. [a href=/manage/ target=_blankManage/a]/p pa href=http://www.liaoxuefeng.com/ target=_blankwww.liaoxuefeng.com/a. All rights reserved./p a target=_blank href=#i class=uk-icon-html5 style=font-size:64px; color: #444;/i/a /div /div /div/body/html __base__.html 定义的几个 block 作用如下： 用于子页面定义一些 meta，例如 rss feed： % block meta % ... % endblock % 覆盖页面的标题： % block title % ... % endblock % 子页面可以在 head 标签关闭前插入 JavaScript 代码： % block beforehead % ... % endblock % 子页面的 content 布局和内容： % block content % ...% endblock % 我们把首页改造一下，从 __base__.html 继承一个 blogs.html： % extends __base__.html %% block title %日志% endblock %% block content % div class=uk-width-medium-3-4 % for blog in blogs % article class=uk-article h2a href=/blog/ blog.id blog.name /a/h2 p class=uk-article-meta发表于 blog.created_at/p p blog.summary /p pa href=/blog/ blog.id 继续阅读 i class=uk-icon-angle-double-right/i/a/p /article hr class=uk-article-divider % endfor % /div div class=uk-width-medium-1-4 div class=uk-panel uk-panel-header h3 class=uk-panel-title友情链接/h3 ul class=uk-list uk-list-line lii class=uk-icon-thumbs-o-up/i a target=_blank href=#编程/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#读书/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#Python教程/a/li lii class=uk-icon-thumbs-o-up/i a target=_blank href=#Git教程/a/li /ul /div /div% endblock % 相应地，首页 URL 的处理函数更新如下： @get(/)def index(request): summary = Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. blogs = [ Blog(id=1, name=Test Blog, summary=summary, created_at=time.time()-120), Blog(id=2, name=Something New, summary=summary, created_at=time.time()-3600), Blog(id=3, name=Learn Swift, summary=summary, created_at=time.time()-7200) ] return __template__: blogs.html, blogs: blogs Blog 的创建日期显示的是一个浮点数，因为它是由这段模板渲染出来的： p class=uk-article-meta发表于 blog.created_at /p 解决方法是通过 jinja2 的 filter（过滤器），把一个浮点数转换成日期字符串。我们来编写一个 datetime 的 filter，在模板里用法如下： p class=uk-article-meta发表于 blog.created_at|datetime /p filter 需要在初始化 jinja2 时设置。相关代码如下： def datetime_filter(t): delta = int(time.time() - t) if delta 60: return 1分钟前 if delta 3600: return %s分钟前 % (delta // 60) if delta 86400: return %s小时前 % (delta // 3600) if delta 604800: return %s天前 % (delta // 86400) dt = datetime.fromtimestamp(t) return %s年%s月%s日 % (dt.year, dt.month, dt.day)...init_jinja2(app, filters=dict(datetime=datetime_filter))... 现在，完善的首页显示如下 编写 API什么是 Web API 呢？ 如果我们想要获取一篇 Blog，输入 http://localhost:9000/blog/123，就可以看到 id 为 123 的 Blog 页面，但这个结果是 HTML 页面，它同时混合包含了 Blog 的数据和 Blog 的展示两个部分。对于用户来说，阅读起来没有问题，但是，如果机器读取，就很难从 HTML 中解析出 Blog 的数据。 如果一个 URL 返回的不是 HTML，而是机器能直接解析的数据，这个 URL 就可以看成是一个 Web API。比如，读取 http://localhost:9000/api/blogs/123，如果能直接返回 Blog 的数据，那么机器就可以直接读取。 REST 就是一种设计 API 的模式。最常用的数据格式是 JSON。由于 JSON 能直接被 JavaScript 读取，所以，以 JSON 格式编写的 REST 风格的 API 具有简单、易读、易用的特点。 编写 API 有什么好处呢？由于 API 就是把 Web App 的功能全部封装了，所以，通过 API 操作数据，可以极大地把前端和后端的代码隔离，使得后端代码易于测试，前端代码编写更简单。 一个 API 也是一个 URL 的处理函数，我们希望能直接通过一个 @api 来把函数变成 JSON 格式的 REST API，这样，获取注册用户可以用一个 API 实现如下： @get(/api/users)def api_get_users(*, page=1): page_index = get_page_index(page) num = yield from User.findNumber(count(id)) p = Page(num, page_index) if num == 0: return dict(page=p, users=()) users = yield from User.findAll(orderBy=created_at desc, limit=(p.offset, p.limit)) for u in users: u.passwd = ****** return dict(page=p, users=users) 只要返回一个 dict，后续的 response 这个 middleware 就可以把结果序列化为 JSON 并返回。 我们需要对 Error 进行处理，因此定义一个 APIError，这种 Error 是指 API 调用时发生了逻辑错误（比如用户不存在），其他的 Error 视为 Bug，返回的错误代码为 internalerror。 客户端调用 API 时，必须通过错误代码来区分 API 调用是否成功。错误代码是用来告诉调用者出错的原因。很多 API 用一个整数表示错误码，这种方式很难维护错误码，客户端拿到错误码还需要查表得知错误信息。更好的方式是用字符串表示错误代码，不需要看文档也能猜到错误原因。 可以在浏览器直接测试 API，例如，输入 http://localhost:9000/api/users，就可以看到返回的 JSON： 功能注册和登录用户管理是绝大部分 Web 网站都需要解决的问题。用户管理涉及到用户注册和登录。 用户注册相对简单，我们可以先通过 API 把用户注册这个功能实现了： _RE_EMAIL = re.compile(r^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)1,4$)_RE_SHA1 = re.compile(r^[0-9a-f]40$)@post(/api/users)def api_register_user(*, email, name, passwd): if not name or not name.strip(): raise APIValueError(name) if not email or not _RE_EMAIL.match(email): raise APIValueError(email) if not passwd or not _RE_SHA1.match(passwd): raise APIValueError(passwd) users = yield from User.findAll(email=?, [email]) if len(users) 0: raise APIError(register:failed, email, Email is already in use.) uid = next_id() sha1_passwd = %s:%s % (uid, passwd) user = User(id=uid, name=name.strip(), email=email, passwd=hashlib.sha1(sha1_passwd.encode(utf-8)).hexdigest(), image=http://www.gravatar.com/avatar/%s?d=mms=120 % hashlib.md5(email.encode(utf-8)).hexdigest()) yield from user.save() # make session cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = ****** r.content_type = application/json r.body = json.dumps(user, ensure_ascii=False).encode(utf-8) return r 注意用户口令是客户端传递的经过 SHA1 计算后的 40 位 Hash 字符串，所以服务器端并不知道用户的原始口令。 接下来可以创建一个注册页面，让用户填写注册表单，然后，提交数据到注册用户的 API： % extends __base__.html %% block title %注册% endblock %% block beforehead %scriptfunction validateEmail(email) var re = /^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)1,4$/; return re.test(email.toLowerCase());$(function () var vm = new Vue( el: #vm, data: name: , email: , password1: , password2: , methods: submit: function (event) event.preventDefault(); var $form = $(#vm); if (! this.name.trim()) return $form.showFormError(请输入名字); if (! validateEmail(this.email.trim().toLowerCase())) return $form.showFormError(请输入正确的Email地址); if (this.password1.length 6) return $form.showFormError(口令长度至少为6个字符); if (this.password1 !== this.password2) return $form.showFormError(两次输入的口令不一致); var email = this.email.trim().toLowerCase(); $form.postJSON(/api/users, name: this.name.trim(), email: email, passwd: CryptoJS.SHA1(email + : + this.password1).toString() , function (err, r) if (err) return $form.showFormError(err); return location.assign(/); ); ); $(#vm).show(););/script% endblock %% block content % div class=uk-width-2-3 h1欢迎注册！/h1 form id=vm v-on=submit: submit class=uk-form uk-form-stacked div class=uk-alert uk-alert-danger uk-hidden/div div class=uk-form-row label class=uk-form-label名字:/label div class=uk-form-controls input v-model=name type=text maxlength=50 placeholder=名字 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label电子邮件:/label div class=uk-form-controls input v-model=email type=text maxlength=50 placeholder=your-name@example.com class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label输入口令:/label div class=uk-form-controls input v-model=password1 type=password maxlength=50 placeholder=输入口令 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label重复口令:/label div class=uk-form-controls input v-model=password2 type=password maxlength=50 placeholder=重复口令 class=uk-width-1-1 /div /div div class=uk-form-row button type=submit class=uk-button uk-button-primaryi class=uk-icon-user/i 注册/button /div /form /div% endblock % 这样我们就把用户注册的功能完成了 用户登录比用户注册复杂。由于 HTTP 协议是一种无状态协议，而服务器要跟踪用户状态，就只能通过 cookie 实现。大多数 Web 框架提供了 Session 功能来封装保存用户状态的 cookie。 Session 的优点是简单易用，可以直接从 Session 中取出用户登录信息。 Session 的缺点是服务器需要在内存中维护一个映射表来存储用户登录信息，如果有两台以上服务器，就需要对 Session 做集群，因此，使用 Session 的 Web App 很难扩展。 我们采用直接读取 cookie 的方式来验证用户登录，每次用户访问任意 URL，都会对 cookie 进行验证，这种方式的好处是保证服务器处理任意的 URL 都是无状态的，可以扩展到多台服务器。 由于登录成功后是由服务器生成一个 cookie 发送给浏览器，所以，要保证这个 cookie 不会被客户端伪造出来。 实现防伪造 cookie 的关键是通过一个单向算法（例如 SHA1），举例如下： 当用户输入了正确的口令登录成功后，服务器可以从数据库取到用户的 id，并按照如下方式计算出一个字符串： 用户id + 过期时间 + SHA1(用户id + 用户口令 + 过期时间 + SecretKey) 当浏览器发送 cookie 到服务器端后，服务器可以拿到的信息包括： 用户 id 过期时间 SHA1 值如果未到过期时间，服务器就根据用户 id 查找用户口令，并计算： SHA1(用户id + 用户口令 + 过期时间 + SecretKey) 并与浏览器 cookie 中的哈希进行比较，如果相等，则说明用户已登录，否则，cookie 就是伪造的。 这个算法的关键在于 SHA1 是一种单向算法，即可以通过原始字符串计算出 SHA1 结果，但无法通过 SHA1 结果反推出原始字符串。 所以登录 API 可以实现如下： @post(/api/authenticate)def authenticate(*, email, passwd): if not email: raise APIValueError(email, Invalid email.) if not passwd: raise APIValueError(passwd, Invalid password.) users = yield from User.findAll(email=?, [email]) if len(users) == 0: raise APIValueError(email, Email not exist.) user = users[0] # check passwd: sha1 = hashlib.sha1() sha1.update(user.id.encode(utf-8)) sha1.update(b:) sha1.update(passwd.encode(utf-8)) if user.passwd != sha1.hexdigest(): raise APIValueError(passwd, Invalid password.) # authenticate ok, set cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = ****** r.content_type = application/json r.body = json.dumps(user, ensure_ascii=False).encode(utf-8) return r # 计算加密cookie:def user2cookie(user, max_age): # build cookie string by: id-expires-sha1 expires = str(int(time.time() + max_age)) s = %s-%s-%s-%s % (user.id, user.passwd, expires, _COOKIE_KEY) L = [user.id, expires, hashlib.sha1(s.encode(utf-8)).hexdigest()] return -.join(L) 对于每个 URL 处理函数，如果我们都去写解析 cookie 的代码，那会导致代码重复很多次。 利用 middle 在处理 URL 之前，把 cookie 解析出来，并将登录用户绑定到 request 对象上，这样，后续的 URL 处理函数就可以直接拿到登录用户： @asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(check user: %s %s % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(set current user: %s % user.email) request.__user__ = user return (yield from handler(request)) return auth # 解密cookie:@asyncio.coroutinedef cookie2user(cookie_str): Parse cookie and load user if cookie is valid. if not cookie_str: return None try: L = cookie_str.split(-) if len(L) != 3: return None uid, expires, sha1 = L if int(expires) time.time(): return None user = yield from User.find(uid) if user is None: return None s = %s-%s-%s-%s % (uid, user.passwd, expires, _COOKIE_KEY) if sha1 != hashlib.sha1(s.encode(utf-8)).hexdigest(): logging.info(invalid sha1) return None user.passwd = ****** return user except Exception as e: logging.exception(e) return None 这样，我们就完成了用户注册和登录的功能。 编写日志创建页在 Web 开发中，后端代码写起来其实是相当容易的。 例如，我们编写一个 REST API，用于创建一个 Blog： @post(/api/blogs)def api_create_blog(request, *, name, summary, content): check_admin(request) if not name or not name.strip(): raise APIValueError(name, name cannot be empty.) if not summary or not summary.strip(): raise APIValueError(summary, summary cannot be empty.) if not content or not content.strip(): raise APIValueError(content, content cannot be empty.) blog = Blog(user_id=request.__user__.id, user_name=request.__user__.name, user_image=request.__user__.image, name=name.strip(), summary=summary.strip(), content=content.strip()) yield from blog.save() return blog 编写后端 Python 代码不但很简单，而且非常容易测试，上面的 API：api_create_blog() 本身只是一个普通函数。 Web 开发真正困难的地方在于编写前端页面。前端页面需要混合 HTML、CSS 和 JavaScript，如果对这三者没有深入地掌握，编写的前端页面将很快难以维护。 更大的问题在于，前端页面通常是动态页面，也就是说，前端页面往往是由后端代码生成的。 生成前端页面最早的方式是拼接字符串： s = htmlheadtitle + title + /title/headbody + body + /body/html 显然这种方式完全不具备可维护性。所以有第二种模板方式： htmlhead title title /title/headbody body /body/html ASP、JSP、PHP 等都是用这种模板方式生成前端页面。 如果在页面上大量使用 JavaScript（事实上大部分页面都会），模板方式仍然会导致 JavaScript 代码与后端代码绑得非常紧密，以至于难以维护。其根本原因在于负责显示的 HTML DOM 模型与负责数据和交互的 JavaScript 代码没有分割清楚。 要编写可维护的前端代码绝非易事。和后端结合的 MVC 模式已经无法满足复杂页面逻辑的需要了，所以，新的 MVVM：Model View ViewModel 模式应运而生。 MVVM 最早由微软提出来，它借鉴了桌面应用程序的 MVC 思想，在前端页面中，把 Model 用纯 JavaScript 对象表示： script var blog = name: hello, summary: this is summary, content: this is content... ;/script View 是纯 HTML： form action=/api/blogs method=post input name=name input name=summary textarea name=content/textarea button type=submitOK/button/form 由于 Model 表示数据，View 负责显示，两者做到了最大限度的分离。 把 Model 和 View 关联起来的就是 ViewModel。ViewModel 负责把 Model 的数据同步到 View 显示出来，还负责把 View 的修改同步回 Model。 ViewModel 如何编写？需要用 JavaScript 编写一个通用的 ViewModel，这样，就可以复用整个 MVVM 模型了。 好消息是已有许多成熟的 MVVM 框架，例如 AngularJS，KnockoutJS 等。我们选择 Vue 这个简单易用的 MVVM 框架来实现创建 Blog 的页面 templates/manage_blog_edit.html： % extends __base__.html %% block title %编辑日志% endblock %% block beforehead %scriptvar ID = id , action = action ;function initVM(blog) var vm = new Vue( el: #vm, data: blog, methods: submit: function (event) event.preventDefault(); var $form = $(#vm).find(form); $form.postJSON(action, this.$data, function (err, r) if (err) $form.showFormError(err); else return location.assign(/api/blogs/ + r.id); ); ); $(#vm).show();$(function () if (ID) getJSON(/api/blogs/ + ID, function (err, blog) if (err) return fatal(err); $(#loading).hide(); initVM(blog); ); else $(#loading).hide(); initVM( name: , summary: , content: ); );/script% endblock %% block content % div class=uk-width-1-1 uk-margin-bottom div class=uk-panel uk-panel-box ul class=uk-breadcrumb lia href=/manage/comments评论/a/li lia href=/manage/blogs日志/a/li lia href=/manage/users用户/a/li /ul /div /div div id=error class=uk-width-1-1 /div div id=loading class=uk-width-1-1 uk-text-center spani class=uk-icon-spinner uk-icon-medium uk-icon-spin/i 正在加载.../span /div div id=vm class=uk-width-2-3 form v-on=submit: submit class=uk-form uk-form-stacked div class=uk-alert uk-alert-danger uk-hidden/div div class=uk-form-row label class=uk-form-label标题:/label div class=uk-form-controls input v-model=name name=name type=text placeholder=标题 class=uk-width-1-1 /div /div div class=uk-form-row label class=uk-form-label摘要:/label div class=uk-form-controls textarea v-model=summary rows=4 name=summary placeholder=摘要 class=uk-width-1-1 style=resize:none;/textarea /div /div div class=uk-form-row label class=uk-form-label内容:/label div class=uk-form-controls textarea v-model=content rows=16 name=content placeholder=内容 class=uk-width-1-1 style=resize:none;/textarea /div /div div class=uk-form-row button type=submit class=uk-button uk-button-primaryi class=uk-icon-save/i 保存/button a href=/manage/blogs class=uk-buttoni class=uk-icon-times/i 取消/a /div /form /div% endblock % 初始化 Vue 时，我们指定 3 个参数： el：根据选择器查找绑定的 View，这里是 #vm，就是 id 为 vm 的 DOM，对应的是一个 div 标签； data：JavaScript 对象表示的 Model，我们初始化为 name: , summary: , content: ； methods：View 可以触发的 JavaScript 函数，submit 就是提交表单时触发的函数。 接下来，我们在 form 标签中，用几个简单的 v-model，就可以让 Vue 把 Model 和 View 关联起来： !-- input的value和Model的name关联起来了 --input v-model=name class=uk-width-1-1 Form 表单通过 form v-on=submit: submit 把提交表单的事件关联到 submit 方法。 需要特别注意的是，在 MVVM 中，Model 和 View 是双向绑定的。如果我们在 Form 中修改了文本框的值，可以在 Model 中立刻拿到新的值。试试在表单中输入文本，然后在 Chrome 浏览器中打开 JavaScript 控制台，可以通过 vm.name 访问单个属性，或者通过 vm.$data 访问整个 Model 如果我们在 JavaScript 逻辑中修改了 Model，这个修改会立刻反映到 View 上。试试在 JavaScript 控制台输入 vm.name = MVVM简介，可以看到文本框的内容自动被同步了 双向绑定是 MVVM 框架最大的作用。借助于 MVVM，我们把复杂的显示逻辑交给框架完成。由于后端编写了独立的 REST API，所以，前端用 AJAX 提交表单非常容易，前后端分离得非常彻底。 日志列表页MVVM 模式不但可用于 Form 表单，在复杂的管理页面中也能大显身手。例如，分页显示 Blog 的功能，我们先把后端代码写出来： 在 apis.py 中定义一个 Page 类用于存储分页信息： class Page(object): def __init__(self, item_count, page_index=1, page_size=10): self.item_count = item_count self.page_size = page_size self.page_count = item_count // page_size + (1 if item_count % page_size 0 else 0) if (item_count == 0) or (page_index self.page_count): self.offset = 0 self.limit = 0 self.page_index = 1 else: self.page_index = page_index self.offset = self.page_size * (page_index - 1) self.limit = self.page_size self.has_next = self.page_index self.page_count self.has_previous = self.page_index 1 def __str__(self): return item_count: %s, page_count: %s, page_index: %s, page_size: %s, offset: %s, limit: %s % (self.item_count, self.page_count, self.page_index, self.page_size, self.offset, self.limit) __repr__ = __str__ 在 handlers.py 中实现 API： @get(/api/blogs)def api_blogs(*, page=1): page_index = get_page_index(page) num = yield from Blog.findNumber(count(id)) p = Page(num, page_index) if num == 0: return dict(page=p, blogs=()) blogs = yield from Blog.findAll(orderBy=created_at desc, limit=(p.offset, p.limit)) return dict(page=p, blogs=blogs) 管理页面： @get(/manage/blogs)def manage_blogs(*, page=1): return __template__: manage_blogs.html, page_index: get_page_index(page) 模板页面首先通过 API：GET /api/blogs?page=? 拿到 Model： page: has_next: true, page_index: 1, page_count: 2, has_previous: false, item_count: 12 , blogs: [...] 然后，通过 Vue 初始化 MVVM： scriptfunction initVM(data) var vm = new Vue( el: #vm, data: blogs: data.blogs, page: data.page , methods: edit_blog: function (blog) location.assign(/manage/blogs/edit?id= + blog.id); , delete_blog: function (blog) if (confirm(确认要删除“ + blog.name + ”？删除后不可恢复！)) postJSON(/api/blogs/ + blog.id + /delete, function (err, r) if (err) return alert(err.message || err.error || err); refresh(); ); ); $(#vm).show();$(function() getJSON(/api/blogs, page: page_index , function (err, results) if (err) return fatal(err); $(#loading).hide(); initVM(results); ););/script View 的容器是 #vm，包含一个 table，我们用 v-repeat 可以把 Model 的数组 blogs 直接变成多行的 tr： div id=vm class=uk-width-1-1 a href=/manage/blogs/create class=uk-button uk-button-primaryi class=uk-icon-plus/i 新日志/a table class=uk-table uk-table-hover thead tr th class=uk-width-5-10标题 / 摘要/th th class=uk-width-2-10作者/th th class=uk-width-2-10创建时间/th th class=uk-width-1-10操作/th /tr /thead tbody tr v-repeat=blog: blogs td a target=_blank v-attr=href: /blog/+blog.id v-text=blog.name/a /td td a target=_blank v-attr=href: /user/+blog.user_id v-text=blog.user_name/a /td td span v-text=blog.created_at.toDateTime()/span /td td a href=#0 v-on=click: edit_blog(blog)i class=uk-icon-edit/i a href=#0 v-on=click: delete_blog(blog)i class=uk-icon-trash-o/i /td /tr /tbody /table div v-component=pagination v-with=page/div/div 往 Model 的 blogs 数组中增加一个 Blog 元素，table 就神奇地增加了一行；把 blogs 数组的某个元素删除，table 就神奇地减少了一行。所有复杂的 Model-View 的映射逻辑全部由 MVVM 框架完成，我们只需要在 HTML 中写上 v-repeat 指令，就什么都不用管了。 可以把 v-repeat=blog: blogs 看成循环代码，所以，可以在一个 tr 内部引用循环变量 blog。v-text 和 v-attr 指令分别用于生成文本和 DOM 节点属性。 效率现在，我们已经把一个 Web App 的框架完全搭建好了，从后端的 API 到前端的 MVVM，流程已经跑通了。 在继续工作前，注意到每次修改 Python 代码，都必须在命令行先 Ctrl-C 停止服务器，再重启，改动才能生效。 在开发阶段，每天都要修改、保存几十次代码，每次保存都手动来这么一下非常麻烦，严重地降低了我们的开发效率。有没有办法让服务器检测到代码修改后自动重新加载呢？ Django 的开发环境在 Debug 模式下就可以做到自动重新加载，如果我们编写的服务器也能实现这个功能，就能大大提升开发效率。 可惜的是，Django 没把这个功能独立出来，不用 Django 就享受不到，怎么办？ 其实 Python 本身提供了重新载入模块的功能，但不是所有模块都能被重新载入。另一种思路是检测 www 目录下的代码改动，一旦有改动，就自动重启服务器。 按照这个思路，我们可以编写一个辅助程序 pymonitor.py，让它启动 wsgiapp.py，并时刻监控 www 目录下的代码改动，有改动时，先把当前 wsgiapp.py 进程杀掉，再重启，就完成了服务器进程的自动重启。 要监控目录文件的变化，我们也无需自己手动定时扫描，Python 的第三方库 watchdog 可以利用操作系统的 API 来监控目录文件的变化，并发送通知。我们先用 pip 安装： $ pip3 install watchdog 利用 watchdog 接收文件变化的通知，如果是 .py 文件，就自动重启 wsgiapp.py 进程。 利用 Python 自带的 subprocess 实现进程的启动和终止，并把输入输出重定向到当前进程的输入输出中： #!/usr/bin/env python3# -*- coding: utf-8 -*-__author__ = Michael Liaoimport os, sys, time, subprocessfrom watchdog.observers import Observerfrom watchdog.events import FileSystemEventHandlerdef log(s): print([Monitor] %s % s)class MyFileSystemEventHander(FileSystemEventHandler): def __init__(self, fn): super(MyFileSystemEventHander, self).__init__() self.restart = fn def on_any_event(self, event): if event.src_path.endswith(.py): log(Python source file changed: %s % event.src_path) self.restart()command = [echo, ok]process = Nonedef kill_process(): global process if process: log(Kill process [%s]... % process.pid) process.kill() process.wait() log(Process ended with code %s. % process.returncode) process = Nonedef start_process(): global process, command log(Start process %s... % .join(command)) process = subprocess.Popen(command, stdin=sys.stdin, stdout=sys.stdout, stderr=sys.stderr)def restart_process(): kill_process() start_process()def start_watch(path, callback): observer = Observer() observer.schedule(MyFileSystemEventHander(restart_process), path, recursive=True) observer.start() log(Watching directory %s... % path) start_process() try: while True: time.sleep(0.5) except KeyboardInterrupt: observer.stop() observer.join()if __name__ == __main__: argv = sys.argv[1:] if not argv: print(Usage: ./pymonitor your-script.py) exit(0) if argv[0] != python3: argv.insert(0, python3) command = argv path = os.path.abspath(.) start_watch(path, None) 一共 70 行左右的代码，就实现了 Debug 模式的自动重新加载。用下面的命令启动服务器： $ python3 pymonitor.py wsgiapp.py 或者给 pymonitor.py 加上可执行权限，启动服务器： $ ./pymonitor.py app.py 在编辑器中打开一个 .py 文件，修改后保存，看看命令行输出，是不是自动重启了服务器： $ ./pymonitor.py app.py [Monitor] Watching directory /Users/michael/Github/awesome-python3-webapp/www...[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000...[Monitor] Python source file changed: /Users/michael/Github/awesome-python-webapp/www/handlers.py[Monitor] Kill process [2747]...[Monitor] Process ended with code -9.[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000... 现在，只要一保存代码，就可以刷新浏览器看到效果，大大提升了开发效率。 完善在 Web App 框架和基本流程跑通后，剩下的工作全部是体力活了：在 Debug 开发模式下完成后端所有 API、前端所有页面。我们需要做的事情包括： 把当前用户绑定到 request 上，并对 URL/manage/ 进行拦截，检查当前用户是否是管理员身份： @asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(check user: %s %s % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(set current user: %s % user.email) request.__user__ = user if request.path.startswith(/manage/) and (request.__user__ is None or not request.__user__.admin): return web.HTTPFound(/signin) return (yield from handler(request)) return auth 后端 API 包括： 获取日志：GET apiblogs 创建日志：POST apiblogs 修改日志：POST apiblogs:blog_id 删除日志：POST apiblogs:blog_iddelete 获取评论：GET apicomments 创建评论：POST apiblogs:blog_idcomments 删除评论：POST apicomments:comment_iddelete 创建新用户：POST apiusers 获取用户：GET apiusers管理页面包括： 评论列表页：GET managecomments 日志列表页：GET manageblogs 创建日志页：GET manageblogscreate 修改日志页：GET manageblogs 用户列表页：GET manageusers用户浏览页面包括： 注册页：GET register 登录页：GET signin 注销页：GET signout 首页：GET 日志详情页：GET blog:blog_id把所有的功能实现，我们第一个 Web App 就宣告完成！ 部署很多做开发的同学把部署这件事情看成是运维同学的工作，这种看法是完全错误的。首先，最近流行 DevOps 理念，就是说，开发和运维要变成一个整体。其次，运维的难度，其实跟开发质量有很大的关系。代码写得垃圾，运维再好也架不住天天挂掉。最后，DevOps 理念需要把运维、监控等功能融入到开发中。你想服务器升级时不中断用户服务？那就得在开发时考虑到这一点。 下面，我们就来把 awesome-python3-webapp 部署到 Linux 服务器。 搭建 Linux 服务器要部署到 Linux，首先得有一台 Linux 服务器。要在公网上体验的同学，可以在 Amazon 的 AWS 申请一台 EC2 虚拟机（免费使用 1 年），或者使用国内的一些云服务器，一般都提供 Ubuntu Server 的镜像。想在本地部署的同学，请安装虚拟机，推荐使用 VirtualBox。 我们选择的 Linux 服务器版本是 Ubuntu Server 14.04 LTS，原因是 apt 太简单了。如果你准备使用其他 Linux 版本，也没有问题。 Linux 安装完成后，请确保 ssh 服务正在运行，否则，需要通过 apt 安装： $ sudo apt-get install openssh-server 有了 ssh 服务，就可以从本地连接到服务器上。建议把公钥复制到服务器端用户的 .ssh/authorized_keys 中，这样，就可以通过证书实现无密码连接。 部署方式利用 Python 自带的 asyncio，我们已经编写了一个异步高性能服务器。但是，我们还需要一个高性能的 Web 服务器，这里选择 Nginx，它可以处理静态资源，同时作为反向代理把动态请求交给 Python 代码处理。这个模型如下 Nginx 负责分发请求 在服务器端，我们需要定义好部署的目录结构： /+- srv/ +- awesome/ -- Web App根目录 +- www/ -- 存放Python源码 | +- static/ -- 存放静态资源文件 +- log/ -- 存放log 在服务器上部署，要考虑到新版本如果运行不正常，需要回退到旧版本时怎么办。每次用新的代码覆盖掉旧的文件是不行的，需要一个类似版本控制的机制。由于 Linux 系统提供了软链接功能，所以，我们把 www 作为一个软链接，它指向哪个目录，哪个目录就是当前运行的版本 而 Nginx 和 python 代码的配置文件只需要指向 www 目录即可。 Nginx 可以作为服务进程直接启动，但 app.py 还不行，所以，Supervisor 登场！Supervisor 是一个管理进程的工具，可以随系统启动而启动服务，它还时刻监控服务进程，如果服务进程意外退出，Supervisor 可以自动重启服务。 总结一下我们需要用到的服务有： Nginx：高性能 Web 服务器 + 负责反向代理； Supervisor：监控服务进程的工具； MySQL：数据库服务。在 Linux 服务器上用 apt 可以直接安装上述服务： $ sudo apt-get install nginx supervisor python3 mysql-server 然后，再把我们自己的 Web App 用到的 Python 库安装了： $ sudo pip3 install jinja2 aiomysql aiohttp 在服务器上创建目录 /srv/awesome/ 以及相应的子目录。 在服务器上初始化 MySQL 数据库，把数据库初始化脚本 schema.sql 复制到服务器上执行： $ mysql -u root -p schema.sql 服务器端准备就绪。 部署用 FTP 还是 SCP 还是 rsync 复制文件？如果你需要手动复制，用一次两次还行，一天如果部署 50 次不但慢、效率低，而且容易出错。 正确的部署方式是使用工具配合脚本完成自动化部署。Fabric 就是一个自动化部署工具。由于 Fabric 是用 Python 2.x 开发的，所以，部署脚本要用 Python 2.7 来编写，本机还必须安装 Python 2.7 版本。 要用 Fabric 部署，需要在本机（是开发机器，不是 Linux 服务器）安装 Fabric： $ easy_install fabric Linux 服务器上不需要安装 Fabric，Fabric 使用 SSH 直接登录服务器并执行部署命令。 下一步是编写部署脚本。Fabric 的部署脚本叫 fabfile.py，我们把它放到 awesome-python-webapp 的目录下，与 www 目录平级： awesome-python-webapp/+- fabfile.py+- www/+- ... Fabric 的脚本编写很简单，首先导入 Fabric 的 API，设置部署时的变量： # fabfile.pyimport os, refrom datetime import datetime# 导入Fabric API:from fabric.api import *# 服务器登录用户名:env.user = michael# sudo用户为root:env.sudo_user = root# 服务器地址，可以有多个，依次部署:env.hosts = [192.168.0.3]# 服务器MySQL用户名和口令:db_user = www-datadb_password = www-data 然后，每个 Python 函数都是一个任务。我们先编写一个打包的任务： _TAR_FILE = dist-awesome.tar.gzdef build(): includes = [static, templates, transwarp, favicon.ico, *.py] excludes = [test, .*, *.pyc, *.pyo] local(rm -f dist/%s % _TAR_FILE) with lcd(os.path.join(os.path.abspath(.), www)): cmd = [tar, --dereference, -czvf, ../dist/%s % _TAR_FILE] cmd.extend([--exclude=\\%s\\ % ex for ex in excludes]) cmd.extend(includes) local( .join(cmd)) Fabric 提供 local(...) 来运行本地命令，with lcd(path) 可以把当前命令的目录设定为 lcd() 指定的目录，注意 Fabric 只能运行命令行命令，Windows 下可能需要 Cgywin 环境。 在 awesome-python-webapp 目录下运行： $ fab build 看看是否在 dist 目录下创建了 dist-awesome.tar.gz 的文件。 打包后，我们就可以继续编写 deploy 任务，把打包文件上传至服务器，解压，重置 www 软链接，重启相关服务： _REMOTE_TMP_TAR = /tmp/%s % _TAR_FILE_REMOTE_BASE_DIR = /srv/awesomedef deploy(): newdir = www-%s % datetime.now().strftime(%y-%m-%d_%H.%M.%S) # 删除已有的tar文件: run(rm -f %s % _REMOTE_TMP_TAR) # 上传新的tar文件: put(dist/%s % _TAR_FILE, _REMOTE_TMP_TAR) # 创建新目录: with cd(_REMOTE_BASE_DIR): sudo(mkdir %s % newdir) # 解压到新目录: with cd(%s/%s % (_REMOTE_BASE_DIR, newdir)): sudo(tar -xzvf %s % _REMOTE_TMP_TAR) # 重置软链接: with cd(_REMOTE_BASE_DIR): sudo(rm -f www) sudo(ln -s %s www % newdir) sudo(chown www-data:www-data www) sudo(chown -R www-data:www-data %s % newdir) # 重启Python服务和nginx服务器: with settings(warn_only=True): sudo(supervisorctl stop awesome) sudo(supervisorctl start awesome) sudo(/etc/init.d/nginx reload) 注意 run() 函数执行的命令是在服务器上运行，with cd(path) 和 with lcd(path) 类似，把当前目录在服务器端设置为 cd() 指定的目录。如果一个命令需要 sudo 权限，就不能用 run()，而是用 sudo() 来执行。 配置 Supervisor上面让 Supervisor 重启 awesome 的命令会失败，因为我们还没有配置 Supervisor 呢。 编写一个 Supervisor 的配置文件 awesome.conf，存放到 /etc/supervisor/conf.d/ 目录下： [program:awesome]command = /srv/awesome/www/app.pydirectory = /srv/awesome/wwwuser = www-datastartsecs = 3redirect_stderr = truestdout_logfile_maxbytes = 50MBstdout_logfile_backups = 10stdout_logfile = /srv/awesome/log/app.log 配置文件通过 [program:awesome] 指定服务名为 awesome，command 指定启动 app.py。 然后重启 Supervisor 后，就可以随时启动和停止 Supervisor 管理的服务了： $ sudo supervisorctl reload$ sudo supervisorctl start awesome$ sudo supervisorctl statusawesome RUNNING pid 1401, uptime 5:01:34 配置 NginxSupervisor 只负责运行 app.py，我们还需要配置 Nginx。把配置文件 awesome 放到 /etc/nginx/sites-available/ 目录下： server listen 80; # 监听80端口 root /srv/awesome/www; access_log /srv/awesome/log/access_log; error_log /srv/awesome/log/error_log; # server_name awesome.liaoxuefeng.com; # 配置域名 # 处理静态文件/favicon.ico: location /favicon.ico root /srv/awesome/www; # 处理静态资源: location ~ ^\\/static\\/.*$ root /srv/awesome/www; # 动态请求转发到9000端口: location / proxy_pass http://127.0.0.1:9000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 然后在 /etc/nginx/sites-enabled/ 目录下创建软链接： $ pwd/etc/nginx/sites-enabled$ sudo ln -s /etc/nginx/sites-available/awesome . 让 Nginx 重新加载配置文件，不出意外，我们的 awesome-python3-webapp 应该正常运行： $ sudo /etc/init.d/nginx reload 如果有任何错误，都可以在 /srv/awesome/log 下查找 Nginx 和 App 本身的 log。如果 Supervisor 启动时报错，可以在 /var/log/supervisor 下查看 Supervisor 的 log。 如果一切顺利，你可以在浏览器中访问 Linux 服务器上的 awesome-python3-webapp 了 如果在开发环境更新了代码，只需要在命令行执行： $ fab build$ fab deploy 自动部署完成！刷新浏览器就可以看到服务器代码更新后的效果。","categories":["1.语言","Python"]},{"title":"JavaScript","path":"/2024/05/22/1-语言-工具语言-JavaScript/","content":"示例分析//在当前页面重新载入页面function reloadPageContent(reloadPage) window.location.replace(reloadPage);//按钮点击展开或隐藏function updateClick() $(document).ready((function() //ready函数来确保文档加载完毕后再执行代码(jquery库代码)\t$(a).click((function() //为文档中的所有a标签绑定点击事件 $(this).next(.menu).toggle()//找到当前被点击的a标签的下一个.menu类的元素，切换它的可见性\t)) ))//获取并更新innerHTML中的内容function getInnerHTML(filePos) var xhr = new XMLHttpRequest(); xhr.open(GET, filePos, true); xhr.onreadystatechange = function() if (xhr.readyState === 4 xhr.status === 200) var htmlContent = xhr.responseText; document.getElementById(mainmenu).innerHTML = htmlContent; updateClick(); ; xhr.send();function showPicture() fetch(http://124.222.246.202/get_picture?id=1, method: GET,headers: Content-Type: application/json,) .then(response = response.text()) .then(data = document.getElementById(mainmenu).innerHTML=data)function openFile(filePos) var xhr = new XMLHttpRequest(); xhr.open(POST, http://124.222.246.202/getFileContent, true); xhr.setRequestHeader(Content-Type, application/json;charset=UTF-8); var message = filePos ; var jsonMessage = JSON.stringify(message); xhr.onreadystatechange = function () if (xhr.readyState === 4 xhr.status === 200) var responseContainer = document.getElementById(mainmenu); responseContainer.innerHTML = meta name=viewport content=width=device-width, initial-scale=1link rel=stylesheet href=2.css/github-markdown-css/github-markdown.cssstyle.markdown-body box-sizing: border-box;min-width: 200px;max-width: 980px;margin: 0 auto;padding: 45px;@media (max-width: 767px) .markdown-body padding: 15px;/stylearticle class=markdown-body+marked.parse(xhr.responseText)+/article; ; xhr.send(jsonMessage);function blogList() // 创建XMLHttpRequest对象 var xhr = new XMLHttpRequest(); // 配置请求，将消息发送到后端Python服务器 xhr.open(POST, http://124.222.246.202/getFileList, true); // 设置请求头，告诉服务器发送的是JSON数据 xhr.setRequestHeader(Content-Type, application/json;charset=UTF-8); // 创建要发送的消息对象 var message = message: Hello, backend! ; // 将消息对象转换为JSON格式 var jsonMessage = JSON.stringify(message); // 处理响应 xhr.onreadystatechange = function () if (xhr.readyState === 4 xhr.status === 200) // 在页面上显示后端返回的消息 var responseContainer = document.getElementById(mainmenu); responseContainer.innerHTML = 后端返回的消息: + xhr.responseText; ; // 发送请求 xhr.send(jsonMessage);","categories":["1.语言","工具语言"]},{"title":"Python返回前端请求IP地址","path":"/2024/05/22/0-平台-服务器-微信-Python返回前端请求IP地址/","content":"前端 js 代码script\tfetch(/get_ip, method: GET,headers: Content-Type: application/json,) .then(response = response.text()) .then(data = document.getElementById(ip_addr).innerHTML=data)/script","categories":["0.平台","服务器","微信"]},{"title":"LNMP环境","path":"/2024/05/22/0-平台-服务器-博客-LNMP环境/","content":"前言在通过 Docker 部署 WordPress 的过程中，我意识到许多需要修改的文件都必须通过 docker-compose 脚本映射到本地，这让改动变得不太方便。此外，由于 Docker 的特性，关闭并重启容器后，里面的数据往往会丢失。为了解决这个问题，只能依赖于持久化存储，而这可以通过 volume 或者称为“数据容器”的方案来实现。 容器一旦关闭，我们可以使用 -v 或者 --volumes-from 来重新利用以前的数据。此外，Docker 还支持挂载宿主机的磁盘目录，从而实现数据的永久存储。这种方式虽然可行，但在实际操作中，能够直观地查看和修改所有文件显得更为放心。因此，我决定通过手动配置 LNMP 的基础运行环境来建立我的 WordPress 网站。 目前配置 LNMP 环境可选的方式有以下几种： 通过宝塔面板进行可视化配置，适合不熟悉命令行的用户。 使用脚本实现一键配置，减少手动操作的复杂性。 各软件组件独立进行手动安装与配置，适合深入了解每个组件的用户。 在这次设置中，我选择通过脚本配置，并将之前 Docker 中搭建的 WordPress 的所有数据导入新的环境中。 LNMP 介绍LNMP 是 WordPress 运行的基础环境，其全名相对应的是四个主要组件：Linux、Nginx、MySQLMariaDB 和 PHP。这些组件的角色功能如下： Linux：作为操作系统，它提供了基本的系统服务和资源管理，比如文件系统、用户管理和网络配置等。 Nginx：这是一个高性能的 Web 服务器，能有效处理客户端请求并将其转发给后端应用程序。Nginx 的异步处理能力使其能够轻松应对大量并发请求，特别适合用于动态站点。 MySQLMariaDB：这两者都是关系型数据库，负责存储和管理应用程序的数据。MySQL 和 MariaDB 提供强大的数据查询和存储功能，支持多种存储引擎。 PHP：作为服务器端的编程语言，PHP 允许开发人员编写复杂的程序逻辑，如处理用户请求、与数据库交互等。 LNMP 架构具有明显的优点： 高性能：如前所述，Nginx 能处理大量并发请求，适合流量密集型的网站。 稳定可靠：Linux 系统以其稳定性著称，广泛用于服务器环境，保证了良好的系统服务和资源管理。 易于扩展：选择 MySQL 或 MariaDB 可以轻松实现高可用和分布式架构，支持业务增长。 灵活可定制：PHP 支持丰富的框架和库，能够满足多样化的业务需求。 LNMP 架构在 Web 开发和运维领域得到了广泛的应用，尤其在面对高并发和大数据场景时，能够保持良好的性能表现与可扩展性。 此外，值得一提的是还有其他几种架构。例如，LAMP 是 Linux + Apache + MySQL + PHP 的组合，LNAMP 则是 Linux + Nginx + Apache + MySQL + PHP。Apache 是一种排名第一的 Web 服务器软件，以其跨平台特性和安全性被广泛采纳，是目前最流行的 Web 服务器之一。 一键安装 LNMP登录 VPS 或服务器使用 PuTTY 或其他类似的 SSH 工具登录到您的 VPS 或服务器。成功登录后，运行以下命令以创建一个新的屏幕会话： screen -S lnmp 如果出现 screen: command not found 的提示，您可以通过以下命令安装 screen： apt-get install screen 有关 screen 的详细用法，请参考其 官方教程。 下载并安装 LNMP 一键安装包您可以选择下载两个版本的 LNMP 安装包： 下载版：推荐给美国及海外的 VPS 或空间较小的用户使用。 完整版：推荐给国内 VPS 用户，包含了一些预先放入的源码文件，方便快速安装。 安装 LNMP 稳定版如果您希望进行无人值守安装，可以使用无人值守命令生成工具，或查看相关的无人值守说明教程。 使用以下命令下载并解压 LNMP 安装包： wget http://soft.vpser.net/lnmp/lnmp1.9.tar.gz -cO lnmp1.9.tar.gz tar zxf lnmp1.9.tar.gz cd lnmp1.9 ./install.sh lnmp 如果您的目标是安装 LNMPA 或 LAMP，将命令中的 lnmp 替换为 lnmpa 或 lamp 即可。此外，您还可以选择单独安装 Nginx 或数据库，运行以下命令： ./install.sh nginx 或 ./install.sh db 如果您需要更改网站和数据库目录、自定义 Nginx 参数或 PHP 参数模块（如是否开启 lua），请在运行 ./install.sh 命令前修改安装包目录下的 lnmp.conf 文件。详细的参数说明可以在 lnmp.conf 文件中查看。 如遇到 wget: command not found 的提示，您可以使用以下命令安装 wget： yum install wget 或 apt-get install wget 如果下载速度慢或遇到下载问题，请考虑更换其他下载节点，具体替换方法可以在 LNMP 的文档中找到。 执行 LNMP 安装命令运行 LNMP 安装命令后，可能会出现以下提示： 当前安装包中提供了多种 MySQL 和 MariaDB 的版本选项。如果您选择安装 MySQL 5.6、5.7 或 MariaDB 10，确保您的内存配置至少为 1G。如果仅需安装数据库，可以使用以下命令： ./install.sh db 在提示中，输入相应 MySQL 或 MariaDB 版本前的序号并回车，进入下一个步骤。 如果您选择 MySQL 5.7 或 8.0 且系统架构为 x86 或 x86_64，系统会提示您是否使用二进制包进行安装：“Using Generic Binaries [yn]:”。输入 y 表示使用二进制安装，输入 n 则使用源码编译。如果选择了二进制方式，建议离线安装或自行下载至安装包的 src 目录。 接下来，您需要设置 MySQL 的 root 密码。出于安全考虑，您可以直接回车，系统会自动生成一个密码（例如 lnmp.org#随机数字）。如果需要删除错误输入的密码，按住 Ctrl 并同时按 Backspace 或只按 Backspace 键（根据系统不同情况而定）。 接着，系统会询问您是否启用 MySQL InnoDB，引擎默认开启，建议直接回车或输入 y。如果您确定不需要，可以输入 n。请注意，MySQL 5.7 及以上版本无法关闭 InnoDB。 选择 PHP 版本时，请确认所选版本与您的程序兼容。输入相应 PHP 版本的序号并回车，接下来会提示您是否安装内存优化选项。可以选择不安装、Jemalloc 或 TCmalloc，直接回车则为默认不安装。 如果您选择的是 LNMPA 或 LAMP，系统会进一步提示设置管理员邮箱，该邮箱在出现错误时会显示在错误页面上。接着，选择 Apache 版本，输入对应版本序号并回车。 在提示“Press any key to install… or Press Ctrl+c to cancel”后，按下回车键确认开始安装。LNMP 脚本将自动安装和编译 Nginx、MySQL、PHP、phpMyAdmin 等软件及相关组件。安装耗时从几十分钟到几个小时不等，具体时间依赖于机器配置及网络速度。 安装完成安装完成后，系统应显示： Nginx: OK, MySQL: OK, PHP: OK 同时，Nginx、MySQL、PHP 都应显示为运行状态，并确保 80 和 3306 端口存在，并提示安装时间及“Install lnmp V1.9 completed! enjoy it.”，说明安装成功。如果系统卡在“Install lnmp V1.9 completed! enjoy it.”不自动退出，可以按 Ctrl + c 强制退出。 完成安装后，您可以按照添加虚拟主机的教程添加虚拟主机。随后，使用 SFTP 或 FTP 服务器上传网站代码，并将域名解析到 VPS 或服务器的 IP 地址。确保解析生效后，即可使用您的网站。 安装失败如果出现某个部分没有成功安装的提示，意味着安装失败。您需要使用 WinSCP 或其他相关工具，将 /root 目录下的 lnmp-install.log 文件下载到本地，并在 LNMP 支持论坛发帖，附上您系统的发行版名称、版本号以及 32 位或 64 位等信息，并将 lnmp-install.log 压缩后上传，我们会通过日志分析错误并提供解决方案。 注意：默认情况下，LNMP 不会安装 FTP 服务器，若需要 FTP 服务器，请参考 此链接。 添加、删除虚拟主机及伪静态管理有关如何添加和删除虚拟主机的详细步骤，请访问 此链接。 扩展组件的安装如果需要安装扩展组件如 eAccelerator、xcache、memcached、imageMagick、ionCube、redis 或 opcache，请参考 此链接。 LNMP 相关软件的目录及文件位置关于 LNMP 相关软件的目录和文件位置的信息，可以访问 此链接。 LNMP 状态管理命令了解 LNMP 状态管理命令的详细内容，请查看 此链接。 仅安装数据库或 Nginx从 LNMP 1.5 版本开始，用户可以选择仅安装 MySQLMariaDB 数据库或 Nginx。要单独安装 Nginx，请在安装包目录下运行： ./install.sh nginx 要单独安装数据库，请运行： ./install.sh db LNMP 一键安装包的离线安装请注意，离线安装并不意味着不需要源，而是需要您在本地建立一个源用于安装。 对于 CentOS 系统，离线安装的详细教程请参考 此链接。 对于 DebianUbuntu 发行版，您需要在完全相同的临时环境下使用以下命令下载所有必需的软件包： apt-get install -d 软件包 然后通过 dpkg-scanpackages 命令将这些软件包打包至源目录。将该目录打包后上传至目标服务器并设置为源即可。 需要注意的是，如果选择在安装 MySQLMariaDB 时使用“Generic Binaries”（二进制包），必须提前下载好指定的二进制包并上传至 LNMP 安装包的 src 目录。 卸载 LNMP 一键安装包要卸载 LNMP 一键安装包，请在 LNMP 安装包目录下执行以下命令： ./uninstall.sh 按提示选择当前环境类型并回车确认，该操作会删除 LNMP 的相关程序组件，同时保留网站文件和备份数据库目录至 /root 目录下。如果还有其他需要保存的文件，请确保在卸载前进行备份。 独立安装安装 Nginx使用以下命令在你的系统上安装 Nginx： sudo apt install nginx 此命令通过 APT 包管理器从默认软件源中下载并安装 Nginx。安装完成后，你可以通过访问 http://localhost 来检查 Nginx 是否正常运行，默认情况下，Nginx 会在地址栏输入“localhost”时显示欢迎页面。 编辑 Nginx 配置首先，进入 Nginx 的配置目录： cd /etc/nginx/sites-enabled 删除默认配置文件，以防止它干扰你自己的设置： sudo rm -f default 接下来，新建一个名为 test 的配置文件，使用以下命令： sudo vim test 在打开的编辑器中，输入以下内容，以配置 Nginx 服务： server listen 80; root /var/www/html; server_name localhost; location / index index.php index.html index.htm; error_page 500 502 503 504 /50x.html; location = /50x.html root /var/www/html; location ~ \\.php$ fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; 在此配置中，重要的部分是： listen 80; 表示 Nginx 将监听 HTTP 请求。 root /var/www/html; 指定网站文件的根目录。 location ~ \\.php$ 部分启用对 PHP 文件的处理。 完成输入后，按 Esc 退出插入模式，输入 :wq 保存并退出。 启动、设置开机启动 Nginx执行以下命令来启动 Nginx 服务： sudo systemctl start nginx 接着设置 Nginx 在系统启动时自动运行： sudo systemctl enable nginx 检查 Nginx 服务状态在本地浏览器中访问以下地址，确认 Nginx 服务正在正常运行： http://你的云服务器实例的公网 IP 如果看到 Nginx 欢迎页面，就证明你的配置成功了！ MySQL 数据库要配置 MySQL，首先需要通过命令行进入 MySQL 的命令行界面。请按以下步骤进行设置。使用下面的命令安装 MariaDB，它是 MySQL 的社区版本： sudo apt install mariadb-server mariadb-client 启动 MySQL在终端中运行以下命令以启动 MySQL： sudo mysql 设置 root 用户密码进入 MySQL 后，您需要为 root 用户设置一个安全密码。可以使用以下命令： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY mynewpassword; 在这个示例中，我们将密码设置为 Mysql@1234，因此您可以运行： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY Mysql@1234; 退出 MySQL在设置密码后，输入以下命令以退出 MySQL： exit; 安全配置 MySQL为了提升 MySQL 的安全性，接下来我们要运行安全配置命令。使用： sudo mysql_secure_installation 根据提示依次完成以下配置项： 输入 root 用户的密码： 这里要输入刚刚设置的密码，例如 Mysql@1234。 Securing the MySQL server deployment.Enter password for user root: 说明：在输入密码时，系统不会显示字符以确保安全。只需输入密码并按 Enter。 更改 root 用户密码： 系统会询问是否希望更改 root 用户的密码，您可以输入 Y。 Change the password for root? (Press y|Y for Yes, any other key for No) : Y 然后再次输入新密码，并确认输入。 删除匿名用户： 输入 Y 来删除 MySQL 自带的匿名用户。默认情况下，MySQL 安装时会创建匿名用户，这会让任何人都能登录 MySQL，不需要创建用户账号，仅限于测试使用。 Remove anonymous users? (Press y|Y for Yes, any other key for No) : Y 禁止 root 用户远程登录： 输入 Y，以确保 root 只可以通过 localhost 进行连接，避免从网络上被猜测密码。 Disallow root login remotely? (Press y|Y for Yes, any other key for No) : Y 移除 test 数据库： 通过输入 Y，我们会移除 MySQL 默认的 test 数据库，避免其他用户随意访问。 Remove test database and access to it? (Press y|Y for Yes, any other key for No) : Y 重新加载授权表： 输入 Y 用以重载权限表，确保所有更改立即生效。 Reload privilege tables now? (Press y|Y for Yes, any other key for No) : Y 当命令行回显 All done! 时，表示安全配置已完成。 测试登录到 MySQL 数据库使用以下命令测试是否能够成功登录 MySQL 数据库： sudo mysql -uroot -p 此时命令行会提示您输入密码： Enter password: 同样，输入密码时命令行不会显示字符。输入正确的密码后，您将看到类似以下的信息，这表明您已成功登录： Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 15Server version: 8.0.29-0ubuntu0.20.04.3 (Ubuntu)Copyright (c) 2000, 2022, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type help; or \\h for help. Type \\c to clear the current input statement.mysql 安装 PHP安装 PHP使用以下命令安装 PHP 及其常用模块： sudo apt install php7.4-cli php7.4-common php7.4-mysqlnd php7.4-fpm 启动 PHP-FPM 服务检查安装的版本是否为 7.4。如果确认是 7.4，接着启动 PHP-FPM 服务： systemctl start php7.4-fpm 然后将 PHP-FPM 服务设置为开机自启动： systemctl enable php7.4-fpm 修改 Nginx 配置以支持 PHP再次打开 Nginx 配置文件： sudo vim /etc/nginx/sites-enabled/test 按下 i 进入编辑模式，找到 fastcgi_pass 行，将其修改为： fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; 完成后，按 Esc，输入 :wq 保存并退出。 验证环境配置若 /var/www/html 文件夹下有其他文件，先用以下命令删除它们： sudo rm -rf /var/www/html/* 接着，创建一个测试文件： sudo vim /var/www/html/index.php 在编辑模式下输入： ?php phpinfo(); ? 保存并退出后，重启 Nginx 服务： sudo systemctl restart nginx 最后，在本地浏览器中访问以下地址，查看 PHP 环境配置是否成功： http://你的云服务器实例的公网 IP 如果页面显示 PHP 信息，说明环境配置成功！","categories":["0.平台","服务器","博客"]},{"title":"16-8禁食软件架构设计","path":"/2024/05/22/3-软件-0杂项-16-8禁食软件架构设计/","content":"介绍这个应用程序旨在帮助用户记录每日的禁食时间，以确保实现稳定、健康的十六小时禁食计划。 奖励机制为了鼓励用户坚持禁食，应用可以提供多种奖励机制。例如，当用户连续一周达成目标时，可以解锁特定的健康食谱，或是获得积分，这些积分能够兑换成商品或服务。此外，用户还可以分享自己的成就，获得社交平台的赞赏和反馈，增强保持禁食习惯的动力。 功能记录 开始计时：用户只需点击一个按钮便可启动计时器，记录禁食的起始时间。 结束计时：再次点击同一按钮可停止计时器，这使得用户能够轻松地监控禁食的持续时间。 在使用过程中，如果应用意外退出，系统会妥善记录这一中途退出情况，确保用户在下次启动时能够顺利续写禁食时间。 当程序启动时，它会自动读取上次的计时状态和禁食日志。这意味着如果用户没有结束禁食状态，应用会根据中间经过的时间继续计时，从而维持一贯的禁食周期。 若用户想要重新开始禁食，应用会首先检查日志中是否已经记录了当天的禁食时间。如果当天有记录且不想覆盖，计时将不会启动。反之，如果用户选择覆盖，之前的禁食时间将被清除，系统将重新启动定时器。 例如，当用户在 “2023-07-26 10:10:10” 点击开始计时后，应用将开始记录当前的禁食状态。 在用户想要结束计时时，系统会停止计时器，并将当前的时间、禁食时间及状态进行记录，比如： 记录格式为 “2023-07-26 10:10:30 0”，表示结束计时并显示当前时间和状态。 最终，应用将保存当前日期及禁食时间，如 “2023-07-26 0 0 20”，这代表禁食持续了 20 分钟。 查询用户可以随时查询到每日的禁食时间。系统会保存每日的禁食数据，并在发现重复记录时提供弹窗提示，帮助用户选择最有效的数据进行查看。 查询时，用户可以根据点击的日期查看对应的禁食时长，这样能够让用户清晰了解自己的坚持情况。 此外，应用会形象化地显示出用户的禁食进度。禁食达到目标时，表格中的状态将以绿色标识；未达到时，则以红色标识，以便于用户快速识别自己的表现。 目标用户可以轻松设定每日的禁食目标，并实时查看目标达成情况。表格将清楚地展示每日设定的目标与目前的达成状态，帮助用户防止懈怠并鼓励持续进步。 设置用户能够根据个人健康需求设置每日的禁食时长。同时，应用支持手动设立目标，允许用户根据自身情况灵活调整禁食计划，增强个性化体验。","categories":["3.软件","0杂项"]},{"title":"TV BOX","path":"/2024/05/22/3-软件-音视频-TV-BOX/","content":"应用端TVBOXo0HalfLife0o 开源的 APK 可通过以下链接访问：TVBox APK。使用此应用程序前，首先需要配置其地址。前往应用的设置界面，找到“配置地址”选项，添加适合的视频源，确保您能够顺利观看所需的内容。 ZY-PlayerZY-Player 是 another popular 应用程序，可以在 GitHub 上找到其源代码和安装包：ZY-Player。 视频源某些视频源因地址限制，可能无法直接访问。为了加速获取这些源，您可以参考以下链接，帮助快速连接到视频内容。例如，您可以使用 jsDelivr 和 Statically 提供的加速地址： jsDelivr 加速地址： ZY-Player-PC.json Statically 加速地址： ZY-Player-PC.json 集合以下是一些维护良好的 TVBox 接口项目，您可以从中获取最新的视频源配置： YuanHsing 维护的 TVBOX 接口项目 另一个 TVBox 项目 备选项目 网站您可以通过以下网站获取视频源配置，确保您可以接入各类内容： 网站 地址 FongMi FongMi 配置 巧技 巧技 配置 俊于 俊于 配置 霜辉月明 霜辉月明 配置 小雅 小雅 配置 TVBox Cainisi 神器 神器每日推送 饭太硬 饭太硬 云星日记 云星日记 肥猫 肥猫 仓库以下是一些重要的开发者及其项目，您可以在这些仓库中找到各类 TV 应用程序和接口： 唐三大佬的仓库：唐三仓库 巧技大佬的仓库：巧技仓库 俊于大佬、唐三大佬和影魔大佬的联合仓库：官方仓库 TV 猫盒：这个项目非常实用：猫盒项目 pluto-player：非开源项目，具备大量功能且支持在线升级，但目前不支持低版本安卓：pluto-player takagen99 项目：takagen99 o0HalfLife0o 项目：o0HalfLife0o AlphaTV 项目：AlphaTV clanTV 项目：clanTV FongMi-TV 项目：FongMi-TV BearTV：许多人提到的熊爱项目：BearTV 官方仓库，已于 2022 年 7 月 18 日封仓：官方仓库链接 多线路 TV 版本仓库：多线路 TV 版本 四角大神的仓库，部分内容已经被删除，但可以根据需要查看：四角大神仓库","categories":["3.软件","音视频"]},{"title":"Docker","path":"/2024/05/22/0-平台-Docker-Docker/","content":"Docker 是一种流行的容器化平台，它可以帮助开发人员和运维人员更轻松地构建、交付和运行应用程序。 架构Docker 的架构包括以下组件： Docker 守护进程：运行在主机上的后台进程，负责管理 Docker 对象，如镜像、容器、网络和数据卷。 Docker 客户端：通过 Docker API 与 Docker 守护进程通信。 Docker 镜像：包含应用程序和其依赖项的只读文件系统。 Docker 容器：Docker 镜像的可运行实例。 Docker 仓库：用于存储 Docker 镜像的地方。 主要需要注意的是镜像IMAGE和容器CONTAINER 可以将镜像视为虚拟机的一个快照，镜像是容器的基础，定义了容器的基本配置和内容 容器，即为镜像的实例化内容，当启动一个容器时，Docker 会从镜像创建一个只读的文件系统层，并在其上添加一个可写层，容器中的所有更改和数据都存储在这个可写层上。 基本命令Docker 提供了一系列命令行工具，用于管理 Docker 容器和镜像，以及执行与容器相关的操作 以下是一些常用的 Docker 命令： docker images：列出本地所有的镜像。 docker rmi image：删除一个镜像。 docker pull image：从仓库中拉取一个镜像。 docker build -t image_name path_to_dockerfile：根据 Dockerfile 构建新的自定义镜像。 docker push image：将一个镜像推送到仓库中。 docker run image：根据指定的镜像创建并启动一个新的容器。 docker ps：列出当前正在运行的容器。加 -a 列出所有，包括运行中的和已经停止的 docker start container_id/container_name：启动已停止的容器。 docker stop container_id/container_name：停止运行中的容器。 docker restart container_id/container_name：重启容器。 docker rm container_id/container_name：删除指定容器。 docker logs container_id/container_name：查看容器的日志输出。 docker exec -it container_id/container_name command：在正在运行的容器中执行特定命令。 docker exec -it container /bin/bash 进入 container 容器中的命令行 docker inspect container_id/container_name：查看容器的详细信息，包括 IP 地址、端口映射等。 docker network ls：列出所有 Docker 网络。 docker volume ls：列出所有 Docker 卷。 DockerfileDockerfile 是一种文本文件，用于定义如何构建 Docker 镜像。包含了一系列的指令和参数，用于指导 Docker 引擎在基础镜像上添加应用程序代码、运行时环境、依赖项和配置文件等，最终生成一个新的 Docker 镜像。 以下是一个简单的 Dockerfile 示例： FROM ubuntu:latest RUN apt-get update apt-get install -y nginx CMD [nginx, -g, daemon off;] 该 Dockerfile 使用最新版本的 Ubuntu 镜像作为基础镜像，并在其中安装了 nginx。 一些 dockerfile 中的指令： FROM： 指定基础镜像。每个 Docker 镜像都是基于一个基础镜像构建的，这个指令用于设置构建的起点。 MAINTAINER： 设置镜像的作者信息，通常是作者的名字和电子邮件。 RUN： 在镜像构建过程中执行的命令。可以用于安装软件包、更新系统、设置环境等操作。 CMD： 设置容器启动时要执行的命令。如果在运行镜像时没有指定要执行的命令，则将执行这里设置的默认命令。 ENTRYPOINT： 设置容器启动时要执行的固定命令。与 CMD 类似，但可以将参数传递给 ENTRYPOINT 指定的命令。 COPY： 将本地文件复制到镜像中。 ADD： 类似于 COPY，但它还支持复制网络资源和自动解压缩压缩文件。 WORKDIR： 设置容器的工作目录，后续的指令将在这个目录下执行。 EXPOSE： 指定容器运行时监听的端口号，但并不会自动将端口映射到宿主机。 ENV： 设置环境变量，可以在容器内部访问。 ARG： 声明构建时的参数，构建时可以通过 –build-arg 参数传递。 VOLUME： 创建一个可以从宿主机或其他容器挂载的挂载点。 USER： 设置运行镜像的用户。ONBUILD： 定义一个触发器，在子镜像构建时执行特定的操作。 Docker ComposeDocker Compose 是一个工具，用于定义和运行多个 Docker 容器的应用程序。 docker-compose 需要编写 yml 脚本，定义配置以及多个容器之间的依赖关系和网络连接 * 注意：yml 文件对缩进有严格要求 通过命令控制 docker-compose以下是一个简单的 docker-compose.yml 文件示例： version: 3.9services: db: image: mysql:5.7 volumes: - ./db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - ./wordpress_data:/var/www/html ports: - 80:80 - 443:443 restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: wordpress_data: 这里用到了 mysql:5.7 和 wordpress:latest 两个 Docker 镜像，WordPress 镜像依赖 depends_on 于 MySQL 镜像。 restart: always 参数表明容器服务宕机后会自动重启。 MYSQL_ROOT_PASSWORD 为数据库的 root 密码，MYSQL_PASSWORD 为数据库的普通用户密码，请自行修改，对应的 WORDPRESS_DB_PASSWORD 也要同时修改。MYSQL_USER 为数据库普通用户的用户名，如果有需要也可以修改，对应的 WORDPRESS_DB_USER 也要同时修改。 80:80 的意思是把宿主机的 80 端口映射到容器内部的 80 端口。如需通过其他端口访问，只需修改前面的 80。比如，我要通过 8080 端口访问 WordPress，填写 8080:80 即可。 volumes 会将主机中指定的目录 ./wordpress_data 和容器中的指定目录 /var/www/html 共享，类似于虚拟机中的共享文件夹。并且在容器销毁后目录中的文件依旧存在。 在 Docker Compose 版本 3 及以上的配置中，不再使用 links 字段来定义容器之间的连接。取而代之的是使用 Docker 网络来实现容器之间的通信。现在，Docker Compose 默认创建一个项目级别的默认网络，其中每个服务（service）都可以使用它。 只需保证 db 和 wordpress 属于同一个项目（即在同一个 docker-compose.yml 文件中定义），它们将自动连接到默认网络，并可以通过服务名称（db 和 wordpress）相互访问。 脚本Docker Compose官方文档 命令 docker-compose up -d：根据当前目录的 yml 文件配置启动容器，-d 参数代表在后台运行 docker-compose ps：查看运行状态 docker-compose stop：停止运行 docker-compose restart：重启 docker-compose restart service-name：重启单个服务 docker-compose exec service-name sh：进入容器命令行 docker-compose logs [service-name]：查看容器运行 log，-f 指定文件名 安装及使用利用 docker 配置 wordpress 个人博客在安装 docker 时，发现 docker 有多个版本： docker.io：debianubuntu 官方基于 docker 社区源码封装的版本，将 docker 的依赖直接转接到主系统上 docker-ce：docker.com 放出来的社区版，使用 golang 将依赖封装在一个包中 docker-ee：docker.com 维护的商业版.一般使用docker.io 安装 docker.io： sudo apt install docker.io 安装 docker-compose： sudo apt install docker-compose 创建一个文件夹用于存储 volume 以及 yml 文件： mkdir wordpress cd wordpress 编辑 yml 文件（yml 文件内容参照 Docker介绍）： vi myBlog.yml 启动容器（初次启动时会下载镜像，速度较慢）： sudo docker-compose up -d 如果有错误，查看启动日志： sudo docker-compose logs 如果需要进入容器内命令行： sudo docker-compose exec -it 容器名称 /bin/bash 停止并删除容器 sudo docker-compose down 镜像和容器的构建、导出docker build、docker export、docker save 和 docker commit 是 Docker 的一些常用命令，它们在 Docker 镜像和容器的构建、导出和保存等方面有不同的作用。 docker build作用：使用 Dockerfile 定义构建规则，构建一个新的 Docker 镜像。 描述：docker build 命令是用于根据 Dockerfile 创建一个新的 Docker 镜像。 Dockerfile 中包含了构建镜像所需的指令，例如安装软件、配置环境等。 docker build 命令会根据 Dockerfile 的指令逐步构建镜像的不同层，最终生成一个可执行的镜像。 docker export作用：导出 Docker 容器的文件系统作为一个 tar 归档文件。 docker export 命令将 Docker 容器导出为一个 tar 文件，其中包含容器中的文件系统和元数据，但不包括镜像的元数据和层。这意味着，使用 docker export 命令导出的文件无法用作 Docker 镜像的源文件，只能用于将容器迁移到另一个 Docker 主机或将容器中的文件系统导出到本地。 例如，如果你想要将一个正在运行的 WordPress 容器迁移到另一个 Docker 主机，可以使用 docker export 命令将容器导出为一个 tar 文件，然后将该文件传输到目标主机并使用 docker import 命令导入为一个新的 Docker 镜像。 docker export container_id wordpress.tar docker save作用：将 Docker 镜像保存为 tar 归档文件。 docker save 命令将 Docker 镜像导出为一个 tar 文件，其中包含镜像的元数据和层，可以用作 Docker 镜像的源文件。这意味着，使用 docker save 命令导出的文件可以用于在不同的 Docker 主机之间共享镜像，或者将镜像备份到本地。 例如，如果你想要将一个名为 wordpress:latest 的 Docker 镜像备份到本地，可以使用 docker save 命令将镜像导出为一个 tar 文件。 docker save -o wordpress.tar wordpress:latest 总之，docker export 命令导出的文件只包含容器中的文件系统和元数据，而 docker save 命令导出的文件包含完整的镜像元数据和层，可以用于在不同的 Docker 主机之间共享镜像或备份到本地。 docker commit作用：将容器的变更保存为新的 Docker 镜像。 描述：docker commit 命令允许你将一个正在运行的容器的变更保存为一个新的 Docker 镜像。它会创建一个新的镜像层，将容器中的变更添加到这个层中，最终生成一个新的镜像。 例如：遇到了一个 docker 环境，需要带回来自己调试，打包正在运行的容器，快速拖环境跑路 docker ps //获取正在运行的容器,找到IDdocker commit -a test -m wordpress 容器名称或ID //将容器打包成镜像docker save -o ./wordpress.tar 容器名称或ID //拖到本地docker load -i hackgod-demo.tar //导入镜像 容器打包及导入导出可以使用 docker commit 命令来完成，docker commit 可以从容器创建一个新的镜像。 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]`## 参数说明-a : 提交的镜像作者；-c : 使用 Dockerfile 指令来创建镜像；-m : 提交时的说明文字；-p : 在 commit 时，将容器暂停 打包成镜像将容器 a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。 docker stop 2a2a11e2c043docker commit -a alway.com -m socks5 2a2a11e2c043 alway.com/wangwei/socks5:v1 导入docker load --input uu.tar(也可以使用docker load -i uu.tar或者 docker load uu.tar)docker load uu.tar 导出docker save /root/docker_images/uu.tar ubuntu:latestdocker save /root/docker_images/ubuntu:latest uu.tardocker save -o /root/docker_images/[镜像名].tar [镜像名]:latest 启动docker run -it -d --name container-name -pp1:p1-pp2:p2new-image-namedocker run -it -d --name qinglong -p 5700:5700 alway.com/wangwei/qinglong:v1 联系和区别 docker build 和 docker commit 都用于构建 Docker 镜像，但它们的方式不同。 docker build 是通过 Dockerfile 定义构建规则，逐步构建镜像，而 docker commit 是将容器的变更直接保存为新的镜像。 docker export 和 docker save 都用于导出 Docker 镜像或容器的文件系统，但它们导出的内容不同。 docker export 导出容器的文件系统作为归档文件，但不包含镜像的元数据和历史记录，不能用于还原容器。而 docker save 导出完整的 Docker 镜像，包含了元数据和文件系统，可以用于还原镜像。 docker build 和 docker save 都用于创建 Docker 镜像 docker export 用于导出容器的文件系统，而 docker commit 用于将容器的变更保存为新的镜像。","categories":["0.平台","Docker"]},{"title":"微信公众号后端配置","path":"/2024/05/22/0-平台-服务器-微信-微信公众号后端配置/","content":"后端服务代码from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonapp = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[http://124.222.246.202,http://127.0.0.1])#CORS(app)HOME_PATH = /home/ubuntu/lemonadeWebSite/html/#@app.route(/, methods=[GET])#def home_index():# index_html = open(/home/ubuntu/liuluhua.github.io/index.html, r)# print (文件名: , index_html.name)# print (是否已关闭 : , index_html.closed)# print (访问模式 : , index_html.mode)# return index_html.read()@app.route(/get_ip, methods=[GET])def ip_addr(): ip_addr = request.remote_addr api_url = fhttps://ipinfo.io/ip_addr/json response = requests.get(api_url) data = response.json() ret_data = 来自+data.get(country)+ +data.get(region)+的+data.get(ip)+朋友; return ret_data@app.route(/get_picture, methods=[GET])def picture_show(): pic_dir = 0.res/Picture/ name = request.args.get(id) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = for file_name in os.listdir(act_addr): fileNameList += fimg src=pic_dirname/file_name alt=file_name print(file_name) print (fileNameList) return (fileNameList)@app.route(/getFileContent, methods=[POST])def getFileContent(): filePath = request.get_json().get(filePos) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(/getFileList, methods=[POST])def getFileList(): return json.dumps(request.get_json()) + getDirList(HOME_PATH+Python);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(fdivdir:depth name:) ret_list.append(entry.name+/div) getDirList(entry.path, ret_list, depth+1) else: file_pos = dir_path.replace(/home/ubuntu/html,) ret_list.append(fpa onclick=openFile(\\file_pos/entry.name\\)file:depth name: + entry.name+/a/p) return .join(ret_list)@app.route(/signin, methods=[POST])def signin(): print(post signin) username = request.form.get(username) password = request.form.get(password) button_clicked = request.form.get(signin) # 或者使用 signup #jsonify(response: test) # 确定哪个按钮被点击了 if button_clicked == signin: # 处理登录操作 return fLogin: Username=username, Password=password elif button_clicked == signup: # 处理注册操作 return fSignup: Username=username, Password=password else: # 没有按钮被点击或者未知按钮名称 return Unknown button pressed@app.route(/wechat, methods=[GET])def wechat_signature(): data = request.args echostr = data.get(echostr) signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) if not signature or not timestamp or not nonce: return False tmp_str = .join(sorted([liuluhua, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(UTF-8)).hexdigest() if tmp_str == signature: return echostr else: print(Failed) return Failed@app.route(/wechat, methods=[POST])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是不是文本 if text == req.get(MsgType): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = ToUserName:req.get(FromUserName), FromUserName:req.get(ToUserName), CreateTime:int(time.time()), MsgType:text, Content:req.get(Content) # 把构造的字典转换成xml格式 xml = xmltodict.unparse(xml:resp) # print(req.get(Content)) # 返回数据 return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml:resp) return xmlif __name__ == __main__: app.run(host=127.0.0.1, port=9080) Nginx 配置# Default server configuration#server listen 80 default_server; listen [::]:80 default_server; # SSL configuration # # listen 443 ssl default_server; # listen [::]:443 ssl default_server; # # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 # # Read up on ssl_ciphers to ensure a secure configuration. # See: https://bugs.debian.org/765782 # # Self signed certs generated by the ssl-cert package # Dont use them in a production server! # # include snippets/snakeoil.conf; root ~/lemonadeWebSite/html; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; #server_name _; location / # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; #proxy_pass http://localhost:9999; # proxy_http_version 1.1; # proxy_set_header Upgrade $http_upgrade; # proxy_set_header Connection upgrade; # proxy_set_header Host $host; # proxy_cache_bypass $http_upgrade; location ~ ^/(wechat|get_*|signin) proxy_pass http://localhost:9999; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ # include snippets/fastcgi-php.conf; # # # With php7.0-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php7.0-fpm: # fastcgi_pass unix:/run/php/php7.0-fpm.sock; # # deny access to .htaccess files, if Apaches document root # concurs with nginxs one # #location ~ /\\.ht # deny all; ## Virtual Host configuration for example.com## You can move that to a different file under sites-available/ and symlink that# to sites-enabled/ to enable it.##server # listen 80;# listen [::]:80;## server_name example.com;## root /var/www/example.com;# index index.html;## location / # try_files $uri $uri/ =404;# #","categories":["0.平台","服务器","微信"]},{"title":"游戏架构","path":"/2024/05/22/3-软件-0杂项-游戏架构/","content":"solarRTS 的设计架构 目标类 地图类 生产类 子弹类 主程序 关卡得分基础属性 游戏窗口加载 地图绘制 坐标点初始化 友军加载 敌军加载 子弹加载 事件加载 开始游戏 结束游戏 玩法 长按屏幕弹出菜单，创建","categories":["3.软件","0杂项"]},{"title":"内网穿透方案","path":"/2024/05/22/3-软件-代理穿透-内网穿透方案/","content":"内网穿透，也称为 NAT 穿透或端口转发，是一种技术手段，用于在没有公网 IP 的情况下，使外网用户能够访问内网中的设备和服务。其基本原理是通过中转服务器或特定的网络配置，将内网设备的 IP 地址和端口映射到外网，从而实现内外网之间的通信。 具有公网 IP服务器端具有公网 IP获取公网 IP+DDNS 解析什么是 DDNSDDNS 的意思是动态域名解析。是解决有公网 IP ，但是公网 IP 不固定的问题，用固定的域名代替动态变化的公网 IP。 无公网 IP 网络环境用内网穿透方案，即类似如 nat123 内网映射方式，将内网 IP 映射成域名（自动生成二级域名或用自己域名）地址，然后通过域名来访问。 DDNS (Dynamic Domain Name System) 是一种可以动态更新域名解析的服务，它可以让您的域名指向一个动态 IP 地址，而不是一个固定的 IP 地址。它可以让您的域名跟随您的设备，而不需要您每次更改 IP 地址时都去更新域名解析。 适用情况： 路由器是公网 IP，但是公网 IP 不固定 检测方法： 用百度搜索 IP，百度会显示当前的 IP 地址，把这个 IP 地址和路由器的 IP 地址作比较，如果一致，说明是公网 IP，如果不一致，说明是运营商用一个 IP 然后经过多层 NAT 之后分配的内网 IP。 具有公网 IP 云服务器FRP将内网端口映射到公网服务器，通过公网服务器 + 端口的形式访问内网端口。需要了解配置 frps 和 frpc 的配置文件如何配置，针对特定端口进行开放 下载 frp 文件，根据实际要部署的环境的架构利用 wget 下载相应版本 项目地址 https://github.com/fatedier/frp 安卓版本仓库地址 https://github.com/FrpcCluster/frpc-Android 下载完成后 tar -xvf 解压，进入目录，修改 fps.toml 配置文件 文档地址 https://gofrp.org/zh-cn/docs/ frps 服务端配置安装前需 uname -a 查看云服务器的外网处理器架构,根据不同的架构下载不同 frp 版本，x86_64 的 下载 后缀带 amd 的即可 wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz 解压后编辑 frps.toml 文件 #bindAddr = 0.0.0.0bindPort = 9085 //内网设备绑定的端口# auth tokenauth.token = ****** //接入验证码，需要和设备端保持一致# Configure the web server to enable the dashboard for frps.# 使能dashboard(非必要)# 使能控制面板# 控制面板必须配置port# dashboard is available only if webServer.port is set.webServer.addr = 0.0.0.0webServer.port = 9086webServer.user = lemonadewebServer.password = lemonade# console or real logFile path like ./frps.log # 使能log(非必要)# 输入的日志文件log.to = ./frps.log //日志存储位置# trace, debug, info, warn, errorlog.level = info //存储等级log.maxDays = 3 //时间 netstat -ntlp 查看端口占用情况 启动 frps 服务 ./frps -c ./frps.toml， 需要注意服务器开通指定端口的防火墙 frpc 客户端配置 //具有公网IP的服务器地址serverAddr = 124.222.246.*** //接入端口serverPort = 9085//接入tokenauth.token=******[[proxies]]//将本设备的5000端口映射到服务器的9087端口name = frp-nas//类型type = tcp localIP = 0.0.0.0//本地端口localPort = 5000//公网端口remotePort = 9087[[proxies]]name = frp-nas-sshtype = tcplocalIP = 0.0.0.0localPort = 9090remotePort = 9088 微软的 devtunnel缺点是穿透的地址最长只能保持 30 天，执行安装命令： #Windowswinget install Microsoft.devtunnel#Linux curl -sL https://aka.ms/DevTunnelCliInstall | bash 登录自己的账户 devtunnel user login [-g] #-g代表github账户 假定需要将本机的 9006 端口做为对外穿透的端口，则命令为： devtunnel host -p 9006 [--allow-anonymous] [--expiration 2d] [--allow-anonymous] 允许任何人都可以访问 [--expiration 2d] 设置有效时间，过期自动删除，默认为 30 天，最大值为 30 天 如果你需要创建多个端口，则可以改为： devtunnel host -p 9006 9007 9008 由于一个 powershell 窗口同一时间默认只能运行一个 devtunnel 进程，所以如果你需要创建并监听多个内网映射端口，则需要像上面那样同时填写多个端口 查看当前系统中隧道端口列表： devtunnel list 查看某个隧道详细信息 假定隧道 id 为 “liuluhua”，列出 liuluhua 当前的一些配置或状态信息 devtunnel show liuluhua 托管某个隧道 假定我们在其他 powershell 窗口里创建了一个隧道 “liuluhua”，我们现在当前 powershell 中托管监控它 devtunnel host liuluhua 删除某个隧道： 假定要删除的某个 隧道 id 为 “liuluhua” devtunnel delete liuluhua 删除全部的隧道： devtunnel delete-all #devtunnel port create lemonade -p 5245#devtunnel host lemonadedevtunnel create [隧道名] -a#-a 表示可以表示隧道可以匿名访问#执行成功会输出隧道信息devtunnel port create [隧道名] -p 8080#隧道名为可选，默认为刚才创建的隧道#可以添加多个端口devtunnel host [隧道名]#隧道名为可选，默认为刚才创建的隧道#devtunnel delete [隧道名]#可以删除隧道 cloudflare控制台页面 https://dash.cloudflare.com 要有一个 Cloudflare 的账号，并且添加了所需要使用的域名，同时，开通 Cloudflare Zero Trust。 Tailscale免费版 构建虚拟局域网 —ZeroTier、Tailscale 以及蒲公英 在 zerotier 创建虚拟局域网，客户端安装后复制虚拟局域网 ID 加入即可实现访问，但是连接速度不稳定 进阶方式可以自己搭建 moon 服务器和 planet 服务器，但是也需要公网服务器 私有部署zerotier-planet服务 一分钟自建zerotier-planet 学习文档内网穿透 - Jonnyan的原创笔记 - 亖亖亖 (mrdoc.fun) cpolar 内网穿透cpolar 官网地址: https://www.cpolar.com 使用一键脚本安装命令 curl -L https://www.cpolar.com/static/downloads/install-release-cpolar.sh | sudo bash 向系统添加服务 sudo systemctl enable cpolar 启动 cpolar 服务 sudo systemctl start cpolar cpolar 安装成功后，在外部浏览器上访问 Linux 的 9200 端口即:【http:服务器的局域网 ip:9200】，使用 cpolar 账号登录,登录后即可看到 cpolar web 配置界面,结下来在 web 管理界面配置即可。 登录后，点击左侧仪表盘的隧道管理——创建隧道，创建一个的公网 http 地址隧道 隧道名称：可自定义命名，注意不要与已有的隧道名称重复 协议：选择 http 本地地址：8380(本地访问的地址) 域名类型：免费选择随机域名 地区：选择 China Top 隧道创建成功后，点击左侧的状态——在线隧道列表,查看所生成的公网访问地址，有两种访问方式,一种是 http 和 https。使用上面的 Cpolar https 公网地址,在任意设备的浏览器进行访问,即可成功看到界面,这样一个公网地址且可以远程访问就创建好了,使用了 cpolar 的公网域名,无需自己购买云服务器,即可到公网进行远程访问了！ 如果我们需要长期异地远程访问，由于刚才创建的是随机的地址，24 小时会发生变化。另外它的网址是由随机字符生成，不容易记忆。如果想把域名变成固定的二级子域名，并且不想每次都重新创建隧道来访问，我们可以选择创建一个固定的 http 地址来解决这个问题。 固定公网地址我们接下来为其配置固定的 HTTP 端口地址，该地址不会变化，方便分享给别人长期查看你的博客，而无需每天重复修改服务器地址。配置固定 http 端口地址需要将 cpolar 升级到专业版套餐或以上。 登录 cpolar 官网，点击左侧的预留，选择保留二级子域名，设置一个二级子域名名称，点击保留,保留成功后复制保留的二级子域名名称。保留成功后复制保留成功的二级子域名的名称。返回登录 Cpolar web UI 管理界面，点击左侧仪表盘的隧道管理——隧道列表，找到所要配置的隧道，点击右侧的编辑。修改隧道信息，将保留成功的二级子域名配置到隧道中 域名类型：选择二级子域名 Sub Domain：填写保留成功的二级子域名 点击更新(注意,点击一次更新即可,不需要重复提交) 更新完成后,打开在线隧道列表,此时可以看到公网地址已经发生变化,地址名称也变成了固定的二级子域名名称的域名 最后,我们使用固定的公网 https 地址访问,可以看到访问成功,这样一个固定且永久不变的公网地址就设置好了，可以随时随地进行异地访问！ freedns42","categories":["3.软件","代理穿透"]},{"title":"RSS","path":"/2024/05/22/1-语言-工具语言-RSS/","content":"Rsshub 的 docker 部署 下载 docker-compose.yml wget https://raw.githubusercontent.com/DIYgod/RSSHub/master/docker-compose.yml 检查是否有需要修改的配置 vi docker-compose.yml # or your favorite editor 创建 redis 卷 Create a docker volume to persist Redis caches docker volume create redis-data 启动 docker-compose up -d Channelchannel 参考手册 元素 描述category 可选的。为 feed 定义所属的一个或多个种类。cloud 可选的。注册进程，以获得 feed 更新的立即通知。copyright 可选。告知版权资料。description 必需的。描述频道。docs 可选的。规定指向当前 RSS 文件所用格式说明的 URL。generator 可选的。规定用于生成 feed 的程序。image 可选的。在聚合器呈现某个 feed 时，显示一个图像。language 可选的。规定编写 feed 所用的语言。lastBuildDate 可选的。定义 feed 内容的最后修改日期。link 必需的。定义指向频道的超链接。managingEditor 可选的。定义 feed 内容编辑的电子邮件地址。pubDate 可选的。为 feed 的内容定义最后发布日期。rating 可选的。feed 的 PICS 级别。skipDays 可选的。规定忽略 feed 更新的天。skipHours 可选的。规定忽略 feed 更新的小时。textInput 可选的。规定应当与 feed 一同显示的文本输入域。 Itemitem 参考手册 元素 描述author 可选的。规定项目作者的电子邮件地址。category 可选的。定义项目所属的一个或多个类别。comments 可选的。允许项目连接到有关此项目的注释（文件）。description 必需的。描述此项目。enclosure 可选的。允许将一个媒体文件导入一个项中。guid 可选的。为项目定义一个唯一的标识符。link 必需的。定义指向此项目的超链接。pubDate 可选的。定义此项目的最后发布日期。source 可选的。为此项目指定一个第三方来源。 验证可以在 http://www.feedvalidator.org 找到很好的验证器。 RSS 阅读器功能文字 字体 字号 背景 翻页 图片 缩放 移动 下载 视频 播放暂停 快进 进度条 音量 下载 设置 订阅 自动手动同步 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["1.语言","工具语言"]},{"title":"设置flask后端CORS跨域访问","path":"/2024/05/22/1-语言-Python-设置flask后端CORS跨域访问/","content":"设置前后端分离 环境搭建flask 项目地址 https://tutorial.helloflask.com/ 安装 flask 和 flask-cors cors 用于允许服务器进行跨域访问 pip install flaskpip install flask-cors 浏览器 js 前端代码function SendUrlToServer(url, method)\tlet requestUrl = http://124.222.246.202:8081/fetch-sub-url?url=+url;\t/*let requestUrl = ?url=http://127.0.0.1:8081/fetch-sub-url*/\tfetch(requestUrl, method: method,\theaders: Content-Type: application/json\t,\t/*body: JSON.stringify( url: url )*/\t).then(response = response.text()).then(data = console.log(Response from server:);).catch(error = console.error(Error sending data:, error););function RSS() SendUrlToServer(https://rsshub.app/bilibili/ranking/0/3/1, GET); 服务器端 python 代码from flask import Flask, request, jsonifyfrom flask_cors import CORSimport requestsimport feedparser##get python pathimport ospython_path = os.environ.get(PYTHONPATH)print(PYTHONPATH:, python_path)##get endapp = Flask(__name__)#CORS(app, resources=r/*: origins: http://127.0.0.1:80) # 允许指定的来源访问CORS(app)@app.route(/fetch-sub-url, methods=[GET,POST])def fetch_sub_url(): #data = request.get_json() #url = data.get(url) #url = https://www.baidu.com url = request.args.get(url) print (current url is ===+url) try: response = requests.get(url) response_text = response.text return response_text except requests.exceptions.RequestException as e: return jsonify(error: str(e)) # 解析RSS feed #feed = feedparser.parse(url) # 打印feed的标题 #print(Feed Title:, feed.feed.title) # 打印feed中的条目 #for entry in feed.entries: # print( Title:, entry.title) # print(Link:, entry.link) # print(description:, entry.description) #return feedif __name__ == __main__: app.run(host=0.0.0.0, port=8081) 后端服务开机自启 systemdetcsystemdsystem 启动 [Unit]Description=Start Python BackEnd With HtmlAfter=multi-user.target[Service]WorkingDirectory=/home/ubuntuType=idle#ExecStart=/home/ubuntu/html/BackEnd/start_backend.shExecStart=/usr/bin/python3 /home/ubuntu/html/BackEnd/main.pyUser=ubuntuGroup=ubuntuEnvironment=PYTHONPATH=/home/ubuntu/.local/lib/python3.10/site-packages[Install]WantedBy=multi-user.target 将服务单元文件复制到 systemd 目录： 将您的服务单元文件复制到etcsystemdsystem目录下。您可以使用 sudo 命令进行拷贝，确保文件的权限设置正确。 sudo cp your-service-name.service /etc/systemd/system/ 重新加载 systemd 配置： 您需要重新加载 systemd 配置以使更改生效。 sudo systemctl daemon-reload 启用服务： 要启用服务，使其在系统启动时自动启动，可以运行以下命令： sudo systemctl enable your-service-name.service 这将会在适当的运行级别下创建符号链接，以便服务在系统启动时自动启动。 启动服务： 如果您想立即启动服务，可以运行以下命令启动服务 sudo systemctl start your-service-name.service 完整后端处理代码： from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonimport socketimport asynciofrom aiohttp import web# root_dir = /home/ubuntu/html/# pic_dir = 0.res/Picture/# name = 1#request.args.get(id)# act_addr = os.path.join(root_dir,pic_dir,name);# fileNameList = # for file_name in os.listdir(act_addr):# fileNameList += pic_dir+name+/+file_name# print(fileNameList)app = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[http://124.222.246.202,http://127.0.0.1])HOME_PATH = /home/ubuntu/BlogData/#@app.route(/, methods=[GET])#def home_index():# index_html = open(/home/ubuntu/liuluhua.github.io/index.html, r)# print (文件名: , index_html.name)# print (是否已关闭 : , index_html.closed)# print (访问模式 : , index_html.mode)# return index_html.read()@app.route(/get_ip, methods=[GET])def ip_addr(): ip_addr = request.remote_addr api_url = fhttps://ipinfo.io/ip_addr/json response = requests.get(api_url) data = response.json() ret_data = 来自+data.get(country)+ +data.get(region)+的+data.get(ip)+朋友; return ret_data@app.route(/get_picture, methods=[GET])def picture_show(): pic_dir = 0.res/Picture/ name = request.args.get(id) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = for file_name in os.listdir(act_addr): fileNameList += fimg src=pic_dirname/file_name alt=file_name print(file_name) print (fileNameList) return (fileNameList)@app.route(/getFileContent, methods=[POST])def getFileContent(): filePath = request.get_json().get(filePos) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(/getFileList, methods=[POST])def getFileList(): #return json.dumps(request.get_json()) + getDirList(HOME_PATH+Python); return getDirList(HOME_PATH+Python);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(detailssummaryspan class=tree-item) ret_list.append(entry.name+/span/summary) getDirList(entry.path, ret_list, depth+1) ret_list.append(/details) else: file_pos = dir_path.replace(/home/ubuntu/html,) ret_list.append(fdetailssummary \\ span class=tree-item onclick=openFile(\\file_pos/entry.name\\) + entry.name+/summary/details) return .join(ret_list)@app.route(/signin, methods=[POST])def signin(): print(post signin) username = request.form.get(username) password = request.form.get(password) button_clicked = request.form.get(signin) # 或者使用 signup #jsonify(response: test) # 确定哪个按钮被点击了 if button_clicked == signin: # 处理登录操作 return fLogin: Username=username, Password=password elif button_clicked == signup: # 处理注册操作 return fSignup: Username=username, Password=password else: # 没有按钮被点击或者未知按钮名称 return Unknown button pressed@app.route(/wechat, methods=[GET])def wechat_signature(): data = request.args echostr = data.get(echostr) signature = data.get(signature) timestamp = data.get(timestamp) nonce = data.get(nonce) if not signature or not timestamp or not nonce: return False tmp_str = .join(sorted([******, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(UTF-8)).hexdigest() if tmp_str == signature: return echostr else: print(Failed) return Failed@app.route(/wechat, methods=[POST])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[xml] # 判断post过来的数据中数据类型是不是文本 if text == req.get(MsgType): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = ToUserName:req.get(FromUserName), FromUserName:req.get(ToUserName), CreateTime:int(time.time()), MsgType:text, Content:req.get(Content) # 把构造的字典转换成xml格式 xml = xmltodict.unparse(xml:resp) # print(req.get(Content)) # 返回数据 return xml else: resp = ToUserName: req.get(FromUserName, ), FromUserName: req.get(ToUserName, ), CreateTime: int(time.time()), MsgType: text, Content: I LOVE ITCAST xml = xmltodict.unparse(xml:resp) return xmlif __name__ == __main__: app.run(host=127.0.0.1, port=9080)","categories":["1.语言","Python"]},{"title":"Obsidian笔记建设","path":"/2024/05/22/0-平台-服务器-Obsidian笔记建设/","content":"Obsidian 配置Ctrl+Shift+I 在控制台里可以查看详细日志，所有插件的日志都可以在这里看到 Hexo 忽略文件和文件夹由于 hexo 的文章只存在于 source 目录下，我们需要让 Obsidian 忽略其他文件的内容以优化性能以及减少不必要的搜索结果。具体的操作是在 设置-文件与链接-Exclude Files，将需要忽略的文件添加进去（尤其是 node_modules）。 Templater模板配置说明文档 https://silentvoid13.github.io/Templater/introduction.html 首先我们要创建模板，我们可以在 source 目录下创建 _obsidian 文件夹，并创建一篇 Post Template 的文章（md 文件），我们再创建新文章的时候，只需要点击侧边栏的『插入模板』按钮就可以快速生成 Front-matter 信息： ---title: % tp.file.title %date: % tp.file.creation_date(format=YYYY-MM-DD HH:mm:ss) %update: % tp.file.last_modified_date(YYYY-MM-DD HH:mm:ss) %comments: truetags:categories:dg-publish: true---定义脚本function generateTimestampUrl() var timestamp = Math.round(new Date() / 1000); var url = timestamp.toString(36) return url; module.exports = generateTimestampUrl; osidian-git快捷键 Ctrl + P 打开命令面板，输入 open source control view 启用可视化操作面板 obsidian-pangu已用 Linter 替代 中英文之间加空格 Hidden Folder目录隐藏插件 FileTree左侧菜单出现了一个 File Tree 的 Tab 页，点击后就可以看到文件以树形的结构呈现，我们展开 source 文件夹，并右键 _post 文件夹，选择 Focuse on Folder 后，左侧的文件列表中就只会显示 _post 文件夹中的内容了 Github Publisher已使用整个仓库进行同步发布，不采用这种单页面发布形式 将 Obsidian 中的文章和本地附件上传到 Github 仓库，上传前可以指定文件目录、自定义内容替换等操作。 能将 Obsidian 仓库里的任意笔记自动或者手动同步到 GitHub 代码仓库的任意位置。首先设置好 Github 相关信息，包括 Github repository，用户名，token 以及 Branch。当然也可以在单个笔记文件里，通过文档属性（frontmatter），单独设置接收笔记上传的 Github 仓库信息（可以选择同一用户下的不同仓库，同一仓库下的不同位置）。 上传设置 设定上传的笔记存储在 Github 仓库的位置。因为我的 hexo 博客日志文件保存在 sourceposts 目录下，故选择 Fixed Folder，设定好默认上传到的目录。 文章发布 在文章文档属性添加一个 share 属性（可以根据需要在插件设置里改成其他任意名称），赋予值 true。文章写好后，share: true 右键发布。 ShellCommand可以解决 obsidian 无法打开 . 开头的默认文件的问题 再介绍个终极优化方案，之前我们执行命令是通过运行 bat 文件，而 Shell commands 可以在 Obsidian 中设置好命令，并通过 Obsidian 的命令面板或快捷键快速运行。 在插件设置面板中添加命令 运行博客： Shell commands 没有显示终端窗口的功能，所以需要我们启动 powershell 再传入命令 有了终端窗口我们才可以在窗口中按 Ctrl + C 关闭 Hexo 服务，否则它会一直占用端口 start powershell -NoExit -Command start http://localhost:4000 ; cd Blog ; hexo s 打开站点和主题配置文件： start Blog/_config.ymlstart Blog/themes/butterfly4.3.1/_config.yml 然后修改默认执行环境为 PowerShell 5，可以为每个命令设置下别名，就是在命令面板显示的名字 Emo 插件用 PicGo 支持更多自定义设置 用于自托管图片 image auto upload plugin也是用于自托管图片 Linter 插件用户在保存笔记时按照一定的格式，格式化笔记，这里用到的功能： 保存笔记时自动插入 front-matter 进入 Linter 的设置，选择 YAML 设置，找到其中的插入 YAML 设置（ Insert YAML attributes），打开开关后，输入要插入的 front-matter 自动更新文件修改时间戳 进入 Linter 的设置，选择 YAML 设置，找到其中的 YAML 时间戳（ yaml-timestamp），设置为 Hexo 识别的 date 和 update 格式化笔记 主要的是一个不同语言中间的空格自动添加，进入 Linter 的设置，选择空格，找到其中的 Space between Chinese Japanese or Korean and English or numbers，打开即可 其他插件 Image Converter 转化图片格式，我统一转为 webp，并设置了图片分辨率大小。 Unique attachments 用于将附件的文件名统一为 “字母 + 数字”的格式,记着在配置里加入 webp 图片格式 Image Inserter 用于找图片，我用于设置文章封面，即设置 cover.image 属性。 目前在用的插件","categories":["0.平台","服务器"]},{"title":"ELF文件分析","path":"/2024/05/22/0-平台-Linux-程序-ELF文件分析/","content":"ELF 全称 “Executable and Linkable Format”，即可执行可链接文件格式，目前常见的 Linux、 Android 可执行文件、共享库（.so）、目标文件（ .o）以及 Core 文件（吐核）均为此格式。 文件布局常见的 ELF 文件大致结构如下： 常见的 ELF 格式如上图所示，左边为链接视图，右边为执行视图。从大局上看，ELF 文件主要分为 3 个部分: ELF Header Section Header Table Program Header Table 其中，ELF Header 是文件头，包含了固定长度的文件信息；Section Header Table 则包含了链接时所需要用到的信息；Program Header Table 中包含了运行时加载程序所需要的信息。 链接视图静态链接器（即编译后参与生成最终 ELF 过程的链接器，如 ld ）会以链接视图解析 ELF。编译时生成的 .o（目标文件）以及链接后的 .so （共享库）均可通过链接视图解析，链接视图可以没有段表（如目标文件不会有段表）。 执行视图动态链接器（即加载器，如 x86 架构 linux 下的 libld-linux.so.2 或者安卓系统下的 systemlinker 均为动态链接器）会以执行视图解析 ELF 并动态链接，执行视图可以没有节表。 文件头 ELF HeaderELF 的结构声明位于系统头文件 elf.h 中，ELF 格式分为 32 位与 64 位两种，除了重定位类型稍有区别，其它大致相同，为了简化描述，后续说明将省略 3264 字样。 ELF Header 的声明如下 : #define EI_NIDENT (16)typedef struct unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version */ Elf_Addr e_entry; /* Entry point virtual address */ Elf_Off e_phoff; /* Program header table file offset */ Elf_Off e_shoff; /* Section header table file offset */ Elf_Word e_flags; /* Processor-specific flags */ Elf_Half e_ehsize; /* ELF header size in bytes */ Elf_Half e_phentsize; /* Program header table entry size */ Elf_Half e_phnum; /* Program header table entry count */ Elf_Half e_shentsize; /* Section header table entry size */ Elf_Half e_shnum; /* Section header table entry count */ Elf_Half e_shstrndx; /* Section header string table index */ Elf_Ehdr; 注释都很清楚了，挑一些比较重要的来说。其中 e_type 表示 ELF 文件的类型，有以下几种: ET_NONE: 未知类型 ET_REL: 可重定向类型(relocatable)，通常是我们编译的 *.o 文件 ET_EXEC: 可执行类型(executable)，静态编译的可执行文件 ET_DYN: 共享对象(shared object)，动态编译的可执行文件或者动态库 *.so ET_CORE: coredump 文件 e_entry 是程序的入口虚拟地址，注意不是 main 函数的地址，而是.text 段的首地址 _start。当然这也要求程序本身非 PIE(-no-pie)编译的且 ASLR 关闭的情况下，对于非 ET_EXEC 类型通常并不是实际的虚拟地址值。 其他的字段大多数是指定 Section Header(e_sh)和 Program Header(e_ph)的信息。SectionProgram Header Table 本身可以看做是数组结构，ELF 头中的信息指定对应 Table 数组的位置、长度、元素大小信息。最后一个 e_shstrndx 表示的是 section table 中的第 e_shstrndx 项元素，保存了所有 section table 名称的字符串信息。 e_ident包含了Maigc Number和其它信息，共16字节。0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。 e_typeELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。 e_machine处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 e_verison: 文件版本，目前常见的 ELF 文件版本均为 EV_CURRENT（1）。 e_entry: 入口虚拟地址。 e_phoff: 段表文件偏移。 e_shoff: 节表文件偏移。 e_flags: 处理器特定的标志，一般为 0。 e_ehsize: Elf_Header 的大小（字节） e_phentsize: 段头（Program Header）的大小（字节）。 e_phnum: 段的数量。 e_shentsize: 节头（Section Header）的大小（字节）。 e_shnum: 字的数量。 e_shstrndx: 节字符串表的节索引。 Section Headersection header table 是一个数组结构，这个数组的位置在 e_shoff 处，共有 e_shnum 个元素(即 section)，每个元素的大小为 e_shentsize 字节。每个元素的结构如下: typedef struct Elf32_Word\tsh_name; /* Section name (string tbl index) */ Elf32_Word\tsh_type; /* Section type */ Elf32_Word\tsh_flags; /* Section flags */ Elf32_Addr\tsh_addr; /* Section virtual addr at execution */ Elf32_Off\tsh_offset; /* Section file offset */ Elf32_Word\tsh_size; /* Section size in bytes */ Elf32_Word\tsh_link; /* Link to another section */ Elf32_Word\tsh_info; /* Additional section information */ Elf32_Word\tsh_addralign; /* Section alignment */ Elf32_Word\tsh_entsize; /* Entry size if section holds table */ Elf32_Shdr; 其中 sh_name 是该 section 的名称，用一个 word 表示其在字符表中的偏移，字符串表(.shstrtab)就是上面说到的第 e_shstrndx 个元素。ELF 文件中经常使用这种偏移表示方式，可以方便组织不同区段之间的引用。 sh_type 表示本 section 的类型，SPEC 中定义了几十个类型，列举其中一些如下: SHT_NULL: 表示该 section 无效，通常第 0 个 section 为该类型 SHT_PROGBITS: 表示该 section 包含由程序决定的内容，如.text、.data、.plt、.go SHT_SYMTABSHT_DYNSYM: 表示该 section 中包含符号表，如.symtab、.dynsym SHT_DYNAMIC: 表示该 section 中包含动态链接阶段所需要的信息 SHT_STRTAB: 表示该 section 中包含字符串信息，如.strtab、.shstrtab SHT_RELSHT_RELA: 包含重定向项信息 虽然每个 section header 的大小一样(e_shentsize 字节)，但不同类型的 section 有不同的内容，内容部分由这几个字段表示: sh_offset: 内容起始地址相对于文件开头的偏移 sh_size: 内容的大小 sh_entsize: 有的内容是也是一个数组，这个字段就表示数组的元素大小 与运行时信息相关的字段为: sh_addr: 如果该 section 需要在运行时加载到虚拟内存中，该字段就是对应 section 内容(第一个字节)的虚拟地址 sh_addralign: 内容地址的对齐，如果有的话需要满足 sh_addr % sh_addralign 0 sh_flags: 表示所映射内容的权限，可根据 SHF_WRITEALLOCEXECINSTR 进行组合 另外两个字段 sh_link 和 sh_info 的含义根据 section 类型的不同而不同，如下表所示: 至于不同类型的 section，有的是保存符号表，有的是保存字符串，这也是 ELF 表现出拓展性和复杂性的地方，因此需要在遇到具体问题的时候查看文档去进行具体分析。 Program Headerprogram header table 用来保存程序加载到内存中所需要的信息，使用段(segment)来表示。与 section header table 类似，同样是数组结构。数组的位置在偏移 e_phoff 处，每个元素(segment header)的大小为 e_phentsize，共有 e_phnum 个元素。单个 segment header 的结构如下: typedef struct Elf32_Word\tp_type; /* Segment type */ Elf32_Off\tp_offset; /* Segment file offset */ Elf32_Addr\tp_vaddr; /* Segment virtual address */ Elf32_Addr\tp_paddr; /* Segment physical address */ Elf32_Word\tp_filesz; /* Segment size in file */ Elf32_Word\tp_memsz; /* Segment size in memory */ Elf32_Word\tp_flags; /* Segment flags */ Elf32_Word\tp_align; /* Segment alignment */ Elf32_Phdr; 既然 program header 的作用是提供用于初始化程序进程的段信息，那么下面这些字段就是很直观的: p_offset: 该 segment 的数据在文件中的偏移地址(相对文件头) p_vaddr: segment 数据应该加载到进程的虚拟地址 p_paddr: segment 数据应该加载到进程的物理地址(如果对应系统使用的是物理地址) p_filesz: 该 segment 数据在文件中的大小 p_memsz: 该 segment 数据在进程内存中的大小。注意需要满足 p_memszp_filesz，多出的部分初始化为 0，通常作为.bss 段内容 p_flags: 进程中该 segment 的权限(RWX) p_align: 该 segment 数据的对齐，2 的整数次幂。即要求 p_offset % p_align p_vaddr。 剩下的 p_type 字段，表示该 program segment 的类型，主要有以下几种: PT_NULL: 表示该段未使用 PT_LOAD: Loadable Segment，将文件中的 segment 内容映射到进程内存中对应的地址上。值得一提的是 SPEC 中说在 program header 中的多个 PT_LOAD 地址是按照虚拟地址递增排序的。 PT_DYNAMIC: 动态链接中用到的段，通常是 RW 映射，因为需要由 interpreter(ld.so)修复对应的的入口 PT_INTERP: 包含 interpreter 的路径，见下文 PT_HDR: 表示 program header table 本身。如果有这个 segment 的话，必须要在所有可加载的 segment 之前，并且在文件中不能出现超过一次。 在不同的操作系统中还可能有一些拓展的类型，比如 PT_GNU_STACK、PT_GNU_RELRO 等，不一而足。 参考链接 Linux Foundation Referenced Specifications Executable and Linkable Format (ELF) Tool Interface Standard (TIS) Executable and Linking Format (ELF) Specification Version 1.2 elf(5) - format of Executable and Linking Format (ELF) files How programs get run: ELF binaries 深入了解GOT,PLT和动态链接","categories":["0.平台","Linux","程序"]},{"title":"Qexo本地部署","path":"/2024/05/21/0-平台-服务器-博客-Qexo本地部署/","content":"Qexo 是一个快速、强大、美观的在线 静态博客编辑器。使用 GPL3.0 开源协议。支持包括且不限于在 Vercel 等平台部署, 为您的静态博客添加动态的元素 项目地址： https://github.com/Qexo/Qexo 本地部署安装 mysql sudo apt install mysql-server 查看并更新密码 sudo cat /etc/mysql/debian.cnf 进入 mysql，输入上面查询到的用户名和密码 mysql -u debian-sys-maint -p 创建 Qexo 要使用表 create database qexo; 克隆 qexo 项目到本地 git clone https://github.com/Qexo/Qexo.git 编辑配置，以使用 Mysql 为例, 确认好安装相关依赖后在 manage.py 的同级目录下创建并修改 configs.py import pymysql pymysql.install_as_MySQLdb() DOMAINS = [127.0.0.1, 124.222.246.202] DATABASES = default: ENGINE: django.db.backends.mysql, NAME: 数据库表, USER: 数据库用户名, PASSWORD: 数据库密码, HOST: 127.0.0.1, PORT: 3306, OPTIONS: init_command: SET sql_mode=STRICT_TRANS_TABLES 安装依赖 pip3 install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate 启动 Qexo 博客管理后端 后台运行，退出 shell 也在运行 nohup python3 manage.py runserver 0.0.0.0:9082 --noreload 访问公网 IP+ 端口即可打开 Qexo 管理页面","categories":["0.平台","服务器","博客"]},{"title":"USB设备连接到WSL","path":"/2024/05/21/0-平台-WSL-USB设备连接到WSL/","content":"在 WSL2（Windows Subsystem for Linux 2）中连接 3D 打印机的 USB 端口，首先需要将该设备从 Windows 系统挂载到 Linux 系统。这一过程需要在 Windows 环境中安装一个名为 usbipd 的工具。usbipd 允许 Windows 上的 USB 设备共享给 WSL2 的 Linux 系统使用。 安装 usbipd你可以通过下面的链接访问 usbipd 的 GitHub 仓库，以获取更多信息和相关文档： usbipd GitHub 地址 在你的 Windows 命令行中执行以下命令以安装 usbipd： # 在 Windows 命令行中执行winget install usbipd 确保执行成功。你可以在命令行中输入 usbipd --version 来确认 usbipd 是否已正确安装，并查看其版本。 安装所需环境在完成 usbipd 的安装后，你需要设置 WSL2 环境以支持 USB 设备的挂载。在你的 WSL2 终端中执行以下命令： ## 在你的 WSL 中执行sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 这段代码主要的作用是安装必要的 Linux 工具包，并设置 usbip 的可执行路径。 如果在这个过程中你遇到错误提示，如 usbipd: error: WSL ‘usbip’ client not correctly installed，请检查上述步骤是否完全执行，必要时重新运行安装命令以确保所有组件都已正确配置。 列出并挂载 Windows 中的设备到 Linux 环境在完成了环境的设置后，接下来你需要列出所有可用的 USB 设备并将其挂载到 WSL2 中。你可以在 Windows 终端中执行以下命令： # 在 Windows 终端中执行usbipd wsl list 此命令会显示出当前连接的所有 USB 设备，列表中会包括它们的 busid，这在后面的步骤中是必需的。 一旦你找到了想要挂载的设备的 busid，可以使用以下命令将该设备挂载到 Linux 环境中： usbipd wsl attach --busid=4-1 请根据你想要连接的实际设备 ID 替换 4-1。执行后，你应该能够在 WSL2 内访问到你的 3D 打印机，接下来的步骤是配置和使用打印机。 通过以上步骤，你可以顺利地在 WSL2 环境中使用 USB 设备，享受更灵活的开发和打印体验。","categories":["0.平台","WSL"]},{"title":"Vmware共享文件夹","path":"/2024/05/21/0-平台-VMware-Vmware共享文件夹/","content":"查看共享的文件夹使用 vmware-hgfsclient 命令，你可以查看当前系统中所有的共享文件夹。这个命令被广泛应用于 VMware 虚拟机环境中，以便于快速了解主机与虚拟机之间的共享资源。 输入以下命令： vmware-hgfsclient 运行后，系统会列出所有可用的共享文件夹名称，方便你确认需要挂载的共享资源。 挂载共享文件夹要将共享文件夹挂载到虚拟机上，你需要使用 vmhgfs-fuse 命令。这个命令会把主机的共享文件夹映射到虚拟机的一个目录中，使得两者之间可以无缝地共享文件。 执行以下命令，将主机下的 ShareDir 挂载到虚拟机的 /home/forlinx/ShareDir 文件夹中： vmhgfs-fuse .host:/ShareDir /home/forlinx/ShareDir -o subtype=vmhgfs-fuse,allow_other 如果在挂载后发现共享文件夹没有出现在指定位置，可以尝试执行以下命令： vmhgfs-fuse .host:/ /home/forlinx/ShareDir 如果没有其他错误信息显示，就可以认为挂载成功了。 注意：在进行挂载之前，请确认 /mnt 目录下的 hgfs 目录已经存在。如果没有，你可以通过以下命令创建它： mkdir /mnt/hgfs 最后，运行 ls 命令来查看挂载内容，确保共享文件夹内的文件已经同步： ls /home/forlinx/ShareDir 如果能看到文件内容，就表示挂载成功。 自动挂载为了提高工作效率，如果你想避免每次重启后都手动挂载共享文件夹，可以创建一个启动脚本，实现自动挂载。 脚本首先，创建一个名为 startShare.sh 的脚本文件，输入以下命令： vmhgfs-fuse .host:/ /home/forlinx/ShareDir 之后，为该脚本添加可执行权限： chmod a+x startShare.sh 接下来，将这个脚本添加到系统启动时的自启中，这样每次系统启动时都会自动执行这个挂载操作。 启动文件如果希望通过修改系统的启动文件来实现这一目标，首先，你应该备份当前的 /etc/fstab 文件，以便在需要时能够恢复。例如，运行以下命令： cp /etc/fstab /etc/fstab_bak 然后，使用文本编辑器（如 vim）打开 fstab 文件： vim /etc/fstab 在文件的最后添加以下内容： # mount hgfs.host:/kali_share /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0 保存并退出编辑器后，系统将在每次启动时自动挂载指定的共享文件夹，这样你就可以省去手动挂载的麻烦，确保文件始终可以访问。","categories":["0.平台","VMware"]},{"title":"3D打印控制命令","path":"/2024/05/21/3-软件-3D打印-3D打印控制命令/","content":"限位开关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令： QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确，如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） [stepper_X]endstop_pin: ^PE5 #修改前endstop_pin: ^!PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令 PID_CALIBRATE HEATER=heater_bed TARGET=100 它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速 M106 S64 ，然后发送命令 PID_CALIBRATE HEATER=extruder TARGET=245 它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。 GCode 协议指令Klipper G-Code 协议指令 https://www.klipper3d.org/G-Codes.html marlin G-Code 协议指令 https://marlinfw.org/meta/gcode/ 部分我使用到的命令 命令 用途 M112 使 Klipper 进入 “shutdown”（关闭）状态 FIRMWARE_RESTART 重新加载配置文件并重启 SAVE_CONFIG 保存配置文件 GET_POSITION 获取位置 ps -ef | grep klippy 查看使用的 printer.cfg 文件位置 QUAD_GANTRY_LEVEL 调平","categories":["3.软件","3D打印"]},{"title":"3D打印相关软件","path":"/2024/05/21/3-软件-3D打印-3D打印相关软件/","content":"系统固件KlipperKlipper 是一个高性能、灵活的 3D 打印机固件，它通过将一些计算工作转移到更强大的主机（如 Raspberry Pi）上来提高打印质量和速度。 MarlinMarlin 是目前最流行的 3D 打印机固件之一，支持广泛的硬件平台和 3D 打印机模型，具有丰富的功能和高度的可定制性。 控制软件fluiddFluidd 是一个基于网页的控制界面，用于管理和监控运行 Klipper 固件的 3D 打印机。它提供了用户友好的界面和实时监控功能。GitHub 地址: https://github.com/fluidd-core/fluidd安装手册: https://github.com/dw-0/kiauh Make-meMake-me 是一个通过 WiFi 控制 Replicator 2 打印机的开源项目，使用 GitHub 的聊天机器人 Hubot 来监控和完成打印任务。目前只支持 Mac 的 OS X。 Pepeteir-ServerPepeteir-Server 是一个新型的 Repeteir 产品，可以在 Raspberry Pi 上运行，支持控制多台打印机，内存消耗极小。它的网页操作界面简单，但不支持 Mac 和 PC。 OctoprintOctoprint 是一个完全基于网页的 3D 打印机控制程序，可以远程控制打印机，并通过网络摄像头监控打印过程。支持 Raspberry Pi。 BotqueueBotqueue 是一个开源的远程打印机控制软件，可以控制多台打印机。用户上传 .stl 文件后，软件会完成切片和打印工作。它支持为每台打印机设置独立的切片特性。 切片软件切片软件用于将 3D 模型按层切片，并生成用于打印的 G 代码。 CuraCura 由 Ultimaker 开发，兼容多种 3D 打印机。它不仅可以切片，还提供 3D 打印机控制界面，尤其适用于 Ultimaker 的 3D 打印机。 Slic3rSlic3r 是开源且免费的切片软件，因其快捷性和高度可定制化而广受欢迎。许多 3D 打印机制造商提供默认的 Slic3r 配置文件（.INI 文件），可以用作初始设置。 Skeinforge另一款非常流行的切片软件。同样开源，免费。 kisslicerKISSlicer 是一款跨平台的切片软件，名称源自 “Keep It Simple”（保持简单），目标是提供一个简单易用的界面。 PrintrunPrintrun 既是控制软件，也是切片软件，可以独立完成从切片到打印的整个过程。支持 Mac、Linux 和 PC 操作平台。 Repetier-HostRepetier-Host 与 Printrun 类似，是一款综合性软件，具有切片、零件定位和机器控制功能。用户界面相对更复杂但更直观，同样支持 Mac、Linux 和 PC 操作平台。 3D 建模软件BlenderBlender 是一款开源的 3D 建模软件，功能强大且完全免费。它不仅可以用于 3D 建模，还支持动画、渲染、雕刻等多种功能，适用于各种复杂的 3D 设计和制作。 TinkercadTinkercad 是一个由 Autodesk 开发的在线 3D 建模工具，适合初学者使用。它基于浏览器，无需下载软件，界面友好且易于使用。 Fusion 360Fusion 360 同样由 Autodesk 开发，是一款功能强大的云端 3D CAD、CAM 和 CAE 工具。它适用于从初学者到专业人士的各个层级，提供了全面的建模、仿真和制造功能。 SketchUpSketchUp 是一款广受欢迎的 3D 建模软件，以其直观的用户界面和易用性著称。它有免费版本（SketchUp Free）和专业版本（SketchUp Pro），适用于建筑、工程、游戏开发等多个领域。 FreeCADFreeCAD 是一款开源的 3D CAD 建模软件，适合于产品设计、机械工程以及建筑设计。它具有模块化的架构，可以通过插件扩展其功能。 SolidWorksSolidWorks 是一款由 Dassault Systèmes 开发的专业 3D CAD 软件，广泛应用于工程设计、产品设计和制造业。它功能强大，但价格较高，通常用于工业级应用。 OnshapeOnshape 是一个基于云的 3D CAD 建模软件，适用于团队协作和设计项目。它无需安装，直接在浏览器中运行，支持实时协作和版本控制。 OpenSCADOpenSCAD 是一款开源的 3D CAD 建模软件，适用于创建精确的 3D 模型。它使用编程语言来定义模型，适合那些有编程经验的用户。","categories":["3.软件","3D打印"]},{"title":"Python安装","path":"/2024/05/21/1-语言-Python-Python安装/","content":"源码安装打开终端，使用以下命令更新软件包列表： sudo apt update 安装编译 Python 3.10 所需的依赖项： sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码并进入解压后的目录： tar -xf Python-3.10.0.tgzcd Python-3.10.0 配置 Python 3.10 的编译选项： ./configure --enable-optimizations 编译并安装 Python 3.10： make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。 安装时网络问题见 pip下载网络问题","categories":["1.语言","Python"]},{"title":"pip下载网络问题","path":"/2024/05/21/1-语言-Python-pip下载网络问题/","content":"在使用 Python 安装包工具 pip 时经常会出现下载很慢的情况，这其中有很大一部分原因和 pip 的源有关，在我们安装 python 后，通常 python 解释器自带 pip 这个工具，但是这里 pip 是设置的默认源，也就是官方源：https://pypi.org/simple，这个源在国内的下载速度是很慢的，所以我们为了提高包的下载速度我们可以通过换源来实现。 临时使用参数可以在使用 pip 的时候加参数 -i https://pypi.tuna.tsinghua.edu.cn/simple pip install -i https://pypi.tuna.tsinghua.edu.cn/simple markdown 这样就会从清华这边的镜像去安装 markdown。 # 清华源pip install markdown -i https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip install markdown -i https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip install markdown -i http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip install markdown -i http://pypi.douban.com/simple/# 中国科学技术大学pip install markdown -i http://pypi.mirrors.ustc.edu.cn/simple/ 报错未添加信任源pip install beautifulsoup4 --trusted-host mirrors.aliyun.com 永久修改命令行# 清华源pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip config set global.index-url http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip config set global.index-url http://pypi.douban.com/simple/# 换回默认源pip config unset global.index-url 配置文件 Linux 下 ~/.pip/pip.conf Windows 下 %HOMEPATH%\\pip\\pip.ini内容如下： [global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 报错未添加信任源[install]trusted-host=pypi.douban.com","categories":["1.语言","Python"]},{"title":"Linux下的CH34x串口识别","path":"/2024/05/21/2-通讯协议-串口-Linux下的CH34x串口识别/","content":"ch341.ko 是一个 Linux 内核模块，用于支持 CH341 USB 转串口芯片。要在内核中编译该模块，需要找到其配置选项。这个配置选项通常在 Linux 内核的配置文件中定义，并且可以通过配置内核选项来启用。 判断是否识别使用 lsusb 命令可以看到有 Bus 001 Device 005: ID 1a86:7523 QinHeng Electronics CH340 serial converter 是能识别出 ch34x 设备 检查串口是否被驱动加载输入指令 ls /dev/ttyUSB* 将会列出 USB 的加载情况。如果提示 No such file or directory 则是没有被驱动加载。 占用情况因报文件不存在错误，采用 dmesg|grep tty 命令检查发现，被 brltty 进程占用。 brltty 是一个后台进程（守护进程），为盲人提供对 LinuxUnix 控制台的访问（当处于文本模式时），使用可刷新盲文显示。 移除该 apt remove brltty。 权限chmod a+rw /dev/ttyUSB0 即可 重装驱动-单独编译下载最新的驱动 CH341SER_LINUX https://github.com/WCHSoftGroup/ch341ser_linux 解压后进入 “driver” 目录下 输入 make 命令编译驱动，正常编译完成后，将会看到生成了 ch341.ko 模块 输入 sudo make load 或者 sudo insmod ch341.ko 动态加载驱动（重启需要再次加载），或者输入 sudo make install 安装驱动（重启不丢失） 输入 sudo make unload 或者 sudo rmmod ch341.ko 或者 sudo make uninstall 卸载驱动 如果编译失败，可能是 ch34x.c 和实际内核版本不匹配，uname -r 可查看操作系统的发行版号，之后在 https://elixir.bootlin.com/linux/latest/source 中查找对应内核版本的源代码文件，一般位于 /drivers/usb/serial/ch341.c，替换后重新编译 如果 insmod 失败，查看 /lib/modules/$(uname -r)/kernel/drivers/usb/serial 目录下是否已经有了 ko 模块，将目录中生成 ko 文件复制到此处，使用 lsmod 查看模块 重装驱动-交叉编译编译一个 ARM64 的 ch341 的 ko 文件，用于 4.19.206 内核的 Linux，ch341.ko 模块的定义位于 drivers/usb/serial/Kconfig 文件中，通过配置 USB_SERIAL_CH341 选项可以在内核中启用该模块。编译内核时根据配置生成相应的模块文件，然后通过 modprobe 加载即可使用该模块。 在 drivers 目录下的所有文件中，在文件的内容中查找字符串 CH341grep -r CH341 drivers/ 确认串口类型，是 CH341 还是 PLX2303 ch341.c 文件中的 usb_device_id 是否包含要使用的 VID，PID（lsusb 命令查看） 查找配置选项，在 Linux 内核源代码目录中，驱动程序的配置选项通常定义在 Kconfig 文件中。要查找 ch341 驱动的配置选项，可以在内核源代码目录下运行以下命令：grep -r CH341 drivers/ 这将搜索包含 CH341 字符串的所有文件，通常会找到类似以下的条目： drivers/usb/serial/Kconfig:config USB_SERIAL_CH341drivers/usb/serial/Kconfig:\ttristate USB CH341 single port serial driver 配置内核，知道配置选项后，可以使用 make menuconfig 或 make nconfig 等工具来配置内核。在 USB Serial Converter support 菜单下，找到并启用 USB CH341 single port serial driver 选项。或者配置 USB_SERIAL_CH341=m，将其设置为模块（M）或内联（*），如果希望编译为模块，选择 M。 Device Drivers --- [*] USB support --- * USB Serial Converter support --- * USB CH341 single port serial driver 编译内核和模块，配置完成后，编译内核和模块： makemake modulesmake modules_install 加载模块，编译完成后，可以使用 modprobe 加载模块：modprobe ch341 验证模块加载，使用 lsmod 验证模块是否成功加载，如果显示 ch341 模块，则说明加载成功。lsmod | grep ch341 重装驱动-apt包提供了一些可能默认没有包含的额外内核模块。 sudo apt install linux-modules-extra-$(uname -r) 手动加载 ch341 驱动程序： sudo modprobe ch341 检查驱动程序是否已加载： lsmod | grep ch341 检查设备是否被识别： dmesg | grep ch341 KO 文件开机自动加载/etc/modules 文件中添加模块打开 /etc/modules 文件： sudo vi /etc/modules 在文件末尾添加你想要加载的 KO 文件的名字（不需要路径，只需要模块名），比如： my_module 使用 modprobe 配置文件创建一个新的文件在 /etc/modprobe.d/ 目录，例如 custom.conf： sudo vi /etc/modprobe.d/custom.conf 添加如下内容，指定模块名称： install your_module_name /sbin/insmod /path/to/your/module.ko 使用 rc.local 文件打开 /etc/rc.local 文件： sudo vi /etc/rc.local 在 exit 0 之前添加 insmod 命令，指定模块的完整路径： sudo insmod /path/to/your/module.koexit 0 创建 systemd 服务创建一个新的服务文件，例如 load-module.service： sudo vi /etc/systemd/system/load-module.service 在文件中添加以下内容，指定模块路径： [Unit]Description=Load custom kernel module[Service]Type=oneshotExecStart=/sbin/insmod /path/to/your/module.koExecStop=/sbin/rmmod your_module_nameRemainAfterExit=true[Install]WantedBy=multi-user.target","categories":["2.通讯协议","串口"]},{"title":"自启动","path":"/2024/05/21/0-平台-Linux-系统参数-自启动/","content":"设置脚本vi /etc/rc.local# 添加内容/usr/bin/nginx startchmod +x /etc/rc.d/rc.local# /etc/rc.d/rc.local是/etc/rc.local的软连接 自启动服务在 /etc/systemd/system/my_startup.service 或 /usr/lib/systemd/system/startmyapp.service 编辑或创建一个服务文件 [Unit]Description=API Server for Klipper SV1Documentation=https://moonraker.readthedocs.io/Requires=network-online.targetAfter=network-online.target[Install]WantedBy=multi-user.target[Service]Type=simpleUser=forlinxSupplementaryGroups=moonraker-adminRemainAfterExit=yesWorkingDirectory=/home/forlinx/moonrakerEnvironmentFile=/home/forlinx/printer_data/systemd/moonraker.envExecStart=/home/forlinx/moonraker-env/bin/python $MOONRAKER_ARGSRestart=alwaysRestartSec=10 加载服务到自启动中 sudo systemctl daemon-reloadsudo systemctl enable my_startup 操作服务 # 设置开机自启动systemctl enable startmyapp.service# 停止开机自启动systemctl disable startmyapp.service# 启动服务systemctl start startmyapp.service# 关闭服务systemctl stop startmyapp.service# 重新启动服务systemctl restart startmyapp.service# 重新加载服务配置文件systemctl reload startmyapp.service# 查看服务当前状态systemctl status startmyapp.service# 查看所有已启动的服务systemctl list-units --type=services# 查询服务是否开机启动systemctl is-enabled startmyapp.service 查看服务状态journalctl 是 Systemd 日志收集服务 journal 的一个命令行界面。它允许用户查询和操作 systemd journal 中的日志条目。这对于诊断系统服务问题、追踪错误或者监控系统事件非常有用。下面是几个使用 journalctl 的基本命令示例： 查看所有日志，这个命令会显示系统中所有服务的日志。 journalctl 查看特定服务的日志，将服务名替换为你想查看服务的日志名称，例如查看 nginx 服务日志： journalctl -u 服务名.servicejournalctl -u nginx.service 实时查看日志，这个命令会像 tail -f 一样实时显示新的日志条目。 journalctl -f 查看特定时间范围内的日志，这个例子会显示从 2023 年 4 月 1 日 0 点到 23 点 59 分 59 秒之间的日志。 journalctl --since 2023-04-01 00:00:00 --until 2023-04-01 23:59:59 查看包含特定关键词的日志，使用 grep 结合 journalctl 来过滤特定关键词，例如查找包含”error”的日志，或者直接使用 journalctl 的 grep 参数（-g 或–grep）： journalctl | grep errorjournalctl -u 服务名.service --grep 关键字 清空日志，这个命令会删除所有超过 1 天的日志条目。请注意，这将永久删除日志数据。 journalctl --vacuum-time=1d","categories":["0.平台","Linux","系统参数"]},{"title":"CAN和CANFD","path":"/2024/05/20/2-通讯协议-CAN-CAN和CANFD/","content":"CAN 和 CANFD对于 CAN-FD 而言，数据比特率要大于等于件裁比特率，用 ip link set can0 type can bitrate 500000 这个命令操作 CAN-FD 是有问题的，换成 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on，而后就可以利用 CAN-FD 进行数据的收发 按照配置 CAN 的方式去配置 CAN-FD，导致少配置了 CAN-FD 的数据比特率，导致出错。之前配置 CAN 的指令为 ip link set can0 type canbitrate 500000，实际通过分析 CAN-FD 的驱动代码以及 CAN-FD 通信协议的报文格式发现，对于 CAN-FD，数据比特率是要大于仲裁比特率的。换用 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on 配置数据比特率之后，CAN-FD 就可以正常收发数据了, 分析:CAN-FD 采用了两种方式来提高通信的效率，其中一种叫可变及更高的数据传输速率:从控制场中的 BRS 位到 ACK 场之前(含 CRC 但为了保证总线的健壮可靠，仲裁段(ID 和 ACK)保持不变，采用原分界符)为可变速率，CAN-FD 数据段的传输速率最大可达 5MbitsCAN 总线用的速率(最高 1Mbits)。 注意:两种速率各有一套位时间定义寄存器，对于 CAN-FD 来说均要配置。 CAN 和 CANFDCAN 与 CAN-FD 主要区别： 传输速率不同 CAN：最大传输速率 1Mbps。 CAN-FD：速率可变，仲裁比特率最高 1Mbps（与 CAN 相同），数据比特率最高 8Mbps。 数据长度不同 CAN：一帧数据最长 8 字节 CAN-FD：一帧数据最长 64 字节。 帧格式不同和 ID 长度不同。 CANFD 不存在远程帧，CAN 报文中的 RTR（用于区别标准帧与远程帧）被替换为 RRS（远程请求替代位，默认值为 0） CANFD 报文的标准帧和扩展帧—IDE 为 1 表示为扩展帧、为 0 表示标准帧 FDF 用于传统 CAN 报文和 CANFD 报文，FDF 位为 0 时为传统报文，FDF 为 1 时为 CANFD 报文 BRS 位速率切换位，BRS 位为 0 时 CANFD 速率保持恒定速率、BRS 位为 1 时 CANFD 的数据段会被切换到高速率。 ESI 错误状态指示位：CAN 报文中发送节点的错误状态只有该节点自己知道，CANFD 报文中可以通过 ESI 标志位来告诉其他节点该节点的错误状态，当 ESI 为 1 时表示发送节点处于被动错误状态、当 ESI 为 0 时表示发送节点处于主动错误状态 CRC：随着数据场的扩大，为了保证信息发送的质量，CAN FD 的 CRC 计算不仅要包括数据段的位，还包括来自 SOF 的 Stuff Count 和填充位。通过比较 CRC 的计算结果，可以判断接收节点是否能够正常接收。 在 CAN 中，CRC 的位数是 15 位，而在 CAN FD 中，CRC 场扩展到了 21 位。 当传输报文为 15 字节时：CRC 15 位 当传输数据为 16 字节或更少时：CRC 17 位 当传输数据超过 16 字节时：CRC 21 位 CAN FD DLCDLC 和 数据长度的关系在 Linux 的 SocketCAN 中，struct canfd_frame 中的 len 字段表示实际的有效负载长度（即数据长度），而 CAN FD 协议使用的是 4-bit 的 DLC（Data Length Code）来表示帧中数据的长度。这两者之间的关系是通过一组映射规则来转换的。 在 CAN FD 协议中，DLC 是一个 4 位的字段，允许的取值范围为 0 到 15。这些 DLC 值并不是直接表示字节长度，而是与有效负载长度之间有一个固定的映射关系。具体映射如下： DLC 数据字节数 (Payload Length) 0-8 0-8 9 12 10 16 11 20 12 24 13 32 14 48 15 64 struct canfd_frame 中 len 和 DLC 的转换在 SocketCAN 中，应用程序通过 struct canfd_frame 来发送 CAN FD 帧。struct canfd_frame 中的 len 字段表示实际的有效负载长度，而内核会根据这个 len 值来确定对应的 DLC 值。转换规则如下： 如果 len 的值在 0 到 8 ，DLC 的值与 len 直接相等。例如，len 5，则 DLC 5。 如果 len 的值大于 8，系统会根据 DLC 与有效负载长度的固定映射来选择最小的 DLC，使得能传输指定的字节数。例如： len 9 到 len 12，DLC 9，对应 12 字节的负载。 len 13 到 len 16，DLC 10，对应 16 字节的负载。 len 17 到 len 20，DLC 11，对应 20 字节的负载。 len 21 到 len 24，DLC 12，对应 24 字节的负载。 len 25 到 len 32，DLC 13，对应 32 字节的负载。 len 33 到 len 48，DLC 14，对应 48 字节的负载。 len 49 到 len 64，DLC 15，对应 64 字节的负载。 实际发送时的 DLC 计算当你在 SocketCAN 中使用 canfd_frame 结构体发送数据时： 你在 len 字段中指定实际的数据长度。 内核会根据上述规则，自动计算并设置相应的 DLC 值，确保数据可以正确传输。 如果 len 的值不直接对应某个 DLC（如 len 33），内核会自动选择能容纳该数据长度的最小 DLC（在这个例子中，DLC 会被设置为 14，对应 48 字节）。 示例假设你要发送 33 个字节的数据： struct canfd_frame 的 len 设置为 33。内核根据 len 值选择对应的 DLC 为 14（因为 DLC14 对应 48 字节的有效负载长度，可以容纳 33 个字节）。 实际发送时，CAN FD 帧会包含 33 字节的数据，DLC 会标记为 14，表示该帧允许的最大有效负载是 48 字节，尽管只使用了 33 字节。","categories":["2.通讯协议","CAN"]},{"title":"CANOpen 笔记","path":"/2024/05/20/2-通讯协议-CAN-CANOpen-笔记/","content":"项目地址 CANopenNode https://github.com/CANopenNode/CANopenNode CANopenLinux https://github.com/CANopenNode/CANopenLinux CANopenDemo https://github.com/CANopenNode/CANopenDemo CANopenEditor https://github.com/CANopenNode/CANopenEditor 帮助文档 CANopenLinux https://canopennode.github.io/CANopenLinux CANopenDemo https://canopennode.github.io/index.html CANopenCANopen 是一种基于 CAN（Controller Area Network） 通信协议的高层协议和设备协议，定义了网络管理、设备配置、通信对象和应用对象等方面的标准，以确保不同设备之间的互操作性和通信的一致性。 协议CiA 通过一系列文件维护保持 CANopen 设备和通讯协议规定。基本配置由 CiA 301 CANopen 应用层和通信配置规范定义。规范包括： CANopen 对象字典中的数据类型、编码规则和对象 CANopen 通信服务和协议 CANopen 网络管理服务和协议 CANopen 通讯配置 – 物理层 预定义的通信对象标识符连接数集、与紧急事件相关的对象、时间标识和同步通信对象 此基本 CiA 301 配置规定由其他 CiA 文件进行了补充和扩展，为一些具体领域的设备和功能规定了设备、应用程序和接口配置。具体有以下几个部分，按照自身应用程序的实际情况引入。 CiA 302 – CANopen 附加应用层功能 CiA 303-1 – 布线和接头管脚分配 CiA 303-3 – 指示器规范 CiA 306 – CANopen 电子数据表规范 CiA 309 – 从其他网络接入 CANopen CiA 315 – CANopen 通用框架 CiA 401 – 通用 IO 模块的 CANopen 设备配置 CiA 402 – 驱动和运动控制的 CANopen 设备配置 OSI 模型CANopen 的 OSI 模型，Data link 和 Physical 是由 CAN 进行实现的，Presentation 和 Session 是由 CANopen 进行实现的。 物理层（Physical Layer）定义了物理介质、电气特性、传输速率和编码规范等。 数据链路层（Data Link Layer）划分数据帧、错误检测与纠正、流量控制。 网络层（Network Layer）提供路径选择、逻辑寻址、路由选择等功能。 传输层（Transport Layer）提供端到端的传输控制和错误恢复。 会话层（Session Layer）建立、维护、同步和恢复会话。 表示层（Presentation Layer）数据的加密、压缩、格式转换等。 应用层（Application Layer）用户数据交互和应用支持。 设备模型每个 CANopen 设备都遵循一个通用的设备模型，因此不同的设备能依据同样的 CANopen 标准。CANopen 设备模型的三个组成部分是： 通讯接口 对象字典 应用程序一个 CANopen 设备必须支持一定数量的网络管理服务 NMT，需要至少一个 SDO。每个生产或消费过程数据的设备需要至少一个 PDO。所有其它的通讯对象是可选的。 核心概念通讯模式 设备节点通信有 3 种模型：主设备从设备、客户端服务器和生产者消费者 通讯协议 协议用于通信，例如配置节点（SDO）或传输实时数据（PDO） 定义了设备之间通信的机制和方式，包括对象字典、服务数据对象（SDO）、过程数据对象（PDO）、网络管理（NMT）等。 设备状态 设备支持不同的状态。“主”节点可以更改“从”节点的状态，例如将其重置。 对象字典（Object Dictionary，OD） 每个 CANopen 设备都有一个对象字典，OD 带有指定设备配置的条目，类似于一个查找表，列出了设备中的所有参数和数据。对象字典包括通信对象和应用对象，使用 16 位索引和 8 位子索引进行标识。可以通过 SDO 访问。 EDS（Electronic Data Sheet） EDS 是用于 OD 的标准文件格式，允许更新设备的服务 通讯模式CANopen 通过不同的通讯模式在节点之间传输报文: 生产消费模式: 它是一个广播连接，以推送模式工作（信号生产节点向消费节点发送无任何特定要求的信息）和引入模式（消费节点向信号生产节点要求特定信息）。 用户机服务器模式: 通过 SDO 协议，用户节点向服务器节点要求数据（对象字典索引），然后服务器节点通过发送在指定索引处的对象内容来响应。 主机从机模式: 主机节点可在任何时候向从机节点发送或要求数据。例如：NMT 协议通信。 数据帧数据帧由帧头 + 数据区组成，帧头由功能 ID+NodeID+RTR(远程传输请求)构成。 11 位的 CAN ID 称为通信对象标识符（COB-ID），分为两个部分： 前 4 位等于功能代码 Function Code（代表一个 CANopen 通信对象） 后 7 位包含节点 IDNode ID CANopen 网络中使用的 COB-ID 标识符的预定义分配 数据区部分的定义就要通过 CANopen 中的重要概念，对象字典 OD 来实现。 对象字典 OD对象字典（OD）是 CANopen 协议的核心概念。它是一组预定义的 CANopen 对象，使用索引和子索引访问对象。对象字典提供了应用程序和设备之间的沟通方式，提供了配置该设备的途径，和与设备通信的方法。 所有 CANopen 节点必须具有对象字典（OD），对象字典是指含有描述的 CANopen 节点的 行为 的所有 参数 的 标准化结构。 设备（例如从设备）的 OD 条目可以由其他设备（例如主机）使用 SDO 通过 CAN 进行访问。例如，通过 SDO 可以使应用程序主机更改从属发送心跳的频率。 作为对象索引存储在对象字典中的信息包括： 通信和应用程序配置参数 标准化设备配置参数 制造商特定设备配置文件参数 设备配置静态数据类型 设备配置复杂数据类型 复杂和静态数据类型 制造商特定数据类型 其他 可以按照 CANopen 标准的指导，以预定义的方式添加自己特定的制造商配置和数据类型。制造商还可以通过扩展由标准设备配置和数据类型规范要求的标准设备功能，来增强其设备的功能。 主索引索引值低于 0x0FFF 的是一些数据类型定义。一个节点的对象字典的有关范围在 0x1000 到 0x9FFF 之间，该范围内定义了一系列称为子协议的文档，用于定义节点的通讯行为。 通讯子协议区域详细划分 通用通讯对象 OD 示例配置下图是一个 TPDO 的定义示例，该 TPDO 在主索引 0x1800 的子索引中定义该 TPDO 相关的通信参数，主要是 TPDO 的发送类型和触发事件等设置，同时在和 0x1800 地址对应的 0x1A00 中定义了映射参数，在该参数的子索引中，定义了具体的映射地址和对象。并给出了该 TPDO 消息在发送时数据区内容。 电子数据表（EDS）一个节点的对象字典是在电子数据文档（EDS：Electronic Data Sheet）中描述。 实际上，将使用适当的软件工具来配置管理复杂的 CANopen 网络。 一个电子数据表（EDS）是一个标准化的电子文件，描述为 CANopen 设备定义的通信功能和对象。此供应方生成的文件有 3 个区域： 关于 EDS 文件的信息 一般设备信息 具有默认变量的对象字典 EDS 文件可用作 CANopen 设备的配置和网络设置工具。 通讯协议通信对象CANopen 通信单元由必要的通信接口和协议软件组成，通过总线在节点之间进行通信对象的发送和接收。各种 CANopen 通信对象用于实现各种类型的通信，CANopen 协议定义了几种不同类型的通信对象，每种对象都用于特定的通信目的： 过程数据对象（PDO）：用于实时数据传输，具有高优先级和低延迟。PDO 传输的数据量小，但传输速度快，适用于传感器数据和控制命令等实时性要求高的场景。 服务数据对象（SDO）：用于非实时数据传输，如配置参数和大数据块的传输。SDO 传输的灵活性更大，但优先级较低，适用于设备配置和诊断等场景。 网络管理对象（NMT）：用于控制设备状态和网络操作模式，如启动、停止和复位设备。 同步对象（SYNC）：用于网络同步，确保所有节点在同一时间点进行操作。 时间戳对象（TIME）：提供时间参考，用于时间相关的操作。 紧急情况对象 (EMCY) ： 指定状态下可用的通讯对象及状态转换说明： 中括号内的字母表示处于不同状态那些通讯对象可以使用。 a. NMTb. Node Guard c. SDO d. Emergencye. PDO f. Boot-up 网络管理（NMT）所有的 CANopen 节点都有自己专属的 NMT 状态，而主站可以通过 NMT 去控制从站的状态。CANopen 的网络管理采取主机从机通信模式。整个网络被设置为一个“状态机”，其中一个设备被指定为 NMT 主机，其余设备被指定为 NMT 从机。NMT 主机控制和监控 NMT 从机的状态。通过 NMT 主机触发，NMT 从机进行状态转换，实现 CANopen 网络的各个阶段。 NMT 服务用于通过 NMT 命令来控制 CANopen 设备的状态。只有 NMT-Master 节点能够传送 NMT Module Control 报文。所有从设备必须支持 NMT 模块控制服务。NMT Module Control 消息不需要应答。为了更改状态，NMT 主设备发送 COBID+2 字节的消息。 COB-ID 为 0（function code0 和 node ID0），优先级为最高。 第一个 CAN 数据字节 Requested State 包含请求的状态 第二个 CAN 数据字节包含目标节点的节点 ID。节点 ID 0 表示广播命令。所有从节点都处理此消息。 通过具体的 NMT 协议，如启动协议、模块控制协议、心跳协议（Heartbeat Protocol）和节点监测，主机向从机发出状态更改命令，进行这些状态转换。NMT 主机向特定节点或所有节点发送 NMT 命令代码以改变状态。 在预运行状态下，应用程序配置工具可以使用SDO 通信，配置 NMT 从机和设置参数。由于设备尚未开始运行，因此在此状态下不能使用 PDO 通信。 一旦状态从预运行变为运行状态，节点中的所有通信对象都将变为活跃状态，并且运行节点之间均可进行 PDO 和 SDO 通信。在此阶段，也可以通过 SDO 访问对象字典。当节点状态更改为停止时，PDO 和 SDO 通信都将停止。 实际状态取值 步骤 Byte 0 取值（命令） 状态 （2） 01 operation （3） 02 stop （4） 80 pre-operation （5） 81 reset app （6） 82 reset communication 示例# node 0x6 进入 `operational` 模式000 01 06# 所有节点进入 `pre-operational` 模式000 80 00 服务数据对象（SDO）SDO 提供了直接访问 CANopen 设备对象字典的入口，入口条件包括数据类型及大小。 访问者被称作客户端(client)，对象字典被访问且提供所请求服务的 CANopen 设备别称作服务器(server)。任何类型的 SDO 传输都由客户端发起，数据字典 OD 持有者是服务端，客户端和服务端都可以主动中止传输。通常情况下 CAN 总线网络中只有一个客户端。 客户的 CAN 报文和服务器的应答 CAN 报文总是包含 8 字节数据（尽管不是所有的数据字节都一定有意义）。一个客户的请求一定有来自服务器的应答。如果超时没有确认，则客户端节点将会重新发送原报文。 SDO 服务用于访问更改 CANopen 设备的对象字典中的值。允许 CANopen 节点通过 CAN 网络读取另一个节点的对象字典编辑值。下载（Download）是指对对象字典进行写操作，上传（Upload）指对对象字典进行读操作。 客户端节点可以通过以下 CAN 帧广播来启动 SDO 下载到节点 5，这将触发节点 5（并被其他节点忽略）。SDO 客户端的“接收”（即请求）CAN 帧如下所示： SDO 消息变量数据区 Byte 说明： Byte0 命令字节，主要定义了以下内容： CCS（客户端命令说明符，Client Command Specifier）描述传输类型（下载 download上载 upload） n 是数据字节 4-7 中不包含数据的 bytes （如果设置了 e＆s 则有效） 如果设置，e 表示 快速传输(所有数据在单个 CAN 帧中)分段传输 如果设置，s 表示数据大小显示在 n 中 Byte1+Byte2 主索引字节（16 位）确认 OD 主索引 Byte3 子索引字节（8 位）确认 OD 子索引 Byte4-7 包含实际的数据内容 一旦节点（客户端）发送了 CAN 帧，从节点 5（服务端）便会通过 RSDO 进行响应，并带有 COB-ID585。该响应包含索引子索引和 4 个空数据字节。自然地，如果客户端节点请求上传（即从节点 5 OD 读取数据），则节点 5 将以字节 4-7 中包含的相关数据进行响应。 SDO 灵活，但会带来大量输出，使其不适用于实时操作数据。同时数据只能包含在后续 4 个字节中，对于较大的数据方案，无法一次传输完毕。因此 SDO 中实现了 2 种传送机制，两种传送机制实际包含 4 个请求应答协议，共有 5 个协议如下： 快速传送（Expedited transfer） ： 最多传输 4 字节数据 启动域下载 （Initiate Domain Download） 启动域上传 （Initiate Domain Upload） 分段传送（Segmented transfer） ： 传输数据长度大于 4 字节 域分段下载（Download Domain Segment） 域分段上传 （Upload Domain Segment） 域传送中止（Abort Domain Transfer）。 快速 SDOCommand specifier(CS)命令符: 0x40 读取命令 0x2F 写一个字节 0x4F 返回值响应一个字节 0x2B 写两个字节 0x4B 返回值响应两个字节 0x27 写三个字节 0x47 返回值响应三个字节 0x23 写四个字节 0x43 返回值响应四个字节 0x60 写成功应答 0x80 异常响应 启动域下载（Initiate Domain Download） Bit 7 6 5 4 3 2 1 0 客户端 0 0 1 - n n e s 服务器 0 1 1 - - - - n ： 如果 e=1 且 s=1，则有效，否则为 0；表示数据部分中无意义数据的字节数（字节 8－n 到 7 数据无意义）。 e ： 0 正常传送，1 加速传送（数据在一个帧中）。 s ： 是否指明数据长度，0 数据长度未指明，1 数据长度指明。 e 0， s 0： 由 CiA 保留。 e 0， s 1 ： 数据字节为字节计数器，byte 4 是数据低位部分（LSB），byte 7 是数据高位部分（MSB）。 e 1 ： 数据字节为将要下载（download）的数据。 启动域上传（Initiate Domain Upload） Bit 7 6 5 4 3 2 1 0 客户端 0 1 0 - - - - - 服务器 0 1 0 - n n e s n，e，s： 与启动域下载相同。 分段 SDO域分段下载（Download Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 0 0 t n n n c 服务器 0 0 1 t - - - - n ：无意义的数据字节数。如果没有指明段长度，则为 0。 c ： 0 有后续分段需要 download，1 最后一个段。 t ： 触发位，后续每个分段交替清零和置位（第一次传送为 0，等效于 requestresponse）。 域分段上传（Upload Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 1 1 t - - - - 服务器 0 0 0 t n n n c n，c，t ： 与域分段下载相同。 示例通讯示例 -upload 数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 40 00 14 02 00 00 00 00 若成功，应答： 585 4F 00 14 02 FE 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 40 02 18 01 00 00 00 00 若成功，应答：585 60 02 18 01 08 02 12 60 通讯示例 -download数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 2F 00 14 02 FE 00 00 00 若成功，应答： 585 60 00 14 02 00 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 23 02 18 01 08 02 12 60 若成功，应答：585 60 02 18 01 00 00 00 00 过程数据对象（PDO）PDO 属于过程数据，即单向传输，无需接收节点回应 CAN 报文来确认，从通讯术语上来说是属于“生产消费”模型。、生产者“生产数据”，并使用 Transmit PDO（TPDO）将其传输到“消费者”（主用户）。相反，它可以通过 Receive PDO（RPDO）从使用者接收数据。 PDO 服务用于在设备之间传输实时数据，例如来自温度传感器的温度数据。PDO 承载大量信息，被视为最重要的 CANopen 协议。PDO 消息可以包含 8 个完整字节的数据，并且它可以在单个帧中包含多个对象参数值。因此在 PDO 服务中用 1 帧完成 SDO 至少需要 4 帧的操作。 带有特定 11 位 CAN 标识符的 TPDO 由一个设备发送，并作为 RPDO 由零个或多个设备接收。每个 PDO 在对象字典中用 2 个对象描述： PDO 通讯参数：包含哪个 COB-ID 将被 PDO 使用，传输类型，禁止时间和定时器周期。在索引 0x1400+ 和 0x1800+ 的对象字典中。 PDO 映射参数：包含一个对象字典中对象的列表，这些对象映射到 PDO 里，包括它们的数据长度（in bits）。生产者和消费者必须知道这个映射，以解释 PDO 内容。在索引 0x1600+ 和 0x1A00+ 的对象字典中。 生产者节点可以被配置为每 100ms 响应消费者所广播的 SYNC 触发。然后，节点 5 可以例如在下面广播，以 COB-ID 185 的 TPDO： 注意数据区部分 3 个参数值的打包方式，这些值是由数据字典中对应的映射结构决定了一个 PDO 的数据类型和映射关系。 通信参数定义了该设备所使用的 COB-ID、传输类型、定时周期等。RPDO 通讯参数位于对象字典索引的 0x1400 to 0x15FF，TPDO 通讯参数位于对象字典索引的 0x1800 to 0x19FF。每条索引代表一个 PDO 的通信参数集，其中的子索引分别指向具体的各种参数。PDO 消息的内容是预定义的（或者在网络启动时配置的）。 Number of entries 参数条目数量：即本索引中有几条参数； COB-ID：即这个 PDO 发出或者接收的对应 CAN 帧 ID； 发送类型：即这个 PDO 发送或者接收的传输形式，通常使用循环同步和异步制造商特定事件较多； Inhibit time 生产禁止约束时间(110ms)：约束 PDO 发送的最小间隔，避免导致总线负载剧烈增加，比如数字量输入过快，导致状态改变发送的 TPDO 频繁发送，总线负载加大，所以需要一个约束时间来进行“滤波”，这个时间单位为 0.1ms； Event timer 事件定时器触发的时间(单位 ms)：定时发送的 PDO，它的定时时间，如果这个时间为 0，则这个 PDO 为事件改变发送。 SYNC start value 同步起始值：同步传输的 PDO，收到诺干个同步包后，才进行发送，这个同步起始值就是同步包数量。比如设置为 2，即收到 2 个同步包后才进行发送。 发送类型PDO 可以有多种发送类型： 同步（通过接收 SYNC 对象实现同步） 非周期：远程帧预触发传送或设备子协议中规定的对象特定事件预触发传送。 周期：传送在每 1 到 240 个 SYNC 消息后触发。 异步 远程帧触发传送。通过发送与 PDO 的 COB-ID 相同的远程帧来触发 PDO 发送 由设备子协议中规定的对象特定事件触发传送。（基本采用这种，例如定时传输，数据变化传输等） 由传输类型定义的不同 PDO 传输模式，传输类型为 PDO 通讯参数对象的一部分，由 8 位无符号整数定义。 间隔时间一个 PDO 可以指定一个禁止时间，即定义两个连续 PDO 传输的最小间隔时间，避免由于高优先级信息的数据量太大，始终占据总线，而使其它优先级较低的数据无力竞争总线的问题。禁止时间由 16 位无符号整数定义，单位 100us。 定时周期一个 PDO 可以指定一个事件定时周期，当超过定时时间后，一个 PDO 传输可以被触发（不需要触发位）。事件定时周期由 16 位无符号整数定义，单位 1ms。 映射参数RPDO 通讯参数 1400h to 15FFh，映射参数 1600h to 17FFh，数据存放为 2000h 之后厂商自定义区域； TPDO 通讯参数 1800h to 19FFh，映射参数 1A00h to 1BFFh，数据存放为 2000h 之后厂商自定义区域。 包含了一个对象字典中的对象列表，这些对象映射到相应的 PDO，其中包括数据的长度（单位，位），对于生产者和消费者都必须要知道这个映射参数，才能够正确的解释 PDO 内容。就是将通信参数、应用数据和具体 CAN 报文中数据联系起来。 子索引 0：PDO 中映射应用程序对象的数量： 值 0：映射被禁用。 值 1：子索引 0x01 有效。 值 2-8: 子索引 0x01 至 (0x02 至 0x08) 有效。 子索引 1-8： 应用对象 1-8： 位 16-31：索引 位 8-15：子索引 位 0-7：数据长度（位） 示例示例设备配置 节点 ID: 0x01 第二个 Transmit PDO (TPDO2): TPDO2 的 COB-ID: 0x280 + Node_ID 0x281 对象字典（Object Dictionary）定义： 0x1801: TPDO2 通信参数 子索引 0x00: 0x02 (表示有 2 个子索引) 子索引 0x01: 0x00000281 (TPDO2 的 COB-ID, 使能) 子索引 0x02: 0x00 (传输类型，假设为 0x00 表示同步传输) 0x1A01: TPDO2 映射参数 子索引 0x00: 0x02 (映射对象数量，表示有两个对象映射到这个 TPDO) 子索引 0x01: 0x60000208 (映射对象 0x6000，子索引 0x02，8 位) 子索引 0x02: 0x64010110 (映射对象 0x6401，子索引 0x01，16 位) 假设当前设备中的数据如下： 对象 0x6000，子索引 0x02: 0xAB 对象 0x6401，子索引 0x01: 0x1234 TPDO2 实际发送的 CANopen 数据帧报文由以下 3 个字节组成： Byte 0: 0xAB Byte 1: 0x34 (低 8 位) Byte 2: 0x12 (高 8 位) 实际的 CANopen 数据帧：CAN ID: 0x281 Data: [0xAB, 0x34, 0x12] 设置一个 TPDO Index 1800 + n，subindex 01 ，COB_ID（通讯对象的标识符）：包含 CAN-ID 和附加控制位的标识符 Index 1800 + n，subindex 02， 写传输类型 t， t 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t FD ：收到 PDO 请求后 t FE ：事件驱动（制造商指定） t FF ：事件传输，节点自发传输 PDO Index 1800 + n， subindex 03，抑制时间。 如果传输类型设置为 FE 和 FF，它是最小的 PDO 传输间隔，单位 100us，值为 0 禁用抑制时间。PDO 报文需要延时 t × 100us 的时间才发出，以此避免在多 PDO 报文同时发出时，引起的时间冲突 。 Index 1800 + n， subindex 05，时间定时器。 如果传输类型设置为 FE 和 FF，它是 PDO 传输间隔，单位 ms，值为 0 禁用。t 0xC8，200ms。 Index 1A00 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 18 02 FF 00 00 00 设置索引 Index 1800，事件传输 605 2F 00 18 05 C8 00 00 00 设置索引 Index 1800，时间间隔 200ms 605 2F 00 1A 00 00 00 00 00 设置子索引禁用 605 23 00 1A 01 10 00 30 400x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 23 00 1A 02 20 00 10 200x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） 605 2F 00 1A 00 02 00 00 00 设置映射数量，用多少设多少，这里用了 2 个 设置一个 RPDO Index 1400 + n, subindex 01 ，COB_ID（通讯对象的标识符） Index 1400 + n, subindex 02，写传输类型 t， t 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t FD ：收到 PDO 请求后 t FE ：事件驱动（制造商指定） t FF ：事件传输，节点自发传输 PDO Index 1600 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 14 02 FF 00 00 00 设置索引 Index 1400，事件传输 605 2F 00 16 00 00 00 00 00 设置子索引禁用 605 23 00 16 01 10 00 30 40 设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 2F 00 16 00 01 00 00 00 设置映射数量，用多少设多少，这里用了 01 定义映射时，先设置子索引禁用；再设置相应映射；然后设置映射数量对于 TPDO 来说，其通信参数中的 COB-ID 是自身的 COB-ID，当发送 TPDO 时用来表明这个 TPDO 是谁发出的。对于 RPDO 来说，其通信参数的 COB-ID 是发送方的 COB-ID，用来表示自己只接受某个 CAN 节点发过来的 TPDO。 同步（SYNC）SYNC 消息通常由应用程序主机触发。每个节点都以该同步报文作为 PDO 触发参数，因此该同步报文的 COB-ID 具有比较高的优先级以及最短的传输时间。一般选用 0x80 作为同步报文的 CAN-ID，将 SYNC 消息（COB-ID 080）发送到 CANopen 网络。 在网络范围内同步（尤其在驱动应用中）：在整个网络范围内当前输入值准同时保存，随后传送（如果需要），根据前一个 SYNC 后接收到的报文更新输出值。 主从模式：SYNC 主节点定时发送 SYNC 对象，SYNC 从节点收到后同步执行任务。 在 SYNC 报文传送后，在给定的时间窗口内传送一个同步 PDO。 用 CAL 中基本变量类型的 CMS 对象实现。 CANopen 建议用一个最高优先级的 COB-ID 以保证同步信号正常传送。SYNC 报文可以不传送数据以使报文尽可能短。 一般同步报文由 NMT 主机发出，CAN 报文的数据为 0 字节。但如果一个网络内有 2 个同步机制，就需要设置不同的同步节拍，比如某些节点按 1 个同步帧发送 1 次 PDO，其他的节点收到 2 个同步帧才发送 1 次 PDO，所以这里 PDO 参数中的同步起始值就起了作用。 在同步协议中，有 3 个约束条件： 同步命令：0x1005 中规定了同步帧的命令为 0x80； 通讯循环周期：索引 0x1006 规定了同步帧的循环周期； 同步窗口时间：索引 0x1007 约束了同步帧发送后，从节点发送 PDO 的时效，即在这个时间内发送的 PDO 才有效，超过时间的 PDO 将被丢弃。 示例配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值） 23 05 10 00 80 00 00 00 读取 1006 信息 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms 100000us） 23 06 10 00 A0 86 01 00 时间戳（TIME-stamp）时间标记对象（Time Stamp），NMT 主机发送自身的时钟，为网络各个节点提供公共的时间参考，即网络对时，这在故障诊断中非常需要。 时间戳协议采用广播方式，无需节点应答，CAN-ID 为 0x100，数据长度为 6，数据为当前时刻与 1984 年 1 月 1 日 0 时的时间差。节点将此时间存储在对象字典 1012h 的索引中。 主机发出带有 CAN ID 100 的 TIME 消息，TIME 服务包含一个 6 字节的日期和时间信息。其中最初的 4 个数据字节包含午夜之后的毫秒数，随后的 2 个字节包含自 1984 年 1 月 1 日以来的天数。 紧急情况（EMCY）紧急报文协议（Emergency protocol）用于设备发生致命错误（例如传感器故障）的情况，从而使其可以向网络的其余部分指示此错误。 受影响的节点以高优先级向网络发送发送设备内部错误代码，提示 NMT 主站。紧急报文属于诊断性报文，一般不会影响 CANopen 通讯，其 CAN-ID 存储在 0x1014 的索引中，一般会定义为 0x080 + node-ID，数据包含 8 个字节，例如，节点 5 具有 COB-ID 085 + 数据字节，数据字节包含有关错误的信息，可以查找厂商定义的错误代码。 紧急信息的内容如下 Bytes 0…1： CO_EM_errorCode_t，在本例中为 0x5000（设备硬件） Bytes 2：CO_errorRegister_t，本例中为 0x01（通用错误） Bytes 3：CO_EM_errorStatusBits_t 中的错误条件索引，本例中为 0x2F（CO_EM_NON_VOLATILE_MEMORY - 访问非易失性设备内存时出错） Bytes 4…7：附加信息参数，本例中为 0x00000014 或 0x00000074 紧急信息由 CO_errorReport() 函数内部触发。您可以在 CO_EM_NON_VOLATILE_MEMORY 的源代码中查找紧急信息的来源。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不等于零，则禁止节点进入 NMT 运行状态，并且不能与其交换 PDO。 节点监测NMT 主机定期使用远程帧询问从机的当前状态，并将其与网络数据库中记录的早期状态相比较。任何不匹配和缺少 PDO 传输的状态都会以适当的错误代码表示，然后应用程序将采取适当的操作，如设备重置或错误标识。这称为节点监测，是通过使用节点监测协议得以实现。 NMT 从机使用一种称为生命监测的技术，通过在预定义的时间间隔里，内部检查节点监测帧的接收，来检测 NMT 主机的缺失。 现代设备设计使用 Heartbeat 协议进行节点监视，其中 NMT 从设备（Heartbeat Producer 心跳发出者）将周期性地向 NMT 主设备（Heartbeat Consumer 心跳使用者）发送 Heartbeat 报文。 这些报文之间的间隔是可配置的，并在主、从两个设备的对象字典中 Heartbeat producer time（心跳产生时间）对象上都进行设置。如果心跳报文在此时间限制内未到达，则发出者将被视为关机，使用者将采取补救措施，如设备重置或错误显示。 当一个 Heartbeat 节点启动后它的 Boot-up 报文是其第一个 Heartbeat 报文。Heartbeat 消费者通常是 NMT-Master 节点，它为每个 Heartbeat 节点设定一个超时值，当超时发生时采取相应动作。 示例读取心跳时间设置 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 2B 17 10 00 E8 03 00 00 Master 节点发送远程帧（无数据）NMT-Master - NMT-Slave COB-ID 0x700 + Node_ID NMT-Slave 节点发送如下报文应答 NMT-Master - NMT-Slave COB-ID 0x700 + Node_ID Byte0 Bit 7-0 : 状态 LSSLSS（Layer Setting Services）是一个用于配置和管理 CANopen 设备的一种服务。它提供了一些特定的功能，主要用于设备的初始化和配置，例如设置节点 ID 和波特率。LSS 对于在生产、调试和运行过程中配置 CANopen 设备非常有用。 LSS 的主要功能 设置节点 ID： 在 CANopen 网络中，每个节点都有一个唯一的节点 ID，范围为 1 到 127。LSS 允许动态设置或修改节点 ID，而不需要物理访问设备。这在设备初始安装和替换时特别有用。 设置波特率： CANopen 网络中的所有节点必须使用相同的波特率进行通信。LSS 允许动态修改设备的波特率，以便在不同的网络条件下进行适应和优化。 设备识别： LSS 可以用于识别网络中的设备。通过 LSS 服务，可以查询设备的唯一标识符（例如制造商代码、产品代码、序列号等），从而实现设备的识别和管理。 LSS 服务的主要操作 Switch Mode Global： 切换所有节点到配置模式或操作模式。 Switch Mode Selective： 选择性地切换特定节点到配置模式或操作模式。 Configure Node-ID： 设置节点 ID。 Configure Bit Timing Parameters： 设置 CAN 总线的波特率参数。 Identify Remote Slave： 识别网络中的设备，读取其唯一标识符。 LSS 协议的示例假设我们需要将一个设备的节点 ID 设置为 0x02，并将波特率设置为 250 kbps。以下是使用 LSS 的步骤： 切换到配置模式： 发送 LSS Switch Mode Selective 命令，将目标设备切换到配置模式。 设置节点 ID： 使用 LSS Configure Node-ID 命令，设置设备的节点 ID。 设置波特率： 使用 LSS Configure Bit Timing Parameters 命令，设置设备的波特率。 切换到操作模式： 发送 LSS Switch Mode Global 命令，将所有设备切换到操作模式。 LSS 消息格式LSS 消息使用特定的 CAN 标识符和数据格式。以下是 LSS Switch Mode Selective 命令的示例： CAN ID：0x7E5（LSS 主站到从站） 数据：0x04 0x00 0x00 0x00 0x00 0x00 0x00 0x00（切换到配置模式） 设置节点 ID 的命令： CAN ID：0x7E5 数据：0x11 0x02 0x00 0x00 0x00 0x00 0x00 0x00（设置节点 ID 为 0x02） 设置波特率的命令： CAN ID：0x7E5 数据：0x13 0x03 0x00 0x00 0x00 0x00 0x00 0x00（设置波特率为 250 kbps，假设 0x03 表示 250 kbps）","categories":["2.通讯协议","CAN"]},{"title":"USB权限设置","path":"/2024/05/20/2-通讯协议-USB-USB权限设置/","content":"因 Linux 系统下将涉及到 usb 底层驱动的调用，运行时，一定要加 sudo 获取权限运行，否则 USB 设备没有权限操作。 现通过创建 UDEV 规则，配置 USB 权限后，可以调用指定设备不加权限运行。 输入 lsusb，查看当前的 USB 设备的 ID，确定需要配置的 USB。 创建一个新的 udev 规则。名称取为：99-myusb.rules sudo vi /etc/udev/rules.d/99-myusb.rules 在 99-myusb.rules 文件中，输入以下内容 ##ACTION==add,SUBSYSTEMS==usb, ATTRSidVendor==04d8, ATTRSidProduct==0053, GROUP=users, MODE=0777 这条 udev 规则的作用是，当供应商 ID 为 04d8 且产品 ID 为 0053 的 USB 设备插入系统时，将该设备的用户组设置为 users，并赋予所有用户读、写、执行的全部权限。 插拔一下 USBCAN 设备或重启一下电脑后，即可不加 sudo 权限运行程序了 对某个特定 USB 设备设置权限。每当这个设备插入系统时，规则会自动应用。 ACTION==add：这表示规则在设备添加（插入）时生效。udev 可以根据不同的动作（如添加、移除等）触发规则，add 动作指设备插入时。 SUBSYSTEMS==usb：表示规则适用于 USB 子系统的设备。udev 管理系统中的设备，子系统用于分类，USB 是其中一种。 ATTRSidVendor==04d8：表示设备的供应商 ID（Vendor ID）为 04d8。每个 USB 设备都有唯一的供应商 ID，用于标识设备的制造商。 ATTRSidProduct==0053：表示设备的产品 ID（Product ID）为 0053。每个供应商的不同产品有不同的产品 ID，用于区分供应商的各个设备。 GROUP=users：表示设备的用户组被设置为 users。这决定了哪些用户组的成员有权访问该设备。 MODE=0777：表示设备的权限模式被设置为 0777，即所有用户对该设备都有读、写、执行权限。","categories":["2.通讯协议","USB"]},{"title":"Socket套接字","path":"/2024/05/20/2-通讯协议-网络-Socket套接字/","content":"Socket 最初是作为网络上不同主机之间进程的通信接口，后来应用越来越广，在同一主机上的不同进程之间通信也可以用 Socket。 简单来说，当网络上不同主机之间的两个进程（A、B）采用 Socket 进行通信时，那么它们之间需要建立一个通信端点，即创建 Socket，创建 Socket 时就分配端口号和网络地址。当进程 A 向进程 B 发送数据时，进程 A 必须要知道进程 B 的网络地址及端口号。 Socket 采用 CS 模型进行设计的，即 ClientServer，面向客户端—服务器模型。 每一个 Socket 都用一个半相关描述： {协议，本地地址，本地端口} 一个完整的 Socket 则用一个相关描述: {协议，本地地址，本地端口，远程地址，远程端口} 套接字套接字，另外一种进程间通信的方式。之前的 IPC 机制只能限定在一台计算机系统上进行资源共享。而套接字接口可以使，一台机器上的进程和另外一个机器上的进程通信。 什么是套接字套接字是一种通信机制，凭借这种机制，客户服务器系统的工作即可以在本地单机上工作，也可以跨网络进行。 套接字和管道类型，同样是读写类文件描述符的操作。不同的是，套接字明确的将客户和服务器分开来。套接字机制可以实现多个客户连接一个服务器。 套接字连接首先，服务器应用程序使用 socket 来创建一个套接字，它是系统分配给该服务器进程的类似文件标识符的资源，它不能与其它进程共享。ps：线程貌似也不行。 接下来，服务器进程会给套接字起个名字。本地套接字的名字是 Linux 文件系统中的文件名。对于网络套接字，它的名字是与客户连接的特定网络有关的服务标识符（端口号或访问点）。这个标识符将允许 Linux 将进入针对特定端口号的连接转接到正确的服务器进程。例如：Web 服务器一般在 80 端口上创建有关套接字，这是一个专用于此目的的标识符。Web 浏览器知道对于用户想访问的 Web 节点，应该使用端口 80 来建立 HTTP 连接。 我们用系统调用 bind 来给套接字命名(关联于本地某个文件)然后服务器进程就开始等待客户连接这个命名套接字。系统调用 listen 的作用是，创建一个队列并将其用于存放来自客户的请求连接。服务器通过系统调用 accept 来接受客户的连接。服务器调用 accept 时，它会创建一个与原来的命名套接字不同的新套接字。这个套接字只用来与这个特定客户进行通信，而命名套接字则被保留下来继续处理来自其它客户的连接。 基于套接字系统的客户端更加简单。客户首先调用 socket 创建一个未命名套接字，然后将服务器的命名套接字作为一个地址（或标识符）来调用 connect 与服务器建立连接。 一旦连接建立，我们就可以想使用底层的文件描述符那样用套接字来实现双向的数据通信。 套接字属性套接字的特性有 3 个属性确定，它们是：域（domain）、类型（type）和协议（protocol） 套接字的域域指定套接字通信中使用的网络介质。 最常见的套接字域是 AF_INET,它指的是 Internet 网络。许多 Linux 局域网使用的都是此网络。 还有一个域是 UNIX 文件系统域 AF_UNIX,即使一台还未联网的计算机上的套接字也可以使用这个域。这个域的底层协议就是文件输入输出，而它的地址就是文件名。当运行这个程序时，就可以在当前目录下看到这个地址。 服务器计算机上可能有多个服务器正在运行。客户可以通过 IP 端口来指定一台机器上某个特定服务。在系统内部，端口通过分配一个唯一的 16 位的整数来标识，在系统外部，则需要通过 IP 地址和端口号的组合来确定。套接字作为通信的终点，它必须在开始通信之前绑定一个端口。知名的服务通常也有一些端口，比如 ftp（21）和 httpd（80）等。在选择端口时不要随意选择以避免端口被占用的情况。一般情况下，小于 1024 的端口号都是为系统服务保留的。 套接字类型一个套接字域可能有多种不同的通信方式，而每种通信方式又有其不同的特性。但 AF_UNIX 域的套接字没有这样的问题，它提供了一个可靠的双向通信路径。在网络域中，我们就需要注意底层网络的特性，以及不同的通信机制是如何受到它们的影响。 因特网提供了两种通信机制：流（stream）和数据包（datagram）。他们有着截然不同的服务层次。 流套接字 流套接字（在某些方面类似于标准输入输出流）提供的是一个有序、可靠、双向字节流的连接。ps：使用 TCP 中的序号机制保证大的消息将被分片、传输、再重组。这很像一个文件流，它接受大量的数据，然后以小数据块的形式将它们写入底层磁盘。 流套接字由底层 SOCK_STREAM 指定，它们是在 AF_INET 域中通过 TCPIP 连接实现。 TCPIP 代表的是传输控制协议（Transmission Control Protocol）网际协议（Internet Protocol）。IP 协议是针对数据包的底层协议，它提供一台计算机通过网络到达另一台计算机的路由。TCP 协议提供排序、流控和重传，以保证大数据的传输可以完整地到达目的地或报告一个适当的错误条件。 数据报套接字 与流套接字相反，由类型 SOCK_DGRAM 指定的数据报套接字不建立和维持一个连接。它对可以发送的数据报的长度有限制。数据报作为一个单独的网络消息被传输，它可能丢失、复制或无序到达。 数据报套接字在 AF_INET 域中通过 UDPIP 连接实现，它提供的是一种无序的不可靠服务。但从资源的角度来看，相对来说它们开销比较小，因此不需要维护网络连接。而且不需要花费时间来建立连接，所以它们的速度也很快。 数据包适用于信息服务中的“单次（single-shot）”查询，它主要用来提供日常状态信息或执行低优先级的日志记录。服务器的奔溃不会给客户造成不便，也不会要求客户重启。 字节流套接字（SOCK_STREAM）字节流的套接字可以提供可靠的数据传输、面向连接的通讯流。数据按何种顺序发送，就按何种顺序接收。例如，当我们按顺序发送 A-B-C，那么在数据到达接收端时，它的顺序也是 A-B-C。字节流套接字采用的是 TCP（Transmission Control Protocol）协议。保证了数据传输的可靠性。 数据报套接字（SOCK_DGRAM）数据报套接字定义了一种无连接的服务。所谓无连接服务，简单来说，即在发送数据时，无需在收发两端建立类似 TCP 那样的握手连接，在发送时，将数据打包，然后加上远程 IP 地址，即可把该数据包发送出去。 数据通过相互独立的报文进行传输。并且是无序的、不可靠的传输。 原始套接字（SOCK_ROW）先启动服务器，通过调用 socket() 函数建立一个套接字，然后调用 bind() 函数将该套接字和本地网络地址联系在一起，再调用 listen() 函数使套接字做好侦听的准备，并规定它的请求队列的长度，之后就调用 accept() 函数来接收连接。 客户端在建立套接字之后就可调用 connect() 和服务器建立连接。 连接一旦建立，客户端和服务器之间就可以通过调用 recv()recvfrom() 函数和 send()sendto 函数来进行发收数据。 最后，待数据传送结束后，双方调用 close() 函数关闭套接字。 套接字协议暂时使用默认值。 创建套接字socket 系统调用创建一个套接字并返回一个描述符，该描述符可以用来访问该套接字。 int socket(int domain, int type, int protocol); 创建的套接字是一条通信线路的一个端点。domin 指定协议族，type 指定这个套接字的通信类型，protocol 指定使用的协议。 参数 domain 的取值包括：AF_UNIX 和 AF_INET 前者用于 UNIX 和 Linux 文件系统实现本地套接字，后者用于 UNIX 网络套接字，通过包括因特网在内的 TCPIP 网络进行通信的程序。 参数 type 取值包括：SOCK_STREAM 和 SOCK_DGRAM protocol：通常不需要选择，将该参数设为 0 表示使用默认协议。 套接字地址每个套接字域都有其之间的地址格式。 在 AF_UNIX 域中，套接字的地址由结构 sockaddr_un 来表示，该结构定义在头文件 sysun.h 中。 struct sockaddr_un sa_family_t sun_family; /*AF_INET*/ char sun_path[]; /*pathname*/; 在 AF_UNIX 域中，套接字的地址由 char sun_path[]指定。 在 AF_INET 域中，套接字的地址由 sockadd_in 来指定。该结构定义在 netinetin.h 中，它至少包括以下几个成员： struct sockaddr_in short int sin_family; /*AF_INET*/ unsigned short int sin_prot; /*Port number*/ struct in_addr sin_addr; /*Internet address*/;struct in_addr unsigned long int s_addr；； 命名套接字要想让 socket 创建的套接字可以被其它进程使用，服务器程序就必须给该套接字命名，即将套接字关联到一个文件系统的路径名。 int bind(int sockfd,const struct sockaddr * address,siz_t address_len); bind 系统调用 address 的地址值与文件描述符 socket 的未命名套接字相关联。地址结构体的长度由 address_len 传递。 传入参数时需要将一个特定的地址结构体指针（struct sockaddr_inun）转换为执行通用地址类型(struct sockaddr)。成功返回 0，失败返回-1 并设置 errno 创建套接字队列为了接受多个套接字（客户端）的连接，服务器程序必须创建一个队列来保存未处理的请求。它用 listen 系统调用来完成这一操作。 int listen(int socket,int backlog); arg1：命名套接字，arg2：队列的最大长度，即等待处理进入的客户端个数，超过则导致客户端请求失败。与 bind 返回相同，成功返回 0，失败返回-1 并设置 errno 接受连接accept 系统调用来等待客户建立对该套接字的连接。 int accept(int socket, struct sockaddr * address, size_t *address_len); accept 系统调用只有当客户端试图连接到由 socket 参数指定的套接字上时才返回。这里的客户指，在套接字队列中排在第一个的未处理连接。 套接字必须先由 bind 调用关联一个文件系统的路径名（即为套接字命名），然后由 listen 调用为其分配一个连接队列。 连接客户的地址将被放到 address 参数指向的 sockaddr 结构中。如果不关心客户端的地址，则将其值设为 NULL 即可。 参数 address_len 指定客户结构的长度。如果客户地址的长度超过这个值，它将被截断。 如果套接字队列中没有未处理的连接。accept 将堵塞直到有客户建立连接为止。我们可以通过对套接字描述符设置 O_NONBLOCK 标志来改变这一行为，使用函数 fcntl。 int flags = fcntl(socket,F_GETFL,0);fcntl(socket,F_SETFL,O_NONBLOCK | flags) 当有未处理的客户连接时，accept 函数将返回一个新的套接字描述符。发送错误时，返回-1 并设置 errno 请求连接客户程序通过一个未命名的套接字和服务器监听套接字之间建立连接的方法来连接到服务器。使用 connect 调用 int connect(int sockfd, const struct sockaddr *address, size_t address_len); 参数 socket 指定的套接字将连接到参数 address 指定的服务器套接字，address 指向的结构的长度有参数 address_len 指定。 参数 sockfd 指定的套接字必须通过 socket 调用获得一个有效的文件描述符。成功返回 0，失败返回-1，设置 errno。 如果连接不能立刻建立，connect 调用将被堵塞一段不确定的超时时间。一旦超时时间到达，连接将被放弃，connect 调用失败。但如果 connect 调用被一个信号中断，而该信号又得到了处理，connect 还会失败。 关闭套接字使用 close 函数来终止服务器和客户上的套接字连接，就如同对底层文件描述符进行关闭一样。你应该总是在连接的两端都关闭套接字。对于服务器来说，应该在 read 调用返回为 0 即没有数据可读的情况下关闭套接字，但如果有一个套接字是一个面向连接类型的，并且设置了 SOCK_LINGER 选项，close 调用会在该套接字 还有未传输数据时堵塞。此举，需要设置套接字选项。 套接字通信文件系统套接字的缺点是，除非程序员使用一个绝对路径名，否则套接字将创建在服务器的工作目录下。 为了接受客户的连接，你需要创建一个服务器及客户都可访问的全局目录（如：tmp 目录）。 而对网络套接字来说，你只需要选择一个未被使用的端口号即可。 其它端口号及通过他们提供的服务通常都列在系统文件etcservices 中，在选择端口号，注意不好选择在该配置文件中的端口号。 其实也不用看，没有那么好的运气能碰到，只要选择端口号在 3000 以上，应该就没事。 出于演示的目的，我们将使用这个回路网路（一个只包含它自身的回路（loopback）网路）。回路网络对于调试网络应用程序很有用处，因为它排除了任何外部网络问题。回路网路中只包含一台计算机，传统上它被称为 localhost，标准地址：127.0.0.1。 每一个与计算机进行通信的网路都有一个与之关联的硬件接口。一台计算机可能在每个网络中都有一个不同的网路名。当然也就会有几个不同的 IP 地址。 主机字节序和网络字节序在 Linux 机器上运行新版本的服务器和客户端时，我们可以用 netstat 命令来查看网路连接情况。 $ netstat -A inetActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 localhost:9741 localhost:51246 TIME_WAIT 现在可以看到这条对应的服务器和客户的端口号。 Local Address 一栏显示的服务器的地址和端口号，Foreign Address 一栏显示的远程客户的地址和端口号。 可是，当你在程序中选择的端口为 3366 时，在命令中输出的却是 9741.为什么不同呢？ 答案是：通过套接字传递的端口号和地址都是二进制数字。不同的计算机使用不同的字节序来表示整数。 比如：Inter 处理器采用小端字节序和网络传输采用的大端字节序。大端字节序意思为数据的地址随之内存的地址变大而变大。 为了使不同类型的计算机可以通过网络传输的多个字节整数的值达成一致，你需要定义一个网络字节序。客户和服务器程序必须在传输前，将它们的内部整数表示方式转化为网络字节序。通过以下函数实现： unsigned long int htonl(unsigned long int hostlong);unsigned short int htons(unsigned short int hostshort);unsigned long int ntohl(unsigned long int netlong);unsigned short int ntohs(unsigned short int netshort); 这些函数将 16 位和 32 位整数在主机字节序和标准的网络字节序之间进行转换。函数名是与之对应的转换操作的简写形式。如果计算机本身的主机字节序和网络字节序相同，这些操作的实际上就是空操作。 转换之后的 netstat 操作。 $ netstat -A inetActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 localhost:3366 localhost:34411 TIME_WAIT 为了让不同体系结构的计算机上的客户和服务器可以正确的操作，总是在网络程序中使用这些转换函数是很有必要的。 网络信息到目前为止，我们的客户和服务器程序一直是把地址和端口号编译到程序的内部。对于一个更通用的服务器和客户程序来说，我们可以通过网络信息函数来决定应该使用的地址和端口。 如果你有足够的权限，可以将自己的服务添加到etcservices 文件中的已知服务列表中，并在这个文件中为端口号分配一个名字，使用户可以使用符号化的服务名而不是端口号的数字。 类似的，如果给定一个计算机的名字，你可以通过调用解析地址的主机数据库函数来确定它的 IP 地址。这些函数通过查询网络配置文件来完成这一工作，如ecthosts 文件或网络信息服务。常用的网络信息服务有 NIS（Network Information Service，网络信息服务，以前叫 Yellow Pages，黄页服务）和 DNS（Domain Name Service，域名服务） 主机数据库函数在接口头文件 netdb.h 中声明。 struct hostent *gethostbyaddr(const void *addr, size_t len, int type);struct hosten *gethostbyname(const char *name); 这些函数返回的数据结构中至少会包含以下几个成员： struct hostent char *h_name; /* official name of host */ char **h_aliases; /* alias list */ int h_addrtype; /* host address type */ int h_length; /* length of address */ char **h_addr_list; /* list of addresses */ 如果没有我们查询的主机或地址有关的数据项，这些信息函数将返回一个空指针。 类似的，与服务及其关联端口号有关的信息也可以通过一些服务信息函数来获取。 struct servent *getservbyname(const char *name,const char *proto);struct servent *getservbyport(int port,const char *proto); proto 参数指定用于连接服务的协议，它有两个取值 tcp 和 udp，前者用于 SOCK_STREAM 类型的 TCP 连接，后者用于 SOCK_DGRAM 类型的 UDP 数据报。 返回的数据结构中至少会包含以下几个成员： struct servent char * s_name; /* name of the service*/ char ** s_aliases; /* list of aliases*/ int s_port; /* The IP port number*/ char *s_proto; /* The service type, usually tcp or udp */; 如果你想获得某台计算机上的主机数据库信息，可以调用那个 gehostbyname 函数并且将结果打印出来。注意，要将返回的地址列表信息转化为正确的 IP 地址类型，需用函数 int_ntoa 将它们从网络字节序转成主机字节序的字符串后打印出来。 char *inet_ntoa(struct in_addr in); 这个函数的作用是，将有关因特网主机地址转化为一个点分四元组格式的字符串。失败时返回-1，但 POSIX 规范未定义错误类型。 最后一个函数：gethostname，得到主机的名称 int gethostname(char *name, int legth); 这个函数的作用，将当前主机的主机的名字写入 name 指向的字符串中。主机名将以 NULL 结尾。参数 length 指定了字符串 name 的长度，如果返回的主机名太长，它就会被截断。调用成功返回 0，失败返回-1，适当的设置 errno 编写一个连接到标准服务的程序：使用 gethostbyname 得到主机的 IP 地址，getservbyname 得到服务的端口，最后使用 connect 请求服务。 多客户目标：如何让单个服务器进程在不堵塞、不等待客户请求到达的前提下处理多个客户。 select 系统调用在编写 Linux 应用程序时，我们经常会遇到需要检查好几个输入的状态才能确定下一步行动的情况。如果是在一个单用户系统中，运行一个“忙等待”循环还是可以接受的，它不停地扫描输入设备看是否有数据，如果有数据到达就读取它。但这种做法很消耗 CPU 的时间。 select 系统调用允许程序同时在多个底层文件描述符上等待输入的到达（或输出的完成）。这意味着程序可以一直堵塞到有事情可做为止。类似的，服务器也可以通过同时在多个打开的套接字上等待请求到来的方法来处理多个客户。 select 函数对数据结构 fd_set 进行操作，它是由打开的文件描述符而构成的集合。 有一组定义好的宏来控制这个集合。 void FD_ZERO(fd_set *fdset);void FD_CLR(int fd, fd_set *fdset);void FD_SET(int fd, fd_set *fdset);int FD_ISSET(int fd, fd_set *fdset); 顾名思义，FD_ZERO 用于将 fd_set 初始化为空集合，FD_SET，FD_CLR 就是添加和删除由 fd 传入到集合中文件描述符。 如果 FD_ISSET 宏中参数 fd 属于 fd_set 中一个元素，FD_ISSET 宏将返回非零值。 fd_set 结构中可以容纳的文件描述符的最大数目有常量 FD_SETSIZE 指定。 select 函数通过一个超时值来防止无限期的堵塞。这个超时值由一个 timeval 结构给出。这个结构定义在头文件 systime.h 中，它由以下几个成员组成： struct timeval time_t tv_sec; /* seconds */ long tv_usec; /* microseconds */; 类型 time_t 在头文件 systypes.h 中被定义一个整数类型。 select 系统调用的原型为： int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *except, struct timeval *timeout); select 调用用于测试文件描述符集合中，是否有一个文件描述符已处于可读，可写或其它状态，之后它将堵塞以等待某个文件描述符进入上述状态。 参数 nfds 指定需要测试的文件描述符的数目，测试的描述符范围从 0 到 nfds-1。3 个文件描述符都设为 NULL，表示不执行对应测试。 select 函数会在发生以下情况时返回：readfds 可读，writefds 可写，exceptfds 相应（不知道什么时候会出现以下情况，旧版中定义为出错时。）如果这三种情况都没有发送，函数将在 timeval 指定的一段超时时间后返回，如果 timeval 参数是一个空而且套接字上也没有进入那三种状态，调用将一直堵塞下去。 当 select 返回时，描述符集合将被修改以指示哪些描述符正处于可读、可写或其它状态。 然后使用 FD_ISSET 对描述符进行测试，来找出需要处理的描述符。如果 select 是因为超时而返回的，所有的描述符集合将被清空。 select 调用成功将返回发生变化的描述符总数，出错返回-1 并设置 errno。 多客户服务器可以让 select 调用同时检查监听套接字和客户的连接套接字。一旦 select 调用指示有活动发生，就可以使用 FD_ISSET 来遍历，所有连接的文件描述符，以检查是哪个套接字上面活动发生。 如果是套接字可读的话，这说明正有一个客户请求连接，即服务器使用 socket 函数创建的套接字描述符有活动，此时就可以调用 accept 函数接受客户端的连接，如果是某个客户套接字描述符活跃，一个客户需要服务端进行读写操作。如果读操作返回 0 则表明有一个客户进程已经结束，你可以关闭套接字并把它从描述符集合中删除。 数据包在有些情况下，在程序中花费时间来建立和维持一个套接字连接是不必须要的。 当用户需要一个短小的数据查询并期望接受到一个短小的相应时，我们一般就使用 UDP 提供的服务。例如主机上的 daytime 服务。 因为 UDP 提供的是不可靠服务，所以你可以会发现数据包或响应会丢失。如果数据包对于你来说非常重要，就需要小心编写 UDP 程序，以检查错误并在必要是重传。 使用 UDP 数据包是，你需要使用 sendto 和 recvfrom 来代替原有使用在套接字上的 read 和 write 调用。 sendto 系统调用从 buffer 缓冲区中给使用指定套接字地址的目标服务器发送一个数据包。 int sendto(int sockfd, void *buffer, size_t len, int flags, struct sockaddr *to, socklen tolen); 在正常调用中，flags 参数一般被设置为 0. recvfrom 系统调用在套接字上等待从特定地址到来的数据包，并将它放入 buffer 缓冲区。 int recvfrom(int sockfd, void *buffer, size_t len, int flag, struct sockaddr *to, socklen fromlen); 在正常调用中，flags 参数一般被设置为 0. 两个函数的调用，成功返回操作的字符数，错误返回-1，并设置 errno 通过以上函数可以创建出一个 UDP 服务器，一个使用 sendto 函数发数据，一个使用 recvfrom 函数接数据。另外通过使用 setsocketopt 函数来设置套接字描述符的超时情况。也可以采用使用 sigaction 信号访问的方式来实现","categories":["2.通讯协议","网络"]},{"title":"CAN学习笔记","path":"/2024/05/17/2-通讯协议-CAN-CAN学习笔记/","content":"概述介绍CAN 总线是一种串行通信协议，使用的是两条差分信号线，只能表达一个信号。简洁的物理层决定了 CAN 必然要配上一套复杂的协议。根据不同的距离、不同的网络，可配置不同的速度，最高速度为 1MBits。 CAN 2.0A 为标准格式，CAN 2.0B 为扩展格式。 可以多主方式工作，网络上的任意节点均可以在任意时刻主动地向网络上的其他节点发送信息，而不分主从，通信方式灵活。 网络上的节点 (信息) 可分成不同的优先级，可以满足不同的实时要求。 采用非破坏性位仲裁总线结构机制，当两个节点同时向网络上传送信息时，优先级低的节点主动停止数据发送，而优先级高的节点可不受影响地继续传输数据。 CAN 属性 属性 说明 报文（Messages） CAN 协议对数据、操作命令 (如读写) 以及同步信号进行打包，打包后的这些内容称为报文，简单来说就是具有固定格式的数据包。 信息路由（Information Routing） 报文寻找结点的方式。 位速率（Bit rate） 数据位的传输速度。 优先权（Priorities） 报文发送的优先权。 远程数据请求（Remote Data Request） 通过发送远程帧，需要数据的节点可以请求另一节点发送相应的数据帧。 多主机（Multimaster） 总线空闲时，任何结点都可以开始传送报文。 仲裁（Arbitration） 当 2 个及以上的单元同时开始传送报文，那么就会有总线访问冲突。仲裁是确定哪个单元的具有发送优先权。 安全性（Safety） CAN 的每一个节点均采取了强有力的措施以进行错误检测、错误标定及错误自检。 错误检测（Error Detection） 包括监视、循环冗余检查、位填充、报文格式检查。 错误检测的执行（Performance of Error Detection） 错误标定和恢复时间（Error Sinalling and Recovery Time） 任何检测到错误的结点会标志出已损坏的报文。此报文会失效并将自动地开始重新传送。如果不再出现新的错误，从检测到错误到下一报文的传送开始为止，恢复时间最多为 29 个位的时间。 故障界定（Fault Confinement） CAN 结点能够把永久故障和短暂扰动区分开来。永久故障的结点会被关闭。 连接（Connections） CAN 串行通讯链路是可以连接许多结点的总线。理论上，可连接无数多的结点。但由于实际上受延迟时间或者总线线路上电气负载的影响，连接结点的数量是有限的。 单通道（Single Channel） 总线是由单一进行双向位信号传送的通道组成。 总线值（Bus value） 总线可以具有两种互补的逻辑值之一：“显性”（可表示为逻辑 0）或“隐性”（可表示为逻辑 1）。 应答（Acknowledgment） 所有的接收器检查报文的连贯性。对于连贯的报文，接收器应答；对于不连贯的报文，接收器作出标志。 睡眠模式／唤醒（Sleep Mode Wake-up） 为了减少系统电源的功率消耗，可以将 CAN 器件设为睡眠模式以便停止内部活动及断开与总线驱动器的连接。CAN 器件可由总线激活，或系统内部状态而被唤醒。 工作原理当 CAN 总线上的节点发送数据时，以报文形式广播给网络中的所有节点，总线上的所有节点都不使用节点地址等系统配置信息，只根据每组报文开头的 11 位标识符解释数据的含义来决定是否接收。这种数据收发方式称为面向内容的编址方案。 当某个节点要向其他节点发送数据时，这个节点的处理器将要发送的数据和自己的标识符传送给该节点的 CAN 总线接口控制器，并处于准备状态；当收到总线分配时，转为发送报文状态。数据根据协议组织成一定的报文格式后发出，此时网络上的其他节点处于接收状态。处于接收状态的每个节点对接收到的报文进行检测，判断这些报文是否是发给自己的以确定是否接收。 层次结构CAN 被细分为三个层次，其中的对象层和传输层包括所有由 ISOOSI 模型定义的数据链路层的服务和功能。 对象层（the object layer）的作用范围包括： 查找被发送的报文。 确定由实际要使用的传输层接收哪一个报文。 为应用层相关硬件提供接口。 传输层（the transfer layer）的作用主要： 传送规则，也就是控制帧结构、执行仲裁、错误检测、出错标定、故障界定。 总线上什么时候开始发送新报文及什么时候开始接收报文，在传输层里确定。 位定时的一些普通功能也可以看作是传输层的一部分。 传输层的修改是受到限制的。 物理层（the phyical layer）的作用： 在不同节点之间根据所有的电气属性进行位信息的实际传输。当然，同一网络内，物理层对于所有的节点必须是相同的。 编程在对象层进行，这一层直接与应用层交互，并且提供了管理和处理 CAN 消息的接口。通过对象层，应用程序可以发送和接收 CAN 的打包消息。打包的过程就是在原始数据的基础上再加上帧起始段、仲裁段、控制段、CRC 校验、应答和帧结束，把这些内容按特定的格式打包好，就可以用一个通道表达各种信号了，当数据包被发送时，只要接收方按约定格式去解读，就能还原出原始数据。 传输层的功能主要由 CAN 控制器硬件和驱动程序实现。通常，程序员不直接操作传输层，而是通过对象层的 API 间接利用传输层的功能。传输层负责处理 CAN 协议的低级细节，如位级传输、错误处理和仲裁。 位填充是为了防止突发错误而设定的功能。位填充的规则如下： 5 位连续相同电平之后，必须填充一位反向位，即不允许有 6 个连续相同位； SOF 之前为总线空闲状态，不需要同步，因此不需要位填充； CRC 之后为固定格式，不允许填充； 由 CAN 控制器自动实现； 物理层通常由 CAN 收发器硬件和相关电气接口组成。 仲裁方式在总线空闲态，最先开始发送消息的单元获得发送权。多个单元同时开始发送时，各发送单元从仲裁段的第一位开始进行仲裁。连续输出显性电平最多的单元继续发送。即逐位地对比 各个结点发出的报文 ID。 由于线与的关系，显示位“0”可以覆盖隐性位“1”，因此 ID 最小的节点赢得仲裁，总线上表现为该结点的报文，其他结点失去仲裁，退出发送，转为接收状态。 标准格式 ID 与具有相同 ID 的远程帧或者扩展格式的数据帧在总线上竞争时，标准格式的 RTR 位为显性位的具有优先权，可继续发送。 位时序CAN 协议的通信方法位 NRZ(non-return to zero)方式。各个位的开头或结尾都没有附加同步信号。 发送单元以与位时序同步的方式开始发送数据。 接收单元根据总线上电平的变化进行同步并进行接收工作。 由发送单元在非同步的情况下发送的每秒钟的位数称为位速率。一个位可分为 4 段。 同步段（SS） 传播时间段（PTS） 相位缓冲段 1（PBS1） 相位缓冲段 2（PBS2） 这些段又由可称为 Time Quantum（以下称为 Tq）的最小时间单位构成。 1 位分为 4 个段，每个段又由若干个 Tq 构成，这称为位时序。 1 位由多少个 Tq 构成、每个段又由多少个 Tq 构成等，可以任意设定位时序。通过设定位时序，多个单元可同时采样，也可任意设定采样点。 采样点：是读取总线电平，并将读到的电平作为位值的点，位置在 PBS1 结束处。 设置位时序和计算位速率ip link set can0 type cantq 125 prop-seg 6 phase-seg1 7 phase-seg2 2 sjw 1 同步段（Sync Segment）: 固定为 1 TQ，用于同步位定时器。 传播时间段（Propagation Segment, prop-seg）: 用于补偿信号在总线上传播的时间延迟 相位缓冲段 1（Phase Buffer Segment 1, phase-seg1）: 用于提高抗干扰能力，允许时间调整。 相位缓冲段 2（Phase Buffer Segment 2, phase-seg2）: 也用于提高抗干扰能力，允许时间调整。 ip link set can0 type can: 设置名为 can0 的网络接口的类型为 CAN。 tq 125: 设置时间量化（Time Quantum，TQ）为 125 ns。TQ 是 CAN 控制器内部的基本时间单位，用于划分整个位时间。 prop-seg 6: 设置传播时间段（Propagation Segment）为 6 TQ。传播时间段用于补偿信号在 CAN 总线上传播的延迟。为 6 个时间量化，6 * 125 ns 750 ns。 phase-seg1 7: 设置相位缓冲段 1（Phase Buffer Segment 1）为 7 TQ。这个时间段用于调整边沿相位，通常包括采样点之前的时间。为 7 个时间量化，875 ns。 phase-seg2 2: 设置相位缓冲段 2（Phase Buffer Segment 2）为 2 TQ。这个时间段用于调整边沿相位，通常包括采样点之后的时间。为 2 个时间量化，250 ns。 sjw 1: 设置同步跳跃宽度（Synchronization Jump Width，SJW）为 1 TQ。SJW 用于重新同步时可以跳跃的最大时间量。为 1 个时间量化，1 * 125 ns 125 ns。 计算位时间和位速率 总位时间是所有段的时间总和： Sync Segment: 1 TQ Propagation Segment: 6 TQ Phase Buffer Segment 1: 7 TQ Phase Buffer Segment 2: 2 TQ 总时间量化数 1 + 6 + 7 + 2 16 TQ 总位时间 16 * 125 ns 2000 ns 2 μs 位速率（Bit Rate） 1 总位时间 1 2 μs 500 kbps 同步方式硬件同步接收单元在总线空闲状态检测出帧起始时进行的同步调整。 在检测出边沿的地方不考虑 SJW 的值而认为是 SS 段 在同步在接收过程中检测出总线上的电平变化时进行大的同步调整。 当检测出边沿时，根据 SJW 的值通过加长 PBS1 或缩短 PBS2（采样点位置在 PBS1 结束处），以调整同步，最大调整量不超过 SJW 的值。 边沿出现在 PTS 和 PBS1 之间时，通过加长 PBS1 边沿出现在 PBS2 时，通过缩短 PBS2 位填充位填充时为防止突发错误而设定的功能。在同样的电平持续 5 位时添加一个位的反型数据。 发送单元 发送数据帧和遥控帧时，SOF~CRC 段的数据，相同电平持续 5bits，下一位插入反型数据。 接收单元 接收数据帧和遥控帧时，SOF~CRC 段的数据，相同电平持续 5bits，需要删除下一个位再接收。如果数据仍然和前 5bits 相同，则被视为错误并发送错误帧。 数据帧帧类型为了更有效地控制通讯，CAN 一共规定了 5 种类型的帧 数据帧：发送单元向接收单元传送数据的帧。 远程帧：接收单元向发送单元请求数据的帧。 错误帧：检测出错误时向其它单元通知错误的帧。 过载帧：接收单元通知其尚未就绪的帧。 间隔帧：将数据帧及遥控帧与前面的帧分离开来的帧。 CAN 帧定义数据帧由帧起始、仲裁段、控制段、数据段、CRC、ACK、帧结束共 7 个段构成。数据帧和遥控帧有标准帧和扩展帧两种帧，标准帧有 11 个位的标识符 ID，扩展帧有 29 个位的 ID。 帧起始 (Start Of Frame,SOF)，1bit 表示帧开始的段，设置为 0。 仲裁段（Identifier，ID），11bits29bits 表示数据帧优先级的段 标准帧与扩展帧的构成有所不同，均禁止高 7 位为隐性 (ID1111111XXXX…) 仲裁段的内容主要为本数据帧的 ID，标准帧的 ID 有 11 个位，扩展帧的 ID 有 29 个位，在 CAN 协议中，ID 决定着数据帧发送的优先级，也决定着其它节点是否会接收这个数据帧。CAN 总线不对挂载在它之上的节点分配优先级和地址，对总线的占有权是由信息的 ID 决定的，即对于重要的信息，优先级高的 ID，能够优先发送出去 RTR 位 (Remote Transmission Request Bit) 远程传输请求位，用于区分数据帧和遥控帧的，为 0 表示数据帧，1 表示遥控帧。 控制段 控制段由 6 个位构成，表示数据段的字节数 IDE 位 (Identifier Extension Bit) 标识符扩展位，用于区分标准帧与扩展帧，为 0 表示标准帧，1 表示扩展帧 SRR 位 (Substitute Remote Request Bit) 只存在于扩展帧，它用于替代标准帧中的 RTR 位，扩展帧中的 SRR 位固定为 1，RTR 在数据帧中为 0，所以两个 ID 相同的标准帧与扩展帧，标准帧的优先级较高 DLC 数据长度码（Data Length Code） 数据的字节数必须为 0～8 字节 数据段（Data Field） 数据段可包含 0～8 个字节的数据 CRC 段 CRC 段是检查帧传输错误的段，由 15 个位的 CRC 值和 1 个位的 CRC 界定符 (隐性分隔位) 构成 CRC 是根据多项式生成的 CRC 值，CRC 的计算范围包括帧起始、仲裁段、控制段、数据段 接收方以同样的方式计算 CRC 值并进行比较，不一致时利用错误帧请求重新发送 ACK 段 ACK 段包括 ACK 槽位、ACK 界定符位 2 个位 发送单元的 ACK 段：发送单元在 ACK 段发送 2 个位的隐性位 接收单元的 ACK 段：接收到正确消息的单元在 ACK 槽发送显性位，通知发送单元正常接收结束，这称作“发送 ACK”或者“返回 ACK” 帧结束 (End Of Frame，EOF) 帧结束是表示该帧结束的段，由发送节点发送 7 个位的隐性位构成 CAN 数据帧的结束符长度并不是完全不定的，而是根据数据位速率（Data Bit Rate，DBR）而定。CAN 总线协议规定，对于数据位速率低于等于 125kbps 的网络，CAN 数据帧的结束符长度为 7 个位；对于数据位速率大于 125kbps 的网络，CAN 数据帧的结束符长度为 3 个位。这是因为在高速网络中，由于数据传输速率更快，所以 CAN 控制器可以更快地检测到结束位，因此可以减少结束符的长度，从而提高网络的传输效率。而在低速网络中，由于数据传输速率较慢，所以 CAN 控制器需要更长的时间来检测结束位，因此需要一个更长的结束符来确保数据帧传输的正确性和完整性。因此，CAN 数据帧的结束符长度是根据数据位速率而定的，并不是完全不定的。 Socket CAN 帧结构体 帧头，canid_t 定义了一个无符号的 32 位整形数，按位确定功能 0-28 位为标识符，如果是扩展帧，则高 11 位为标准 ID 29 位标识是数据帧还是错误消息 30 位说明是否是远程帧 31 位说明是标准帧还是扩展帧。 帧长，8 位无符号表示数据区长度 数据区，定义 CAN_MAX_DLEN 个 8 位无符号数，按照数组的形式申请 *__attribute__((aligned(8))) 告诉编译器，将变量 data 放在一个地址是 8 的倍数的内存位置上。 /* CAN payload length and DLC definitions according to ISO 11898-1 */#define CAN_MAX_DLC 8#define CAN_MAX_DLEN 8struct can_frame canid_t can_id; /* 32 bit CAN_ID + EFF/RTR/ERR flags */ __u8 can_dlc; /* frame payload length in byte */ __u8 data[CAN_MAX_DLEN] __attribute__((aligned(8)));;/** Controller Area Network Identifier structure** bit 0-28 : CAN identifier (11/29 bit)* bit 29 : error message frame flag (0 = data frame, 1 = error message)* bit 30 : remote transmission request flag (1 = rtr frame)* bit 31 : frame format flag (0 = standard 11 bit, 1 = extended 29 bit)*/typedef __u32 canid_t;typedef unsigned char __u8; 帧类型定义如下： /* special address description flags for the CAN_ID */#define CAN_EFF_FLAG\t0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG\t0x40000000U /* 远程帧 */#define CAN_ERR_FLAG\t0x20000000U /* error frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK\t0x000007FFU /* 标准帧 (SFF) */#define CAN_EFF_MASK\t0x1FFFFFFFU /* 扩展帧 (EFF) */#define CAN_ERR_MASK\t0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 实际对 can_frame 发送的处理是在 mcp251x_hw_tx 中进行 static void mcp251x_hw_tx(struct spi_device *spi, struct can_frame *frame, int tx_buf_idx)\tstruct mcp251x_priv *priv = spi_get_drvdata(spi);\tu32 sid, eid, exide, rtr;\tu8 buf[SPI_TRANSFER_BUF_LEN];\t//取can_id的31位，判断是标准帧还是扩展帧\texide = (frame-can_id CAN_EFF_FLAG) ? 1 : 0; if (exide)//如果是扩展帧，can_id的0-28位为ID，其中高11位为标准ID sid = (frame-can_id CAN_EFF_MASK) 18;\telse sid = frame-can_id CAN_SFF_MASK; /* Standard ID */\teid = frame-can_id CAN_EFF_MASK; /* Extended ID */\trtr = (frame-can_id CAN_RTR_FLAG) ? 1 : 0; /* 是否是远程帧*/\tbuf[TXBCTRL_OFF] = INSTRUCTION_LOAD_TXB(tx_buf_idx); //发送缓冲器控制寄存器地址\tbuf[TXBSIDH_OFF] = sid SIDH_SHIFT; //发送缓冲器标准ID高8位\t//5-7位存放发送缓冲器低3位,3位存放帧格式，0-1位存放扩展标识符低18位的高两位（16-17）\tbuf[TXBSIDL_OFF] = ((sid SIDL_SID_MASK) SIDL_SID_SHIFT) | (exide SIDL_EXIDE_SHIFT) | ((eid SIDL_EID_SHIFT) SIDL_EID_MASK);\tbuf[TXBEID8_OFF] = GET_BYTE(eid, 1); //存放扩展标识符低18位的8-15位\tbuf[TXBEID0_OFF] = GET_BYTE(eid, 0); //扩展标识符低18位的低8位（0-7）\tbuf[TXBDLC_OFF] = (rtr DLC_RTR_SHIFT) | frame-can_dlc; //6位存放远程帧标识符，0-3存放数据长度码\tmemcpy(buf + TXBDAT_OFF, frame-data, frame-can_dlc);//拷贝要发送的数据\tmcp251x_hw_tx_frame(spi, buf, frame-can_dlc, tx_buf_idx);\t/* use INSTRUCTION_RTS, to avoid repeated frame problem */\tpriv-spi_tx_buf[0] = INSTRUCTION_RTS(1 tx_buf_idx);\tmcp251x_spi_trans(priv-spi, 1); 帧长度位填充 3bits Classic CAN Standard Frame标准帧（不考虑位填充）共：108Bit 帧起始（1bit）、仲裁段（12bit）、控制段（6bit）、数据段（8×8bit）、循环冗余码段（16bit）、应答段（2bit）和帧结束（7bit） Classic CAN Extended Frame扩展帧（不考虑位填充）共：128Bit 帧起始（1bit）、仲裁段（32bit）、控制段（6bit）、数据段（8×8bit）、循环冗余码段（16bit）、应答段（2bit）和帧结束（7bit） CANFD Standard Frame标准帧（不考虑位填充；DLC 8）共：117Bit 帧起始（1bit）、仲裁段（12bit）、控制段（9bit）、数据段（8×8bit）、循环冗余码段（22bit）、应答段（2bit）和帧结束（7bit） CANFD Standard Frame标准帧（不考虑位填充；DLC 64）共：569Bit 帧起始（1bit）、仲裁段（12bit）、控制段（9bit）、数据段（64×8bit）、循环冗余码段（26bit）、应答段（2bit）和帧结束（7bit） CANFD CAN Extended Frame扩展帧（不考虑位填充；DLC 8）共：136Bit 帧起始（1bit）、仲裁段（32bit）、控制段（8bit）、数据段（8×8bit）、循环冗余码段（22bit）、应答段（2bit）和帧结束（7bit） CANFD CAN Extended Frame扩展帧（不考虑位填充；DLC 64）共：588Bit 帧起始（1bit）、仲裁段（32bit）、控制段（8bit）、数据段（64×8bit）、循环冗余码段（26bit）、应答段（2bit）和帧结束（7bit） SocketCAN 实例CAN 功能分析一个标准的 CAN 功能包括： CAN 接口号指定 CAN 接口号 can0 指定 CAN 通讯波特率或 TQ，单位 Kbps，默认为 500 Kbps 指定 CAN 发送帧 ID 指定 CAN 发送帧数据 需要包含数据的大小端模式转换 指定 CAN 帧发送间隔，单位 ms， 默认为 250ms, 最小值为 1ms 指定 CAN 帧发送次数 指定 CAN 发送帧为标准帧扩展帧 发送数据时错误判断，本地环回功能基于 LINUX SOCKET 机制实现的 CAN 接口，其基本的流程如下所示： 设置套接字 socket 指定 CAN 设备 ioctl 绑定套接字与设备 bind 设置过滤规则 setsockopt 发送接受报文 read/write 关闭套接字 close 示例代码#include stdio.h#include stdlib.h#include string.h#include unistd.h#include sys/socket.h#include sys/types.h#include linux/can.h#include linux/can/raw.hint main() int sock; struct sockaddr_can addr; struct ifreq ifr; struct can_frame frames[10]; // 一次最多读取10个CAN数据包 struct msghdr msg; struct iovec iov; char ctrlmsg[CMSG_SPACE(sizeof(struct timeval) + 3 * sizeof(struct timespec) + sizeof(__u32))]; int nbytes; sock = socket(PF_CAN, SOCK_RAW, CAN_RAW); strcpy(ifr.ifr_name, can0); ioctl(sock, SIOCGIFINDEX, amp;ifr); memset(amp;addr, 0, sizeof(addr)); addr.can_family = AF_CAN; addr.can_ifindex = ifr.ifr_ifindex; bind(sock, (struct sockaddr *)amp;addr, sizeof(addr)); memset(amp;msg, 0, sizeof(msg)); memset(amp;iov, 0, sizeof(iov)); iov.iov_base = frames; iov.iov_len = sizeof(frames); msg.msg_name = amp;addr; msg.msg_namelen = sizeof(addr); msg.msg_iov = amp;iov; msg.msg_iovlen = 1; msg.msg_control = amp;ctrlmsg; msg.msg_controllen = sizeof(ctrlmsg); while (1) nbytes = recvmsg(sock, amp;msg, MSG_DONTWAIT); if (nbytes 0) int num_frames = nbytes / sizeof(struct can_frame); printf(Received %d CAN frames: , num_frames); for (int i = 0; i num_frames; i++) printf( ID: 0x%X, DLC: %d, Data: , frames[i].can_id, frames[i].can_dlc); for (int j = 0; j frames[i].can_dlc; j++) printf(%02X , frames[i].data[j]); printf( ); usleep(1000); close(sock); return 0; 初始化SocketCAN 中大部分的数据结构和函数在头文件 linuxcan.h 中进行了定义。 CAN 总线套接字的创建采用标准的网络套接字操作来完成。网络套接字在头文件 syssocket.h 中定义。 套接字的初始化方法如下： int s;struct sockaddr_can addr;struct ifreq ifr;s = socket(PF_CAN, SOCK_RAW, CAN_RAW);//创建SocketCAN 套接字strcpy(ifr.ifr_name, can0);ioctl(s, SIOCGIFINDEX, ifr);//指定 can0 设备addr.can_family = AF_CAN;addr.can_ifindex = ifr.ifr_ifindex;bind(s, (structsockaddr *)addr,sizeof(addr)); //将套接字与 can0 绑定 参数配置#include stdio.h#include stdlib.h#include string.h#include unistd.h#include fcntl.h#include linux/can.h#include linux/can/raw.h#include linux/can/error.h#include linux/can/netlink.h#include linux/sockios.h#include sys/ioctl.h#include sys/socket.h#include net/if.h#define CAN_INTERFACE can0#define BITRATE 500000#define DBITRATE 4000000int set_bitrate(const char *ifname, int bitrate, int dbitrate) struct ifreq ifr; struct can_bittiming bt; struct can_bittiming dbt; // Open socket int s = socket(PF_INET, SOCK_DGRAM, 0); if (s 0) perror(socket); return -1; // Specify the interface name strncpy(ifr.ifr_name, ifname, IFNAMSIZ); // Bring the interface down if (ioctl(s, SIOCGIFFLAGS, ifr) 0) perror(SIOCGIFFLAGS); close(s); return -1; ifr.ifr_flags = ~IFF_UP; if (ioctl(s, SIOCSIFFLAGS, ifr) 0) perror(SIOCSIFFLAGS); close(s); return -1; // Set bitrate for classical CAN memset(bt, 0, sizeof(bt)); bt.bitrate = bitrate; ifr.ifr_data = (void *)bt; if (ioctl(s, SIOCSCANBT, ifr) 0) perror(SIOCSCANBT); close(s); return -1; // Set data bitrate for CAN FD memset(dbt, 0, sizeof(dbt)); dbt.bitrate = dbitrate; ifr.ifr_data = (void *)dbt; if (ioctl(s, SIOCSCANDBT, ifr) 0) perror(SIOCSCANDBT); close(s); return -1; // Bring the interface up if (ioctl(s, SIOCGIFFLAGS, ifr) 0) perror(SIOCGIFFLAGS); close(s); return -1; ifr.ifr_flags |= IFF_UP; if (ioctl(s, SIOCSIFFLAGS, ifr) 0) perror(SIOCSIFFLAGS); close(s); return -1; // Close socket close(s); return 0;int main() const char *ifname = CAN_INTERFACE; int bitrate = BITRATE; int dbitrate = DBITRATE; if (set_bitrate(ifname, bitrate, dbitrate) 0) fprintf(stderr, Failed to set CAN interface settings ); return 1; printf(CAN interface %s configured with bitrate %d and dbitrate %d , ifname, bitrate, dbitrate); return 0; 参数查看ip -details -statistics link show can0 canconfig can0 数据发送在数据收发的内容方面， CAN 总线与标准套接字通信稍有不同，每一次通信都采用 can_ frame 结构体将数据封装成帧。 结构体定义如 Socket CAN 帧结构体 数据发送使用 write 函数来实现。 如果发送的数据帧 (标识符为 0x123) 包含单个字节 (0xAB) 的数据，可采用如下方法进行发送： struct sockaddr_can addr;struct can_frame frame;struct ifreq ifr;//如果为扩展帧，那么frame.can_id = CAN_EFF_FLAG | 0x123;frame.can_id = 0x123;frame.can_dlc = 1; //数据长度为 1frame.data[0] = 0xAB; //数据内容为 0xABint nbytes = write(s, frame, sizeof(frame));//发送数据nbytes = send(s, frame, sizeof(frame), 0);nbytes = sendto(s, frame, sizeof(frame), 0, (struct sockaddr *)addr, sizeof(addr));//sendmsg struct msghdr msg;struct iovec iov;memset(msg, 0, sizeof(msg));msg.msg_name = addr;msg.msg_namelen = sizeof(addr);iov.iov_base = frame;iov.iov_len = sizeof(frame);msg.msg_iov = iov;msg.msg_iovlen = 1;nbytes = sendmsg(s, msg, 0); 如果要发送远程帧 (标识符为 0x123)，可采用如下方法进行发送： struct can_frame frame;frame.can_id = CAN_RTR_FLAG | 0x123;write(s, frame, sizeof(frame)); 数据接收数据接收使用 read 函数来完成，实现如下： struct can_frame frame;int nbytes = read(s, frame, sizeof(frame));nbytes = recv(s, frame, sizeof(frame), /*0*/MSG_DONTWAIT);nbytes = recvfrom(s, frame, sizeof(frame), 0, (struct sockaddr *)addr, sizeof(addr));struct msghdr msg;struct iovec iov;memset(msg, 0, sizeof(msg));memset(iov, 0, sizeof(iov));iov.iov_base = frame;iov.iov_len = sizeof(frame);msg.msg_iov = iov;msg.msg_iovlen = 1;nbytes = recvmsg(s, msg, 0); 错误处理当帧接收后，可以通过判断 can_id 中的 CAN_ERR_FLAG 位来判断接收的帧是否为错误帧。 如果为错误帧，可以通过 can_id 的其他符号位来判断错误的具体原因。 错误帧的符号位在头文件 linux/can/error.h 中定义。 例如以下代码用于设置 CAN 接口的错误过滤器 can_err_mask_t err_mask;err_mask = CAN_ERR_ACK | CAN_ERR_CRTL | CAN_ERR_BUSOFF | CAN_ERR_BUSERROR;ret = setsockopt(interface-fd, SOL_CAN_RAW, CAN_RAW_ERR_FILTER, err_mask, sizeof(err_mask));if(ret 0)\tlog_printf(LOG_ERR, CAN_ERROR_FILTER_FAILED, interface-ifName);\tlog_printf(LOG_DEBUG, DBG_ERRNO, setsockopt(can err));\treturn CO_ERROR_SYSCALL; CAN_ERR_ACK, CAN_ERR_CRTL, CAN_ERR_BUSOFF, CAN_ERR_BUSERROR 是 CAN 错误的不同类型。这些标志位分别表示收到错误应答、控制器错误、总线关闭、总线错误。 SOL_CAN_RAW 表示操作的是原始 CAN 套接字。 CAN_RAW_ERR_FILTER 是设置原始 CAN 套接字的错误过滤器选项。 过滤规则设置在数据接收时，系统可以根据预先设置的过滤规则，实现对报文的过滤。过滤规则使用 can_filter 结构体来实现，定义如下： struct can_filter canid_t can_id;\tcanid_t can_mask;; 过滤器工作原理：CAN 过滤器使用按位与（）操作来决定是否接收一个帧。 if ((received_can_id filter.mask) == (filter.can_id filter.mask)) // 接收此帧else // 丢弃此帧 通过这条规则可以在系统中过滤掉所有不符合规则的报文，使得应用程序不需要对无关的报文进行处理。在 can_filter 结构的 can_id 中，符号位 CAN_INV_FILTER 在置位时可以实现 can_id 在执行过滤前的位反转。 用户可以为每个打开的套接字设置多条独立的过滤规则，使用方法如下： structcan_filter rfilter[2];rfilter[0].can_id = 0x123;rfilter[0].can_mask = CAN_SFF_MASK;//#define CAN_SFF_MASK 0x000007FFUrfilter[1].can_id = 0x200;rfilter[1].can_mask = 0x700;//设置规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER,rfilter, sizeof(rfilter)); 第一个过滤器 (rfilter): can_id: 0x123mask: 0x7FF (CAN_SFF_MASK)这个过滤器将只接收 ID 为 0x123 的标准帧。因为掩码是 0x7FF，所以 ID 必须完全匹配。 第二个过滤器 (rfilter): can_id: 0x200mask: 0x700 这个过滤器将接收 ID 范围从 0x200 到 0x2FF 的帧。因为： 0x200 0x700 = 0x200 任何 0x2XX 的 ID 与 0x700 进行按位与操作后都等于 0x200 过滤规则禁用。原始套接字就会忽略所有接收到的报文。在仅需要发送数据的应用中，可以在内核中省略接收队列，以此减少 CPU 资源的消耗。禁用方法如下： //禁用过滤规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER, NULL, 0); 通过错误掩码可以实现对错误帧的过滤， 例如： can_err_mask_t err_mask = (CAN_ERR_TX_TIMEOUT | CAN_ERR_BUSOFF );setsockopt(s, SOL_CAN_RAW,CAN_RAW_ERR_FILTER,err_mask,sizeof(err_mask)); 缓冲区大小设置以下代码用于设置缓冲区大小为 512KB，并查询设置之后的缓冲区大小 //todo - modify rx buffer size? first one needs rootbytes = 512*1024;sLen = sizeof(bytes);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUFFORCE, (void *)bytes, sLen);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUF, (void *)bytes, sLen);/* print socket rx buffer size in bytes (In my experience, the kernel reserves * around 450 bytes for each CAN message) */sLen = sizeof(bytes);getsockopt(interface-fd, SOL_SOCKET, SO_RCVBUF, (void *)bytes, sLen);if (sLen == sizeof(bytes)) log_printf(LOG_INFO, CAN_SOCKET_BUF_SIZE, interface-ifName, bytes / 446, bytes); root 用户使用 SO_RCVBUFFORCE 设置缓冲区大小。 普通用户使用 SO_RCVBUF 设置缓冲区大小 回环功能设置在默认情况下， 本地回环功能是开启的，可以使用下面的方法关闭回环开启功能： int loopback = 0; // 0 表示关闭, 1 表示开启( 默认)setsockopt(s, SOL_CAN_RAW, CAN_RAW_LOOPBACK,loopback, sizeof(loopback)); 在本地回环功能开启的情况下，所有的发送帧都会被回环到与 CAN 总线接口对应的套接字上。 默认情况下，发送 CAN 报文的套接字不想接收自己发送的报文，因此发送套接字上的回环功能是关闭的。 可以在需要的时候改变这一默认行为： int ro = 1; // 0 表示关闭( 默认), 1 表示开启setsockopt(s, SOL_CAN_RAW, CAN_RAW_RECV_OWN_MSGS, ro, sizeof(ro)); 套接字状态利用 ioctl() 检查套接字状态 使用 ioctl() 函数结合 FIONREAD 命令可以查询当前套接字接收缓冲区中等待读取的字节数。如果返回的字节数大于 0，则表示有数据可供接收。示例代码如下： int bytes_available;ioctl(sock, FIONREAD, bytes_available);if (bytes_available 0) printf(套接字中有 %d 字节的CAN数据可接收 , bytes_available); // 现在可以读取数据 // ... else printf(套接字中没有可接收的CAN数据 ); ioctl() 函数和 SIOCSIFFLAGS ioctl() 函数：这是一个系统调用函数，用于在用户空间程序中向内核发出特定的控制命令，以实现对设备、接口等的配置和管理。 SIOCSIFFLAGS：这是 ioctl() 函数使用的一个常量，用于设置网络接口的标志。通过 ioctl() 和 SIOCSIFFLAGS，可以启用或禁用一个网络接口，设置接口的工作模式和其他标志位。 CAN 通讯设计硬件ARM 需要有 CAN 控制器和 CAN 收发器 CAN 控制器（CAN Controller）是负责实现 CAN 协议的逻辑部分的组件 CAN 收发器（CAN Transceiver）是负责 CAN 总线电平信号和 CAN 控制器之间的电信号转换的组件 CAN 控制器示例： 内置于微控制器中的 CAN 模块（例如 STM32 系列微控制器的内置 CAN 控制器）。 独立的 CAN 控制器芯片（例如 MCP2515）。 CAN 收发器示例： 常见的独立 CAN 收发器芯片（例如 MCP2551、TJA1050 等）。 先选择 CAN 控制器芯片，一般的 PC 和 ARM 都没有 CAN 控制器，一般是 MCP2515 和 SJA1000，主要区别是 MCP2515 是 SPI 接口，SJA1000 是 IO 接口。所以 MCP2515 占用资源少，5-6 个管脚就可以控制，SJA1000 占用的管脚就多。 内核Linux 中有对 CAN（Controller Area Network）总线的支持，主要通过 SocketCAN 子系统实现。内核编译时选择响应的支持芯片。 $ make linux-menuconfigNetworking support ---\tCAN bus subsystem support ---\t--- CAN bus subsystem support Raw CAN Protocol (raw access with CAN-ID filtering) Broadcast Manager CAN Protocol (with content filtering) CAN Device Drivers --- Virtual Local CAN Interface (vcan) Platform CAN drivers with Netlink support [*] CAN bit-timing calculation Microchip 251x series SPI CAN Controller SocketCAN 支持多种 CAN 控制器硬件，通过不同的内核驱动程序实现对具体硬件的支持。例如，以下是一些常见的 CAN 控制器驱动程序： sja1000：PhilipsNXP SJA1000 CAN 控制器 mcp251x：Microchip MCP251x SPI CAN 控制器系列（如 MCP2515） flexcan：FreescaleNXP FlexCAN 模块 这些驱动程序通常位于内核源代码树的 drivers/net/can 目录下。 驱动需要支持 CAN 控制器驱动，控制 CAN 控制器发送 CAN 帧。对于一般的 CAN 控制器，进行初始化时，最关键的是以下两步： 配置 CAN 的位时序； 配置 CAN 的消息报文； 应用程序CAN 数据发送跟踪当我们在用户层通过 socket 进行 CAN 数据的发送时，需要进行以下操作： 创建一个套接字 socket，采用 AF_CAN 协议。 将创建的套接字返回描述符 sockfd，绑定到本地的地址。 通过 sendto 系统调用函数进行发送，sendto 的系统调用会发送一帧数据报到指定的地址，在 CAN 协议调用之前把该地址移到内核空间和检查用户空间数据域是否可读。 在 net/socket.c 源文件中，在 sendto 的系统调用 （sys_sendto） 里，会调用到 sock_sendmsg() 函数，接下来调用 __sock_sendmsg() 函数。 再往下一步就是 __sock_sendmsg_nosec 函数。在 __sock_sendmsg_nosec() 函数中会返回一个 sendmsg 函数指针。 在 /net/can/raw.c 源文件中，将 raw_sendmsg 函数地址赋给 sendmsg 函数指针，即在函数 __sock_sendmsg_nosec() 中 return sock-ops-sendmsg(iocb,sock, msg, size)，返回的函数指针将指向 raw_sendmsg() 函数。 在 net/can/af_can.c 源文件中，can_send 函数负责 CAN 协议层的数据传输，即传输一帧 CAN 报文（可选本地回环）。参数 skb 指针指向套接字缓冲区和在数据段的 CAN 帧。loop 参数是在本地 CAN 套接字上为监听者提供回环。 以下开始进行到 CAN 的底层驱动代码了，由于 CAN 驱动是编译进内核中，所以在系统启动时会注册 CAN 驱动。 注册 CAN 驱动过程中会初始化 d_can_netdev_ops 结构体变量。 在这个过程中，d_can_netdev_ops 结构体变量定义了 3 个函数指针，其中 (*ndo_start_xmit) 函数指针指向 d_can_start_xmit 函数的入口地址。 在 d_can_start_xmit() 函数中，会调用 d_can_write_msg_object() 函数准备消息报文进行传输。 CAN 数据接收跟踪对于网络设备，数据接收大体上采用中断 +NAPI 机制进行数据的接收。同样，我们现在的 CAN 模块也是采用同样的方式进行数据的接收。由于我们只针对 CAN 总线接收数据这条主线进行分析。因些，会忽略一些针对 CAN 协议的设置及初始化等相关代码。 NAPI（New API）是一种改进的网络数据接收机制，它通过减少中断处理的次数来提高性能。NAPI 的基本思想是延迟数据包的处理，使得多个数据包可以一次性地在中断处理程序中进行处理，从而减少了中断的数量，提高了系统的处理效率。 中断 +NAPI 机制的工作原理大致如下： 当网络数据包到达时，网络接口卡会生成一个中断通知操作系统。 中断服务程序会执行一些必要的处理，然后调用 NAPI 机制。 NAPI 机制会检查网络接口缓冲区中是否有足够的数据需要处理。 如果有足够的数据，NAPI 会立即开始处理这些数据，而不会再次触发中断。如果数据量不足，NAPI 会退出，并要求在将来的某个时候再次调用。 处理完数据后，系统可以选择性地决定是否重新启用中断服务程序。 通过将数据包的处理延迟到一组数据包到达时再进行，中断 +NAPI 机制能够大大减少中断的数量，提高系统的处理效率，特别是在高负载情况下。 在初始化 CAN 设备时，我们需要给 CAN 设备分配 NAPI 功能。我们通过 netif_napi_add() 函数将 CAN 设备添加到 NAPI 机制列表中。 将 CAN 设备添加到 NAPI 机制列表中后，在中断处理函数 d_can_isr 中，我们通过 napi_schedule() 函数调度已经在 NAPI 机制列表中的 d_can_poll() 函数。该函数会通过轮询的方式接收数据。而根据 NAPI 机制，当中断产生后，会调度轮询机制同时关闭所有的中断。 当中断产生时，会调用函数 d_can_poll()，该函数即采用轮询的方式进行数据的接收。由于 CAN 总线状态中断具有最高优先权，在接收数据之前，需要对 CAN 总线的状态进行判断。而对于 CAN 总线错误状态有三种：主动被动关闭。 当总线状态数据状态正常时，从 CAN 模块的接收寄存器中接收数据。 测试要在 linux 下面配置和测试 CAN，需要安装以下三个组件。 iproute2 （配置 CAN 接口时需要） libsocketcan（使用 CAN 必须） CAN 的测试小工具 can-utils https://github.com/linux-can/can-utils 可以直接通过命令行形式控制 CAN # 配置CAN接口（假设设备名为`can0`）：ip link set can0 up type can bitrate 500000# 启动CAN接口ip link set up can0# 查看CAN接口状态ip -details link show can0# CAN 2.0 linkupip link set can0 up type can bitrate 100000# CAN 2.0 FD linkupip link set can0 up type can bitrate 500000 dbitrate 2000000 fd on# 命令来配置 CAN 总线的位速率：ip link set can0 type cantq 125 prop-seg 6 phase-seg1 7 phase-seg2 2 sjw 1# 可以使用 ip 命令直接设定位速率500kbps：ip link set can0 type can bitrate 500000# 当设置完成后，可以通过下面的命令查询 can0 设备的参数设置：ip -details link show can0# 当设置完成后，可以使用下面的命令使能 can0 设备：ifconfig can0 up# 使用下面的命令取消 can0 设备使能：ifconfig can0 down# 在设备工作中，可以使用下面的命令来查询工作状态：ip -details -statistics link show can0 负载计算在 CAN 总线上，发送一帧数据所需的时间可以通过帧的总位数和波特率来计算。 发送时间计算 发送时间 = 总位数 / 波特率= 111 位 / 500000 位/秒= 222 * 10^-6 秒 总线负载计算，是总线实际使用的带宽与总带宽的比值，通常表示为百分比。 总线负载 = ((总帧时间秒×每秒发送的帧数)/总可用时间秒)×100%总帧时间：一帧数据的发送时间每秒发送的帧数：一秒钟内发送的帧数总可用时间：每秒可用的时间，即 1 秒 假设每秒发送 1000 帧数据，则 1 秒内该总线上的负载为： 总帧时间：222 微秒 = 222 * 10^-6 秒每秒发送的帧数：1000 帧/秒总可用时间：1 秒总线负载=((222*10^−6 * 1000) / 1)×100%总线负载=22.2% Qt 中的 CAN 插件需要编译安装 socketCAN 插件， https://doc.qt.io/qt-5/qtserialbus-socketcan-overview.html ，关键字【Using SocketCAN Plugin】 pro 文件中添加 QT += serialbus QString errorString;const QListQCanBusDeviceInfo devices = QCanBus::instance()-availableDevices(QStringLiteral(socketcan), errorString);if (!errorString.isEmpty())\tqDebug() errorString; 多线程下利用线程权限进行高速的 CAN 通信用 PC 里能达到的 CAN 通信（使用 USBCAN-II）速度是 1ms 使用 3 个线程类：1 个用来接收，1 个用来发送，1 个用来解析 接收线程使用最高线程权限：QThread::HighestPriority，其余线程用 QThread::HighPriority 如何循环发送报文：在发送线程里再多加一个定时器，timeout 时间为需要循环发送的时间（可达到 1ms）； 用户在主界面设置需要发送的报文为 OBJ 结构体数组，然后通过构造函数的方式传到发送线程，最后发送就行了。 解析过程：接收函数循环接收报文，每接收到 n 帧就发送到解析线程，然后根据 ID 解析，将解析数据发送主界面显示（不要 append） 问题记录RK3568 在高速接收 CAN 帧消息时，出现 RCU 告警 rcu INFO: rcu_sched self-detected stall on CPU，CPU 占用跑满，该问题原因是错误帧中断过多导致的系统卡顿问题。 原因为 RK3568 默认的 CAN 驱动位 CANFD，调整设备树中的驱动为 CAN 后正常接收。 《Rockchip RK3568RK3568B2RK3568J Application Notice-RKAN18055》中提到存在以下设计缺陷：RK3568 作为发送方，扩展帧概率性变成标准帧，导致接收方存在丢帧情况，进而影响设备的正常通讯或者控制。产生原因是在发送扩展帧时候，内部寄存器状态值在特定组合条件下，触发 load 失败，从而最后按标准帧而非扩展帧的格式来发送 ID 和 DLC 段。RK3568 作为 接收方 概率性出现 CRC 校验错误和 ID 段填充位错误 ，导致接收方会往总线发送错误帧，由发送方进行重发。 3568 原生 CAN 驱动使用自收方案修改 kernelarcharm64bootdtsrockchiprk3568.dtsi 文件，注释掉下图部分，取消 workround 帧的配置，修改后会自动打开 CAN 的 TXtoRX，原生 CAN 发送扩展帧数据时，会收回自己发出的数据做校验，若校验不是扩展帧将重新发送一帧。 注意：此方案在扩展出来的 ID 部分 ID 为 0 时，会触发无限重发机制，慎用。","categories":["2.通讯协议","CAN"]},{"title":"shell介绍","path":"/2024/05/17/1-语言-Shell-shell介绍/","content":"shellshell 是一个编程语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支；也是一个命令行解释器，交互式地解释和执行用户输入的命令；还是内核的保护工具，它调用了系统核心的大部分功能来执行程序、建立文件并以并行的方式协调各个程序的运行。 Shell 有两种执行命令的方式： 交互式（Interactive）：解释执行用户的命令，用户输入一条命令，Shell 就解释执行一条。 批处理（Batch）：用户事先写一个 Shell 脚本 (Script)，shell 脚本是 shell 命令的有限序列，将各类命令预先放入其中，方便一次性执行的一个程序文件，主要用于方便管理员进行设置或者管理，而不必一条一条地敲命令。 Shell 脚本是解释执行的，不需要编译，Shell 程序从脚本中一行一行读取并执行这些命令，相当于一个用户把脚本中的命令一行一行敲到 Shell 提示符下执行 Linux 的 Shell 种类众多，常见的有：Bourne Shell（usrbinsh 或binsh）、Bourne Again Shell（binbash）、C Shell（usrbincsh）、K Shell（usrbinksh）、Shell for Root（sbinsh）等等。 不同的 Shell 语言的语法有所不同，所以不能交换使用。我们关注的重点是 Bash，Bash 也是大多数 Linux 系统默认的 Shell。在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，在下面的文字中，我们可以看到#!binsh，它同样也可以改为#!binbash。 编写 Shell 脚本的格式是固定的，一个简单的 shell 脚本如下： #!/bin/sh#print hello world in the console windowa = hello worldecho $a 首行中的符号 #! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。 如果首行没有这句话，在执行脚本文件的时候，将会出现错误。 后续的部分就是主程序，Shell 脚本像高级语言一样，也有变量赋值，也有控制语句。 除第一行外，以#开头的行就是注释行，直到此行的结束。 如果一行未完成，可以在行尾加上 “，这个符号表明下一行与此行会合并为同一行。 编辑完毕，将脚本存盘为 filename.sh，文件名后缀 sh 表明这是一个 Bash 脚本文件。执行方式： 1.加可执行权限 chmod u+x filename.sh ./filename.sh2.执行通过bash运行 /bin/bash filename.sh3.将路径添加到环境变量 chmod u+x filename.sh PATH+=:/home/fs/Temp filename.sh //任意目录运行4.添加到bin文件夹 chmod u+x filename.sh sudo mv filename.sh /bin/ 注意，一定要写成.filename.sh，而不是 filename.sh。运行其它二进制的程序也一样，直接写 filename.sh，linux 系统会去 PATH 里寻找有没有叫 filename.sh 的，而只有bin, sbin, usrbin，usrsbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 filename.sh 是会找不到命令的，要用.filename.sh 告诉系统说，就在当前目录找。 速查表 命令 含义 %!xxd 将二进制文件转换为 16 进制和 ASCII 表形式查看 * 代表通配符，可代表任意长度的任意字符； ？ 可代表单个长度的任意字符 [] 通配括号中的元素 [^……] 除去括号中的元素，其他通配 file 将输出重定向到 file 中去（新建） file 将输出重定向到 file 中去（追加模式） file 将 file 作为标准输入 2 或 –标准错误 pipe 管道,将第一个命令的输出作为第二个命令的输入 shell 命令使用 tab 补齐：命令 文件名 路径 history ：查看命令历史 通配符 *：匹配任意长度任意字符串 管道 |：第一个指令的输出作为第二个指令的输入：ls /usr/bin | wc -l 重定向 : 命令置换：反撇号 ls `pwd` 常用命令 用户管理命令 进程管理命令 通配符*?[...][-][^...][a-z, ABC] // 表示匹配a到z和A,B,C中任意一个字符ls file[3-4][5-9].c /*表示名匹配文件名含[3-4]中的一个字符和[5-9]中的一个字符，两个字符的共两个字符的文件名都符合规则。*/ 管道| 将第一个命令的正确输出内容 通过管道输出给 第二个命令作为输入.要求第一个命令有输出，第二个命令有输入功能。 重定向echo hello world test 将内容输出到文件 test 中。 echo hello Eric test 将字符串内容追加到 test 中,在 test 原有的内容上添加 2 2 将报错信息重定向或追加到指定文件. 将正确信息和错误信息一起重定向或追加到指定文件。 0 标准输入 stdin 1 标准输出 stdout ‘ ’ main() return ; fflush(stdout); 2 标准出错 stderr /dev/null 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 cat /dev/null ~/.bash_history // 利用/dev/null清空指定文件。/dev/zero command file 将输出重定向到 file。 command file 将输入重定向到 file。 command file 将输出以追加的方式重定向到 file。 n file 将文件描述符为 n 的文件重定向到 file。 n file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n m 将输出文件 m 和 n 合并。 n m 将输入文件 m 和 n 合并。 tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 管道和重定向的比较command1 | command2 左输出 | 右输入 command file 左输出 右文件 command file 左输入 右文件 管道的命令同时执行,command2 等待 command1 的输出 (阻塞) 重定向是有优先级的,由进程优先级决定. 常用命令less/more alias 定义别名 alias md=mkdirmd dir1 dir2 //md就是mkdir了,这里创建了两个目录(文件夹)dir1和dir2. head/tail sort 排序命令 cat /etc/passwd | sort -t: -k 4 -n //-t指定分隔符 -k 4 指定分隔后的段, -n 完整比较。manman 1 可执行程序或Shell命令man 2 ?man 3 ? 用户管理命令adduserdeluser --remove-home //删除用户的同时，删除其工作目录chownchown xiaomeng jielun //将文件jielun的所有者改为xiaomeng.su 切换用户passwd 修改密码sudo //用超级用户权限执行一次命令；sudo passwd //普通用户修改root用户密码;usermodusermod -l Ez xiaoming //更改用户名xiaoming为Ez,要保证用户不在登陆状态; 相关文件: /etc/passwd/etc/shadow/etc/skel//etc/group/etc/gshadowchmod 改变文件读写执行权限rw- r-- r--110 100 1006 4 4| | |其他用户| |组用户权限|所属者的权限Xm 进程管理信息进程的概念:程是指正在执行的程序的实例。每个运行的程序都在系统中作为一个进程存在。进程是操作系统进行任务调度和资源管理的基本单位，它拥有自己的内存空间、执行代码、数据和资源。进程之间相互独立，彼此隔离，这样可以确保一个进程的异常不会影响其他进程的正常运行。进程与程序的区别:程序是一组静态的指令和数据的集合，它们存储在磁盘上；而进程是程序的实例，是程序在内存中的执行过程。程序只是静态的代码和数据的集合，而进程是具有动态特性、在系统中运行的实体。 进程 程序 定义 进程是正在运行的程序的实例。在操作系统中，进程代表了一个独立的执行单元，拥有自己的内存空间、程序代码、数据和资源。每个运行的程序都以进程的形式存在。 程序是一组指令和数据的集合，它是静态的、存储在磁盘上的文件，描述了如何执行特定任务。程序本身并不占用系统资源，只有在被加载到内存并运行时，才成为一个进程。 特性 进程是一个动态的实体，具有生命周期，可以处于运行、就绪、阻塞、挂起等不同状态，而且进程之间相互独立，彼此隔离。 程序是一个静态的实体，只是存储在磁盘上的文件，并不具有自己的执行状态和资源。 生命周期 进程从创建、运行到终止，进程有一个明确的生命周期。当进程终止时，它占用的资源会被操作系统回收。 程序本身没有生命周期，只有在被加载到内存并执行为进程后，才会有生命周期。 进程和程序之间是一种从程序到进程的实例化关系。当运行一个程序时，操作系统会为该程序创建一个对应的进程，使得程序在内存中得以执行。 进程的查看: ps -auxps -elf 进程的几种状态: 运行（Running）：表示进程正在运行或正在执行。 就绪（Ready）：表示进程已经准备好运行，但由于系统资源限制或其他进程的运行，它暂时还没有得到处理器的分配。 阻塞（Blocked）：也称为等待（Waiting），表示进程由于等待某个事件的发生（如 IO 操作完成、信号等）而暂停执行，直到事件发生才能继续运行。 挂起（Suspended）：表示进程被暂时挂起，不占用 CPU 资源，并且可能被放置在磁盘上。这种状态通常用于系统中的一些特殊情况，如进程被调试或由于内存不足而被置换出来。 shell 命令行下查找在当前目录下所有文件中查找内容包含 string 的文件并列出字符所在的文件,所在行及所在行的内容: find ./ -name * -exec grep -n string ./ \\; 使用 find 查找时希望忽略某个目录 (-prune): 如果希望在app 目录下查找文件，但不希望在appbin 目录下查找: find /app -name /app/bin -prune -o -print 使用 type 选项: 如果要在etc 目录下查找所有的目录: find /etc -type d -print 如果要在etc 目录下查找.svn 的目录: find /etc -name .svn -type d -print 为了在当前目录下查找除目录以外的所有类型的文件: find . ! -type d -print 为了在当前目录下查找所有的符号链接文件，可以用: find . -type | -print 为了用 ls -l 命令列出所匹配到的文件，可以把 ls -l 命令放在 find 命令的 -exec 选项中: find . -type f -exec ls -l \\; 注：f 表示普通文件 shell 脚本各种执行方式source ./*.sh . ./*.sh ./*.sh 的区别 ./*.sh 的执行方式等价于 sh ./*.sh 或者 bash ./*.sh， 此三种执行脚本的方式都是重新启动一个子 shell,在子 shell 中执行此脚本。 .source ./*.sh 和 . ./*.sh 的执行方式是等价的，即两种执行方式都是在当前 shell 进程中执行此脚本，而不是重新启动一个 shell 而在子 shell 进程中执行此脚本。验证依据：没有被 export 导出的变量（即非环境变量）是不能被子 shell 继承的验证结果： [root@localhost ~]#name=dangxu //定义一般变量[root@localhost ~]# echo $namedangxu[root@localhost ~]# cat test.sh //验证脚本，实例化标题中的./*.sh#!/bin/shecho $name[root@localhost ~]# ls -l test.sh //验证脚本可执行-rwxr-xr-x 1 root root 23 Feb 611:09 test.sh[root@localhost ~]# ./test.sh //以下三个命令证明了结论一[root@localhost ~]# sh ./test.sh[root@localhost ~]# bash ./test.sh[root@localhost ~]# . ./test.sh //以下两个命令证明了结论二dangxu[root@localhost ~]# source ./test.shdangxu[root@localhost ~]#","categories":["1.语言","Shell"]},{"title":"正则表达式笔记","path":"/2024/05/17/1-语言-工具语言-正则表达式笔记/","content":"正则表达式什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。 正则表达式就是记录文本规则的代码，用于模式匹配和搜索文本的工具。 正则表达式的模式 字面值字符：普通字符按照字面意义进行匹配,例如字母、数字、空格等，可以直接匹配它们自身。 特殊字符：例如点号 .、星号 *、加号 +、问号 ? 等，它们具有特殊的含义和功能。 字符类：用方括号 [ ] 包围的字符集合，用于匹配方括号内的任意一个字符。[^ ] 匹配除了括号内的字符以外的任意一个字符 元字符：例如 \\d、\\w、\\s 等，用于匹配特定类型的字符，如数字、字母、空白字符等。 量词：例如 n、n,、n,m 等，用于指定匹配的次数或范围。 边界符号：例如 ^、$、\\b、\\B 等，用于匹配字符串的开头、结尾或单词边界与非边界位置。 分组和捕获：( )：用于分组和捕获子表达式。(?: )：用于分组但不捕获子表达式。 字符字符匹配直接在方括号里列出： [aeiou] 就匹配任何一个英文元音字母 [.?!] 匹配标点符号 (.或?或!) 也可以指定一个字符范围： [0-9] 代表的含意与\\d 就是完全一致的：一位数字 [a-z0-9A-Z_] 也完全等同于\\w。 普通字符 字符 含义 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（ 、\\r）之外的任何单个字符，相等于 [^ \\r]。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] 非打印字符 字符 含义 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 特殊字符 字符 含义 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则$ 也匹配 ‘ ’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。 * 匹配前面的子表达式零次或多次。要匹配 * 字符，请使用*。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。 . 匹配除换行符 之外的任何单字符。要匹配 . ，请使用 . 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 [。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’ ’ 匹配换行符。序列 ‘ 匹配 “，而 ‘(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用^。 { 标记限定符表达式的开始。要匹配 {，请使用 {。 | 指明两项之间的一个选择。要匹配|，请使用 |。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。例如 IP 地址表达式:((2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?).)3(2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?) 限定符 字符 含义 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于 {0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 “do” 、 “does”、 “doxy” 中的 “do” 和 “does”。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 含义 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 或 \\r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 或 \\r 之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 不能将限定符与定位符一起使用。由于在紧靠换行或者单词边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式 转义字符与反义字符 在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。 反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法 (?#comment) 来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。 如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。 前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样 .*? 就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 现在看看懒惰版的例子吧： a.*?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，” 或 “ 操作,字符具有高于替换运算符的优先级，使得m 反向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本 (也就是此分组捕获的内容) 可以在表达式或其它程序中作进一步的处理。 反向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b 可以用来匹配重复的单词，像 go go, 或者 kitty kitty。 总结 确定需要匹配的基本字符或字符类别集合等 确定匹配的字符或字符集合的数量 特殊字符和转义字符的处理 边界和位置的匹配 使用捕获组 () 进行多组匹配 使用反向引用 使用逻辑操作符进行判定 正则表达式字符含义表 字符 含义 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 “n”。\\ 匹配一个换行符。序列 \\\\ 匹配 “\\ 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \\ 或 \\\\r 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 \\ 或 \\\\r 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o2 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o2, 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o1, 等价于 o+。o0, 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。o0,1 等价于 o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，o+? 将匹配单个 “o”，而 o+ 将匹配所有 o。 . 匹配除换行符（ 、\\r）之外的任何单个字符。要匹配包括 \\ 在内的任何字符，请使用像 (. ) 的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在 VBScript 中使用 SubMatches 集合，在 JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ( 或 )。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “ 或 “ 字符 ( ) 来组合一个模式的各个部分是很有用。例如， industr(?:y (?pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，Windows(?95 98 (?!pattern) 正向否定预查 (negative assert)，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如 Windows(?!95 98 (?pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，(?95 98 (? 反向否定预查，与正向否定预查类似，只是方向相反。例如 “(?” 能匹配 “3.1Windows” 中的 “Windows”，但不能匹配 “2000Windows” 中的 “Windows”。 x y 匹配 x 或 y。例如，z [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 “plain” 中的 a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，[^abc] 可以匹配 “plain” 中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\\\\b 可以匹配”never” 中的 er，但不能匹配 “verb” 中的 er。 \\B 匹配非单词边界。er\\\\B 能匹配 “verb” 中的 er，但不能匹配 “never” 中的 er。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的c 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\\\x41 匹配 “A”。\\\\x041 则等价于 \\\\x04 “1”。正则表达式中可以使用 ASCII 编码。 um 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)\\\\1 匹配两个连续的相同字符。 标识一个八进制转义值或一个向后引用。如果 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 m 标识一个八进制转义值或一个向后引用。如果 m 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 m 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 m 将匹配八进制转义值 nm。 ml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。","categories":["1.语言","工具语言"]},{"title":"USB挂载监测","path":"/2024/05/17/2-通讯协议-USB-USB挂载监测/","content":"功能程序监测到插入U盘后，自动执行执行U盘内和本地指定文件夹双向同步功能 要点 Linux 下如何用 QT 检测到 U 盘已经插入，并实现 mount 与 umount 实现方式使用 qt 自带的 QDBus 可以实现，下面为连接代码，当系统有设备插入时，可以调用 slotDeviceAdded(QString udi) 函数。 在 pro 文件中应该加入 QT +=dbus #include QtDBus/QDBusConnection#include QDbusInterface//以下为检测设备的插入 QDBusConnection::systemBus().connect( org.freedesktop.Hal, /org/freedesktop/Hal/Manager, org.freedesktop.Hal.Manager, DeviceAdded, this, SLOT(slotDeviceAdded(QString )));//以下为检查设备的拨出 QDBusConnection::systemBus().connect( org.freedesktop.Hal, /org/freedesktop/Hal/Manager, org.freedesktop.Hal.Manager, DeviceRemoved, this, SLOT(slotDeviceRemoved(QString ))); 在 slotDeviceAdded(QString udi) 函数中，要使用到 QDBusInterface device(org.freedesktop.Hal, udi, org.freedesktop.Hal.Device , QDBusConnection::systemBus()); 通过 HAL 可以查询到设备为 volume 的设备，然后通过判断是否为devsd 的设备，就可以判断出是否为 U 盘，然后调用 mount 就可以了。 这时记录下 U 盘的 UDI，在检测到设备拨出时，再查询一下 U 盘的 UDI 是否还在，就知道 U 盘是否被拨出了。","categories":["2.通讯协议","USB"]},{"title":"Ollama项目","path":"/2024/05/17/3-软件-AI-Ollama项目笔记/","content":"https://huggingface.co/ Llama 中文社区 https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file 安装Linuxcurl -fsSL https://ollama.com/install.sh | sh 支持的模型访问地址 https://ollama.com/library ollama.exe list 列出本地模型 ollama run qwen 运行 qwen 模型，如果没有则下载 NAME SIZE FEATURES codellama:latest 3.8 GB llama3:latest 4.7 GB starcoder2:3b 1.7 GB qwen:4b 2.3G nomic-embed-text 配置更换保存位置WindowsWindows 下 Ollama 默认使用系统盘（一般为 C 盘）来存放模型文件，先来看看帮助: ollama.exe serve --help 返回 Start ollamaUsage: ollama serve [flags]Aliases: serve, startFlags: -h, --help help for serveEnvironment Variables: OLLAMA_HOST The host:port to bind to (default 127.0.0.1:11434) OLLAMA_ORIGINS A comma separated list of allowed origins. OLLAMA_MODELS The path to the models directory (default is ~/.ollama/models) OLLAMA_KEEP_ALIVE The duration that models stay loaded in memory (default is 5m) 从帮助文件可以看，我们通过设置环境变量（OLLAMA_MODELS）来指定模型目录，可以通过系统设置里来配置环境变量（系统变量或者用户变量），也可以通过命令行来配置 set OLLAMA_MODELS=d:\\ollama Linux默认地址是~.ollamamodels， 如果想移到别的目录，同样是设置环境变量 OLLAMA_MODELS export OLLAMA_MODELS=/data/ollama 导出模型这里以 qwen:7b 为例，先查看模型信息， ollama show --modelfile qwen:7b 返回 # Modelfile generated by ollama show# To build a new Modelfile based on this one, replace the FROM line with:# FROM qwen:7bFROM /Users/m2max/.ollama/models/blobs/sha256-87f26aae09c7f052de93ff98a2282f05822cc6de4af1a2a159c5bd1acbd10ec4TEMPLATE if .System |im_start|system .System |im_end| end |im_start|user .Prompt |im_end||im_start|assistantPARAMETER stop |im_start|PARAMETER stop |im_end| 从模型文件信息里得知 /Users/m2max/.ollama/models/blobs/sha256-46bb65206e0e2b00424f33985a5281bd21070617ebcfda9be86eb17e6e00f793 即为我们想要的 qwen:7b （格式为 gguf），导出代码为 cp /Users/m2max/.ollama/models/blobs/sha256-46bb65206e0e2b00424f33985a5281bd21070617ebcfda9be86eb17e6e00f793 qwen_7b.gguf 导入模型下载模型可以从 hugggingface.co 或者镜像网站 hf-mirror.com 下载所需 gguf 格式的大模型（不然得自己转） 假设我们要下载的是这两天大火的斯坦福的模型 Octopus-v2， 搜 Octopus-v2，找有 GGUF 标识的，比如我们选择个链接 https://hf-mirror.com/brittlewis12/Octopus-v2-GGUF/tree/main 下载 octopus-v2.Q8_0.gguf 导入模型需要准备 Modelfile 文件，From pathtoqwen_7b.gguf。上面是最简单的办法 当然可以从上面模型信息生成完成版本的 Modelfile # Modelfile generated by ollama show# To build a new Modelfile based on this one, replace the FROM line with:# FROM qwen:7bFROM /path/to/qwen_7b.ggufTEMPLATE if .System |im_start|system .System |im_end| end |im_start|user .Prompt |im_end||im_start|assistantPARAMETER stop |im_start|PARAMETER stop \\|im_end|\\ 记得替换你的模型的完整路径 另外不同模型的 template 和 stop parameter 不同，这个不知道就不写，或者网上搜索 然后执行 ollama create qwen:7b -f Modelfile 导入模型的时候，确保硬盘可用空间在模型大小的 2 倍以上，transferring model data 复制一个完整的模型。creating model layer 生成一个新的模型文件。 第三方访问https://ollama.fan/reference/api/ ollama 提供了 OpenAI 的兼容 API 这里以沉浸式翻译为例 需要设置环境变量 OLLAMA_ORIGINS，设置任何应用都可以访问 ollama。 OLLAMA_ORIGINS=*","categories":["3.软件","AI"]},{"title":"1. Git介绍和基本命令","path":"/2024/05/17/3-软件-Git-1-Git介绍和基本命令/","content":"版本控制版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 Git 是免费、开源的分布式版本控制系统。 集中式版本控制系统集中管理的中央服务器，保存着所有文件的修改历史版本。 协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。 分布式版本控制系统远程仓库同步所有版本信息到本地的每个用户 本地可以查看所有的历史版本信息，偶尔远程更新，查看其他用户修改提交到远程 用户即使离线也可以本地提交，push 推送到远程服务器才需要联网 每个用户都保存了历史版本 工作区域Workspace：电脑本地看到的文件和目录，在 Git 的版本控制下，构成了工作区。 IndexStage：暂存区，一般存放在.git 目录下，即.gitindex,它又叫待提交更新区，用于临时存放你未提交的改动。执行 git add，这些改动就添加到这个区域。 Repository：本地仓库，你执行 git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 HEAD 指向最新放入仓库的版本。当你执行 git commit，文件改动就到本地仓库。 Remote：远程仓库，云端版本库 文件状态Untracked: 文件未加入到 git 库，未参与版本控制，处于未跟踪状态。通过 git add，可以变为 Staged 状态 Unmodified：文件已经加入 git 库，版本库中的文件快照内容与文件夹中还完全一致。 Unmodified 的文件如果被修改, 就会变为 Modified。如果使用 git remove 移出版本库，则成为 Untracked 文件。 Modified：文件被修改进入 modified 状态，文件这个状态通过 stage 命令可以进入 staged 状态 staged：暂存状态. 执行 git commit 则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为 Unmodified 状态。 正向工作流git 的正向工作流程一般就这样： 从远程仓库拉取文件代码回来；git pull 在工作目录，增删改文件； 把改动的文件放入暂存区；git add 将暂存区的文件提交本地仓库；git commit 将本地仓库的文件推送到远程仓库；git push 常用命令git clone [url] #克隆远程仓库git add [dir/file]#添加目录/文件到暂存区git commit [--amend] -m [msg] #提交暂存区到仓库区,msg为说明信息(amend用新的commit覆盖提交)git log [--oneline] [-p [file]]#查看提交历史(online精简模式)(p指定文件)git blame #列表方式查看指定文件的提交历史git diff #显示暂存区和工作区的差异git diff #显示暂存区和工作区的差异git diff filepath #filepath路径文件中，工作区与暂存区的比较差异git diff HEAD filepath #工作区与HEAD ( 当前工作分支)的比较差异git diff branchName filepath #当前分支文件与branchName分支的文件的比较差异git diff commitId filepath #与某一次提交的比较差异git status [-s] [--show-stash] #查看当前工作区暂存区变动(-s概要信息)（show-stash显示暂存文件）git pull/fetch #拉取远端代码#git pull = git fetch+ git merge。pull的话，拉取远程分支并与本地分支合并#fetch只是拉远程分支，怎么合并，可以自己再做选择。git pull #拉取远程仓库所有分支更新并合并到本地分支。git pull origin master #将远程master分支合并到当前本地master分支git pull origin master:master #将远程master分支合并到当前本地master分支，冒号后面表示本地分支git fetch --all #拉取所有远端的最新代码git fetch origin master #拉取远程最新master分支代码git push #推送到远端git push origin master #将本地分支的更新全部推送到远程仓库master分支。git push origin -d #删除远程branchname分支git push --tags #推送所有标签 # git rebase`rebase`又称为衍合，是合并的另外一种选择。 `rebase`好处是： 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：`git pull --rebase`# git stash`stash`命令可用于临时保存和恢复修改git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作git stash list 显示保存的工作进度列表git stash pop stash@num 恢复工作进度到工作区git stash show ：显示做了哪些改动git stash drop stash@num ：删除一条保存的工作进度git stash clear 删除所有缓存的stash。# git reflog显示当前分支的最近几次提交# git blame`git blame filepath`记录了某个文件的更改历史和更改人# git remotegit remote 查看关联的远程仓库的名称git remote add url 添加一个远程仓库git remote show [remote] 显示某个远程仓库的信息","categories":["3.软件","Git"]},{"title":"2. Git服务器环境搭建和客户端使用","path":"/2024/05/17/3-软件-Git-2-Git服务器环境搭建和客户端使用/","content":"服务端 安装 git 和 ssh sudo apt-get install gitsudo apt-get install openssh-server openssh-client 增加 git 用户并生成文件夹 sudo adduser gitsudo mkdir /home/git 创建 ssh 证书认证文件 sudo mkdir /home/git/.sshsudo touch /home/git/.ssh/authorized_keys 临时修改文件的权限 sudo chmod 777 /home/git/.ssh/authorized_keys 把需要访问 git 服务器的客户端公钥 id_rsa.pub的内容复制到 authorized_keys 文件 修改 authorized_keys 文件的权限 sudo chmod 700 /home/gitsudo chmod 700 /home/git/.sshsudo chmod 600 /home/git/authorized_keyssudo chown -R git:git /home/gitsudo chown -R git:git /home/git/.sshsudo chown -R git:git /home/git/.ssh/authorized_keys 为了安全考虑禁止登录 git 服务器的 shell，修改 git 的 shell 用 /usr/bin/git-shell 把 /etc/passwd 的 git:x:1004:1004:,,,:/home/git:/bin/bash 改成： git:x:1004:1004:,,,:/home/git:/usr/bin/git-shell 保存 建代码仓库 sudo mkdir /home/Repo #创建仓库的目录sudo git init --bare /home/Repo/test.git #创建仓库sudo chown -R git:git /home/Repo/test.git #修改权限为git 以后每创建一个新的仓库，记得最后一步操作: 修改仓库所属用户为 git。 客户端 安装 git Linux 环境下 sudo apt-get install git Windows 环境下直接安装 Git安装包 配置连接 通过密钥方式 ssh-keygen -t rsa [-C 你的邮箱地址] 会生成 id_rsa.pub 文件,添加该公钥到到服务器 Linux 环境下，密钥默认位于 /home/ubuntu/.ssh/id\\_rsa Windows 环境下密钥位于 C:\\Users\\xxx.ssh\\id\\_rsa.pub 通过用户名密码 git config –global user.name “username”git config –global user.email “username@gmail.com” 在连接 git 时，会需要输入账号密码，直接输入即可 附注：增量备份 -Git 服务器备份通过 rsync 使用 crontab 建立每天凌晨 3 点定时触发的任务 crontab -e 0 3 * * * * rsync -av -e ssh -i /path/to/id_rsa /homt/git/ remote_user@X.X.X.X:~/backup","categories":["3.软件","Git"]},{"title":"3. Git常用操作","path":"/2024/05/17/3-软件-Git-3-Git常用操作/","content":"项目创建对于网络项目git clone [url] 将 GitHub 中的网络项目复制到本地，只需在修改完之后 commit 即可，然后更新仓库代码，就可同步修改。 对于本地项目首先要创建一个文件夹用以存放文件，然后使用 git init 对进行初始化操作 git status 得到 git 中文件的状态 git add filename 将 filename 文件加入到 git 本地仓库中去（git rm -cached 可移除） git commit -m ‘status’ 表示提交信息（status 表示附加信息） 之后对本地项目进行关联 git remote add origin [url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 关联之后可以向远程仓库提交代码（更新仓库代码） 日常 push`git status` #获取状态`git add . `#添加文件到暂存区`git commit -m 20191121 push `#提交文件`git push origin master `#推送 日常 pull git diff 比较工作目录和 Index 中的代码。 git fetch 当于从远程获取最新版本到本地，不会自动 merge ，比 Git pull 更安全些 git checkout app/model/user.rb 将 user.rb 文件从上一个已提交的版本中更新回来，未提交的工作目录中的内容全部会被覆盖 首次使用配置 ssh ssh-keygen -t rsa ssh -T git@github.com 将.ssh 下的 pub 公钥复制到 github 账号中的设置-SSH，添加密钥即可 首次使用设置用户 git config (--global) user.name username git config (--global) user.email username@gmail.com git config --global user.name liuluhuagit config --global user.email 718050012@qq.com 上传下载常用命令 git push origin（仓库名） master（分支） 更新仓库代码（上传） git pull origin（仓库名） master（分支） 更新本地代码（下载） 回退历史版本 git log git reset --hard \\[commit\\_id] git revert \\[commit\\_id] 网络项目 git clone \\[url] git remote add origin \\[url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 版本情况 git tag 查看版本情况 git tag V1.0 新建版本 git checkout V1.0 切换至版本 V1.0 分支情况 git branch 查看当前分支情况 git checkout a 切换到分支 a git checkout -b a 新建分支 a 并切换到分支 a git branch -d a 删除 a 分支 git merge a 将 a 分支的代码合并到 master 分支上","categories":["3.软件","Git"]},{"title":"版本控制方案","path":"/2024/05/17/3-软件-Git-版本控制方案/","content":"Git 方案1. 仓库创建 仓库创建基于当前的项目，例如备份仪表项目仓库，LSA 项目等 2. 分支创建 项目主分支保存项目代码及文档，负责发布代码 项目开发分支保存项目源码，分支仅管理员可见 项目运行分支保存项目头文件及库文件代码，分支所有人可见 项目人员开发分支基于运行分支创建，仅该人员有权限，该人员开发任务基于该分支进行修改代码 3. 代码提交 各人员代码仅提交在单独分支，提交完成后，由管理员审核后，同步源代码至开发分支 4. 版本回退 SVN 方案","categories":["3.软件","Git"]},{"title":"DRM+EGL 执行错误分析","path":"/2024/05/17/0-平台-Linux-Graphics-DRM-EGL-执行错误分析/","content":"mesa 运行 DRM+EGL 执行错误分析： src\\egl\\main\\egldefines.h 中定义了 EGL_VENDOR #define _EGL_VENDOR_STRING Mesa Project 输出结果为 Mesa Project，确认输出无误 https://askubuntu.com/questions/1027168/why-is-opengl-vendor-mesa-project 以上问题项中，该选项显卡为 Nvidia glxinfo tells you what the X11 server you’re running under is using for GL. It doesn’t tell you what an arbitrary program not using X11 might use. 故分析如下： 未正确启用显卡，EGL 采用的是 Mesa 软件渲染，故无法提供正确的 config 证明： 是否有 GLX 或 Wayland 等方案解决该问题","categories":["0.平台","Linux","Graphics"]},{"title":"DRM+GBM+EGL显示","path":"/2024/05/17/0-平台-Linux-Graphics-DRM-GBM-EGL显示/","content":"DRM (Direct Rendering Manager)、GBM (Generic Buffer Manager) 和 EGL (Embedded-System Graphics Library) 组合在一起，是在 Linux 平台上进行图形渲染和硬件加速的常见方式。这些组件一起提供了一个完整的图形渲染栈，允许应用程序直接与图形硬件进行交互。 DRM（Direct Rendering Manager）：DRM 是 Linux 内核中的一个子系统，用于管理图形硬件的驱动程序。它提供了一种通用的接口，允许用户空间程序直接与硬件交互，通过设备文件 /dev/dri/cardX 访问。DRM 提供了诸如模式设置、显示控制、渲染加速等功能。 GBM（Generic Buffer Manager）：GBM 是一个用于管理图形缓冲区的库，通常与 DRM 配合使用。它提供了一种标准的接口，用于分配、管理和操作图形内存。GBM 还提供了与 EGL 和 OpenGL ES 兼容的接口，使应用程序能够使用硬件加速进行渲染。 EGL（Embedded-System Graphics Library）：EGL 是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。EGL 通常与 GBM 和 DRM 一起使用，通过 GBM 提供的接口来创建图形表面，并将其与 OpenGL 或 OpenGL ES 上下文关联起来，实现硬件加速的图形渲染。","categories":["0.平台","Linux","Graphics"]},{"title":"LinuxGraphics 笔记","path":"/2024/05/17/0-平台-Linux-Graphics-LinuxGraphics-笔记/","content":"modetest 命令 利用 xrandr 在命令行指定输出 xrandr --output HDMI-1 --mode 1920x1080 | ./a.out Mesa 是一个开源的实现了 OpenGL 规范的图形库，它提供了一个 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU（OpenGL Utility Library）通常被视为 OpenGL 的一个独立组件，而不是 OpenGL 的核心部分。 GLU 提供了一些 OpenGL 的辅助功能，比如进行复杂几何运算和对象构造等。虽然 GLU 在许多 OpenGL 实现中都有支持，但它并不是 OpenGL 规范的一部分，因此在某些情况下，OpenGL 实现可能不包括 GLU 或将其作为一个可选组件。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 如果你需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，例如从系统的 OpenGL 安装中获取，或者从其他地方下载 GLU 的实现。然后将 GLU 的头文件包含到你的项目中，并链接 GLU 库以使用 GLU 提供的功能。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 DRM利用 DRM+GBM+EGL 指定显卡运行代码分析 Mesa GBM（Generic Buffer Management）是一个开源图形缓冲区管理库，用于管理图形内存缓冲区。它是 Mesa 3D 图形库的一部分。GBM 主要用于 Linux 平台，为 Direct Rendering Manager (DRM) 内核子系统提供了一个用户空间 API。它提供了一种统一的接口，用于在 Linux 系统中管理图形缓冲区和设备之间的交互。 在 DRM（Direct Rendering Manager）中，CRTC（Cathode Ray Tube Controller）是一个显示管控制器，负责控制显示管的扫描、同步和刷新操作。它与 Encoder（编码器）和 Connector（连接器）之间存在着一定的联系。 CRTC（Cathode Ray Tube Controller）：CRTC 控制着实际显示设备的扫描和刷新操作。每个 CRTC 都与一个显示管（如液晶显示器或投影仪）相关联，负责生成该显示设备的图像信号。一个显卡可能有多个 CRTC，每个 CRTC 控制一个显示输出。 Encoder（编码器）：Encoder 是 CRTC 输出信号的编码器，将图像数据转换为特定格式的信号以便发送到显示设备。Encoder 通常与特定类型的连接器（如 HDMI、DVI、VGA 等）相关联，以便将图像数据转换为对应的视频信号格式。一个 CRTC 可能与多个 Encoder 相关联，这意味着它可以同时支持多种连接器类型。 Connector（连接器）：Connector 表示与显卡相连的物理显示端口，如 HDMI 接口、DVI 接口等。每个 Connector 对应一个实际的显示输出接口，比如连接显示器或投影仪的端口。每个 Connector 都与一个 Encoder 相关联，该 Encoder 负责将图像数据编码成连接器所需的信号格式。 在 DRM 中，通常的工作流程是： 用户空间（如图形驱动程序）通过 DRM 接口选择一个 Connector，然后创建一个 CRTC 并将其与所选 Connector 关联起来。 然后，用户空间会创建一个 Encoder，并将其与所选的 Connector 关联起来，以便将图像数据编码成正确的视频信号格式。 最后，用户空间会将帧缓冲区（Framebuffer）的内容提交给 CRTC 进行显示。CRTC 接收到帧缓冲区的内容后，会将其发送给相关联的 Encoder，最终显示到连接器所代表的显示设备上。 总之，CRTC 负责控制实际的显示设备，Encoder 负责将图像数据转换为视频信号格式，而 Connector 则表示实际的物理显示端口，它们之间相互关联，共同完成图像显示的任务。 EGL 是 Khronos 渲染 API（如 OpenGL、OpenGL ES 或 OpenVG）与底层本地平台 (窗口) 系统之间的接口。 EGL 主要功能：处理图形上下文管理、Buffer 管理和渲染同步 Display (EGLDisplay): 对实际显示设备窗口系统的抽象； Surface (EGLSurface): 存储图像的内存区域； Context (EGLContext): 存储渲染 API 的状态信息；一套标准的 EGL 绘制流程简介: 获取 EGL Display 对象：eglGetDisplay 初始化与 EGLDisplay 之间的连接：eglInitialize 获取 EGLConfig 对象：eglChooseConfig eglGetconfigs 创建 EGLContext 实例：eglCreateContext 创建 EGLSurface 实例：eglCreatewindowSurface eglCratePbufferSurface 连接 EGLContext 和 EGLSurface 上下文: eglMakeCurrent 使用 OpenGL ES API 绘制图形：gl_* 切换 front buffer 和 back buffer 显示：eglSwapBuffer 断开并释放与 EGLSurface 关联的 EGLContext 对象：eglRelease 删除 EGLSurface 对象 删除 EGLContext 对象 终止与 EGLDisplay 之间的连接 EGL Display 的获取EGLDisplay eglGetDisplay(NativeDisplayType native_display)EGLDisplay eglGetPlatformDisplay( EGLenum platform, void * native_display, const EGLAttrib * attrib_list);EGLDisplay eglGetPlatformDisplayEXT( EGLenum platform, void *native_display, const EGLint *attrib_list); eglGetDisplay 会根据现在的环境来决定默认的原生窗口系统，其他两个需要手动指定平台； compositor 运行相当于是裸机运行没有窗口环境，首先必须通过 GBM 或者 EGL_PLATFORM_DEVICE_EXT 扩展这两种方式来获取 EGLDisplay; GBM 概念: 基于 GEMTTM 的驱动对外是没有提供统一的内存管理接口的，至少 Buffer Object 创建销毁等操作是需要自行提供设备相关的即口进行实现的。 用户态没有统一的接口对缓冲区进行管理，这导致某些特定用户态程序的开发的困难，如 wayland compositor。 简单的说 GBM 就是为了实现 DRM(gbm_device) 作为 EGL 的本地平台，创建的句柄可以用来初始化 EGL 和创建渲染目标缓冲区 // get gdm_device// path = /dev/dri/renderD128 / dev/dri/card0egl_gbm.render_fd = open(path, O_RDWR|O_CLOEXEC);assert(-1 != egl_gbm.render_fd);egl_gbm.gbm_device = gbm_create_device(egl_gbm.render_fd);assert(NULL != egl_gbm.gbm_device);// get display1. egl_gbm.display = eglGetDisplay((EGLNativeDisplayType)egl_gbm.gbm_device);2. egl_gbm.display = eglGetPlatformDisplay(EGL_PLATFORM_GBM_KHR, egl_gbm.gbm_device, NULL);3. egl_gbm.display = eglGetPlatformDisplayEXT(EGL_PLATFORM_GBM_MESA, egl_gbm.gbm_device, NULL);// wlroots里面从严谨性来说，通过GBM获取EGL Display的时候，eglGetPlatformDisplayEXT后面的参数应该是EGL_PLATFORM_GBM_MESA而不是EGL_PLATFORM_GBM_KHR； Wayland：Wayland 是一种图形显示服务器协议，而 DRM 是 Linux 内核中的 Direct Rendering Manager 子系统，用于管理图形硬件驱动程序。在 Wayland 中，客户端应用程序通过 Wayland 协议与显示服务器通信，而 Wayland 服务器通过 DRM 接口与底层的图形硬件交互。 ** GBM**：直接的关系是 DRM 和 GBM，其中 DRM（Direct Rendering Manager）是 Linux 内核中的子系统，用于管理图形硬件的驱动程序，而 GBM（Generic Buffer Manager）是一个用户态库，提供了一个标准接口，用于分配、管理和操作图形内存，通常与 DRM 配合使用。GBM 通常与 DRM（Direct Rendering Manager）配合使用，用于与底层的图形硬件进行交互。应用程序可以使用 GBM 接口来分配和管理图形缓冲区，以便进行硬件加速的图形渲染。GBM 与 Wayland 无直接关联，但在一些特定的场景下，它们可能会一起使用。 GBM 控制 EGL：GBM 通常与 EGL 结合使用，以在硬件加速的图形渲染中创建和管理图形表面（buffers）。EGL（Embedded-System Graphics Library）是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。 EGL 操作 OpenGL API 进行操作：EGL 用于管理 OpenGL 或 OpenGL ES 的上下文和表面，以便应用程序可以使用 OpenGL API 进行图形操作。EGL 提供了一个标准的接口，用于在不同的图形系统中创建和管理 OpenGL 上下文和表面，以便实现跨平台的图形渲染。 确定显卡linux 内核检测到机器上的显卡时，会加载正确的设备驱动程序（位于内核树中的 ./drivers/gpu/drm/xy），并提供两个字符设备来控制显卡。 Udev （或您使用的任何热插拔应用程序）将把它们创建为 /dev/dri/card0 /dev/dri/controlID64 我们只需要第一个。 你可以像我们在这里做的那样，在应用程序中硬编码这个路径，但建议使用真正支持热插拔和多座的 libudev。不过，这超出了本文的讨论范围。 如果有多块显卡，可能还会有 /dev/dri/card1、/dev/dri/card2、…… modeset_open(out,node)： 辅助函数用于打开作为 @node 给定的 DRM 设备。 成功时，新的 fd 将存储在 @out 中。如果失败，则返回负错误代码。 打开文件后，我们还要检查 DRM_CAP_DUMB_BUFFER 功能。 如果驱动程序支持该功能，我们就可以创建简单的内存映射缓冲区，而无需任何依赖于驱动程序的代码。 由于我们希望避免使用任何 radeon、nvidia、intel 等驱动程序的特定代码，因此我们在此依赖于 DUMB_BUFFER。 确认显示设备我们需要找到可用的显示设备。 libdrm 提供了 drmModeRes 结构，其中包含所有需要的信息。 通过 drmModeGetResources(fd) 获取， 通过 drmModeFreeResources(res) 释放。 显卡上的物理连接器称为 “connector”。您可以将显示器插入其中并控制显示内容。 我们肯定会对当前使用的 connector 感兴趣，因此，我们需遍历连接器列表，并尝试在每个可用的显示器上显示测试图片。 然而，这并不像听起来那么容易。首先，我们需要检查连接器是否被实际使用（显示器已插入并打开）。 然后，我们需要找到一个能控制该连接器的 CRTC，CRTC 稍后介绍。 然后，我们创建一个帧缓冲器对象 framebuffer object。 准备完成后我们就可以对帧缓冲区进行 mmap()，并在其中绘制测试图片。 然后，我们就可以告诉 DRM 设备在给定的 CRTC 上用选定的连接器显示帧缓冲。 由于我们要在帧缓存上绘制动态图像，因此必须记住所有这些设置。 因此，我们要为成功初始化的每对连接器 +crtc+ 帧缓冲器创建一个 “struct modeset_dev “ 对象，并将其推入全局设备列表。 因此，下一步我们需要实际准备好找到的所有连接器。 这段文字主要讲述了在 Linux 系统中确定显卡和显示设备的过程。以下是关键点的概括： 内核检测与驱动加载：Linux 内核会自动检测并加载适合的显卡驱动程序。 创建字符设备：显卡驱动程序会创建两个字符设备，用于控制显卡。 确认显示设备和 CRTC：通过遍历连接器列表，并尝试在每个可用显示器上显示测试图片，来确定合适的显示设备（CRTC）。 避免完整模式集的设置：在使用 CRTC 之前，需要确保其他设备没有占用该 CRTC。 创建并维护设备列表：为成功初始化的每一对连接器 +CRTC+ 帧缓冲器创建一个 struct modeset_dev 对象，并将其添加到全局设备列表中。modeset_prepare(fd)：该辅助函数将 DRM fd 作为参数，然后简单地从设备中获取资源信息。 如果初始化成功，我们只需将此对象作为新设备添加到全局模式集设备列表中。 资源结构包含所有连接器 ID 的列表。 我们使用辅助函数 drmModeGetConnector() 获取每个连接器的更多信息。 如果连接器当前未使用，也未插入监视器，我们的辅助函数 modeset_setup_dev() 将返回 -ENOENT。 因此，我们可以忽略该连接器。 modeset_find_crtc(fd, res, conn, dev)： 这个小助手试图为给定的连接器找到合适的 CRTC。 实际上，我们必须再引入一个 DRM 对象，以便更清楚地说明这一点：编码器（Encoders）。 编码器可以帮助 CRTC 将帧缓冲器中的数据转换成正确的格式，以便用于所选的连接器。 我们不需要了解更多的转换信息就能使用它。 不过，您必须知道，每个连接器可以使用的编码器都是有限的。 而每个编码器只能与有限的 CRTC 配合使用。 因此，我们要做的就是尝试每一个可用的编码器，并寻找该编码器可以配合使用的 CRTC。 如果我们找到了第一个工作组合，我们就会很高兴，并将其写入 @dev 结构。 但在遍历所有可用编码器之前，我们首先要在一个连接器上尝试当前激活的编码器 +CRTC，以避免出现完整的模式集。 不过，在使用 CRTC 之前，我们必须确保之前设置的其他设备都没有使用该 CRTC。 请记住，每个 CRTC 只能驱动一个连接器！因此，我们只需遍历之前设置的设备的 “modeset_list”，并检查该 CRTC 之前是否未被使用。 否则，我们将继续使用下一个 CRTC编码器组合。","categories":["0.平台","Linux","Graphics"]},{"title":"Mesa","path":"/2024/05/17/0-平台-Linux-Graphics-Mesa/","content":"","categories":["0.平台","Linux","Graphics"]},{"title":"OpenGL显示","path":"/2024/05/17/0-平台-Linux-Graphics-OpenGL显示/","content":"GLUGLU（OpenGL Utility Library）是 OpenGL 的一个辅助库，提供了一些更高级的几何计算和对象构造函数，如曲面和体的生成、平移、旋转等，这些函数在处理复杂的几何操作时非常有用。 GLFWGLFW 是一个流行的开源库，主要用于创建和管理图形应用程序中的窗口、OpenGL 或 Vulkan 上下文，以及处理用户输入、定时器等功能。适用于各种图形应用程序的开发，提供了窗口管理、上下文管理、输入处理等功能，使开发者能够专注于图形渲染和应用逻辑的实现。 主要功能： 窗口管理： GLFW 允许开发者创建窗口并对其进行管理，包括调整大小、最小化、最大化、关闭等操作。 上下文管理： 它提供了创建 OpenGL 或 Vulkan 上下文的功能，使得图形渲染程序可以在窗口中绘制图形。 输入处理： GLFW 支持处理用户输入，包括键盘输入、鼠标移动和点击、游戏手柄等。 事件处理： 它允许开发者监听和响应各种事件，如窗口大小改变、键盘按键、鼠标移动等。 监视器管理： GLFW 支持多个显示器的管理，可以获取显示器的分辨率、刷新率等信息。 使用步骤： 初始化： 在程序启动时，调用 GLFW 的初始化函数来初始化库。 创建窗口： 使用 GLFW 的窗口创建函数来创建一个窗口并指定其属性，如大小、标题等。 创建上下文： 使用 GLFW 的上下文创建函数来创建一个 OpenGL 或 Vulkan 上下文。 主循环： 在主循环中轮询事件，并根据事件类型做出相应的处理。 渲染： 在渲染阶段，使用 OpenGL 或 Vulkan 等图形 API 绘制场景。 清理： 在程序结束时，调用 GLFW 的清理函数来释放资源并关闭库。 利用 glfw 监视器 Demo #include GLFW/glfw3.h int main() // 初始化 GLFW if (!glfwInit()) return -1; // 获取监视器（显示器）列表 int count; GLFWmonitor** monitors = glfwGetMonitors(count); // 指定要使用的显示设备索引 int monitor_index = 0; // 设置为你想要的显示设备索引 // 获取指定索引的显示设备 GLFWmonitor* monitor = (monitor_index count) ? monitors[monitor_index] : NULL; // 获取显示设备的视频模式 const GLFWvidmode* mode = glfwGetVideoMode(monitor); // 创建窗口并指定显示设备 GLFWwindow* window = glfwCreateWindow(mode-width, mode-height, OpenGL Window, monitor, NULL); if (!window) glfwTerminate(); return -1; // 进入主循环 while (!glfwWindowShouldClose(window)) // 渲染代码 glClear(GL_COLOR_BUFFER_BIT); // ... glfwSwapBuffers(window); glfwPollEvents(); // 清理资源 glfwDestroyWindow(window); glfwTerminate(); return 0; GLUT（OpenGL Utility Toolkit） GLUT 是一个跨平台的工具包，用于创建和管理 OpenGL 窗口、处理用户输入等。它提供了一组简单的 API，使得编写基本的 OpenGL 程序变得更加容易。 - GLUT 支持多种操作系统，包括 Windows、Linux 和 macOS。 - 使用 GLUT，你可以很快地编写出一个可以在不同平台上运行的简单 OpenGL 程序，而不必担心平台特定的细节。 - 但是，GLUT 对于创建复杂的图形用户界面（GUI）可能不够灵活，因为它的功能相对有限。 GLUT 是一个跨平台的工具包，用于简化 OpenGL 应用程序的开发。它提供了一组函数，用于创建窗口、处理输入事件、进行基本的图形绘制等，使开发者可以更轻松地编写 OpenGL 应用程序，而无需处理底层的窗口系统的细节。 GLUT 提供了一个相对简单的接口，适用于快速原型设计和简单的图形应用程序。它通常用于学习 OpenGL、编写小型游戏、演示程序等。 GLX（OpenGL Extension to the X Window System） GLX 是 OpenGL 在 X Window System 上的扩展，它允许 OpenGL 应用程序与 X 服务器通信，并在 X 窗口系统中创建 OpenGL 上下文。GLX 提供了一组函数，用于在 X 窗口系统中创建 OpenGL 渲染上下文、管理 OpenGL 窗口和图形渲染等。 GLX 允许 OpenGL 应用程序直接与 X 服务器通信，而不需要借助其他库或工具。它提供了对 OpenGL 的完整支持，可以实现高性能的图形渲染和交互。 GLX 则是 OpenGL 在 X 窗口系统上的扩展，提供了与 X 服务器通信和在 X 窗口系统中创建 OpenGL 渲染上下文的功能。 EGL（Embedded Graphics Library）EGL 是一个用于管理图形渲染上下文的接口，通常用于嵌入式系统和移动设备上。 - EGL 是 OpenGL ES 和 OpenVG 的标准的本地显示系统接口，它提供了与底层窗口系统交互的能力。 - 在 Linux 上，EGL 通常与 GBM（Generic Buffer Manager）或其他图形系统配合使用，如 Wayland。 - 使用 EGL，你可以在嵌入式系统上更好地控制 OpenGL 上下文的创建和管理，以及与窗口系统的交互。","categories":["0.平台","Linux","Graphics"]},{"title":"Ubuntu更换国内源","path":"/2024/05/17/0-平台-Linux-Ubuntu-Ubuntu更换国内源/","content":"Ubuntu 更换国内源Ubuntu 本身的源使用的是国内的源，下载速度比较慢。 清华源地址 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu-ports/ bionic 代表 ubuntu18 备份etcaptsources.list 文件mv /etc/apt/sources.list /etc/apt/sourses.list.backup 新建etcaptsources.list 文件并添加以下内容#163源deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 更改完成之后执行一下 apt update 命令 其他的一些 apt 命令sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 其他几个国内的源：#中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse#阿里云源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse#清华源deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse","categories":["0.平台","Linux","Ubuntu"]},{"title":"加密方案","path":"/2024/05/17/0-平台-Linux-加密-加密方案/","content":"3568 应用程序及主板可执行文件加密在针对可执行文件的加壳加密和解密中，通常会使用以下步骤： 加壳加密： 选择壳程序： 选择一个用于加壳的程序，通常是一个小型的程序，它可以将原始的 ELF 文件嵌入到自身中，并添加解密逻辑。 嵌入并加密原始 ELF 文件： 将原始的 ELF 可执行文件嵌入到壳程序中，并对嵌入的原始 ELF 文件进行加密处理，使用加密算法对文件内容进行加密，确保只有正确的解密密钥可以解密文件。 生成加密后的文件： 将加密后的 ELF 文件保存为一个新的可执行文件，这个文件是经过加密处理的。 解密： 执行加密后的文件： 执行加密后的 ELF 文件，这个文件是壳程序，它包含了解密逻辑。 解密逻辑： 壳程序在运行时会对自身进行解密，并将嵌入的原始 ELF 文件解密出来。 还原原始 ELF 文件： 解密后的原始 ELF 文件会被还原到内存中，然后壳程序会将控制权转移到原始 ELF 文件，使得原始程序可以正常执行。 本文档实现的加密方式主要分为以下两个模块： 内核空间下，基于内核密钥保留服务的 ELF 文件解密并交付内核正常运行模块 用户空间下，基于非对称加密算法的 ELF 文件内容加密，主要针对 ELF Header 模块【可选加密 program header 和 section header】 1. 应用程序加壳1.1 ELF 文件格式介绍应用程序加壳模块对应用程序进行加密操作，主要针对以下模块进行加密操作 ELF header Program header table 【可选】 Section header table 【可选】 其中 ELF header 指明了 ELF 文件的整体信息，如 ELF 文件的 magic value、类型、版本、目标机器等。 #define EI_NIDENT (16)typedef struct unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version 文件版本,目前常见的ELF文件版本均为EV_CURRENT(1)*/ Elf_Addr e_entry; /* Entry point virtual address 入口虚拟地址。*/ Elf_Off e_phoff; /* Program header table file offset 段表文件偏移。*/ Elf_Off e_shoff; /* Section header table file offset 节表文件偏移。*/ Elf_Word e_flags; /* Processor-specific flags 处理器特定的标志，一般为0。*/ Elf_Half e_ehsize; /* ELF header size in bytes Elf_Header的大小（字节）*/ Elf_Half e_phentsize;\t/* Program header table entry size 段头的大小（字节）。*/ Elf_Half e_phnum; /* Program header table entry count 段的数量。*/ Elf_Half e_shentsize;\t/* Section header table entry size 节头的大小（字节）。*/ Elf_Half e_shnum; /* Section header table entry count 字的数量。*/ Elf_Half e_shstrndx; /* Section header string table index 节字符串表的节索引*/ Elf_Ehdr;[e_ident]包含了Maigc Number和其它信息，共16字节。\t0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。[e_type]ELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。[e_machine]处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 另外，ELF header 还指明了 program header table 与 section header table 两个表在文件中的偏移位置、条目个数、条目大小。 这两个表的位置和长度随着 sectionsegment 的个数而变化，而 ELF header 总是位于文件最开头，且长度固定。 如果想要访问 program header table 和 section header table 中的信息，必须通过 ELF header 来找到它们在文件中的确切位置。 Program header table 主要描述了将哪一个或哪几个 section 组织为一个 segment，以及各个 segment 的描述信息。 ELF 程序头是对二进制文件中段的描述，是程序装载必需的一部分。段（segment）是在内核装载时被解析的，描述了磁盘上可执行文件的内存布局以及如何映射到内存中。可以通过引用原始 ELF 头中名为 e_phoff（程序头表偏移量）的偏移量来得到程序头表， Section header table 描述了 ELF 文件中所有的 section，以及每个 section 的类型、长度等描述信息。 节，不是段。段是程序执行的必要组成部分，在每个段中，会有代码或者数据被划分为不同的节。节头表是对这些节的位置和大小的描述，主要用于链接和调试。节头对于程序的执行来说不是必需的，没有节头表，程序仍可以正常执行，因为节头表没有对程序的内存布局进行描述，对程序内存布局的描述是程序头表的任务。节头是对程序头的补充。readelf –l 命令可以显示一个段对应有哪些节，可以很直观地看到节和段之间的关系。 Section header table 中并不存储每个 section 的名称。所有 section 的名称全部存储在一个名为 section header string table 的 section 中，名称之间用 \\0 分隔。在 ELF header 中，记录了该 section 在 section header table 中的索引。 1.2 功能模块针对以上理解，加壳程序的功能有以下： 针对 ELF 文件，通过字段异或【RSA 加密(可选)】的方式进行覆写 ELF header【ProgramSection header table(可选)】 ELF 开头修改为 HMAVIC【加密方式字段】【加密内容字段】ELF 【可选】单独进行末尾追加签名，确认为 HMAVIC 程序 1.3 代码实现#define SIGN_OFFSET 9#define SIGN_CONTENT HMAVIC#define SIGN_LENGTH 6 调试 xxd -l 100 a.runreadelf -h a.run 2. 内核密钥保留服务2.1 密钥配置文件配置文件内容 #表示这个配置文件包含一系列的请求信息，用于生成证书请求[ req ]# 指定生成的 RSA 密钥长度为 2048 位default_bits = 2048# 指定用于请求的分辨名 (DN)，在 [ req_distinguished_name ] 部分中定义distinguished_name = req_distinguished_name# 禁用交互式提示，生成证书时不会要求用户输入prompt = no# 指定字符编码为 UTF-8string_mask = utf8only# 指定用于 X.509 扩展的配置，定义在 [ myexts ] 部分x509_extensions = myexts# 定义了请求的分辨名信息，包括组织 (O)、通用名 (CN) 和电子邮件地址 (emailAddress)[ req_distinguished_name ]# 指定组织名为hmavicO = hmavic# 指定通用名为 verification for hmavicCN = verification for hmavic# 指定电子邮件地址emailAddress = liuluhua7@gmail.com# 定义了 X.509 扩展信息，包括基本约束 (basicConstraints)、密钥用途 (keyUsage)、主题密钥标识符 (subjectKeyIdentifier) 和颁发者密钥标识符 (authorityKeyIdentifier)[ myexts ]# 指定证书不是 CA 证书，即不具有颁发其他证书的权限basicConstraints=critical,CA:FALSE# 指定密钥用途为数字签名keyUsage=digitalSignature# 指定使用 SHA-1 哈希算法生成主题密钥标识符subjectKeyIdentifier=hash# 指定使用密钥标识符生成颁发者密钥标识符authorityKeyIdentifier=keyid 生成密钥并导入证书 openssl req -new -nodes -utf8 -sha256 -days 36500 -batch -x509 -config x509.hm.genkey -outform PEM -out kernel_key.pem -keyout kernel_key.pem 使用 OpenSSL 工具生成一个配置信息由 x509.hm.genkey 指定的自签名的 X.509 格式证书。 以下是命令中每个选项的解释： openssl req：使用 OpenSSL 工具中的 req 子命令，用于处理证书请求和生成证书。-new：指定创建一个新的证书请求。-nodes：不加密生成的私钥，即不设置私钥密码。-utf8：指定使用 UTF-8 编码。-sha256：指定使用 SHA-256 哈希算法生成证书签名。-days 36500：指定证书的有效期为 36500 天-batch：在生成证书请求时不会提示用户输入任何信息，而是使用配置文件中指定的默认值。-x509：指定生成自签名的 X.509 格式证书，而不是生成证书请求。-config x509.genkey：指定使用配置文件 x509.genkey 中的配置信息来生成证书。-outform PEM：指定输出的证书格式为 PEM 格式。-out kernel_key.pem：指定输出的证书文件名为 kernel_key.pem。-keyout kernel_key.pem：指定输出的私钥文件名为 kernel_key.pem，因为在本例中私钥和证书是一对的。 2.2 编译内核修改 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 在文件最后增加以下内容： ## Certificates for signature checking#CONFIG_SYSTEM_TRUSTED_KEYRING=yCONFIG_SYSTEM_TRUSTED_KEYS=certs/kernel_key.pem 进入顶层目录执行 ./build.sh kernel 在编译过程中，应该可以看到如下信息： ...EXTRACT_CERTS PATH_TO_CERT/kernel_key.pemAS certs/system_certificates.oAR certs/built-in.o... 待内核编译完成，烧录内核至开发板，查看 proc 文件系统中的 /proc/keys。如果能够看到自行生成的密钥，那么说明该密钥已经被放置于内核的系统密钥环中。 3. 内核模块脱壳并运行3.1 功能模块针对加壳进行编写脱壳模块功能如下： 内核模块安装时进行 RSA 核验，核验通过则安装模块，否则卸载模块 注入到内核 ELF 运行之前，对 HMAVIC 开头的 ELF 进行拦截 根据加密方式和内容进行解密处理，解密完成后覆写内容交由 Linux 内核处理 【可选】针对未签名程序，拒绝执行 3.2 将解密模块嵌入内核中我们为 ELF 的签名与验证生成了一对 RSA 公私钥，将公私钥以符合 X.509 标准的方式导入到一个 PEM 编码的文件中。通过上述机制，可以将文件中的公钥证书编译到内核的系统密钥环上。这样，在 ELF 签名验证模块 中，可以通过使用系统密钥环中的公钥证书，对 ELF 文件中的签名信息进行验证。 首先，我们对 Linux 内核中已有的 内核模块签名 验证机制的代码进行了分析。在内核源代码目录 certs/system_keyring.c 中，定义了内核内置的受信密钥： certssystem_keyring.c 复制 static struct key *builtin_trusted_keys; 但由于这个变量没有被声明为 extern，因此无法在其它内核代码中直接引用这个变量。但是在这个源文件中，开放了 verify_pkcs7_signature() 函数，使得其它内核代码能够通过这个函数，间接使用内置密钥环的签名验证功能： certssystem_keyring.c 复制 /** * verify_pkcs7_signature - Verify a PKCS#7-based signature on system data. * @data: The data to be verified (NULL if expecting internal data). * @len: Size of @data. * @raw_pkcs7: The PKCS#7 message that is the signature. * @pkcs7_len: The size of @raw_pkcs7. * @trusted_keys: Trusted keys to use (NULL for builtin trusted keys only, * (void *)1UL for all trusted keys). * @usage: The use to which the key is being put. * @view_content: Callback to gain access to content. * @ctx: Context for callback. */int verify_pkcs7_signature(const void *data, size_t len, const void *raw_pkcs7, size_t pkcs7_len, struct key *trusted_keys, enum key_being_used_for usage, int (*view_content)(void *ctx, const void *data, size_t len, size_t asn1hdrlen), void *ctx)... 在内核代码中，通过 #include linux/verification.h 使用该函数时，输入 签名数据 与 被签名数据 的 缓冲区内存地址 和 缓冲区长度，就能够使用内置密钥完成签名认证。因此，ELF 签名验证模块 只要能够从 ELF 文件中正确提取 PKCS #7 格式的签名数据，以及签名保护的目标数据，就可以通过这个函数验证数字签名是否正确。 模块代码 ```编译 Makefile```makefileifneq ($(KERNELRELEASE),)obj-m := binfmt_elf_signature_verification.oelse# KDIR := ../#KDIR := /lib/modules/$(shell uname -r)/buildKDIR := /home/forlinx/Desktop/OK3568-linux-source/kernelall: $(MAKE) -C $(KDIR) M=$(PWD) modulesclean: $(RM) *.ko $(RM) *.o $(RM) *.mod* $(RM) *.symvers $(RM) *.order $(RM) .*.mk $(RM) .*.cmd $(RM) -r .tmp_versionsendif 执行 make ARCH=arm64 CROSS_COMPILE=/home/forlinx/Desktop/OK3568-linux-source/buildroot/output/OK3568/host/bin/aarch64-buildroot-linux-gnu- 参考Linux ELF 文件数据完整性保护系统 附录 A OpenSSL 进行密钥生成验证A1 私钥openssl genpkey -algorithm RSA -out private_key.pem -aes256 将生成一个 AES256 加密的 RSA 私钥，并将其保存到名为 private_key.pem 的文件中。 生成时需要密码，密码为 HmAvic@123 A2 公钥openssl rsa -in private_key.pem -pubout -out public_key.pem 将从私钥文件 private_key.pem 中提取公钥，并将其保存到名为 public_key.pem 的文件中。 A3 签名openssl dgst -sha256 -sign private_key.pem -out signature.bin your_elf_file 使用 SHA-256 算法对 your_elf_file 进行签名，并将签名结果保存到 signature.bin 文件中。 A4 签名认证openssl dgst -sha256 -verify public_key.pem -signature signature.bin your_elf_file 使用公钥 public_key.pem 验证 signature.bin 文件中的签名是否与 your_elf_file 匹配。 A5 签名和认证代码实现 #include stdio.h#include stdlib.h#include openssl/rsa.h#include openssl/pem.h#include openssl/sha.h#define BUF_SIZE 1024// 函数声明int sign_file(const char* file_path, const char* private_key_path, const char* signature_path);int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path);int main() const char* file_path = your_elf_file; const char* private_key_path = private_key.pem; const char* public_key_path = public_key.pem; const char* signature_path = signature.bin; // 签名文件 if (sign_file(file_path, private_key_path, signature_path) != 0) fprintf(stderr, Failed to sign file. ); return 1; printf(File signed successfully. ); // 验证签名 if (verify_signature(file_path, signature_path, public_key_path) != 0) fprintf(stderr, Signature verification failed. ); return 1; printf(Signature verified successfully. ); return 0;int sign_file(const char* file_path, const char* private_key_path, const char* signature_path) FILE* file = fopen(file_path, rb); if (!file) fprintf(stderr, Failed to open file. ); return 1; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) SHA256_Update(sha256, buffer, bytes_read); unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, sha256); fclose(file); // 加载私钥 FILE* private_key_file = fopen(private_key_path, rb); if (!private_key_file) fprintf(stderr, Failed to open private key file. ); return 1; RSA* rsa = PEM_read_RSAPrivateKey(private_key_file, NULL, NULL, NULL); fclose(private_key_file); if (!rsa) fprintf(stderr, Failed to load private key. ); return 1; // 对 ELF 文件哈希进行签名 unsigned char signature[BUF_SIZE]; unsigned int signature_length; if (!RSA_sign(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, signature_length, rsa)) fprintf(stderr, Failed to sign hash. ); RSA_free(rsa); return 1; // 将签名写入文件 FILE* signature_file = fopen(signature_path, wb); if (!signature_file) fprintf(stderr, Failed to create signature file. ); RSA_free(rsa); return 1; fwrite(signature, 1, signature_length, signature_file); fclose(signature_file); RSA_free(rsa); return 0;int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path) FILE* file = fopen(file_path, rb); if (!file) fprintf(stderr, Failed to open file. ); return 1; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) SHA256_Update(sha256, buffer, bytes_read); unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, sha256); fclose(file); // 加载公钥 FILE* public_key_file = fopen(public_key_path, rb); if (!public_key_file) fprintf(stderr, Failed to open public key file. ); return 1; RSA* rsa = PEM_read_RSA_PUBKEY(public_key_file, NULL, NULL, NULL); fclose(public_key_file); if (!rsa) fprintf(stderr, Failed to load public key. ); return 1; // 读取签名文件 FILE* signature_file = fopen(signature_path, rb); if (!signature_file) fprintf(stderr, Failed to open signature file. ); RSA_free(rsa); return 1; unsigned char signature[BUF_SIZE]; size_t signature_length = fread(signature, 1, BUF_SIZE, signature_file); fclose(signature_file); // 验证签名 if (RSA_verify(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, signature_length, rsa) != 1) fprintf(stderr, Signature verification failed. ); RSA_free(rsa); return 1; RSA_free(rsa); return 0; 附录 B 如何实现对程序的加解密公钥加密，私钥解密 方式一：不同设备内核烧录不同的私钥进行解密 方式二：不同设备内核烧录相同的私钥进行解密 B1 生成 RSA 密钥对首先，你需要生成 RSA 密钥对，包括私钥和公钥。下面是一个示例命令来生成 RSA 密钥对： openssl genpkey -algorithm RSA -out private_key.pem -aes256openssl rsa -pubout -in private_key.pem -out public_key.pem 这个命令会生成一个 RSA 私钥文件 private_key.pem，并在生成的同时使用 AES256 算法对私钥进行加密保护。然后从私钥中提取公钥，并保存到 public_key.pem 文件中。 B2 使用 RSA 加密文件要使用 RSA 公钥加密文件，你可以执行以下命令： openssl rsautl -encrypt -pubin -inkey public_key.pem -in plaintext.txt -out encrypted.txt 这个命令会使用公钥文件 public_key.pem 对明文文件 plaintext.txt 进行加密，并将加密后的结果输出到 encrypted.txt 文件中。 B3 使用 RSA 解密文件要使用 RSA 私钥解密文件，你可以执行以下命令： openssl rsautl -decrypt -inkey private_key.pem -in encrypted.txt -out decrypted.txt 这个命令会使用私钥文件 private_key.pem 对加密文件 encrypted.txt 进行解密，并将解密后的结果输出到 decrypted.txt 文件中。 如何向内核中添加密钥 如何在程序中读取密钥","categories":["0.平台","Linux","加密"]},{"title":"博客Hexo部署","path":"/2024/05/17/0-平台-服务器-博客-博客Hexo部署/","content":"√ 博客框架采用 Hexo √ 部署到 GitHubPages（） √ 部署到 Vercel（GitHub Publish）- 已取消部署 × 通过 Netlify 部署和构建 √ 利用 Obsidian Digital GardenFlowershow 插件在 Vercel 上将笔记内容部署为 Obsidian 数字花园 - 已取消部署 部署流程 创建 GitHub 发布仓库 GitHub仓库部署 创建 GitHub 源码仓库，并在仓库中部署 Hexo 在源码仓库中创建工作流，工作流主要完成任务是在接收到同步后，完成以下几个动作 GitHub Actions 构建之前需要调用 hexo 插件自动生成 category 信息 构建静态页面生成 public 文件夹 将 public 文件夹拷贝至发布仓库 Hexo 仓库部署Hexo 仓库部署分为两种形式，一种是部署在 Github 上，利用 GitHub Actions 生成页面，一种是部署在本地，本地生成页面后将 public 同步到 github pages。 如果部署在 GitHub，则需要两个仓库，一个用于部署 Hexo 源码，一个用于部署 GitHubPages，之后需要通过 github actions 进行发布管理。优点是本地不需要 Hexo 环境，直接提交后自动构建页面 源码仓库闭源，同步笔记到源码仓库后，源码仓库通过 actions 时触发同步到发布仓库，更新发布仓库页面 如果部署在本地，需要在本地生成静态网页，之后将静态网页通过 publisher 发布 public 文件夹到 github 仓库，但是需要本地具有 Hexo 环境，且需要在本地生成静态网页 Github 部署可以实现两个仓库都在 GitHub，并通过 GitHub Actions 在源码仓库进行编译，编译完成后自动将源码仓库的静态页面内容复制到发布仓库，实现自动化的发布管理。 将 Hexo 的源码仓库设置在 GitHub 上，你可以在这个仓库中编辑和管理 Hexo 的源代码、主题和文章。 创建另一个 GitHub 仓库作为发布仓库，用于存放生成的静态网页。你可以将 Hexo 生成的 public 文件夹的内容推送到这个仓库中。该仓库利用 GitHub Pages，直接通过 username.github.io 进行访问 在 Hexo 源码仓库中设置一个 GitHub Actions workflow，以便在每次提交或推送时自动将更新的内容复制到发布仓库。 需要配置 GitHub 的 ssh，可以有权限访问两个仓库 需要配置发布仓库的 deploy key，可以有权限写入发布仓库 域名获取 GitHub 二级域名 GitHubPages liuluhua.github.io 二级域名 https://freedomain.one/ linglu.work.gd cloudflare 托管 https://dash.cloudflare.com/ 解析包括添加三条解析记录 192.30.252.153 是 GitHub 的地址，你也可以 ping 你的 http:你的用户名.github.io 的 ip 地址，填入进去。 第三个记录类型是 CNAME，CNAME 的记录值是：http:你的用户名.github.io 这里千万别弄错了。 绑定 Github 域名，登录 GitHub，进入之前创建的仓库，点击 settings，设置 Custom domain，输入你的域名 PicGo 和 Github 图床配置PicGo 是一个开源的图片上传工具，主要用于将本地图片上传到各种图片托管服务，并生成图片链接。它提供了图形界面和命令行两种方式来使用。 用途图片托管：将本地图片上传到图片托管服务，如 GitHub 等。图片压缩：在上传图片之前，可以选择对图片进行压缩以减小图片文件大小，节省存储空间和加快图片加载速度。图片管理：通过 PicGo 上传的图片可以在相应的托管服务上进行管理，包括查看、删除等操作。图片链接生成：上传成功后，PicGo 会生成图片链接，方便在博客、论坛等地方直接使用图片。 GitHub 图床配置 创建一个 public 仓库 进入 Settings-Developer Settings-Personal access tokens (classic) 生成 token 设置自定义域名为 https://raw.staticdn.net/liuluhua/liuluhua.github.io/ImageBed 配置 Github 图床图床设计选择 GitHub，输入在 GitHub 的仓库名，分支名和 token 即可 设置 GitHub 为默认图床 设置图床参数 设定存储路径 插件 super-prefix安装 super prefix 插件，将图片存储时按照时间分类存储（Nodejs 环境） 配置文件路径插件 需要在 PicGo 设置中关闭时间戳重命名 /img/2019/11/18/20191118005858.jpeg 参数 建议值 说明 prefixFormat YYYY/MM/DD/ 文件名个性前缀格式 (以结尾) fileFormat YYYYMMDDHHmmss 文件名个性格式 Emo 插件如果不想要在配置 picGo 软件，直接用 Obsidian 中的 Emo 插件即可，相比起来缺少了自定义域名等功能 GitHubGithub Pages 部署GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。 创建 GitHub 账号，并创建一个基于用户名.github.io 的仓库 使用 GitHub Pages 进行部署，所建仓库必须取名为“GitHub 用户名.github.io” 勾选“Add a README file”，不然后面会看不到 GitHub Pages 域名和部署分支 仓库需要创建为公有仓库，即 public 仓库大小限制为 创建完成后 GitHub Pages 给我们提供了一个格式为 https://GitHub用户名.github.io 的免费域名，并且相应的网站是从该仓库的 mainmaster 分支构建得到的 自定义域名，在 GitHub 仓库 Settings-Pages-Custom domain 添加自己的域名 Git HookGit hook 是一种机制，允许在特定的 Git 事件发生时触发自定义的脚本或命令。这些事件可以包括提交 (commit)、推送 (push)、合并 (merge) 等。使用 Git hook，你可以在这些事件发生时执行自定义的操作，比如运行测试、格式化代码、触发构建等。Git 提供了一系列的预定义钩子，你可以将自己的脚本绑定到这些钩子上，或者创建自定义的钩子。 GitHub ActionsGitHub Actions 是 GitHub 提供的一项持续集成（CI）和持续部署（CD）服务，允许开发者自动化软件开发工作流程。通过 GitHub Actions，你可以在 GitHub 上运行自定义的代码（称为动作），以响应存储库中的事件，例如推送代码、创建拉取请求等。 一个 GitHub Actions 的核心概念是 workflow（工作流），它是一系列由动作组成的自定义任务，这些任务可以在特定的事件触发时自动执行。每个 workflow 都定义了一系列步骤，每个步骤又包含一个或多个动作。workflow 可以用 YAML 格式定义，并存储在存储库的 .github/workflows 目录中。 通过 GitHub Actions，实现将代码同步 GitHub 之后，由 GitHub Actions 执行页面的发布。 执行 GitHub Actions，在需要执行的储存库中前往 Settings Pages Source，并将 Source 改为 GitHub Actions。 在储存库中建立 .github/workflows/blogPublish.yml 并写入内容 环境变量配置在 Settings – Secrets and Variables – Actions 里面,配置后，可以在 actions 里面通过 $ secrets.dingtalk_secret 调用到对应的数据 文章更新时间问题使用 Github Actions 造成的文章更新时间问题参考原文： https://mrseawave.github.io/blogs/articles/2021/01/07/ci-hexo-update-time/ 当使用 Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。对于 Github Actions 可以使用命令在构建之前进行处理 jobs: deploy_gh_pages: steps: - name: Restore file modification time run: | git ls-files -z | while read -d path; do touch -d $(git log -1 --format=@%ct $path) $path; done 如果 git 命令不好用， 也可以使用 find 命令 find source/_posts -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果 github actions 中使用 actionscheckout@v2，请设定它的参数 fetch-depth: 0，因为 0 表示获取所有分支和标签的所有历史记录。默认值为 1 gitignore在 Git 仓库的根目录下编辑有.gitignore 文件，该文件中定义了一些不需要上传至 GitHub 的内容，列在该文件中的文件或文件夹将会被忽略，不在上传 Hexo 忽略文件.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_multiconfig.yml Obsidian 忽略文件.obsidian/workspace .obsidian 文件本身是可以同步的，当前存储库的插件以及相关的配置都会下载在这个文件夹中，因此将其同步到 git 记录中也是非常有用的，假如你切换设备就不需要重新为当前的存储库重新配置 Obsidian 了。 GitHub 仓库部署源码仓库部署 创建一个私有仓库，此处我创建一个 BlogDeploy 仓库，仓库拉取到本地后，在仓库中部署 Hexo使用 创建 gitignore 文件，排除 Hexo 不用上传的文件 同步仓库到远端 发布仓库部署 创建一个 GitHub 仓库，仓库必须取名为“GitHub 用户名.github.io” 仓库需要创建为公有仓库，即 public 创建一个分支，分支名为 ImageBed，用于做图床上传 获取 Token，选择用户 Settings-Developer settings-Personal access tokens，token 的权限获取，勾上 workflow 即可 图床分支创建用于存储图片，图床分支的相关信息部署完成后，需要在 PicGo 中进行配置 git checkout -b my-test //在当前分支下创建my-test的本地分支分支git push origin my-test //将my-test分支推送到远程git branch --set-upstream-to=origin/my-test //将本地分支my-test关联到远程分支my-test上 git branch -a //查看远程分支 Hexo 部署Hexo 是一个基于 Node.js 的静态网站生成器，主要用于快速、简单地搭建个人博客或静态网站。它采用 Markdown 格式来撰写内容，并提供了丰富的主题和插件生态系统，可以轻松扩展和定制网站功能和外观。 适用于个人博客、项目文档、个人简历等各种静态网站的搭建和管理。 目录架构_config.yml #网站的配置信息package.json #应用程序的信息scaffolds #模版文件夹source #存放用户资源，Markdown 文档\t_drafts\t_poststhemes #主题文件夹public #网站文件 Hexo 使用使用流程 安装 hexosudo npm install -g hexo-cli 查看版本，确认安装成功 hexo -v 创建一个新文件夹 Hexo，并初始化该文件夹 hexo init Hexo 清除缓存 hexo clean 生成静态文件 hexo g 开启本地服务器并修改端口为 80hexo s -p 9050 常用命令 npm install -g hexo-cli #安装Hexo npm update hexo -g #升级 hexo init #初始化博客 命令简写 hexo n 我的博客hexo new 我的博客 #新建文章 hexo ghexo generate #生成 hexo shexo server #启动服务预览 hexo dhexo deploy #部署 hexo server #Hexo会监视文件变动并自动更新，无须重启服务器 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令端口修改 node_modules\\hexo-server\\index.js 临时启动 hexo s -p 9050 hexo generate 将 Hexo 源码目录中已有的源码编译生成为静态网页文件，生成以下： db.json 文件：编译过程中产生的中间文件，不用关心； public 文件夹：新生成的静态网页文件就存放在这个目录下。 hexo deploy 将静态网页文件推送到 GitHub Pages Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容 快捷编辑配置文件站点配置文件和主题配置文件是我们 DIY 博客经常要编辑的两个文件，在 Obsidian 中没法编辑 yml 文件，可以通过 URL 来打开 yml 文件，会自动调用默认的编辑器打开。创建一个专门用于编辑配置的文件，写入我们两个配置文件所在的相对路径： [打开站点配置文件](Blog/_config.yml)[打开主题配置文件](Blog/themes/stellar/_config.yml)# 或者通过osidian插件shellcommands打开.开头的隐藏文件[Github 同步忽略文件配置](obsidian://shell-commands/?vault=BlogDeployexecute=f4b02rlcvr) 站点配置文件在 blog 根目录里的 _config.yml 文件称为站点配置文件 主题修改:theme 网站标题:title 副标题:subtitle 网站描述:description 作者:author 网站头像外部链接:avatar 网站语言:language:zh-Hans 时区:timezone:AsiaShanghai 自定义域名：url: 忽略文件： skip_render: # 排除一些obsidian编辑器的文件和一些脚本/模板文件 - _posts/.obsidian/* - _posts/Scripts/* - _posts/Templates/* 主题配置文件使用的主题：stellar 或者 Next，二选其一 进入根目录 themes 文件夹，里面有个 _config.yml 文件，为主题配置文件 社交外链的设置，即在侧栏展示你的个人社交网站信息。(插件 jiathis) 插入网易云，进入网页版的网易云音乐，选择喜欢的音乐，点击生成外链播放器，在侧栏插入这首歌的音乐播放器，修改 blog/themes/next/layout/_macro 的 sidebar.swig 文件，添加刚刚复制的外链代码 设置背景，在 blog/themes/next/source/css/_custom 文件的 custom.styl 首部添加 body background:url(./background.jpg); background-attachment: fixed; ，fixed 固定背景图片 增加侧栏菜单条目，默认的侧栏菜单条目有：首页、归档、标签、关于、搜索等。如果你想要增加其他的菜单条目，修改主题配置文件 _config.yml 里的 Menu Settings 中的 menu 和 menu_icons 两个地方 域名配置文件进入 blog/source 目录下，创建一个文件，文件名 CNAME，写入你的自定义域名 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 扩展：abbrlink文章永久链接 category并列分类，了解一下： categories: - [Linux] - [Tools]并列+子分类，再了解一下： categories: - [Linux, Hexo] - [Tools, PHP] 自定义文章标签生成标签页面 hexo new page tags，修改 blogsourcetagsindex.md，添加 type: “tags” title: tagsdate: 2023-01-08 11:27:57type: tags 以后就可以在文章文件头添加标签了，如下 title: Hexo + GitHub 搭建个人博客date: 2023-01-07 13:15:00tags:- Hexo- Next- 博客 手动生成和添加是十分繁琐的，后续利用插件形式按照目录格式为文章自动生成标签。 部署插件 hexo-deployer-git 编辑 Hexo 顶层目录下的 _config.yml 文件，文件最后可以看到 deployment 相关内容 deploy： type: git repo: git@github.com:liuluhua/liuluhua.github.io.git branch: main repo 填写仓库 ssh 地址 branch 的填写需要和 GitHub Pages部分指定的Branch保持一致 搜索插件 hexo-generator-searchdbstellar 自带了搜索插件，故未配置该插件 安装 hexo-generator-searchdbnpm install hexo-generator-searchdb 修改主题配置文件 local_search:\tenable: true 自动标签插件 hexo-auto-category该插件在 Hexo 进行 build 的时候会去自动根据文章目录情况来自动修改文章的 categories 信息 安装插件 npm install hexo-auto-category --save 修改站点配置文件 _config.yml，使文章链接清晰 # Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the max_depth of directory-tree you want to generate, should 0# multiple: multiple category hierarchiesauto_category: enable: true multiple: true depth: 5# 修改 permalink 让你的文章链接更加友好，并且有益于 SEO permalink: :year/:month/:hash.html# 规定你的新文章在 _post 目录下是以 cateory new_post_name: :category/:title| 该插件需要每次手动构建执行 hexo g 时才会更新 categories 信息。 仓库部署在本地，上传时使用 git hook，在我们每次执行 commit 前都自动运行 npx hexo generate 触发自动生成 categories 的行为，并将生成后的变更自动添加到本次提交中，然后一同 push 到 github 上去。这里可以使用 husky 来很方便的设置这样一个 git hook 1. 安装 huksy：npm install husky --save-dev 2. 执行 huksy 初始化指令：npx husky install *3. 在 package.json 中的 scripts 中写入：prepare: husky install 4. 在生成的 .husky 目录创建 pre-commit 文件（chmod a+x pre-commit），并写入以下内容，之后提交代码时，检查有无 categories 的生成信息。 #!/usr/bin/env sh . $(dirname -- $0)/_/husky.sh npx hexo generate git add . 仓库部署在 GitHub 时直接利用 GitHub Actions 自动生成 站点地图 hexo-generator-sitemap修改主题配置文件 menu: sitemap: /sitemap.xml || fa fa-sitemap 执行 hexo cl hexo g 生成 sitemap.xml 此时可以在 blog/public 文件夹下看到 sitemap.xml 验证，进入 Google Search Console ，选择网址前缀，输入网址时记得加上 https:，选择 HTML 标记，你会得到元标记 meta name=google-site-verification content=xxxxxxxx /，将 content 后的内容加入到主题配置文件中 google_site_verification: xxxxxxxx，执行 hexo cl hexo g hexo d 点击前往资源页面，添加站点地图，成功提交 静态资源压缩 hexo-neat主题配置文件添加配置 neat_enable: trueneat_html: enable: true exclude:neat_css: enable: true exclude: - **/*.min.cssneat_js: enable: true mangle: true output: compress: exclude: - **/*.min.js 字数统计 hexo-word-counter评论系统 utterancUtterances 是一个基于 Github Issues 的轻量级评论系统，主页地址 http://utteranc.es Hexo Stellar 主题的配置文件如下： ######## Comments ########comments: service: utterances # beaudar, utterances, giscus, twikoo, waline, artalk comment_title: 快来参与讨论吧~ # utterances # https://utteranc.es/ utterances: repo: liuluhua/liuluhua.github.io issue-term: title issue-number: theme: preferred-color-scheme label: 💬 其他使用情况下，在你的网页需要插入 Utterances 评论的位置，粘贴以下代码（username，reponame 分别修改为你的 GitHub 用户名，仓库名）。 script src=https://utteranc.es/client.js repo=username/reponame issue-term=pathname theme=github-light crossorigin=anonymous async/script 设置字体霞鹜文楷字库 GitHub 地址： https://github.com/lxgw/LxgwWenKai 更改站点配置文件，增加如下字段 inject: head: link rel=stylesheet href=https://cdn.jsdelivr.net/gh/satouriko/LxgwWenKai_Webfonts@v1.101/dist/LXGWWenKaiMono-Bold.css / 更改主题配置文件，找到 style 字段在 font-family 中增加字体名称： style: font-family: logo: LXGWWenKaiMono body: LXGWWenKaiMono code: LXGWWenKaiMono codeblock: LXGWWenKaiMono Canvas nest 背景动画 在 blog/source/_data 文件夹下新建 footer.njk 并编辑 script color=0,255,255 opacity=1 zIndex=-1 count=70 src=https://cdn.staticfile.org/canvas-nest.js/1.0.1/canvas-nest.js/script 修改主题配置文件 custom_file_path: footer: source/_data/footer.njk stellar 主题中直接添加在主题配置文件 _config.yml footer 的 content 中 设置背景音乐在 stellar 主题的 _data/widgets.yml 文件中找到 welcome 字段，在其中的 content 部分添加： welcome: layout: markdown title: 哈喽~ 旅人： content: |iframe frameborder=no border=0 marginwidth=0 marginheight=0 width=224 height=86 src=//music.163.com/outchain/player?type=2id=512983678auto=1height=66/iframe 百度数据分析进入 https://tongji.baidu.com/ 申请账号后，输入网址获取统计代码，之后在 stellar 主题的配置文件 _config.yml 的扩展插件部分插入以下代码： baiduanalytics: enable: true # 使能百度分析接口 inject: | ...扩展插件代码 MathJax 安装 hexo-filter-mathjax 修改主题配置文件 math: mathjax: enable: true 此后可在文章文件开头添加参数 mathjax: true 以使用 MathJax CDN 修改主题配置文件 vendors: plugins: custom custom_cdn_url: https://cdn.staticfile.org/$cdnjs_name/$version/$cdnjs_file 运行时间next 主题在 /blog/themes/next/layout/_partials/footer.njk 中添加 stellar 主题在主题配置文件 _config.yml 中找到 footer: 中的 content: |，在其后添加 div span id=timeDate载入天数.../span span id=times载入时分秒.../span/divscript var now = new Date(); function createtime() var grt= new Date(05/20/2024 05:20:00);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )hnum = 0 + hnum; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )mnum = 0 + mnum; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )snum = 0 + snum; document.getElementById(timeDate).innerHTML = 本站已安全运行 +dnum+ 天 ; document.getElementById(times).innerHTML = hnum + 小时 + mnum + 分 + snum + 秒; setInterval(createtime(),250);/script 文章页眉显示标签用于 next 主题 在 blog/source/_data 文件夹下新建 post-meta.njk 并编辑 span class=post-meta-item %- if post.tags and post.tags.length % %- set tag_indicate = i class=fa fa-tag/i if theme.tag_icon else # % span class=post-tags %- for tag in post.tags.toArray() % a href= url_for(tag.path) rel=tag tag_indicate tag.name /a %- endfor % /span %- endif %/span 修改主题配置文件 custom_file_path: postMeta: source/_data/post-meta.njk 评论系统 Waline Waline评论系统的配置 前往 Waline 官网 根据指引到 Vercel 进行 Waline 服务端部署 安装 @walinehexo-nextnpm install @waline/hexo-next 为了不使用魔法也能正常评论，我们需要有自己的域名解析到 Waline 服务端，可以在域名控制台给自己的博客域名添加二级域名，添加 CNAME 解析到 cname-china.vercel-dns.com 或添加 A 解析到 76.223.126.88（也可以前往 Vercel All IP 自行挑选合适的节点），接着进入 Vercel 的 Waline 应用的控制台，在 Settings-Domains 里添加上文提到的二级域名，这样在主题配置文件添加配置后就可以正常评论了 主题配置文件添加配置 配置完评论后及时到 Waline 服务端登录，以便管理评论 可选择开启评论邮件提醒功能， Waline 官网 有详细的说明 阅读量统计用于 next 主题 Leancloud（https://console.leancloud.cn/） 创建应用，进入该应用的 设置-应用凭证，找到 AppID 和 AppKey，记录下来后面配置要用 配置 _config.yml 启用网页访问统计，配置 leancloud 的 app_id 和 app_key，打开计数功能，统计来源改为 leancloud #网页访问统计#Analysis of website visitorsweb analytics:\tenable:trueleancloud:\tapp id: app key: # 浏览量计数# Number of visitsviews:\tenable:true\t#统计数据来源\t#Data Source\t#Options:busuanzi | leancloud\tsource:leancloud\tformat:次 PV、UV 统计数用于 next 主题显示页面的访问量和访客数量 # 展示网站的 pv、w 统计数# Display website pv and uv statisticsstatistics:\tenable:true\t#统计数据来源，使用leancloud 需要设置web analytics:leancloud中的参数;busuanzi 显示统计数据很大属于正常现象，部署后会正常\t# Data source.If use leancloud,you need to set the parameter inweb analytics:leancloud\t# Options:busuanzian | leancloud\tsource:leancloud\t#页面显示的文本，是数字的占位符(必须包含)，下同\t# Displayed text, is a placeholder for numbers (must be included), the same below\tpv format:总访问量 次\tuv format:总访客数 人 词句 APIp id=hitokotoa href=# id=hitokoto_text:D 获取中.../a/pscriptfetch(https://v1.hitokoto.cn).then(response = response.json()).then(data = const hitokoto = document.querySelector(#hitokoto_text)hitokoto.href = `https://hitokoto.cn/?uuid=$data.uuid`hitokoto.innerText = data.hitokoto).catch(console.error)/script","categories":["0.平台","服务器","博客"]},{"title":"Markdown笔记","path":"/2024/05/16/1-语言-工具语言-Markdown笔记/","content":"Markdown 笔记语法表格 文本样式 样式 语法 示例 加粗 前后 ** 或 __ 加粗 1 加粗 2 斜体 前后 * 或 _ 斜体 1 斜体 2 删除线 前后 ~~ 删除线 内联代码 前后 code 下划线 前u 后 /u 下划线 高亮 前后== 高亮文本 引用 此内容为引用内容 链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接 Blog网址 图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中 图片可拖动为文件到任意窗口使用 无序列表 项目 项目 1 项目 A 项目 B 项目 2 有序列表 项目 1 项目 A 项目 B 项目 2 任务列表 A 计划 A1 计划 A2 计划 B 计划 代码块代码块支持 168 种编程语言 // javascript 冒泡排序function bubbleSort(array) let swapped = true; do swapped = false; for (let j = 0; j array.length; j++) if (array[j] array[j + 1]) let temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; swapped = true; while (swapped); return array; KaTeX 数学公式内联公式质能方程 $Emc^2$ 公式块$$\\displaystyle \\left( \\sum_{k1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k1}^n a_k^2 \\right) \\left( \\sum_{k1}^n b_k^2 \\right)$$","categories":["1.语言","工具语言"]},{"title":"Nginx学习笔记","path":"/2024/05/16/3-软件-Web相关-Nginx学习笔记/","content":"Nginx功能Nginx 是一款功能强大的网络服务器，广泛用于处理高并发连接。以下是 Nginx 的一些主要功能： Web 服务器：可以高效地提供静态内容，如 HTML 页面、图片和视频。 负载均衡：将请求分散到多个后端服务器，确保用户在高流量情况下依然获得快速响应。例如，当网站流量突然增加时，Nginx 可以根据配置智能地将请求分配给不同的服务器，避免单台服务器过载。 API 网关：作为微服务架构中的中间层，Nginx 可以管理 API 请求，将其路由到适当的服务，并提供统一的接口给前端应用。 DDoS 防御：利用流量限制和 IP 黑名单等技术，Nginx 能有效抵御分布式拒绝服务（DDoS）攻击，确保网站继续正常服务。 反向代理：使用户请求经过 Nginx 后转发至后端服务器，为用户提供了透明的访问体验。比如，用户向 Nginx 请求数据，而用户并不知道数据实际上来自于不同的后端服务。 Web 应用防火墙：通过配置规则，对进入的请求进行过滤，帮助保护应用免受常见攻击，如 SQL 注入和跨站脚本（XSS）攻击。 缓存：Nginx 可以缓存响应内容，减少后端服务器的负担，从而提高网站性能。例如，访问量较大的网页在初次请求后，会被缓存，后续请求将直接从缓存中读取，提高了响应速度。 下载在大多数基于 Debian 的系统中，使用以下命令安装 Nginx： sudo apt install nginx -y 安装完成后，访问服务器的公网 IP 地址，你将看到 Nginx 的默认欢迎页面，表明安装成功。 配置 NginxNginx 的主要配置文件位于 /etc/nginx/ 目录下。要修改默认的配置文件，你可以使用以下命令： sudo vi /etc/nginx/sites-enabled/default 根据配置文件中的 root 指令，确认网页根目录位置为 /var/www/html。如果你想方便访问，可以链接网页根目录到用户的主目录： ln -s /var/www/html ~/html 配置文件进入 Nginx 的配置目录： cd /etc/nginx/sites-enabled 默认的配置文件可能以 default 命名。你可以删除此文件并替换为你的自定义页面配置。输入以下内容： server listen 8080; # 设置 Nginx 监听的端口 root /home/ubuntu/html; # 网站根目录，确保使用绝对路径 location / index index.php index.html index.htm; # 默认访问的首页 # 如果你使用 PHP，这里是 PHP 文件解析的配置示例 # location ~* \\.php$ # fastcgi_index index.php; # fastcgi_pass 127.0.0.1:9000; # include fastcgi_params; # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param SCRIPT_NAME $fastcgi_script_name; # # 自定义错误页面规则 # error_page 404 /404.html; # location = /40x.html # error_page 500 502 503 504 /50x.html; # location = /50x.html 对于反向代理的配置示例如下： http upstream backend1 server 127.0.0.1:8000; # 定义后端服务器（服务1） upstream backend2 server 127.0.0.1:8001; # 定义后端服务器（服务2） server listen 80; # Nginx 监听的端口 location /service1/ proxy_pass http://backend1; # 将请求转发到服务1 location /service2/ proxy_pass http://backend2; # 将请求转发到服务2 在编辑完配置文件后，可以使用以下命令检查配置文件的正确性： nginx -t 确保没有错误后，重新启动 Nginx 服务以使更改生效： sudo systemctl start nginxsudo systemctl enable nginx # 设置开机自动启动 随后，直接在浏览器中输入服务器的 IP 地址加上设置的端口即可访问网站。 修改页面，重载页面在修改完页面内容后，如果需要 Nginx 重新加载配置，可以使用： sudo nginx -s reload 常用命令 查看 Nginx 版本： nginx -v 配置文件所在位置为 /etc/nginx，主配置文件通常命名为 nginx.conf。 检查配置文件中的潜在问题： nginx -t 重新加载 Nginx 配置文件以应用更改： nginx -s reload 停止 Nginx 服务： nginx -s quit # 或使用 nginx -s stop 关键配置项说明 events: 定义 Nginx 事件处理模型。 http: 设置 HTTP 相关的配置选项。 server: 每个 server 块定义了一台虚拟服务器。 include: 用于包含外部配置文件。 listen: 指定 Nginx 监听的端口号。 server_name: 设置允许的主机名，支持多个域名。 root: 定义网站根目录的位置。 index: 指定默认访问的页面名称。 return: 发送特定的 HTTP 响应。 location: 处理特定 URI 的请求，支持完全匹配和正则表达式匹配。 rewrite: 用于 URL 重写，可以改变请求的 URL 格式。 proxy_pass: 指定请求转发的目标地址。","categories":["3.软件","Web相关"]},{"title":"ffmpeg-m3u8转mp4","path":"/2024/05/16/3-软件-音视频-ffmpeg-m3u8转mp4/","content":"FFmpeg 命令行工具将 m3u8 文件转换为 mp4 格式 下载并安装 FFmpeg您可以从 官方网站 下载适合您操作系统的版本。 打开命令行工具 在 Windows 上，您可以按下 Win + R 键，然后输入 cmd 并按 Enter 键打开命令提示符。 在 Mac OS 或 Linux 上，您可以打开终端应用程序。 转换 m3u8 文件在命令行中，导航到包含 m3u8 文件的目录，然后运行以下命令： ffmpeg -i input.m3u8 -c copy output.mp4 input.m3u8 是要转换的 m3u8 文件的名称，output.mp4 是转换后的 mp4 文件的名称。 该命令将使用 FFmpeg 将 m3u8 文件转换为 mp4 格式，并将其保存在相同的目录中。 请注意，此命令只能将 m3u8 文件转换为 mp4 格式，而不能将其中的视频文件下载到本地计算机。 如果您需要下载 m3u8 文件中的视频文件，请使用其他工具或软件。 将分段式 m3u8 文件转换为 MP4 文件#!/bin/bashcd ./m3u8Movie #分段式m3u8文件所在文件夹for i in 1..2473 #轮询所有分段式文件数量do if [ -f $i ]; then #检测文件存在 mv $i $i.mp4 #重命名 fi echo file ./$i.mp4 list.txt #添加到列表中去done#调用ffmpeg进行视频连接操作ffmpeg -f concat -safe 0 -i list.txt -c copy ../movie.mp4#-f 指定输入格式为concat，表示要进行视频文件的连接操作#-safe 0 设置安全模式为0，允许使用不安全的文件名#-i 指定文本文件包含了要连接的视频文件的列表及其路径#-c 直接复制输入视频文件的音视频流，而不进行重新编码。这样可以加快处理速度而不损失质量。#指定输出文件路径和名称","categories":["3.软件","音视频"]},{"title":"Qt多项目管理","path":"/2024/03/03/1-语言-Qt-Qt多项目管理/","content":"Qt 工程过大或需要将工程分模块编译成库的形式加载时,需要将整体的 Qt 项目拆分各个小模块进行编译。 1.条件编译文件unix //执行unix环境下的配置选项win32 //执行Windows环境下的配置选项contains(QT_ARCH, arm64) //执行在架构为arm64的环境下的配置选项 2. 子项目 lib子项目工程文件为 QT -= guiTARGET = printHelloCONFIG += staticlibTEMPLATE = libDEFINES += printHello_LIBRARYCONFIG -= debug_and_releaseSOURCES += printHello. cppHEADERS += printHello. h 3. 子项目 dllQT -= guiTARGET = printNiceTEMPLATE = libDEFINES += printNice_LIBRARYCONFIG -= debug_and_releaseSOURCES += printNice. cppHEADERS += printNice. h 4.可执行程序项目 exeQT += core gui widgetsTARGET = printTEMPLATE = appSOURCES += main. cpp printwindow. cppLIBS += -LprintHello -lprintHello -LprintNice -lprintNiceFORMS += printwindow. uiHEADERS += printwindow. h 5.管理项 DirsTEMPLATE = subdirsSUBDIRS += printHello/printHello.pro printNice/printNice.pro print.proCONFIG += ordered","categories":["1.语言","Qt"]},{"title":"金融学","path":"/2023/12/03/4-其他-金融-金融学/","content":"金融学什么是金融和金融学金融是一个广泛的概念，涵盖了资金的获取、使用和管理。它不仅关乎个人的理财和企业的投资决策，还涉及国家整体经济的运作。例如，家庭通过贷款购房、企业通过融资扩展业务，以及政府通过发行债券筹集资金，都是金融活动的表现。金融学则是研究金融现象、行为及其机制的学科。它提供理论框架和实用工具，帮助我们理解和分析各种金融活动的动态。 金融体系概述金融体系是由金融市场、金融机构、金融工具和金融监管构成的复杂网络。金融市场是进行资金交易的场所，比如股票交易所和债券市场；金融机构包括银行、保险公司、投资公司等，负责资金的中介和管理；金融工具如股票、债券和衍生品，用于转移风险和实现投资回报；而金融监管则确保市场的稳定性和透明性。例如，证券监管委员会负责监管股票市场，以保护投资者的利益。 货币什么是货币货币是一种普遍接受的交换媒介，用于商品和服务的交易。它不仅共有价值，还能作为价值的储存手段和计量单位。值得注意的是，货币的定义与在日常生活中对它的感性认识密切相关。比如，我们在超市看到的一张纸币，正是货币作为交换媒介的重要体现。 货币的感性认识人们对货币的直观理解往往停留在纸币和硬币等实物形式上。然而，随着数字支付的普及，电子货币（如支付宝、微信支付）也成为了日常交易的重要组成部分。它们在便利性上大大超过了传统货币，体现了货币概念的不断演变。 货币的理论追溯 起源：货币的起源可以追溯到早期的物物交换。在这种交易中，双方需要找到彼此都想要的商品，这常常事倍功半。为了简化交易，社会逐渐引入了一些被广泛认可的物品（如贝壳、盐、金属）。最终，这些物品演化为今天的货币。 本质：货币本质上是一种社会合约，它的价值基于人们的信任和共识。即使在金本位制下，纸币的真正价值并不在于纸张本身，而在于它能够兑换成一定量的黄金或其他商品。 职能：货币主要具有以下几种职能：作为交换媒介（简化买卖过程），作为价值尺度（提供价格标准），以及作为价值存储（允许财富的积累）。 货币的实际测算 货币层次的划分：货币层次通常分为几个级别，如 M0、M1 和 M2。M0 指流通中的现金，M1 包括 M0 及活期存款，而 M2 则涵盖 M1 和各类定期存款。通过货币层次的划分，经济学家能够更好地分析货币供给和需求的变化。 货币制度货币制度是一个国家针对货币发行、流通及管理的一系列法律、制度和政策的总和。它直接影响着经济的稳定性与发展。 货币制度的构成要素主要构成要素包括： 货币发行机构：通常为中央银行，负责控制货币的供应量和利率。 货币政策工具：如利率调整、公开市场操作等，用于调控经济。 货币的种类：包括法定货币和数字货币等。 货币制度类型货币制度可以依据货币的性质、流通方式和管理方式分类，如： 金本位制：货币的价值与黄金挂钩，提供了稳定性，但对货币政策的灵活性限制较大。 纸币制：现代流通中的纸币，可以较为灵活地调节经济。 数字货币制度：随着科技的发展，数字货币作为一种新兴货币形式正在逐渐体验发展和应用。 利息和利率信用和信用形式信用是指在缺乏即时支付的情况下，借贷双方的信任基础。信用形式有很多，包括个人信用、企业信用和国家信用等。高信用的个体或机构通常能获得更低的借款利率示例：拥有良好信用评分的个人更容易获得银行的贷款批准。 利率体系利率体系是指在一个经济体中，借贷和投资的利率水平如何形成和变化。通常，利率由市场供需关系、中央银行的货币政策、通货膨胀预期等多重因素决定。不同类型的贷款和投资会有不同的利率，如房贷、车贷和消费贷。 货币的时间价值货币的时间价值是指，相同金额的货币在不同时间点上的价值不同，这主要体现在未来的收益和当前的消费。这一概念是金融决策的核心。 终值：终值是指未来某一时点的货币价值，考虑了投资的利息。比如，一个人投资 1000 元，假设年利率为 5%，经过一年后，其终值为 1050 元。 现值：现值则是将未来的货币价值折现回现在的价值。例如，若一年后你将收到 1050 元，折现回现在以 5%的利率计算，现值约为 1000 元。 利率水平的决定利率水平受多种因素影响，包括经济增长率、通货膨胀、中央银行政策等。例如，当经济发展良好、就业率高时，消费者和企业借贷意向上升，利率可能上升；相反，经济放缓时，借贷需求下降，利率可降低。 利率结构理论利率结构理论使我们理解不同期限的贷款或投资利率如何变化。通常情况下，长期利率较高，因为较长时间的资金占用存在更大风险。同时，市场对基准利率的预期也会影响结构。例如，预期经济增长强劲时，长期利率可能上升。 利率的作用利率在经济中扮演着至关重要的角色。它不只影响个人的借贷成本和储蓄回报，也直接与企业的投资决策关联。高利率可能抑制消费和投资，进而影响经济增长，反之亦然。因此，中央银行需通过调整利率来实现经济稳定。例如，在经济衰退期间，降低利率可以激励消费和投资，从而促进经济复苏。 外汇与汇率外汇和汇率的基本概念外汇是指一个国家的货币在国际市场上和其他国家货币进行兑换的能力，通常涉及到贸易与投资的交易。学习外汇交易时，了解汇率的变化 、国际市场的走向以及政治经济因素至关重要。例如，如果你在中国，有 1,000 元人民币，想要在海外旅行并兑换成美元，那么你需要关注人民币对美元的汇率变动。 汇率则是两种货币之间的价格关系，通常表示为一种货币可兑换另一种货币的比率。例如，如果 1 美元等于 7 人民币，那么汇率就是 7。汇率的变化，可以受到多种因素的影响，包括经济数据、政治事件和市场情绪。 汇率标价方法汇率的标价方法主要有两种：直接标价法与间接标价法。直接标价法通常是将外币作为基准，比如在美元与人民币的关系中，1 美元7 人民币就是直接标价。而间接标价法则是将本国货币作为基准，比如在中国可以表述为 1 人民币0.14 美元。 主要类型汇率主要分为浮动汇率与固定汇率。浮动汇率是指市场力量自由调整下的汇率，比如欧元与美元间的汇率，就是随市场供求而变化的。而固定汇率则是由政府或中央银行设定并维持的，例如，香港自 1983 年以来将港元与美元固定在一个固定的汇率范围内。 基本计算计算汇率通常涉及两个主要货币的兑换率。假设你想将 500 美元兑换成人民币，若当前汇率为 1 美元7 人民币，你就可以简单计算：500 × 7 3500 人民币。计算对多个币种进行汇兑时，先查找相关汇率，再依次计算。 汇率制度汇率制度是一个国家或地区采取的管理其本国货币与外币之间汇率的政策及方式。常见的汇率制度包括： 浮动汇率制度：汇率由市场供求关系决定，波动较大，国家干预较少。 固定汇率制度：国家设定一个固定的汇率，并通过干预外汇市场保持这一汇率，通常是与主要外汇（如美元）挂钩。 管理浮动汇率制度：汇率在市场供需的基础上，由中央银行进行一定的干预，以防止汇率出现过大的波动。 以中国为例，自 1994 年以来实施的汇率制度，就在一定程度上管理汇率的浮动，为市场流动性和国际贸易提供一定保障。 汇率决定理论汇率的决定理论有几种主要的经济理论： 购买力平价理论（PPP）：这一理论认为不同国家的货币在购买相同商品时的能力应是一致的。例如，若一杯咖啡在美国售价 2 美元，在中国售价 14 元人民币，则理论上 1 美元应该等于 7 人民币。 国际费雪效应：根据这一理论，名义利率的差异影响汇率。如果美国的利率为 3%，而中国的利率为 1%，那么长期来看，应该会导致美元升值，人民币贬值。 资产市场理论：该理论强调汇率由市场投资者对两个国家货币的未来预期和信心决定，比如经济增长、政治稳定等因素都可能影响投资者的判断，从而影响汇率的波动。","categories":["4.其他","金融"]},{"title":"交易策略","path":"/2023/12/02/4-其他-金融-交易策略/","content":"交易策略在金融市场中，交易者和投资者经常使用均线指标来帮助他们做出决策。其中两个常用的均线是 50 天均线 和 200 天均线。 50 天均线50 天均线是过去 50 个交易日的平均价格。它可以帮助我们判断一个资产的短期趋势。当价格在 50 天均线之上时，这表明资产处于上升趋势；而当价格在 50 天均线之下时，则表明资产处于下降趋势。例如，如果某只股票的价格连续几天都在 50 天均线之上，这可能意味着市场对该股票有较高的兴趣，并且可能继续上涨。假设某科技股的价格在 50 天均线之上，且成交量也在增加，这可能是一个买入信号，表明投资者对该股的未来表现持乐观态度。 200 天均线200 天均线则用来观察资产的长期趋势。它是过去 200 个交易日的平均价格。长期投资者通常会使用这个指标来判断一个资产的整体走势。如果价格在 200 天均线之上，这往往意味着资产处于长期上升趋势；而如果价格在 200 天均线之下，则可能表明资产正处于长期下降趋势。举个例子，如果某只股票的价格连续几个月都在 200 天均线之下，这可能意味着市场对该股票的兴趣较低，并且可能继续下跌。比如，某家公司的股票在经历了一段时间的下跌后，价格始终未能突破 200 天均线，这可能会促使投资者重新评估该公司的基本面。 交易者的选择不同的交易者和投资者会根据自己的交易策略和风险承受能力来选择使用哪个均线指标。短期交易者通常更关注短期趋势，因此会选择使用较短的均线指标，如 20 天均线。例如，日内交易者可能会利用 20 天均线来捕捉快速的价格波动。而长期投资者更关注资产的整体走势，因此会选择使用较长的均线指标，如 50 天和 200 天均线。 其他交易策略除了均线指标，交易者还可以考虑以下几种策略： 相对强弱指数（RSI）：RSI 是一种动量指标，用于评估资产的超买或超卖状态。当 RSI 超过 70 时，资产可能被视为超买，反之，当 RSI 低于 30 时，资产可能被视为超卖。 布林带：布林带由三条线组成，分别是中间的移动平均线和上下两条标准差线。价格触及上轨可能意味着超买，而触及下轨则可能意味着超卖。 MACD（移动平均收敛发散指标）：MACD 是一种趋势跟踪动量指标，通过两条移动平均线之间的关系来判断买入或卖出信号。 支撑与阻力：支撑位是价格下跌时可能遇到的底部，而阻力位是价格上涨时可能遇到的顶部。交易者可以利用这些水平来制定进出场策略。 趋势线：通过连接价格图表上的高点或低点，交易者可以识别出趋势的方向，并据此做出交易决策。 通过结合这些策略，交易者可以更全面地分析市场，制定出更有效的交易计划。","categories":["4.其他","金融"]},{"title":"基金介绍","path":"/2023/12/02/4-其他-金融-基金介绍/","content":"基金介绍基金是一种集合投资工具，允许多个投资者将资金集中在一起，由专业的基金管理公司进行管理和投资。基金的主要目的是通过分散投资来降低风险，同时追求资本增值或收入。 基金的类型 股票基金股票基金主要投资于股票市场，目标是通过资本增值来实现投资回报。例如，某股票基金可能专注于科技行业，投资于如苹果、谷歌等公司的股票。 债券基金债券基金主要投资于固定收益证券，如国债、企业债等。这类基金通常风险较低，适合寻求稳定收入的投资者。例如，某债券基金可能专注于投资于 AAA 级别的企业债券，以确保较低的违约风险。 混合基金混合基金同时投资于股票和债券，旨在通过资产配置来平衡风险和收益。例如，某混合基金可能将 60%的资金投资于股票，40%投资于债券，以实现资本增值和稳定收入的双重目标。 货币市场基金货币市场基金投资于短期的、流动性强的金融工具，如国库券和商业票据。这类基金通常风险极低，适合希望保持资金流动性并获得小额收益的投资者。 基金的运作方式基金的运作通常包括以下几个步骤： 募集资金基金通过向投资者发行份额来募集资金。投资者购买基金份额后，资金将被集中管理。 投资决策基金经理根据市场分析和投资策略，选择合适的投资标的。比如，某基金经理可能会根据技术分析和基本面分析，决定在特定时机增持或减持某只股票。 收益分配基金的收益通常以分红或资本增值的形式分配给投资者。比如，某股票基金在年度结束时可能会将部分收益以现金分红的方式返还给投资者。 投资基金的优势 专业管理基金由经验丰富的专业人士管理，投资者可以借助他们的专业知识和市场洞察力，降低投资风险。 分散投资基金通过投资于多种资产，降低了单一投资的风险。例如，投资于一个股票基金，投资者的资金将分散在多个公司股票上，而不是集中在一两只股票上。 流动性大多数基金允许投资者在特定时间内赎回份额，提供了较好的流动性。例如，开放式基金通常允许投资者在每个交易日结束时赎回份额。 结论基金作为一种投资工具，适合不同风险偏好的投资者。通过了解基金的类型、运作方式和优势，投资者可以更好地选择适合自己的投资产品，实现财富增值的目标。","categories":["4.其他","金融"]},{"title":"Web3.0","path":"/2023/11/19/3-软件-Web相关-Web3-0/","content":"什么是 Web3.0Web3.0 是互联网的下一代版本，也被称为“分布式互联网”或“价值互联网”。与 Web1.0 和 Web2.0 不同，Web3.0 将建立在区块链技术之上，具有去中心化、安全性和隐私性等特点。它将为用户提供更多的控制权，让他们能够更好地管理自己的数据和资产。Web3.0 的应用场景包括去中心化金融、数字身份验证、物联网、供应链管理等。 去中心化金融Web3.0 的去中心化特点使其非常适合用于金融领域。未来，Web3.0 有望成为去中心化金融（DeFi）的主流形态，为用户提供更加安全、透明和高效的金融服务。 数字身份验证Web3.0 可以使用分布式身份验证技术来保护用户的身份和隐私。未来，Web3.0 有望成为数字身份验证的主流形态，为用户提供更加安全和便捷的身份验证服务。 物联网Web3.0 可以与物联网技术结合，从而实现更加智能和自动化的物联网应用。未来，Web3.0 有望成为物联网的主流形态，为用户提供更加便捷、智能和安全的物联网服务。 供应链管理Web3.0 可以使用区块链技术来实现供应链管理的透明化和自动化。未来，Web3.0 有望成为供应链管理的主流形态，为企业提供更加高效、安全和可靠的供应链管理服务。 去中心化数据用户在 Web3.0 网络中产生的各种数据，包括但不限于以下几类： 个人身份信息：Web3.0 应用可以使用分布式身份验证技术来保护用户的身份和隐私。这些身份信息包括用户的姓名、地址、电话号码、电子邮件地址等个人信息。 数字资产信息：Web3.0 使用区块链技术来管理数字资产，这些数字资产包括加密货币、数字艺术品、游戏道具等。 交易记录：Web3.0 应用中的交易记录是公开的，这意味着任何人都可以查看交易的发起方和接收方，以及交易的时间和金额等信息。 用户行为数据：Web3.0 应用可以记录用户在网络中的行为数据，例如用户访问的网站、搜索的关键词、点击的广告等。 这些数据可以通过 AI 进行分析和处理，从而提供更好的服务和体验。例如，AI 可以使用用户的个人身份信息来提供更加个性化的服务；使用数字资产信息来分析用户的投资偏好；使用交易记录和用户行为数据来预测市场趋势等。 元宇宙是一种虚拟现实（虚拟的真实世界）的概念，它是一个基于区块链和数字资产的虚拟世界，用户可以在其中进行交互和交易。具体来说，Web3.0 提供了以下数据方面的支持： 数字资产管理 去中心化身份验证 智能合约 资产数字资产 NFTNFT 是非同质化代币（Non-Fungible Token）的缩写，它是一种基于区块链技术的数字资产。与传统的加密货币不同，NFT 是不可替代的，每一个 NFT 都是独一无二的，拥有独特的价值和属性。在 Web3.0 中，NFT 可以用来代表各种数字资产，这为 Web3.0 提供了更加开放和自由的数字资产交易环境，也为数字内容的创作者提供了更多的收益来源。 NFT 的最大特点是可以用来代表任何类型的数字资产，例如数字艺术品、音乐、视频、游戏道具等。通过区块链技术，NFT 可以保证数字资产的唯一性和真实性，并且可以实现数字资产的所有权、交易和流通。 NFT 的交易通常是在区块链上进行的，交易记录和资产所有权都会被永久地记录在区块链上，使得交易过程更加透明和可追溯。近年来，NFT 在数字艺术品市场上得到了广泛的应用，一些数字艺术品以高价成交，引起了社会各界的广泛关注。 探讨Web3.0 应用的去中心化的特点使其相对于传统互联网应用更难被追踪。这是因为 Web3.0 应用不依赖于中心化的机构或公司来管理和维护网络，而是由网络中的节点共同维护和管理。这意味着没有单一的控制点，使得监管和追踪变得更加困难。 此外，Web3.0 应用使用加密技术来保护用户的数据和资产，使得用户可以在不泄露个人信息的情况下使用网络。这有助于防止个人信息被滥用和泄露。 然而，应该注意的是，Web3.0 应用并不是完全匿名的。虽然用户可以使用假名或匿名身份来访问网络，但是他们的行为和交易仍然可以被追踪。例如，区块链上的交易记录是公开的，这意味着任何人都可以查看交易的发起方和接收方。因此，虽然 Web3.0 应用相对于传统互联网应用更难被追踪，但仍然需要注意个人信息的保护和隐私的维护。 应用场景智能合约 自动化和执行合同，而 AI 可以帮助智能合约更好地理解和分析合同条款。这可以提高智能合约的效率和准确性，从而降低成本和风险。 分析和预测市场趋势 帮助用户做出更明智的投资决策。 更好的用户体验 例如通过自然语言处理技术来实现更智能的客户服务。 物联网和供应链管理 优点 ** 去中心化：**Web3.0 建立在区块链技术之上，具有去中心化的特点。这意味着没有中心化的机构或公司掌控网络，而是由网络中的节点共同维护和管理，从而降低了单点故障的风险。 ** 安全性：**Web3.0 使用加密技术和智能合约来保护用户的数据和资产，从而提高了网络的安全性。由于数据和资产的所有权归用户所有，他们可以更好地控制自己的信息和资产。 ** 隐私性：**Web3.0 使用加密技术保护用户的隐私，使得用户可以在不泄露个人信息的情况下使用网络。这有助于防止个人信息被滥用。 ** 开放性：**Web3.0 是开放的网络，任何人都可以参与其中，从而促进了创新和发展。这使得 Web3.0 更具有包容性和透明性。 ** 智能合约：**Web3.0 使用智能合约来自动化和执行合同，从而降低了成本和风险。智能合约可以在不需要中介的情况下执行交易，从而提高了效率和可靠性。 缺点 技术和性能难题：Web3.0 需要整合多种新技术，例如区块链、人工智能、物联网等，这些技术本身也存在一些难题和挑战。例如，区块链技术目前仍然存在扩展性和性能问题，人工智能技术需要大量的数据和计算资源支持，物联网技术需要解决设备互联互通的问题等等。 标准化问题：Web3.0 需要建立一系列的标准和规范，以确保不同的技术和应用能够互相兼容和协同工作。目前，Web3.0 标准化还处于初步阶段，需要各方共同努力推进标准的制定和实施。 安全和隐私问题：Web3.0 的去中心化特性使得其更加安全和去中心化，但同时也带来了一些安全和隐私问题。例如，区块链技术本身并不是完全安全的，智能合约和去中心化应用也存在漏洞和攻击的风险。同时，Web3.0 的去中心化特性也可能导致个人隐私泄露的问题。 用户体验问题：Web3.0 需要为用户提供更加安全、去中心化和智能化的互联网体验，但是在实现过程中也需要考虑到用户体验的问题。例如，去中心化应用的使用门槛较高，需要用户具备一定的技术知识和操作能力，这可能会影响用户的使用体验。 ** 法律监管不完善：**Web3.0 的去中心化特点可能会导致法律监管的困难。例如，一些 Web3.0 应用可能涉及非法活动，但由于缺乏中心化的机构，可能难以监管和惩罚。","categories":["3.软件","Web相关"]},{"title":"串口终端软件picocom及putty的安装和配置","path":"/2023/08/22/2-通讯协议-串口-串口终端软件picocom及putty的安装和配置/","content":"串口和终端软件什么是串口工具接收和发送分开，只有点击发送时，才将数据发送，一般用于串口数据调试 什么是终端工具终端工具的连接方式多种多样，包含串口，SSH，telnet 等方式，一般用于登录服务器，进行命令行操作 putty 在 Ubuntu 环境下的离线安装和配置由于本次安装 putty 需要在内网环境中安装，所以只能通过离线方式安装，如果可以通过在线方式安装时，只需要输入 sudo apt install putty 进行安装即可。 下载离线安装包，进入官网后选择 Download PuTTY，下拉找到 Unix source archive,当前最新的版本是 putty-0.78.tar.gz putty官方下载地址 从 0.77 版本开始官方改用 CMake 构建 从 0.78 版本开始增加 Github actions 自动编译脚本，方便直接在线编译 2.由于我们是离线配置，所以在本地编译，使用 CMake 进行构建即可 解压压缩包 tar xvf putty-0.78.tar.gz 进入目录 cd putty-0.78 执行 cmake cmake . 执行完成后显示 在执行以下命令进行构建 cmake --build . 执行完成后显示 安装 cmake --build . --target install 此处推荐一个 汉化putty 的开源仓库,有兴趣可以尝试 picocom 在 Ubuntu 环境下的离线安装和配置picocom下载地址1.切换到 piccocom 的源目录 make 2.进行瘦身（非必要） strip picocom 3.移动到 /usr/bin 目录下使得可以在任意处执行命令（非必要） 使用方式执行 picocom -b 115200 -f h /dev/ttyS0 指定波特率,串口，流控","categories":["2.通讯协议","串口"]},{"title":"Nodejs和npm","path":"/2023/05/28/3-软件-Web相关-Nodejs和npm/","content":"更新 nodejs 到最新版本卸载自带的 nodejs sudo apt autoremove nodejs sudo apt purge nodejs 安装 20 版本的 nodejs curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - sudo apt-get install -y nodejs 查看版本是否更新，否则关闭命令行重新打开 nodejs -v 安装 nodejs 安装工具到全局 sudo npm install n -g 安装稳定版本 nodejs sudo n stable 安装 npmsudo apt install npm -y","categories":["3.软件","Web相关"]},{"title":"WireShark的安装","path":"/2023/05/25/3-软件-WireShark-WireShark的安装/","content":"WireShark重点演示： 如何选择网卡接口 如何设置过滤条件 如何查看抓取的报文 Linux 下安装和配置安装sudo apt-get install wireshark 设置运行权限如果您在此阶段以非 root 用户身份运行 wireshark，您将收到消息“没有接口可以用于在当前配置的系统中进行捕获。” 缺省在非 root 账号下运行会发现看不见 interface 信息 Create the wiresharkgroup. sudo groupadd wireshark Add your username to the wiresharkgroup sudo usermod -a -G wiresharkYOUR_USER_NAME Change the group ownership of file dumpcap to wireshark sudo chgrp wireshark/usr/bin/dumpcap Change the mode of the file dumpcap to allow execution bythe group wireshark sudo chmod 750 /usr/bin/dumpcap Grant capabilities with setcap, man capabilities(7), setcap(8), cap_from_text(3) for more info about what are “cap_net_raw”, “cap_net_admin” and “eip”. Anyway, after we grant the capabilities, the dump can perform various network-related operations, use RAW and PACKET sockets; bind to anyaddressfor transparent proxying. sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap Verifythe change sudo getcap /usr/bin/dumpcap Outputshould be like below: /usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip At this point, you will need to log out, then backinto ubuntu 简单介绍下这个软件的一些常用按钮，简单的说下最常用的按钮，打开软件后，下面红框中的按钮从左到右依次是： -1 列表显示所有网卡的网络包情况，一般用的很少； -2 显示抓包选项，一般都是点这个按钮开始抓包； -3 开始新的抓包，一般用的也很少； -4 停止抓包，当你抓完包之后，就是点这个停止了； -5 清空当前已经抓到的数据包，可以防止抓包时间过长机器变卡； 而实际上，一般我们只要知道上面加粗部分的按钮功能，就可以完成抓包了，剩下的就是如何抓你想要的数据包，如何分析的问题了。 接下来说下抓包选项界面，也就是点第二个按钮出来的界面，同样，这里也只介绍最常用的几个功能，首先下图中最上面的红框是选择需要抓的网卡，选择好网卡后会在下面显示这个网卡的 IP 地址。 然后 Capture Filter 中就是要写抓包规则的地方，也叫做“过滤规则”，我们下面要说的很多规则都是要写到这个框里的，规则写好后，点下 面的 Start 就开始抓包了。 当抓包结束之后，如果你需要把抓到的数据包找其他人分析，那么可以点菜单上的 file，然后点 Save As 保存抓到的数据包 使用 Wireshark 时最常见的问题，是当您使用默认设置时，会得到大量冗余信息，以至于很难找到自己需要的部分。这就是为什么过滤器会 如此重要。它们可以帮助我们在庞杂的结果中迅速找到我们需要的信息。 三次握手 Three-way Handshake一个虚拟连接的建立是通过三次握手来实现的 (Client) – [SYN] – (Server)假如 Client 和 Server 通讯. 当 Client 要和 Server 通信时，Client 首先向 Server 发一个 SYN (Synchronize) 标记的包，告诉 Server 请求建立连接.注意: 一个 SYN 包就是仅 SYN 标记设为 1 的 TCP 包 (参见 TCP 包头 Resources). 认识到这点很重要，只有当 Server 收到 Client 发来的 SYN 包，才可建立连接，除此之外别无他法。因此，如果你的防火墙丢弃所有的发往外网接口的 SYN 包，那么你将不 能让外部任何主机主动建立连接。 (Client) – [SYNACK] –(Server)接着，Server 收到来自 Client 发来的 SYN 包后，会发一个对 SYN 包的确认包 (SYNACK) 给 Client，表示对第一个 SYN 包的确认，并继续握手操作.注意: SYNACK 包是仅 SYN 和 ACK 标记为 1 的包. (Client) – [ACK] – (Server)Client 收到来自 Server 的 SYNACK 包,Client 会再向 Server 发一个确认包 (ACK)，通知 Server 连接已建立。至此，三次握手完成，一个 TCP 连接完成。Note: ACK 包就是仅 ACK 标记设为 1 的 TCP 包. 需要注意的是当三此握手完成、连接建立以后，TCP 连接的每个包都会设置 ACK 位。 这就是为何连接跟踪很重要的原因了. 没有连接跟踪,防火墙将无法判断收到的 ACK 包是否属于一个已经建立的连接.一般的包过滤 (Ipchains) 收到 ACK 包时,会让它通过 (这绝对不是个 好主意). 而当状态型防火墙收到此种包时，它会先在连接表中查找是否属于哪个已建连接，否则丢弃该包。 四次握手 Four-way Handshake 四次握手用来关闭已建立的 TCP 连接 (Client) – ACKFIN – (Server) (Client) – ACK – (Server) (Client) – ACKFIN – (Server) (Client) – ACK – (Server)注意: 由于 TCP 连接是双向连接, 因此关闭连接需要在两个方向上做。**ACKFIN 包 (ACK 和 FIN 标记设为 1) 通常被认为是 FIN(终结) 包.**然而, 由于连接还没有关闭, FIN 包总是打上 ACK 标记. 没有 ACK 标记而仅有 FIN 标记的包不是合法的包，并且通常被认为是恶意的。 连接复位 Resetting a connection四次握手不是关闭 TCP 连接的唯一方法. 有时,如果主机需要尽快关闭连接 (或连接超时,端口或主机不可达),RST(Reset) 包将被发送. 注意在，由于 RST 包不是 TCP 连接中的必须部分, 可以只发送 RST 包 (即不带 ACK 标记). 但在正常的 TCP 连接中 RST 包可以带 ACK 确认标记 请注意 RST 包是可以不要收到方确认的? 无效的 TCP 标记 Invalid TCP Flags 到目前为止，你已经看到了 SYN, ACK, FIN, 和 RST 标记. 另外，还有 PSH (Push) 和 URG (Urgent) 标记. 最常见的非法组合是 SYNFIN 包. 注意: 由于 SYN 包是用来初始化连接的, 它不可能和 FIN 和 RST 标记一起出现. 这也是一个恶意攻击. 由于现在大多数防火墙已知 SYNFIN 包, 别的一些组合,例如 SYNFINPSH, SYNFINRST, SYNFINRSTPSH。很明显，当网络中出现这种包时，很你的网络肯定受到攻击了。 别的已知的非法包有 FIN (无 ACK 标记) 和”NULL”包。如同早先讨论的，由于 ACKFIN 包的出现是为了关闭一个 TCP 连接，那么正常的 FIN 包总是带有 ACK 标记。”NULL”包就是没有任何 TCP 标记的包 (URG,ACK,PSH,RST,SYN,FIN 都为 0)。 到目前为止，正常的网络活动下，TCP 协议栈不可能产生带有上面提到的任何一种标记组合的 TCP 包。当你发现这些不正常的包时，肯定有人对你的网络不怀好意。 UDP (用户数据包协议 User DatagramProtocol)TCP 是面向连接的，而 UDP 是非连接的协议。UDP 没有对接受进行确认的标记和确认机制。对丢包的处理是在应用层来完成的。(or accidentalarrival).此处需要重点注意的事情是：在正常情况下，当 UDP 包到达一个关闭的端口时，会返回一个 UDP 复位包。由于 UDP 是非面向连接的, 因此没有任何确认信息来确认包是否正确到达目的地。因此如果你的防火墙丢弃 UDP 包，它会开放所有的 UDP 端口 (?)。 由于 Internet 上正常情况下一些包将被丢弃，甚至某些发往已关闭端口 (非防火墙的) 的 UDP 包将不会到达目的，它们将返回一个复位 UDP 包。 因为这个原因，UDP 端口扫描总是不精确、不可靠的。 看起来大 UDP 包的碎片是常见的 DOS(Denial ofService) 攻击的常见形式 (这里有个 DOS 攻击的例子，http://grc.com/dos/grcdos.htm ). ICMP (网间控制消息协议 Internet ControlMessage Protocol)如同名字一样， ICMP 用来在主机路由器之间传递控制信息的协议。 ICMP 包可以包含诊断信息 (ping, traceroute - 注意目前 unix 系统中的 traceroute 用 UDP 包而不是 ICMP)，错误信息 (网络主机端口 不可达 networkhostport unreachable), 信息 (时间戳 timestamp, 地址掩码 addressmaskrequest, etc.)，或控制信息 (source quench, redirect, etc.) 。 你可以在 http://www.iana.org/assignments/icmp-parameters 中找到 ICMP 包的类型。 尽管 ICMP 通常是无害的，还是有些类型的 ICMP 信息需要丢弃。 Redirect (5), Alternate Host Address(6), Router Advertisement (9) 能用来转发通讯。 Echo (8), Timestamp (13)and AddressMask Request (17) 能用来分别判断主机是否起来，本地时间 和地址掩码。注意它们是和返回的信息类别有关的。 它们自己本身是不能被利用的，但它们泄露出的信息对攻击者是有用的。 ICMP 消息有时也被用来作为 DOS 攻击的一部分 (例如：洪水 ping flood ping,死 ping ?呵呵，有趣 ping of death)?p 包碎片注意 A Note About Packet Fragmentation 如果一个包的大小超过了 TCP 的最大段长度 MSS(Maximum Segment Size) 或 MTU (Maximum Transmission Unit)，能够把此包发往目的的唯一 方法是把此包分片。由于包分片是正常的，它可以被利用来做恶意的攻击。 因为分片的包的第一个分片包含一个包头，若没有包分片的重组功能，包过滤器不可能检测附加的包分片。典型的攻击 Typicalattacks involve in overlapping the packet data in which packet header is 典型的攻击 Typicalattacksinvolve in overlapping the packet data in which packet header isnormal until isit overwritten with different destination IP (or port) thereby bypassing firewall rules。包分片能作为 DOS 攻击的一部分，它 可以 crash older IP stacks 或涨死 CPU 连接能力。 NetfilterIptables 中的连接跟踪代码能自动做分片重组。它仍有弱点，可能受到饱和连接攻击，可以把 CPU 资源耗光。 OK，到此为止，关于 Wireshark 抓包工具的一些小教程已经写完了，而导致我想写这么一个纠结的教程的原因是，前几天通过这个抓包解决了梦幻西游在网维大师无盘上容易掉线的问题，当时捕捉到梦幻西游掉线时的数据包是这样的。 注意下图中的红色数据，123.58.184.241 是梦幻西游的服务器，而 192.168.1.41 是玩梦幻西游的客户机，在掉线时，发现是先有梦幻西游的服务器向客户机发送一个 [FIN,ACK] 数据包，根据上面的解释，FIN 标记的数据包是代表要断开连接的意思，而接着客户机又回给服务器一个确认断 开链接包。当看到这个抓包数据时，就意识到，大家说的在网维大师系统虚拟盘上梦幻爱掉线的问题，并非普通的网络问题，因为通过数据包的信息来看，是梦幻服 务器主动要求断开链接，产生这个情况无非是以下几个原因： 服务器发现客户端非法，比如有外挂什么的，踢掉了客户机； 服务器压力大，踢掉了客户机； 总之不是客户端问题导致的掉线； 那么既然结论是如此，为什么会有在网维大师系统虚拟盘上容易出现梦幻掉线问题呢？原因是由于网维大师系统虚拟盘是模拟真实硬盘方式来实现的，而在模拟过程 中，将硬盘的序列号设置为固定过的 OSDIY888 了，而梦幻西游刚好后识别客户机硬盘信息，发现大量客户端的硬盘序列号都是一样的，就认为是作弊或者使 用挂机外挂了，结果就导致随机被服务器踢下线的情况发生，后来我们将硬盘序列号设置为空，则没再出现该问题。这个问题在未来的新版本中会解决掉。 说这个案例的目的并不是为了说明抓包多有用，而是想说明一些解决问题的思路和方法，有些人是有思路，但是缺方法，比如不会用工具，而有些人收集了很多工具 却不会用，而我其实就属于后者，几年前就收集了 n 多工具，但是用到的没几个。慢慢的学会用这些工具后，发现思维 + 工具，解决问题是效率暴增，接下来的几天 里，会陆续介绍写小工具给大家，也希望大家有空学习下，有问题先百度，再自己摸索，而不是一味的求助，毕竟求人不如求己！自己能直接搞定，是皆大欢喜的事情 注意：由于某些系统为了防止 ARP 攻击，都免疫掉了一个 Npptools.dll 文件，这会导致该软件无法正常安装，打下这个补丁就可以了","categories":["3.软件","WireShark"]},{"title":"WireShark过滤器","path":"/2023/05/22/3-软件-WireShark-WireShark过滤器/","content":"什么是 wiresharkWireshark 是一款开源的网络封包分析软件。它可以捕获、分析和展示计算机网络中的数据包。Wireshark 支持多种网络协议，包括以太网、无线网络、Internet 协议（IP）、传输控制协议（TCP）、用户数据报协议（UDP）等等。 使用 Wireshark，您可以通过连接到计算机网络上的一个接口来捕获网络数据包。捕获的数据包将被 Wireshark 以可视化的方式显示出来，您可以查看每个数据包的详细信息，例如源 IP 地址、目标 IP 地址、协议类型、数据长度等等。 Wireshark 提供了强大的过滤功能，使您能够根据特定的条件过滤数据包，以便更好地分析网络流量。它还提供了许多分析工具和统计功能，如流量图表、协议分层显示、数据包重组等，帮助用户深入了解网络通信并发现潜在的问题。 Wireshark 是一个广泛应用于网络管理、网络安全和网络协议开发的工具。它能够帮助网络管理员诊断和解决网络故障，分析网络性能问题，检测网络安全事件，以及进行协议开发和调试等任务。由于其功能强大且易于使用，Wireshark 成为了网络分析领域的标准工具之一。 过滤器在 Wireshark 中，过滤器（Filter）是一种机制，用于选择和筛选特定的网络数据包以供分析。过滤器允许您根据特定的条件仅显示感兴趣的数据包，从而减少分析的数据量并集中精力于关注的内容。 Wireshark 使用一种称为 “ 显示过滤器 “（Display Filter）的语法来定义过滤条件。您可以根据多个参数，如源目标 IP 地址、协议类型、端口号、数据包长度、特定字段的值等等，创建过滤器规则。当过滤器应用于数据包捕获或已保存的数据包时，只有符合过滤条件的数据包会被显示，而其他数据包将被隐藏。 通过使用过滤器，您可以根据您的需求来选择显示的数据包，使得分析更加高效和专注。例如，您可以创建一个过滤器来只显示特定源 IP 地址的数据包，或者只显示某个协议类型的数据包，以便更好地关注您感兴趣的通信流量。 Wireshark 提供了广泛的过滤器语法和功能，使您能够根据不同的需求创建复杂的过滤条件。您可以使用比较运算符、逻辑运算符、通配符等来构建更精确的过滤规则，并根据需要组合多个条件来定义更复杂的过滤器。 过滤器在网络分析和故障排除中非常有用，可以帮助您集中注意力于感兴趣的数据包，提供更清晰和有针对性的分析。 过滤器的区别捕捉过滤器（CaptureFilters）：用于决定将什么样的信息记录在捕捉结果中。需要在开始捕捉前设置。 显示过滤器（DisplayFilters）：在捕捉结果中进行详细查找。他们可以在得到捕捉结果后随意修改。 两种过滤器的目的是不同的。 捕捉过滤器是数据经过的第一层过滤器，它用于控制捕捉数据的数量，以避免产生过大的日志文件。 显示过滤器是一种更为强大（复杂）的过滤器。它允许您在日志文件中迅速准确地找到所需要的记录。 两种过滤器使用的语法是完全不同的。 捕捉过滤器Protocol（协议）: 可能的值: ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp. 如果没有特别指明是什么协议，则默认使用所有支持的协议。 Direction（方向）: 可能的值: src, dst, src and dst, src or dst 如果没有特别指明来源或目的地，则默认使用 “src or dst” 作为关键字。 例如，”host 10.2.2.2″与”src or dst host 10.2.2.2″是一样的。 Host(s): 可能的值： net, port, host, portrange. 如果没有指定此值，则默认使用”host”关键字。 例如，”src 10.1.1.1″与”src host 10.1.1.1″相同。 Logical Operations（逻辑运算）: 可能的值：not, and, or. 否 (“not”) 具有最高的优先级。或 (“or”) 和与 (“and”) 具有相同的优先级，运算时从左至右进行。 例如， “not tcp port 3128 and tcp port 23″与”(not tcp port 3128) and tcp port 23″相同。 “not tcp port 3128 and tcp port 23″与”not (tcp port 3128 and tcp port 23)”不同。 例子： tcp dst port 3128 捕捉目的 TCP 端口为 3128 的封包。 ip src host 10.1.1.1 捕捉来源 IP 地址为 10.1.1.1 的封包。 host 10.1.2.3 捕捉目的或来源 IP 地址为 10.1.2.3 的封包。 ether host e0-05-c5-44-b1-3c 捕捉目的或来源 MAC 地址为 e0-05-c5-44-b1-3c 的封包。如果你想抓本机与所有外网通讯的数据包时，可以将这里的 mac 地址换成路由的 mac 地址即可。 src portrange 2000-2500 捕捉来源为 UDP 或 TCP，并且端口号在 2000 至 2500 范围内的封包。 not imcp 显示除了 icmp 以外的所有封包。（icmp 通常被 ping 工具使用） src host 10.7.2.12 and not dst net 10.200.0.016 显示来源 IP 地址为 10.7.2.12，但目的地不是 10.200.0.016 的封包。 (src host 10.4.1.12 or src net 10.6.0.016) and tcp dst portrange 200-10000 and dst net 10.0.0.08 捕捉来源 IP 为 10.4.1.12 或者来源网络为 10.6.0.016，目的地 TCP 端口号在 200 至 10000 之间，并且目的位于网络 10.0.0.08 内的所有封包。 src net 192.168.0.024 src net 192.168.0.0 mask 255.255.255.0 捕捉源地址为 192.168.0.0 网络内的所有封包。 注意事项： 当使用关键字作为值时，需使用反斜杠“\\”。“ether proto \\ip” (与关键字”ip”相同). Ether proto 0x0800这样写将会以 IP 协议作为目标。 “ip proto \\icmp” (与关键字”icmp”相同).这样写将会以 ping 工具常用的 icmp 作为目标。 可以在”ip”或”ether”后面使用”multicast”及”broadcast”关键字。当您想排除广播请求时，”no broadcast”就会非常有用。 Protocol（协议）:您可以使用大量位于 OSI 模型第 2 至 7 层的协议。点击”Expression…”按钮后，您可以看到它们。比如：IP，TCP，DNS，SSH String1, String2 (可选项): 协议的子类。点击相关父类旁的”+”号，然后选择其子类。 显示过滤器例子： snmp || dns || icmp 显示 SNMP 或 DNS 或 ICMP 封包。 ip.addr 10.1.1.1 显示来源或目的 IP 地址为 10.1.1.1 的封包。 ip.src ! 10.1.2.3 or ip.dst ! 10.4.5.6 显示来源不为 10.1.2.3 或者目的不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；目的 IP：任意 以及 来源 IP：任意；目的 IP：除了 10.4.5.6 以外任意 ip.src ! 10.1.2.3 and ip.dst ! 10.4.5.6 显示来源不为 10.1.2.3 并且目的 IP 不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；同时须满足，目的 IP：除了 10.4.5.6 以外任意 tcp.port 25 显示来源或目的 TCP 端口号为 25 的封包。 tcp.dstport 25 显示目的 TCP 端口号为 25 的封包。 tcp.flags 显示包含 TCP 标志的封包。 tcp.flags.syn 0×02 显示包含 TCP SYN 标志的封包。 如果过滤器的语法是正确的，表达式的背景呈绿色。如果呈红色，说明表达式有误。 更为详细的说明请见：http://openmaniak.com/cn/wireshark_filters.php 以上只是抓包和简单的过滤，那么其实如果你要想达到能够分析这些网络包的要求时，还需要了解下一些数据包的标记，比如我们常说的 TCP 三次握手是怎么回事？","categories":["3.软件","WireShark"]}]