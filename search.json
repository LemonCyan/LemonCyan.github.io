[{"title":"Qt的线程池","path":"/2024/08/16/1-语言-Qt-Qt的线程池/","content":"线程池线程池是一种常见的并发编程模型，用于管理和复用多个线程来执行任务。它的基本思想是在应用程序启动时创建一组线程，这些线程可以重复使用，以执行一系列的任务，而不需要为每个任务都创建和销毁线程。 线程池通常由线程池管理器、工作队列和一组工作线程组成。 线程池管理器：负责管理线程池的创建、销毁和线程数量的控制。 工作队列：用于存储待执行的任务。当任务提交至线程池时，会被添加到工作队列中，等待线程池中的线程来执行。 工作线程：线程池中的线程会从工作队列中取出任务，并执行任务的操作。 线程池的优点包括： 提高性能：通过重用线程，避免了频繁创建和销毁线程的开销，可以减少系统资源的占用和提高任务的响应速度。 控制并发度：通过限制线程池中的线程数量，可以有效控制并发任务的数量，避免资源过度消耗和系统负载过重。 提供任务队列：线程池可以维护一个任务队列，任务的提交和执行是解耦的，可以灵活地调整任务的处理顺序和优先级。 简化线程管理：由线程池管理器负责线程的创建、销毁和管理，开发者无需手动管理线程的生命周期。 Qt 的线程池QThreadPool 管理并回收单个 QThread 对象，以帮助降低使用线程的程序中的线程创建成本。每个 Qt 应用程序都有一个全局的 QThreadPool 对象，可以通过调用 globalInstance() 来访问。 要使用 QThreadPool 中的一个线程，子类化 QRunnable 并实现 run() 虚函数。然后创建该类的一个对象，并将其传递给 QThreadPool::start()。QThreadPool 默认会自动删除 QRunnable。使用 QRunnable::setAutoDelete() 来更改自动删除标志。 QThreadPool 支持通过在 QRunnable::run() 内部调用 tryStart(this) 多次执行同一个 QRunnable。如果启用了自动删除，当最后一个线程退出 run 函数时，QRunnable 将被删除。在启用自动删除时，使用相同的 QRunnable 多次调用 start() 会造成竞争条件，不建议这样做。 一段时间未使用的线程将会过期。默认的过期超时时间是 30000 毫秒（30 秒）。可以使用 setExpiryTimeout() 更改此设置。设置负的过期超时时间将禁用过期机制。 调用 maxThreadCount() 来查询要使用的最大线程数。如果需要，可以使用 setMaxThreadCount() 更改限制。默认的 maxThreadCount() 是 QThread::idealThreadCount()。activeThreadCount() 函数返回当前正在工作的线程数量。 reserveThread() 函数为外部使用保留一个线程。使用完线程后使用 releaseThread()，以便它可以被重新使用。本质上，这些函数暂时增加或减少活动线程数，在实现对 QThreadPool 不可见的耗时操作时非常有用。 QThreadPool 是用于管理线程的低级类，有关更高级的替代方案，请参阅 Qt Concurrent 模块。 函数说明123456789101112131415161718192021// 获取和设置线程中的最大线程个数int maxThreadCount() const;void setMaxThreadCount(int maxThreadCount);// 给线程池添加任务, 任务是一个 QRunnable 类型的对象// 如果线程池中没有空闲的线程了, 任务会放到任务队列中, 等待线程处理void QThreadPool::start(QRunnable * runnable, int priority = 0);// 如果线程池中没有空闲的线程了, 直接返回值, 任务添加失败, 任务不会添加到任务队列中bool QThreadPool::tryStart(QRunnable * runnable);// 线程池中被激活的线程的个数(正在工作的线程个数)int QThreadPool::activeThreadCount() const;// 尝试性的将某一个任务从线程池的任务队列中删除, 如果任务已经开始执行就无法删除了bool QThreadPool::tryTake(QRunnable *runnable);// 将线程池中的任务队列里边没有开始处理的所有任务删除, 如果已经开始处理了就无法通过该函数删除了void QThreadPool::clear();// 在每个Qt应用程序中都有一个全局的线程池对象, 通过这个函数直接访问这个对象static QThreadPool * QThreadPool::globalInstance(); 一个扫描 IP 地址的线程池实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;QApplication&gt;#include &lt;QThreadPool&gt;class ScanIpThread : public QRunnable&#123;public: QString ipAddr; ScanIpThread(QString ip_addr)&#123; ipAddr = ip_addr; &#125; void run() override &#123; qDebug() &lt;&lt; &quot;Hello world from thread&quot; &lt;&lt; QThread::currentThread(); QStringList parameters;#if defined(WIN32) parameters &lt;&lt; &quot;-n&quot; &lt;&lt; &quot;5&quot;;#else parameters &lt;&lt; &quot;-c 5&quot;;#endif parameters &lt;&lt; ipAddr; int exitCode = QProcess::execute(&quot;ping&quot;, parameters); if (exitCode==0) &#123; qDebug()&lt;&lt;ipAddr&lt;&lt;&quot; it&#x27;s alive&quot;; &#125; else &#123; qDebug()&lt;&lt;ipAddr&lt;&lt;&quot; it&#x27;s dead&quot;; &#125; &#125;&#125;;int main(int argc, char *argv[])&#123; QApplication a(argc, argv); QThreadPool *threadPool = new QThreadPool; threadPool-&gt;setMaxThreadCount(64); for(int i=0; i&lt;255; i++)&#123; ScanIpThread *scanNode = new ScanIpThread(QString(&quot;192.168.0.%1&quot;).arg(i)); // QThreadPool takes ownership and deletes node automatically threadPool-&gt;start(scanNode); &#125; return a.exec();&#125;","categories":["1.语言","Qt"]},{"title":"3568GPU负载查看及参数设置","path":"/2024/08/15/0-平台-嵌入式-3568GPU负载查看及参数设置/","content":"1.Look up the load@frequency of GPU 查看当前负载和频率 1cat /sys/class/devfreq/*.gpu/load 2.Look up the supported mode or supported frquency for GPU 查看当前支持的模式和频率 12cat /sys/class/devfreq/*.gpu/available_governorscat /sys/class/devfreq/*.gpu/available_frequencies 3.Set performance(the most high frequency) for GPU 设置性能模式 1echo performance &gt; /sys/class/devfreq/*.gpu/governor 4.Set frequency for GPU 设置频率 123456#设置模式为用户模式echo userspace &gt; /sys/class/devfreq/*.gpu/governor#打印当前支持的频率cat /sys/class/devfreq/*.gpu/available_frequencies#将要设置的频率写入(ps: you should do step 2 to ensure the available_frequencies before you set) echo 800000000 &gt; /sys/class/devfreq/*.gpu/set_freq 5.Get a version 获取版本信息 1strings libMali.so | grep rk_so_ver 6.Set power always on 1echo always_on &gt; /sys/devices/*.gpu/power_policy 循环打印 GPU 负载脚本 1234567#!/bin/shwhile [ 1 ]docat /sys/class/devfreq/fde60000.gpu/loadsleep 1done","categories":["0.平台","嵌入式"]},{"title":"3566与3568与3588之间的差异","path":"/2024/08/15/0-平台-嵌入式-3566与3568与3588之间的差异/","content":"接口差异 外部存储接口: RK3568 支持 ECC 内存 RK3566 不支持 ECC 内存 PCI-E 接口: RK3568 支持 PCI-E 3.0 RK3566 仅支持 PCI-E 2.1 以太网接口: RK3568 配备双千兆网口 RK3566 只有单千兆网口 SATA 接口: RK3568 支持 3 个 SATA 3.0 接口 RK3566 仅支持 1 个 SATA 3.0 接口 显示输出: RK3568 支持三重显示 RK3566 支持双显示 技术参数差异表： Processor Rockchip RK3568 Rockchip RK3566 Rockchip RK3588 Market (main) Single-board computer Single-board computer High-performance single-board computer ISA ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) ARMv8.2-A (64-bit) Microarchitecture Cortex-A55 Cortex-A55 Cortex-A76 + Cortex-A55 Family RK3500 RK3500 RK3500 Part number(s), S-Spec RK3568 RK3566 RK3588 Release date Q2 2020 Q2 2020 Q1 2022 Lithography 22 nm 22 nm 8 nm Cores 4 4 8 (4+4) Threads 4 4 8 Base frequency 2.0 GHz 1.8 GHz 2.4 GHz (A76), 1.8 GHz (A55) Turbo frequency - - - High performance cores 4x ARM Cortex-A55 @ 2.0 GHz 4x ARM Cortex-A55 @ 1.8 GHz 4x Cortex-A76 @ 2.4 GHz Cache memory 256 KB 256 KB 1 MB L3 Max memory capacity 8 GB 4 GB 32 GB Memory types LPDDR4-1600 DDR3, DDR3L, LPDDR3, DDR4, LPDDR4X LPDDR4X-3200, LPDDR5-2400 Max PCIe lanes 1 1 4 TDP 5 W 5 W 10-15 W GPU integrated graphics ARM Mali-G52 2EE MC2 ARM Mali-G52 MP2 ARM Mali-G610 MP4 GPU execution units 2 2 4 GPU shading units 32 32 - GPU base clock - 850 MHz 1000 MHz GPU boost clock 820 MHz 950 MHz - GPU FP32 floating point 54.4 GFLOPS 54.4 GFLOPS 614 GFLOPS Socket SoC SoC SoC Drystone MIPS 22,736 DMIPS 20,462 DMIPS - AI accelerator AI accelerator RKNN NPU - NPU AI computing operations per seconds 0.8 TOPS - 6 TOPS Crypto engine Cipher Engine, SHA-1, SHA-256&#x2F;224,SHA-512&#x2F;384, MD5, AES-128, AES-192,AES-256, DES, TDES, TRNG - - Max display resolution 4K@60fps - 8K@60fps Video decoding H.265&#x2F;H.264&#x2F;VP9 4K@60fps - 8K@60fps H.265&#x2F;VP9&#x2F;AVS2, 8K@30fps H.264 AVC&#x2F;MVC Video encoding H.265&#x2F;H.264 1080p@60fps - 8K@30fps H.265&#x2F;H.264 Max video capture MIPI-CSI - - Modem Gigabit Ethernet - 2.5 GbE Connectivity SATA 3.0, eMMC, HDMI 2.0,USB 3.0, USB 2.0 - PCIe 3.0, USB 3.1, HDMI 2.1 Wi-Fi WiFi 6 (802.11ax) - Wi-Fi 6 (802.11ax) Bluetooth Bluetooth 5.0 - Bluetooth 5.2 Audio SPDIF, PWM, SPI, I2S, I2C - - (Android 64-bit)Geekbench 4 single core 875 756 - (Android 64-bit)Geekbench 4 multi-core 2,375 1,997 - (Android)Geekbench 5 single core 161 108 ~800 (Android)Geekbench 5 multi-core 492 281 ~2800 (SGEMM)GFLOPS performance 21.2 GFLOPS 18.2 GFLOPS - (Multi-core &#x2F; watt performance)Performance &#x2F; watt ratio 475 pts &#x2F; W 399 pts &#x2F; W -","categories":["0.平台","嵌入式"]},{"title":"Docker随手记","path":"/2024/08/14/0-平台-Docker-Docker随手记/","content":"docker.io 和 docker-ce 区别 docker.io 采用 apt 的方式管理依赖 docker-ce 用 go 的方式管理依赖，会自己管理所有的依赖。","categories":["0.平台","Docker"]},{"title":"curl 命令","path":"/2024/08/14/3-软件-Web相关-curl-命令/","content":"依赖库libcurl 安装示例如下: 1234567891011#ubuntusudo apt-get install libcurl4-openssl-dev#centosyum install libcurl-devel#macos（本身自带curl，这一步非必须）brew install curl#windows（这里的 cpu 架构请根据实际环境灵活选择）vcpkg install curl:x64-windows 备注：建议安装最新版的 libcurl 库，否则可能存在 libcurl 库内存泄露 bug 问题。 curl 命令是一个功能强大的命令行传输工具，用于发送请求和下载文件。它支持多种协议，如 HTTP、HTTPS、FTP 等，可以设置请求头、请求参数等 发送 GET 请求123curl URLcurl URL?a=1&amp;b=nihao 发送 POST 请求1curl -X POST -d &#x27;a=1&amp;b=nihao&#x27; URL 发送 json 格式请求：123curl -H &quot;Content-Type: application/json&quot; -X POST -d &#x27;&#123;&quot;abc&quot;:123,&quot;bcd&quot;:&quot;nihao&quot;&#125;&#x27; URLcurl -H &quot;Content-Type: application/json&quot; -X POST -d @test.json URL -H 代表 header 头 -X 是指定什么类型请求(POST&#x2F;GET&#x2F;HEAD&#x2F;DELETE&#x2F;PUT&#x2F;PATCH) -d 代表传输什么数据 查看所有 curl 命令： man curl 或者 curl -h请求头：H,A,e响应头：I,i,Dcookie：b,c,j传输：F(POST),G(GET),T(PUT),X输出：o,O,w断点续传：r调试：v,–trace,–trace-ascii,–trace-time 测试端口可以用它来测试端口是否开启。 1curl -v ip:port 出现 Connection refused 表示端口关闭； 出现 Connected to ip(ip) port(#0)表示端口开启； 出现 No route to host 表示 IP 错误或者 iptables 限制。","categories":["3.软件","Web相关"]},{"title":"嵌入式操作系统应用情况","path":"/2024/08/14/0-平台-嵌入式-嵌入式操作系统应用情况/","content":"嵌入式操作系统（Embedded Operating System）是一种运行在嵌入式系统硬件上的基础软件，其基本功能是对硬件进行有效管理并对硬件进行一定程度的抽象以便应用软件调用。在军工领域，嵌入式操作系统在具备基本功能的基础上，还需要 具有实时性（Real-time）、安全性（Security &amp;Safety）等特点。 主要嵌入式操作系统及应用情况美国 欧洲 日本 国内自研且有军工应用 SylixOS 对应 Matrix653 ACoreOS653（天脉 2） 国内自研 其他记录POK is a real-time embedded operating system for safety-critical systems. It relies on a micro-kernel architecture that isolates applications and drivers in time and space. It is compatible with POSIX and ARINC653. The kernel was designed to be very small and targets full verification&#x2F;certification: more than 90% of the kernel code if covered. It currently runs on x86, PowerPC and Leon architectures. under the BSD license a653lib,The liba653 LIBRARY is an arinc 653 scheduler for Linux (uses POSIX standard), standardized by the A653.The liba653 LIBRARY can be built for the following operating systems and compilers:Linux 32&#x2F;64 bits (RHEL7) VxWorks653 POSIX 兼容性以下操作系统已知支持 POSIX 标准： VxWorks：支持 POSIX 标准，适用于实时应用。 Linux：大多数发行版部分符合 POSIX 标准，某些版本（如 EulerOS）完全符合。 LynxOS：以其 POSIX 兼容性而闻名，特别适用于实时应用。 RTEMS：完全支持 POSIX，特别适合嵌入式系统。 FreeRTOS：具有一定的 POSIX 兼容性，但主要设计用于微控制器。 ThreadX：通过其 API 提供有限的 POSIX 支持。 Mbed OS：提供一些类似 POSIX 的 API，但并不完全符合。 ARINC 653 兼容性ARINC 653 是针对安全关键系统的标准，主要用于航空电子设备。以下操作系统支持 ARINC 653： Integrity：专为安全关键应用设计，符合 ARINC 653 标准。 PikeOS：支持 ARINC 653，面向安全关键和安全应用。 Deos：完全符合 ARINC 653，专为航空航天中的安全关键系统设计。 FACE 兼容性未来航空能力环境（FACE）是用于军事航空软件标准化的倡议。以下操作系统支持 FACE 标准： Integrity：符合 FACE 标准，适用于军事应用。 VxWorks：有版本支持 FACE，特别是在国防应用中。 RedHawk Linux：旨在满足军事和航空航天应用的 FACE 标准。 Linux：各种发行版可以根据实现进行定制以满足 FACE 标准。 行业标准不同的嵌入式操作系统采用各自的方式管理计算机系统硬件，如果对上层应用程序也采用不同的抽象方法，将会导致在某一个嵌入式操作系统开发的应用程序无法直接在另一个嵌入式操作系统上运行，这既不利于不同厂商之间合作，也不利于新产品继承老产品的工作成果。为此，在国外嵌入式操作系统领域，制定了相关的行业标准。目前常见的行业标准有以下三个： POSIX 可 移 植 操 作 系 统 接 口（Portable Operating System Interface of UNIX，POSIX） 由 IEEE 制定并发布，是为在各种类 UNIX 操作系统上运行软件而定义的一系列 API 标准的总称，其正式称呼为 IEEE 1003，而国际标准名称为 ISO&#x2F;IEC 9945。 ARINC653 航 电 应 用 软 件 标 准 接 口 653（AvionicsApplication Software Standard Interface 653，ARINC653）由美国航空电子工程委员会（AirlinesElectronic Engineering Committee，AEEC）于 1997 年提出，是一种嵌入式操作系统应用程序接口标准，目前是国际上在飞行器软件方面比较通行的软件运行标准。其主要特点是时空分区，如图所示。 在 ARINC653 标准中定义了一个主时间帧，再将主时间帧中分成多个小时间段，每个时间段分配给一个应用程序进程执行。随着航空软件系统的执行，主时间帧周而复始运行，使各个应用程序进程都能有效获得硬件资源。同时，由于每个进程只会在分配的小时间段中执行，从而避免了在时间上多个进程同时执行造成的相互影响。与小时间段相对应，利用处理器存储器管理单元（Memory Management Unit，MMU）、存储器控制器分区（bank）控制等硬件技术，每个应用程序进程运行时使用相互独立的一段存储器，从而避免了在存储器空间上多个进程同时执行造成的相互影响。ARINC653 通过使应用软件中的各进程在时间和空间上同时分开获得了较高的软件运行安全性，有效控制了进程发生错误的影响范围，避免了因为某一进程发生错误时威胁到整个航空软件系统运行，进而威胁到飞行器安全飞行的情况发生。 FACE 未来机载能力环境（Future Airborne Capability Environment，FACE）在 2010 年由美国海军航空系统司令部发起、开源组织（OpenGroup）提出，其策略是在己安装好硬件的军用航电平台上建立软件通用操作环境，使 FACE 组件应用在不同平台上时可被重新部署，从而实现跨平台的可移植性和重用性。FACE 采用“分段式”架构，自顶向下分为操作系统段、I&#x2F;O 服务段、平台特定服务段、传输服务段和可移植组件段，每个段间的接口都进行了标准化定义，使得基于 FACE 标准的应用系统可以从任意一个段间接口开始设计具有自身特色功能段。相比 ARINC653 中只定义了应用程序分时分区使用硬件的软件接口，FACE 标准包含了应用程序从顶层通用服务到底层 IO 的全部内容，制定了应用程序各组件的标准化接口，为应用程序赋予了可移植性、开放性和灵活性，大幅提高了电子系统设计的便利性，为航电设备即插即用等应用场景提供了有效技术支撑。 资质认证 DO178《机载系统和设备合格审定中的软件考虑》（Software Considerations in Airborne Systems and Equipment Certification）是一个典型代表 DO-178 是面向飞机适航性的认证标准，分别在 1985、1992 和 2011 年进行了三次改版，分别称为 DO-178A、DO-178B 和 DO-178C。DO-178 定 义了一套飞机用软件开发的过程管理办法，飞机上使用的软件，包括嵌入式操作系统，必须按照 DO-178 规定进行研制，并在能够向飞机管理机构提供证据说明软件研制过程符合 DO-178 要求的情况下，才有可能通过飞机的适航性认证。 第一，软件生命周期过程的目标； 第二，为满足上述目标要进行的活动； 第三，证明上述目标已经达到的证据，也即软件生命周期数据。 DO-178C 主要过程如图所示。 数据来源：《航空微电子》第 2 期 2022 年 6 月 总第 5 期","categories":["0.平台","嵌入式"]},{"title":"运行流程","path":"/2024/08/12/3-软件-ARINC653介绍-运行流程/","content":"启动分区 分区启动之后，XXXOS 内核就为该分区创建一个初始任务，该任务的主要作用是初始化 APEX 接 12，因此该任务的各项参数(例如优先级和任务栈大小)取决于 APEX 接口的具体实现，如果给定具体的 APEX 接口实现，则该任务的各项参数是固定的，对 APEX 接口的用户是透明的。 初始化 APEX 接口 初始任务以分区配置表为参数，调用 APEX 接口的初始化入口函数 APEX INIT，APEX 接口就会根据分区配置表中的各项参数完成系统对象的初始化，然后创建系统进程，典型的系统进程包括初始进程、IDLE 进程等。创建好系统进程之后，初始任务的生命周期即告结束，系统进程开始运行，APEX 接口的初始化完成。 设置分区为 NORMAL 初始进程将会调用用户程序的入口函数 USERMAIN，真正进入到分区应用程序中，用户在该进程中就可以创建自己的用户进程和其他系统对象，创建完成后设置分区的模式为 NORMAL，用户进程就可以启动运行了，此时初始进程的生命周期也可以结束了。整个分区和 APEX 接口的初始化完成。 值得注意的是， APEX 接口的初始化是一个分界线，从此之后创建的任何进程或对象都必须在分区配置表中有对应的配置，否则创建将会失败，IDLE 等系统进程也不例外。而在初始化 APEX 接口之前创建的系统对象的生命周期必须到此结束，不能延续到 APEX 接口初始化之后，以初始任务为例，在 APEX 接口初始化过程就会被终止。以保证 APEX 接口之上应用程序的可移植性不受具体 OS 的影响。 APEX 配置信息的入口参数的结构。 1234567891011typedef struct&#123;void* processInfo； /*进程整体配置信息*/void* bufferInfo； /*缓冲区整体配置信息*/void* bbInfo； /*黑板整体配置*/void* semInfo； /*信号量整体配置信息*/void* eventInfo； /*事件整体配置信息*/void* queuingInfo；/*队列端口配置信息*/void* samplingInfo； /*采样端口配置信息*/void* hmInfo； /*分区健康监控配置信息*/)T_APEX_CONFIG_INFO；","categories":["3.软件","ARINC653介绍"]},{"title":"接口功能","path":"/2024/08/12/3-软件-ARINC653介绍-接口功能/","content":"ARINC653 介绍ARINC653 作为一个标准，主要阐述了模块化综合航空电子设备 IMA(Integrated Modular Avionics)使用的应用软件的基线操作环境。其定义了航空应用与下层操作环境之间的接口和数据交换的模式以及服务的行为，并描述了嵌入式航空电子软件的运行时环境。 在实际应用过程中，航空电子中的核心模块软件包括两类: 应用软件和核心软件。ARINC653 定义的就是位于应用软件和操作系统 OS 之间的 APEX(APplication EXecutive)接口，APEX 接口是操作系统为应用软件提供的一个功能集合。利用这个功能集合，应用软件可以控制系统的调度，通信和内部状态信息。 APEX 接口相当于为应用提供的一种高层语言。 而对于 OS 来说，是关于参数和入口机制的定义。 ARINC653 标准一个重要的标准就是将航空电子软件进行分时，分区管理。采用二级调度，分区内基于优先级进行调度，分区间通过时间窗口进行时间轮转调度。同时定义了分区内的进程接口，进程间通信接口，分区间通信的 Port 标准接口，并且为了增强系统的可靠性定义了系统级，分区级，进程级别的健康监控管理接口。 分区和区间管理分区（Partitioning）是 ARINC653 中一个核心概念。在 IMA(Integrated Modular Avionics)系统中，一个核心模块会包含一个或多个航空电子应用，并且这些应用要能够独立运行。分区就是航空电子应用中的一个功能划分。分区的单位称为区间，区间内的每一个执行单元称为进程。每一个区间具有自己独立的数据、上下文和运行环境，这样做的好处是能够防止一个区间的错误影响到其他区间。另外，它能使得整个系统容易验证、确认和认证。 区间化以及区间的管理和调度是由 OS 来实现的。ARINC653 为区间的调度规定了一种基于时间窗的循环调度算法。 为了完成各区间的周期性调度，由 OS 维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表,在规定的时间窗口内激活对应区间的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 ARINC supplement 1 对主时间框架的时间定义原则进行了补充。它规定主时间框架的大小应该是核心模块中所有区间周期的最小公倍数的正整数倍，并应考虑到每个区间每次执行的时间长度和执行频率。 在 ARINC653 Supplement 1 发布时又增加了系统区间属性和启动条件属性。区间的工作模式包括空闲，冷启动，热启动和正常四种，如图 3 所示。每个区间所需资源在系统构建时指定，在区间初始化完成时区间对象创建。OS 在进入运行模式时启动应用区间，然后区间进入正常运行模式。监测管理功能在响应致命错误时将重启区间或者停止区间的运行。 根据 ARINC653 标准的规定，需要模块操作系统提供时空隔离机制的支持，因此内核和分区应用在空间上和时间上应进行隔离保护。 下面分两部分论述系统空间时间分配，首先是基于整个模块操作系统的空间和时间分配情况，后面是基于 APEX 接口的实现上的空间和时间分配。 ●空间隔离 在操作系统中，以分区为资源分配单位。采用复平面空间的方式，每个应用都有独立的 4G 空间，从而实现用户与操作系统，用户与用户之间在存储空间上进行隔离，达到互不影响的目的。 从 APEX 接口的设计实现上来讲，空间分配包含两部分的内容： APEX 分区上的资源分配 即使用的是应用分区上的空间资源，包括了各个 APEX 对象管理控制块资源。 分区管理 进程管理 分区健康监控 信号量 事件 黑板 缓冲 时间管理 采样端口 队列端口 内核空间的资源分配 主要是 APEX 接口调用过程中需要在内核分配的资源，列表如下： 内核的域管理 内核的任务管理 内核的周期对象管理 内核信号量 内核黑板 内核消息队列另外，在 APEX 内核支持层封装的对分区间通信的端口的支持，也是在内核空间分配的端口控制管理资源，包括了端口控制链和通道控制链。 ●时间隔离 目前 OS 为基于 APEX 接口的应用分区提供了时间调度表调度策略。通过配置时间调度表，可以控制各个分区在时间点上的运行分配。由操作系统维护一个固定时间长度的主时间框架，该时间框架在模块的运行期内周期性的重复。每个时间框架可以划分为若干个时间窗口。系统利用一个事先确定的配置表，在规定的时间窗口内激活对应域的运行。这样就能够保证每个应用在分配给它的时间周期内访问公共资源不被打断。 接口清单 分区管理分区是一个应用运行的资源单位。一个分区是一个独立的应用环境：它由数据、自己的上下文关系、配置属性和其它项组成。分区的运行要满足时间和空间的要求。 通过分区可以实现应用间的隔离和保护，分区也是应用隔离保护的单位，每个分区有独立的运行空间和堆空间，不同分区的运行空间不会重叠。当一个应用出现致命错误，出现的最坏情况就是应用被系统删除或者重启动。而这个应用的错误不会影响到其他分区，更不会影响到操作系统口。 分区具有独立的调度策略，每个分区在属于自己时间窗口内运行。 一个分区则由一个或多个并发执行的进程组成，分区内的所有进程将共享分区所占有的系统资源。分区管理要求系统中同时可以运行多个不同类型的应用，同时在时间上和空间上互不影响。分区管理主要包括：分区的属性定义、分区的工作状态转换、分区的控制和分区的调度。 函数功能 分区状态的获取 设置分区模式 分区间通信分区间通信是 ARINC 653 标准中使用的一种通用表达方式，其主要定义两个或多个分区间的通信，标准的分区间通信是一项基本需求以支持应用软件的可重用性和可移植性。所有的分区间通信都通过消息进行。消息被定义为有限长度的连续数据块。 消息从单个的源发出，到一个或多个目标。消息的目标是分区而不是分区内的进程。分区通过已定义的访问点访问通道，访问点称为端口(port)。通道由一个或多个端口以及相关的资源组成。端口提供所需的资源以允许特定的分区在特定的通道中发送或接收消息。分区可以通过各自的资源和目的端口使用多个通道交换消息。通道将一个发送端口通过中间端口和一个或多个接收端口连接起来。每个单独的通道都可以配置在专门的模式下运行。可以使用两种传送模式，采样模式(samplingmode)和队列模式(queuingmode)。因此提供了采样端口服务和队列端口服务。 分区间通信遵循以下原则： 发送方和接受方并不关心对方的具体名字和物理位置，以避免系统的其他地方修改之后引起分区的变化。 消息只能有一个源，但可以有若干个目的； 来自不同端口的消息不需要按照它们发送的时间顺序到达它们的目的。 函数功能 采样端口服务 根据采样端口的周期性数据特点，采用内核提供的黑板机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX 内核支持层来实现具体的黑板写和读功能。需要注意的是源端口不用创建对应的黑板。APEX 内核支持层只为目的端口创建对应的黑板。 由于采样端口的数据具有周期性特点，因此存在数据有效性判断。对采样端口数据有效性的定义如下：数据停留在端口的时间小于用户设置的数据刷新周期时间。 数据停留时间&#x3D;从端口获取数据的系统时间一发送数据到端口的系统时间。 队列端口服务 根据队列端口的消息队列数据特点，采用内核提供的消息队列机制来实现。在分区之上的 APEX 接口封装层提供配置初始化功能，提供标准的 APEX 调用接口。在 APEX内核支持层来实现具体的消息的发送和接收功能。需要注意的是源端口不用创建对应的消息队列。APEX 内核支持层只为目的端口创建对应的消息队列。 进程管理完成应用进程的管理，进程是操作系统运行的基本单位。 在分区内的执行体是由一个或多个进程组成，每个进程隶属于特定的分区，分区内的各进程之间并发执行。进程管理主要负责分区内进程的创建、调度和删除等管理工作。 进程分为按固定频率执行的周期进程和由事件触发的非周期进程两类，操作系统应具备对这两类进程的调度能力；进程在出现故障时应允许重新初始化或者终止；对于访问临界区的进程，为保证安全性，在访问时进程管理应禁止调度。 函数功能 创建进程 停止进程 挂起进程 解挂进程 设置进程优先级 分区内通信支持分区内的进程之间相互通信。按通信机制划分，分区内通信共有两种。一种是缓冲区和黑板，用于进程间通信。另一种是信号量和事件，用于进程间同步。 缓冲区和黑板的差别是：缓冲区允许消息以队列的形式存储，消息不允许覆盖，而黑板在任何时刻最多只保留一个消息，消息允许覆盖；信号量和事件的差别是：信号量用于对系统资源的访问，而事件用来完成进程之间的同步／异步操作。 提供了两种分区内通信机制： 函数功能 允许分区内进程间通过缓冲区和黑板进行通信。 通过计数信号量或事件实现进程间的同步。 缓冲 Buffer&#x2F;消息队列 MessageQueue在缓冲区中，消息的每个新实例都携带唯一不同的数据，因此传送时不允许覆盖前一个。缓冲允许在消息队列中存储多个消息。发送进程发送的消息以 FIFO 顺序存储在消息队列中。这种排队模式下不应该丢失任何消息。缓冲中能够存储的消息数量是由缓冲大小确定并在创建时指定的。等待在缓冲上的进程以 FIFO 或者优先级排队。优先级排队的情况下，相同优先级的进程按照 FIFO 顺序排队。排队规则在创建缓冲时定义。如果有进程等待缓冲消息并且缓冲(变得)不为空，则按照应用排队规则算法(FIFO 或者优先级)来确定哪个排队的进程接收此消息。OS 将把该进程从进程队列上移出，将其置为就绪状态。OS 将把消息从缓冲消息队列中移出。 当进程试图从空缓冲接收消息，或者发送消息到满的缓冲，将发生进程重调度。调用进程将被放入队列一段指定的时间，如果在该段时间内没有消息被接收或者发送，OS 将自动从队列中移出该进程，将其置为就绪状态。 黑板 Blackboard黑板是分区内进程间的一种通信机制。它和消息队列一样支持在多个源和目的之间的传输。黑板与消息队列最大的不同点是消息队列允许消息排队，而黑板不允许消息排队。 只要预先分配的存储空间足够大，那么进程可以创建尽可能多的黑板。 当进程进入一个等待状态时，分区需要重新进行进程调度。超时机制限制或者避免了等待时间过长的现象出现。 黑板是不支持排队的，写到黑板上的任何消息可能被擦除或者被新写入的消息覆盖掉。任务可以从黑板上读取一条信息、显示一条信息或者擦除黑板。 试图从空的黑板上读取信息的操作将会导致进程重新调度，进行该操作的进程将会进入队列中等待一段指定时间，如果在该段时间内没有消息被写到黑板上，dOS 将会将该进程从等待队列上移出并将其状态变为就绪。 当有消息被写到黑板上时，所有等待在黑板队列上的进程将会从队列上被移出并设置为就绪状态，该消息会被保持在黑板上。当黑板被擦除时，它会变空。 信号量 Semaphore信号量服务提供了计数信号量。 计数信号量是一种同步对象，常用于对分区内资源访问的控制。计数信号量的计数值一般用于反映当前合法资源的数量。 为了使用信号量，必须在初始化阶段中对其进行创建。创建信号量时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 事件 Event事件是一种同步对象，用于通知进程等待条件的出现。同一分区内的进程可以设置和清除事件，还可以在本分区内创建的事件上等待。 分区内创建的事件能够被分区内的所有进程使用。事件创建时，被设置为 down 状态。为了通知事件条件的发生，可以设置指定的事件为 up 状态，所有等待该事件的进程的状态将从等待变为就绪，然后进行重调度。等待事件的进程的执行顺序应该只依赖于分区内进程调度规则。 为了使用事件，必须在初始化阶段中对其进行创建。创建事件时需要指定对象名字，这个名字仅局限于分区内。此外，这个名字也不是分区配置表的属性。 时间管理时间管理为分区提供了功能接口来控制周期和非周期进程。 周期进程就是以特定频率执行的进程。类似的，只在特定事件之后执行的进程为非周期进程或事件驱动进程。 对于周期进程，分区内每个进程都可以确定一段执行时间来作为进程周期执行的最大时间长度。这个时间长度可用以设定进程的 Deadline 时间。操作系统会通过周期性地评估 Deadline 时间来判断进程是否在分配的时间内完成了执行。在进程执行周期的最后，应该调用 PERIODIC W 舭 T 服务来获取新的 Deadline。新 Deadline 的计时将从进程的下一个周期开始。 对于所有进程，TIMED—WAIT 服务允许进程挂起自己一段时间。待挂起时间到达以后，进程又可以被重新调度。 函数功能 使进程指定时间等待 使进程周期性等待 获取系统时间 健康监控健康监控用于监视硬件、应用程序和操作系统的状态，当发现故障时，记录故障并进行故障隔离，防止故障的蔓延，同时按故障级别(模块级、分区级和任务级)进行必要的恢复。健康监视的另一个功能是在系统配置时，用于检测系统配置的一致性和完整性。 ARINC 对健康监控处理的错误进行了分级，错误有可能发生在模块级、分区级和进程级。模块级错误仅影响模块内的所有分区。分区级错误仅影响该分区。进程级错误影响分区内的一个或者多个进程，或者是整个分区。如下给出各个级别的错误类型定义。 ●模块级错误： 模块初始化阶段出现模块配置错误； 模块初始化阶段出现其它错误： 系统功能执行期间的错误； 分区转换时发生的错误； 加电故障。 ●分区级错误： 分区初始化阶段出现分区配置错误； 分区初始化错误； 进程管理中的错误； 故障处理过程的错误。 ●进程级错误： 应用进程产生的应用错误； 非法的操作系统请求； 进程执行错误(溢出、存储区冲突…)。 错误的级别是由系统人员在状态监控的配置表中定义的，并且与诊断的错误和系统状态相一致的。任何级别上发生的错误，根据其错误特性，将会扩散到其被处理的更高级别上。 故障响应机制依赖于错误级别。模块级和分区级的故障响应是由一张模块状态监控表和每个分区的单独分区状态监控表驱动的。进程级故障响应由应用程序员使用分区的专门(最高优先级)的进程一一错误处理进程决定。程序员可以通过状态监控服务确定错误和故障进程，然后在进程级(例如，停止，启动进程，replenish)或者分区级(例如，设置分区模式：空闲，冷启动，热启动)采取恢复措施。错误处理进程中发生的错误被视为分区级错误。 函数功能 报告错误消息 创建错误处理进程 激活处理进程","categories":["3.软件","ARINC653介绍"]},{"title":"飞凌OK3568的Docker支持","path":"/2024/08/12/0-平台-嵌入式-飞凌OK3568的Docker支持/","content":"编辑 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 增加以下内容 12345678910111213141516#add docker supportCONFIG_MEMCG=yCONFIG_VETH=yCONFIG_BRIDGE=yCONFIG_BRIDGE_NETFILTER=yCONFIG_NETFILTER_XT_MATCH_ADDRTYPE=yCONFIG_NETFILTER_XT_MATCH_CONNTRACK=yCONFIG_NETFILTER_XT_MATCH_IPVS=yCONFIG_NETFILTER_XT_MARK=yCONFIG_POSIX_MQUEUE=yCONFIG_CGROUP_BPF=yCONFIG_NETFILTER_ADVANCED=yCONFIG_NETFILTER_XTABLES=yCONFIG_IP_VS=yCONFIG_IP_PNP=yCONFIG_IP_PNP_DHCP=y 之后再编译烧写测试下 123456789101112131415161718#更新软件源sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo apt install software-properties-common#添加仓库sudo add-apt-repository &quot;deb [arch=arm64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;sudo apt-get update apt-cache madison docker-cesudo apt-get -y install docker-ce=5:20.10.1~3-0~ubuntu-focalsudo docker image ls","categories":["0.平台","嵌入式"]},{"title":"最大打开文件数量","path":"/2024/08/12/0-平台-Linux-文件-最大打开文件数量/","content":"报错：Can’t open so many files 或者 too many open files 涉及参数 参数 说明 默认值 查询语句 nofile 单个进程的最大打开文件数 1024 ulimit -n 或者 cat &#x2F;proc&#x2F;pid&#x2F;limits nr_open 单个进程可分配的最大文件数 1024*1024&#x3D;1048576 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;nr_open file-max 系统内核一共可以打开的最大值 199708 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max nofile 是 linux 操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接字数量） file-max 是设置系统所有进程一共可以打开的文件数量 。同时一些程序可以通过 setrlimit 调用，设置每个进程的限制。 nofile临时修改1ulimit -SHn 128000 分软限制和硬限制，加-H 就是硬限制，加-S 就是软限制。默认显示的是软限制，如果运行 ulimit 命令修改时没有加上-H 或-S，就是两个参数一起改变。 硬限制就是实际的限制，而软限制是警告限制，它只会给出警告。 永久修改一1vi /etc/security/limits.conf * 表示所用的用户 二修改 /etc/profile 增加 1ulimit -SHn 128000 &#x2F;etc&#x2F;profile 是 Linux 系统中的一个重要配置文件，主要用于设置系统级的环境变量和启动程序。该文件在用户登录时被执行，适用于所有用户。 系统总限制临时修改12echo 1200000 &gt; /proc/sys/fs/nr_openecho 200000 &gt; /proc/sys/fs/file-max 永久修改一在文件&#x2F;proc&#x2F;sys&#x2F;fs&#x2F;nr_open 中加入如下代码：（1200000 为修改的参数值） 1fs.nr_open=1200000 在文件 &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max 中插入如下代码： 1fs.file-max=200000 保存并执行 reboot 重启服务器。 二在&#x2F;etc&#x2F;sysctl.conf 中设置 fs.nr_open&#x3D; 1200000 fs.file-max&#x3D;200000，然后执行 sysctl -p，使配置生效。无需重启。 查看系统下各个进程打开的文件描述符数量1lsof -n |awk &#x27;&#123;print $2&#125;&#x27;|sort|uniq -c |sort -nr 12#匹配PID为696的进程lsof -fp | grep 696 | wc -l","categories":["0.平台","Linux","文件"]},{"title":"远程桌面","path":"/2024/07/30/3-软件-内网穿透-远程桌面/","content":"TeamViewerVNC选择 lightdm 作为 Display Manager。首先更新系统软件包列表并安装必要的软件包： 12sudo apt updatesudo apt install -y xserver-xorg-video-dummy x11vnc xfce4 接下来配置 X11 服务器以使用虚拟视频设备。编辑&#x2F;etc&#x2F;X11&#x2F;xorg.conf 文件并添加： 123456789101112131415161718192021Section &quot;Device&quot; Identifier &quot;Configured Video Device&quot; Driver &quot;dummy&quot; VideoRam 256000EndSectionSection &quot;Monitor&quot; Identifier &quot;Configured Monitor&quot; HorizSync 5.0 - 1000.0 VertRefresh 5.0 - 200.0 ModeLine &quot;1920x1080&quot; 148.50 1920 2448 2492 2640 1080 1084 1089 1125 +Hsync +VsyncEndSectionSection &quot;Screen&quot; Identifier &quot;Default Screen&quot; Monitor &quot;Configured Monitor&quot; Device &quot;Configured Video Device&quot; DefaultDepth 24 SubSection &quot;Display&quot; Depth 24 Modes &quot;1920x1080&quot; EndSubSectionEndSection 完成配置后，重启设备以应用更改：sudo reboot，之后配置和启动 x11vnc 服务。 查看设备 IP 地址：ip addr 启动 x11vnc 服务：x 代表端口号 1sudo x11vnc -display :x -auth /var/lib/lightdm/.Xauthority &amp; 然后就可以在 PC 机上使用 ip+5900+x 地址来 VNC 远程连接。 安装必要的软件包123sudo apt updatesudo apt install tigervnc-server #tightvncserver 桌面环境没有桌面环境的话，则需要安装相关的桌面环境 1vncserver -geometry 1920x1080 :1 配置 VNC Server运行 vncserver 命令来首次配置。它会提示您设置密码和查看连接所需的信息。 修改配置文件1sudo nano ~/.vnc/xstartup 将其中的内容修改为以下类似的内容，以确保有正确的桌面环境启动： 123456789101112#!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESSgnome-session &amp;# #!/bin/sh#export XKL_XMODMAP_DISABLE=1#export XDG_CURRENT_DESKTOP=&quot;GNOME-Flashback:GNOME&quot;#export XDG_MENU_PREFIX=&quot;gnome-flashback-&quot;#gnome-session --session=gnome-flashback-metacity --disable-acceleration-#check &amp; 重启 VNC Server12vncserver -kill :1 # 假设您的 VNC 实例是 :1vncserver -geometry 1920x1080 :1 VNCserver 的端口为 5900+X，如果我想要 VNC 端口在 9099 时，则设置 VNC 实例为 1vncserver -geometry 1920x1080 :3199 设置防火墙如果您启用了防火墙，需要允许 VNC 相关的端口通过。VNC 通常使用 5900 + 显示编号的端口，例如第一个实例是 5901。 例如，如果您使用 ufw 防火墙，可以运行以下命令： 1sudo ufw allow 5901 这样，您就完成了 Ubuntu 20 上 VNC Server 的基本配置，可以通过 VNC 客户端使用设置的密码和服务器的 IP 地址及端口进行连接。","categories":["3.软件","内网穿透"]},{"title":"多核处理器的负载均衡","path":"/2024/07/25/0-平台-Linux-内核-多核处理器的负载均衡/","content":"现阶段多核处理器的应用范围越来越广泛，在通常情况下应用程序的调度都是交由操作系统进行管理，操作系统对应用程序进行调度，使其在不同的核上轮番运行。在一般情况下，操作系统的默认调度机制可以应付大部分的情况，但是针对于需要高运行效率的进程来说，就有必要考虑将其固定在一个核上运行，避免在不同的核上调度造成的额外开销。对于绑定的进程来说，该进程将会一直在指定的核上运行，不会在被调度到其他的核上，但是被绑定的核上仍然有可能运行其他进程。 在多核处理器的 Linux 系统中,可以通过几种方法实现应用程序线程在指定 CPU 核上运行,从而提高性能并减少不同核心间切换的开销. 需要注意的是,手动绑核应谨慎使用,因为它可能会影响系统的整体负载均衡. 在大多数情况下,操作系统的默认调度策略已经能够很好地管理线程分配. taskset 命令taskset 可以在命令行中将进程或线程绑定到特定的 CPU 核心. 查看进程绑定情况: 1taskset -p pid 绑定进程到指定 CPU 核: 1taskset -cp cpu-list pid 例如: 1taskset -cp 1,2,5-11 9865 # 将进程 9865 绑定到 1,2,5-11 号核 在启动时绑定可以在启动应用程序时使用 taskset 命令直接绑定: 1taskset -c 0,1 ./your_program sched_setaffinity 系统调用在程序代码中可以使用 sched_setaffinity 函数来设置线程的 CPU 亲和性: 12345678#define _GNU_SOURCE#include &lt;sched.h&gt;cpu_set_t mask;CPU_ZERO(&amp;mask);CPU_SET(0, &amp;mask); // 设置亲和性为 CPU 0sched_setaffinity(0, sizeof(mask), &amp;mask); pthread_setaffinity_np 函数对于 POSIX 线程,可以使用 pthread_setaffinity_np 函数来设置线程亲和性: 1234567#define _GNU_SOURCE#include &lt;pthread.h&gt;cpu_set_t cpuset;CPU_ZERO(&amp;cpuset);CPU_SET(2, &amp;cpuset);pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &amp;cpuset); 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sched.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/syscall.h&gt;pid_t gettid(void)&#123; return syscall(SYS_gettid);&#125;/** * @brief print_running_cpu * pthread_setaffinity_np函数用于设置线程的CPU亲和度。 * CPU_SET和CPU_ZERO用于设置和清除CPU掩码。 * print_running_cpu函数通过系统命令查询线程当前运行的CPU核，并打印出来。 */void print_running_cpu() &#123; char qry_cmd[1024] = &#123; 0 &#125;; sprintf(qry_cmd, &quot;ps -o pid,spid,psr -T -p %d | grep %d | tail -n 1 | awk &#123;&#x27;print $3&#x27;&#125;&quot;, getpid(), gettid()); FILE *fp = popen(qry_cmd, &quot;r&quot;); if(fp == NULL) return; char cpu_id_str[200] = &#123; 0 &#125;; fgets(cpu_id_str, 80, fp); fclose(fp); printf(&quot;[%d] : current thread(%d@%d) is running on cpu(%d) &quot;, gettid(), gettid(), getpid(), atoi(cpu_id_str));&#125;void bind_thread_to_cpu(int cpu_id) &#123; cpu_set_t cpu_mask; CPU_ZERO(&amp;cpu_mask); CPU_SET(cpu_id, &amp;cpu_mask); pthread_setaffinity_np(pthread_self(), sizeof(cpu_mask), &amp;cpu_mask);&#125;void* thread_func(void* p_arg) &#123; int bind_cpu_id = *(int *)p_arg; printf(&quot;[%d] : setting cpu affinity for thread(%d@%d) to cpu(%d) &quot;, gettid(), gettid(), getpid(), bind_cpu_id); bind_thread_to_cpu(bind_cpu_id); print_running_cpu(); while(1) &#123; // 模拟工作负载 long loop = 4000000000; while(loop--) &#123;&#125; sleep(0); print_running_cpu(); &#125; return NULL;&#125;int main(int argc, char *argv[])&#123; int cpu_id_1 = 1; int cpu_id_2 = 2; pthread_t thr_id_1, thr_id_2; // 创建并绑定线程1到CPU 1 pthread_create(&amp;thr_id_1, NULL, thread_func, &amp;cpu_id_1); sleep(1); // 确保线程1已经绑定 // 创建并绑定线程2到CPU 2 pthread_create(&amp;thr_id_2, NULL, thread_func, &amp;cpu_id_2); // 等待线程结束 pthread_join(thr_id_1, NULL); pthread_join(thr_id_2, NULL);&#125;","categories":["0.平台","Linux","内核"]},{"title":"ARM和X86","path":"/2024/07/24/0-平台-平台相关-ARM和X86/","content":"围绕 ARM 处理器设计的计算机与围绕 Intel 或 AMD 设计的计算机是不可互换使用的。有两个基本问题是它们都要解决的，尽管方式各有不同： 如何平衡晶体管数量与程序复杂性？ 如何确定速度、功耗和成本的优先级？ 定义许多 IT 人士都非常熟悉 x86 处理器，因为它是大多数计算机和服务器硬件中使用的处理器类型。从架构角度来说，x86 系统中的硬件组件（如声卡、显卡、内存、存储器和 CPU）都是相互独立的。大多数组件都有单独的芯片，称为控制器。我们可以对这些组件进行更改或扩展，而不会影响连接性或整个硬件平台。 而 ARM 处理器没有单独的 CPU。相反，处理单元与其他硬件控制器位于同一物理载板上，形成一个集成电路。此外，与英特尔或 AMD CPU 不同，没有所谓的 ARM 处理器制造商。相反，Arm Holdings 公司将芯片的设计方案授权给其他硬件制造商，然后这些制造商将 ARM 处理器芯片整合到他们的硬件设计中。与传统基于 x86 的计算机不同，ARM 芯片不可互换使用，并且具有高度的应用特定性。这些处理器在所谓的系统级芯片（SoC）中一起制造的。 RISC 和 CISC计算机科学中两种主要理念之间的分歧：简化程序员的工作&#x2F;简化微处理器的工作。 要想使用计算机执行任何高效的操作，操作系统及其执行的程序需要与中央处理器（CPU）以及其他硬件（如内存、存储器和网卡）进行交互。CPU 发挥着在操作系统（和上面运行的程序）与这些硬件之间进行调解的作用。为了简化程序员的工作，CPU 有一组预定义的操作和计算，称为指令集或 ISA（指令集架构）。操作系统及其执行的程序（均由程序员编写）依赖这些指令来执行低层功能，例如： CPU 与硬件（内存、存储器、网络等）之间的交互 算术函数（加法、减法等） 数据操作（二进制移位等）。 CISC最初的 x86 CPU 拥有（并且现在仍然拥有）非常丰富的指令集。一条指令可以完成整个计算（如乘法）或将一块数据直接从内存中的一个位置移动到另一个位置。这听起来没什么大不了，但在内存中的不同位置之间进行乘法计算和移动数据确实需要在低层执行大量指令。对于 x86 计算机，这一系列复杂的操作可以在一个周期内完成。具有这种类型指令集的处理单元被称为复杂指令集计算机（CISC，Complex Instruction Set Computer）。 然而，CISC 计算机中的指令如此强大，也意味着它需要更多的晶体管，从而会占用空间并消耗能量。 RISC精简指令集计算机，Reduced Instruction Set Computer 在现实中，大多数计算机仅使用 CISC 计算机所提供的大量指令中的一小部分。最终，精简指令集计算机（RISC）处理器设计应运而生。RISC 处理器也有一个指令集，但其中每条指令仅代表一个能耗较低的简单操作。这就使汇编语言程序员的工作变得更加复杂，但却简化了处理器的工作。利用 RISC 处理器和先进的 RISC 计算机，可以通过运行多条指令或通过将复杂工作推给编译器（而不是 CPU 内核）来执行复杂操作。 其中离不开一些权衡与取舍。x86 CPU 往往具有非常快的计算能力，并且在编程和指令数量方面会更加清晰或简单，但它的代价，就是更大、更昂贵且具有大量晶体管的芯片。ARM 处理器对于某些类型的操作而言可能非常快，但单个指令的重复循环可能会减慢它的速度，这是因为操作更为复杂，并且定义和执行操作的更多工作被推给了编程（和程序员），而不是指令集。 此外，鉴于以上差异，我们可能难以计算其 MIPS（每秒百万条指令，一种对计算机原始处理能力的常用度量），因为不同类型的处理器在执行同一活动时需要用到不同的指令集。 ARM 与 x86 的能耗 RISC 架构源自为小型计算机或微型计算机（最终成为 PC）制造性能更好、外形更小的芯片的需求。于是，这就引出了第二个基本设计问题：究竟是侧重于芯片性能（处理速度或时钟速度）还是能源消耗（功耗）。 由于 ARM 处理器集成到了 SoC 上，因此长期以来围绕的焦点就是整体资源管理，包括低能耗和更低的热量生成。例如，ARM 架构（如 ARMv8）往往没有简单的散热系统（手机上没有风扇）。而另一方面，x86 CPU 倾向于支持高端处理速度，而不是以低功耗为目标。 虽然两种 CPU 设计都具有高性能（ARM 和 x86 阵营都有速度在世界上数一数二的超级计算机），但 ARM 设计往往侧重于更小巧的外形、电池使用时间、尺寸、免除散热要求和成本（这也许是最重要的）等方面。这就是 ARM 处理器主导智能手机、平板电脑甚至树莓派系统等小型电子产品和移动设备的原因。而 x86 架构在服务器、PC 甚至笔记本电脑中更为常见，因为这些领域需要实时的速度和灵活性，并且对散热和尺寸的限制较少。","categories":["0.平台","平台相关"]},{"title":"Docker Pull超时","path":"/2024/07/24/0-平台-Docker-Docker-Pull超时/","content":"修改镜像仓库地址 123sudo vim /etc/docker/daemon.jsonsystemctl daemon-reloadsystemctl restart docker 12345678910&#123;\t&quot;registry-mirrors&quot;: [ &quot;https://do.nark.eu.org&quot;, &quot;https://dc.j8.work&quot;, &quot;https://docker.m.daocloud.io&quot;, &quot;https://dockerproxy.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://docker.nju.edu.cn&quot;\t]&#125;","categories":["0.平台","Docker"]},{"title":"QProcess类来执行系统命令并获取输出","path":"/2024/07/23/1-语言-Qt-QProcess类来执行系统命令并获取输出/","content":"使用 QProcess 的 start 方法启动命令。通过 waitForStarted 等待命令启动完成，使用 connect 连接 readyReadStandardOutput 信号到一个槽函数，当有新的标准输出时，会触发该槽函数读取并输出结果。最后使用 waitForFinished(-1)等待命令执行完毕，-1 表示无限等待，直到命令完成。 123456789101112131415161718192021222324252627282930313233#include &lt;QCoreApplication&gt;#include &lt;QProcess&gt;int main(int argc, char *argv[])&#123; QCoreApplication a(argc, argv); QProcess process; // 以异步方式启动命令，这里以执行&quot;dir&quot;命令为例（Windows 系统） process.start(&quot;cmd&quot;, QStringList() &lt;&lt; &quot;/c&quot; &lt;&lt; &quot;dir&quot;); // 等待命令启动完成 if (!process.waitForStarted()) &#123; qDebug() &lt;&lt; &quot;Command failed to start!&quot;; return 1; &#125; // 连接信号与槽，以便在有新的标准输出时进行处理 QObject::connect(&amp;process, &amp;QProcess::readyReadStandardOutput, [&amp;]() &#123; QString output = process.readAllStandardOutput(); qDebug() &lt;&lt; output; &#125;); // 等待命令执行完成 if (!process.waitForFinished(-1)) &#123; qDebug() &lt;&lt; &quot;Command execution timed out!&quot;; return 1; &#125; return a.exec();&#125; 上述代码是在 Windows 系统下执行 dir 命令的示例。如果你在 Linux 系统下，需要将启动命令修改为相应的终端命令，例如 process.start(“bash”, QStringList() &lt;&lt; “-c” &lt;&lt; “ls”); 来执行 ls 命令列出目录内容。 QProcess 中 start 和 write 中写的命令，末尾要加上 （Linux 直接加 ，Windows 加 \\r ），否则命令可能无法执行。并且，write 方法不可与 waitForFinished 一起使用，否则会阻塞 30 秒，waitForFinished 只能用 start 一起使用。 如果要执行带有管道“|”等特殊字符的命令，可能需要一些额外的处理。例如，在 Linux 系统下执行 ps -ef | grep’mem’这样的命令，需要按照如下方式启动进程： 12QString cmd = &quot;ps -ef | grep&#x27;mem&#x27;&quot;;process.start(&quot;bash&quot;, QStringList() &lt;&lt; &quot;-c&quot; &lt;&lt; cmd); 这样就可以通过 QProcess 获取执行系统命令的输出结果了。Qt 无法直接识别管道“|”和重定向“&gt;&gt;”命令，需要在启动程序或终端时作为参数传入这些命令，而不是启动后再输入。","categories":["1.语言","Qt"]},{"title":"Portainer","path":"/2024/07/22/0-平台-Docker-Portainer/","content":"Portainer can be used to manage Docker containers through a web interface. CE 社区版本部署 首先，创建 Portainer Server 用于存储其数据库的卷： 1docker volume create portainer_data 12345678910111213version: &quot;3&quot;services: portainer: image: portainer/portainer-ce:latest container_name: portainer ports: - 9094:9000 volumes: - portainer_data:/data - /var/run/docker.sock:/var/run/docker.sock restart: unless-stoppedvolumes: portainer_data: 现在安装已完成，访问以下网址登录 Portainer Server 实例： https://localhost:9094","categories":["0.平台","Docker"]},{"title":"0个部署服务器的功能","path":"/2024/07/22/0-平台-服务器-0个部署服务器的功能/","content":"完成对 Alist 的启动与关闭 完成对 photoprism 的启动与关闭 完成 frp 的穿透 完成 devtunnel 的穿透 完成更新 devtunnel 并获取最新的 IP 地址导入 photo.html 完成仓库的更新 【√】80 端口：TVBOX 订阅 9050：本地&#x3D;Hexo 博客部署端口 博客Hexo建设 【√】9080：FRP 映射对接端口 内网穿透方案 【√】9081：FRP 的 DashBoard内网穿透方案 【√】9082: Docker 管理面板 Portainer 【√】9083 Qexo 管理页面 博客管理后端Qexo建设 【√】9084：Alist 映射端口 Alist网盘搭建 【√】9085：PDF 处理工具搭建到云服务器 【√】9090：SSH 端口 【√】9091：3D 打印机的 Mainsail 端口 3D打印机环境配置 9092：OK3568portainer 9093： Photoprism照片备份方案 9094：Photoprism_ 我的 9082：NAS 映射端口 NAS相关配置 9090：1Panel 服务器运维管理面板 9091: GitServer","categories":["0.平台","服务器"]},{"title":"内核模块","path":"/2024/07/22/0-平台-Linux-内核-内核模块/","content":"内核模块的编译 内核模块的安装 内核模块的调试","categories":["0.平台","Linux","内核"]},{"title":"文件系统","path":"/2024/07/22/0-平台-平台相关-文件系统/","content":"文件系统存储限制FAT32 文件系统对单个文件的大小有限制。具体来说，FAT32 文件系统支持的最大文件大小是 4 GB (gigabytes)。这是因为 FAT32 使用 32 位字段来记录文件大小，而 32 位的最大值是 4,294,967,295 字节，约等于 4 GB。 如果需要存储超过 4 GB 的单个文件，可以考虑使用其他文件系统，例如： exFAT：支持非常大的文件，适用于大容量存储设备，例如 USB 闪存驱动器和 SD 卡。 NTFS：Windows 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 ext4：Linux 系统常用的文件系统，支持非常大的文件和分区，适合硬盘和固态硬盘。 文件系统选择建议 USB 闪存驱动器&#x2F;SD 卡：如果需要兼容性且文件大于 4 GB，建议使用 exFAT。 Windows 系统硬盘：NTFS 是默认且最适合的选择。 Linux 系统硬盘：ext4 是默认且最适合的选择。 转换文件系统的步骤如果需要将 FAT32 文件系统转换为 exFAT 或 NTFS，可以通过以下步骤实现： 将 FAT32 转换为 exFAT（在 Windows 中） 备份数据：转换文件系统会格式化驱动器，因此请先备份所有数据。 格式化为 exFAT： 打开“文件资源管理器”。 右键点击需要转换的驱动器。 选择“格式化”。 在文件系统选项中选择“exFAT”。 点击“开始”。 将 FAT32 转换为 NTFS（在 Windows 中） 备份数据：虽然有非破坏性转换方法，但仍建议备份数据以防万一。 非破坏性转换（不会丢失数据）：convert X: &#x2F;fs:ntfs。其中 X: 是要转换的驱动器号。","categories":["0.平台","平台相关"]},{"title":"关于U盘被占用无法弹出","path":"/2024/07/22/0-平台-Windows-关于U盘被占用无法弹出/","content":"Win+R 打开【运行】–&gt;输入 eventvwr.msc 回车打开【事件查看器】–&gt;事件查看器(本地)–&gt;Windows 日志–&gt;系统–&gt;找到最近的【警告 来源 Kernel-PnP】–&gt;双击打开–&gt;你会看到【进程 ID 为 **** 的应用程序已停止删除或弹出设备】，记住这个进程 ID。","categories":["0.平台","Windows"]},{"title":"ETF小助手功能更新","path":"/2024/07/19/3-软件-0-项目-ETF小助手功能更新/","content":"管理功能，添加&#x2F;删除 计算功能，今日估值，持仓成本， 显示功能，显示当前估值和成本比较 历史记录，显示历史曲线 10 日&#x2F;20 日等均线 【×】北向资金&#x3D;&#x3D;&gt;实现方式 API 实时涨跌1https://fundgz.1234567.com.cn/js/007345.js?v=20200908175500 数字为基金代码，rt 为时间戳， 123456789101112131415161718192021/*****功能：获取基金实时信息，天天基金数据接口：http://fundgz.1234567.com.cn/js/基金代码.js传入：基金代码输出：基金实时信息 --&gt; dictfundcode -- 基金代码name -- 基金名称jzrqv -- 上一交易日dwjz -- 基金净值（截止上一交易日）gsz -- 估算净值（实时）gszzl -- 估算涨幅（实时）gztime -- 更新时间（实时）******/jsonpgz(&#123; &quot;fundcode&quot;: &quot;007345&quot;, &quot;name&quot;: &quot;: &quot;富国科技创新灵活配置混合&quot;, &quot;jzrq&quot;: &quot;2020-09-17&quot;, &quot;dwjz&quot;: &quot;1.9441&quot;, &quot;gsz&quot;: &quot;1.9717&quot;, &quot;gszzl&quot;: &quot;1.42&quot;, &quot;gztime&quot;: &quot;2020-09-18 15:00&quot;&#125;); 基金净值数据1http://fund.eastmoney.com/f10/F10DataApi.aspx?type=lsjz&amp;code=007345&amp;page=1&amp;per=49&amp;sdate=2020-09-01&amp;edate=2020-09-18 基金列表1http://fund.eastmoney.com/js/fundcode_search.js 返回数据 12345678910111213141516var r = [ [ &quot;000001&quot;, &quot;HXCZHH&quot;, &quot;华夏成长混合&quot;, &quot;混合型&quot;, &quot;HUAXIACHENGZHANGHUNHE&quot; ], [ &quot;000002&quot;, &quot;HXCZHH&quot;, &quot;华夏成长混合(后端)&quot;, &quot;混合型&quot;, &quot;HUAXIACHENGZHANGHUNHE&quot; ]] 基金详情1http://fund.eastmoney.com/pingzhongdata/007345.js?v=20200908175500 基金公司列表1http://fund.eastmoney.com/js/jjjz_gs.js 返回数据 123456789101112var gs=&#123; op: [ [ &quot;80163340&quot;, &quot;安信基金&quot; ], [ &quot;80036782&quot;, &quot;招商基金&quot; ] ]&#125; 基金增幅排名1http://fund.eastmoney.com/data/rankhandler.aspx?op=ph&amp;dt=kf&amp;ft=gp&amp;rs=&amp;gs=0&amp;sc=zzf&amp;st=desc&amp;sd=2016-03-29&amp;ed=2017-03-29&amp;qdii=&amp;tabSubtype=,,,,,&amp;pi=1&amp;pn=50&amp;dx=1&amp;v=0.6370068000914493 ft： fund type 类型 所有-all 股票型-gp 混合型-hh 债券型-zq 指数型-zs 保本型-bb QDII-qdii LOF-lof 当前基金净值http://fundgz.1234567.com.cn/js/[基金代码].js?rt=[时间戳] （其中时间戳 rt 用于避免浏览器缓存数据，可省略）。 例如，http://fundgz.1234567.com.cn/js/001186.js，返回的结果类似于：jsonpgz({“fundcode”:”001186”,”name”:”富国文体健康股票”,”jzrq”:”2022-09-20”,”dwjz”:”1.9300”,”gsz”:”1.9187”,”gszzl”:”-0.58”,”gztime”:”2022-09-21 15:00”});。这是一个文本数据，需要进一步处理。可以使用 Python 中的 requests、re、json 等库进行处理，将文本转化为字典格式，以便提取所需信息，代码示例如下： 123456789101112131415import requestsimport jsonimport redef realtmfundinfo(fundcode): fund_id = fundcode real_time_url = f&quot;http://fundgz.1234567.com.cn/js/&#123;fund_id&#125;.js&quot; org_content = requests.get(real_time_url) fund_info = org_content.text fund_info = re.findall(r&quot;\\&#123;.+\\&#125;&quot;, fund_info) fund_info = json.loads(fund_info[0]) return fund_infofund_info = realtmfundinfo(&quot;001186&quot;)print(fund_info) 历史基金净值http://fund.eastmoney.com/pingzhongdata/[基金代码].js?v=[时间戳] （时间戳 v 可省略）。 例如，http://fund.eastmoney.com/pingzhongdata/001186.js，可获取该基金的申购费率、持仓股票、历史单位净值、历史累计净值等多个信息。返回基金的净值日期（date）、单位净值（nav）、累计净值(cumnav)、净值回报率(equityReturn)、每份派送金(unitMoney).处理返回的文本数据的 Python 代码示例如下： 1234567891011121314151617181920212223242526import requestsimport jsonimport reimport pandas as pddef htrfundinfo(fundcode): fund_id = fundcode history_tmurl = f&quot;http://fund.eastmoney.com/pingzhongdata/&#123;fund_id&#125;.js&quot; org_content = requests.get(history_tmurl) fund_info = org_content.text # 提取单位净值 temp_nav = re.findall(r&quot;data_networthtrend\\s=\\s(\\(\\&#123;.+\\&#125;\\));\\/\\*累计净值走势\\*\\/&quot;, fund_info)[0] temp_nav = json.loads(temp_nav) temp_nav = pd.DataFrame(temp_nav) temp_nav.rename(columns=&#123;&quot;x&quot;:&quot;date&quot;,&quot;y&quot;:&quot;nav&quot;&#125;, inplace=True) n = len(temp_nav[&quot;date&quot;]) for i in range(n): temp_nav[&quot;date&quot;][i] = time.strftime(&#x27;%y-%m-%d&#x27;, time.localtime(temp_nav[&quot;date&quot;][i]/1000.)) temp_nav = temp_nav.set_index(&#x27;date&#x27;) # 提取累计净值 temp_cumnav = re.findall(r&quot;data_acworthtrend\\s=\\s(\\(.+\\));\\/\\*累计收益率走势\\*\\/&quot;, fund_info)[0] temp_cumnav = eval(temp_cumnav) return temp_navfund_nav = htrfundinfo(&quot;001186&quot;)print(fund_nav)","categories":["3.软件","0.项目"]},{"title":"部署stable-diffusion-webui","path":"/2024/07/18/3-软件-AI-部署stable-diffusion-webui/","content":"git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui .&#x2F;webui-user.bat activate.bat pip install –pre openvino pip install torch pip install torchvision 修改 pip install -r .requirements.txt pip install pyproject.toml-based pip install setuptools rust pip install ninja pip3 install –force-reinstall ninja webui-user.bat &#x2F;&#x2F;下载 minggw64 要求&gt;&#x3D;8.0，配置到系统环境变量 下载 msvc","categories":["3.软件","AI"]},{"title":"重装系统无法识别硬盘","path":"/2024/07/18/0-平台-Windows-重装系统无法识别硬盘/","content":"Win11 重新安装系统时，由于缺少 RST 驱动，导致进入 PE 后无法识别到硬盘，需要安装该驱动，搜索 intel_rst_technology 并下载， https://global-download.acer.com/GDFiles/Driver/IRST/IRST_Intel_19.2.0.1003_W11x64_A.zip?acerid=637907037961464459&amp;Step1=&amp;Step2=&amp;Step3=SF314-71&amp;OS=ALL&amp;LC=en&amp;BC=ACER&amp;SC=PA_6 之后在重装系统时选择 load driver 加载该驱动即可识别硬盘","categories":["0.平台","Windows"]},{"title":"网络设备驱动的中断处理","path":"/2024/07/18/0-平台-Linux-驱动-网络设备驱动的中断处理/","content":"devm_request_irq 和 request_threaded_irq 都是用于注册中断处理程序的函数，但它们的用途和管理机制有所不同。以下是这两个函数的详细说明及如何使用它们。 devm_request_irqdevm_request_irq 是用于注册中断处理程序的设备管理函数，它的主要优点是自动管理资源。当设备驱动程序被卸载时，系统会自动释放中断资源，避免资源泄漏。 函数原型： 123int devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t handler, unsigned long irqflags, const char *devname, void *dev_id); 参数说明：dev：指向设备结构体的指针。irq：要申请的中断号。handler：中断处理程序的函数指针。irqflags：中断标志，如 IRQF_SHARED 等。devname：设备名称，用于显示和调试。dev_id：设备标识，一般为设备结构体的指针，用于区分共享中断。 request_threaded_irqrequest_threaded_irq 是用于注册中断处理程序和线程化中断处理程序的函数。线程化中断处理程序运行在中断上下文之外，因此可以执行更复杂的操作而不会阻塞中断处理。 函数原型： 123int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id); 参数说明： irq：要申请的中断号。 handler：顶半部中断处理程序的函数指针。可以为 NULL。 thread_fn：线程化中断处理程序的函数指针。不能为 NULL。 irqflags：中断标志，如 IRQF_SHARED 等。 devname：设备名称，用于显示和调试。 dev_id：设备标识，一般为设备结构体的指针，用于区分共享中断。","categories":["0.平台","Linux","驱动"]},{"title":"栈和队列","path":"/2024/07/17/1-语言-1-数据结构-栈和队列/","content":"栈（stack）栈是限定仅在表的一端进行插入或删除操作的线性表。我们把允许插入和删除操作的一端称为栈顶（top），另一端称为栈底（bottom）。不含任何数据元素的栈称为空栈。栈又称为“后进先出（Last In First Out，简称 LIFO）的线性表”，简称为 LIFO 结构。 栈的插入操作，称为进栈&#x2F;入栈&#x2F;压栈。栈的删除操作，称为出栈&#x2F;弹栈。 栈的顺序存储结构及实现 定义 1234567typedef int data_t; //定义栈中数据元素的数据类型typedef struct&#123;\tdate_t *data; //用指针指向栈的存储空间\tint maxlen; //当前栈的最大元素个数\tint top; //指向栈顶位置（数组下标）的变量&#125;seqstack_t; //顺序栈类型定义 创建栈 123456789seqstack_t *CreateEmptyStack(int max_len)&#123;\tseqstack_t *stack;\tstack = (seqstack_t *)malloc(sizeof(seqstack_t));\tstack-&gt;data = (data_t *)malloc(sizeof(data_t)*max_len);\tstack-&gt;top = -1;\tstack-&gt;max_len = max_len;\treturn stack;&#125; 摧毁一个栈 123456789void DestroyStack(seqstack_t *stack)&#123;\tif(stack != NULL)\t&#123; if(stack-&gt;data != NULL) free(stack-&gt;data); free(stack);\t&#125;&#125; 清空一个栈 12345void ClearStack(seqstack_t *stack)&#123;\tif(stack != NULL) stack-&gt;top = -1;&#125; 判断栈是否为空 1234567int EmptyStack(seqstack_t *stack)&#123;\tif(stack == NULL) return -1;\treturn(stack-&gt;top == -1 ? 1 : 0);&#125; 5、判断栈是否为满 123456int FullStack(seqstack_t *stack)&#123;\tif(stack == NULL) return -1;\treturn(stack-&gt;top == (stack-&gt;max_len - 1) ? 1 : 0);&#125; 6、进栈 1234567891011int PushStack(seqstack_t *stack ,data_t x)&#123;\tif(FullStack(stack)) return -1;\telse\t&#123; stack-&gt;top++; stack-&gt;data[stack-&gt;top] = x;\t&#125;\treturn 0;&#125; 7、出栈 1234567891011int PopStack(seqstack_t *stack,data_t *x)&#123;\tif(EmptySqstack(stack)) return -1;\telse\t&#123; *x = stack-&gt;data[stack-&gt;top]; stack-&gt;top--;\t&#125;\treturn 0;&#125; 8、取栈顶元素 12345678int GetTop(seqstack_t *stack,data_t *x)&#123;\tif(EmptyStack(stack)) return -1;\telse *x = stack-&gt;data[stack-&gt;top];\treturn 0;&#125; 栈的链式存储结构及实现若是栈中元素的数目变化范围较大或不清楚栈元素的数目，就应该考虑使用链式存储结构。人们将用链式存储结构表示的栈称作”链栈”。链栈通常用一个无头结点的单链表表示。插入操作和删除操作均在链表头部进行，链表尾部就是栈底，栈顶指针就是头指针。 定义 123456typedef int data_t;typedef struct node_t&#123;\tdata_t data; //数据域\tstruct node_t *next; //链接指针域&#125;linkstack_t; //链栈类型定义 创建空栈： 1234567linkstack_t *CreateLinkstack()&#123;\tlinkstack_t *top;\ttop = (linkstack_t *)malloc(sizeof(linkstack_t));\ttop-&gt;next = NULL;\treturn top;&#125; 判断是否为空栈： 1234int EmptyStack(linkstack_t *top)&#123;\treturn (top-&gt;next == NULL ? 1 : 0);&#125; 入栈 123456789void PushStack(linkstack_t *top,data_t x)&#123;\tlinkstack_t *p;\tp = (linkstack_t *)malloc(sizeof(linkstack_t));\tp-&gt;data = x;\tp-&gt;next = top-&gt;next;\ttop-&gt;next = p;\treturn;&#125; 出栈 123456789101112int PopStack(linkstack_t stack,data_t *x)&#123;\tif(stack-&gt;next == NULL || stack == NULL) return -1;\tlinkstack_t p;\tp = stack-&gt;next;\tstack-&gt;next = p-&gt;next;\tif(x != NULL) *x = p-&gt;data;\tfree(p);\treturn 0;&#125; linkstack123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;linkstack.h&quot;linkstack_t *CreateEmptyLinkstack()&#123;\tlinkstack_t *s;\ts = (linkstack_t *)malloc(sizeof(linkstack_t));\ts-&gt;next = NULL;\treturn s;&#125;void DestroyLinkstack(linkstack_t *stack)&#123;\tif (stack) &#123; /* clear the stack linked list */ ClearLinkstack(stack); /* free the stack header */ free(stack);\t&#125;&#125;int EmptyLinkstack(linkstack_t *stack)&#123;\tif (stack) &#123; return ((NULL == stack-&gt;next) ? 1 : 0);\t&#125; else &#123; return -1;\t&#125;&#125;void ClearLinkstack(linkstack_t *stack)&#123;\tlinkstack_t *node; /* node to be removed */\tif (!stack) return;\twhile ( NULL != stack-&gt;next ) &#123; /* disconnect the one to be removed */ node = stack-&gt;next; stack-&gt;next = node-&gt;next; free(node);\t&#125;\treturn;&#125;int PushStack(linkstack_t *stack, data_t x)&#123;\tlinkstack_t *node; /* node to be inserted */\tif (!stack) return -1;\tnode = (linkstack_t *)malloc(sizeof(linkstack_t));\tif (NULL == node) &#123; return -1;\t&#125;\tnode-&gt;data = x;\t/* insert from the head of the link list * it&#x27;s cheaper to push from the head of the single-linked * list. */\tnode-&gt;next = stack-&gt;next;\tstack-&gt;next = node;\treturn 0;&#125;int PopStack(linkstack_t *stack, data_t *data)&#123;\tlinkstack_t *node; /* node to be removed */ if (!stack) return -1;\tif (!(stack-&gt;next)) return -1; /* stack is empty */\t/* pop from the head of the list */\tnode = stack-&gt;next;\tstack-&gt;next = node-&gt;next;\tif (data) &#123; *data = node-&gt;data;\t&#125;\t/* now we can free the node safely */\tfree(node); return 0;&#125;int GetTop(linkstack_t *stack, data_t *data)&#123;\tif (!stack) return -1;\tif (!(stack-&gt;next)) return -1; /* stack is empty */ if (data) &#123; *data = stack-&gt;next-&gt;data;\t&#125;\treturn 0;&#125;void\tVisitStack(linkstack_t *stack)&#123;\tlinkstack_t *node; /* node to be iterated */ if (!stack) return;\t/* print from the base to the top */\tprintf(&quot;stack = &#123;&quot;);\tif (stack-&gt;next) &#123; /* list is not empty */ node = stack-&gt;next; while (NULL != node) &#123; printf(&quot;%d,&quot;, node-&gt;data); node = node-&gt;next; &#125; printf(&quot;\\b&#125; &quot;);\t&#125; else &#123; printf(&quot;&#125; &quot;);\t&#125;&#125; 栈的应用递归递归：函数在自身的函数体内直接或间接地调用自身。 示例：递归法求斐波那契数列 123456789101112131415int Fbi(int i)&#123; if(i&lt;2) return i==0?0:1;\treturn Fbi(i-1)+Fbi(i-2);&#125;int main()&#123; int i;\tfor(i=0;i&lt;40;i++) printf(&quot;%d\\t&quot;,Fbi(i));\tprintf(&quot; &quot;);\treturn 0;&#125; 要实现递归，必要的两个条件是递归出口和递归逻辑。在示例程序中，if(i&lt;2)就是递归出口，而 Fbi(i-1)+Fbi(i-2)就是递归逻辑。对比递归代码和非递归（迭代）代码，我们可以看出递归和迭代的区别：迭代使用循环结构，而递归使用分支结构 在某些程序中，递归能使得程序结构简洁清晰，容易理解。但是大量的调用递归函数会建立许多该函数的副本，需要大量的内存存储空间。而迭代法则无需大量的存储空间。 要想实现递归，我们需要明白递归的过程本质上是函数返回顺序是其调用顺序的逆序，即：先行调用的函数会在后面获得返回值。这种先行存储数据，并在之后逆序恢复得到数据的过程，显然很符合栈这种数据结构。因此，编译器使用栈来实现函数的递归。 在调用阶段，对于每层递归，函数的局部变量、参数、返回地址都被压入栈中，再去调用下次递归。在返回阶段，依次弹出位于栈顶的函数，获得计算结果。这也是为什么需要“递归出口”的原因，递归出口可以看做是从压栈到弹栈的状态转变因素。 后缀（逆波兰）表示法中缀表达式，即运算符（此处特指算数运算符）在操作数中间。9+(3-1)*3+10/2 后缀表示法，也称为逆波兰表示法，即运算符在两个操作数之后出现 9 3 1 - 3 * + 10 2 / + 后缀表达式的算法规则：从左到右遍历表达式，若遇到数字则进栈，遇到运算符则弹出栈顶两个元素进行运算，计算结果再次压栈，最后计算得到的结果就是最终结果。 我们以 9 3 1 - 3 * + 10 2 / + 进行讲解（操作数入栈） 初始化一个空栈，此栈用于对要计算的操作数的进出及存储。 9、3、1 都是数字，因此依次入栈 接下来是-，是符号，弹出栈顶两个元素作为操作数，注意先弹出的元素在符号右侧，后弹出的元素在符号左侧，即 3 - 1，得到计算结果 2，将 2 压栈。 数字 3 进栈 后面是 *，栈顶两个元素弹栈进行运算 2 * 3，得到结果 6，再压入栈 后面是+，栈顶两个元素弹栈进行运算 9 + 6，得到结果 15，再压入栈 数字 10 和 2 进栈 后面是&#x2F;，栈顶两个元素弹栈进行运算 10 &#x2F; 2，得到结果 5，再压入栈 最后一个符号是+，栈顶两个元素弹栈进行运算 15 + 5，得到结果 20 最终结果是 20，栈变为空，结束运算。 中缀表达式转化为后缀表达式的规则：从左到右遍历中缀表达式的每个数字和符号，若是数字就输出，即成为后缀表达式的一部分；若是符号则判断其与栈顶符号的优先级，是右括号或优先级低于或等于栈顶符号的则栈顶元素依次出栈并输出，直至遇到一个比其优先级低的运算符为止，并将当前符号进栈，一直到最终输出后缀表达式为止。 我们以 9+(3-1)*3+10/2------&gt;9 3 1 - 3 * + 10 2 / + 进行讲解（运算符入栈） 初始化一个空栈，用于对符号进出栈使用。 第一个数字是 9，输出 9。后面的符号+入栈。 第三个字符是（，依然是符号，因其是左括号还未配对，故进栈。 第四个字符是数字 3，输出，此时表达式为 9 3，接着符号-进栈。 接下来是数字 1，输出，此时表达式为 9 3 1，后面是符号），此时我们需要把（之前的所有元素都出栈，直至输出（为止。此时总的表达式是 9 3 1 -。 紧接着是符号 *，因为此时的栈顶符号是+，优先级低于 *，因此不输出，* 进栈。紧接着是数字 3，输出，总表达式为 9 3 1 – 3. 之后是符号+，此时栈顶元素是 *，比+优先级高，因此栈中元素出栈并输出（因为没有比+更低优先级的符号，所以全部出栈），总输出表达式为 9 3 1 – 3 * +。然后将这个符号+进栈。 紧接着输出数字 10，总表达式为 9 3 1 – 3 * + 10。之后是符号 /，所以 / 进栈。 最后一个数字为 2，此时总表达式为 9 3 1 – 3 * + 10 2。 因已到最后，所以将栈中符号全部出栈。最终获得的后缀表达式为 9 3 1 – 3 * + 10 2 / +。 队列队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。队列是一种先进先出（First In First Out）的线性表，简称 FIFO。允许插入操作的一端称为队尾，允许删除操作的一端称为队头。 队列作为特殊的线性表，有顺序队列和链式队列两种形式。 队列的顺序存储结构及实现如果我们要建立元素个数为 n 的队列，则需要建立一个数组长度不小于 n 的数组，数组下标为 0 的为队头，当最大下标的为队尾。若有元素要入队，则只需将其存储在第 n+1 个位置即可。而若想出队，则删除了下标为 0 的元素后，所有在其后的元素都需要向前移动一格，即保持下标为 0 的元素为队头。但这样做显然浪费了大量时间。 解决该问题的方法就是不再限制下标为 0 的元素为队头，每次出队后，队头自动变成当前数组下标最小的元素即可。这样就无需所有元素向前移动。但是，若如此做，则会造成大量的已出队的元素的存储空间浪费。而且，若此时入队元素已经大于 n，则我们需要更大的存储空间才行，但队头位置有大量空间未利用，空间浪费严重。 解决以上问题的方法就是如果后面满了，则我们就从头开始，也就是将队列做成头尾相接的循环。我们把这种头尾相接的顺序存储结构的队列称为循环队列。 在循环队列中，当队列为空时，有 front=rear，而当所有队列空间全占满时，也有 front=rear。为了区别这两种情况，规定循环队列最多只能有 MaxSize-1 个队列元素，当循环队列中只剩下一个空存储单元时，队列就已经满了。因此，队列判空的条件时 front=rear，而队列判满的条件时 front=（rear+1）%MaxSize。 队头指针 front，指向队头元素的位置的前一个位置。即指向预留的位置； 队尾指针 rear，指向队尾元素的位置； 入队： rear = (rear + 1) % N (maxsize)，然后元素放入队尾 rear 所指向的位置； 出队： front = (front + 1) % N，然后取出队头指针 front 所指向的元素； 队空： front == rear; 队满： (rear + 1) % N == front, N 为数组的元素个数； 为了区别空队和满队，满队元素个数比数组元素个数少一个。 这样，我们就需要两个指示其队头（front）和队尾（rear）的下标变量。 1234567#define N 64 //队列中数据元素的数据类型typedef int data_t;typedef struct&#123;\tdata_t data[N]; //用数组作为队列的储存空间\tint front,rear; //指示队头位置和队尾位置的指针&#125;sequeue_t; 当 (rear+1)%QueueSize==front 时，此时队尾的下个位置就是队头，则该队列为满队列。注意 rear 的位置不是队尾元素的位置，而是队尾元素的下一个位置，即当队列满时，队列中还有一个空闲存储空间，但我们规定该状态下就是满队列。 那么，定义好队列的的队头和队尾位置，我们来考虑怎样计算队列长度。 当 rear&gt;front 时，表示队尾在队头右边，此时队列长度为 rear-front； 当 rear&lt;front 时，表示队尾在队友左边，此时计算队列长度应分成两部分，即 rear 一部分，QueueSize-front 一部分，总体长度为 rear-front+QueueSize。 通用计算队列长度的公式是 length=(rear-front+QueueSize)%QueueSize 创建空队列 12345678sequeue_t *CreateEmptySequeue()&#123;\tsequeue_t *queue;\tqueue = (sequeue_t *)malloc(sizeof(sequeue_t));\tif (NULL == queue) return NULL;\tqueue-&gt;front = queue-&gt;rear = 0;\treturn queue;&#125; 摧毁一个队列 1234567voidDestroySequeue(sequeue_t *queue)&#123;\tif (NULL != queue)\t&#123; free(queue);\t&#125;&#125; 判断一个队列是否为空 123456intEmptySequeue(sequeue_t *queue)&#123;\tif (NULL == queue) return-1;\treturn (queue-&gt;front == queue-&gt;rear ? 1 : 0);&#125; 判断一个队列是否为满 12345intFullSequeue(sequeue_t *queue)&#123;\tif (NULL == queue) return-1;\treturn ((queue-&gt;rear + 1) % N == queue-&gt;front ? 1 : 0);&#125; 清空一个队列 123456voidClearSequeue(sequeue_t *queue)&#123;\tif (NULL == queue) return;\tqueue-&gt;front = queue-&gt;rear = 0;\treturn;&#125; 入队 12345678intEnQueue(sequeue_t *queue, data_t x)&#123;\tif (NULL == queue) return - 1;\tif (1 == FullSequeue(queue)) return-1; /* full */\tqueue-&gt;rear = (queue-&gt;rear + 1) % N;\tqueue-&gt;data[queue-&gt;rear] = x;\treturn 0;&#125; 出队 12345678910intDeQueue(sequeue_t *queue, data_t *x)&#123;\tif (NULL == queue) return-1;\tif (1 == EmptySequeue(queue)) return-1; /* empty */\tqueue-&gt;front = (queue-&gt;front + 1) % N;\tif (NULL != x) &#123; *x = queue-&gt;data[queue-&gt;front];\t&#125;\treturn 0;&#125; 队列的链式存储结构及实现队列的链式存储结构本质上是从单链表演化而来的。将单链表改造成链式队列，如果将头结点做为队头，最后一个节点做为队尾，则该队列的出队操作方便，而入队操作较慢；反之，如果将头结点做为队尾，最后一个节点做为队头，则该队列的入队操作方便，而出队操作较慢。那么，能否将单链表稍加改进，使得该链式队列的入队操作和出队操作一样方便呢？ 答案是可以的，只需要改进头结点。将“头结点存储一个 next 指针”改为“头结点存储两个指针 front 和 rear”，front 指针指向队头，rear 指针指向队尾。这样我们进行出队&#x2F;入队操作时，只需要访问这两个指针就能快速地找到队头&#x2F;队尾。 队列的链式存储结构定义，将单链表的头结点稍加改造 1234567891011typedef int data_t;typedef struct node_t//定义单链表&#123;\tdata_t data;\tstruct node_t *next;&#125;linknode_t, *linklist_t;typedef struct//定义链式队列&#123; linklist_t front, rear;&#125;linkqueue_t; 创建空队列 1234567891011linkqueue_t *CreateEmptyLinkqueue()&#123;\tlinkqueue_t *lp = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif(lp == NULL) return;\tlp-&gt;front = lp-&gt;rear = (linknode_t *)malloc(sizeof(linknode_t));\tif(lp-&gt;front == NULL) return;\tlp-&gt;front-&gt;next = NULL;\treturn lp;&#125; 摧毁一个链队列 12345678void DestroyLinkqueue(linkqueue_t *queue)&#123;\tif(queue != NULL)\t&#123; ClearLinkqueue(queue); free(queue);\t&#125;&#125; 清空一个链队列 1234567891011void ClearLinkqueue(linkqueue_t *queue)&#123;\tlinknode_t *qnode;\twhile(q-&gt;front)\t&#123; qnode = queue-&gt;front; queue-&gt;front= qnode-&gt;next; free(qnode);\t&#125;\tqueue-&gt;rear = NULL;&#125; 判定链式队列是否为空 由于单链表的属性，链式队列几乎不会出现“队列已满”的情况，因此不考虑判定链式队列是否已满的操作。判定链式队列是否为空，只需要判定队列的 front 指针是否为空即可。 123456int EmptyLinkqueue(linkqueue_t *queue)&#123;\tif(queue == NULL) return-1;\treturn(queue-&gt;front == queue-&gt;rear ? 1 : 0);&#125; 队列的链式存储结构——入队操作 入队操作其实就是在链表尾部插入节点。（需要判定插入时链表是否为空，如果链表为空，则 front 和 rear 两个指针都需要操作）新来的数据节点附在当前 rear 节点之后，并将 rear 节点指向该节点即可。 123456789101112131415161718192021int EnQueue(linkqueue_t *queue,data_t x)&#123;\tlinknode_t *node_new;\tif(queue == NULL) return-1;\tnode_new = (linknode_t *)malloc(sizeof(linknode_t));\tif(node_new == NULL) return-1;\tnode_new-&gt;data = x;\tnode_new-&gt;next = NULL;\tif(queue-&gt;front-&gt;next == NULL)\t&#123; queue-&gt;front-&gt;next = queue-&gt;rear = node_new;\t&#125;\telse\t&#123; queue-&gt;rear-&gt;next = node_new; queue-&gt;rear = node_new;\t&#125;\treturn 0;&#125; 队列的链式存储结构——出队操作 出队操作就是将链表的头结点的后继节点出队，并将其之后的节点设置为头结点的后继节点。若链表除头结点外仅剩一个元素，则需将 rear 指向头结点。 123456789101112int DeQueue(linkqueue_t *queue,data_t *x)&#123;\tlinknode_t *node_remove;\tif(queue == NULL || queue-&gt;front-&gt;next == NULL) return-1;\tnode_remove = queue-&gt;front-&gt;next;\tqueue-&gt;front-&gt;next = node_remove-&gt;next;\tif(x != NULL) *x = node_remove-&gt;data;\tfree(node_remove);\treturn 0;&#125; 链式队列代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143typedef int data_t;typedef struct node_t&#123;\tdata_t data;\tstruct node_t *next;&#125; linknode_t, *linklist_t;typedef struct&#123;\tlinklist_t front, rear;&#125; linkqueue_t;linkqueue_t *CreateEmptyLinkqueue()//创建空队列&#123;\tlinkqueue_t *queue;\tqueue = (linkqueue_t *)malloc(sizeof(linkqueue_t));\tif (NULL == queue)\t&#123; perror(&quot;Create Empty LinkQueue Error&quot;); return NULL;\t&#125;\tqueue-&gt;rear = queue-&gt;front = NULL;\treturn queue;&#125;int ClearLinkqueue(linkqueue_t *queue)//清空队列&#123;\tlinknode_t *node_remove;\tnode_remove = queue-&gt;front;\twhile (NULL != node_remove)\t&#123; queue-&gt;front = queue-&gt;front-&gt;next; free (node_remove); node_remove = queue-&gt;front;\t&#125;\tqueue-&gt;rear = NULL;\treturn OK;&#125;int DestroyLinkqueue(linkqueue_t *queue)//销毁队列&#123;\tif (queue)\t&#123; ClearLinkqueue(queue); free(queue); return OK;\t&#125;\telse\t&#123; printf(&quot;DestroyLinkqueue Error &quot;); return ERROR;\t&#125;&#125;int EmptyLinkqueue(linkqueue_t *queue)//判定队列是否为空&#123;\tif (!queue)\t&#123; printf(&quot;EmptyLinkqueue Error &quot;); return -1;\t&#125;\treturn queue-&gt;front == NULL ? OK : ERROR;&#125;int EnQueue(linkqueue_t *queue, data_t x)//入队&#123;\tlinknode_t *node_new;\tif (!queue)\t&#123; printf(&quot;EnQueue Error &quot;); return ERROR;\t&#125;\tnode_new = (linknode_t *)malloc(sizeof(linknode_t));\tnode_new-&gt;data = x;\tnode_new-&gt;next = NULL;\tif(EmptyLinkqueue(queue)==OK)\t&#123; queue-&gt;front = queue-&gt;rear = node_new;\t&#125;\telse\t&#123; queue-&gt;rear-&gt;next = node_new; queue-&gt;rear = node_new;\t&#125;\treturn OK;&#125;int DeQueue(linkqueue_t *queue, data_t *x)//出队&#123;\tlinknode_t *node_remove;\tif(!queue)\t&#123; printf(&quot;DeQueue Error &quot;); return ERROR;\t&#125;\tif(EmptyLinkqueue(queue)==OK) &#123; printf(&quot;queue is Empty &quot;); return ERROR; &#125;\tnode_remove = queue-&gt;front;\tqueue-&gt;front = node_remove-&gt;next;\tif (NULL == queue-&gt;front) queue-&gt;rear = NULL;\tif(x)\t&#123; *x = node_remove-&gt;data;\t&#125;\tfree(node_remove);\treturn OK;&#125;int VisitQueue(linkqueue_t *queue)//遍历队列&#123;\tlinknode_t *node;\tprintf(&quot;aueue = &#123;&quot;);\tnode = queue-&gt;front;\tif (NULL == node) &#123; printf(&quot;&#125; &quot;); return OK;\t&#125;\twhile (NULL != node) &#123; printf(&quot;%d,&quot;, node-&gt;data); node = node-&gt;next;\t&#125;\tprintf(&quot;\\b&#125; &quot;);\treturn OK;&#125; 球钟问题球钟是一个利用球的移动来记录时间的简单装置。它有三个可以容纳若干个球的指示器：分钟指示器，五分钟指示器，小时指示器。若分钟指示器中有 2 个球，五分钟指示器中有 6 个球，小时指示器中有 5 个球，则时间为 5:32。每过一分钟，球钟就会从球队列的队首取出一个球放入分钟指示器，分钟指示器最多可容纳 4 个球。当放入第五个球时，在分钟指示器的 4 个球就会按照他们被放入时的相反顺序加入球队列的队尾。而第五个球就会进入五分钟指示器。按此类推，五分钟指示器最多可放 11 个球，小时指示器最多可放 11 个球。 当小时指示器放入第 12 个球时，原来的 11 个球按照他们被放入时的相反顺序加入球队列的队尾，然后第 12 个球也回到队尾。这时，三个指示器均为空，回到初始状态，从而形成一个循环。因此，该球钟表示时间的范围是从 0：00 到 11：59。 思考：球钟需要多少个球，才能实现计时范围为 0：00 到 11：59？ 提示：使用 3 个栈来分别表示 1min 指示器、5min 指示器和 1h 指示器，使用一个队列来存储小球 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define MAXSIZE_1 5#define MAXSIZE_2 12#define MAXSIZE_ball 28#define OK 1#define ERROR 0typedef int data_t;typedef struct //一分钟的顺序栈&#123;\tdata_t data[MAXSIZE_1];\tint top;&#125;one_min_t;typedef struct //五分钟与一小时的顺序栈&#123;\tdata_t data[MAXSIZE_2];\tint top;&#125;five_min_t;typedef struct //所有小球的存放队列&#123;\tdata_t data[MAXSIZE_ball];\tint front;\tint rear;&#125;SqQueue;int main()&#123; int i; data_t *the_ball; one_min_t *one_min; five_min_t *five_min,*one_hour; SqQueue *ball; one_min = CreateEmptyStack(); five_min = CreateEmptyStack(); one_hour = CreateEmptyStack(); ball = CreateEmptyQueue(); for(i = 0; i &lt; MAXSIZE_ball; i++) &#123; EnQueue(ball,i+1); &#125; DeQueue(ball,the_ball); if(0==PushStack(one_min,the_ball)) &#123; for(i=0; i&lt;4; i++) &#123; PopStack(one_min,the_ball); EnQueue(ball,the_ball); &#125; &#125; return 0;&#125;int PushStack(SqStack *s,data_t e)//压栈&#123;\tif(s-&gt;top==MAXSIZE-1)\t&#123; printf(&quot;Stack is Full &quot;); return ERROR;\t&#125;\ts-&gt;top++;\ts-&gt;data[s-&gt;top]=e;\treturn OK;&#125;int PopStack(SqStack *s,data_t *e)//弹栈&#123;\tif(s-&gt;top==-1)\t&#123; printf(&quot;Stack is Empty &quot;); return ERROR;\t&#125;\t*e=s-&gt;data[s-&gt;top];\ts-&gt;top--;\treturn OK;&#125;SqStack* CreateEmptyStack()//创建栈&#123; SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) &#123; printf(&quot;CreateEmptyStack Error &quot;); exit(0); &#125; stack-&gt;top=-1; return stack;&#125;int EmptyStack(SqStack *s)//判断栈是否是空栈&#123; return -1==s-&gt;top?OK:ERROR;&#125;int FullStack(SqStack *s)//判断栈是否是满栈&#123; return MAXSIZE-1==s-&gt;top?OK:ERROR;&#125;int ClearStack(SqStack *s)//清空栈内元素&#123; s-&gt;top=-1; return OK;&#125;SqQueue *CreateEmptyQueue()//创建队列&#123;\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL)\t&#123; printf(&quot;CreateEmptyQueue Error &quot;); return NULL;\t&#125;\tsq-&gt;front=0;\tsq-&gt;rear=0;\treturn sq;&#125;int EmptyQueue(SqQueue *Q)//判断队是否为空&#123;\tif(Q==NULL)\t&#123; printf(&quot;EmptyQueue Error &quot;); return -1;\t&#125;\tif(Q-&gt;rear==Q-&gt;front) return OK;\telse return ERROR;&#125;int FullQueue(SqQueue *Q)//判断队是否已满&#123;\tif(Q==NULL)\t&#123; printf(&quot;EmptyQueue Error &quot;); return -1;\t&#125;\tif((Q-&gt;rear+1)%MAXSIZE==Q-&gt;front) return OK;\telse return ERROR;&#125;int EnQueue(SqQueue *Q,data_t e)//元素e入队&#123;\tif(FullQueue(Q)==OK)\t&#123; printf(&quot;Queue is Full &quot;); return ERROR;\t&#125;\tQ-&gt;data[Q-&gt;rear]=e;\tQ-&gt;rear=(Q-&gt;rear+1)%MAXSIZE;\treturn OK;&#125;int DeQueue(SqQueue *Q,data_t *e)//元素出队，出队元素存储在e中&#123;\tif(EmptyQueue(Q)==OK)\t&#123; printf(&quot;Queue is Empty &quot;); return ERROR;\t&#125;\t*e=Q-&gt;data[Q-&gt;front];\tQ-&gt;front=(Q-&gt;front+1)%MAXSIZE;\treturn OK;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#define ONEMIN 5#define FIVEMIN 12#define ONEHOUR 12#define BALLQUE 28#define OK 1#define ERROR 0typedef int data_t;typedef struct&#123;\tdata_t *data;\tint top;//栈顶\tint maxlen;&#125;SqStack;typedef struct&#123;\tdata_t *data;\tint front;//队头位置\tint rear;//队尾位置\tint maxlen;&#125;SqQueue;/**************************队列部分**************************/SqQueue *CreateEmptyQueue(int length)//创建队列&#123;\tSqQueue *sq = (SqQueue*)malloc(sizeof(SqQueue));\tif(sq==NULL)\t&#123; printf(&quot;CreateEmptyQueue Error &quot;); return NULL;\t&#125;\tsq-&gt;data = (data_t*)malloc(sizeof(data_t)*length);\tsq-&gt;maxlen=length;\tsq-&gt;front=0;\tsq-&gt;rear=0;\treturn sq;&#125;int EmptyQueue(SqQueue *Q)//判断队是否为空&#123;\tif(Q==NULL)\t&#123; printf(&quot;EmptyQueue Error &quot;); return -1;\t&#125;\tif(Q-&gt;rear==Q-&gt;front) return OK;\telse return ERROR;&#125;int FullQueue(SqQueue *Q)//判断队是否已满&#123;\tif(Q==NULL)\t&#123; printf(&quot;EmptyQueue Error &quot;); return -1;\t&#125;\tif((Q-&gt;rear+1)%Q-&gt;maxlen==Q-&gt;front) return OK;\telse return ERROR;&#125;int EnQueue(SqQueue *Q,data_t e)&#123;\tif(FullQueue(Q)==OK)\t&#123; printf(&quot;Queue is Full &quot;); return ERROR;\t&#125;\tQ-&gt;data[Q-&gt;rear]=e;\tQ-&gt;rear=(Q-&gt;rear+1)%Q-&gt;maxlen;\treturn OK;&#125;int DeQueue(SqQueue *Q,data_t *e)&#123;\tif(EmptyQueue(Q)==OK)\t&#123; printf(&quot;Queue is Empty &quot;); return ERROR;\t&#125;\t*e=Q-&gt;data[Q-&gt;front];\tQ-&gt;front=(Q-&gt;front+1)%Q-&gt;maxlen;\treturn OK;&#125;/**************************栈部分**************************/int PushStack(SqStack *s,data_t e)//压栈&#123;\tif(s-&gt;top==s-&gt;maxlen-1)\t&#123; printf(&quot;Stack is Full &quot;); return ERROR;\t&#125;\ts-&gt;top++;\ts-&gt;data[s-&gt;top]=e;\treturn OK;&#125;data_t PopStack(SqStack *s)//弹栈&#123;\tif(s-&gt;top==-1)\t&#123; printf(&quot;Stack is Empty &quot;); return ERROR;\t&#125;\tdata_t e=s-&gt;data[s-&gt;top];\ts-&gt;top--;\treturn e;&#125;SqStack* CreateEmptyStack(int length)//创建栈&#123; SqStack *stack = (SqStack*)malloc(sizeof(SqStack)); if(stack==NULL) &#123; printf(&quot;CreateEmptyStack Error &quot;); exit(0); &#125;\tstack-&gt;data = (data_t*)malloc(sizeof(data_t)*length);\tstack-&gt;maxlen=length; stack-&gt;top=-1; return stack;&#125;int EmptyStack(SqStack *s)//判断栈是否是空栈&#123; return -1==s-&gt;top?OK:ERROR;&#125;int FullStack(SqStack *s)//判断栈是否是满栈&#123; return s-&gt;maxlen-1==s-&gt;top?OK:ERROR;&#125;void ShowTime(SqStack *one_min,SqStack *five_min,SqStack *one_hour)//计算球钟内3个栈的小球所代表的时间并打印&#123;\tint hour,minute;\tminute=(one_min-&gt;top+1)+(five_min-&gt;top+1)*5;\thour=one_hour-&gt;top+1;\tprintf(&quot;time: %d:%d &quot;,hour,minute);&#125;int main()&#123;\tSqStack *one_min = CreateEmptyStack(ONEMIN);//1分钟栈\tSqStack *five_min = CreateEmptyStack(FIVEMIN);//5分钟栈\tSqStack *one_hour = CreateEmptyStack(ONEHOUR);//1小时栈\tSqQueue *ballque = CreateEmptyQueue(BALLQUE);//球队列\tint i;\tdata_t data;\tfor(i=1;i&lt;=ballque-&gt;maxlen-1;i++)\t&#123; EnQueue(ballque,i);\t&#125;\twhile(1)\t&#123; DeQueue(ballque,&amp;data);//出队一个球 PushStack(one_min,data);//压入1分钟栈中 if(FullStack(one_min)==OK)//如果1分钟栈已满 &#123; for(i=0;i&lt;one_min-&gt;maxlen-1;i++)//弹出4个元素到队列中 &#123; EnQueue(ballque,PopStack(one_min)); &#125; PushStack(five_min,PopStack(one_min));//第5个压入5分钟栈 &#125; if(FullStack(five_min)==OK)//如果5分钟栈已满 &#123; for(i=0;i&lt;five_min-&gt;maxlen-1;i++)//弹出11个元素到队列中 &#123; EnQueue(ballque,PopStack(five_min)); &#125; PushStack(one_hour,PopStack(five_min));//第12个元素压入1小时栈 &#125; if(FullStack(one_hour)==OK)//如果1小时栈已满 &#123; for(i=0;i&lt;one_hour-&gt;maxlen;i++)//弹出12个元素到队列中 &#123; EnQueue(ballque,PopStack(one_hour)); &#125; &#125; ShowTime(one_min,five_min,one_hour);//打印时间 sleep(1);//延时1秒\t&#125; return 0;&#125; 两个栈实现队列队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead，分别完成在队列尾部插入元素和在队列头部删除节点的功能。 12345678910111213template &lt;typename T&gt;class CQueue&#123;public: CQueue(void); ~CQueue(void); void appendTail(const T&amp; element); T deleteHead();private: stack&lt;T&gt; stack1; stack&lt;T&gt; stack2;&#125;; 思路：栈是先进后出，而队列是先进先出的，而要用栈实现队列的话，两步操作如下： 进队列：第一个栈 stack1 专门用来压入数据； 出队列：要把队列头部元素输出，而这个头部会在 stack1 中的底部，因此我们需要利用辅助栈 stack2 ，把 stack1 元素依次压入 stack2，这样原来 stack1 中的底部元素变成 stack2 的栈顶，而这就是队列的 head，将之输出即可。 上面分析是针对 stack2 空的情况，若 stack2 非空，则要继续把 stack2 中元素依次 pop 出来。 12345678910111213141516171819202122232425262728//进队列template &lt;typename T&gt; void CQueue&lt;T&gt;::appendTail(const T&amp; element)&#123; stack1.push(element);&#125;//出队列template &lt;typename T&gt; T CQueue&lt;T&gt;::deleteHead()&#123; if (stack2.empty()) &#123; //若stack2是空的，则把stack1的元素copy过来 while (!stack1.empty()) &#123; T&amp; data = stack1.top(); stack1.pop(); stack2.push(data); &#125; &#125; if (stack2.empty()) &#123; throw new exception(&quot;queue is empty&quot;); &#125; //取stack2栈顶元素，即队列的head T head = stack2.top(); stack2.pop(); return head;&#125; 数组实现队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//数组实现队列template &lt;typename T&gt;class CArrayQueue&#123;public: CArrayQueue(void); ~CArrayQueue(void); void appendTail(const T&amp; element); T deleteHead();private: const static int nSize; T Array[10]; int nHead; int nTail;&#125;;template &lt;typename T&gt; const int CArrayQueue&lt;T&gt;:: nSize = 10;template &lt;typename T&gt; CArrayQueue&lt;T&gt;::CArrayQueue(void)&#123; this-&gt;nHead = 0; this-&gt;nTail = -1;&#125;template &lt;typename T&gt; CArrayQueue&lt;T&gt;::~CArrayQueue(void)&#123; this-&gt;nHead = 0; this-&gt;nTail = -1;&#125;//进队列template &lt;typename T&gt; void CArrayQueue&lt;T&gt;::appendTail(const T&amp; element)&#123; if (nTail - nHead &gt;= nSize) &#123; throw new exception(&quot;Queue is full!&quot;); &#125; Array[(++nTail) % nSize] = element; if (nHead / nSize &gt; 0 ) &#123; nTail -= nSize; nHead -= nSize; &#125; &#125;//出队列template &lt;typename T&gt; T CArrayQueue&lt;T&gt;::deleteHead()&#123; T Head = Array[nHead++]; return Head;&#125;","categories":["1.语言","1.数据结构"]},{"title":"线程","path":"/2024/07/16/1-语言-C语言-线程/","content":"传统多任务操作系统中一个可以独立调度的任务（或称之为顺序执行流）是一个进程。每个程序加载到内存后只可以唯一地对应创建一个顺序执行流，即传统意义的进程。 每个进程的全部系统资源是私有的，如虚拟地址空间，文件描述符和信号处理等等。使用多进程实现多任务应用时存在如下问题： 任务切换，即进程间上下文切换，系统开销比较大。（虚拟地址空间以及 task_struct 都需要切换） 多任务之间的协作比较麻烦，涉及进程间通讯。（因为不同的进程工作在不同的地址空间） 所以，为了提高系统的性能，许多操作系统规范里引入了轻量级进程的概念，也被称为线程。 通常线程指的是共享相同地址空间的多个任务。线程最大的特点就是在同一个进程中创建的线程共享该进程的地址空间；但一个线程仍用 task_struct 来描述，线程和进程都参与统一的调度。所以，多线程的好处便体现出来： 大大提高了任务切换的效率；因为各线程共享进程的地址空间，任务切换时只要切换 task_struct 即可； 线程间通信比较方便；因为在同一块地址空间，数据共享； 当然，共享地址空间也会成为线程的缺点，因为共享地址空间，如果其中一个线程出现错误（比如段错误），整个线程组都会崩掉！ Linux 之所以称呼其线程为 LWP( Light Weight Process )，因为从内核实现的角度来说，它并没有为线程单独创建一个结构，而是继承了很多进程的设计： 继承了进程的结构体定义 task_struct ； 没有专门定义线程 ID，复用了 PID； 更没有为线程定义特别的调度算法，而是沿用了原来对 task_struct 的调度算法。 线程已经替代原来的进程称为调度的实际最小单位。 原来的进程概念可以看成是多个线程的容器，称之为线程组；即一个进程就是所有相关的线程构成的一个线程组。传统的进程等价于单线程进程。 每个线程组都有自己的标识符 tgid (数据类型为 pid_t )，其值等于该进程(线程组)中的第一个线程(group_leader)的 PID。 线程创建1234567int pthread_create(pthread_t *thread,const pthread_attr_t *attr,void *(* routine)(void *), void *arg)# 函数参数# thread ：创建的线程ID# attr ：指定线程的属性，NULL表示使用缺省属性# routine ：线程执行的函数# arg ：传递给线程执行的函数的参数 创建成功返回 0，否则返回-1 routine 是回调函数（callback），函数类型由内核来决定，这里将地址传给内核； 函数并不是线程创建了就会执行，而是只有当其被调度到 cpu 上时才会被执行 arg 是线程执行函数的参数，，使用时需要先进行类型转换，才能使用； 如果 arg 参数不止一个，我们可以将其放入到结构体中，传入结构体指针； 线程管理和进程中的 exit() 、wait()一样，这里 pthread_join 与 pthread_exit 是工作在两个线程之中； 1234#以阻塞的方式等待thread指定的线程结束。pthread_join(thread, [线程返回的参数]) pthread_exit([线程返回的参数]) 同步和互斥临界资源：某些资源来说，其在同一时间只能被一段机器指令序列所占用。这些一次只能被一段指令序列所占用的资源就是所谓的临界资源。 临界区：对于临界资源的访问，必须是互斥进行。也就是当临界资源被一个指令序列占用时，另一个需要访问相同临界资源的指令序列就不能被执行。指令序列不能执行的实际意思就是其所在的进程&#x2F;线程会被阻塞。所以我们定义程序内访问临界资源的代码序列被称为临界区。 互斥：是指同事只允许一个访问者对临界资源进行访问，具有唯一性和排它性。但互斥无法限制访问这个对资源的访问顺序，即访问时无序的。 同步：是指在互斥的基础上，通过其他机制实现访问者对资源的有序访问。 线程间互斥引入互斥(mutual exlusion)锁的目的是用来保证共享数据的完整性。 互斥锁主要用来保护临界资源。每个临界资源都有一个互斥锁来保护，任何时刻最多只能有一个线程能访问该资源；线程必须先获得互斥锁才能访问临界资源，访问完资源后释放该锁。如果无法获得锁，线程会阻塞直到获得锁为止； 通常，我们在临界区前上锁，临界区后解锁； 123456//初始化互斥锁int pthread_mutex_init (pthread_mutex_t *mutex, pthread_mutexattr_t *attr )//申请互斥锁int pthread_mutex_lock(pthread_mutex_t *mutex)//释放互斥锁int pthread_mutex_unlock(pthread_mutex_t *mutex) 同步同步(synchronization) 指的是多个任务（线程）按照约定的顺序相互配合完成一件事情；线程间同步——P &#x2F; V 操作 信号量代表某一类资源，其值表示系统中该资源当前可用的数量。信号量是一个受保护的变量，只能通过三种操作来访问： 初始化 12345678//初始化信号量int sem_int (sem_t *sem,int pshared,unsigned int value)函数参数sem：初始化的信号量pshared：信号量共享的范围（0：线程间使用 非0 ：进程间使用）value ：信号量初值函数返回值成功：0出错：-1 P 操作（申请资源）P（S）含义如下： 123456789101112int sem_wait (sem_t *sem) //P 操作函数参数 sem：信号量函数返回值成功：0出错：-1if (信号量的值大于 0)&#123;\t请资源的任务继续运行；\t信号量的值 减一；&#125;else&#123;\t请资源的任务阻塞；&#125; V 操作（释放资源）V（S）含义如下： 1234567891011int sem_post(sem_t *sem) //V 操作函数参数sem：信号量函数返回值成功：0出错：-1if (没有任务在等待该资源)&#123;\t信号量的值 加一；&#125;else&#123;\t唤醒第一个等待的任务，让其继续运行；&#125;","categories":["1.语言","C语言"]},{"title":"Qt线程管理QThread","path":"/2024/07/16/1-语言-Qt-Qt线程管理QThread/","content":"QThread 会通知你触发了一个信号当线程 started()和 finished()时，或者使用 isFinished()和 isRunning()来查询线程的状态。 可以通过调用 exit()或 quit()来停止线程。在极端情况下，你可能要强行 terminate()一个执行线程。但是，这样做是危险的。请阅读文档查看 terminate()和 setTerminationEnabled()的详细信息。 可以通过连接 finished()信号到 QObject::deleteLater()释放运行刚刚结束的线程对象。 使用 wait()来阻塞调用的线程，直到其他线程执行完毕（或者直到指定的时间过去）。 QThread 中还提供了静态的、平台独立的休眠功能：sleep()、msleep()、usleep()允许秒，毫秒和微秒来区分。 注意：一般情况下，wait()和 sleep()函数应该不需要，因为 Qt 是一个事件驱动型框架。而不是 wait()，关心监听信号 finished()。取代 sleep()，可以考虑使用 QTimer。 静态函数 currentThreadId()和 currentThread()返回标识当前正在执行的线程。前者返回该线程的平台特定的 ID，后者返回一个线程指针。 要设置线程的名称，可以在启动线程之前调用 setObjectName()。如果不调用 setObjectName()，线程的名称将是线程对象的运行时类型（上例中“WorkerThread”，因为这是 QThread 子类的类名）。 和界面有关的函数不能通过 QThread 的方式执行 movetothreadWorker 槽中的代码将在一个单独的线程中执行，然而，可以将（来自任何对象、在任何线程中）任何信号与该槽自由地连接，在不同的线程里连接信号和槽也是安全的，这要归功于一个叫排队的连接机制（queued connections）。 123456789101112131415161718192021222324252627282930313233class Worker : public QObject&#123;\tQ_OBJECT\tpublic slots: void doWork(const QString &amp;parameter) &#123; // ... emit resultReady(result); &#125;\tsignals: void resultReady(const QString &amp;result);&#125;;class Controller : public QObject&#123;\tQ_OBJECT\tQThread workerThread;\tpublic: Controller() &#123; Worker *worker = new Worker; worker-&gt;moveToThread(&amp;workerThread); connect(workerThread, &amp;QThread::finished, worker, &amp;QObject::deleteLater); connect(this, &amp;Controller::operate, worker, &amp;Worker::doWork); connect(worker, &amp;Worker::resultReady, this, &amp;Controller::handleResults); workerThread.start(); &#125; ~Controller() &#123; workerThread.quit(); workerThread.wait(); &#125;\tpublic slots: void handleResults(const QString &amp;);\tsignals: void operate(const QString &amp;);&#125;; 实例化 QThread是子类化 QThread 中并重新实现 run 函数，在 run()返回后线程就会退出，在线程中将不会有任何的事件循环运行除非调用 exec()。 当子类化 QThread 时，构造函数在旧线程中执行，然而 run()在新线程中执行。 一个线程实例位于实例化它的旧线程中，而非调用 run()的新线程中，这意味着所有线程的排队槽将在旧线程中执行。因此，开发人员希望在新线程调用槽必须 通过 movetothread 实现，新槽不应直接在子类化 QThread 中来实现。 1234567891011121314151617class WorkerThread : public QThread&#123;\tQ_OBJECT\tvoid run() Q_DECL_OVERRIDE &#123; QString result; emit resultReady(result);\t&#125;\tsignals: void resultReady(const QString &amp;s);&#125;;void MyObject::startWorkInAThread()&#123;\tWorkerThread *workerThread = new WorkerThread(this);\tconnect(workerThread, &amp;WorkerThread::resultReady, this, &amp;MyObject::handleResults);\tconnect(workerThread, &amp;WorkerThread::finished, workerThread, &amp;QObject::deleteLater);\tworkerThread-&gt;start();&#125;","categories":["1.语言","Qt"]},{"title":"照片备份方案","path":"/2024/07/13/0-平台-服务器-照片备份方案/","content":"Alist 网盘+Photoprism 访问方案 域名是 github.io 上部署了博客，博客中增加一个静态页面用于重定位至相册地址 相册地址通过 devtunel 进行内网穿透，devtunl 内网穿透地址 30 天后会发生变化，所以需要在 30 天内执行一次更新静态页面中的 IP 地址 PhotoPrism 配置官方脚本选择下载官方脚本 1234#Linux wget https://dl.photoprism.app/docker/docker-compose.yml#Windowscurl.exe -o docker-compose.yml https://dl.photoprism.app/docker/windows/docker-compose.yml 自定义进行自定义选项，默认需要依赖数据库 可以选择不依赖数据库镜像 自定义访问端口 自定义相册文件映射地址，其中&#x2F;photoprism&#x2F;import 为需要导入的照片地址，&#x2F;photoprism&#x2F;originals 为已经导入的照片地址 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364services: photoprism: image: photoprism/photoprism:latest restart: unless-stopped stop_grace_period: 10s security_opt: - seccomp:unconfined - apparmor:unconfined ports: - &quot;5246:2342&quot; environment: PHOTOPRISM_ADMIN_USER: &quot;username&quot; # admin login username PHOTOPRISM_ADMIN_PASSWORD: &quot;password&quot; # initial admin password (8-72 characters) PHOTOPRISM_AUTH_MODE: &quot;password&quot; # authentication mode (public, password) PHOTOPRISM_SITE_URL: &quot;http://localhost:2342/&quot; # server URL in the format &quot;http(s)://domain.name(:port)/(path)&quot; PHOTOPRISM_DISABLE_TLS: &quot;false&quot; # disables HTTPS/TLS even if the site URL starts with https:// and a certificate is available PHOTOPRISM_DEFAULT_TLS: &quot;true&quot; # defaults to a self-signed HTTPS/TLS certificate if no other certificate is available PHOTOPRISM_ORIGINALS_LIMIT: 5000 # file size limit for originals in MB (increase for high-res video) PHOTOPRISM_HTTP_COMPRESSION: &quot;gzip&quot; # improves transfer speed and bandwidth utilization (none or gzip) PHOTOPRISM_DEBUG: &quot;false&quot; # run in debug mode, shows additional log messages PHOTOPRISM_READONLY: &quot;false&quot; # do not modify originals folder; disables import, upload, and delete PHOTOPRISM_EXPERIMENTAL: &quot;false&quot; # enables experimental features PHOTOPRISM_DISABLE_CHOWN: &quot;false&quot; # disables updating storage permissions via chmod and chown on startup PHOTOPRISM_DISABLE_WEBDAV: &quot;false&quot; # disables built-in WebDAV server PHOTOPRISM_DISABLE_SETTINGS: &quot;false&quot; # disables settings UI and API PHOTOPRISM_DISABLE_TENSORFLOW: &quot;false&quot; # disables all features depending on TensorFlow PHOTOPRISM_DISABLE_FACES: &quot;false&quot; # disables face detection and recognition (requires TensorFlow) PHOTOPRISM_DISABLE_CLASSIFICATION: &quot;false&quot; # disables image classification (requires TensorFlow) PHOTOPRISM_DISABLE_VECTORS: &quot;false&quot; # disables vector graphics support PHOTOPRISM_DISABLE_RAW: &quot;false&quot; # disables indexing and conversion of RAW images PHOTOPRISM_RAW_PRESETS: &quot;false&quot; # enables applying user presets when converting RAW images (reduces performance) PHOTOPRISM_SIDECAR_YAML: &quot;true&quot; # creates YAML sidecar files to back up picture metadata PHOTOPRISM_BACKUP_ALBUMS: &quot;true&quot; # creates YAML files to back up album metadata PHOTOPRISM_BACKUP_DATABASE: &quot;true&quot; # creates regular backups based on the configured schedule PHOTOPRISM_BACKUP_SCHEDULE: &quot;daily&quot; # backup SCHEDULE in cron format (e.g. &quot;0 12 * * *&quot; for daily at noon) or at a random time (daily, weekly) PHOTOPRISM_INDEX_SCHEDULE: &quot;&quot; # indexing SCHEDULE in cron format (e.g. &quot;@every 3h&quot; for every 3 hours; &quot;&quot; to disable) PHOTOPRISM_AUTO_INDEX: 300 # delay before automatically indexing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_AUTO_IMPORT: -1 # delay before automatically importing files in SECONDS when uploading via WebDAV (-1 to disable) PHOTOPRISM_DETECT_NSFW: &quot;false&quot; # automatically flags photos as private that MAY be offensive (requires TensorFlow) PHOTOPRISM_UPLOAD_NSFW: &quot;true&quot; # allows uploads that MAY be offensive (no effect without TensorFlow) PHOTOPRISM_SITE_CAPTION: &quot;AI-Powered Photos App&quot; PHOTOPRISM_SITE_DESCRIPTION: &quot;&quot; # meta site description PHOTOPRISM_SITE_AUTHOR: &quot;&quot; # meta site author ## Video Transcoding (https://docs.photoprism.app/getting-started/advanced/transcoding/): # PHOTOPRISM_FFMPEG_ENCODER: &quot;software&quot; # H.264/AVC encoder (software, intel, nvidia, apple, raspberry, or vaapi) # PHOTOPRISM_FFMPEG_SIZE: &quot;1920&quot; # video size limit in pixels (720-7680) (default: 3840) # PHOTOPRISM_FFMPEG_BITRATE: &quot;32&quot; # video bitrate limit in Mbit/s (default: 50) working_dir: &quot;/photoprism&quot; # do not change or remove ## Storage Folders: use &quot;/&quot; not &quot;\\&quot; as separator, &quot;~&quot; is a shortcut for C:/user/&#123;username&#125;, &quot;.&quot; for the current directory volumes: # &quot;C:/user/username/folder:/photoprism/folder&quot; # example # - &quot;~/Pictures:/photoprism/originals&quot; # original media files (photos and videos) # - &quot;D:/example/family:/photoprism/originals/family&quot; # *additional* media folders can be mounted like this # - &quot;E:/:/photoprism/import&quot; # *optional* base folder from which files can be imported to originals - &quot;E:/01.照片/:/photoprism/import&quot; - &quot;./original/:/photoprism/originals&quot; - &quot;./videos:/photoprism/originals/videos&quot; - &quot;./storage:/photoprism/storage&quot; # *writable* storage folder for cache, database, and sidecar files (never remove)## Create named volumes, advanced users may remove this if they mount a regular host folder## for the database or use SQLite instead (never remove otherwise)volumes: database: driver: local","categories":["0.平台","服务器"]},{"title":"程序加载","path":"/2024/07/12/0-平台-Linux-程序-程序加载/","content":"Linux 中分为用户态和内核态，执行 ELF 文件在用户态的表现就是执行 execve 系统调用，随后陷入内核进行处理。 内核空间内核空间对 execve 的处理其实可以单独用一篇文章去介绍，其中涉及到进程的创建、文件资源的处理以及进程权限的设置等等。我们这里主要关注其中 ELF 处理相关的部分即可，实际上内核可以识别多种类型的可执行文件，ELF 的处理代码主要在 fs&#x2F;binfmt_elf.c 中的 load_elf_binary 函数中。 对于 ELF 而言，Linux 内核所关心的只有 Program Header 部分，甚至大部分情况下只关心三种类型的 Header，即 PT_LOAD、PT_INTERP 和 PT_GNU_STACK。以 3.18 内核为例，load_elf_binary 主要有下面操作: 对 ELF 文件做一些基本检查，保证 e_phentsize &#x3D; sizeof(struct elf_phdr)并且 e_phnum 的个数在一定范围内； 循环查看每一项 program header，如果有 PT_INTERP 则使用 open_exec 加载进来，并替换原程序的 bprm-&gt;buf; 根据 PT_GNU_STACK 段中的 flag 设置栈是否可执行； 使用 flush_old_exec 来更新当前可执行文件的所有引用； 使用 setup_new_exec 设置新的可执行文件在内核中的状态； setup_arg_pages 在栈上设置程序调用参数的内存页； 循环每一项 PT_LOAD 类型的段，elf_map 映射到对应内存页中，初始化 BSS； 如果存在 interpreter，将入口(elf_entry)设置为 interpreter 的函数入口，否则设置为原 ELF 的入口地址； install_exec_creds(bprm)设置进程权限等信息； create_elf_tables 添加需要的信息到程序的栈中，比如 ELF auxiliary vector； 设置 current-&gt;mm 对应的字段； 从内核的处理流程上来看，如果是静态链接的程序，实际上内核返回用户空间执行的就是该程序的入口地址代码；如果是动态链接的程序，内核返回用户空间执行的则是 interpreter 的代码，并由其加载实际的 ELF 程序去执行。 为什么要这么做呢？如果把动态链接相关的代码也放到内核中，就会导致内核执行功能过多，内核的理念一直是能不在内核中执行的就不在内核中处理，以避免出现问题时难以更新而且影响系统整体的稳定性。事实上内核中对 ELF 文件结构的支持是相当有限的，只能读取并理解部分的字段。 用户空间内核返回用户空间后，对于静态链接的程序是直接执行，没什么好说的。而对于动态链接的程序，实际是执行 interpreter 的代码。ELF 的 interpreter 作为一个段，自然是编译链接的时候加进去的，因此和编译使用的工具链有关。对于 Linux 系统而言，使用的一般是 GCC 工具链，而 interpreter 的实现，代码就在 glibc 的 elf&#x2F;rtld.c 中。 interpreter 又称为 dynamic linker，以 glibc2.27 为例，它的大致功能如下: 将实际要执行的 ELF 程序中的内存段加载到当前进程空间中； 将动态库的内存段加载到当前进程空间中； 对 ELF 程序和动态库进行重定向操作(relocation)； 调用动态库的初始化函数(如 .preinit_array, .init, .init_array)； 将控制流传递给目标 ELF 程序，让其看起来自己是直接启动的； 其中参与动态加载和重定向所需要的重要部分就是 Program Header Table 中 PT_DYNAMIC 类型的 Segment。前面我们提到在 Section Header 中也有一部分参与动态链接的 section，即.dynamic。我在自己解析动态链接文件的时候发现，实际上 .dynamic section 中的数据，和 PT_DYNAMIC 中的数据指向的是文件中的同一个地方，即这两个 entry 的 s_offset 和 p_offset 是相同。每个元素的类型如下: 123456789typedef struct&#123; Elf32_Sword\td_tag; /* Dynamic entry type */ union &#123; Elf32_Word d_val; /* Integer value */ Elf32_Addr d_ptr; /* Address value */ &#125; d_un;&#125; Elf32_Dyn; d_tag 表示实际类型，并且 d_un 和 d_tag 相关。同样的，标准中定义了几十个 d_tag 类型，比较常用的几个如下: DT_NULL: 表示 _DYNAMIC 的结尾 DT_NEEDED: d_val 保存了一个到字符串表头的偏移，指定的字符串表示该 ELF 所依赖的动态库名称 DT_STRTAB: d_ptr 指定了地址保存了符号、动态库名称以及其他用到的字符串 DT_STRSZ: 字符串表的大小 DT_SYMTAB: 指定地址保存了符号表 DT_INIT&#x2F;DT_FINI: 指定初始化函数和结束函数的地址 DT_RPATH: 指定动态库搜索目录 DT_SONAME: Shared Object Name，指定当前动态库的名字(logical name) 其中有部分的类型可以和 Section 中的 SHT_xxx 类型进行类比，完整的列表可以参考 ELF 标准中的 Book III: Operating System Specific 一节。 在 interpreter 根据 DT_NEEDED 加载完所有需要的动态库后，就实现了完整进程虚拟内存映像的布局。在寻找某个动态符号时，interpreter 会使用广度优先的方式去进行搜索，即先在当前 ELF 符号表中找，然后再从当前 ELF 的 DT_NEEDED 动态库中找，再然后从动态库中的 DT_NEEDED 里查找。 因为动态库本身是位置无关的(PIE)，支持被加载到内存中的随机位置，因此为了程序中用到的符号可以被正确引用，需要对其进行重定向操作，指向对应符号的真实地址。 Interpreter Hack假设现在面对两种场景: 目标环境的可写磁盘直接 mount 为 noexec，无法执行代码 目标环境内核监控任何非系统路径的程序的执行都会直接告警 运用上面学到的 ELF 知识，利用 interpreter 进行执行。示例如下: 123456789101112131415$ cat hello.c#include &lt;stdio.h&gt;int main() &#123;\treturn puts(&quot;hello!&quot;);&#125;$ gcc hello.c -o hello$ ./hellohello!$ chmod -x hello$ ./hellobash: ./hello: Permission denied$ /lib64/ld-linux-x86-64.so.2 ./hellohello!$ strace /lib64/ld-linux-x86-64.so.2 ./hello 2&gt;&amp;1 | grep execexecve(&quot;/lib64/ld-linux-x86-64.so.2&quot;, [&quot;/lib64/ld-linux-x86-64.so.2&quot;, &quot;./hello&quot;], 0x7fff1206f208 /* 9 vars */) = 0 /lib64/ld-linux-x86-64.so.2 本身应该是内核调用执行的，但我们这里可以直接进行调用。这样一方面可以在没有执行权限的情况下执行任意代码，另一方面也可以在一定程度上避免内核对 execve 的异常监控。 利用(滥用)interpreter 我们还可以做其他有趣的事情，比如通过修改指定 ELF 文件的 interpreter 为我们自己的可执行文件，可让内核在处理目标 ELF 时将控制器交给我们的 interpreter，这可以通过直接修改字符串表或者使用一些工具如 patchelf 来轻松实现。 对于恶意软件分析的场景，很多安全研究人员看到 ELF 就喜欢用 ldd 去看看有什么依赖库，一般 ldd 脚本实际上是调用系统默认的 ld.so 并通过环境变量来打印信息，不过对于某些 glibc 实现(如 glibc2.27 之前的 ld.so)，会调用 ELF 指定的 interpreter 运行，从而存在非预期命令执行的风险。 加固&#x2F;脱壳与逆向分析比较相关的就是符号表，一个有符号的程序在逆向时基本上和读源码差不多。因此对于想保护应用程序的开发者而言，最简单的防护方法就是去除符号表，一个简单的 strip 命令就可实现。strip 删除的主要是 Section 中的信息，因为这不影响程序的执行。去除前后进行 diff 对比可看到删除的 section 主要有下面这些: 123456789101112131415161718$ diff 0 11c1&lt; There are 35 section headers, starting at offset 0x1fdc:---&gt; There are 28 section headers, starting at offset 0x1144:32,39c32&lt; [27] .debug_aranges PROGBITS 00000000 00104d 000020 00 0 0 1&lt; [28] .debug_info PROGBITS 00000000 00106d 000350 00 0 0 1&lt; [29] .debug_abbrev PROGBITS 00000000 0013bd 000100 00 0 0 1&lt; [30] .debug_line PROGBITS 00000000 0014bd 0000cd 00 0 0 1&lt; [31] .debug_str PROGBITS 00000000 00158a 000293 01 MS 0 0 1&lt; [32] .symtab SYMTAB 00000000 001820 000480 10 33 49 4&lt; [33] .strtab STRTAB 00000000 001ca0 0001f4 00 0 0 1&lt; [34] .shstrtab STRTAB 00000000 001e94 000145 00 0 0 1---&gt; [27] .shstrtab STRTAB 00000000 00104d 0000f5 00 0 0 1 其中 .symtab 是符号表，.strtab 是符号表中用到的字符串。 仅仅去掉符号感觉还不够，熟悉汇编的人放到反编译工具中还是可以慢慢还原程序逻辑。通过前面的分析我们知道，ELF 执行需要的只是 Program Header 中的几个段，Section Header 实际上是不需要的，只不过在运行时动态链接过程会引用到部分关联的区域。大部分反编译工具，如 IDA、Ghidra 等，处理 ELF 是需要某些 section 信息来构建程序视图的，所以我们可以通过构造一个损坏 Section Table 或者 ELF Header 令这些反编译工具出错，从而干扰逆向人员。 当然，这个方法并不总是奏效，逆向人员可以通过动态调试把程序 dump 出来并对运行视图进行还原。一个典型的例子是 Android 中的 JNI 动态库，有的安全人员对这些 so 文件进行了加密处理，并且在.init&#x2F;.initarray 这些动态库初始化函数中进行动态解密。破解这种加固方法的策略就是将其从内存中复制出来并进行重建，重建的过程可根据 segment 对 section 进行还原，因为 segment 和 section 之间共享了许多内存空间，例如: 12345678910111213$ readelf -l main1... Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .plt.got .text .fini .rodata .eh_frame_hdr .eh_frame 03 .init_array .fini_array .dynamic .got .got.plt .data .bss 04 .dynamic 05 .note.ABI-tag .note.gnu.build-id 06 .eh_frame_hdr 07 08 .init_array .fini_array .dynamic .got 在 Section to Segment mapping 中可以看到这些段的内容是跟对应 section 的内容重叠的，一个 segment 可以包含多个 section，但是依然可以根据内存的读写属性、内存特征以及对应段的一般顺序进行区分。 如果程序中有比较详细的日志函数，我们还可以通过反编译工具的脚本拓展去修改.symtab&#x2F;.strtab 段来批量还原 ELF 文件的符号，从而高效地辅助动态调试。 Binary Fuzzing考虑这么一种场景，我们在分析某个 IoT 设备时发现了一个定制的 ELF 网络程序，类似于 httpd，其中有个静态函数负责处理输入数据。现在想要单独对这个函数进行 fuzz 应该怎么做？直接从网络请求中进行变异是一种方法，但是网络请求的效率太低，而且触达该函数的程序逻辑也可能太长。 既然我们已经了解了 ELF，那就可以有更好的办法将该函数抽取出来进行独立调用。在介绍 ELF 类型的时候其实有提到，可执行文件可以有两种类型，即可执行类型(ET_EXEC)和共享对象(ET_DYN)，一个动态链接的可执行程序默认是共享对象类型的: 123$ gcc hello.c -o hello$ readelf -h hello | grep Type Type: DYN (Shared object file) 而动态库(.so)本身也是共享对象类型，他们之间的本质区别在于前者链接了 libc 并且定义了 main 函数。对于动态库，我们可以通过 dlopen&#x2F;dlsym 获取对应的符号进行调用，因此对于上面的场景，一个解决方式就是修改目标 ELF 文件，并且将对应的静态函数导出添加到 dynamic section 中，并修复对应的 ELF 头。 这个思想其实很早就已经有人实现了，比如 lief 的 bin2lib。通过该方法，我们就能将目标程序任意的函数抽取出来执行，比如 hugsy 就用这个方式复现了 Exim 中的溢出漏洞(CVE-2018-6789)。","categories":["0.平台","Linux","程序"]},{"title":"加密方式介绍","path":"/2024/07/12/0-平台-Linux-加密-加密方式介绍/","content":"加密技术通常分为两大类“对称式”和“非对称式”","categories":["0.平台","Linux","加密"]},{"title":"基于Qt的RSS阅读器开发","path":"/2024/07/12/3-软件-0-项目-基于Qt的RSS阅读器开发/","content":"什么是 RSSRSS 语法 channel 元素 描述 &lt;category&gt; 可选的。为 feed 定义所属的一个或多个种类。 &lt;cloud&gt; 可选的。注册进程，以获得 feed 更新的立即通知。 &lt;copyright&gt; 可选。告知版权资料。 &lt;description&gt; 必需的。描述频道。 &lt;docs&gt; 可选的。规定指向当前 RSS 文件所用格式说明的 URL。 &lt;generator&gt; 可选的。规定用于生成 feed 的程序。 &lt;image&gt; 可选的。在聚合器呈现某个 feed 时，显示一个图像。 &lt;language&gt; 可选的。规定编写 feed 所用的语言。 &lt;lastBuildDate&gt; 可选的。定义 feed 内容的最后修改日期。 &lt;link&gt; 必需的。定义指向频道的超链接。 &lt;managingEditor&gt; 可选的。定义 feed 内容编辑的电子邮件地址。 &lt;pubDate&gt; 可选的。为 feed 的内容定义最后发布日期。 &lt;rating&gt; 可选的。feed 的 PICS 级别。 &lt;skipDays&gt; 可选的。规定忽略 feed 更新的天。 &lt;skipHours&gt; 可选的。规定忽略 feed 更新的小时。 &lt;textInput&gt; 可选的。规定应当与 feed 一同显示的文本输入域。 &lt;title&gt; 必需的。定义频道的标题。 &lt;ttl&gt; 可选的。指定从 feed 源更新此 feed 之前，feed 可被缓存的分钟数。 &lt;webMaster&gt; 可选的。定义此 feed 的 web 管理员的电子邮件地址。 item 元素 描述 &lt;author&gt; 可选的。规定项目作者的电子邮件地址。 &lt;category&gt; 可选的。定义项目所属的一个或多个类别。 &lt;comments&gt; 可选的。允许项目连接到有关此项目的注释（文件）。 &lt;description&gt; 必需的。描述此项目。 &lt;enclosure&gt; 可选的。允许将一个媒体文件导入一个项中。 &lt;guid&gt; 可选的。为项目定义一个唯一的标识符。 &lt;link&gt; 必需的。定义指向此项目的超链接。 &lt;pubDate&gt; 可选的。定义此项目的最后发布日期。 &lt;source&gt; 可选的。为此项目指定一个第三方来源。 &lt;title&gt; 必需的。定义此项目的标题。 RSS 阅读器功能文字**字体** **字号** **背景** **翻页** 图片**缩放** **移动** **下载** 视频**播放/暂停** **快进** **进度条** **音量** **下载** 设置**订阅** **自动/手动同步** 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式eg. https://rsshub.app/6v123/latestMovies &#x3D;&#x3D;&#x3D;&gt;&#96;6v123_latestMovies eg. https://rsshub.app/t66y/20/2 &#x3D;&#x3D;&#x3D;&gt;&#96;t66y_20_2 页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["3.软件","0.项目"]},{"title":"进程脱离终端后台运行","path":"/2024/07/12/0-平台-Linux-其他-进程脱离终端后台运行/","content":"运行一个连接到控制终端的进程，作为用户你将会在你的终端上看到这个进程数据的许多行的输出，也包含错误信息。同样，当你关闭一个控制终端，你的进程和子进程都将会终止。为了解决上面两个问题，你需要从一个控制终端完全脱离一个进程。 如何在后台运行一个进程如果一个进程已经运行，按下 Ctrl+Z 就可以暂停它，然后输入命令 bg 就可以继续以一个任务在后台运行了。但是，标准输入（STDIN）、标准输出（STDOUT）和标准错误（STDERR）依旧掺杂到控制台中。你可以通过输入 jobs 查看所有的后台任务。 123$ tar -czf home.tar.gz .$ bg$ jobs 也可以直接使用符号 &amp; 在后台运行一个进程： 12$ tar-czf home.tar.gz . &amp;$ jobs 虽然是作为一个后台任务开始的，但是错误信息依旧发送到终端，这表示，进程依旧和控制终端关联在一起。 disown我们将使用 disown 命令，它在一个进程已经运行并且被放在后台之后使用，它的作用是从 shell 的活动任务列表中移走一个 shell 任务，因此，对于该任务，你将再也不能使用 fg 、 bg 命令了。而且，当你关闭控制控制终端，这个任务将不会挂起（暂停）或者向任何一个子任务发送 SIGHUP 信号。 1234$ sudo rsync Templates/* /var/www/html/files/ &amp;$ jobs$ disown -h %1$ jobs nohup你也可以使用 nohup 命令，这个命令也可以在用户退出 shell 之后保证进程在后台继续运行。 123$ nohup tar -czf iso.tar.gz Templates/* &amp;$ jobs &#x2F;dev&#x2F;null对于图形用户界面 (GUI) 的程序例如 firefox 来说，使用下面的命令行格式会更有效： 1$ firefox /dev/null &amp; 在 Linux 上，&#x2F;dev&#x2F;null 是一个特殊的文件设备，它会忽略所有的写在它上面的数据，上述命令，输入来源和输出发送目标都是 &#x2F;dev&#x2F;null。","categories":["0.平台","Linux","其他"]},{"title":"自动挂载U盘","path":"/2024/07/12/2-通讯协议-USB-自动挂载U盘/","content":"某些场景下，服务器可能没有必要的键盘等输入设备、屏幕等输出设备。此时需要在没有人为干预的情况下实现当插入 U 盘或者硬盘后自动挂载，并执行某些脚本动作。 必要组件udev,udisks busybox (需要用到 blkid)可以直接获取到设备的卷标，这样就可以指定挂载路径名称了。 实现规则编写编写 udev 规则实现 U 盘插入时候的动作。规则文件写在&#x2F;etc&#x2F;udev&#x2F;rules.d 下。 如上， 通过规则定义 U 盘插入与拔出的动作即可，动作的具体实现可以在规则中编写，也可以通过指定执行脚本来实现。本文的规则中仅指定执行脚本。 规则如下： 1ENV&#123;DEVTYPE&#125;=&quot;partition&quot;,RUN+=&quot;/lib/udev/automount.sh&quot;,ENV&#123;REMOVE_CMD&#125;=&quot;/lib/udev/autounmount.sh&quot; 脚本编写将脚本文件写在 /lib/udev 下，根据上文规则，应该分别实现插入的动作脚本和拔出的动作脚本。 插入动作脚本主要在于需要获取到设备的卷标，来确定挂载的路径(即$ID_FS_LABEL) 123456789101112#!/bin/shmount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$&#123;DEVNAME##*/&#125;fiif [ -n $mount_point ];thenmkdir -p /media/$mount_pointmount -t $ID_FS_TYPE -o gid=100,dmask=000,fmask=111,utf8,flush,rw,noatime,users$DEVNAME /media/$mount_pointfi 拔出动作脚本在 U 盘拔出时候，及时删掉挂载的路径 123456789mount_point=$ID_FS_LABELif [ -z $mount_point ];thenmount_point=$&#123;DEVNAME##*/&#125;fiif [ -n $mount_point ];thenumount -l /media/$mount_point rm -r /media/$mount_pointfi 自动执行动作脚本这样，当 U 盘插入时，&#x2F;media&#x2F; 下就会出现于卷标相同的文件夹，并挂载上了 U 盘。因此，需要实现 U 盘插入自动执行的话，通过轮询探测&#x2F;media&#x2F; 下相应目录是否存在即可。如: 1234567891011121314UDISK=$1# ---------------main control area ---------------while (true)do\t# probe mounted disk\tif [ -e&quot;$UDISK&quot; ];\tthen echo&quot;Mounted device [$UDISK] found !&quot;\telse echo&quot;Device not found [$UDISK] !&quot;\tfi\techo&quot;Sleep for sometime...&quot;\tsleep 3sdone 需要注意的问题新版本的 udev 可能会遇到 mount 失效的问题，通过查询资料可知，udev 的 rules 运行于独立的文件空间上，与用户的文件空间不同，因此及时挂载上了，用户也无法访问。因此需要将 udev 的运行方式改为共享。 修改方式如下： 拷贝一份 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;systemd-udevd.service 到 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F; （推荐） 编辑&#x2F;etc&#x2F;systemd&#x2F;system&#x2F; 将 MountFlags 改为 shared 重启即可。","categories":["2.通讯协议","USB"]},{"title":"USB的权限设置最高","path":"/2024/07/12/2-通讯协议-USB-USB的权限设置最高/","content":"使用 lsusb -vvv 命令找出 USB 设备的 vendorID 和 productID 创建一个新的 udev 规则红色框中的为新建的 udev 规则 新建文件内容： 123$ sudo vi/etc/udev/rules.d/50-myusb.rulesSUBSYSTEMS==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;067b&quot;, ATTRS&#123;idProduct&#125;==&quot;2303&quot;, GROUP=&quot;users&quot;, MODE=&quot;0666&quot; 用你自己的”idVendor”和”idProduct”来替换。MODE&#x3D;”0666”表示 USB 设备的权限。建立新文件内容 建立好文件之后重启即可","categories":["2.通讯协议","USB"]},{"title":"USB设备节点名不固定","path":"/2024/07/12/2-通讯协议-USB-USB设备节点名不固定/","content":"Linux 下 USB 设备节点名不固定以 USB 转串口设备为例，通常设备节点名为 ttyUSBx（x 为 0~n）,Linux 内核会根据设备插入的先后顺序进行编号的分配，比如第一个插入的设备编号为 ttyUSB0，然后依此加 1，变为 ttyUSB1，ttyUSB2…… 如果仅仅以设备节点 ttyUSBx 来区别具体是哪个设备，因为末位的编号是随时会变的，所以就会造成混乱。无法保证 A 设备就是 ttyUSB0，B 设备就是 ttyUSB1。在设备文件&#x2F;dev 目录下并没有提供固定显示 ttyUSB 的方法，但是，其实，每个 USB 端口都有唯一的端口号，相当于每个门店的门牌号。只要我们依据端口号来进行设备的区分，那么问题就迎刃而解了。简单点来说就是找到端口号，然后根据端口号找到挂载在这个端口号上面的 USB 设备是 ttyUSB0 还是 ttyUSB1….(这个是变化的，前面讲到了)。 关于端口号的查看方法连接好两个 USB 转串口设备之后: 12345ls -l/sys/class/tty/ttyUSB*lrwxrwxrwx root root 2017-08-0113:40 ttyUSB0 -&gt;../../devices/ff540000.usb/usb3/3-1/3-1.1/3-1.1:1.0/ttyUSB0/tty/ttyUSB0lrwxrwxrwx root root 2017-08-0113:43 ttyUSB1 -&gt;../../devices/ff540000.usb/usb3/3-1/3-1.2/3-1.2:1.0/ttyUSB1/tty/ttyUSB1 其中 ttyUSB0 所在的端口号为 3-1.1，而 ttyUSB1 所在的端口号为 3-1.2，可以看出，这里的 3-1.1 端口上比 3-1.2 上提前插上 USB 设备，所以会以这种方式命名。如果插入设备的顺序相反，那么端口号 3-1.1 上对应的设备应该是 ttyUSB1，而 3-1.2 上对应的设备应该是 ttyUSB0。但是如果在实际过程中我们只需要采集端口 3-1.1 传来的数据，我们该如何通过 ttyUSBx 不定的设备节点，获取到固定端口的数据呢？ 实际工程中，碰到的一个问题是：硬件上连接有两个 USB 转串口设备，硬件只要一上电，两个 USB 设备几乎是同时上电的，这将导致 ttyUSB0 或者 ttyUSB1 无法每次固定的对应到上一次的那个相同端口，上层软件需要通过串口设备节点&#x2F;dev&#x2F;ttyUSBx 来打开一个串口，并从串口获取数据，但是这个 ttyUSBx 设备并不是一直都指向固定的一个 usb 端口号，这直接导致我们无法往下操作了。 这里使用 bash 语言加 Python 正则表达式的相关知识解决这个问题： 第一次上电的时候，我们需要确定哪个端口上的数据是我们所需要的：ls -l/sys/class/tty/ttyUSB* 假设是 3-1.1 这个端口是我们的 data 端口。 以后每次上电，我们要找到 3-1.1 这个端口后面挂载的 ttyUSB 设备是 ttyUSB0 还是 ttyUSB1，并建立一个软链接将当时获取到的 ttyUSBx 生成一个软链接，名字固定为 ttydata,那么以后每次打开&#x2F;dev&#x2F;ttydata 就能找到正确 3-1.1 这个端口，并获取数据了。 建立一个文件夹 getUSB，该文件夹下面包含： cmd.sh 是利用 bash 脚本获取 /sys/class/tty/ttyUSB* 的一些信息保存在 device_usb.txt 中 getUSB.py 是通过 device_usb.txt 中的信息，获取到当前挂着在端口 3-1.1 上的是 ttyUSB0 还是 ttyUSB1 并保存在 usbdev 中 cmd.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#!/bin/bashdeclare -i a=0declare -i b=0#等待一段时间没有检测ttyUSB0设备到会自动跳出whilewhile [[ ! -e &quot;/sys/class/tty/ttyUSB0&quot; ]]do\tsudo sleep 0.01s\ta=a+1\tif [ $a -eq 300 ];then break\tfidone#if USB0been detected ,also get out of whilewhile [[ ! -e &quot;/sys/class/tty/ttyUSB1&quot; ]]do\tsudo sleep 0.01s\tb=b+1\tif [[ $b -eq 300||$a -ne 0 ]];then break\tfidone#如果不存在ttyUSB设备#如果完美检测到了两个ttyUSB设备，则将信息log到device_usb.txt当中if [[ ! -e /sys/class/tty/ttyUSB0&amp;&amp;! -e/sys/class/tty/ttyUSB1 ]]; then echo &quot;Not have ttyUSB0 or not have ttyUSB1&quot;else tty1=$(ls -l /sys/class/tty/ttyUSB0)\ttty2=$(ls -l /sys/class/tty/ttyUSB1)\tsudo ls -l /sys/class/tty/ttyUSB0 /sys/class/tty/ttyUSB1 &gt;./device_usb.txtfi#非空检测if [ ! -n &quot;$tty1&quot; ] ;then # &quot;! -n&quot; showsblank var echo &quot;tty1 is empty&quot;fi#delay 0.01s to make sure the device_usb.txt completesudo sleep 0.01s#remove the old USB device shortcutif [ ! -e &quot;/dev/ttydata&quot; ] ;then # 如果/dev/ttydata本身不存在\techo &quot;-------------/dev/ttydata not found&quot;else #如果存在，则需删除之，然后重新创建之\techo &quot;/dev/ttydata is exist&quot;\tsudo rm /dev/ttydatafi#exct Python language to get the rignt USB interface#调用当前路径下的getUSB.py这个Python语言，明确此次是哪个,ttyUSB0,或者ttyUSB1挂载在端口3-1.1上./getUSB.py #获取到这个设备usbdev=$(cat ./usbdev) echo &quot;the device is : &quot;echo $usbdev#将这个设备软连接到/dev/ttydata以后每次打开这个ttydata即可sudo ln -s /dev/$usbdev /dev/ttydata getUSB.py12345678910111213141516171819202122#!/usr/bin/python#coding:utf-8import re #正则表达式sss = open(&quot;./device_usb.txt&quot;,&quot;rb&quot;)#打开 device_usb.txt 设备，并读取内容www = open(&quot;./usbdev&quot;,&quot;wb&quot;) #当前路径下创建usbdev文件，后续会写入内容s_read = sss.read() usb3/3-1/3-1.1/r = r&quot;usb3/3-1/3-1\\.1.+(ttyUSB[0-9])&quot;#正则中“.”需要转义，所以使用“\\.”表示“.”#这个规则是找到usb3/3-1/3-1.1/这个字符串后面紧跟的是此次上电生成的 ttyUSB0 或者ttyUSB1output = re.findall(r,s_read)www.write(output[0]) #将结果写到usbdev中www.close()sss.close() 完成之后设置开机项目，将文件夹当道一个位置，然后设置开机启动 cmd.sh（在&#x2F;etc&#x2F;rc.local 中设置）则每次开机之后，会从&#x2F;dev&#x2F;ttydata 获取到固定端口的数据","categories":["2.通讯协议","USB"]},{"title":"Perplexity生产的文案","path":"/2024/07/12/3-软件-AI-Perplexity生产的文案/","content":"上篇：心即理（约 800 字） 嘿，你是不是经常觉得生活很复杂？工作压力大，人际关系难处理，还要面对各种选择和困惑？别担心，500 年前的王阳明就给我们留下了”心学”，这个古老的智慧宝库可能正是你需要的！ 想象一下，你正站在人生的十字路口。左边是你的理想，右边是现实的压力。你该怎么选？王阳明会告诉你：答案就在你心里！ 没错，”心即理”——你内心的声音就是最好的指引。那个让你热血沸腾的梦想？追随它！因为你的心已经告诉你答案了。 但是，什么是”心即理”呢？简单来说，就是宇宙的真理、人生的道理都存在于我们的内心。我们不需要到外面去寻找答案，因为答案一直都在我们心里。 想想看，当你遇到困难时，是不是常常向外求助？找朋友倾诉，上网搜索解决方法，甚至求助于算命先生？其实，王阳明告诉我们，最了解你的人就是你自己。 当你纠结是否要换工作时，仔细聆听内心的声音。是继续安稳但没有激情的工作，还是追随内心的热爱？你的心知道答案。 当你在人际关系中感到困扰时，问问自己的内心。是否真的需要讨好每个人？还是应该保持真实的自我？你的心会给你指引。 王阳明教导我们，要学会静心。在这个喧嚣的世界里，我们常常被外界的声音淹没。但只有在安静中，我们才能听到内心最真实的声音。 试着每天花几分钟，静下心来。关掉手机，远离噪音，就这样静静地坐着。你会惊讶地发现，内心的声音变得如此清晰。 生活中遇到难题？问问你的心。 不知道该不该坚持？听听你的内心声音。 面对重大决定无所适从？相信你的直觉。 记住，你的内心比你想象的要强大得多。相信它，你会发现生活其实很简单。因为当你学会信任自己的内心时，外界的纷扰就不再那么重要了。 “心即理”不是逃避现实，而是找到面对现实的力量。它教我们，无论外界如何变化，我们内心的指引才是最可靠的。所以，下次当你感到迷茫时，别忘了停下来，聆听你内心的声音。因为答案，一直都在那里。 中篇：知行合一（约 800 字） 我们刚刚学会了如何聆听内心的声音，但是光有想法还不够。王阳明的第二个智慧告诉我们：知行合一。这是什么意思呢？简单来说，就是知道和做到必须结合在一起。 想想看，我们生活中有多少事情是知道该做，却没有去做的？ 知道要健身有什么用？穿上运动鞋出门才是真的！ 明白要孝顺父母有什么用？打个电话问候才是真的！ 懂得要学习新技能有什么用？实际去报名课程才是真的！ 知识和行动就像一枚硬币的两面，缺一不可。所以，别再找借口了，行动起来！ 也许你会说：”我知道该做什么，但就是做不到。”这正是王阳明要告诉我们的：真正的”知”，必然会导致”行”。如果你没有行动，说明你还没有真正理解。 举个例子，你知道熬夜对身体不好，但还是经常熬夜。为什么？因为你还没有真正理解熬夜的危害。当你真正明白了，行动自然就会跟上。 知行合一不是一蹴而就的。它需要我们不断练习，不断尝试。每一次行动，都是一次学习的机会。每一次尝试，都让你离目标更近一步。 害怕失败？记住，行动才是最好的老师。即使失败了，你也会获得宝贵的经验。这些经验会让你下一次做得更好。 知行合一并不意味着你要一下子完成所有事情。从小事做起，慢慢积累。今天多走 1000 步，明天早起半小时，后天给父母打个电话。这些小小的行动，会逐渐改变你的生活。 在工作中，知行合一同样重要。不要只是坐在办公室里想点子，去实践它！不要只是抱怨工作环境，主动提出改进建议并付诸行动！ 记住，知识不等于能力，想法不等于成果。只有当你把知识转化为行动，把想法变成现实，你才能真正成长和进步。 所以，从现在开始，不要只是坐着想，站起来做！这才是真正的知行合一。 每当你有了新的想法，问问自己：我该如何把它变成行动？ 每当你学到新知识，思考一下：我要如何在生活中应用它？ 知行合一不仅是一种学习方法，更是一种生活态度。它教导我们，生活的真谛不在于知道多少，而在于做了多少。 所以，别再等待了。无论你心中有什么想法，现在就采取行动吧！因为只有行动，才能让你的人生 truly（真正地）与众不同。 下篇：致良知（约 800 字） 现在，我们来到王阳明心学的最核心概念：致良知。这听起来可能有点深奥，但其实它比你想象的要简单得多。 闭上眼睛，深呼吸。感受到了吗？那个总是告诉你该做什么、不该做什么的声音？那就是王阳明所说的”良知”。每个人都有，关键是要听从它、相信它、实践它。 良知，简单来说就是我们内心与生俱来的道德判断能力。它告诉我们什么是对的，什么是错的。当你看到有人需要帮助时，那个促使你伸出援手的冲动，就是良知在起作用。 但在现实生活中，我们常常忽视这个声音。为什么？因为现实世界太复杂，我们被各种外在的声音干扰了。 想象一下，你在工作中发现了一个可以让公司赚大钱的机会，但这个机会可能会伤害到一些人。你的良知告诉你这是不对的，但现实的压力又让你犹豫不决。这时候，”致良知”就显得尤为重要。 致良知，就是要我们始终保持对内心良知的关注和实践。它不是要我们逃避现实，而是要在复杂的现实中坚持做正确的事。 在生活中践行良知并不总是容易的。它可能意味着你要放弃一些眼前的利益，可能会让你显得”不合群”，甚至可能会给你带来一些麻烦。但是，当你坚持按照良知行事时，你会发现内心的平静和满足感是无可比拟的。 致良知不是一蹴而就的。它需要我们不断练习，不断提醒自己。每当你面临选择时，试着问问自己：这个决定符合我的良知吗？如果我的孩子这样做，我会赞同吗？ 致良知并不仅仅体现在重大决策上，它更多地体现在日常生活的点点滴滴中。帮助需要帮助的人，诚实待人，尊重他人，保护环境…这些看似微小的行为，都是在践行良知。 当你面对选择时，静下心来，倾听你的良知。 当你感到迷茫时，回归内心，你的良知会给你答案。 当你面临压力时，坚持你的良知，它会给你力量。 良知就像内心的指南针，永远指向正确的方向。相信它，你就能在纷繁复杂的世界中找到属于自己的路。 致良知不仅是一种哲学思想，更是一种生活态度。它教导我们，无论外界如何变化，只要我们始终坚持内心的良知，就能保持内心的平静和生活的方向。 所以，从今天开始，试着更多地聆听你内心的声音，更勇敢地按照良知行事。你会发现，这不仅能让你成为一个更好的人，还能让这个世界变得更美好。","categories":["3.软件","AI"]},{"title":"RK3568系统移植分析","path":"/2024/07/12/0-平台-嵌入式-RK3568系统移植分析/","content":"写入硬件时间 hwclock-uw.txt 3568 的内核配置文件路径 1234编译配置文件：device/rockchip/common/build.sh板级配置文件：device/rockchip/ok3568/BoardConfig-ok3568.mkbuildroot 配置文件：buildroot/configs/OK3568_defconfiguboot 配置文件：u-boot/configs/OK3568-C_defconfig","categories":["0.平台","嵌入式"]},{"title":"实时操作系统和分时操作系统","path":"/2024/07/12/0-平台-嵌入式-实时操作系统和分时操作系统/","content":"实时操作系统（RTOS）RTOS，英文全称 Real Time Operating System，即实时操作系统。 实时操作系统定义实时操作系统（RTOS）是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统作出快速响应，并控制所有实时任务协调一致运行的操作系统。 因而，提供及时响应和高可靠性是其主要特点。 实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的。 软实时则只要按照任务的优先级，尽可能快地完成操作即可。我们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。 实时操作系统是保证在一定时间限制内完成特定功能的操作系统。例如，可以为确保生产线上的机器人能获取某个物体而设计一个操作系统。在“硬”实时操作系统中，如果不能在允许时间内完成使物体可达的计算，操作系统将因错误结束。 在“软”实时操作系统中，生产线仍然能继续工作，但产品的输出会因产品不能在允许时间内到达而减慢，这使机器人有短暂的不生产现象。一些实时操作系统是为特定的应用设计的，另一些是通用的。 一些通用目的的操作系统称自己为实时操作系统。但某种程度上，大部分通用目的的操作系统，如微软的 Windows NT 或 IBM 的 OS&#x2F;390 有实时系统的特征。这就是说，即使一个操作系统不是严格的实时系统，它们也能解决一部分实时应用问题。 实时操作系统的特征 多任务 有线程优先级 多种中断级别 小的嵌入式操作系统经常需要实时操作系统，内核要满足实时操作系统的要求。 实时操作系统的相关概念基本概念 代码临界段：指处理时不可分割的代码。一旦这部分代码开始执行则不允许中断打入； 资源：任何为任务所占用的实体； 共享资源：可以被一个以上任务使用的资源； 任务：也称作一个线程，是一个简单的程序。每个任务被赋予一定的优先级，有它自己的一套 CPU 寄存器和自己的栈空间。典型地，每个任务都是一个无限的循环，每个任务都处在以下五个状态下：休眠态，就绪态，运行态，挂起态，被中断态； 任务切换：将正在运行任务的当前状态（CPU 寄存器中的全部内容）保存在任务自己的栈区，然后把下一个将要运行的任务的当前状态从该任务的栈中重新装入 CPU 的寄存器，并开始下一个任务的运行； 内核：负责管理各个任务，为每个任务分配 CPU 时间，并负责任务之间通讯。分为不可剥夺型内核于可剥夺型内核； 调度：内核的主要职责之一，决定轮到哪个任务运行。一般基于优先级调度法； 关于优先级的问题任务优先级：分为优先级不可改变的静态优先级和优先级可改变的动态优先级； 优先级反转：优先级反转问题是实时系统中出现最多的问题。共享资源的分配可导致优先级低的任务先运行，优先级高的任务后运行。解决的办法是使用“优先级继承”算法来临时改变任务优先级，以遏制优先级反转。 互斥虽然共享数据区简化了任务之间的信息交换，但是必须保证每个任务在处理共享共享数据时的排他性。使之满足互斥条件的一般方法有：关中断，使用测试并置位指令（TAS），禁止做任务切换，利用信号量。 因为采用实时操作系统的意义就在于能够及时处理各种突发的事件，即处理各种中断，因而衡量嵌入式实时操作系统的最主要、最具有代表性的性能指标参数无疑应该是中断响应时间了。中断响应时间通常被定义为： 中断响应时间&#x3D;中断延迟时间+保存 CPU 状态的时间+该内核的 ISR 进入函数的执行时间。 中断延迟时间&#x3D;MAX(关中断的最长时间，最长指令时间) + 开始执行 ISR 的第一条指令的时间。 分时操作系统（TSOS）TSOS，英文全称 Time-sharing Operating System，即分时操作系统。 使一台计算机同时为几个、几十个甚至几百个用户服务的一种操作系统叫分时操作系统。把计算机与许多终端用户连接起来，分时操作系统将系统处理机时间与内存空间按一定的时间间隔，轮流地切换给各终端用户的程序使用。 由于时间间隔很短，每个用户的感觉就像他独占计算机一样。分时操作系统的特点是可有效增加资源的使用率。例如 UNIX 系统就采用剥夺式动态优先的 CPU 调度，有力地支持分时操作。 产生分时系统是为了满足用户需求所形成的一种新型 OS 。它与多道批处理系统之间，有着截然不同的性能差别。用户的需求具体表现在以下几个方面: 人—机交互 共享主机 便于用户上机 分时系统的基本思想时间片：是把计算机的系统资源（尤其是 CPU 时间）进行时间上的分割，每个时间段称为一个时间片，每个用户依次轮流使用时间片。 分时技术：把处理机的运行时间分为很短的时间片，按时间片轮流把处理机分给各联机作业使用。 分时操作系统：是一种联机的多用户交互式的操作系统。一般采用时间片轮转的方式使一台计算机为多个终端服务。对每个用户能保证足够快的响应时间，并提供交互会话能力。 设计目标：对用户的请求及时响应，并在可能条件下尽量提高系统资源的利用率。 适合办公自动化、教学及事务处理等要求人机会话的场合。 工作方式一台主机连接了若干个终端；每个终端有一个用户在使用；交互式地向系统提出命令请求；系统接受每个用户的命令；采用时间片轮转方式处理服务请求；并通过交互方式在终端上向用户显示结果；用户根据上步结果发出下道命令 分时系统实现中的关键问题：及时接收。及时处理。 特征交互性：用户与系统进行人机对话。 多路性：多用户同时在各自终端上使用同一 CPU。 独立性：用户可彼此独立操作，互不干扰，互不混淆。 及时性：用户在短时间内可得到系统的及时回答。 影响响应时间的因素：终端数目多少、时间片的大小、信息交换量、信息交换速度。 区别RTOS 和 TSOS 各有各的特点，RTOS 一般用于相对低速的 MCU，比如运动控制类、按键输入等动作要求实时处理的系统，一般要求 ms 级，甚至 us 级响应。 分时：现在流行的 PC，服务器都是采用这种运行模式，即把 CPU 的运行分成若干时间片分别处理不同的运算请求。 实时：一般用于单片机上，比如电梯的上下控制中，对于按键等动作要求进行实时处理。 最后 分通过以上分析，可以明确 linux 是分时系统，不过可以改成实时的如：ucLinux 就是 linux 修改而来的实时系统，至于他们的区别，可以引用百度中的类似回答： 分时系统是一个系统可以同时为两个或两个以上的账户服务！ 实时系统是能立即对指令做出反应的操作系统！微软的常见系统不能吧！而且还死机！战斗机中的操作系统就是实时的系统，想想如果别人打仗时战斗机中的电脑反应的是飞行员上一条指令或死机了，谁还敢开这架飞机呢？","categories":["0.平台","嵌入式"]},{"title":"随手记","path":"/2024/07/12/0-平台-嵌入式-随手记/","content":"MIPI 接口的含义 MIPI 中的 DSI 和 CSI 显示 DSI = display 摄像头 CSI = camera 设备树中的标识符 设备树中的 &amp; 引用节点 @指定设备地址 串口设备树配置 串口的硬流控和软流控 linux 查看版本 lsb_release -a gpu 信息及使用率查看 clinfo 查看 gpu 信息 查看 gpu 使用率 cat &#x2F;sys&#x2F;devices&#x2F;ffa30000.gpu&#x2F;dvfs 修改 IPvi /etc/network/interfaces.d/eno0 修改网关vi /etc/resolv.conf docker 下载 dockerdocker pull vookimedlo/ubuntu-qt:5.15_gcc_focal 安装 x11sudo apt-get install x11-xserver-utils 放开权限 xhost + 失败的话 export DISPLAY=:0.0 安装 VNCServersudo apt install tigervnc-standalone-server 创建配置文件touch $HOME/.vnc/xstartup 编辑配置文件 vim .vnc/xstartup 1234567891011#!/bin/shunset SESSION_MANAGERunset DBUS_SESSION_BUS_ADDRESS/etc/X11/xinit/xinitrc# Assume either Gnome or KDE will be started by default when installed# We want to kill the session automatically in this case when user logs out. In case you modify# /etc/X11/xinit/Xclients or ~/.Xclients yourself to achieve a different result, then you should# be responsible to modify below code to avoid that your session will be automatically killedif [ -e /usr/bin/gnome-session -o -e /usr/bin/startkde ]; then vncserver -kill $DISPLAYfi 添加权限chmod u+x .vnc/xstartup 启动 vncservervncserver :1 -geometry 1920x1000 -depth 24 -localhost no 启动 dockerdocker run -dit -P -e DISPLAY=$DISPLAY --privileged --network=host -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v /dev/bus/usb:/dev/bus/usb -v /home/lfxs/StudioData:/StudioData --name qoriq/arm64-ubuntu mydb:0.1 /bin/bash 123456789-d: 后台运行容器，并返回容器 ID-i: 以交互模式运行容器，通常与 -t 同时使用;-P: 随机端口映射，容器内部端口随机映射到主机的端口-p: 指定端口映射，格式为：主机(宿主)端口:容器端口-e:设置环境变量--privileged 是否允许 Docker 运行的容器拥有 root 权限--network指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；常用 bridge 和 host-v:绑定一个卷--name :容器名 xarclock 测试 安装 xarclock sudo apt-get install xarclock 启动 xarclock xarclock start docker docker run -d -v /etc/localtime:/etc/localtime:ro -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY -e GDK_SCALE -e GDK_DPI_SCALE --name accupara/qt5 jess/libreoffice docker run -d --name zerotier --restart=always --device=/dev/net/tun --net=host --cap-add=NET_ADMIN --cap-add=SYS_ADMIN -v /var/lib/zerotier-one:/var/lib/zerotier-one zerotier/zerotier:latest 启动 dockerdocker run -ti -v","categories":["0.平台","嵌入式"]},{"title":"RK3568内核CAN修改验证笔记","path":"/2024/07/09/0-平台-嵌入式-RK3568内核CAN修改验证笔记/","content":"修改方案说明 设备树中原节点配置为 CANFD，修改为 CAN 设备树中修改节点接收缓冲区，由原来的 6 改为 32 修改驱动中的中断处理机制，原来是进中断直接处理，修改为 NAPI 的方式进入中断进行轮询处理 CAN 控制器工作原理Rockchip 的 CAN 控制器包含以下主要模块: 接口管理逻辑：连接外部主控制器，解释命令，控制寄存器寻址。 CAN 核心模块：负责 CAN 帧的串并转换。 发送缓冲器：存储待发送的完整报文。 验收滤波器：过滤不需要接收的报文。 接收 FIFO：存储从 CAN 总线接收的报文。 节点信息输入 ip -details link show can0 查看节点信息 CANFD 节点信息，节点中带有 &lt;FD&gt; 字样 CAN 节点信息 设备树配置Rockchip 的 CAN 控制器在设备树中进行配置。定义了 CAN 控制器的兼容性、寄存器地址、中断、时钟、复位、引脚配置等信息。设备树地址 kernel/arch/arm64/boot/dts/rockchip/OK3568-C-common.dtsi 123456789&amp;can0 &#123;\tcompatible = &quot;rockchip,can-1.0&quot;;\tassigned-clocks = &lt;&amp;cru CLK_CAN0&gt;;\tassigned-clock-rates = &lt;300000000&gt;;\tpinctrl-names = &quot;default&quot;;\tpinctrl-0 = &lt;&amp;can0m0_pins&gt;;\trx-fifo-depth = &lt;32&gt;;\tstatus = &quot;okay&quot;;&#125;; kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi 123456789101112can0: can@fe570000 &#123;\tcompatible = &quot;rockchip,rk3568-can-2.0&quot;;\treg = &lt;0x0 0xfe570000 0x0 0x1000&gt;;\tinterrupts = &lt;GIC_SPI 1 IRQ_TYPE_LEVEL_HIGH&gt;;\tclocks = &lt;&amp;cru CLK_CAN0&gt;, &lt;&amp;cru PCLK_CAN0&gt;;\tclock-names = &quot;baudclk&quot;, &quot;apb_pclk&quot;;\tresets = &lt;&amp;cru SRST_CAN0&gt;, &lt;&amp;cru SRST_P_CAN0&gt;;\treset-names = &quot;can&quot;, &quot;can-apb&quot;;\ttx-fifo-depth = &lt;1&gt;;\trx-fifo-depth = &lt;6&gt;;\tstatus = &quot;disabled&quot;;&#125;; compatible 用来配置 CAN 控制器的驱动，默认启用的 CANFD 123456# rockchip,can-1.0用来匹配can控制器驱动compatible=&quot;rockchip,can-1.0&quot;# rockchip,can-2.0用来匹配canfd控制器驱动。compatible=&quot;rockchip,can-2.0&quot;rockchip,can-1.0rockchip,canfd-1.0 assigned-clock-rates 用来配置 can 的时钟频率，如果 CAN 的比特率低于 1M 建议修改 CAN 时钟到 200M，信号更稳定。高于 1M 比特率的，时钟设置 300M 就可以。 pinctrl 根据实际连接情况配置 can h 和 can l 的 iomux 作为 can 功能使用。 IOMUX 是 Input&#x2F;Output Multiplexer 的缩写，意思是输入&#x2F;输出多路复用器。在嵌入式系统和微控制器中，IOMUX 是一种硬件机制，用于配置芯片的引脚功能。 rx-fifo-depth: 决定接收 FIFO 缓冲区可以存储的 CAN 消息数量。默认该值设置为 &lt;6&gt;，这意味着接收 FIFO 可以容纳多达 6 条 CAN 消息，然后由软件处理，从而有助于确保消息接收的可靠性而不会丢失。需要在缓冲容量和资源使用间的权衡 rx-fifo-depth 的影响 缓冲容量: 更深的 FIFO 缓冲区可以存储更多的消息，这在 CAN 控制器以高频率接收消息且软件无法立即处理时非常有用，这有助于防止消息丢失。延迟: 更大的 FIFO 可能会引入轻微的延迟，因为消息可能会在缓冲区中等待更长时间才被处理。然而，与避免消息丢失的好处相比，这种延迟通常是最小的。资源使用: 增加 FIFO 深度可能会使用更多的硬件资源（例如内存），但对于合理的值来说，这通常可以忽略不计。系统响应性: 如果读取 FIFO 消息的软件不够快，拥有更深的 FIFO 可以帮助吸收突发的输入消息，从而使系统更具响应性并避免丢失消息。 内核配置要使用 CAN 功能，需要在内核配置中启用相关选项，内核配置文件地址 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 123456#y编译进内核#n不编译#m模块方式加载CONFIG_CAN=yCONFIG_CAN_ROCKCHIP=yCONFIG_CANFD_ROCKCHIP=y 修改内核中的 CAN FD 节点为 CAN 节点并关闭内核中的 CANFD 功能。修改 vi ./kernel/arch/arm64/configs/OK3568-C-linux_defconfig 中的 CONFIG_CANFD_ROCKCHIP=n，关闭 CANFD 驱动文件Rockchip 的 CAN 驱动文件通常位于内核源码的 drivers/net/can/rockchip/ 目录下。 网络设备驱动的中断处理 中说明了关于网络设备中断的处理 将给定的 CAN 驱动代码改为使用 NAPI(New API)进行开发，我们需要进行以下主要修改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100//在 struct rockchip_can 中添加 NAPI 结构：struct rockchip_can &#123; struct can_priv can; struct napi_struct napi; // ... 其他成员 ...&#125;;//实现 NAPI 轮询函数：static int rockchip_can_poll(struct napi_struct *napi, int budget)&#123;//budget 每次调用 NAPI 轮询函数时最多处理的包数量。 struct rockchip_can *rcan = container_of(napi, struct rockchip_can, napi); struct net_device *ndev = rcan-&gt;can.dev; int work_done = 0; while (work_done &lt; budget) &#123; if (!(readl(rcan-&gt;base + CAN_STATE) &amp; RX_BUF_FULL)) break; rockchip_can_rx(ndev); work_done++; &#125; if (work_done &lt; budget) &#123; napi_complete_done(napi, work_done); // 重新启用中断 writel(readl(rcan-&gt;base + CAN_INT_MASK) &amp; ~RX_FINISH, rcan-&gt;base + CAN_INT_MASK); &#125; return work_done;&#125;//修改中断处理函数：static irqreturn_t rockchip_can_interrupt(int irq, void *dev_id)&#123; struct net_device *ndev = dev_id; struct rockchip_can *rcan = netdev_priv(ndev); u32 isr; isr = readl(rcan-&gt;base + CAN_INT); if (!isr) return IRQ_NONE; // 处理接收中断 if (isr &amp; RX_FINISH) &#123; // 禁用接收中断 writel(readl(rcan-&gt;base + CAN_INT_MASK) | RX_FINISH, rcan-&gt;base + CAN_INT_MASK); napi_schedule(&amp;rcan-&gt;napi); &#125; // 处理其他中断... return IRQ_HANDLED;&#125;//在驱动初始化函数中设置 NAPI：static int rockchip_can_probe(struct platform_device *pdev)&#123; // ... 其他初始化代码 ... netif_napi_add(ndev, &amp;rcan-&gt;napi, rockchip_can_poll, 64); // ... 其他初始化代码 ...&#125;//在 rockchip_can_open 函数中启用 NAPI：static int rockchip_can_open(struct net_device *ndev)&#123; // ... 其他初始化代码 ... napi_enable(&amp;rcan-&gt;napi); // ... 其他初始化代码 ...&#125;//在 rockchip_can_stop 函数中禁用 NAPI：static int rockchip_can_stop(struct net_device *ndev)&#123; struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... napi_disable(&amp;rcan-&gt;napi); // ... 其他清理代码 ...&#125;//在驱动卸载函数中删除 NAPI：static int rockchip_can_remove(struct platform_device *pdev)&#123; struct net_device *ndev = platform_get_drvdata(pdev); struct rockchip_can *rcan = netdev_priv(ndev); // ... 其他清理代码 ... netif_napi_del(&amp;rcan-&gt;napi); // ... 其他清理代码 ...&#125; 使用 NAPI 来处理接收数据能够提高性能并减少中断负载。NAPI 允许驱动在高负载情况下轮询接收数据，而不是为每个接收的帧生成中断。这可以显著提高系统的效率，特别是在高数据率的情况下。 LED 状态指示可以通过修改内核驱动，实现 LED 状态灯根据 CAN 收发数据情况变化，以显示 CAN 活动状态。 测试和使用 can-utils 工具包进行 CAN 接口的测试和使用 candump 用于接收数据 cansend 用于发送数据CANOpen 调试 中说明了相关命令的使用 CAN 和 CANFD对于 CAN-FD 而言，数据比特率要大于等于件裁比特率，用 ip link set can0 type can bitrate 500000 这个命令操作 CAN-FD 是有问题的，换成 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on，而后就可以利用 CAN-FD 进行数据的收发 按照配置 CAN 的方式去配置 CAN-FD，导致少配置了 CAN-FD 的数据比特率，导致出错。之前配置 CAN 的指令为 ip link set can0 type canbitrate 500000，实际通过分析 CAN-FD 的驱动代码以及 CAN-FD 通信协议的报文格式发现，对于 CAN-FD，数据比特率是要大于仲裁比特率的。换用 ip link set can0 type can bitrate 500000 dbitrate 500000 fd on 配置数据比特率之后，CAN-FD 就可以正常收发数据了, 分析:CAN-FD 采用了两种方式来提高通信的效率，其中一种叫可变及更高的数据传输速率:从控制场中的 BRS 位到 ACK 场之前(含 CRC 但为了保证总线的健壮可靠，仲裁段(ID 和 ACK)保持不变，采用原分界符)为可变速率，CAN-FD 数据段的传输速率最大可达 5Mbit&#x2F;sCAN 总线用的速率(最高 1Mbit&#x2F;s)。 注意:两种速率各有一套位时间定义寄存器，对于 CAN-FD 来说均要配置。","categories":["0.平台","嵌入式"]},{"title":"人工智能知识结构","path":"/2024/07/02/3-软件-AI-人工智能知识结构/","content":"基础知识 Python 编程语言 基础语法与数据结构 常用库：NumPy、Pandas、Matplotlib 面向对象编程与函数式编程 机器学习基础 监督学习与非监督学习 回归、分类、聚类算法 评估指标：准确率、召回率、F1-score 等 自然语言处理（NLP）基础 文本预处理：分词、词性标注、命名实体识别等 经典模型：TF-IDF、Word2Vec、GloVe 等 数学基础 线性代数：矩阵运算、特征值与特征向量等 微积分：导数、积分、多变量函数等 概率统计：概率分布、贝叶斯定理、假设检验等 前沿算法和框架 Transformer、BERT 等算法原理 Transformer 架构及其注意力机制 BERT、GPT 等模型的工作原理与应用场景 深度学习框架 TensorFlow PyTorch 框架对比与选择 NLP 技术 词嵌入（Word Embeddings） 循环神经网络（RNN）及其变种（LSTM、GRU） 自然语言生成（NLG）与理解（NLU） 工程化实践 模型部署 REST API 部署 云服务（如 AWS、GCP、Azure） 边缘设备部署 模型优化 模型压缩：量化、剪枝、知识蒸馏等 高效推理：ONNX、TensorRT 等 集成与应用 将 LLM 集成到 Web 应用、移动应用等 构建对话系统、自动摘要等具体应用 实践项目 参与开源 LLM 项目 贡献代码、文档或测试 学习社区最佳实践 自主实现 LLM 应用 选题、需求分析 数据收集与清洗 模型训练与调优 应用部署与测试 持续学习 关注 LLM 领域最新研究成果 阅读顶会论文（如 ACL、EMNLP、NeurIPS 等） 关注相关技术博客与新闻 参加机器学习比赛 Kaggle 比赛 各类 NLP 挑战赛（如文本生成、对话系统等） 应用优化 性能优化 提高模型推理速度 减少资源占用 模型调整 调整超参数 修改模型结构 数据扩充 增加训练数据量 进行数据增强","categories":["3.软件","AI"]},{"title":"Python学习笔记","path":"/2024/07/02/1-语言-Python-Python学习笔记/","content":"Python 是一种面向对象的解释型计算机程序设计语言，可以处理系统运维、图形处理、数学处理、文本处理、数据库编程、网络编程、web 编程、多媒体应用、pymo 引擎、黑客编程、爬虫编写、机器学习、人工智能等等。 基础入门（12 学时）Python 基础Python 简介Python 安装语法格式与编码规范Python 包管理及其版本管理工具的使用类型与运算（包括容器以及容器的访问使用）Python 的字符串List，set，Dict，tuple 等类型（包括访问、添加、删除等超作）切片列表推倒生成器迭代器和解析语句与语法以及文件操作常用关键字运算符和基本运算（位运算）赋值、表达式以及输入输出If、for 以及 while函数以及函数式编程入门函数基础作用域参数与返回值（多返回值、默认参数等）递归匿名函数：lambda函数式编程工具：filter 和 reduce文件操作文本文件、二进制文件读写文件和目录操作序列化与反序列化模块与面向对象模块代码编写基础类代码编写基础多线程、Re 正则表达式的使用线程模块使用 Threading 模块创建线程线程同步线程优先级队列（ Queue）网络编程什么是 Socket?requests 网络库的简介和使用Python 实践（8 学时）网络爬虫网络爬虫技术价值、简单的网络爬虫架构URI 管理器及其实现方法网页下载及其 urllib2、requests 的使用网页解析器和 BeautifulSoup 模块数据分析与机器学习库以及相关算法介绍数据分析库：Numpy&#x2F;Scipy&#x2F;Pandas机器学习库：Scikit-Learn数据可视化库：Matplotlib文本分析库：NLTK网络分析库：igraph","categories":["1.语言","Python"]},{"title":"位操作","path":"/2024/07/01/1-语言-C语言-位操作/","content":"尽管 &amp;&amp; 操作符的优先级较低，但它仍然会对两个关系表达式施加控制。&amp;&amp; 操作符的左操作数总是首先进行求值 如果它的值为真，然后紧接着对右操作数进行求值。 如果左操作数的值为假，那么右操作数便不再进行求值，因为整个表达式的值肯定是假的，右操作数的值已无关紧要。 操作符 || 具有相同的特点，它首先对左操作数进行求值，如果它的值是真的，右操作数便不再求值，因为整个表达式的值此时已经确定。这个行为常常被称为短路求值（short-circuited evaluation）。 表达式的顺序必须确保正确。这点非常有用。下面这个例子在标准 Pascal 中是非法的： 1if ( x &gt;= 0 &amp;&amp; x &lt; MAX &amp;&amp; array[x] == 0) ... 在 C 中，这段代码首先检查 x 的值是否在数组下标的合法范围之内。如果不是，代码中的下标引用表达式便被忽略。由于 Pascal 将完整地对所有的子表达式进行求值，所以如果下标值错误，尽管程序已经费尽心思对下标值进行范围检查，但程序仍会由于无效的下标引用而导致失败。 警告： 位操作符常与逻辑操作符混淆，但它们不可互换的。它们之间的第 1 个区别是 || 和 &amp;&amp; 操作符具有短路性。 如果表达式的值取决于左操作数可决定，它就不再对右操作数进行求值。与之相反，| 和 &amp; 操作符两边的操作数都需要进行求值。 其次，逻辑操作符用于测试零值和非零值，而位操作符用于比较它们的的操作数中的对应的位。这里有一个例子： 12if( a &lt; b &amp;&amp; c &gt; d )...if( a &lt; b &amp; c &gt; d )... 因为关系操作符产生的表达式是 0，或是 1，所以这两条语句的结果是一样的。但是，如果 a 是 1 而 b 是 2，下一对语句就不会产生相同的结果。 12if( a &amp;&amp; b )...if( a &amp; b )... 因为 a 和 b 都是非零值，所以第 1 条语句的值为真，但第 2 条语句的值却是假，因为 a 和 b 的位模式中，没有一个位在两者中的值都是 1。 设置结构体内位域12345678910111213141516171819typedef int * INT32;#define INT64 int *struct node_t&#123; char a; char b:2; char d:3; char e:4; char c;&#125; __attribute__((packed));int main(int argc, const char *argv[])&#123; printf(&quot;%d &quot;, sizeof(struct node_t)); struct node_t val; val.b = 5; printf(&quot;%d &quot;, val.b);&#125; 结构体 node_t 包含五个成员：a、b、d、e 和 c。 b:2、d:3 和 e:4 是位域，分别占用 2 位、3 位和 4 位。 __attribute__((packed)) 告诉编译器不要对该结构体进行内存对齐优化取消对齐填充，使其按定义的字节顺序紧凑存储。所以结构体的大小会是各个成员字节数和位域位数的总和。 char a 和 char c 各占 1 字节。 char b:2、char d:3 和 char e:4 共占 9 位，即 2 字节（因为位域不足一个字节，但会补齐到一个字节的最小单位）。总大小为 1 + 2 + 1 &#x3D; 4 字节。 所以，sizeof(struct node_t) 的输出是 4。val.b &#x3D; 5 的值会被截断到 2 位，所以 printf(“%d ”, val.b); 的输出会是 1（因为 5 的二进制为 101，截断到 2 位为 01。","categories":["1.语言","C语言"]},{"title":"内联函数","path":"/2024/07/01/1-语言-C语言-内联函数/","content":"内联函数在 C 语言中，如果一些函数被频繁调用，不断地有函数入栈，即函数栈，会造成栈空间或栈内存的大量消耗。为了解决这个问题，特别的引入了 inline 修饰符，表示为内联函数。 栈空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足所造成的程式出错的问题，函数的死循环递归调用的最终结果就是导致栈内存空间枯竭。 下面我们来看一个例子： 12345678910111213//函数定义为 inline 即:内联函数inline char* dbtest(int a)&#123;\treturn (i % 2 &gt; 0) ? &quot;奇&quot; : &quot;偶&quot;;&#125;int main()&#123;\tint i = 0;\tfor (i=1; i &lt; 100; i++)\t&#123; printf(&quot;i:%d 奇偶性:%s /n&quot;, i, dbtest(i));\t&#125;&#125; 上面的例子就是标准的内联函数的用法，使用 inline 修饰带来的好处我们表面看不出来，其实在内部的工作就是在每个 for 循环的内部任何调用 dbtest(i) 的地方都换成了 (i%2&gt;0)?&quot;奇&quot;:&quot;偶&quot; 这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。 其实这种有点类似咱们前面学习的动态库和静态库的问题，使 dbtest 函数中的代码直接被放到 main 函数中，执行 for 循环时，会不断调用这段代码，而不是不断地开辟一个函数栈。 内联函数的编程风格定义关键字 inline 必须与函数定义体放在一起才能使函数成为内联，仅将 inline 放在函数声明前面不起任何作用。 如下风格的函数 Foo 不能成为内联函数： 1234inline void Foo(int x, int y); // inline 仅与函数声明放在一起void Foo(int x, int y)&#123;&#125; 而如下风格的函数 Foo 则成为内联函数： 1234void Foo(int x, int y);inline void Foo(int x, int y)// inline 与函数定义体放在一起&#123;&#125; inline 是一种“用于实现的关键字”，而不是一种“用于声明的关键字”。一般地，在大多数教科书中内联函数的声明、定义体前面都加了 inline 关键字。 限制inline 只适合函数体内代码简单的函数使用，不能包含复杂的结构控制语句例如 while、switch，并且内联函数本身不能是直接递归函数(自己内部还调用自己的函数)。 慎用内联内联能提高函数的执行效率，但是是以代码膨胀（复制）为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 以下情况不宜使用内联： 如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。 如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。","categories":["1.语言","C语言"]},{"title":"GitHub加速访问","path":"/2024/06/22/3-软件-Git-GitHub加速访问/","content":"Git clonegitclone.com 是一个 github.com 缓存加速网站，通过缓存经常访问的 github 仓库，加速 git clone from github 操作。当你使用 clone 仓库时 1git clone https://gitclone.com/github.com/xxxxx/xxxxx 会创建一个镜像，以后其他开发者 clone 时就可以使用镜像缓存进行 clone，速度得到了很大的提升，一般 git clone from github 只能达到 20k&#x2F;s，经过 gitclone.com 加速后可以达到 1.2M&#x2F;s。 第三方加速镜像站通过第三方 github 镜像站进行加速访问，网站的内容跟 GitHub 是完整同步的镜像，然后在这个网站里面进行下载克隆等操作。 镜像站 https://github.com.cnpmjs.org 123git clone https://github.com/xxxxx/xxxxx替换为git clone https://github.com.cnpmjs.org/xxxxx/xxxxx 镜像站 https://hub.fastgit.org 123git clone https://github.com/xxxxx/xxxxx替换为git clone https://hub.fastgit.org/xxxx/xxxx GitHub 文件加速利用 Cloudflare Workers 对 github release 、 archive 以及项目文件进行加速，部署无需服务器且自带 cdn. https://gh.api.99988866.xyz https://g.ioiox.com GitHub-Raw通过 GitHub raw 域名并非 github.com 而是 raw.githubusercontent.com，上方的 GitHub 加速如果不能加速这个域名，那么可以使用 Static CDN 提供的反代服务。 将 raw.githubusercontent.com 替换为 raw.staticdn.net 即可加速 1234https://github.com/xxxxx/xxxxx替换为https://raw.githubusercontent.com/xxxx/xxxxhttps://raw.staticdn.net/xxxx/xxxx jsdelivr 加速通过 jsdelivr 唯一美中不足的就是它不能获取 exe 文件以及 Release 处附加的 exe 和 dmg 文件。 123https://github.com/xxxxx/xxxxx替换为下面 jsdelivr 地址https://cdn.jsdelivr.net/gh/xxxxx/xxxxx/ 部署免费 gh-proxy通过 Cloudflare Workers 和 gh-proxy 开源项目对 GitHub 文件加速,通过 Cloudflare Workers 部署无需服务器且自带 CDN。开源项目: gh-proxy 文件加速自行部署。 使用 Github 镜像站你可以通过修改 Github 的链接来加速访问。例如，如果你直接访问 https://github.com 速度很慢，你可以尝试将其改为 https://github.hscsec.cn 以加速访问。当 GitHub 资源访问缓慢时使用下面任意网址仅替换掉 https://github.com 域名即可。 推荐的镜像站有： https://github.hscsec.cn https://521github.com https://mirror.ghproxy.com https://gh.api.99988866.xyz","categories":["3.软件","Git"]},{"title":"C语言基础","path":"/2024/06/17/1-语言-C语言-C语言基础/","content":"基本数据类型12345678char: 1 Bytes : 8 bitsshort:2 Bytes : 16 bitsint: 4 Bytes : 32 bitslong: 4 Bytes : 32 bitsfloat: 4 Bytes : 32 bitsdouble: 8 Bytes : 64 bitslong long: 8 Bytes : 64 bitslong double: 16 Bytes : 96 bits 数据类型存储数据在内存中以补码形式存储（溢出时截取补码的一段（然后求原码在输出）） 123char c;c = 1222;printf(&quot;%d %c &quot;,c ,c); 关键字auto数据存放在栈上 register 不能用&amp;运算符获 取 regi ste r 变量的地址 register 变量的必须是 CPU 寄存器可以接受的值 register 关键字指明将变量存储在寄存器中 register 只是请求寄存 器变量， 但不一定成功，如果没有申请到空间，那么该变量与 auto 变量没有区别 static（将值放在了数据段，所以它的值在全局都具有继承性（但不具有访问性，只在该函数内部可以访问）） （限制作用域） stati c 关键字指明变量的“静态”属性 static 关键同时具有“作用域限定符”的意义 static 修饰的局部变量存储在程序静态区 static 的另一个意义是文件作用域标识符 static 修饰的全局变量作用域只是声明的文件中 static 修饰的函数作用域只是声明的文件中 为 何 static 在 fu n 函数中 定义为全局变量不行？ 局部变量生命周期为函数运行期间， 加上 stat ic 类型后，生命周期为程序运行期间，但只可在函数中进行访问 修改变量的储存类型（将数据从栈上放到了数据段）并不表示修改变量的作用域!它仍然只能在该代码块内部按名字访问。 extern外部参照引用（其他文件中（编译时应该一起）所有函数体外部说明的变量） （类似于声明？） （exter n 延长了全局变量的作用域（到其他文件中 用 exter n 引用），不具有改变值和类型的功能) （不分配内存，不能初始化）） （不可以改变类型） exter n 关键字的使用： （具 有 externa l 链接属性，储存于静态内存中） 如果一个变量声明于函数&#x2F;代码块内部，在它前面添 加 exter n 关键字将使它所引用的是全局变量，而非局部变量； 声明于函数最外层作用域的局部变量无法与形参同名，因为他们的作用域相同 局部变量生效的范围内，会自动屏蔽全局变量 exter n 使全局变 量 i 在 fu n 中可以被访问，如果没 有 extern 在函数中， i 将变为局部变量。 exter n 只是声明一个变量，该变量需在别处已被定义 const指定变量不可被当前线程改变（但有可能被系统或其他线程改变）。 关键字“static”，译成中文就是“静态的”，所以内部函数又称静态函数。但此处“static”的含义不是指存储方式，而是指对函数的作用域仅局限于本文件。 使用内部函数的好处是：不同的人编写不同的函数时，不用担心自己定义的函数，是否会与其它文件中的函数同名，因为同名也没有关系。 局部 static 变量 a.静态局部变量在函数内定义,生存期为整个源程序，但作用域与自动变量相同，只能在定义该变量的函数内使用。退出该函数后， 尽管该变量还继续存在，但不能使用它。 b.对基本类型的静态局部变量若在说明时未赋以初值，则系统自动赋予 0 值。而对自动变量不赋初值，则其值是不定的。 全局 static 变量 全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。但是他们的作用域，非静态全局 变量的作用域是整个源程序（多个源文件可以共同使用）。静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。 static 函数（也叫内部函数） 只能被本文件中的函数调用，而不能被同一程序其它文件中的函数调用。区别于一般的非静态函数（外部函数） static 在 c 里面可以用来修饰变量，也可以用来修饰函数。 先看用来修饰变量的时候。变量在 c 里面可分为存在全局数据区、栈和堆里。其实我们平时所说的堆栈是栈而不包含对，不要弄混。 判断 ip 地址合法 判断大小端 堆栈区别，static const voliate 关键字存储模型全局静态变量全局变量(外部变量)的说明之前再冠以 static 就构成了静态的全局变量。全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。这两者在存储方式上并无不同。这两者的区别虽在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。 static 全局变量与普通的全局变量有什么区别：static 全局变量只初使化一次，防止在其他文件单元中被引用; static 局部变量和普通局部变量有什么区别：static 局部变量只被初始化一次，下一次依据上一次结果值； static 函数与普通函数有什么区别：static 函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝。 C 程序一直由下列部分组成： 正文段——CPU 执行的机器指令部分；一个程序只有一个副本；只读，防止程序由于意外事故而修改自身指令； 初始化数据段（数据段）——在程序中所有赋了初值的全局变量，存放在这里。 非初始化数据段（bss 段）——在程序中没有初始化的全局变量；内核将此段初始化为 0。 栈——增长方向：自顶向下增长；自动变量以及每次函数调用时所需要保存的信息（返回地址；环境信息）。 堆——动态存储分。 在全局变量之前加上关键字 static，全局变量就被定义成为一个全局静态变量。 内存中的位置：静态存储区（静态存储区在整个程序运行期间都存在） 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：全局静态变量在声明他的文件之外是不可见的。准确地讲从定义之处开始到文件结尾。 定义全局静态变量的好处： 不会被其他文件所访问，修改 其他文件中可以使用相同名字的变量，不会发生冲突。 局部静态变量在局部变量之前加上关键字 static，局部变量就被定义成为一个局部静态变量。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被程序自动初始化为 0（自动对象的值是任意的，除非他被显示初始化） 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域随之结束。 注：当 static 用来修饰局部变量的时候，它就改变了局部变量的存储位置，从原来的栈中存放改为静态存储区。但是局部静态变量在离开作用域之后，并没有被销毁，而是仍然驻留在内存当中，直到程序结束，只不过我们不能再对他进行访问。 当 static 用来修饰全局变量的时候，它就改变了全局变量的作用域（在声明他的文件之外是不可见的），但是没有改变它的存放位置，还是在静态存储区中。 静态函数在函数的返回类型前加上关键字 static，函数就被定义成为静态函数。函数的定义和声明默认情况下是 extern 的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。 定义静态函数的好处： 其他文件中可以定义相同名字的函数，不会发生冲突 静态函数不能被其他文件所用。 存储说明符 auto，register，extern，static，对应两种存储期：自动存储期和静态存储期。 auto 和 register 对应自动存储期。具有自动存储期的变量在进入声明该变量的程序块时被建立，它在该程序块活动时存在，退出该程序块时撤销。 关键字 extern 和 static 用来说明具有静态存储期的变量和函数。用 static 声明的局部变量具有静态存储持续期（static storage duration），或静态范围（static extent）。虽然他的值在函数调用之间保持有效，但是其名字的可视性仍限制在其局部域内。静态局部对象在程序执行到该对象的声明处时被首次初始化。 由于 static 变量的以上特性，可实现一些特定功能。 统计次数功能 声明函数的一个局部变量，并设为 static 类型，作为一个计数器，这样函数每次被调用的时候就可以进行计数。这是统计函数被调用次数的最好的办法，因为这个变量是和函数息息相关的，而函数可能在多个不同的地方被调用，所以从调用者的角度来统计比较困难。 C 语言中使用静态函数的好处： 静态函数会被自动分配在一个一直使用的存储区，直到退出应用程序实例，避免了调用函数时压栈出栈，速度快很多。 存储类 时期 作用域 链接 声明方式 自动 自动 代码块 空 代码块内 寄存器 自动 代码块 空 代码块内，使用关键字 register 具有外部链接的静态 静态 文件 外部 所有函数之外 具有内 部链接的静态 静态 文件 内部 所有函数之外 ，使用关键字 static 空链接的静态 静态 代码块 空 代码块内，使用关键字 static 变量类型 声明的位置 是否存于堆栈 作用域 如果声明 为 static 全局 所有代码块之外 否 从声明处到文件尾 不允许从其他源文件访问 局部 代码块起始处 是 整个代码块 变量不存储于堆栈中，它的值在程序整个执行期一直保持 形式参数 函数头部 是 整个函数 不允许 位的对齐字节对齐：在 32 位操作系统中，大多数计算机体系结构要求数据按照特定的字节边界对齐。常见的对齐边界是 4 字节（32 位）或 8 字节（64 位）。这是为了优化内存访问和数据传输的效率。如果数据没有按照正确的字节对齐方式存储，可能会导致额外的开销和性能下降。 结构体成员对齐：在结构体中，结构体成员的对齐方式可能会影响整个结构体的对齐方式。编译器通常会自动对结构体成员进行对齐，以满足所使用的编译器和平台的要求。默认情况下，大多数编译器会使用最大对齐方式，即按照结构体中最大成员的字节大小进行对齐。 指令对齐：在代码中，指令的对齐方式也是重要的。大多数处理器要求指令按照特定的字节边界对齐。指令对齐可以提高指令的执行速度和整体性能。 对于字节对齐，编译器通常会自动处理，但也可以通过编译器的指令或属性进行手动控制。在 C 语言中，可以使用特定的编译指令来控制结构体成员的对齐方式，例如使用 #pragma pack 指令。 以下是一个示例，展示了如何使用 #pragma pack 指令来设置结构体成员的对齐方式： 1234567891011121314151617#include &lt;stdio.h&gt;#pragma pack(push, 1) // 以1字节对齐方式压栈struct Example &#123; char a; int b; short c;&#125;;#pragma pack(pop) // 弹出对齐方式int main() &#123; struct Example ex; printf(&quot;Size of struct: %zu &quot;, sizeof(ex)); // 输出结构体的大小 return 0;&#125; 在上述示例中，通过使用 #pragma pack(push, 1) 指令将对齐方式设置为 1 字节，然后定义了一个名为 Example 的结构体，包含了 char、int 和 short 类型的成员变量。最后使用 #pragma pack(pop) 指令将对齐方式还原为默认值。 在运行示例程序后，可以观察到结构体 Example 的大小可能会受到对齐方式的影响。如果不进行任何对齐操作，默认情况下编译器可能会根据平台和编译器的要求进行对齐，大小会大于 1 字节。 总结来说，在 32 位的操作系统中，位的使用和对齐操作是为了优化内存访问和数据传输的效率。字节对齐、结构体成员对齐和指令对齐是常见的对齐方式，可以通过编译器的指令或属性进行手动控制，以满足特定的需求和平台要求。 函数指针利用函数指针，通过区分不同设备的设备号，通过函数指针的方式去调用不同的接口，从而完成一套程序可以支持多种不同的设备，完成各设备的通信协议的匹配工作， 宏定义操作符操作符#通常称为字符串化的操作符 1234567#include &lt;stdio.h&gt;#define mkstr(s) #sint main(void)&#123;printf(mkstr(I like C))return 0;&#125; 替换结果 12345int main(void)&#123;printf(&quot;I like C&quot;);return 0;&#125; 操作符##可以把两个独立的字符串连接成一个字符串 123456789#include&lt;stdio.h&gt;#define SORT(X) sortFunction##Xvoid main(void)&#123;\tchar *array;\tint elements , element size;\tSORT(3)(array , elements , element_size);&#125; 替换结果 123456void main(void)&#123;\tchar *array;\tint elements, element size;\tsortFunction3(array, elements,element size);&#125; 调试宏定义FILE 和 LINE 是 C&#x2F;C++ 编译器预定义的宏，用于获取当前源代码文件名和行号的信息。 __FILE__：它是一个字符串常量，表示当前源代码所在的文件名。编译器在编译过程中会将 FILE 替换为当前源代码文件的路径和名称。例如，如果你的源代码文件名是 “example.c”，那么 FILE 的值将是一个字符串常量 “example.c”。 __LINE__：它是一个整数常量，表示当前源代码的行号。编译器会将 LINE 替换为当前源代码行号的数值。例如，如果在源代码的第 10 行使用了 __LINE__，那么它的值将是整数常量 10。 这些宏通常在调试和错误处理过程中使用，它们可以帮助程序员定位错误或记录特定代码位置的信息。通过在代码中使用 FILE 和 LINE 宏，可以在程序中动态地获取和打印出错位置，或者用于调试输出。 以下是一个示例，展示了如何使用 FILE 和 LINE 宏： 1234567891011121314151617#include &lt;stdio.h&gt;void printLocation() &#123; printf(&quot;Error occurred in file: %s &quot;, __FILE__); printf(&quot;Error occurred at line: %d &quot;, __LINE__);&#125;int main() &#123; int x = 42; if (x &gt; 50) &#123; printLocation(); &#125; return 0;&#125; 在上述示例中，定义了一个函数 printLocation()，它使用了 FILE 和 LINE 宏来打印错误发生的文件名和行号信息。在 main() 函数中，通过一个简单的条件判断来模拟错误情况，当 x 大于 50 时，调用 printLocation() 函数。 运行示例程序，如果条件满足，将输出类似以下内容的错误信息： 12Error occurred in file: example.cError occurred at line: 14 通过使用 FILE 和 LINE 宏，我们可以方便地了解错误发生的具体位置，有助于调试和排查问题。","categories":["1.语言","C语言"]},{"title":"平台环境搭建","path":"/2024/06/14/0-平台-嵌入式-平台环境搭建/","content":"镜像烧录选用镜像为 Ubuntu18.04，分为 ARMV7 版本和 ARMV8 版本 分区扩展由于 emmc 给定的分区太小，需要对文件系统分区的大小进行扩容操作 ext4 格式的文件， 制作一个大于 6GB 的 EXT4 空文件, 由于安装的软件较多时，文件系统会很大，可以根据情况自行更改。 1sudo dd if=/dev/zero of=ubuntu18_rootfs.ext4 bs=1500M count=3 将新建的 ubuntu18_rootfs.ext4 文件格式化为 ext4 格式。 1sudo mkfs.ext4 ubuntu18_rootfs.ext4 新建一个临时的文件夹 rootfs_tmp,将 ubuntu18_rootfs.ext4 文件挂载到临时目录 rootfs_tmp,并拷贝文件系统。 123mkdir -p rootfs_tmpsudo mount -o loop ubuntu18_rootfs.ext4 ./rootfs_tmpsudo cp -avrf ./ubuntu-rootfs/* ./ 拷贝完后，卸载挂载的 ubuntu18_rootfs.ext4 文件，即完成了文件系统的制作。 1sudo umount ./rootfs_tmp ubuntu18_rootfs.ext4 就是可以用于下载的。 SD 卡启动 101 EMMC 启动 010 列出 USB 设备 1~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -l usb 烧录 1~/STMicroelectronics/STM32Cube/STM32CubeProgrammer/bin/STM32_Programmer_CLI -c port=usb1 -w ./flashlayout_myir-image-ubuntu18/trusted/FlashLayout_sdcard_stm32mp157c-ya157c-512d-v2-ubuntu18.tsv 磁盘空间扩展&#x2F;扩容 安装相关工具并查看当前分区情况，parted 是硬盘分区工具，这里用来查看磁盘分区情况，按需删除不需要的分区，以及扩展分区容量 12sudo apt update &amp;&amp; sudo apt intall -y parted resize2fssudo fdisk -l 删除分区 123456789101112# 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看分区编号(parted) print# 如果该分区后面有分区的话，删除该分区(parted) rm 8# 再次查看分区(parted) print# 删除扩展分区(parted) rm 7# 保存更改并退出(parted) quit 增加分区 12345678910111213# 进入 parted 工具$ sudo parted /dev/mmcblk1# 查看磁盘信息(parted) print# 直接扩展分区(parted)resizepart 6# 这里输入的数值，就是上方输出中 End: 后方的数值End? [9713MB]? 21.5GB# 扩展完成之后退出 parted(parted) quit#此时分区容量已经扩展完成了，但是文件系统还未识别扩展的容量，所以扩展的容量还没法使用。下面扩展一下已经重新分区的文件系统$ sudo resize2fs /dev/mmcblk1p6#此时不出意外的话应该扩容完成了，可以使用 df -h 来查看容量。 磁盘空间管理 当前目录按照空间使用大小排序(-h 参数，按 MB 显示)sudo du -s * | sort -nr 磁盘按照空间使用大小排序(-h 参数，按 MB 显示)df -h 磁盘空间整理apt-get clean 把安装的软件的备份也删除，不会影响软件使用。 挂载 SD 卡到开发板上，由于磁盘空间不足，安装位置设置挂载目录为主目录，指定 HOME=/mnt，打印 echo $HOME 确认已经成功设置 磁盘格式化mkfs.ext4 /dev/mmcblk1 磁盘新建分区fdisk /dev/mmcblk1 进入磁盘管理，输入 F 查询当前磁盘剩余未分区内容 SD 卡自动挂载编译 /etc/fstab 文件 1/dev/mmcblk1p1 /mnt/sdcard vfat rw,relatime,fmask=0000,dmask=0000,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro 0 0 网络连接利用 Win32DiskImager-1.0.0-binary 烧录 SD 后发现没有无线网卡驱动，ko 格式不兼容，待测试验证换个镜像用 stmcubeProgram 烧录后问题解决 WIFI 启动 wlan0sudo ifconfig wlan0 up 启动时提示 SIOCSIFFLAGS: Operation not possible due to RF-kill，利用 rfkill list，查看 Wireless LAN 是否被软件阻止 Soft blocked: yes，然后输入 sudo rfkill unblock wifi 解开，并输入 rfkill list 确认状态。之后在执行上述语句，启动 wlan0。 扫描 Wifi，需要在 2.4GHz 频段 12sudo iw dev wlan0 scan | grep SSIDsudo iwlist wlan0 scanning | grep SSID 设置 Wifi 配置 12345678910#生成配置文件sudo wpa_passphrase lemonade 12245612 &gt;&gt; ./wifi.conf#关闭wpa_supplicantsudo killall wpa_supplicant#初始化 wpa_supplicant# -D 指定驱动名称# -B 在后台运行守护进程# -c 配置信息的路径# -i 监听的wifi接口sudo wpa_supplicant -B -Dnl80211 -c./wifi.conf -iwlan0 设置 DHCP 利用 udhcpc 自动获取udhcpc -i wlan0 编辑配置文件自动获取 IPsudo vi /etc/systemd/network/wlan0.network 12345[Match]Name=wlan0[Network]DHCP=yes 编辑完成后重启服务，systemctl restart systemd-networkd 利用 dhclient 自动获取 1234#释放租约sudo dhclient -r wlan0#重新获取租约sudo dhclient wlan0 需要设置 DNS 服务echo &quot;nameserver 8.8.8.8&quot; &gt; /etc/resolv.conf 查看网卡信息ip addr show wlan0 测试网络连通性ping 360.com 有线设置有线网络的 IP 地址自动获取 软件源配置编辑源配置文件 1sudo vi /etc/apt/sources.list ubuntu 18.04 for arm 清华源配置12345678910111213# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse ubuntu 18.04 for arm 中科大源配置12345678910deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-proposed main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main multiverse restricted universedeb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main multiverse restricted universe 更新 python 版本armv7 上使用 python3.8 安装时依赖包编译不通过，版 安装 Python3.8，并查看安装路径 12sudo apt install python3.8which python3.8 为了方便使用，建议创建软连接，首先把之前的软连接删除： 12sudo rm -rf /usr/bin/python3sudo rm -rf /usr/bin/pip3 创建 python3 和 pip3 的软连接： 12sudo ln -s &quot;Python3Path&quot; /usr/bin/python3sudo ln -s &quot;Python3Path&quot; /usr/bin/pip3 更换 pip 地址pip下载网络问题 网络问题导致无法 clone 在主机的浏览器上登录 github 下载 klipper 和 moonrarker 的压缩包，到开发板上解压 解压后，修改 kiauh 中的 klipper .sh 和 moonrarker.sh 中指定的目录位置，文件夹的名称及路径设置为脚本中的名称和路径 WIFI 配置脚本Wifi 连接脚本，执行 ifup_wifi_sta.sh -ssid Lemonade -passwd 12345678 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#!/usr/bin/env sh#File: /usr/bin/ifup_wifi_sta.shSSID=PASSWD=WLAN=wlan0WPA_FILE=/etc/wpa_supplicant.confDRIVER_NAME=nl80211usage()&#123;\techo &quot;Usage: ./ifup_wifi_sta [-ssid wifi_sta_name] [-passwd wifi_sta_passwd] [-driver nl80211 or wext]&quot;&#125;clean_stage()&#123;\tkillall udhcpc\tkillall wpa_supplicant\tkillall hostapd\tkillall udhcpd\tsleep 1&#125;enable_wifi()&#123;\tT_HCI=&quot;phy0&quot;\tRFKILL_SYS_PATH=&quot;/sys/class/rfkill/&quot;\tdir=`ls $&#123;RFKILL_SYS_PATH&#125;`\tfor i in$&#123;dir&#125;\tdo if [ $&#123;T_HCI&#125; == `cat $&#123;RFKILL_SYS_PATH&#125;$&#123;i&#125;/name` ];then echo 0 &gt; $&#123;RFKILL_SYS_PATH&#125;$&#123;i&#125;/state echo &quot;find$&#123;T_HCI&#125; enable it&quot; sleep 1 echo 1 &gt;$&#123;RFKILL_SYS_PATH&#125;$&#123;i&#125;/state fi\tdone&#125;parse_input_info()&#123;\twhile [ $# -gt 0 ];do case $1 in -ssid) SSID=&quot;$2&quot; shift ;; -passwd) PASSWD=&quot;$2&quot; if [ $&#123;#PASSWD&#125; -lt 8 ];then echo &quot;passwd should be 8...64&quot; exit fi shift ;; -driver) DRIVER_NAME=&quot;$2&quot; shift ;; -h) usage exit ;; esac shift $(( $# &gt; 0? 1:0))\tdone\techo &quot;SSID:$&#123;SSID&#125; PASSWD:$&#123;PASSWD&#125;DRIVER:$&#123;DRIVER_NAME&#125;&quot;&#125;connect_wifi()&#123;\tif [ -n &quot;$&#123;SSID&#125;&quot; ];then head -n4 $&#123;WPA_FILE&#125; &gt; $&#123;WPA_FILE&#125;.tmp wpa_passphrase $&#123;SSID&#125; $&#123;PASSWD&#125;&gt;&gt;$&#123;WPA_FILE&#125;.tmp mv $&#123;WPA_FILE&#125; $&#123;WPA_FILE&#125;.bak mv $&#123;WPA_FILE&#125;.tmp $&#123;WPA_FILE&#125;\tfi\twpa_supplicant -B -i$&#123;WLAN&#125; -c$&#123;WPA_FILE&#125; -D$&#123;DRIVER_NAME&#125; &gt; /dev/null 2&gt;&amp;1&#125;obtain_dns()&#123;\ttime=10\twhile [ $time -gt 0 ];do state=`wpa_cli -i$&#123;WLAN&#125; -p/var/run/wpa_supplicant status | grepwpa_state | awk -F[=] &#x27;&#123;print $2&#125;&#x27;` if [ &quot;$&#123;state&#125;&quot;=&quot;COMPLETED&quot; ];then udhcpc-i $&#123;WLAN&#125; exit fi let time -= 1 sleep 1\tdone\techo &quot;connectwifi error&quot;&#125;parse_input_info $@clean_stageenable_wificonnect_wifiobtain_dns 自启动脚本配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#!/bin/sh# 启动服务# root@ok3568:/home/forlinx# cat /etc/systemd/system/startfrp.service# [Unit]# Description=startfrp# Requires=network-online.target# After=network-online.target# [Install]# WantedBy=multi-user.target# [Service]# Type=simple# User=root# RemainAfterExit=yes# ExecStart=/home/forlinx/S99Startfrp.sh# Restart=always# RestartSec=10# 目标地址用于检查网络连接，这里使用的是 Google 的公共 DNS 服务器TARGET=8.8.8.8# 检查以太网接口check_ethernet() &#123; local interface=$1 if ethtool $interface | grep -q &#x27;Link detected.*: yes&#x27;; then echo &quot;Ethernet interface $interface is connected.&quot; #释放mlan0接口当前通过DHCP获得的IP地址租约。-r选项代表“release”，即释放已有租约。 #请求一个新的IP地址租约。通过DHCP协议获取一个新的IP地址配置，包括IP地址、子网掩码、默认网关以及DNS服务器地址等信息。 dhclient -r $interface &amp;&amp; dhclient $interface else echo &quot;Ethernet interface $interface is NOT connected.&quot; fi&#125;# 检测无线网络并连接（注意：此部分涉及安全信息，请谨慎处理）connect_wireless() &#123;\twpa_passphrase lemonade 12245612 &gt;&gt; ./wifi.conf\tkillall wpa_supplicant\twpa_supplicant -B -Dnl80211 -cwifi.conf -imlan0\trm ./wifi.conf\t#udhcpc -i mlan0\tdhclient -r mlan0\tdhclient mlan0&#125;# 网络检查函数，ping 目标地址，如果成功返回 0，否则返回 1check_network() &#123;\tsleep 1\tping -c 1 $TARGET &gt; /dev/null 2&gt;&amp;1\treturn $?&#125;# 主程序开始echo &quot;Checking Ethernet interfaces...&quot;check_ethernet eth0check_ethernet eth1# 连接无线网络柠檬水，这里仅作为示例，请勿直接使用明文密码echo &quot;Attempting to connect to wireless network &#x27;lemonade&#x27;...&quot;iwlist wlan0 scanning | grep SSIDconnect_wireless# 检查网络是否连接if check_network; then\techo &quot;Network is connected. Executing commands...&quot;\t# 执行 insmod 命令\t/sbin/insmod /home/forlinx/ch341.ko\tif [ $? -ne 0 ]; then echo &quot;Failed to execute insmod command&quot; exit 1\tfi\t# 执行 frpc 命令\t/home/forlinx/frp_0.58.1_linux_arm64/frpc -c /home/forlinx/frp_0.58.1_linux_arm64/frpc.toml &amp;\tif [ $? -ne 0 ]; then echo &quot;Failed to execute frpc command&quot; exit 1\tfi\techo &quot;Commands executed successfully&quot;else\techo &quot;Network is not connected. Exiting...&quot;\texit 1fi","categories":["0.平台","嵌入式"]},{"title":"Qt的条件编译","path":"/2024/06/12/1-语言-Qt-Qt的条件编译/","content":"通过 DEFINES 定义宏可以在 pro 文件中使用 DEFINES += 宏名来定义宏。然后在 pro 文件或源码中使用 contains(DEFINES,宏名) 来判断该宏是否被定义,从而实现条件编译。 123456789101112DEFINES += MY_MACRO # 定义宏 MY_MACROcontains(DEFINES, MY_MACRO) &#123; message(&quot;MY_MACRO defined&quot;)\t# 做一些操作&#125; else &#123; message(&quot;MY_MACRO not defined&quot;) # 做其他操作&#125;contains(QMAKE_HOST.os, Unix) &#123; # 针对unix平台做一些操作&#125; 在源码中也可以使用 #ifdef MY_MACRO...#endif 来根据宏定义进行条件编译。 通过 CONFIG 配置CONFIG 变量用于指定工程配置和编译器选项,每个选项值都可用于条件判断。 1234567CONFIG += MY_CONFIGMY_CONFIG &#123; LIBS += -lmydll # 链接某库&#125; else &#123; LIBS += -lxxxdll # 链接其他库&#125; 通过平台判断QMake 提供了一些内置变量来判断当前平台,如 win32、macx、android 等,可以根据这些变量进行条件编译。 12345678910win32 &#123; LIBS += -lwindowslib&#125;macx &#123; LIBS += -lmaclib &#125;!macx:!win32 &#123; # 针对unix平台做一些操作 &#125;","categories":["1.语言","Qt"]},{"title":"文件IO","path":"/2024/06/07/0-平台-Linux-IO-文件IO/","content":"文件 IO 文件描述符 进程的概念 从硬盘到内存到cpu的的动态过程 进程内唯一，每个打开的文件都对应内核中的一块区域，被内核管理 内核给用户一个整型值用来通知内核要操作的文件 缺省默认当前可用的最小值 012 缺省文件描述符 分别映射一个硬件设备 由系统默认打开 文件 IO API 编程接口,就是函数名 fp = open(pathname, flag); fp = open(pathname, flag, mode); ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); close(fd); lseek(); 空洞文件。 文件和目录 文件属性: stat(&quot;pathname&quot;, struct stat p); fstat(int fd, ....); lstat(&quot;..&quot;, ....); getpwuid(); //根据uid获取用户信息 getgrgid(); // gid 组信息 localtime(); struct stat &#123;&#125;; 文件信息结构体 struct passwd &#123;&#125;; 用户信息结构体 pw = getpwuid(sb.st_uid); struct group &#123;&#125;; 组信息结构体 struct tm&#123;&#125;; 时间结构体 文件夹: DIR *opendir(); struct dirent * readdir(); closedir(); struct dirent &#123;&#125;; 拓展: getopt(); 获取短参函数 ls -la access(); 检查文件文件是否存在和文件权限函数 chdir();","categories":["0.平台","Linux","IO"]},{"title":"Shell脚本","path":"/2024/06/07/1-语言-Shell-Shell脚本/","content":"Shell 脚本的本质: shell命令的有序集合 #!&#x2F;bin&#x2F;bash chmod u+x test.sh.&#x2F;test.sh &#x3D;&#x3D; &#x2F;home&#x2F;fs&#x2F;Temp&#x2F;test.sh &#x2F;bin&#x2F;bash test.sh chmod u+x test.shPATH+&#x3D;:&#x2F;home&#x2F;fs&#x2F;Temptest.sh 任意目录运行 chmod u+x test.sh sudo mv test.sh &#x2F;bin&#x2F; Shell 变量 自定义变量: 1.不区分数据类型,全部识别为字符串 2.命名符合标识符规定, 3.引用 $Var $&#123;&#125; 边界识别 4. 只读变量 readonly 变量名 5. 删除变量 unset 变量名 set 显示本地的所有变量 位置变量: $# 参数的个数 $? 命令执行结果,函数返回结果, $$ 进程id $1,$2..$9,$&#123;10&#125;, $&#123;11&#125; $@ &quot;&quot; $* &quot;$*&quot; 当做整体处理 环境变量 (全局可以访问的变量) env export 变量名 将局部变量变为全局变量 PS: 脚本中定义的变量只在本脚本有效 功能语句 read -p &quot;提示内容&quot; -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 read -n 5 AA BB CC read AA BB CC hello xiaoming, mingtian you kong expr expr $AA + $BB sum=`expr $AA +　$BB` sum=$(expr $AA + $BB) sum=$(($AA + $BB)) sum=$[$AA + $BB] let &quot;sum=$AA + $BB&quot; let sum=$AA+$BB test 字符串 test str1 = str2 != 整数\t-eq -ne -gt -ge -lt -le 文件属性 -d -f -r -w 结构语句 switch case if for while untill if [ ] then\tfi if [ ]then else fi case case var in 1) ... ;; 2|3|4) ... ;; esac for 变量 in 单词表 do .. done for ((i=0; i&lt;N; i++)) do done for var in `ls` for var in $(ls) for var\t#单词表的内容是位置参数变量时，可以省略in ... while 表达式 do 。。 done while (($i &lt; $loop)) do ... done 函数 定义： 函数返回值用$? 输出给了变量 var&#x3D;$(add_fun) 返回值范围 0-255 传参: add_fun str1 str2 str3 gcc 编译流程 step1:预处理 头文件加载,宏定义替换,条件编译,注释 生成预处理文件.i &lt;有效文件&gt; gcc -E name.c -o name.i gcc -o name.i -E name.c step2:编译 检查代码的语法错误,如果有错误，报错，结束编译。否则，生成汇编代码.s gcc -S name.i -o name.s\tgcc -o name.s -S name.i step3:汇编 将汇编源码编译生成机器码(目标文件).o gcc -c name.s -o name.o gcc -o name.o -c name.s step4:链接 将目标文件(&gt;=个)链接生成可执行文件 gcc name.o -o name gcc -o name name.o gdb","categories":["1.语言","Shell"]},{"title":"音乐人专辑","path":"/2024/06/05/3-软件-AI-音乐人专辑/","content":"专辑简介 专辑名: 月球上的思念 艺术家: [你的名字] 发行日期: [发布日期] 简介: 《月球上的思念》是一张充满深情与孤独的音乐专辑，灵感源于宇航员在月球上独自一人时对妻子的深切思念。专辑融合了抒情流行、电子和氛围音乐，以优美的旋律和感人的歌词，描绘了思念、孤独、怀念和希望的情感旅程。 每一首歌都仿佛是一封写给远方爱人的信件，表达了对爱人无尽的思念和重逢的期盼。通过音乐，听众可以感受到宇宙的浩瀚与生命的脆弱，以及爱情的坚韧与力量。 曲目列表: 月球上的孤独 无声的思念 回忆的影像 遥远的对话 无助的夜晚 怀念地球上的日子 信念的支撑 重逢的期望 爱的反思 坚守的希望 让《月球上的思念》带你踏上一段情感之旅，在音乐中感受孤独中的温暖与希望中的力量。","categories":["3.软件","AI"]},{"title":"Alist网盘搭建","path":"/2024/05/31/0-平台-服务器-Alist网盘搭建/","content":"Alist 搭建方案 方案一：云服务器直接搭建及存储 方案二：云服务搭建页面，NAS 需要搭建 webdav，同时需要提供 NAS 穿透方案 方案三：云服务器提供穿透方案 frp&#x2F;Cloudflared，NAS 搭建页面和存储 本地搭建仓库地址 https://github.com/alist-org/alist Relaes 地址 https://github.com/alist-org/alist/releases 下载对应版本的 alist 使用，直接解压后按照下述方式运行即可 1234# 解压下载的文件，得到可执行文件：unzip alist-xxxx.zip# 运行程序.\\alist.exe server 之后访问本地 http://127.0.0.1:5244/ 即可打开 Alist 页面。 Docker 搭建123456789101112131415version: &#x27;3.3&#x27;services: alist: #离线下载选择&#x27;xhofe/alist-aria2:latest&#x27; image: &#x27;xhofe/alist:latest&#x27; container_name: alist volumes: - &#x27;./alist_data:/opt/alist/data&#x27; ports: - &#x27;9083:5244&#x27; environment: - PUID=0 - PGID=0 - UMASK=022 restart: unless-stopped Alist 启动脚本 VBS1234567Dim ws_alistDim ws_frpSet ws_alist = Wscript.CreateObject(&quot;Wscript.Shell&quot;)ws_alist.run &quot;alist.exe server&quot;,vbhideSet ws_frp = Wscript.CreateObject(&quot;Wscript.Shell&quot;)ws_frp.run &quot;.\\frpc.exe -c .\\frpc.toml&quot;,vbhideWscript.quit 配置本地12345678910# 获得管理员信息 以下两个不同版本，新版本也有随机生成和手动设置# 低于v3.25.0版本.\\alist.exe admin# 高于v3.25.0版本# 随机生成一个密码.\\alist.exe admin random# 手动设置一个密码 `NEW_PASSWORD`是指你需要设置的密码.\\alist.exe admin set NEW_PASSWORD dockerAlist 配置存储直接按照 Alist 官方文档配置即可，配置完成后，NAS 利用 CloudSync 套件，添加 WebDav 站点后即可访问。 1234# 随机生成一个密码docker exec -it alist ./alist admin random# 手动设置一个密码,`NEW_PASSWORD`是指你需要设置的密码docker exec -it alist ./alist admin set NEW_PASSWORD WebDav 配置如果没有单独留路径选项那正常就是在 站点后面添加 /dav 选项，如下所示： 其他 搭建 NAS，192.168.2.100:5000 搭建 Alist，192.168.2.100:5244 Alist 添加夸克网盘&#x2F;移动云盘&#x2F;百度网盘 NAS 中安装 CloudSync，链接到 Alist 的 WebDav，双向同步方案 通过 FRP 透传 NAS 的端口和 WebDav 的端口到外网 如何让 Alist 网盘内不同的文件夹同步","categories":["0.平台","服务器"]},{"title":"NAS相关配置","path":"/2024/05/31/0-平台-服务器-NAS相关配置/","content":"控制面板-网络-设置，设置 DNS 为 223.5.5.5 或者 114.114.114.114 或者 119.29.29.29 配置时间服务器控制面板-高级模式-区域选项，与 NTP 服务器同步：打字填入 ntp1.aliyun.com 或者 time.apple.com 配置 SSH 服务 打开控制面板 选择终端机和 SNMP，启动 SSH 功能，设置端口号 打开 mobaxterm 连接 NAS 的 IP 加上设置的 SSH 端口号 进入终端后输入用户名和密码登录，之后输入 sudo -i 进入 root 用户但是默认 22 端口要改掉，最好在 9000 以上 配置自启动编辑 rc.local 添加自启动脚本 1234#!/bin/shcd /home/ubuntu/frpServer/frp_0.52.3_linux_amd64#按照配置文件启动服务器端./frps -c ./frps.toml 在 NAS 中添加脚本到任务计划 进入控制面板，选择任务计划，选择新增 - 触发的任务 - 用户定义的脚本 编辑任务名称，选择账号为 root，事件为开机，勾选已启动 编辑任务设置，编辑运行命令中的内容为 bash /root/start.sh 确定保存后在该任务上右击，选择运行 猫盘考虑下大猫盘接入 USB 接口 配置 FRP，同步至云服务器 配置 SYNC，同步至夸克&#x2F;移动&#x2F;百度 frp 方案依赖服务器带宽，比较卡","categories":["0.平台","服务器"]},{"title":"3D打印机环境配置","path":"/2024/05/30/3-软件-3D打印机-3D打印机环境配置/","content":"3D 打印机3D 打印（3D printing）是一种快速成型技术，也被称为添加制造（Additive Manufacturing，AM）。它是一种通过将材料逐层叠加以构建三维实体物体的过程。与传统的制造方法不同，3D 打印不需要模具或切削工具，而是通过从计算机辅助设计（CAD）模型中生成的数字模型直接创建物体。 FDM（熔融沉积成型）：FDM 是目前最常见的 3D 打印技术，它使用热塑性材料通过打印头喷出的方式逐层堆积，最终形成所需的物体。FDM 打印机的结构和控制系统比较简单，价格也比较实惠，因此广泛应用于家庭、办公室和教育等领域。 SLA（光固化成型）：SLA 使用紫外线激光器或 LED 光源照射光敏树脂，使其逐层固化成为所需的物体。SLA 打印机的精度和表面光滑度比 FDM 更高，但价格也更贵。 SLS（选择性激光烧结）：SLS 使用激光束将热塑性粉末烧结在一起，逐层堆积形成所需的物体。SLS 打印机可以使用多种材料，可以打印出更复杂的结构，但价格也更昂贵。 DLP（数字光处理）：DLP 使用光敏树脂和数字投影仪，通过投影仪将光固化在涂层的树脂上，逐层堆积形成所需的物体。DLP 打印机的速度和精度都比较高，但价格也较贵。 FDM通过将加热的材料挤出打印头，逐层堆积形成打印件 打印头 打印床&#x2F;热床 控制系统（主板、电机、传感器和用户界面） 打印材料 G-Code 一种用于控制数控机床（包括 3D 打印机、数控铣床、数控车床等）运动和操作的编程语言。 结构结构主要分为两部分： 一个负责三维空间的移动的组件 (三维移动部分) 一个负责进料、融化材料和挤出材料的组件（挤出部分） 打印时材料会一层又一层地堆积在之前已经「挤出来」的材料上，所以在这两个组件共同协作下就能打印出一个完成的 3D 物体了。 结构 - 三维移动部分打印机在 3D 的空间运动的传动方式有很多种，一般较为便宜的打印机会选择笛卡尔结构。笛卡尔结构指的是 X Y Z 方向上的运动是独立的，这种方式比较直观，结构也比较简单。常用的 3D 打印机的结构有以下几种： Prusa i3 型：控制 X&#x2F;Z 轴，Y 轴通过工作台的移动来实现。CoreXY 型：CoreXY 最大的特别之处在于其 X、Y 电机是协同运作的，并且它的同步带在不同同步轮的摆放下能够形成多种不一样的缠绕方法。由于两个电机的协同运动，电机带动的力比单一电机的力要大，且会减少在 XY 方向面上的一个电机重量，提高精准性。**CoreXY 结构：CoreXY 结构采用的是两个电机通过传动带和滑块来实现打印头的运动，其中 X 和 Y 轴的传动带交叉布置，使得打印头的运动方向可以在 X 和 Y 轴上独立控制。CoreXY 结构的优点是打印速度快，同时打印头的重量对定位精度的影响较小，同时可以实现较大的打印范围。缺点是结构复杂，需要更多的零件和更高的制造精度，同时维护和升级也较为困难。 Um &#x2F;Ultimaker 型：X 轴、Y 轴的电机都在静止的框架上，但挤出头在两个互相垂直的光轴的交叉处。**UM 结构（Ultimaker 结构）：UM 结构采用的是直线轴承和滑块来实现运动，其中 X 和 Y 轴分别由两个电机驱动，通过传动带和滑块来实现打印头的运动。UM 结构的优点是定位精度高，速度快，同时结构简单，易于维护和升级。缺点是打印头的质量和稳定性对定位精度有较大影响，同时打印头的重量也会影响打印速度。 MB：主要体现在挤出电机一般都装在喷头旁，近程进丝，双光轴承载挤出组件，X 方向的运动一般是通过电机带动同步带，通过带传动使两边一起运动。 delta 三角洲（并联臂）型 结构 - 挤出部分挤出部分分为以下： 挤出头 送料步进电机 送料步进电机驱动板 FDM 3D 打印机除了怎么动的很关键以外，怎么取料、融化材料、挤出材料也非常重要。 其中取料和挤出材料是由挤出机处理的，融化材料则是由热端处理的。 挤出机从材料盘中将材料拉出来，送进去热端融化。 并持续往热端送更多的料让融化的材料从喷嘴中挤出来。 其中挤出机的精度和挤出的速度决定了打印质量和速度。精度高意味着可以更好的控制挤出的量。挤出的材料太多或者太少对打印的质量影响都非常大。挤出的速度快就很直接的决定了你能打印多快。 而影响挤出机的精度和速度的两个关键因素就是： 挤出机的类型 挤出机的齿轮数量 FDM 挤出机分为两个大类： 远端挤出机 远端挤出机在于挤出机不需要跟着喷嘴一块移动，减轻了需要移动的零件的重量 远端挤出机由于从喷嘴挤出压力的是通过材料本身传递的，所以远端挤出机的反应时间较长，并且对打印的材料比较敏感，例如 TPU 之类的软质材料就没法很好的打印出来 近端挤出机 近程挤出机由于距离热端非常近，所以需要的挤出力量也比较小，这样挤出精度就会更高 近程挤出机是和热端是集成在一起的，因此 X Y 轴上移动的部件的重量增加了，震动也会相对的增加 另外一个影响挤出机精度的就是挤出机的齿轮了。较低端的机器一般都是配备都是单齿轮，虽然对比双齿轮的挤出机，无论是对材料的咬合能力还是挤出精度都表现更差，但它便宜而且工作，对于预算相对比较紧张的朋友是一个不错的选择。 传动系统传动系统分为以下几个部分： Xyz 步进电机 限位开关 步进电机驱动板 同步带 传动系统是 3D 打印机中负责移动打印头（或喷嘴）和打印平台的机械组件。它在 3D 打印过程中发挥以下作用： 控制位置：传动系统通过精确的运动控制，将打印头定位在正确的位置，以便在每个层次上精确地添加材料。 三维定位：传动系统的运动控制使得打印头可以在 X、Y、Z 三个方向上精确移动，从而实现三维打印。 打印速度：传动系统的运动控制还影响到打印速度。更快的传动系统能够加快打印速度，但需要保持精确性和稳定性，以确保打印质量不受影响。 自动校准：一些高级的传动系统具备自动校准功能，能够自动检测打印平台和打印头的位置，从而保持打印的准确性和稳定性。 加热部分加热部分分为以下： 热床 MOS 管打印机的床就是用来承载挤出机挤出来的材料。是 3D 打印机上的一个移动平台，用于支撑正在打印的物体。其主要作用如下： 粘附和稳定：打印平台上的特殊表面或涂层（例如热床、胶水、胶带等）可以提供粘附性，确保打印的第一层材料牢固地附着在平台上，并防止其在打印过程中发生位移或变形。 * 塑料在不同的温度下粘性不一样，控制床的温度可以让不同的塑料在保持形状的同时达到最大的粘性。如果温度太高则有可让打印的形状变形，温度太低则有可能让打印的材料不粘床。床的温度和热端的温度共同决定了可以打印什么材料。如果能顺利融化材料，但是他并不能稳定的黏在床上，打印也会有非常大几率失败。 平整度：打印平台的调平性（平整度）对于打印质量至关重要。如果平台不平整，可能导致打印的物体底部出现变形或不平整的表面。 防止翘曲：特定类型的 3D 打印材料，例如 ABS（丙烯腈 - 丁二烯 - 苯乙烯）等，有时容易在冷却过程中产生翘曲。热床可以在打印过程中加热，有助于减少材料翘曲，提高打印的成功率。 电气系统电气系统分为以下几个模块： 电源 主板（需要烧录固件代码如 Marlin） 显示屏 传感器&#x2F;加热模块等 了解各模块的所需电源电压，功耗等信息选取合适电源了解打印机的所需功能，进行针对性选择主板 其他扩展模块Octoprint 远程监控模块3d 打印的成功率和模型文件、材料、切片 gcode 代码、天气、机器等关联，然后只有在打印中才能知道模型有没有出问题，octoprint 连接 Wifi，通过网页端远程摄像头监控进度，同时能够开始和停止打印机的操作。 自动调平通常机器在几天内调平过一次之后很大几率不用重新调平，但是你对机器的一举一动包括机器自己的老化都会影响热床的位置移动和变形，自动调平模块 3D touch（也有别的）能够让完全手动的调平变成半自动调平。 双 Z 结构顾名思义就是有两根 Z 轴。 单一的 Z 轴由于在一边容易导致 Z 轴变形造成模型垂直方向变形。同时也可能会让 XY 平面在变形的 Z 轴运动受阻。 双 Z 结构不仅能够减少变形，同时增强 Z 轴的稳定性。 硬件硬件选型硬件采用 MKS Gen L v2.1，固件采用 Klipper pin 口图 硬件相关主要考虑因素: 驱动电机数量（根据 3D 打印机的结构方案确定） 限位开关 风扇控制 挤出头控制 热敏电阻（热床&#x2F;加热棒&#x2F;挤出头） 单下位机方案需要支持屏幕接口 上位机方案需要支持 USB 连接 控制架构目前 3D 打印机的主流架构一般情况下，有以下两种方式： 上位机（运行 fluidd 控制软件）+ 下位机（运行 kilpper 固件）+Web 显示 * 由于手头上正好有一块 Linux 开发板，所以准备采用上位机方案，局域网部署（OctoPrint 和 Fluidd 二选一安装配置即可。） 下位机（运行 marlin 固件）+ 串口屏显示 * 优点：只需要一块控制板加上串口屏，不需要上位机控制软件，节约成本 缺点：屏幕小，显示的信息少 固件在 3D 打印机中，固件控制着 3D 打印机的运动和操作。固件负责将 G 代码转换为实际的运动和操作，例如将 G 代码中的坐标转换为电机的运动，控制加热器的温度等。 固件还负责处理传感器的输入，例如温度传感器、限位开关等，并根据这些输入控制 3D 打印机的运动和操作。 3D 打印机的固件通常是预装在单片机上的，但用户也可以根据需要进行更新和修改，以实现更好的性能和功能。 在 3D 打印领域，主流的固件有以下几种： Marlin：3D 打印机领域最流行的固件之一，因为它具有广泛的硬件支持和强大的功能。Marlin 支持多种传感器和功能，如自动床平衡、断电续打、LCD 屏幕等。Marlin 还提供了一套易于使用的配置文件，可以通过修改这些文件来对 3D 打印机进行高度自定义。由于 Marlin 是开源软件，因此用户可以根据自己的需要进行修改和定制，以实现更好的性能和功能。 Klipper：Klipper 是一款比较新的开源固件，它具有更高的计算能力，可以实现更快的运动和更高的精度。 Repetier：Repetier 是另一款流行的开源固件，它具有类似于 Marlin 的功能和支持。 Smoothie：Smoothie 是一款基于 ARM 处理器的开源固件，它支持多个独立的电机和传感器，并具有良好的可扩展性。 本次机器组装选择的方案是 klipper，可以很方便的直接在上位机修改打印机参数，不需要每次修改参数后重新烧写固件 Klipper 固件配置及烧写Klipper 官方文档 https://www.klipper3d.org/zh/Overview.html ，建议详细阅读，很多参数和问题都有说明 获取 klipper 源码 1git clone https://github.com/Klipper3d/klipper.git 执行脚本安装一些系统依赖、设置。安装很慢时，可以更换下 pip 的源 pip下载网络问题 1./klipper/scripts/install-ubuntu-22.04.sh 然后配置和构建 elf 文件 123cd ~/klipper/make menuconfigmake 需要确定连接到微控制器的串行端口， 12ls /dev/serial/by-id/*ls /dev/ttyUSB* 可以用类似以下的方法来刷写固件： 123sudo service klipper stopmake flash FLASH_DEVICE=/dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0sudo service klipper start 刷写时要确保 端口没有被占用 控制软件上位机主板采用一块手头空余的 Linux 主板，软件采用 Fluidd，如果是上位机的形式，则由运行在上位机的 3D 打印机控制软件来控制 3D 打印机，主要考虑因素: ARM 架构，功耗低（需要长时间工作） USB 接口，连接下位机 网口，局域网 Web 显示打印机控制 显示屏，本地显示打印机控制 WIFI，可以无线打印 监控模块，可以远程查看打印情况 先在 WSL 环境下搭建调试 Fluidd， 适用于 3D 打印机的 Klipper 固件，提供 WEB 页面和控制。 KIAUH (Klipper Installation And Update Helper)安装安装方式采用推荐的安装脚本安装，该脚本可以直接完成所有环境配置。 在通过该脚本进行安装时，需要实时从 github 和 pip 下载文件，由于网络不稳定的情况导致安装失败的，可以下载 klipper&#x2F;mooraker&#x2F;fluidd 等文件后，置于~目录下，并修改 kiauh 中的 scripts 文件夹下的相关脚本，将脚本中的 clone 部分删除，避免网络不稳定导致的错误。pip 部分可以修改 pip 源，稳定下载。 界面如下所示： 执行脚本前需要安装 git sudo apt-get update &amp;&amp; sudo apt-get install git -y 下载 KIAUH 到本地： 1git clone https://github.com/dw-0/kiauh.git 执行脚本 1./kiauh/kiauh.sh KIAUH 的主菜单中。您将看到多个操作可供选择，具体取决于您想要执行的操作。要选择操作，只需在“执行操作”提示中输入相应的数字，然后按 ENTER 确认即可。 moonraker选择 1 Install,需要输入密码，之后选择 2 moonraker，安装完成后进入浏览器输入 http://127.0.0.1:7125/server/info 测试 moonraker 是否正常安装。 moonraker 的作用： Moonraker is the API that fluidd communicates with, which in turn communicates with Klipper. All three components are required for a healthy printer. 如果出现 pip 下载速度太慢导致的失败，参阅 pip下载网络问题 无法构建 pillow 和 streaming-form-data 这两个包的轮子（wheels），检查发现是头文件没有导致的错误，将 /usr/include/python3.6 下的所有头文件拷贝至 /usr/include fluidd(mainsail 二选一)选择 1 Install 之后选择 4 Fluidd 进行安装，安装完成后访问 http://127.0.0.1 正常打开 fluidd 页面 安装之前进入 kiauh/resources 下，编辑 fluidd 文件可以更改端口。 Mainsail(fluidd 二选一)修改 /kiauh/resources/mainsail 中的 80 端口为 9090，安装 mainsail 到 9090 端口 配置打印机配置文件，一般在用户主目录中名为 printer.cfg 的文件 配置文件示例 /home/linux/printer.cfg。 刷写 Klipper 后，名称可能会改变，检查 USB 节点名称： 123ls /dev/serial/by-id/*或者ls /dev/ttyUSB* 确认节点名称并写入配置文件中去。 123/dev/serial/by-id/usb-1a86_USB2.0-Serial-if00-port0或者/dev/ttyUSB0 用这个唯一的名字更新配置文件。更新 [mcu] 部分，类似于： 12[mcu]serial: /dev/ttyUSB0 在编辑该文件后，发出 restart 或 FIREWARE_RESTART 命令以重新加载配置（命令根据实际上位机）。如果 Klipper 配置文件被成功读取，并且成功找到并配置了微控制器，那么 “status” 命令将报告打印机已准备就绪。 默认的 Klipper 启动脚本在 /tmp/klippy.log 中放置日志，提供更详细的信息。 问题解决由于本次安装是在 WSL 中的 Ubuntu 进行安装的，所以有以下两个问题需要解决 1）systemd 中的服务无法启动导致的 moonraker.service 无法运行 Windows 版本要求 (已验证 Win11 22H2) 启动 windows Power Shell，更新 wsl 1wsl --update 进入 Ubuntu 1wsl ~ 编辑配置 1sudo vi /etc/wsl.conf 添加以下内容 12[boot]systemd=true 保存并退出 ubuntu 1exit 在 windows power shell 中关闭 ubuntu 1wsl --shutdown 然后重新进入 ubuntu 1wsl ~ 查询 systemd 服务 1sudo systemctl status 2）在 WSL 中无法打开 Windows 的 USB 端口 WSL2 内核要求 &gt;&#x3D; 5.10.60.1 进入 Ubuntu 1wsl ~ 查询内核版本 1uname -a 退出 Ubuntu 1exit 安装 usbipd-win 1winget install usbipd 进入 Ubuntu，安装客户端工具 12sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 退出 Ubuntu，添加 USB 设备到 WSL 中去 1234usbipd wsl list //列出所有连接到Windows的USB设备。usbipd wsl attach --busid //添加USB设备进入Ubuntu，需要管理员权限usbipd wsl detach --busid //停止USB设备共享usbipd wsl attach -a --busid 2-7 // -a 自动绑定 进入 Ubuntu，查看已经连接的 USB 设备 1lsusb 配置 udev，允许非 root 用户访问 USB 设备,需要在设备连接前完成该操作。需要将根据自己 USB 设备编写的 60-myusb.rules 文件复制到 /etc/udev/rules.d 嵌入式部署时相关问题部署 3d 打印机环境到开发板，所有环境已部署完毕，目前需要解决的问题点是需要编译 ch341 在 linux 环境下的驱动，驱动内核版本 4.19.204 详见 Linux下的CH34x串口识别 切片软件-Slic3rd 的交叉编译配置开源软件，项目地址 https://github.com/slic3r/Slic3r Slic3r 的 C++ 端仅支持 CLI。虽然可以构建 GUI，但它不起作用。 安装依赖需要 GCC4.9 或更高版本 1sudo apt-get install build-essential libgtk2.0-dev libwxgtk3.0-dev libwx-perl libmodule-build-perl git cpanminus libextutils-cppguess-perl libboost-all-dev libxmu-dev liblocal-lib-perl wx-common libopengl-perl libwx-glcanvas-perl libtbb-dev libxmu-dev freeglut3-dev libwxgtk-media3.0-dev libboost-thread-dev libboost-system-dev libboost-filesystem-dev libcurl4-openssl-dev 获取源代码123$ git clone https://github.com/alexrj/Slic3r.git$ cd Slic3r$ git checkout -b origin/stable 由于 wxPerl 的最新版本无法正确编译，因此我们将安装一个修补版本： $ cpanm --local-lib local-lib git://github.com/alranel/wxPerl-0.9924.git@Experimental-Dev 构建 Slic3r 123$ export LDLOADLIBS=-lstdc++$ perl Build.PL$ perl Build.PL --gui 在您最喜欢的文本编辑器中创建一个文件，调用它 slic3r 并将以下内容粘贴到其中： 123#!/bin/sh(i=$# ; while [ $i -gt 0 ] ; do echo $1 ; shift ; i=$(expr $i - 1) ; done) | xargs -d &#x27; &#x27; perl ./slic3r.pl将其标记为可执行文件chmod +x slic3r 如果您想启动 GUI，请使用： $ slic3r --gui 如果您希望默认启动 GUI，则步骤相同，只是需要在 slic3r 脚本中添加 –gui 标志： 12#!/bin/sh(i=$# ; while [ $i -gt 0 ] ; do echo $1 ; shift ; i=$(expr $i - 1) ; done) | xargs -d &#x27; &#x27; perl ./slic3r.pl --gui 将其标记为可执行文件 chmod +x slic3r 切片软件-Cura 的使用设置打印机长宽高&#x3D;200*200*200mm 打印头孔径 0.4mm 材料直径 1.75mm 配置 Cura 设置可见性可以根据自己在切片时实际需要调整的相关参数进行显示 移动和缩放模型长按鼠标滚轮中键，可平移视角 长按鼠标右键，可旋转视角 滚动鼠标滚轮，可放大缩小视角 选中模型后，在 Cura 的左侧，依次功能为 移动 缩放 旋转 镜像 单一模型设置 支撑拦截器 在相应位置添加方块减少支撑应用右击模型，可进行“复制”、“清空平台”、“居中模型等设置 设置打印参数点击右侧的打印参数设置栏，选择多种模式 质量即层高：数值越小，打印物体表面效果越好，打印时间越长。默认选择 0.15mm 填充打印模型内部的模型密度，默认以网格状的形式填充。默认选择 20% 如果填充率过低，也会有一定程度导致翘边，不同的内部填充图案也可以有效减少翘边。 材料主要设置打印时喷嘴和热床的温度。一般耗材上会写有打印温度。也可通过打印温度塔测试出每种最耗材品牌最佳的打印温度。建议首层温度用 230°C，容易粘床。 打印 PLA，热床的温度建议在 50-60°C。 速度PLA 建议打印速度为 60mm&#x2F;s，±20 也在常用速度。 过快步进电机会丢步，按实际情况设置 移动当喷嘴移动到非打印区域上方时回抽耗材 当打印出现拉丝情况，可调整回抽设置。建议回抽距离用 2.0mm，回抽速度用 50mm&#x2F;s，加大数值可减少拉丝情况。如果打印过程中喷嘴有碰到打印物的情况，可勾选 Z 轴抬升。 附着加大模型第一层与打印平台的接触面积，增加附着力，让模型在打印过程中更稳固。当打印模型的高度较高，接触面积较小时使用。 skirt 裙边 在打印模型前，在模型外围打印一圈，让喷头里面的出丝比较顺滑,主要用于擦净喷头 brim 在模型的边缘处加上薄薄的一层，防止翘边，适用于打印较高的物体且接触面较小，容易倒塌的时候 raft 底座，在底座上在打印模型，适用于接触面多且复杂的情况 支撑在模型的悬垂部分生成支撑结构，防止模型倒塌。作为入门最难的一个设置。通常角度过大，打印过程中悬空部位则需要添加支撑，否则容易下垂。支撑与模型接触面往往很粗糙，影响模型质量。 支撑悬垂角度越大，需要支撑部位（红色部分）则越小。建议 45-50 间。 添加支撑的最小悬垂角度，当角度为 0 时，将支撑所有悬垂，当角度为 90 度时，不提供任何支持 Cura 提供普通支撑和树型支撑两种选择。 树型支撑对模型影响更小，也节省材料。注意，它只适合于非平面的悬空，如鼻尖，指尖或拱形。对于平面的悬空，树形支撑无法提供足够的稳定性。 正常支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：0支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。当模型底面较为平缓时，可设置较大的间隙，减少拆支撑难度。当模型底面变化大时，应设置较小的间隙。同时，支撑间隙与支撑密度也有关联，支撑密度较高时，可适当拉大间隙。支撑 X&#x2F;Y 距离：1-1.5mm 树形支撑建议参数支撑图案：锯齿形支撑密度：15-20支撑墙行数：1连接支撑锯齿形: 勾选支撑 Z 距离：推荐比层高略小（如：0.2 层高，设置为 0.15）一般此参数为 0.6~1.5 倍层高。支撑 X&#x2F;Y 距离：1-1.5 保存和预览点击右下角的切片，等待切片完毕后，可在预览界面预览打印效果、耗材用量及预计用时。拉动最右边进度条，可查看每层打印情况。点击右下角保存 gcode 文件准备打印。 特殊操作 偏好设置”—“基本”—“自动下降模型到打印平台” 假如只想打印一半模型，可解除 Z 轴限制，可使模型下降至负数。切片后只会打印平台上方部分。 3D 打印机问题总结平台上的蓝色纸有什么用处，用到什么程度需要更换？美纹纸，它的作用一是防止刮坏喷嘴，二让模型与平台粘接更稳。 由于打印材料的热胀冷缩效应，当打印大体积模型时，可能会发生翘边现象，建议打印前先贴上蓝色美纹纸，才开始打印。该纸可反复使用，直到破损或者明显粘不住模型为止。 大部分人都在用 PEI 喷涂的钢板作为底面。PEI 的特性是冷的时候不粘，热的时候具有一定的粘性。 新的 PEI 床和旧的自带的床。更换 PEI 后打印 PETG 就非常好用了。等床凉了以后轻轻一拿就可以从床上拿起来了，不像是原来那张床用铲子翘半天。 不过新床目前也是遇到了一些问题，就是打 PLA 没有原来粘了。所以用 PLA 打印第一层得时候需要压得更低一点，才能获得最佳得粘性。 哪些模型要加支撑？如何判断？ 红色位置是需要加支撑的位置，Cura 右侧可以设置支撑的相关参数 调平台这个步骤怎么确保距离调的 ok 呢？喷嘴距离平台距离太远或太近有什么区别？为什么模型打印过程中直接被拖走？ 首先在调节平台之前我们需要先保证 X 轴在丝杆上移动是水平的 喷嘴和平台的距离标准为一张 A4 纸的距离，如果不好判断，塞张纸在平台和喷嘴之间，以正常抽拉并附带阻力为标准； 在不会刮伤平台的前提下，调的越近模型粘的越牢固！ 我们还可以通过模型打印第一层的状态来判断距离是否调好，有以下三种情况： 1、正确的距离：扁平，无间隙，铺在平台上面很平整无毛刺,喷头与热床是最佳距离能保证打印出的耗材被紧压在热床上成平整的带状（扁皮状）。如图所示： 2、不正确的距离：细圆的，粘上去时铺的不均匀，有空隙和翘起，说明距离太远,耗材是靠重力作用垂到热床，形成圆润的条状，其黏附效果不佳，模型容易移动，打印效果非常不理想。如图所示： 3、不正确的距离：出丝时，压在平台上会出现中间薄两边有不规则突起（有毛刺）的，说明贴的太紧，或者可能造成无法出丝以及喷头移动时会刮带到之前打印的地方，相关形状如图所示： 以上情况均可以通过调节热床下方的弹簧来调整。 调节平台需要注意什么？而且每次打印前都需要检查平台吗？ 调节弹簧螺丝时，请注意按住下方的羊角螺母，不然在拧的过程中也会一起转动； 每次调完或检查平台操作后，都必须移动喷嘴在平台上走一圈，确保不会刮伤平台才能进行下一步操作； 虽然不需要您每次在打印前调节平台，但需要以 1 天 1 次作为周期性检查，平台距离合适； 为什么预热后上料？为何我感觉插到底了，下方喷嘴却不出丝？换料的时候需要注意哪些情况？ 上料时，如果喷头没有加热，耗材插到底也不会吐丝，客户就无法判断是否已正常上料，所以必须先预热，再上料！ 在上料时，插入进料口后一段距离感觉已经无法插入，但是喷头下方并没有出丝，因为在耗材在进入进料口后需要穿过挤出轮和压料轮中间后再进入下方喷嘴导料管，在上耗材的时候没有把耗材前段剪尖和捋直，导致耗材插入时没能直接进入下方导料口而被旁边阻挡，如图： 正确上料步骤：预热—剪尖并捋直耗材—下压螺丝—笔直插入耗材—出丝 每次打模型前都需要预热吗？提前预热的情况只有在进行换料前才需要提前预热，正常打印时，您只需要选择打印的模型文件即可自动加热； 模型打印过程中停电了能否继续打印？如果停电了模型直接终止打印，下次开机无法延续打印（但可以通过测量已打印高度，仅将未打印的部分切片进行打印，再粘上，仅适合非精密零件模型） 那中途可以暂停再继续打吗？看机器是否有设计暂停打印功能 在打印时暂停喷嘴依旧处于加热状态，耗材因重力作用会下垂流出，影响模型外观； 中途耗材用完怎么办？ 首先模型在软件进行切片转换格式的时候就会显示所需打印的时间，耗材长度以及重量，那您需要判断机器上余下的耗材能否支持本次打印完成，避免中途打印耗材用完； 若碰到耗材中途快用完，请在耗材还没进入进料口的时候及时的进行暂停，并迅速拔出剩余耗材，将新的耗材插入至喉管的深度即可 每次打完需要将耗材取出来做排空处理吗？不是，距离下次打印超过 72 小时，则需要排空处理； 喷头需要定期清理吗？需要！ 挤出头加热到指定温度后用最小号的内六角螺丝刀，压下进料弹簧，插入进料口，往下挤压，挤压的时候扳手插慢慢插到底时，来回挤压三次，扳手回抽不要过急或过长，插进去后小幅度的在里面挤压三次即可，再迅速拔出，空烧 1 分钟左右注意观察下方是否有东西流出，流完或没东西流出一分钟后请用我们配送的小捅针，从下方喷嘴插入，抽拉三次没东西流出即可；最后一步，请弄根新耗材，插入到底向下挤压出丝后猛的迅速拔出，尽量带出内壁附着物即可； 模型刚开始打印第一层就不出丝，怎么回事？如果这种情况发生在您刚才有换过耗材的情况下，那您需要确定耗材已上到底，并出丝；确保喷嘴是否顶到平台，导致无间隙空间吐丝； 打出来的模型很脆，外壁像网丝状，很脆，一捏就瘪了？此情况属于出丝量很小，需要检查以下几点： 拉料正常，料盘上的耗材没有打结等缠住现象； 耗材在进入导料管与喷嘴（加热管&#x2F;喉管）之前，要穿过一个 u 型轮和挤出电机齿轮中间，u 型轮压住耗材让齿轮把耗材往下挤送，u 型轮压住耗材的力量是由旁边的六角螺钉顶着弹簧的力度来决定的，螺丝扭紧弹簧弹性越大，u 型轮压料就越紧，反之越松， 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 齿轮本身带动耗材挤压也有许多因素，耗材从上往下经过齿轮的时候是否有在齿轮的中间，如果齿轮脱位，耗材在齿轮的牙边下去的，可能出现带不动耗材往下的情况而出丝不顺 模型打印时，突然在某一层高处整体向 X（左右）&#x2F;Y（前后）方向偏移？首先需要确定机器传动系统问题，再来排除软件参数和主板固件问题，排除方法如下： 首先需要判断你的模型摆放在平台上时，偏移的方向是 x（横向）还是 y（纵向），然后我们需要检查对应的 xy 轴的传动系统是否正常，第一先检查皮带是否松动脱落；第二检查同步轮固定螺丝是否松动 ① 带松动加紧： 首先，如果是 X 轴皮带松动，必须拉紧至绷紧状态，切平行； ②同步轮松动：Y 轴传动系统同步轮和 X 轴同步轮都需要检查到； 排除完机器问题，建议看下软件参数是否存在问题 例如检查是否是电机运动速度过快或出现阻碍导致的丢步 以上两点排除完毕，需要对主板固件程序进行重新烧录来解决问题 打印模型过程中中间断了几层，但是上面打印还可以？为什么模型突然中途就不出丝，喷嘴一直在空走打印不出丝？这几种问题都属于前期能正常打，但是中途不出丝的情况，这种情况需要从以下几点判断： 挤出电机接线口处四针排线松动，导致电机挤出齿轮来回正反转，耗材送不下去； 打印不出丝时，可以从电机右侧方弹簧方向往里面看到齿轮转到情况，如果齿轮来回摆动不定，说明接线出有问题，将接线拔掉重新插入尝试即可； 进料口旁螺丝太松或者太紧都有可能导致耗材挤出速度受到影响 耗材在料盘上缠住，导致进料不顺,检查料盘的耗材缠绕是否有拉扯住 喷嘴可能有残料堵塞,可以把喷头首先预热 230，一手按住进料口旁螺丝，一手快速挤压耗材（多送点丝），再迅速拔出，然后让喷嘴空烧一会儿，直到有黑色物质从喷嘴里流出，然后用钢丝从喷嘴端插入，抽拉，拔出，让里面剩余的耗材掉出，重复抽拉动作，直到喷嘴没料自然流出为止，最后上料，重新打印； 为什么打印模型在中途过程中，喷嘴周边缠着很多耗材，模型变成一团乱丝，不成形？这种情况分两种： 刚开始打印阶段，此情况一般是喷嘴和平台之间的距离过远，喷嘴出丝无法粘住平台，就会被喷嘴带走并一直出丝形成一坨； 打印过程中出丝不均匀，有断层现象，打印模型比实际高度低，超过一定间隙距离后出料正常是没附着下面的模型上面就会缠成一坨； 打印过程中喷嘴突然停止在打印模型上方不打印，并未回原点，怎么回事？ 切片问题,重新切片打印测试 内存卡松及读取问题 主板固件问题 为什么把模型保存在卡里是显示 ok，但插入机器后选择模型打印后不加热也没反应？为什么 SD 卡在电脑读取正常放入机器缺显示无卡？一般由于保存文件时的文件名上，切片完成后进行保存时文件名请使用英文字母或数字. 为什么 SD 卡在电脑读取正常放入机器缺显示无卡？这种问题首先要排除卡和卡槽是否正常配合，保证卡和卡槽读取正常，如果重新插入还是无法读取，可用您身边的内存卡保存文件插入机器是否能正常读取 为什么选择模型打印，机器没任何反应？或者加热了很久但是不打印？这种情况可能喷嘴冷却风扇提前开启，导致实际温度和设置温度总有 1-2 度差距，导致无法打印，请您选择停止打印并关掉风扇开关后，重新选择打印模型即可； 宽度 5mm 高度 6mm 的字体打得出来不,类似这种小模型需要修改哪些参数呢？小模型打印需要将速度和挤出量降低，模型可以打得更好看。比如打 5mm 左右的字体，可以采用 22 左右的速度配合 85 的挤出量来进行切片打印，温度采用 190 左右的即溶温度即可，这适合小模型打印哦； 为什么在打印模型时，某个位置会剧烈振动，机器声音很大？这种位置一般是模型实体部分的填充，特别是交窄的壁厚，填充为波浪形，打印速度很快的时候 xy 配合产生共振引起的 为什么在打印很大模型例如 190*190*180 和平台尺寸相近的模型时，喷头移动到某个方向极限值时，会有振动然后再改方向进行移动呢？打印前，喷嘴会在模型周围打一圈进行排空出料的操作，这样的话就实际增加了大模型的成型空间，导致直接碰到机箱，可以把此设置关掉即可 查看切片时是否有裙边设置 打印模型经常翘边问题怎么解决？PLA 与 ABS 通用原因： 喷嘴距离与平台太远，没能充分贴紧平台 模型与热床接触面积太小，导致附着力不够 解决办法：可增加 brim 或者 raft 垫子 ；打印 ABS 的话 Brim 效果更理想； 打印 ABS 时开了散热风扇。 解决办法：在打印是进入主界面的控制 – 温度 – 风扇速度 Bed 中由最高转速 255 改成 100 减少冷却效果，直接关闭风扇开关效果更理想； - 挤出头或热床温度不合适，挤出头温度不够可能导致挤出的材料流动性不够，无法完美的平铺在热床上，影响其粘滞力。热床温度过高也可能导致翘边，原因是材料受热流动性变大，不能稳固黏在热床上。 - 热床表面不干净。手的汗与油粘在胶带上，表面上看不见，但也导致表面打滑，影响黏附效果。这种情况在湿度大的南方比较常见。 ABS 材料很特殊因为它有一定的收缩率，打印较大的物体时，效果更佳明显，整体收缩导致底面翘起。最好能配合洞洞板。 显示屏下方显示 Err 报错，挤出头&#x2F;热床温度温度显示不正常？喷头上热敏电阻的接触不良或者损坏了 拆下热敏电阻，若是接触不良，则重新拔插接好；若是线的焊点脱落，用电烙铁焊好否则易损坏电阻；若是损坏，则更换新的热敏电阻。注：固定线时螺丝不宜拧过紧 这个黑色螺丝拧松，热敏电阻取出来，同时热敏电阻线也从主板上拔下来，用万用表测一下阻值，80-100K 正常 打完第一层，打印头在左边，要打上面一层的时候，打印头不是要回到右边的吗，回去的时候就会刮在之前打印的第一层上并留下一条线呢？那是距离平台过近，会刮到上一层打印的耗材 平台距离喷嘴近有利于粘住平台，不会翘边; 会轻微刮到上一层打印模型，但不影响模型成型过程，最多挂点料在喷嘴上挂着，然后在掉下来 模型平面上字体打出来效果不好怎么办？如果字写在模型上，此情况可以将模型竖起来打，层厚 0.1 能更为细腻的打出字体； 为什么从绘图软件里导出来的模型放在 cura 里显示不规整，弧面都是棱面组成的？在绘图软件里导出 stl 的时候会有二进制和 ASCⅡ，通常选择二进制并将角度和弦值设置默认最小值，但在 maya 等一些软件里，文件导出的时候 stl 格式是默认设置的，这是软件的特性，但是这个默认数值会随着你文件的建模时的网格细腻程度增加，也就是说文件平滑原本是一倍的，现在加到三倍导出来的 STL 就会比一倍的细腻很多 调试机器时选择自动丝出来都不是直的，是弯曲的?如果出丝是弯曲的 挤出量有关；挤出量一般由温度以及进料口旁边的螺丝松紧度有关，需要检查进料口旁边的螺丝 温度原因，1.风扇吹的 2.温度可以适当加高到 200 度左右 温度总是上不去或者不稳定？ 挤出头的热敏感应件没固定好在铝块里，打印的时候易松，导致探温不准； 导风嘴冷却风扇的风是吹到喷嘴下方的模型，如果没有调好就会吹到 喷嘴，导致温度下降； 如果出现以下情况是怎么导致？ 挤出齿轮底部缠料，一般是由此部位温度过高引起耗材变软，送丝过程中导致齿轮下部耗材折断而缠住； 遇到此情况首先需检查电机前方的方形冷却风扇是否工作以及叶片是否完整，避免冷却不够而导致堵料； 请检查耗材是否长时间未密封保存而变脆，取一段从中间这段，若折后显白痕且有韧性即正常，若折后直接啪的应声而断即已变脆； X 轴架构在 Z 轴电机丝杆控制上下过程中，会导致一边高一边低，每次都需要重新调节平台高度呢？ x 轴本身没有平衡，在移动过程中反应更明显； 请解决 X 轴调平问题； 黄色 T 型螺母太紧，导致 T 型螺母与丝杆紧配受力不均匀，移动不顺畅； 将固定 T 型螺母上的螺丝不要拧紧，留半个螺纹的缝隙，给予缓冲，再将 x 轴调至平衡，移动 z 轴电机调试！ x 轴光杆太长，没有完全捅到底去，顶住丝杆，导致移动不顺 检查光杆插入深度； 将 Z 轴两边的两个光杆去掉，控制电机上升是否正常，排除光杆弯曲配合滑动轴承配合不顺问题（可以单独将光杆插入滑动轴承，上下移动是否顺滑） 更换光杆或者滑动轴承 以上问题都检查后就可能: 移动不顺畅的丝杆部分弯曲或者螺纹损伤，更换丝杆 在更新固件后，挤出电机齿轮检测出反转，无法正常下料 固件中电机引脚配置反了 拔出挤出电机后端电机线接口，按照现在正常 1234 线序，把其中‘一组’12 对调或者 34 对掉即可 如果模型摆放在软件里为中心点，但在实际打印过程中并不在平台中间；因为机器喷嘴回原点的时候并不在热床平台上方而是在外面，而 cura 软件的机器设置里原点就在平台某个角的正上方，为了补偿原点所在误差，需要将软件的平台设置扩大，才能让模型打印在正中间，如图操作更改即可： 加热后拔料感觉扯不出来，也无法下压了铝块融化处剩余耗材口径较大，加热后直接上拉耗材，易堵在口径较小的喉管处，并迅速冷却，以至堵塞喉管 预热达到温度后，一只手按住进料口旁边的螺丝，另一只手将耗材往下挤压，让前端耗材挤出一段距离后，再迅速拔出耗材即可避免堵塞喉管 选择自动回原点时，当喷头移动至限位开关的时候，电机一直不停的往前走，撞击限位开关并抖动，这是怎么回事？ 您需要检查在部件回原点触碰到限位开关之前是否有东西挡住它前进才无法触碰到限位开关而不停止运动； - 可能是限位开关坏了导致的，检查方法是将每个轴的移动部件移至轴中部，选择自动回原点，在部件向原点限位开关移动的过程中，请按住限位开关，观察部件是否停止移动，如果没有停止，请马上切断电源，基本上可以确定限位开关问题 为什么 X 轴上的喷头在移动过程中，一顿一顿的，特别是在回原点的时候，移动时几乎在抖动很不顺畅？ 排除下电机线与电机的问题：拆卸底板：需要用万用表检查 x 轴四根电机线是否都是通路，如果正常就是电机本身问题； 可以断电后手动运动下挤出头，是否丝杆或滑块中的钢珠生锈导致运动不流畅 超出打印范围安装软件的时候初始设置选择错误机型导致的，重新设置机型即可 不粘床，找平 自动找平后，但有的时候打印出来的第一层还是和床粘的不紧密 Z Offset 设置也会影响粘不粘床。 其中白色部分为压力传感器（BLTouch），右边蓝色硅胶罩下面的为喷头 可以看到左边白色的压力传感器的高度和右边蓝色硅胶套下面的喷嘴是不在一个高度的。设置喷嘴和床之前的距离是以压力传感器的反馈为准的。但是压力传感器测到的距离是传感器本身到床的距离，并不是喷嘴到床的距离。所以压力传感器到喷嘴之间的高度差就是 Z Offset，需要通过调整它来设置合适的喷嘴高度。 手动调平 需要用到一张纸，一般打印用的 A4 即可。 然后在床的中点进行 Z Offset 调整，在四个角落（螺丝位置）手动调整床的高低。具体步骤如下： 中点 Z-Offset 调整 首先通过控制面板将喷嘴移动到床的中间的正上方，接下来将纸放喷嘴下方的床上，紧接着慢慢将 Z 轴的高度降低到 0（如果降不下去不要硬来），喷嘴可能会压住纸或者没碰到纸；尝试前后不停的移动纸张。 如果纸张能移动并且刚好有一点阻力就是合适的喷嘴高度不需要调节，通常而言不会那么顺利；如果如果喷嘴完全没碰到纸张，或者纸张移动完全没有任何阻力，可以尝试通过调整 Z-Offset ，一点点降低喷嘴高度。直到达到上述的移动纸张有一点点阻力的状态；如果纸张被压的很死无法动弹，则先将 Z 轴升高到 5mm 然后尝试调整 Z-Offset 升高喷嘴，然后再继续尝试慢慢降低 Z 轴到 0mm，反复调整直到移动纸张有一点点阻力的状态。 使用一张纸来手动找到喷头合适高度的方法。但是这个能移动但是有一点点阻力状态有点模糊，它并不是一个固定的点，是一段区间内都可以感觉到能移动但是有摩擦力。我建议是选摩擦力稍微轻一点的力度的点，这样喷嘴高度较高，后面调整的时候不容易刮伤床上的底板。 四周螺丝调整 在中间确定了最基本的 Z 轴的高度之后则需要物理调整四周的螺丝了，调整四周的螺丝需要按照顺序一个一个的调整，并且需要多次调整和确认，具体步骤如下： 首先抬起 Z 轴让喷嘴距离床大概 5mm 的距离，再移动到任意一个距离调整螺母的正上方，将纸放在喷嘴正下方的床上，紧接着一点点尝试往下移动 Z 轴到 0mm，和上面一样如果降不下去不要硬来；接下来就和上面一样，尝试移动不停的前后移动纸张，如果处于能移动但是有摩擦力的状态则是合适的，如果完全没碰到纸张，在移动纸张的同时旋转下方的螺丝来物理调节这个角落的高度，直到纸张处于能移动但是有摩擦力的状态。最后将 Z 抬起到 5mm 左右，顺&#x2F;逆时针移动到下一个调节螺母的上方，重复以上步骤。 上面步骤是单个角落手动物理调整床高度的方法，完成四个点（上图的床只有四个螺丝，有几个螺丝就校准几个点）为一个循环。因为打印机的床是一个固体，所以当你上下移动某一个角落的高度的时候另外三个角落的高低也是会受到影响的，尤其是相邻的两个角落。所以这里需要多个循环来拧螺丝调整各个角落的高度，直到四个角落的高度都合适的情况，即为纸张能移动但是有阻力的状态。 在拧玩螺丝校准完四个角落的高度后，需要再次通过 Z-Offset 校准中间喷嘴的高度。因为在调整四角的螺丝的时候可能会整体抬高或者降低了床的高度，所以中间的喷嘴高度需要再一次校准。重复上面中点 Z-Offset 校准即可。 如果固件自带自动找平还是比较简单的，选择自动找平等就好了。虽然手动找平完之后床基本上是处于可以用的状态了，但是便宜的桌面打印机的床它本身可能就是凹凸不平的，所以需要自动找平来弥补床本身的凹凸起伏的部分。如果没有自动找平的打印机就没有太好的办法避免这个了。只能通过稍微压低一点点喷嘴来做到尽量都粘到床。 测试调平是否成功 在做完上述的调整后就可以进行最终的调整了。这一步是通过打印一些模型来确认喷嘴的高度是否合适。 虽然用纸调整好了喷嘴的高度，但是纸有薄有厚，调整出来的喷嘴高度并不一定是最好的打印高度，所以最终还是需要通过打印来调整。 打印测试时尽量选择有颜色的材料，透明透明材料会看不清楚第一层有没有打好，在打印模型的时候，手需要在电源附近随时待命。在喷嘴高度设置错误或者床不平的时能及时停止打印机降低损失。 打印出来的模型主要是用来检查喷嘴的高度和床是否倾斜的，四周的圆柱和绕场一周的线条用来检查床的倾斜度。 外围线条如果高低不平均，薄的那边就是较高的地方，厚的那边则是较低的地方。四角的圆柱则可以和上述的 Raise 3D 的示意图来比较确认喷头的高度是否合适。如果不合适可能需要重新手动找平。中间的圆形是确认喷嘴高度用的。同样通过对比来观察高度是否合适，如果床并没有很严重的倾斜，则只需要调整 Z-Offset 来移动喷嘴。然后重新打印确认。如果确认床有倾斜，就要重新走一遍手动找平的流程的了，然后重新打印确认。 当然找平也不是一定完美的。但是有自动找平后，整个过程还是比较简单的。但是也有无论怎么调整，都觉得床有倾斜或者高度不对的时候。这里就要分两种情况讨论了。如果能正常打印不想折腾了就选一个能调整到的最好的状态直接用吧。如果严重到了无法打印的程度，则需要检查打印的装配是不是有问题了。 过度挤出 打印出来的东西都有奇怪的纹理。而且质量也参差不齐。 检查之后是 klipper 配置里面的挤出机的「roration_distance」配错了。导致挤出机往外挤的时候给了远比正常情况多的料，进而溢出到边缘产生了神奇的纹理。 Klipper 配置里面的挤出机转一圈挤多少料这些东西都需要自己配置。所以配置挤出参数时是需要校准的，当你给指令让他挤 100mm 的材料的时候，他应该就挤出来 100mm 左右的材料。没有校准所以导致了非常严重的过度挤出，配置正确后打印的东西表面的问题就漂亮多了。 正常挤出打印的零件的表面质感 材料与环境湿度由于 FDM 3D 打印件一般都需要将材料加热到 200 摄氏度或以上的温度才能打印，所以当材料通过热端的时候，其中的水蒸气会蒸发出来，造成喷嘴里面的材料有间隙，这些现象还会造成打印件在物理特性上的改变： 水汽膨胀造成挤出原料不均匀导致的表面粗糙 水汽膨胀造成材料之间有很多空隙导致的强度下降 水汽膨胀喷嘴中黏在一块的材料有缝隙，导致拉丝。 材料均需要密封干燥保存！买干燥盒 主要成分简称 推荐打印喷嘴温度 推荐打印床温度 特点 PLA 190˚C – 230˚C 25˚C-60˚C 易受潮 TPU 200˚C – 210˚C 50˚C 易拉丝 PETG 230˚C – 240˚C 70˚C – 80˚C ABS 245˚C – 265˚C 90˚C – 100˚C 有毒 ASA 240˚C – 260˚C 75˚C – 95˚C PC 250˚C – 270˚C 90˚C – 105˚C PA6 250˚C – 270˚C 25˚C – 50˚C PA6-CF 280˚C – 300˚C 25˚C – 50˚C","categories":["3.软件","3D打印机"]},{"title":"CANOpenNode 代码分析","path":"/2024/05/28/2-通讯协议-CAN-CANOpenNode-代码分析/","content":"主文件 CO_main_basic.c进入 Main 函数中运行，最开始都是一些关于存储&#x2F;多线程&#x2F;功能启用部分的配置代码，后面我们会根据宏定义来讲解。实际的第一行初始化代码从以下开始。 123uint32_t heapMemoryUsed = 0;CO_config_t *config_ptr = NULL;CO = CO_new(config_ptr, &amp;heapMemoryUsed); 该函数的作用是创建一个 CAN open 对象，在单个 OD 的情况下，config 应为 NULL，参数从默认的 “OD.h “文件中获取。如果定义了 CO_USE_GLOBALS，那么函数将为所有 CANopenNode 对象使用全局静态变量。否则，它将从堆中分配所有对象。 12CO_epoll_t epMain;err = CO_epoll_create(&amp;epMain, MAIN_THREAD_INTERVAL_US); 该函数创建 Linux epoll 监控 timerfd 和 eventfd。创建并配置多个 Linux 通知，以触发任务的执行。CO_epoll_create 中实现了 epoll 拦截并监控多个文件描述符，其中 timerfd 以恒定的定时器间隔触发，eventfd 则根据外部信号触发。 123CO_CANptrSocketCan_t CANptr = &#123;0&#125;;CANptr.can_ifindex = if_nametoindex(&quot;can0&quot;);CANptr.epoll_fd = epMain.epoll_fd; 设置用于 CO_CANinit 的指针参数，主要传入 CAN 设备名和监控的 epoll 描述符。 之后进入 CAN open 通讯初始化阶段，注意该阶段是可以通过 0x82 命令，即 CANopen communication reset 重置的。 12CO_CANsetConfigurationMode((void *)&amp;CANptr);CO_CANmodule_disable(CO-&gt;CANmodule); 进入 CAN 配置，主要还是在通过 0x82 命令重启后，禁用 CANmodule 模块。 1err = CO_CANinit(CO, (void *)&amp;CANptr, 0 /* bit rate not used */); 初始化 CAN 驱动，如果是通过 0x82 命令重启的通讯，也必须重新初始化。其中的波特率参数在 Linux 部分中还不被支持。之后是 LSS 部分的初始化，该部分内容属于 CiA 305，先略过，之后有时间在分析实现。 123456789101112131415161718#define NMT_CONTROL \\ CO_NMT_STARTUP_TO_OPERATIONAL \\ | CO_NMT_ERR_ON_ERR_REG \\ | CO_ERR_REG_GENERIC_ERR \\ | CO_ERR_REG_COMMUNICATION err = CO_CANopenInit(CO, /* CANopen object */ NULL, /* alternate NMT */ NULL, /* alternate em */ OD, /* Object dictionary */ NULL, /* Optional OD_statusBits */ NMT_CONTROL, /* CO_NMT_control_t */ 500, /* firstHBTime_ms */ 1000, /* SDOserverTimeoutTime_ms */ 500, /* SDOclientTimeoutTime_ms */ false, /* SDOclientBlockTransfer */ CO_activeNodeId, //Node ID &amp;errInfo); 初始化除 PDO 对象外的 CAN open 通讯协议（同样也必须在 0x82 命令后调用）。 CO CANopen 对象。 em 紧急对象，用于不同的 CANopen 对象内部，通常用于错误报告。如果为空，则使用 co-&gt;em。如果为空，且 co-&gt;CNT_EM 为 0，则函数错误返回。 NMT 如果 co-&gt;CNT_NMT 为 0，则必须指定该对象；如果 co-&gt;CNT_NMT 为 1，则该对象将被忽略，可以为 NULL。NMT 对象用于 NMT 对象用于在 CO_process()内部检索 NMT 内部状态。 od CANopen 对象字典。之前有提到的 ODxyz.h 中定义。 OD_statusBits 传递给 CO_EM_init() 的参数。可以为空。 NMTcontrol 传递给 CO_NMT_init() 的参数。 firstHBTime_ms 传递给 CO_NMT_init() 的参数。 SDOserverTimeoutTime_ms 传递给 CO_SDOserver_init() 的参数。 SDOclientTimeoutTime_ms SDO 客户端的默认超时时间毫秒，一般为 500。 SDOclientBlockTransfer 如果为 “true”，则默认在 SDO 客户端设置块传输。 nodeId CANopen 节点 ID（1 … 127）或 0xFF（未配置）。在 CANopen 初始化中，它与 CO_LSSinit() 中的 pendingBitRate 相同。如果为未配置，则某些 CANopen 对象将不会被初始化或处理。 errInfo 也可以在函数返回 CO_ERROR_NO 的非关键错误中设置。 成功时返回 CO_ERROR_NO。 1CO_epoll_initCANopenMain(&amp;epMain, CO); 该函数用于配置 CAN 接收后的自定义回调。自定义回调函数可由应用程序选择性注册，并在操作系统中配置线程。回调函数会在高优先级线程预处理完某些内容后调用，并且必须由低优先级线程进一步处理。例如，当接收到 CAN 报文并进行预处理后，回调应唤醒主线程处理函数。 123CO_EM_initCallbackRx(CO-&gt;em, EmergencyRxCallback);CO_NMT_initCallbackChanged(CO-&gt;NMT, NmtChangedCallback);CO_HBconsumer_initCallbackNmtChanged(CO-&gt;HBcons, 0, NULL, HeartbeatNmtChangedCallback); CO_EM_initCallbackRx，初始化 Emergency 接收回调函数。该函数在收到错误条件后执行。 CO_NMT_initCallbackChanged，初始化 NMT 状态变化回调函数。该函数在 NMT 状态发生变化后被调用。该函数可能会唤醒处理 NMT 事件的外部任务。第一次调用会立即向消费者提供 当前的 NMT 状态。 CO_HBconsumer_initCallbackNmtChanged，初始化心跳消费者 NMT 更改回调函数，当 NMT 状态发生变化时调用的回调函数。 1CO_TIME_set(CO-&gt;TIME, time_ms, time_days, TIME_STAMP_INTERVAL_MS); 设置当前时间，并设置生产者的间隔时间为 TIME_STAMP_INTERVAL_MS，以毫秒为单位，此处设置为 10000ms。 12345err = CO_CANopenInitPDO(CO, /* CANopen object */ CO-&gt;em, /* emergency object */ OD, /* Object dictionary */ CO_activeNodeId, &amp;errInfo); 必须在通信重置 0x82 部分的末尾调用该函数，否则某些 OD 变量将无法正确映射到 PDO 中。函数参数就是 CAN Open 对象，EM 对象，OD 对象，NodeID 以及错误信息这些。 1CO_CANsetNormalMode(CO-&gt;CANmodule); 已完成所有对象初始化，设置状态，准备进入主循环函数。在主循环函数中，通过 epoll 监控多个文件描述符。 1234CO_epoll_wait(&amp;epMain);CO_epoll_processRT(&amp;epMain, CO, false);CO_epoll_processMain(&amp;epMain, CO, GATEWAY_ENABLE, &amp;reset);CO_epoll_processLast(&amp;epMain); CO_epoll_wait 函数会阻塞，直到 epoll 上注册了以下事件：timerfd、eventfd 或应用程序指定的事件。函数还会计算自上次调用以来的 timeDifference_us 并准备 timerNext_us。 CO_epoll_processLast，epoll 事件的关闭函数，此函数必须在 CO_epoll_wait() 之后调用。在它们之间是应用程序指定的处理函数，可以检查自己的事件并进行处理。应用程序还可以降低 timerNext_us 变量的值。如果将 timerNext_us 变量调低，则将重新配置间隔定时器，并提前触发 CO_epoll_wait()。 CO_epoll_processRT 和 CO_epoll_processMain 指定了处理函数，接下来先说明 CO_epoll_processRT 处理函数。 123456//CO_CANrxFromEpoll 如果 epoll 事件与任何 CAN 接口匹配，则返回 True。CO_CANrxFromEpoll(co-&gt;CANmodule, &amp;ep-&gt;ev, NULL, NULL);syncWas = CO_process_SYNC(co, ep-&gt;timeDifference_us,pTimerNext_us);CO_process_RPDO(co, syncWas, ep-&gt;timeDifference_us,pTimerNext_us);CO_process_TPDO(co, syncWas, ep-&gt;timeDifference_us,pTimerNext_us); 在 CO_epoll_processRT 中处理以上的 SYNC&#x2F;TPDO&#x2F;RPDO 协议。 1234567891011CO_CANmodule_process(co-&gt;CANmodule);CO_EM_process(co-&gt;em, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_NMT_process(co-&gt;NMT,&amp;NMTstate,timeDifference_us,timerNext_us);CO_SDOserver_process(&amp;co-&gt;SDOserver[i], NMTisPreOrOperational, timeDifference_us,timerNext_us);CO_HBconsumer_process(co-&gt;HBcons, NMTisPreOrOperational, timeDifference_us, timerNext_us);CO_TIME_process(co-&gt;TIME, NMTisPreOrOperational, timeDifference_us); 在 CO_epoll_processMain 中处理了以上的 EM&#x2F;NMT&#x2F;SDOServer&#x2F;HB&#x2F;TIME 协议。 CO_SINGLE_THREAD该参数在 Makefile 中通过-D 参数指定，作用是配置程序在单线程中运行。单线程运行时不同的事件（例如 CAN 接收或计时器到期）会触发循环通过堆栈（所有代码都是非阻塞的）。它需要较少的系统资源。 在多线程操作中，除了主线线程外，还建立了一个实时线程。RT 线程每毫秒运行一次，并使用外围设备读&#x2F;写、控制程序或类似程序处理 PDO 和可选应用程序代码。使用此配置必须考虑竞争条件，例如，从主线线程运行的应用程序代码在访问 OD 变量时必须使用 CO_(UN)LOCK_OD 宏。 CO_CONFIG_STORAGE该参数由 CO_CONFIG_STORAGE_ENABLE 在 CO_config.h 中使能，主要作用是依据 CiA 301 标准对控制数据进行存储和恢复。数据源通常是对象字典中的一组变量，但并不局限于 OD。在生成对象字典（OD.h 和 OD.c 文件）时，会根据 “存储组 “参数将 OD 变量分组为结构。 OD 对象 0x1010 - 存储参数OD 对象 0x1010 - 存储参数： 子索引 0：支持的最高子索引 子索引 1：保存所有参数，UNSIGNED32 子索引 2：保存通信参数，UNSIGNED32 子索引 3：保存应用参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其存储功能的信息： 位 0：如果设置，CANopen 设备根据命令保存参数 位 1：如果设置，CANopen 设备自主保存参数 写入值 0x65766173（’s’、’a’、’v’、’e’，从 LSB 到 MSB）可存储相应数据。相应数据。 OD 对象 0x1011 - 恢复默认参数 子索引 0：支持的最高子索引 子索引 1：恢复所有默认参数，UNSIGNED32 子索引 2：恢复通信默认参数，UNSIGNED32 子索引 3：恢复应用程序默认参数，UNSIGNED32 子索引 4 - 127：特定于制造商，UNSIGNED32 子索引 1 及以上： 读取提供有关其恢复能力的信息： 位 0：如果设置，CANopen 设备恢复参数 写入值 0x64616F6C（’l’、’o’、’a’、’d’从 LSB 到 MSB）可恢复相应数据。相应数据。 CO_CONFIG_GTW网关对象由标准 CiA 309 - CANopen 从其他网络访问涵盖。它可以将 NMT 主站、SDO 客户端和 LSS 主站用作网关设备。 本次使用中不支持该形式，直接在 CO_config.h 中注释掉该模块即可。 数据字典 OD 操纵CANopen 数据字典 OD 基本上是一个 XML 文件，其中包含 CANopen 设备的所有信息。文件的大部分是所有对象字典变量的列表，其中包含所有必要的属性和文档。该文件可使用 OD 编辑器应用程序进行编辑，并可用作数据源，从中生成 CANopenNode 的对象字典。该文件还可用于 CANopen 配置工具，在运行的 CANopen 网络上与 CANopen 设备进行交互。 CANopen 还为 CANopen 设备描述指定了另一种类型的文件。它们是 INI 格式的 EDS 文件。可以在这两种格式之间进行转换。设备描述文件的扩展名为 “XDD”。该文件的名称应包含 CANopen 设备的供应商 ID，以 8 位十六进制数字的形式出现在名称的任意位置，并用下划线分隔。例如 “name1_12345678_name2.XDD”。CANopenNode 包含多个配置文件定义文件，每个 CANopen 对象一个。这些文件的扩展名为 “XPD”。它们采用与 XDD 文件相同的 XML 格式。XML 编辑工具可以使用 XPD 文件将准备好的数据插入正在编辑的设备描述文件 (XDD)。还有扩展名为 “XDC “的设备配置文件。这些文件描述了已配置的 CANopen 设备，并包含其他元素，如默认值、分母和设备调试元素。类似于 INI 格式的 “dcf “文件。 使用OD object是指对象字典中位于特定 16 位索引的对象。CANopen 中有不同类型的 OD 对象：变量、数组和记录（结构）。每个 OD 对象都包含指向实际数据、数据长度和属性的指针。在 OD_objectTypes_t 中被定义。 OD variable 是指定类型的基本变量。例如：int8_t、uint32_t、float64_t……或数据长度已知或未知的二进制数据序列。每个 OD 变量都以指定的 16 位索引和 8 位子索引存在于对象字典中。 OD entry指的是结构元素，其中包含 OD 对象的一些基本属性、OD 对象的类型指示以及指向 OD 对象所有必要数据的指针。OD 条目数组以及 OD 条目总数信息代表 CANopenNode 内部定义的对象字典。参见 OD_entry_t 和 OD_t。 应用程序和堆栈可通过通用的 OD_t 对象和 OD_find() 函数访问 OD 对象。无需直接访问定义对象字典的自定义结构。特定 OD 变量的属性可通过 OD_getSub()函数获取。通过 read 和 write 函数访问实际变量。 OD_getSub() 可以获取这两个函数的指针。参见 OD_stream_t。另请参见快捷方式： CO_ODgetSetters 用于访问不同类型的数据。 可以从不同的线程访问 OD 变量。CANopenNode 基本上在两个线程中运行：快速实时线程（PDO 处理等）和非关键时间主线程（SDO 等）。两个线程都可以访问 OD 变量，因此必须小心谨慎。CANopenNode 使用锁定机制，SDO 服务器在读取或写入 OD 变量时会阻止实时线程的执行。在 CO_storage 中也需要对 OD 变量进行同样的保护。更多信息请参见 CO_driver.h 中的 CO_critical_sections。 OD 文件-ODxyz.c&#x2F;.h一个 CANopen 设备的实际对象字典由一对 OD_xyz.h 和 ODxyz.c 文件定义。 后缀 “xyz “是对象字典的唯一名称。如果使用单个默认对象字典，则省略后缀。这样就可以配置多个对象字典。 用于定义 OD 的数据安排在多个结构中。不同的 OD 配置有不同的结构。用这些结构创建的数据对象可以是常量，也可以是变量。 实际的 OD 变量位于多个结构（即存储组）中。选定的组可以选择存储到非易失性存储器中。 手动编辑 ODxyz.h&#x2F;.c 文件非常容易出错。 OD 编辑工具可生成成对的 ODxyz.h&#x2F;.c 文件。该工具可以编辑 xml 格式的标准 CANopen 设备描述文件。Xml 文件可能还包括一些 CANopenNode 特有的非标准元素。然后，Xml 文件将用于自动生成 ODxyz.h&#x2F;.c 文件。 1234567891011121314151617181920212223242526272829303132/* OD data declaration of all groups ******************************************/typedef struct &#123; uint32_t x1000_deviceType; struct &#123; uint8_t maxSubIndex; uint32_t vendorID; uint32_t productCode; uint32_t revisionNumber; uint32_t serialNumber; &#125; x1018_identity;&#125; ODxyz_PERSIST_COMM_t;typedef struct &#123; uint8_t x1001_errorRegister; uint8_t x1003_preDefinedErrorField_sub0; uint32_t x1003_preDefinedErrorField[8];&#125; ODxyz_RAM_t;extern ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM;extern ODxyz_RAM_t ODxyz_RAM;extern OD_t *ODxyz;/* Object dictionary entries - shortcuts **************************************/#define ODxyz_ENTRY_H1000 &amp;ODxyz-&gt;list[0]#define ODxyz_ENTRY_H1001 &amp;ODxyz-&gt;list[1]#define ODxyz_ENTRY_H1003 &amp;ODxyz-&gt;list[2]#define ODxyz_ENTRY_H1018 &amp;ODxyz-&gt;list[3]#define ODxyz_ENTRY_H1000_deviceType &amp;ODxyz-&gt;list[0]#define ODxyz_ENTRY_H1001_errorRegister &amp;ODxyz-&gt;list[1]#define ODxyz_ENTRY_H1003_preDefinedErrorField &amp;ODxyz-&gt;list[2]#define ODxyz_ENTRY_H1018_identity &amp;ODxyz-&gt;list[3] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#define OD_DEFINITION#include &quot;301/CO_ODinterface.h&quot;#include &quot;ODxyz.h&quot;/* OD data initialization of all groups ***************************************/ODxyz_PERSIST_COMM_t ODxyz_PERSIST_COMM = &#123; .x1000_deviceType = 0, .x1018_identity = &#123; .maxSubIndex = 4, .vendorID = 0, .productCode = 0, .revisionNumber = 0, .serialNumber = 0 &#125;&#125;;ODxyz_RAM_t ODxyz_RAM = &#123; .x1001_errorRegister = 0, .x1003_preDefinedErrorField_sub0 = 0, .x1003_preDefinedErrorField = &#123;0, 0, 0, 0, 0, 0, 0, 0&#125;&#125;;/* All OD objects (constant) **************************************************/typedef struct &#123; OD_obj_var_t o_1000_deviceType; OD_obj_var_t o_1001_errorRegister; OD_obj_array_t o_1003_preDefinedErrorField; OD_obj_record_t o_1018_identity[5];&#125; ODxyzObjs_t;static CO_PROGMEM ODxyzObjs_t ODxyzObjs = &#123; .o_1000_deviceType = &#123; .dataOrig = &amp;ODxyz_PERSIST_COMM.x1000_deviceType, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, .o_1001_errorRegister = &#123; .dataOrig = &amp;ODxyz_RAM.x1001_errorRegister, .attribute = ODA_SDO_R, .dataLength = 1 &#125;, .o_1003_preDefinedErrorField = &#123; .dataOrig0 = &amp;ODxyz_RAM.x1003_preDefinedErrorField_sub0, .dataOrig = &amp;ODxyz_RAM.x1003_preDefinedErrorField[0], .attribute0 = ODA_SDO_RW, .attribute = ODA_SDO_R | ODA_MB, .dataElementLength = 4, .dataElementSizeof = sizeof(uint32_t) &#125;, .o_1018_identity = &#123; &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.maxSubIndex, .subIndex = 0, .attribute = ODA_SDO_R, .dataLength = 1 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.vendorID, .subIndex = 1, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.productCode, .subIndex = 2, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.revisionNumber, .subIndex = 3, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125;, &#123; .data = &amp;ODxyz_PERSIST_COMM.x1018_identity.serialNumber, .subIndex = 4, .attribute = ODA_SDO_R | ODA_MB, .dataLength = 4 &#125; &#125;&#125;;/* Object dictionary **********************************************************/static OD_entry_t ODxyzList[] = &#123; &#123;0x1000, 0x01, ODT_VAR, &amp;ODxyzObjs.o_1000_deviceType, NULL&#125;, &#123;0x1001, 0x01, ODT_VAR, &amp;ODxyzObjs.o_1001_errorRegister, NULL&#125;, &#123;0x1003, 0x09, ODT_VAR, &amp;ODxyzObjs.o_1003_preDefinedErrorField, NULL&#125;, &#123;0x1018, 0x05, ODT_REC, &amp;ODxyzObjs.o_1018_identity, NULL&#125;, &#123;0x0000, 0x00, 0, NULL, NULL&#125;&#125;;OD_t _ODxyz = &#123; (sizeof(ODxyzList) / sizeof(ODxyzList[0])) - 1, &amp;ODxyzList[0]&#125;;OD_t *ODxyz = &amp;_ODxyz; OD_find 查找指定对象123456789101112131415161718192021222324252627282930313233extern OD_t *ODxyz;void myFunc(OD_t *od) &#123; ODR_t odRet;//保存对象字典操作的返回值。 OD_entry_t *entry;//指向对象字典条目的指针。 OD_IO_t io1008;//用于对象字典I/O操作的结构体。 char buf[50]; OD_size_t bytesRd;//存储读取的字节数。 int error = 0; // 查找并初始化0x1008条目和其子索引0x00的IO结构体 entry = OD_find(od, 0x1008);//查找对象字典中的条目。 odRet = OD_getSub(entry, 0x00, &amp;io1008, false);//获取对象字典条目的子索引。 // 读取制造商设备名称 if (odRet == ODR_OK) &#123; /* Locking is necessary from mainline thread, but must not be used from * timer interval (real-time) thread. Locking is not necessary in the * CANoopen initialization section. Locking is also not necessary, if * OD variable is not mappable to PDO and not accessed from RT thread.*/ CO_LOCK_OD(CANmodule); odRet = io1008.read(&amp;io1008.stream, &amp;buf[0], sizeof(buf), &amp;bytesRd);//读取子索引的数据。 CO_UNLOCK_OD(CANmodule); &#125; if (odRet != ODR_OK) error++; /* Use helper and set &quot;Producer heartbeat time&quot; at index 0x1017, sub 0x00 */ // 设置生产者心跳时间 CO_LOCK_OD(CANmodule); /* may not be necessary, see comment above */ odRet = OD_set_u16(OD_find(od, 0x1017), 0x00, 500, false);//设置对象字典条目的子索引值。 CO_UNLOCK_OD(CANmodule); if (odRet != ODR_OK) error++;&#125; 直接根据结构体查找 OD 对象如何直接访问和操作 CANopen 对象字典（Object Dictionary）中的条目，而不是通过查找函数 OD_find 来间接访问。直接访问对象字典条目和变量比通过函数查找要快，因为它避免了函数调用和查找过程。 对象字典的头文件 ODxyz.h，其中定义了对象字典的所有条目和相关结构。 123456789#include &quot;ODxyz.h&quot;void myFuncGlob(void) &#123; // Direct address instead of OD_find() OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; // Direct access to OD variable uint32_t devType = ODxyz_0.x1000_deviceType; ODxyz_0.x1018_identity.serialNumber = 0x12345678; &#125; OD_entry_t *entry_errReg = ODxyz_1001_errorRegister; 直接获取对象字典中 0x1001 索引（错误寄存器）的条目指针 entry_errReg。这里使用的是直接声明的指针 ODxyz_1001_errorRegister，而不是通过 OD_find 函数查找。 uint32_t devType = ODxyz_0.x1000_deviceType; 直接读取对象字典中 0x1000 索引（设备类型）的变量 ODxyz_0.x1000_deviceType，并将其存储到本地变量 devType 中。ODxyz_0.x1018_identity.serialNumber = 0x12345678; 直接修改对象字典中 0x1018 索引（设备标识）的 serialNumber 字段，将其设置为 0x12345678。 如果 OD 对象已启用 OD 扩展，则不得直接访问其 OD 变量。只有通过读、写或辅助函数访问才有效。 修改 PDO 固定长度在 PDO 协议中，数据的接收是严格按照 PDO 中映射的数据长度来读取的，当数据不足时，该数据帧会被丢弃，当数据过长时，该数据帧会被截断。 在此次的应用程序中，由于该设备配置的 PDO 存在两种长度数据，所以需要将 PDO 的数据长度更改为兼容自定义的两种数据长度。 在 CO_PDO.c 文件中，有 RPDO 处理函数 CO_RPDO_process，其中的 for 循环，当小于 PDO-&gt;mappedObjectsCount 数量时，执行 1byte 的拷贝，所以此处我们需要修改为当 i&lt;CO_PDO_MAX_SIZE 时执行拷贝，即对 PDO 中所有的数据进行拷贝，不管该字节是否有数据。","categories":["2.通讯协议","CAN"]},{"title":"博客部署相关服务","path":"/2024/05/25/0-平台-服务器-博客部署相关服务/","content":"Github 托管服务Github 是一个著名的互联网托管服务，用于软件开发和使用 Git 的版本控制。一直拥有各种奇怪的用途，被发掘出来当图床也见怪不怪了。 加速访问方案 GitHub加速访问 你可以上传各种类型的文件，只要 github 接受它们。当你在笔记中提到一个共享的文件时，比如图片&#x2F;脚本、配置文件或任何东西时， 能很好地将其嵌入到 markdown 文件中。 文件链接是否能在 Obsidian 中呈现，取决于 obsidian 本身的支持情况。没关系，即使它们不能被渲染，它们仍然可以作为链接使用。只要去掉开头的感叹号就可以了。速度方面国内可以接受，海外速度很快 域名：user-images.githubusercontent.com 上传方式是新建一个 Repo，然后在 Issue 中传图（直接将图片拖动到 issue 输入框即可），GitHub 会将你的图片分发到 GitHub 用的 CDN 中。 这和使用 GitHub Raw 需要 GitHub 的服务器动态生成文件不同，user-image 这个子域名是 GitHub 专门为静态文件准备的，当然，这个接口不是公开的。善待 GitHub。 NetlifyRailwayhttps://railway.app/ Railway 提供免费容器服务。支持主流语言 python、nodejs 等直接运行，支持 Dockerfile 在线构建 docker 镜像。支持使用 CLI 部署。此外，还提供大量模板直接构建。例如 code server（vscode 网页版）等。 不自动休眠，不自动删数据（手动重新部署当然会删），支持自定义域名，自动 SSL 加密。 提供数据库支持，部署完成之后添加数据库插件即可。 按量付费，每个月 5 美元免费额度，跑个小程序够用。具体可以参考定价。 部署railway 支持三种部署方式： 通过 Github repo 进行部署，需要连接到你自己的特定仓库。如果你的仓库中有 Dockerfile 文件，则会自动解析。参见：Dockerfiles | Railway Docs 使用它们的 CLI，这个我试用了下感觉体验不是很好。不太推荐。 通过自带的模板进行部署，例如 code server。选择 Deploy Starter 即可 Vercelhttps://vercel.com/ Vercel 是一个云服务平台，支持静态网站和动态网站的应用部署、预览和上线。如果你用过 GitHub Pages ，那么心里可能不会太陌生，但你也能通过 vercel 集成 GitHub 后后，在 GitHub 项目进行代码推送，PR 合并自动部署的目的，且你不需要考虑服务器问题。 Vercel 它是一个免费的网站托管平台，也是我目前用过最好的网站托管平台，不仅仅可以部署静态网站，而且还可以部署动态网站，所以我们可以拿 vercel 充当你免费的服务器，主要有以下好处。 关联 github，只需要往 github 提交代码，它会自动获取最新的提交，然后自动部署 提供了免费的域名，省去了申请域名的问题，如果有自己的域名，还可以做个域名解析到这个平台上 提供了免费的 Https 证书，如果证书到期了，它会自动替换，完全不需要操心 傻瓜式的部署方式，它的操作非常简单，Vercel 提供了两种方式：通过命令行部署、通过 Vercel 提供管理后台部署，这期视频我们主要介绍通过命令行部署，因为命令行的部署方式更加简单 Cloudflare","categories":["0.平台","服务器"]},{"title":"博客部署相关文件","path":"/2024/05/25/0-平台-服务器-博客部署相关文件/","content":"部署涉及到的各项关键配置文件有以下，各文件路径基于 Hexo&#x2F;Github&#x2F;Obsidian 的仓库根目录 文件所属 文件名 文件路径 文件用途 GitHub Actions blogPublish.yml .github/workflows 用于仓库同步到 github 之后，自动将源码生成静态页面，同步到发布仓库进行发布 GitHub .gitignore ./ 用于忽略 Hexo 和 Obsidian 中不需要同步到 Git 的文件(有些文件体积过大，占用仓库体积) Hexo _config.yml ./ Hexo 站点配置文件 Hexo package.json ./ npm 安装包及命令文件，部署站点时所需的和 hexo 相关的依赖包都在此文件中 Hexo-Stellar _config.yml themes/stellar/_config.yml Hexo 主题配置文件 Hexo-Stellar widgets.yml themes/stellar/_data/widgets.yml Stellar 主题中的控件配置文件 更换主题 修改 .github/workflows/blogPublish.yml 该文件中指定了主题仓库和主题配置文件，修改主题仓库 修改 _config.theme.yml 该文件中默认为 stellar 的主题配置文件，需要修改为指定的主题配置文件 修改站点配置文件 _config.yml 需要在站点配置文件中修改指定的主题 博客管理后端Qexo建设 博客本地部署方案拉取仓库并本地部署脚本 1234567891011121314rm -rf ./BlogDeploygit clone git@github.com:liuluhua/BlogDeploy.gitcd ./BlogDeploymkdir themescd themesgit clone git@github.com:xaoxuu/hexo-theme-stellar.gitgit clone git@github.com:next-theme/hexo-theme-next.gitcd ..cp ./_config.theme.stellar.widgets.yml ./themes/hexo-theme-stellar/_data/widgets.ymlcp ./_config.theme.stellar.yml ./themes/hexo-theme-stellar/_config.ymlnpm installhexo cleanhexo ghexo s -p 9050","categories":["0.平台","服务器"]},{"title":"AI应用软件了解","path":"/2024/05/24/3-软件-AI-AI应用软件了解/","content":"1. 文本生成 AI 名称 公司 是否开源 功能简介 ChatGPT-4 OpenAI 否 最先进的大语言模型之一,具有强大的自然语言理解和生成能力,可用于写作、编程、分析等复杂任务 Claude3 Anthropic 否 擅长长文本处理和信息整理,最新版本在多项基准测试中表现优异 Gemini Google 否 多模态 AI 模型,具备出色的语音和图像理解能力 Poe Quora 否 集成多个顶级大语言模型的平台,用户可选择不同模型对话 NewBing Microsoft 否 基于 GPT-4 开发的 AI 搜索助手,集成在 Bing 搜索引擎中 通义千问 阿里巴巴 否 支持 10 万字长文本处理的大语言模型 豆包 字节跳动 否 注重陪伴和对话体验的 AI 助手 天工 昆仑万维 否 可生成文本、图像和音乐的 AI 平台 扣子 - - 专注于创建和部署自定义 AI 智能体的平台 2. 图像生成 AI 名称 公司 是否开源 功能简介 Stable Diffusion Stability AI 是 开源的文本到图像生成模型,可免费使用 Midjourney Midjourney 否 付费的高质量图像生成服务,以艺术风格著称 DALL-E 3 OpenAI 否 最新图像生成模型,集成在 ChatGPT 中 Dreamina 字节跳动 否 字节跳动开发的图像生成 AI 通义万象 阿里巴巴 否 集成在通义千问中的图像生成模型 混元助手 腾讯 否 腾讯开发的图文生成 AI Akuma - - 新兴的 AI 图像生成平台,提供多样化创作工具 3. 视频生成 AI 名称 公司 是否开源 功能简介 Sora OpenAI 否 文本到视频生成模型,能创建高质量、逼真的视频内容 Stable Video Diffusion Stability AI 是 开源的视频生成模型 Runway Runway 否 提供 AI 视频编辑和生成工具的平台 Pika Pika Labs 否 专注于短视频创作的 AI 工具 Haiper - - 新兴的 AI 视频生成平台 Dreamina 字节跳动 否 字节跳动的视频生成 AI 产品 Pixverse - - 提供 AI 视频创作和编辑功能的平台 Vidu 清华大学 - 清华大学开发的视频生成 AI Money Print Turbo - - 全自动视频制作工具,可生成文案、素材、字幕和背景音乐 4. 音频生成 AI 名称 公司 是否开源 功能简介 Suno Suno 否 AI 音乐创作平台,提供免费额度 Stable Audio Stability AI 是 Stability AI 开发的音频生成模型 天工音乐 昆仑万维 否 AI 音乐创作工具 网易天音 网易 否 网易开发的 AI 音乐生成平台 5. AI 浏览器和编程助手 名称 公司 是否开源 功能简介 Perplexity Perplexity AI 否 基于 AI 的智能搜索引擎,提供精准的信息检索和问答服务 GitHub Copilot Microsoft&#x2F;OpenAI 否 AI 编程助手,集成在多个代码编辑器中 6. 照片说话和音频模仿 名称 公司 是否开源 功能简介 Emo 阿里巴巴 否 AI 换脸和表情动画工具 SadTalk - 是 开源的 AI 换脸和口型同步技术 GPT-SoVITS - 是 开源的 AI 语音克隆和转换工具 Openvoice 微软 否 微软开发的 AI 语音克隆技术 剪映 字节跳动 否 短视频编辑 App,集成 AI 语音克隆功能 魔音工坊 - - 专注于 AI 语音合成和克隆的在线平台 7. PPT 制作和视频编辑 名称 公司 是否开源 功能简介 讯飞智文 科大讯飞 否 AI 辅助文档创作工具 Gamma Gamma 否 基于 AI 的演示文稿制作平台 WPS AI 金山办公 否 集成的 AI 助手,支持 PPT 等文档智能生成 腾讯智影 腾讯 否 AI 视频创作和编辑平台 剪映 字节跳动 否 短视频编辑 App,集成多种 AI 功能 其他说明：PyTorch 2.0.1 CUDA 11 conda FastGPT+ollama 订阅号对接 ollma 模型—云服务器资源不足 微软 E5 开发者订阅 huggingface.coHugging Face Transformers 是一个开源 Python 库，其提供了数以千计的预训练 transformer 模型，可广泛用于自然语言处理 (NLP) 、计算机视觉、音频等各种任务。 Hugging Face Hub 是一个协作平台，其中托管了大量的用于机器学习的开源模型和数据集，你可以将其视为 ML 的 Github。 Hugging Face Spaces 是 Hugging Face Hub 上提供的一项服务，它提供了一个易于使用的 GUI，用于构建和部署 Web 托管的 ML 演示及应用。该服务使得用户可以快速构建 ML 演示、上传要托管的自有应用，甚至即时部署多个预配置的 ML 应用。","categories":["3.软件","AI"]},{"title":"CANOpen 调试","path":"/2024/05/24/2-通讯协议-CAN-CANOpen-调试/","content":"作为 CAN Open 总线上的数据抓取设备，要求程序具有以下功能 能够作为总线上的从机设备，要求具有以下功能： HeartBeat 本设备 SDO 配置项 PDO 数据配置 如何通过主机 ASK 某一设备的数据 能够作为总线上的主机设备，要求具有以下功能： 从机设备的状态管理 PDO 数据采集 例如，预配置的过程数据对象 (PDO) 由生产者传输。每个 PDO 可能由多个节点使用。每个 CANopen 设备的其他有用的 CANopen 功能还包括：心跳生产者和消费者、紧急生产者、同步生产者或消费者、时间生产者或消费者、SDO 服务器（服务数据对象 - 从对象字典中提供变量）、NMT 从属（网络管理 - 启动或停止通信部分）、LSS 从属（节点 ID 和比特率的配置）。 CANopen 网络通常有一个具有命令功能的设备用于网络配置，例如：NMT 主站、LSS 主站、SDO 客户端、紧急消费者。CANopenNode 中的命令功能根据标准 CiA309-3 使用 Ascii 命令行接口实现。 使能 CAN 接口Linux 下 虚拟 CAN 设备modprobe 是 Linux 系统中的一个命令行工具，用于管理内核模块。内核模块是可以动态加载或卸载的可扩展组件，允许 Linux 内核在运行时添加或删除功能而不需要重启系统。常见的内核模块包括设备驱动程序、文件系统支持以及网络协议等。 创建一个虚拟 CAN 设备，并启用 123sudo modprobe vcansudo ip link add dev can0 type vcansudo ip link set up can0 安装 CAN 监测调试工具，can-utils 项目地址 https://github.com/linux-can/can-utils 12sudo apt-get install can-utilscandump -td can0 #显示can消息 rk3568 的 can 使用时 ip link set can0 up 启用失败报错： can0: incorrect missing data bit-timing 驱动问题，设备树中的节点配置，需要将 kernel/arch/arm64/boot/dts/rockchip/rk3568.dtsi 中的 can0 节点中的 compatible = &quot;rockchip,canfd-1.0&quot; 修改为 compatible = &quot;rockchip,can-1.0&quot;，重新编译后下载 开发板 3568 的 CAN1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253ifconfig can0 downip link set can0 up type can bitrate 500000ifconfig can0 upifconfig can1 downip link set can1 up type can bitrate 500000ifconfig can1 upip link set can0 downip link set can1 downip link set can0 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd onip link set can1 up type can bitrate 1000000 sample-point 0.75 dbitrate 4000000 dsample-point 0.8 fd on#查询当前网络设备:ifconfig -a#关闭CAN:ip link set can0 down#设置比特率500KHz:ip link set can0 type can bitrate 500000#打印can0信息:ip -details -statistics link show can0#启动CAN:ip link set can0 up#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123#DEADBEEF#发送（标准帧,远程帧,ID:123）:cansend can0 123#R#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123#12345678#发送（扩展帧,远程帧,ID:00000123）:cansend can0 00000123#R#开启打印，等待接收:candump can0###########################################设置can fd#设置仲裁段1M波特率，数据段3M波特率:ip link set can0 type can bitrate 1000000 dbitrate 3000000 fd on#发送（标准帧,数据帧,ID:123,date:DEADBEEF）:cansend can0 123##1DEADBEEF#发送（扩展帧,数据帧,ID:00000123,date:DEADBEEF）:cansend can0 00000123##1DEADBEEFifconfig -aip link set can0 type can bitrate 500000ip link set can0 upip link set can1 type can bitrate 500000ip link set can1 upcandump can0 &amp;cansend can1 123#DEADBEEFcansend can1 123#DEADBEEF 这个命令是用于配置 CAN（Controller Area Network，控制器局域网络）接口的 Linux 命令行指令。CAN 是一种用于实时应用的车辆、工业控制及自动化领域的串行通信协议。下面是对该命令各部分含义的详细解析： ip link set can0 up 这部分命令是用来设置指定的网络接口（%s 是一个占位符，通常在脚本中使用，运行时会被实际的接口名称替换）为活动状态（up）。这意味着它将启动指定的 CAN 接口，使其准备好进行数据传输。 type can 指定接口类型为 CAN 总线。这是告诉系统该接口应该被配置和处理为 CAN 总线接口，而不是以太网或其他类型的网络接口。 bitrate 500000 设置 CAN 总线的比特率（通信速度）。500000 代表具体的比特率值，例如 125000 表示 125Kbps。比特率是指每秒钟传输的位数，是 CAN 总线配置中的一个关键参数，需要所有连接到同一总线上的设备匹配。 sample-point 0.75 配置 CAN 位采样点的位置。采样点是在每个 CAN 位的哪个时间点进行信号采样以确定位的逻辑电平（0 或 1）。值范围从 0 到 1，其中 1 代表位时间周期的结束。这里设置为 0.75 意味着在每位的 75%时间点进行采样。 dbitrate 4000000 分布式比特率（Data Bit Rate）设置。这通常用于 FlexCAN（Flexible Data-Rate CAN）等高级 CAN 协议变体中，允许数据段的比特率与仲裁段不同。这里设置为 4000000 表示数据段的比特率为 4Mbps。但需要注意的是，标准 CAN 协议并不支持不同的数据和仲裁比特率，这一选项可能特定于某些高级 CAN 控制器或实现。 dsample-point 0.8 数据段的采样点位置，类似于上述的 sample-point，但特指数据段（如果适用）。在这个例子中，数据段的采样点被设置在每位的 80%时间点。 fd on 启用 CAN FD（Flexible Data-rate CAN）模式。CAN FD 是 CAN 总线协议的一个扩展，允许更灵活的数据长度和更高的数据传输速率，旨在提高 CAN 网络的数据吞吐量。 CAN 通信测试工具canutils 是常用的 CAN 通信测试工具包，内含 5 个独立的程序：canconfig、candump、canecho、cansend、cansequence。 这几个程序的功能简述如下： canconfig 用于配置 CAN 总线接口的参数，主要是波特率和模式。 candump 从 CAN 总线接口接收数据并以十六进制形式打印到标准输出，也可以输出到指定文件。 canecho 把从 CAN 总线接口接收到的所有数据重新发送到 CAN 总线接口。 cansend 往指定的 CAN 总线接口发送指定的数据。 cansequence 往指定的 CAN 总线接口自动重复递增数字，也可以指定接收模式并校验检查接收的递增数字。 ip CAN 波特率、功能等配置。 注意：busybox 里也有集成了 ip 工具，但 busybox 里的是阉割版本。不支持 CAN 的操作。故使用前请先确定 ip 命令的版本（iproute2）。上面工具包，网络上都有详细的编译说明。如果是自己编译 buildroot，直接开启宏就可以支持上述工具包。 12BR2_PACKAGE_CAN_UTILS=yBR2_PACKAGE_IPROUTE2=y CAN 比特率和采样点计算目前 CAN 架构根据输入频率和比特率自动计算。采样点的规则按照 CIA 标准协议： 1234567891011/* Use CiA recommended sample points */if (bt-&gt;sample_point) &#123;\tsample_point_nominal = bt-&gt;sample_point;&#125; else &#123;\tif (bt-&gt;bitrate &gt; 800000) sample_point_nominal = 750;\telse if (bt-&gt;bitrate &gt; 500000) sample_point_nominal = 800;\telse sample_point_nominal = 875;&#125; 比特率计算公式（详细原理可以百度，这里只介绍芯片配置相关）： 12BitRate = clk_can / (2 *(brq + 1) / ((tseg2 + 1) + (tseg1 + 1) + 1)Sample = (1 + (tseg1 + 1)) / (1 + (tseg1 + 1) + (tseg2 + 1)) brq、tseg1、tseg2 见 CAN 的 TRM 中 BITTIMING 寄存器。 CAN Open 用例分析SDO 命令-状态恢复和存储紧急信息、错误寄存器和 NMT 运行前状态在未初始化的非易失性存储器中都有数据源。对象 0x1010 和 0x1011 用于存储和恢复数据，通常来自 CANopen 对象字典。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不为零，则可能禁止节点进入 NMT 操作状态，并且无法与其交换 PDO。 恢复所有非易失性存储器： CAN ID：0x600 + 节点 ID（表示从主机到从节点的 SDO 请求）。0x600 + 4 &#x3D; 0x604。 命令字节：表示写入命令和数据长度。0x23 表示写入 4 字节数据（visible string）。 索引：对象字典索引。0x1011（字节顺序为低字节在前）。 子索引：对象字典子索引。0x01 数据：load：ASCII 码 l、o、a、d 分别为 0x6C、0x6F、0x61、0x64。 构建数据恢复 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x11 0x10），子索引（0x01），数据（0x6C 0x6F 0x61 0x64）。 can0 604 [8] 23 11 10 01 6C 6F 61 64 save：ASCII 码 s、a、v、e 分别为 0x73、0x61、0x76、0x65。 构建数据存储 CAN 帧 CAN ID：0x604。 数据：命令字节（0x23），索引（0x10 0x10），子索引（0x01），数据（0x73 0x61 0x76 0x65）。 can0 604 [8] 23 10 10 01 73 61 76 65 NMT 命令-设置 NMT 状态报文可以发送给特定节点或所有节点。它们可以重置设备、通信或将远程设备的内部状态设置为运行、预运行（禁用 PDO）或停止（仅启用心跳生产者和 NMT 消费者）。 当出现了设置错误寄存器的紧急状况时，start 不起作用。 设置 Node ID 为 4 的设备状态为 reset。 000 82 04 Byte 0 取值（命令） 状态 01 start_remote_node 02 stop_remote_node 80 enter_pre-operational 81 reset_node 82 reset_communication SDO 命令-设置心跳包读取心跳时间设置CAN0 604 [8] 40 17 10 00 00 00 00 00 写入心跳时间设置 CAN ID：0x600 + 节点 ID（4）&#x3D; 0x604。 命令字节：0x2B 表示写入 2 字节（u16）。 索引：0x1017（字节顺序为 17 10）。 子索引：0x00。 数据：1000ms&#x3D;0x03E8，字节顺序为 E8 03。10000ms&#x3D;0x2710 can0 604 [8] 2B 17 10 00 E8 03 00 00 PDO 配置按以下步骤通过写入 OD 变量配置 PDO： 将 PDO 通信参数 COB-ID 中的第 31 位设置为 1，禁用 PDO。 只有禁用 PDO 时才能配置 Node-Id。 将 PDO 映射参数，子索引 0 设置为 0，禁用映射。 配置映射 通过设置 PDO 映射参数，子索引 0 至映射对象数启用映射 通过将 PDO 通信参数 COB-ID 中的第 31 位设置为 0 来启用 PDO 其他配置同步传输信号配置全局同步周期 SYNC 设置值保存在对象 1006h 中。 心跳CANopen 主站的对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 对象 1017h 的值(发生器心跳时间)被此处设置的值重写。适用于所有从站对象的对象 1017h(发生器心跳时间)的值被此处设置的值重写，对象 1016h 的值(接收器心跳时间)变为自动优化后的值。 CAN Open 总线建设假定在一个 can open 网络中，node1 为主节点，node2 和 node3 为从节点，需要配置 node2，让 node2 接收 node3 的 TPDO 消息。 设备配置 设备名 节点地址 类型 Node 1 0x01 主节点（NMT Master） Node 2 0x02 从节点（NMT Slave） Node 3 0x03 从节点（NMT Slave） 其中 Node3 作为 TPDO 消息发出（生产者），期望 Node2 接收 Node3 消息。 PDO 参数配置配置所需信息配置 Node 3 的 TPDO： 确定 Node 3 的 TPDO 消息的 COB-ID 和映射对象。 在 Node 3 的对象字典中设置 TPDO 通信参数和映射参数。 配置 Node 2 的 RPDO： 设置 Node 2 的 RPDO 通信参数，使其接收 Node 3 的 TPDO 消息。 配置 Node 2 的 RPDO 映射参数，以处理从 Node 3 接收到的数据。 通讯参数和映射参数（OD）Node 3 的配置： TPDO 通信参数（0x1802）： 子索引 0x01: COB-ID &#x3D; 0x183 子索引 0x02: 传输类型（例如 0xFF，事件触发） TPDO 映射参数（0x1A02）： 子索引 0x00: 映射对象数量 &#x3D; 2 子索引 0x01: 0x60000208（对象 0x6000，子索引 0x02，8 位） 子索引 0x02: 0x64010110（对象 0x6401，子索引 0x01，16 位） Node 2 的配置： RPDO 通信参数（0x1400）： 子索引 0x01: COB-ID &#x3D; 0x183（与 Node 3 的 TPDO COB-ID 一致） 子索引 0x02: 传输类型（例如 0xFF，事件触发） RPDO 映射参数（0x1600）： 子索引 0x00: 映射对象数量 &#x3D; 2 子索引 0x01: 0x60000208（与 Node 3 的 TPDO 映射一致） 子索引 0x02: 0x64010110（与 Node 3 的 TPDO 映射一致） 配置过程设置 Node 3 的 TPDO 通信参数： 1234CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 83 01 00 00] # 设置 COB-ID 为 0x183（启用）CAN ID: 0x601 (SDO 请求)Data: [2B 00 18 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 3 的 TPDO 映射参数： 12345678CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 00 00 00 00] # 禁用 TPDO 映射CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x601 (SDO 请求)Data: [23 00 1A 02 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x601 (SDO 请求)Data: [2F 00 1A 02 02 00 00 00] # 启用 TPDO 映射 设置 Node 2 的 RPDO 通信参数： 1234CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 00 83 01 00 00] # 设置 COB-ID 为 0x183CAN ID: 0x602 (SDO 请求)Data: [2B 00 14 02 FF 00 00 00] # 设置传输类型为 0xFF（事件触发） 设置 Node 2 的 RPDO 映射参数： 12345678CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 00 00 00 00] # 禁用 RPDO 映射CAN ID: 0x602 (SDO 请求)Data: [23 00 16 01 08 02 60] # 映射对象 0x6000，子索引 0x02，8 位CAN ID: 0x602 (SDO 请求)Data: [23 00 16 02 10 01 64] # 映射对象 0x6401，子索引 0x01，16 位CAN ID: 0x602 (SDO 请求)Data: [2F 00 16 00 02 00 00 00] # 启用 RPDO 映射 通过上述步骤配置 Node 2 的 RPDO 通信参数和映射参数，使其能够接收和处理来自 Node 3 的 TPDO 消息。这种配置确保了 Node 2 能够正确接收和解析 Node 3 发送的 TPDO 数据，完成数据的有效传输和处理。 调试命令控制 NMT 状态 CAN0 000 [2] 01 04&#x2F;CAN0 000 [2] 02 04 控制节点 4 CAN0 000 [2] 01 00&#x2F;CAN0 000 [2] 02 00 控制所有节点 发送 SYNC 信号 CAN0 080 [0] 发送 ERROR 信号 CAN0 084 [8] 数据区根据实际错误定义 恢复参数，在 1011 的 01 写入 load CAN0 604 [8] 2F 11 10 01 6C 6F 61 64 读取 1005 信息（SYNC 的 COB-ID） CAN0 604 [8] 40 05 10 00 00 00 00 00 配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值）。 &#96;CAN0 604 [8] 23 05 10 00 80 00 00 00 读取 1006 信息(SYNC 通信周期) &#96;CAN0 604 [8] 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms &#x3D; 100000us）。 CAN0 604 [8] 23 06 10 00 A0 86 01 00 读取心跳时间设置 CAN0 604 [8] 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 CAN0 604 [8] 2B 17 10 00 E8 03 00 00 设置一个 TPDO配置 1800 的上报方式为异步，读取的话改 2F 为 40 CAN0 604 [8] 2F 00 18 02 FF 00 00 00 配置 1800 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 604 [8] 2B 00 18 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 604 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 604 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 604 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 604 [8] 2F 00 1A 00 02 00 00 00 设置 RPDO配置 1400 接收来自 181 的数据 CAN0 601 [8] 23 00 14 01 81 01 00 00 配置 1400 的上报方式为异步，读取的话改 2F 为 40 CAN0 601 [8] 2F 00 14 02 FF 00 00 00 配置 1400 的上报事件为 100ms（子索引 05）（数据类型 uint16） CAN0 601 [8] 2B 00 14 05 64 00 00 00（单位为 ms） 设置子索引禁用 CAN0 601 [8] 2F 00 1A 00 00 00 00 00 0x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） CAN0 601 [8] 23 00 1A 01 10 00 30 40 0x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） CAN0 601 [8] 23 00 1A 02 20 00 10 20 设置映射数量，用多少设多少，这里用了 2 个 CAN0 601 [8] 2F 00 1A 00 02 00 00 00","categories":["2.通讯协议","CAN"]},{"title":"文件夹双向同步软件设计","path":"/2024/05/22/3-软件-0-项目-文件夹双向同步软件设计/","content":"","categories":["3.软件","0.项目"]},{"title":"网络超时检测的三种方法","path":"/2024/05/22/0-平台-Linux-网络-网络超时检测的三种方法/","content":"网络超时检测的三种方法 网络通信中，很多操作会使得进程阻塞，这时我们要设定时间，到时间后强制返回，避免进程在没有数据的情况下无限阻塞 这里我们总结一下网络超时检测的三种方法： 一、通过 setsockopt 设置套接字属性 SO_RCVTIMEO 123456789101112131415struct timeval t = &#123;5, 0&#125;if (setsockopt(listenfd, SOL_SOCKET, SO_RCVTIMEO, &amp;t, sizeof(t)) == -1) &#123; perror(&quot;setsockopt&quot;); return -1;&#125;memset(&amp;peeraddr, 0, sizeof(peeraddr));len = sizeof(peeraddr);if ((connfd = accept(listenfd, (struct sockaddr *)&amp;peeraddr, &amp;len)) == -1) &#123;\tprintf(&quot;errno=%d: %s &quot;, errno, strerror(errno));\tif (errno == EAGAIN) &#123; printf(&quot;timeout &quot;); return -1;\t&#125;&#125; 二、设定 select 函数的一个参数实现超时处理 123456789struct timeval t= &#123;3, 0&#125;;while (1) &#123;\tt.tv_sec = 3;\tt.tv_usec = 0;\tif ((ret = select(maxfd+1, &amp;rdfs, NULL, NULL, &amp;t)) == -1) &#123; perror(&quot;select&quot;); return -1;\t&#125;&#125; 三、设定一个定时器捕捉 SIGALRM 信号做超时控制 123456789101112struct sigaction act;sigaction(SIGALRM, NULL, &amp;act); //获取SIGALRM信号的属性act.sa_handler = handler; // 设置SIGALRM信号的处理函数sigaction(SIGALRM, &amp;act, NULL); // 设置SIGALRM信号的属性alarm(3); // 定时器设置3秒钟while (1) &#123;\tif ((connfd = accept(listenfd, (struct sockaddr *)&amp;peeraddr, &amp;len)) == -1) &#123;\tif (errno == EINTR) &#123; printf(&quot;timeout &quot;); return -1;\t&#125;&#125; 定时器 3 秒钟内没有数据到来，内核产生 SIGALRM 信号中断当前操作。我们知道设置信号捕捉函数可以用 signal 函数或是 sigaction 函数。但这里只能使用 sigaction 函数，因为 signal 设置的信号处理函数执行完后会重新执行被中断的操作","categories":["0.平台","Linux","网络"]},{"title":"Docker下将已部署的wordpress备份及迁移","path":"/2024/05/22/0-平台-Docker-Docker下将已部署的wordpress备份及迁移/","content":"镜像# Docker 镜像备份 在已经部署好 wordpress 的机器上，使用 docker save 命令将 Docker 镜像保存到本地文件中。 使用以下命令将名为 wordpress 和 mysql 的 Docker 镜像分别保存到名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中： 12docker save wordpress &gt; wordpress_image.tar #保存wordpressdocker save mysql &gt; mysql_image.tar #保存mysql # Docker 镜像读取 将 wordpress_image.tar 和 mysql_image.tar 文件复制到目标机器上。在目标机器上，使用 docker load 命令将本地文件中的 Docker 镜像加载到 Docker 中。 使用以下命令将名为 wordpress_image.tar 和 mysql_image.tar 的本地文件中的 Docker 镜像加载到 Docker 中： 12docker load &lt; wordpress_image.tardocker load &lt; mysql_image.tar 文件系统文件系统备份要将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方，可以使用 Docker 的导入和导出功能，具体步骤如下： 在运行 WordPress 应用程序的 Docker 容器上执行以下命令，将容器中的 WordPress 应用程序导出为 tar 文件： 1docker export &lt;container_id&gt; &gt; wordpress.tar 这将在当前目录下创建一个名为 wordpress.tar 的文件，其中包含 Docker 容器中的整个 WordPress 应用程序。 文件系统读取将 wordpress.tar 文件传输到要部署 WordPress 应用程序的目标服务器上。在目标服务器上执行以下命令，将 wordpress.tar 文件导入到 Docker 中： 1cat wordpress.tar | docker import - &lt;image_name&gt;:&lt;tag&gt; 其中，&lt;image_name&gt; 是你为导入的 Docker 镜像指定的名称，&lt;tag&gt; 是你为该镜像指定的标签。运行导入的 Docker 镜像，启动 WordPress 应用程序的容器： 1docker run -p &lt;host_port&gt;:&lt;container_port&gt; -d &lt;image_name&gt;:&lt;tag&gt; 其中，&lt;host_port&gt; 是你要将容器的端口映射到主机上的端口号，&lt;container_port&gt; 是容器内运行 WordPress 应用程序的端口号。这样，你就可以将 Docker 中的整个 WordPress 应用程序打包并部署到另一个地方。 启动 Docker 按照之前的 docker-compose 的方法启动 dokcer 使用 docker ps -a --no-trunc 需要修改并添加 command wordpress 是 docker-entrypoint.sh apache2-foreground mysql 是 docker-entrypoint.sh mysqld 使用 docker run 命令在目标机器上启动该 Docker 镜像。例如，使用以下命令在目标机器上启动名为 wordpress 的 Docker 镜像： 12345678910#启动mysqldocker run -d \\--name mysql \\-v mysql_data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=liuluhua \\-e MYSQL_DATABASE=wordpress \\-e MYSQL_USER=liuluhua \\-e MYSQL_PASSWORD=liuluhua \\mysql:latest docker-entrypoint.sh mysqld 12345678910111213#启动wordpressdocker run -d \\--name wordpress \\--link mysql \\-p 80:80 \\-e WORDPRESS_DB_HOST=mysql:3306 \\-e WORDPRESS_DB_USER=liuluhua \\-e WORDPRESS_DB_PASSWORD=liuluhua \\-e WORDPRESS_DB_NAME=wordpress \\-v ./wp-content:/var/www/html/wp-content \\-v ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini \\wordpress:latest docker-entrypoint.sh apache2-foreground 启动参数： **-d**：表示以“后台模式”运行容器，即使容器的主进程退出也不会停止容器。 **--name**：表示为容器指定一个名称，这样可以方便地对容器进行管理。 **-v**：表示将主机的目录或文件与容器内的目录或文件进行挂载，即数据卷。例，-v mysql_data:/var/lib/mysql 表示将主机的 mysql_data 目录挂载到容器内的 /var/lib/mysql 目录，这样容器内的 MySQL 数据就可以持久化存储在主机上。 **-e**：表示设置容器内的环境变量。例如，-e MYSQL_ROOT_PASSWORD=liuluhua 表示设置容器内的 MYSQL_ROOT_PASSWORD 环境变量为 liuluhua。 **--link**：表示将一个容器链接到另一个容器，使得容器之间可以进行通信。例如，--link mysql 表示将容器链接到名为 mysql 的容器。 **-p**：表示将容器的端口映射到主机的端口。例如，-p 80:80 表示将容器的 80 端口映射到主机的 80 端口，使得可以通过主机的 IP 地址访问容器内的服务。 **wordpress:latest 和 mysql:latest**：表示使用 wordpress 和 mysql 镜像的最新版本来创建容器。 **./wp-content:/var/www/html/wp-content 和 ./uploads.ini:/usr/local/etc/php/conf.d/uploads.ini**：表示将主机上的 wp-content 目录和 uploads.ini 文件挂载到容器内的 /var/www/html/wp-content 目录和 /usr/local/etc/php/conf.d/uploads.ini 文件，使得容器内的 WordPress 网站可以访问这些文件。","categories":["0.平台","Docker"]},{"title":"内存分布","path":"/2024/05/22/0-平台-Linux-程序-内存分布/","content":"内存分布在 32 位操作系统中，地址空间的最大理论限制是 4GB&#x3D;2 的 32 次方。然而，这个地址空间并不完全可用给用户应用程序，因为操作系统自身也需要地址空间。在 32bit 的 OS 中，可执行文件 4G 内存分布分为: 用户空间 app+C 库\t3G 内核空间 驱动 1G 内核空间通常，内核空间和硬件设备及驱动占用了高位的 1GB 地址空间，即从 0xC0000000 到 0xFFFFFFFF。这部分空间是操作系统用来管理系统资源和硬件设备的，用户态程序不能直接访问。 用户空间剩下的 3GB 地址空间，即从 0x00000000 到 0xBFFFFFFF，被分配给用户态应用程序。用户态应用程序的代码段、数据段、堆、栈和动态链接库（DLL）都在这部分地址空间内。 在这个 3GB 的用户空间中，内存分布通常如下： 1234567891011121314151617181920低地址+-----------------+| .text 段 | 代码段:包含应用程序的可执行代码。一般从较低地址开始分配。+-----------------+| .data 段 | 数据段:包含已初始化的全局变量和静态变量。+-----------------+| .bss 段 | 包含未初始化的全局变量和静态变量。+-----------------+| 堆 (heap) | 堆: 用户自定义空间，用于动态内存分配（如 malloc、new）。 | | 堆一般从数据段之后的地址开始，向高地址方向增长。|(向高地址方向增长) | 用完手动释放+-----------------+| || 空闲区域 | 共享库（DLLs）会被映射到进程的地址空间中，| | 通常在堆和栈之间的某个位置。+-----------------+| 栈 (stack) | 栈: 局部变量，函数参数，函数结束自动释放| | 用于存储局部变量和函数调用信息。| (向低地址方向增长)| 栈一般从高地址开始，向低地址方向增长。+-----------------+高地址 1234567891011121314151617181920#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;/*C语言中数据的内存分配*/int a=0;char *p1;int main()&#123;\tint b; /*b在栈 */\tchar s[] =&quot;abc&quot;; /*s在栈，&quot;abc&quot;在常量区*/\tchar *p2; /*p2在栈*/\tchar *p3=&quot;123456&quot;; /* 123456在常量区，p3 在栈 */\tstatic int c=0; /*可读可写数据段*/\tp1 = (char *)malloc(10);\t/*分配得来的 10个字节的区域在堆区*/\tp2 = (char *)malloc(20);\t/*分配得来的 20个字节的区域在堆区*/ /* 从常量区的“Hello world”字符串复制到刚分配到的堆区 */\tstrcpy(p1，“Hello World&quot;);\treturn 0;&#125;","categories":["0.平台","Linux","程序"]},{"title":"vim安装","path":"/2024/05/22/3-软件-VIM-vim安装/","content":"配置文件 地址 安装环境 12sudo apt install git cscopewget -qO - https://raw.github.com/ma6174/vim/master/setup.sh | sh -x wget 是一个用于从网络下载文件的命令行工具。-q 表示静默模式，不显示下载进度和其他信息。-O - 指定输出到标准输出（stdout），而不是保存到文件。这样下载的文件内容就会直接输出到终端。https://raw.github.com/ma6174/vim/master/setup.sh 是要下载的文件的 URL 地址。| 是管道符号，用于将前一个命令的输出作为后一个命令的输入。sh 是一个用于执行 Shell 脚本的命令。-x 表示在执行脚本时显示详细的调试信息。 setup.sh 内容 123456789101112131415161718192021222324252627282930#!/bin/bashecho &quot;安装将花费一定时间，请耐心等待直到安装完成~~&quot;if which apt-get &gt;/dev/null; then\tsudo apt-get install -y vim vim-gnome ctags xclip astyle python-setuptools python-dev gitelif which yum &gt;/dev/null; then\tsudo yum install -y gcc vim git ctags xclip astyle python-setuptools python-develfi##Add HomeBrew support on Mac OSif which brew &gt;/dev/null;then\techo &quot;You are using HomeBrew tool&quot;\tbrew install vim ctags git astylefisudo easy_install -ZU autopep8sudo ln -s /usr/bin/ctags /usr/local/bin/ctagsmv -f ~/vim ~/vim oldcd ~/ &amp;&amp; git clone https://github.com/ma6174/vim.gitmv -f ~/.vim ~/.vim_old mv -f ~/vim ~/.vimmv -f ~/.vimrc ~/.vimrc_oldmv -f ~/.vim/.vimrc ~/ git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundleecho &quot;ma6174正在努力为您安装bundle程序&quot; &gt; ma6174echo &quot;安装完毕将自动退出&quot; &gt;&gt; ma6174echo &quot;请耐心等待&quot; &gt;&gt; ma6174vim ma6174 -c &quot;BundleInstall&quot; -c &quot;q&quot; -c &quot;q&quot;rm ma6174echo &quot;安装完成&quot; 配置 1234cd /usr/includesudo ctags -Rcd -vim .vimrc 修改最后一行 1set tags=/usr/include/tags 安装 zshZsh 是一种替代默认的命令行 Shell（如 Bash）的 Shell。Zsh（Z Shell）是一种强大的命令行 Shell，它具有许多增强的功能和可定制选项。相较于传统的 Bash Shell，Zsh 提供了更好的自动补全、历史记录管理、拼写修正、主题定制等功能。它还支持丰富的插件和扩展，可以根据用户的需求进行定制和配置。 接下来，chsh -s /bin/zsh 是一个用于更改当前用户的默认 Shell 的命令。chsh 是 “change shell” 的缩写，-s 选项指定要更改为的新 Shell，/bin/zsh 是指要更改为 Zsh 的路径。 12sudo apt install zshchsh -s /bin/zsh","categories":["3.软件","VIM"]},{"title":"Sqlie使用","path":"/2024/05/22/3-软件-数据库-Sqlie使用/","content":"数据库基础安装数据库 1sudo apt-get install sqlite3 数据库指令操作打开一个数据库 1sqlite3 my.db 常用查询: `.table` 查看数据库中的表 `.schema tablename` 查看相应表的结构 `.database` 查看当前打开的数据库 `.quit` 退出当前数据库 `.help` 列出帮助信息 创建表: create table movies (id int, name text, time int, auth text);删除表: drop table tablename;\t添加信息: insert into movies values (.....); insert into movies values (.....);查询信息: select * from movies ;删除信息: delete from movies where id=1;更新信息: update tablename set name=&#39;&#39; where id=2;添加字段: alter table tablename add column sex char ; 1234567891011121314151617181920212223242526//创建名字为tong.db的数据库sqlite3 tong.db//创建一个叫user的table,里面有name, agecreate table user(name, age integer);//name的默认类型是字符串，用“taotao”//age的类型相当于int//删除一个tabledrop table user;//向user中存储数据insert into user values（“taotao”, 18）;//增加一个column叫num,类型是 integeralter table user add column num integer;//更新数据update user set name=&quot;taotao&quot;,age=18 where num=110;//打印所有信息select * from user;//打印某一个信息select * from user where name=&quot;taotao&quot;;//删除一个叫taotao的人delete from user where name=&quot;taotao&quot;;//查看有哪几个表.tables//查看某一个表的属性.schema user//退出.q","categories":["3.软件","数据库"]},{"title":"机器大小端校验","path":"/2024/05/22/0-平台-Linux-其他-机器大小端校验/","content":"大小端字节序大端字节序（Big-Endian）和小端字节序（Little-Endian）是两种不同的字节存储顺序方式，用于在多字节数据类型（如整数、浮点数）在内存中的表示。 在大端字节序中，较高字节（最高有效字节）保存在较低的存储地址，而较低字节（最低有效字节）保存在较高的存储地址。换句话说，数据的高位字节存储在低地址位置，低位字节存储在高地址位置。 例如，整数值 0x12345678 在大端字节序中的存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 相比之下，在小端字节序中，较低字节保存在较低的存储地址，而较高字节保存在较高的存储地址。数据的低位字节存储在低地址位置，高位字节存储在高地址位置。 使用同样的示例值 0x12345678，小端字节序的存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 64 位和 32 位的不同64 位和 32 位的大小端情况是类似的，但存在一些细微差异。 在 64 位系统中，数据被划分为 8 字节（64 位），而在 32 位系统中，数据被划分为 4 字节（32 位）。因此，字节的顺序和对齐方式在这两种情况下可能会有所不同。 例如，考虑一个 64 位整数值 0x1122334455667788。 在大端字节序中，存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 而在小端字节序中，存储顺序如下： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x88 0x77 0x66 0x55 0x44 0x33 0x22 0x11 尽管在 64 位和 32 位系统上字节顺序的原理相同，但具体的存储布局和访问方式可能有所不同。因此，在跨平台开发或数据交换中，需要注意字节序的差异，并采取适当的转换方法以确保数据的正确解释和传输。 影响字节序的选择对于不同的计算机体系结构和通信协议至关重要。它主要影响以下方面： 数据传输：在网络通信和数据交换中，如果通信双方使用不同的字节序，就需要进行字节序的转换，以确保正确解释和传输数据。 文件格式：某些文件格式（如图像、音频、视频）可能使用特定的字节序来存储数据，因此读取和解析这些文件时需要考虑字节序。 处理器架构：不同的处理器架构可能采用不同的字节序。例如，x86 架构使用小端字节序，而 PowerPC 架构使用大端字节序。在开发软件时，需要根据目标处理器架构的字节序选择适当的数据处理方式。 正确地处理字节序是确保跨平台兼容性和数据一致性的重要方面，特别是在网络通信和数据交换的情况下。 比较整数值 0x12345678 在 64 位和 32 位系统上，以大端字节序和小端字节序存储的示例： 64 位系统大端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x12 0x34 0x56 0x78 0x00 0x00 0x00 0x00 64 位系统小端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003 0x1004 0x1005 0x1006 0x1007数据： 0x00 0x00 0x00 0x00 0x78 0x56 0x34 0x12 32 位系统大端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x12 0x34 0x56 0x78 32 位系统小端字节序： 12地址： 0x1000 0x1001 0x1002 0x1003数据： 0x78 0x56 0x34 0x12 校验方法123456789101112131415#include &lt;stdio.h&gt;int main() &#123; unsigned int num = 0x01020304; unsigned char *ptr = (unsigned char*)&amp;num; if (*ptr == 0x01) &#123; printf(&quot;大端字节序 &quot;); &#125; else &#123; printf(&quot;小端字节序 &quot;); &#125; return 0;&#125;","categories":["0.平台","Linux","其他"]},{"title":"网络配置","path":"/2024/05/22/0-平台-Linux-网络-网络配置/","content":"TCP&#x2F;IP 网络相关概念 配置以太网络接口 配置 ppp 网络接口 Linux 环境下的网络配置 检测网络配置 TCP&#x2F;IP 网络相关概念 TCP&#x2F;IP 协议 IP 地址、子网掩码和域名 路由选择和网关地址 端到端连接 Linux 的网络应用 Linux 的网络接口设备 在网络中使用的每一个外围设备的网络接口，在 Linux 的核心（kernel）中都有相应的名字。 网络接口设备和相关的设备接口名：lo 本地回送接口。用于网络软件测试以及本地机进程间通信，无论什么程序一旦使用回送地址发送数据，协议软件立即将其返回，不进行任何网络传输。在 Linux 系统中，回送设备是默认设置好的。ethn 第 n 个以太网卡接口 (n 为 0 表示第一块，以此类推)，eth 是大多数网卡的接口设备名。pppn 第 n 个 ppp 接口。PPP 接口按照与它们有关的 PPP 配置顺序连接在串口上。 网络配置命令 hostnameLinux– 查看或配置计算机的主机名 ifconfig– 查看或配置网络接口 ifup– 启用指定的网络接口 ifdown– 禁用指定的网络接口 route– 查看或配置内核路由表的配置情况 配置以太网络－使用命令 配置 IP 地址 1234567– # ifconfig [interface] [ip-address] [netmask …] [broadcast … ] [up] [down]- 配置默认网关– # route add default gw IP 地址– #route add 0.0.0.0 netmask 0.0.0.0 eth0- 配置 DNS 客户– # vi /etc/resolv.conf TCP&#x2F;IP 配置文件&#x2F;etc&#x2F;sysconfig&#x2F;network 主机最基本网络信息，用于系统启动 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts 系统启动初始化网络信息 &#x2F;etc&#x2F;xinetd.conf 定义由超级进程 xinetd 启动的网络服务 &#x2F;etc&#x2F;hosts 主机和 ip 映射 &#x2F;etc&#x2F;host.conf DNS 客户端搜索顺序 &#x2F;etc&#x2F;resoly.conf 指定 DNS 地址 &#x2F;etc&#x2F;serveices 编辑&#x2F;etc&#x2F;sysconfig&#x2F;entwork-script&#x2F;ifcfg-eth0 文件 Linux 支持一块网卡绑定多 IP，编辑子接口配置文件 ifcfg-eth0:1 Netconfig 调用菜单 配置 ADSL 网络接口 安装 pppoerpm –qa |grep pppoe 配置 pppoeadsl-setup&#x2F;etc&#x2F;sysconfig&#x2F;network-script&#x2F;ifcfg-ppp0adsl-status 启用和挂断 ADSL 网络连接adsl-start (或 ifup ppp0)adsl-stop (或 ifdown ppp0) 网络测试一般方法 排除非自身因素 查看本机 IP 地址 检测与网关的连接 监测与互联网的连接 测试域名解析 测试与特定站点的连接 检测网络状态 Ifconfig– 检测网络接口 ping– 检测网络连通性 netstat– 查看网络状态 traceroute– 检测到目的主机所经过的路由器 tcpdump– 显示本机网络流量的状态 配置网卡信息IP、网关、掩码 1/etc/network/interfaces DNS 1/etc/resolv.conf &#x3D;&#x3D;》重启网卡 sudo service networking restart 123/etc/sysconfig/network-scripts/ifcfg-eno16777736TYPE=Ethernet(设备类型） BOOTPROTO=static（地址分配模式） NAME=eno16777736 ONBOOT=yes（是否启用）IPADDR=192.168.10.10 NETMASK=255.255.255.0 GATEWAY=192.168.10.1 DNS1=192.168.10.1 &#x3D;&#x3D;》重启网卡 systemctl restart network","categories":["0.平台","Linux","网络"]},{"title":"Linux命令","path":"/2024/05/22/0-平台-Linux-其他-Linux命令/","content":"嵌入式开发中常常需要确认开发板的系统版本，CPU，各种外部设备，内寸占用情况等数据。 管理员口令丢失解决办法 开机从 LILO 或 GRUB 中选择进入单用户模式（运行级别 1） 使用 passwd 命令修改 root 口令 重新切换为运行级别 3 或 5 sudo –s # 切换到 root 用户，但是不切换用户环境 操作系统uname -a #查看内核 head -n 1 /etc/issue #查看操作系统版本 cat /proc/cpuinfo #查看CPU信息 hostname #查看计算机名 lspci -tv #列出所有PCI设备 lsusb -tv #列出所有USB设备 lsmod #列出加载的内核模块 env #查看环境变量 资源free -m #查看内存使用量和交换区使用量 df -h #查看各分区使用情况 du -sh &lt;目录名&gt; #查看指定目录的大小 grep MemTotal /proc/meminfo #查看内存总量 grep MemFree /proc/meminfo #查看空闲内存量 uptime #查看系统运行时间、用户数、负载 cat /proc/loadavg #查看系统负载 磁盘和分区mount | column -t #查看挂接的分区状态 fdisk -l #查看所有分区 swapon -s #查看所有交换分区 hdparm -i /dev/hda #查看磁盘参数(仅适用于IDE设备) dmesg | grep IDE #查看启动时IDE设备检测状况 网络ifconfig #查看所有网络接口的属性 iptables -L #查看防火墙设置 route -n #查看路由表 netstat -nltp #查看所有监听端口 netstat -antp #查看所有已经建立的连接 netstat -s #查看网络统计信息 tcpdump 进程ps -aux # 显示瞬间行程 (process) 的动态 ps -ef #查看所有进程 top #实时显示进程状态 nice -n 1 ls # 将 ls 的优先序加 1 并执行 renice +1 987 -u daemon root -p 32 # 将行程 id 为 987 及 32 的行程与行程拥有者为 daemon 及 root 的优先序号码加 1 kill # 送出一个特定的信号 (signal) 给行程 id 为 pid 的行程根据该信号而做特定的动作, 若没有指定, 预设是送出终止 (TERM) 的信号 killall proc bg fg fg n pstree # 将所有行程 (process) 以树状图显示 skill # 送个讯号给正在执行的程序,预设的讯息为 TERM (中断) 用户w #查看活动用户 id &lt;用户名&gt; #查看指定用户信息 last #查看用户登录日志 cut -d: -f1 /etc/passwd #查看系统所有用户 cut -d: -f1 /etc/group #查看系统所有组 crontab -l #查看当前用户的计划任务 crontab 0 6-12/3 * 12 * /usr/bin/backup # 在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backup at 5pm + 3 days /bin/ls # 三天后的下午 5 点执行 /bin/ls: login passwd 服务chkconfig --list #列出所有系统服务 chkconfig --list | grep on #列出所有启动的系统服务 程序rpm -qa #查看所有安装的软件包 文件命令ls -alrtFR filename cut pwd mkdir/rmdir dir rm -rf dir cp -r dest source # 将目录下之档案亦皆依序拷贝至目的地 mv file1 file2 ln -s yy zz # 将档案 yy 产生一个 symbolic link:zz ,不加s为硬链接 touch filename #将档案的时候记录改为现在的时间。若档案不存在,系统会建立新的档案。 cat &gt; file more -s testfile # 逐页显示 testfile 之档案内容,如有连续两行以上空白行则以一行空白行显示。 more +20 testfile # 从第 20 行开始显示 testfile 之档案内容。 less filename # 浏览文字档案的内容 head file tail file tail -f file cat # 把档案串连接后传到基本输出（萤幕或加 &gt; fileName 到另一个档案） diff -u a.patch oldfile newfile # 可以完成比较功能，生成补丁文件 patch -i a.patch filname # 命令用于打补丁，补丁文件是使用diff产生的 split -b 1m filename filename.dump. # 将filename分割为1M大小，分割后的文件名为filename.dump.aa，filename.dump.ab... tr #指令从标准输入设备读取数据，经过字符串转译后，将结果输出到标准输出设备。 SSHssh user@host ssh -p port user@host ssh-copy-id user@host 压缩tar cf file.tar files tar xf file.tar tar czf file.tar.gz files tar xzf file.tar.gz tar cjf file.tar.bz2 tar xjf file.tar.bz2 gzip file gzip -d file.gz compress -f source.dat # 将 source.dat 压缩成 source.dat.Z，解压-d tar cjf - logs/ | split -b 1m - logs.tar.bz2 # 将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令 cat logs.tar.bz2.a* | tar xj # 分包解压 文件权限chmod a+x filename # 对文件增加权限 chown -R dirname # 对目前目录下的所有档案与子目录进行相同的拥有者变更 搜索grep pattern files grep -r pattern dir command | grep pattern find path -name &quot;filename*&quot; # 在 path 路径下查找所有以 filename 开头的文件 locate chdrv # 寻找所有叫 chdrv 的档案 expr #字串长度/从位置处抓取字串/出现次数 网络ping host whois domain dig domian dig -x host wget file wget -c file scp test.c root@192.168.7.1:/home/root\t# SCP 拷贝数据 系统信息date # 显示或设定系统的日期与时间 cal # 显示本月的月历 uptime # 显示开机时间等信息 who # 显示系统中有那些使用者正在上面 whoami finger user cat /proc/cpuinfo cat /proc/meminfo man command free file [filename]\t# 可查看可执行文件是 ARM 架构还是 X86 架构 uname -a\t# 显示电脑以及操作系统的相关信息 df\t# 查看磁盘 mount\t# 挂载 umount\t# 卸载 sync\t# 卸载之前同步数据 cat /sys/kernel/debug/usb/devices\t# 查看 USB 类型 time使用方式： 1time [options] COMMAND [arguments] 使用说明： time 指令的用途,在于等等。需要特别注意的是,部分资讯在 Linux 上显示不出来。这是因为在 Linux 上部分资源的分配函式与 time 指令所预设的方式并不相同,以致于 time 指令无法取得这些资料。 -o or –output&#x3D;FILE 设定结果输出档。这个选项会将 time 的输出写入 所指定的档案中。如果档案已经存在,系统将覆写其内容。 -a or –append 配合 -o 使用,会将结果写到档案的末端,而不会覆盖掉原来的内容。 -f FORMAT or –format&#x3D;FORMAT 以 FORMAT 字串设定显示方式。当这个选项没有被设定的时候,会用系统预设的格式。不过你可以用环境变数 time 来设定这个格式,如此一来就不必每次登入系统都要设定一次。 一般设定上,你可以用 \\t 表示跳栏,或者是用 表示换行。 每一项资料要用 % 做为前导。如果要在字串中使用百分比符号,就用.（学过 C 语言的人大概会觉得很熟悉） time 指令可以显示的资源有四大项,分别是： 1234Time resources Memory resources IO resources Command info 详细的内容如下： 1234567891011121314151617181920212223242526272829303132Time Resources E 执行指令所花费的时间,格式是：[hour]:minute:second。请注意这个数字并不代表实际的 CPU 时间。 e 执行指令所花费的时间,单位是秒。请注意这个数字并不代表实际的 CPU 时间。 S 指令执行时在核心模式（kernel mode）所花费的时间,单位是秒。 U 指令执行时在使用者模式（user mode）所花费的时间,单位是秒。 P 执行指令时 CPU 的占用比例。其实这个数字就是核心模式加上使用者模式的 CPU 时间除以总时间。 Memory Resources M 执行时所占用的实体记忆体的最大值。单位是 KB t 执行时所占用的实体记忆体的平均值,单位是 KB K 执行程序所占用的记忆体总量（stack+data+text）的平均大小,单位是 KB D 执行程序的自有资料区（unshared data area）的平均大小,单位是 KB p 执行程序的自有堆叠（unshared stack）的平均大小,单位是 KB X 执行程序间共享内容（shared text）的平均值,单位是 KB Z 系统记忆体页的大小,单位是 byte。对同一个系统来说这是个常数 IO Resources F 此程序的主要记忆体页错误发生次数。所谓的主要记忆体页错误是指某一记忆体页已经置换到置换档（swap file)中,而且已经分配给其他程序。此时该页的内容必须从置换档里再读出来。 R 此程序的次要记忆体页错误发生次数。所谓的次要记忆体页错误是指某一记忆体页虽然已经置换到置换档中,但尚未分配给其他程序。此时该页的内容并未被破坏,不必从置换档里读出来 W 此程序被交换到置换档的次数 c 此程序被强迫中断（像是分配到的 CPU 时间耗尽）的次数 w 此程序自愿中断（像是在等待某一个 I/O 执行完毕,像是磁碟读取等等）的次数 I 此程序所输入的档案数 O 此程序所输出的档案数 r 此程序所收到的 Socket Message s 此程序所送出的 Socket Message k 此程序所收到的信号 ( Signal )数量 Command Info C 执行时的参数以及指令名称 x 指令的结束代码 ( Exit Status ) -p or –portability 这个选项会自动把显示格式设定成为： 123real %e user %U sys %S 这么做的目的是为了与 POSIX 规格相容。 -v or –verbose 这个选项会把所有程式中用到的资源通通列出来,不但如一般英文语句,还有说明。对不想花时间去熟习格式设定或是刚刚开始接触这个指令的人相当有用。 范例： 利用下面的指令 1time -v ps -aux 我们可以获得执行 ps -aux 的结果和所花费的系统资源。如下面所列的资料： 123456789101112131415161718192021222324252627282930USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.4 1096 472 ? S Apr19 0:04 init root 2 0.0 0.0 0 0 ? SW Apr19 0:00 [kflushd] root 3 0.0 0.0 0 0 ? SW Apr19 0:00 [kpiod] ...... root 24269 0.0 1.0 2692 996 pts/3 R 12:16 0:00 ps -aux Command being timed: &quot;ps -aux&quot; User time (seconds): 0.05 System time (seconds): 0.06 Percent of CPU this job got: 68% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 0 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 238 Minor (reclaiming a frame) page faults: 46 Voluntary context switches: 0 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 mail使用方式： 1mail [-iInv] [-s subject] [-c cc-addr] [-b bcc-addr] user1 [user 2 ...] 使用说明： mail 不仅只是一个指令, mail 还是一个电子邮件程式,不过利用 mail 来读信的人应该很少吧！对于系统管理者来说 mail 就很有用,因为管理者可以用 mail 写成 script ,定期寄一些备忘录提醒系统的使用者。 i 忽略 tty 的中断讯号。 (interrupt) I 强迫设成互动模式。 (Interactive) v 列印出讯息,例如送信的地点,状态等等。 (verbose) n 不读入 mail.rc 设定档。 s 邮件标题。 c cc 邮件地址。 b bcc 邮件地址。 范例： 将信件送给一个或以上的电子邮件地址,由于没有加入其他的选项,使用者必须输入标题与信件的内容等。而 user2 没有主机位置,就会送给邮件伺服器的 user2 使用者。 12mail user1@email.address mail user1@email.address user2 将 mail.txt 的内容寄给 user2 同时 cc 给 user1 。如果将这一行指令设成 cronjob 就可以定时将备忘录寄给系统使用者。 1mail -s 标题 -c user1 user2 &lt; mail.txt","categories":["0.平台","Linux","其他"]},{"title":"时间编程","path":"/2024/05/22/0-平台-Linux-其他-时间编程/","content":"时间类型Coordinated Unicersal Time（UTC）：世界标准时间，也就是大家所熟知的格林威治标准时间（Greenwich Mean Time 吗 GMT） Calendar Time：日历时间，是用“从一个标准时间点（如：1970 年 1 月 1 日 0 点）到此时经过的秒数”来表示时间 时间获取获取日历时间，即从 1970 年 1 月 1 日 0 点到现在所经历的秒数 12#include &lt;time.h&gt;time_t time(time_t*tloc); 将日历时间转化为格林威治标准时间，并保存至 TM 结构 1struct tm *gmtime(const time_t*timep); 将日历时间转化为本地时间，并保存至 TM 结构 1struct tm *localtime(const time_t*timep); 1234567891011struct tm &#123;int tm_sec; /* Seconds(0-60) */int tm_min; /* Minutes(0-59) */int tm_hour; /* Hours(0-23) */int tm_mday; /* Day of the month (1-31) */int tm_mon; /* Month (0-11) */int tm_year; /* Year - 1900 */int tm_wday; /* Day of the week (0-6, Sunday = 0) */int tm_yday; /* Dayin the year (0-365, 1 Jan = 0) */int tm_isdst; /* Daylightsaving time */&#125;; 将 tm 格式的时间转化为字符串，如：Sat Jul 30 08：43：03：2005 1char*asctime(conststruct tm *tm); 将日历时间转化为本地时间的字符串形式 1char*ctime(const time_t*timep); 获取从今日凌晨到现在的时间差，常用于计算事件耗时 12#include &lt;sys/time.h&gt;int gettimeofday(struct timeval *tv,struct timezone *tz); 1234struct timeval &#123;time_t tv_sec; /*seconds*/ 秒数suseconds_t tv_usec; /* microseconds*/ 微秒&#125;; 延时执行使程序睡眠 seconds 12#include &lt;unistd.h&gt;unsigned intsleep(unsigned intseconds); 使程序睡眠 usec 微秒 12#include &lt;unistd.h&gt;int usleep(useconds_t usec);","categories":["0.平台","Linux","其他"]},{"title":"Markdown语法","path":"/2024/05/22/1-语言-前端-Markdown语法/","content":"Markdown 基础介绍Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 Markdown 能被使用来撰写电子书，如：Gitbook。 标题Markdown 标题有两种格式。 使用 &#x3D; 和 - 标记一级和二级标题 1234一级标题=================二级标题----------------- 使用 # 号可表示 1-6 级标题，一级标题对应一个 # 号。 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 段落Markdown 段落的换行有两种格式。 使用两个以上空格加上回车 在段落后面使用一个空行 字体123456*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ 分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 12345**** * ******- - ----------- 删除线如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线 ~~ 即可 1~~这是要删除的文本~~ 下划线利用 html 的 &lt;u&gt; 标签 1&lt;u&gt;带下划线文本&lt;/u&gt; 脚注脚注是对文本的补充说明。 Markdown 脚注的格式如下: [^要注明的文本] 列表Markdown 支持有序列表和无序列表。 无序列表使用星号 (*)、加号 (+) 或是减号 (-) 作为列表标记，这些标记后面要添加一个空格，然后再填写内容 123456789* 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项 有序列表使用数字并加上 . 号来表示 1231. 第一项2. 第二项3. 第三项 列表嵌套只需在子列表中的选项前面添加两个或四个空格即可 1234561. 第一项：- 第一项嵌套的第一个元素- 第一项嵌套的第二个元素2. 第二项：- 第二项嵌套的第一个元素- 第二项嵌套的第二个元素 区块 Markdown 区块引用是在段落开头使用 &gt; 符号 ，然后后面紧跟一个空格符号 区块是可以嵌套的，一个 &gt; 符号是最外层，两个 &gt; 符号是第一层嵌套 区块中也可以使用列表 列表中也可以使用区块，需要在 &gt; 前添加四个空格的缩进 1234567891011&gt; 区块&gt;&gt; 区块嵌套&gt;&gt;&gt; 区块嵌套&gt; 1. 区块列表1&gt; 2. 区块列表2&gt; + 区块列表1&gt; + 区块列表2* 列表1&gt; 列表区块1&gt; 列表区块2* 列表2 代码段落上的一个函数或片段的代码可以用反引号把它包起来（&#96;） 1`printf()` 代码块 四个空格 tab 制表符 用 ``&#96; 包裹一段代码，并指定一种语言 链接12[链接名称](baidu.com)&lt;baidu.com&gt; 高级链接 123这个链接用 1 作为网址变量 [Google][1]然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ 图片12![alt 属性文本](图片地址)![alt 属性文本](图片地址 &quot;可选标题&quot;) 也可以按照高级链接的方式，将图片地址放在文档结尾图片大小如果要修改图片大小，采用 html 的 &lt;img&gt; 标签 表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行 1234| 表头 | 表头 || ---- | ---- || 单元格 | 单元格 || 单元格 | 单元格 | 对齐 -: 设置内容和标题栏居右对齐。 :- 设置内容和标题栏居左对齐。 :-: 设置内容和标题栏居中对齐。 Markdown 技巧 不同的 markdown 编辑器支持的语法略有不同，下方介绍的相关技巧不一定支持 Github Flavored Markdown (GFM) 的工作清单语法 显示效果 KaTeX 数学公式排版语法语法 显示效果 SVG 向量流程图语法 显示效果 向量 UML 顺序图表语法 显示效果","categories":["1.语言","前端"]},{"title":"WireShark的安装","path":"/2024/05/22/3-软件-WireShark-WireShark的安装/","content":"WireShark重点演示： 如何选择网卡接口 如何设置过滤条件 如何查看抓取的报文 Linux 下安装和配置安装1sudo apt-get install wireshark 设置运行权限如果您在此阶段以非 root 用户身份运行 wireshark，您将收到消息“没有接口可以用于在当前配置的系统中进行捕获。” 缺省在非 root 账号下运行会发现看不见 interface 信息 Create the wiresharkgroup. 1sudo groupadd wireshark Add your username to the wiresharkgroup 1sudo usermod -a -G wiresharkYOUR_USER_NAME Change the group ownership of file dumpcap to wireshark 1sudo chgrp wireshark/usr/bin/dumpcap Change the mode of the file dumpcap to allow execution bythe group wireshark 1sudo chmod 750 /usr/bin/dumpcap Grant capabilities with setcap, man capabilities(7), setcap(8), cap_from_text(3) for more info about what are “cap_net_raw”, “cap_net_admin” and “eip”. Anyway, after we grant the capabilities, the dump can perform various network-related operations, use RAW and PACKET sockets; bind to anyaddressfor transparent proxying. 1sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap Verifythe change 1sudo getcap /usr/bin/dumpcap Outputshould be like below: 1/usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip At this point, you will need to log out, then backinto ubuntu 简单介绍下这个软件的一些常用按钮，简单的说下最常用的按钮，打开软件后，下面红框中的按钮从左到右依次是： -1 列表显示所有网卡的网络包情况，一般用的很少； -2 显示抓包选项，一般都是点这个按钮开始抓包； -3 开始新的抓包，一般用的也很少； -4 停止抓包，当你抓完包之后，就是点这个停止了； -5 清空当前已经抓到的数据包，可以防止抓包时间过长机器变卡； 而实际上，一般我们只要知道上面加粗部分的按钮功能，就可以完成抓包了，剩下的就是如何抓你想要的数据包，如何分析的问题了。 接下来说下抓包选项界面，也就是点第二个按钮出来的界面，同样，这里也只介绍最常用的几个功能，首先下图中最上面的红框是选择需要抓的网卡，选择好网卡后会在下面显示这个网卡的 IP 地址。 然后 Capture Filter 中就是要写抓包规则的地方，也叫做“过滤规则”，我们下面要说的很多规则都是要写到这个框里的，规则写好后，点下 面的 Start 就开始抓包了。 当抓包结束之后，如果你需要把抓到的数据包找其他人分析，那么可以点菜单上的 file，然后点 Save As 保存抓到的数据包 使用 Wireshark 时最常见的问题，是当您使用默认设置时，会得到大量冗余信息，以至于很难找到自己需要的部分。这就是为什么过滤器会 如此重要。它们可以帮助我们在庞杂的结果中迅速找到我们需要的信息。 三次握手 Three-way Handshake一个虚拟连接的建立是通过三次握手来实现的 (Client) –&gt; [SYN] –&gt; (Server)假如 Client 和 Server 通讯. 当 Client 要和 Server 通信时，Client 首先向 Server 发一个 SYN (Synchronize) 标记的包，告诉 Server 请求建立连接.注意: 一个 SYN 包就是仅 SYN 标记设为 1 的 TCP 包 (参见 TCP 包头 Resources). 认识到这点很重要，只有当 Server 收到 Client 发来的 SYN 包，才可建立连接，除此之外别无他法。因此，如果你的防火墙丢弃所有的发往外网接口的 SYN 包，那么你将不 能让外部任何主机主动建立连接。 (Client) &lt;– [SYN&#x2F;ACK] &lt;–(Server)接着，Server 收到来自 Client 发来的 SYN 包后，会发一个对 SYN 包的确认包 (SYN&#x2F;ACK) 给 Client，表示对第一个 SYN 包的确认，并继续握手操作.注意: SYN&#x2F;ACK 包是仅 SYN 和 ACK 标记为 1 的包. (Client) –&gt; [ACK] –&gt; (Server)Client 收到来自 Server 的 SYN&#x2F;ACK 包,Client 会再向 Server 发一个确认包 (ACK)，通知 Server 连接已建立。至此，三次握手完成，一个 TCP 连接完成。Note: ACK 包就是仅 ACK 标记设为 1 的 TCP 包. 需要注意的是当三此握手完成、连接建立以后，TCP 连接的每个包都会设置 ACK 位。 这就是为何连接跟踪很重要的原因了. 没有连接跟踪,防火墙将无法判断收到的 ACK 包是否属于一个已经建立的连接.一般的包过滤 (Ipchains) 收到 ACK 包时,会让它通过 (这绝对不是个 好主意). 而当状态型防火墙收到此种包时，它会先在连接表中查找是否属于哪个已建连接，否则丢弃该包。 四次握手 Four-way Handshake 四次握手用来关闭已建立的 TCP 连接 (Client) –&gt; ACK&#x2F;FIN –&gt; (Server) (Client) &lt;– ACK &lt;– (Server) (Client) &lt;– ACK&#x2F;FIN &lt;– (Server) (Client) –&gt; ACK –&gt; (Server)注意: 由于 TCP 连接是双向连接, 因此关闭连接需要在两个方向上做。**ACK&#x2F;FIN 包 (ACK 和 FIN 标记设为 1) 通常被认为是 FIN(终结) 包.**然而, 由于连接还没有关闭, FIN 包总是打上 ACK 标记. 没有 ACK 标记而仅有 FIN 标记的包不是合法的包，并且通常被认为是恶意的。 连接复位 Resetting a connection四次握手不是关闭 TCP 连接的唯一方法. 有时,如果主机需要尽快关闭连接 (或连接超时,端口或主机不可达),RST(Reset) 包将被发送. 注意在，由于 RST 包不是 TCP 连接中的必须部分, 可以只发送 RST 包 (即不带 ACK 标记). 但在正常的 TCP 连接中 RST 包可以带 ACK 确认标记 请注意 RST 包是可以不要收到方确认的? 无效的 TCP 标记 Invalid TCP Flags 到目前为止，你已经看到了 SYN, ACK, FIN, 和 RST 标记. 另外，还有 PSH (Push) 和 URG (Urgent) 标记. 最常见的非法组合是 SYN&#x2F;FIN 包. 注意: 由于 SYN 包是用来初始化连接的, 它不可能和 FIN 和 RST 标记一起出现. 这也是一个恶意攻击. 由于现在大多数防火墙已知 SYN&#x2F;FIN 包, 别的一些组合,例如 SYN&#x2F;FIN&#x2F;PSH, SYN&#x2F;FIN&#x2F;RST, SYN&#x2F;FIN&#x2F;RST&#x2F;PSH。很明显，当网络中出现这种包时，很你的网络肯定受到攻击了。 别的已知的非法包有 FIN (无 ACK 标记) 和”NULL”包。如同早先讨论的，由于 ACK&#x2F;FIN 包的出现是为了关闭一个 TCP 连接，那么正常的 FIN 包总是带有 ACK 标记。”NULL”包就是没有任何 TCP 标记的包 (URG,ACK,PSH,RST,SYN,FIN 都为 0)。 到目前为止，正常的网络活动下，TCP 协议栈不可能产生带有上面提到的任何一种标记组合的 TCP 包。当你发现这些不正常的包时，肯定有人对你的网络不怀好意。 UDP (用户数据包协议 User DatagramProtocol)TCP 是面向连接的，而 UDP 是非连接的协议。UDP 没有对接受进行确认的标记和确认机制。对丢包的处理是在应用层来完成的。(or accidentalarrival).此处需要重点注意的事情是：在正常情况下，当 UDP 包到达一个关闭的端口时，会返回一个 UDP 复位包。由于 UDP 是非面向连接的, 因此没有任何确认信息来确认包是否正确到达目的地。因此如果你的防火墙丢弃 UDP 包，它会开放所有的 UDP 端口 (?)。 由于 Internet 上正常情况下一些包将被丢弃，甚至某些发往已关闭端口 (非防火墙的) 的 UDP 包将不会到达目的，它们将返回一个复位 UDP 包。 因为这个原因，UDP 端口扫描总是不精确、不可靠的。 看起来大 UDP 包的碎片是常见的 DOS(Denial ofService) 攻击的常见形式 (这里有个 DOS 攻击的例子，http://grc.com/dos/grcdos.htm ). ICMP (网间控制消息协议 Internet ControlMessage Protocol)如同名字一样， ICMP 用来在主机&#x2F;路由器之间传递控制信息的协议。 ICMP 包可以包含诊断信息 (ping, traceroute - 注意目前 unix 系统中的 traceroute 用 UDP 包而不是 ICMP)，错误信息 (网络&#x2F;主机&#x2F;端口 不可达 network&#x2F;host&#x2F;port unreachable), 信息 (时间戳 timestamp, 地址掩码 addressmaskrequest, etc.)，或控制信息 (source quench, redirect, etc.) 。 你可以在 http://www.iana.org/assignments/icmp-parameters 中找到 ICMP 包的类型。 尽管 ICMP 通常是无害的，还是有些类型的 ICMP 信息需要丢弃。 Redirect (5), Alternate Host Address(6), Router Advertisement (9) 能用来转发通讯。 Echo (8), Timestamp (13)and AddressMask Request (17) 能用来分别判断主机是否起来，本地时间 和地址掩码。注意它们是和返回的信息类别有关的。 它们自己本身是不能被利用的，但它们泄露出的信息对攻击者是有用的。 ICMP 消息有时也被用来作为 DOS 攻击的一部分 (例如：洪水 ping flood ping,死 ping ?呵呵，有趣 ping of death)?&#x2F;p&gt; 包碎片注意 A Note About Packet Fragmentation 如果一个包的大小超过了 TCP 的最大段长度 MSS(Maximum Segment Size) 或 MTU (Maximum Transmission Unit)，能够把此包发往目的的唯一 方法是把此包分片。由于包分片是正常的，它可以被利用来做恶意的攻击。 因为分片的包的第一个分片包含一个包头，若没有包分片的重组功能，包过滤器不可能检测附加的包分片。典型的攻击 Typicalattacks involve in overlapping the packet data in which packet header is 典型的攻击 Typicalattacksinvolve in overlapping the packet data in which packet header isnormal until isit overwritten with different destination IP (or port) thereby bypassing firewall rules。包分片能作为 DOS 攻击的一部分，它 可以 crash older IP stacks 或涨死 CPU 连接能力。 Netfilter&#x2F;Iptables 中的连接跟踪代码能自动做分片重组。它仍有弱点，可能受到饱和连接攻击，可以把 CPU 资源耗光。 OK，到此为止，关于 Wireshark 抓包工具的一些小教程已经写完了，而导致我想写这么一个纠结的教程的原因是，前几天通过这个抓包解决了梦幻西游在网维大师无盘上容易掉线的问题，当时捕捉到梦幻西游掉线时的数据包是这样的。 注意下图中的红色数据，123.58.184.241 是梦幻西游的服务器，而 192.168.1.41 是玩梦幻西游的客户机，在掉线时，发现是先有梦幻西游的服务器向客户机发送一个 [FIN,ACK] 数据包，根据上面的解释，FIN 标记的数据包是代表要断开连接的意思，而接着客户机又回给服务器一个确认断 开链接包。当看到这个抓包数据时，就意识到，大家说的在网维大师系统虚拟盘上梦幻爱掉线的问题，并非普通的网络问题，因为通过数据包的信息来看，是梦幻服 务器主动要求断开链接，产生这个情况无非是以下几个原因： 服务器发现客户端非法，比如有外挂什么的，踢掉了客户机； 服务器压力大，踢掉了客户机； 总之不是客户端问题导致的掉线； 那么既然结论是如此，为什么会有在网维大师系统虚拟盘上容易出现梦幻掉线问题呢？原因是由于网维大师系统虚拟盘是模拟真实硬盘方式来实现的，而在模拟过程 中，将硬盘的序列号设置为固定过的 OSDIY888 了，而梦幻西游刚好后识别客户机硬盘信息，发现大量客户端的硬盘序列号都是一样的，就认为是作弊或者使 用挂机外挂了，结果就导致随机被服务器踢下线的情况发生，后来我们将硬盘序列号设置为空，则没再出现该问题。这个问题在未来的新版本中会解决掉。 说这个案例的目的并不是为了说明抓包多有用，而是想说明一些解决问题的思路和方法，有些人是有思路，但是缺方法，比如不会用工具，而有些人收集了很多工具 却不会用，而我其实就属于后者，几年前就收集了 n 多工具，但是用到的没几个。慢慢的学会用这些工具后，发现思维 + 工具，解决问题是效率暴增，接下来的几天 里，会陆续介绍写小工具给大家，也希望大家有空学习下，有问题先百度，再自己摸索，而不是一味的求助，毕竟求人不如求己！自己能直接搞定，是皆大欢喜的事情 注意：由于某些系统为了防止 ARP 攻击，都免疫掉了一个 Npptools.dll 文件，这会导致该软件无法正常安装，打下这个补丁就可以了","categories":["3.软件","WireShark"]},{"title":"WireShark过滤器","path":"/2024/05/22/3-软件-WireShark-WireShark过滤器/","content":"什么是 wiresharkWireshark 是一款开源的网络封包分析软件。它可以捕获、分析和展示计算机网络中的数据包。Wireshark 支持多种网络协议，包括以太网、无线网络、Internet 协议（IP）、传输控制协议（TCP）、用户数据报协议（UDP）等等。 使用 Wireshark，您可以通过连接到计算机网络上的一个接口来捕获网络数据包。捕获的数据包将被 Wireshark 以可视化的方式显示出来，您可以查看每个数据包的详细信息，例如源 IP 地址、目标 IP 地址、协议类型、数据长度等等。 Wireshark 提供了强大的过滤功能，使您能够根据特定的条件过滤数据包，以便更好地分析网络流量。它还提供了许多分析工具和统计功能，如流量图表、协议分层显示、数据包重组等，帮助用户深入了解网络通信并发现潜在的问题。 Wireshark 是一个广泛应用于网络管理、网络安全和网络协议开发的工具。它能够帮助网络管理员诊断和解决网络故障，分析网络性能问题，检测网络安全事件，以及进行协议开发和调试等任务。由于其功能强大且易于使用，Wireshark 成为了网络分析领域的标准工具之一。 过滤器在 Wireshark 中，过滤器（Filter）是一种机制，用于选择和筛选特定的网络数据包以供分析。过滤器允许您根据特定的条件仅显示感兴趣的数据包，从而减少分析的数据量并集中精力于关注的内容。 Wireshark 使用一种称为 “ 显示过滤器 “（Display Filter）的语法来定义过滤条件。您可以根据多个参数，如源&#x2F;目标 IP 地址、协议类型、端口号、数据包长度、特定字段的值等等，创建过滤器规则。当过滤器应用于数据包捕获或已保存的数据包时，只有符合过滤条件的数据包会被显示，而其他数据包将被隐藏。 通过使用过滤器，您可以根据您的需求来选择显示的数据包，使得分析更加高效和专注。例如，您可以创建一个过滤器来只显示特定源 IP 地址的数据包，或者只显示某个协议类型的数据包，以便更好地关注您感兴趣的通信流量。 Wireshark 提供了广泛的过滤器语法和功能，使您能够根据不同的需求创建复杂的过滤条件。您可以使用比较运算符、逻辑运算符、通配符等来构建更精确的过滤规则，并根据需要组合多个条件来定义更复杂的过滤器。 过滤器在网络分析和故障排除中非常有用，可以帮助您集中注意力于感兴趣的数据包，提供更清晰和有针对性的分析。 过滤器的区别捕捉过滤器（CaptureFilters）：用于决定将什么样的信息记录在捕捉结果中。需要在开始捕捉前设置。 显示过滤器（DisplayFilters）：在捕捉结果中进行详细查找。他们可以在得到捕捉结果后随意修改。 两种过滤器的目的是不同的。 捕捉过滤器是数据经过的第一层过滤器，它用于控制捕捉数据的数量，以避免产生过大的日志文件。 显示过滤器是一种更为强大（复杂）的过滤器。它允许您在日志文件中迅速准确地找到所需要的记录。 两种过滤器使用的语法是完全不同的。 捕捉过滤器Protocol（协议）: 可能的值: ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp. 如果没有特别指明是什么协议，则默认使用所有支持的协议。 Direction（方向）: 可能的值: src, dst, src and dst, src or dst 如果没有特别指明来源或目的地，则默认使用 “src or dst” 作为关键字。 例如，”host 10.2.2.2″与”src or dst host 10.2.2.2″是一样的。 Host(s): 可能的值： net, port, host, portrange. 如果没有指定此值，则默认使用”host”关键字。 例如，”src 10.1.1.1″与”src host 10.1.1.1″相同。 Logical Operations（逻辑运算）: 可能的值：not, and, or. 否 (“not”) 具有最高的优先级。或 (“or”) 和与 (“and”) 具有相同的优先级，运算时从左至右进行。 例如， “not tcp port 3128 and tcp port 23″与”(not tcp port 3128) and tcp port 23″相同。 “not tcp port 3128 and tcp port 23″与”not (tcp port 3128 and tcp port 23)”不同。 例子： tcp dst port 3128 &#x2F;&#x2F;捕捉目的 TCP 端口为 3128 的封包。 ip src host 10.1.1.1 &#x2F;&#x2F;捕捉来源 IP 地址为 10.1.1.1 的封包。 host 10.1.2.3 &#x2F;&#x2F;捕捉目的或来源 IP 地址为 10.1.2.3 的封包。 ether host e0-05-c5-44-b1-3c &#x2F;&#x2F;捕捉目的或来源 MAC 地址为 e0-05-c5-44-b1-3c 的封包。如果你想抓本机与所有外网通讯的数据包时，可以将这里的 mac 地址换成路由的 mac 地址即可。 src portrange 2000-2500 &#x2F;&#x2F;捕捉来源为 UDP 或 TCP，并且端口号在 2000 至 2500 范围内的封包。 not imcp &#x2F;&#x2F;显示除了 icmp 以外的所有封包。（icmp 通常被 ping 工具使用） src host 10.7.2.12 and not dst net 10.200.0.0&#x2F;16 &#x2F;&#x2F;显示来源 IP 地址为 10.7.2.12，但目的地不是 10.200.0.0&#x2F;16 的封包。 (src host 10.4.1.12 or src net 10.6.0.0&#x2F;16) and tcp dst portrange 200-10000 and dst net 10.0.0.0&#x2F;8 &#x2F;&#x2F;捕捉来源 IP 为 10.4.1.12 或者来源网络为 10.6.0.0&#x2F;16，目的地 TCP 端口号在 200 至 10000 之间，并且目的位于网络 10.0.0.0&#x2F;8 内的所有封包。 src net 192.168.0.0&#x2F;24 src net 192.168.0.0 mask 255.255.255.0 &#x2F;&#x2F;捕捉源地址为 192.168.0.0 网络内的所有封包。 注意事项： 当使用关键字作为值时，需使用反斜杠“\\”。“ether proto \\ip” (与关键字”ip”相同). Ether proto 0x0800这样写将会以 IP 协议作为目标。 “ip proto \\icmp” (与关键字”icmp”相同).这样写将会以 ping 工具常用的 icmp 作为目标。 可以在”ip”或”ether”后面使用”multicast”及”broadcast”关键字。当您想排除广播请求时，”no broadcast”就会非常有用。 Protocol（协议）:您可以使用大量位于 OSI 模型第 2 至 7 层的协议。点击”Expression…”按钮后，您可以看到它们。比如：IP，TCP，DNS，SSH String1, String2 (可选项): 协议的子类。点击相关父类旁的”+”号，然后选择其子类。 显示过滤器例子： snmp || dns || icmp &#x2F;&#x2F;显示 SNMP 或 DNS 或 ICMP 封包。 ip.addr &#x3D;&#x3D; 10.1.1.1 &#x2F;&#x2F;显示来源或目的 IP 地址为 10.1.1.1 的封包。 ip.src !&#x3D; 10.1.2.3 or ip.dst !&#x3D; 10.4.5.6 &#x2F;&#x2F;显示来源不为 10.1.2.3 或者目的不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；目的 IP：任意 以及 来源 IP：任意；目的 IP：除了 10.4.5.6 以外任意 ip.src !&#x3D; 10.1.2.3 and ip.dst !&#x3D; 10.4.5.6 &#x2F;&#x2F;显示来源不为 10.1.2.3 并且目的 IP 不为 10.4.5.6 的封包。 换句话说，显示的封包将会为： 来源 IP：除了 10.1.2.3 以外任意；同时须满足，目的 IP：除了 10.4.5.6 以外任意 tcp.port &#x3D;&#x3D; 25 &#x2F;&#x2F;显示来源或目的 TCP 端口号为 25 的封包。 tcp.dstport &#x3D;&#x3D; 25 &#x2F;&#x2F;显示目的 TCP 端口号为 25 的封包。 tcp.flags &#x2F;&#x2F;显示包含 TCP 标志的封包。 tcp.flags.syn &#x3D;&#x3D; 0×02 &#x2F;&#x2F;显示包含 TCP SYN 标志的封包。 如果过滤器的语法是正确的，表达式的背景呈绿色。如果呈红色，说明表达式有误。 更为详细的说明请见：http://openmaniak.com/cn/wireshark_filters.php 以上只是抓包和简单的过滤，那么其实如果你要想达到能够分析这些网络包的要求时，还需要了解下一些数据包的标记，比如我们常说的 TCP 三次握手是怎么回事？","categories":["3.软件","WireShark"]},{"title":"Qt操作Sqlite3","path":"/2024/05/22/1-语言-Qt-Qt操作Sqlite3/","content":"创建数据库1234567891011121314void SqliteOperator::CreatDb()&#123; if(QSqlDatabase::contains(&quot;qt_sql_default_connection&quot;)) &#123; db = QSqlDatabase::database(&quot;qt_sql_default_connection&quot;); &#125; else &#123; db = QSqlDatabase::addDatabase(&quot;QSQLITE&quot;); db.setDatabaseName(&quot;test.db&quot;); db.setUserName(&quot;test&quot;); db.setPassword(&quot;test&quot;); &#125;&#125; 打开及关闭数据库1234567891011121314bool SqliteOperator::OpenDb()&#123; if(!db.open()) &#123; qDebug() &lt;&lt; &quot;Error: Failed to connect database.&quot; &lt;&lt; db.lastError(); return false; &#125; return true;&#125;void SqliteOperator::CloseDb()&#123; db.close();&#125; 创建数据表1234567891011121314void SqliteOperator::CreateTable()&#123; QSqlQuery sql_query; QString creat_sql = &quot;create table student (id int primary key, name varchar(30), age int)&quot;; sql_query.prepare(creat_sql); if(!sql_query.exec()) &#123; qDebug() &lt;&lt; &quot;Error: Fail to create table.&quot; &lt;&lt; sql_query.lastError(); &#125; else &#123; qDebug() &lt;&lt; &quot;Table created!&quot;; &#125;&#125; 插入数据123456789101112131415161718void SqliteOperator::InsertData()&#123; QString insert_sql = &quot;insert into student values (?, ?, ?)&quot;; QSqlQuery sql_query; sql_query.prepare(insert_sql);sql_query.addBindValue(GetMaxId() +1); sql_query.addBindValue(&quot;Wang&quot;); sql_query.addBindValue(25); if(!sql_query.exec()) &#123; qDebug() &lt;&lt; sql_query.lastError(); &#125; else &#123; qDebug() &lt;&lt; &quot;inserted Wang!&quot;; &#125;&#125; 查询数据1234567891011121314151617181920void SqliteOperator::QueryAllData()&#123; QString select_all_sql = &quot;select * from student&quot;; QSqlQuery sql_query; sql_query.prepare(select_all_sql); if(!sql_query.exec()) &#123; qDebug()&lt;&lt;sql_query.lastError(); &#125; else &#123; while(sql_query.next()) &#123; int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); int age = sql_query.value(2).toInt(); qDebug()&lt;&lt;QString(&quot;id:%1 name:%2 age:%3&quot;).arg(id).arg(name).arg(age); &#125; &#125;&#125; 条件查询123456789101112131415161718192021void SqliteOperator::QueryData()&#123; QString select_sql = QString(&quot;select * from student where name = &#x27;%1&#x27; and (age = &#x27;%2&#x27; or age = &#x27;%3&#x27;)&quot;) .arg(&quot;Wang&quot;) .arg(30) .arg(25); QSqlQuery sql_query; if(!sql_query.exec(select_sql)) &#123; qDebug()&lt;&lt;sql_query.lastError(); &#125; else &#123; while(sql_query.next()) &#123; int id = sql_query.value(0).toInt(); QString name = sql_query.value(1).toString(); qDebug()&lt;&lt;QString(&quot;id:%1 name:%2&quot;).arg(id).arg(name); &#125; &#125;&#125;","categories":["1.语言","Qt"]},{"title":"JavaScript学习笔记","path":"/2024/05/22/1-语言-前端-JavaScript学习笔记/","content":"JavaScript 用法HTML 中的 Javascript 脚本代码必须位于 &lt;script&gt; 与 &lt;/script&gt; 标签之间。 通常，我们需要在某个事件发生时执行代码，比如当用户点击按钮时。 如果我们把 JavaScript 代码放入函数中，就可以在事件发生时调用该函数。 Javascript 脚本代码可被放置在 HTML 页面的 &lt;body&gt; 和 &lt;head&gt; 部分中。 通常的做法是把函数放入 &lt;head&gt; 部分中，或者放在页面底部。这样就可以把它们安置到同一处位置，不会干扰页面的内容。 外部的 JavaScript也可以把脚本保存到外部文件中。外部文件通常包含被多个网页使用的代码。 外部 JavaScript 文件的文件扩展名是 .js。 如需使用外部文件，请在 &lt;script&gt; 标签的 “src” 属性中设置该 .js 文件： 12345&lt;button type=&quot;button&quot; onclick=&quot;myFunction()&quot;&gt;点击这里&lt;/button&gt;&lt;p&gt;&lt;b&gt;注释：&lt;/b&gt;myFunction 保存在名为 &quot;myScript.js&quot; 的外部文件中。&lt;/p&gt;&lt;script src=&quot;myScript.js&quot;&gt;&lt;/script&gt;\t&lt;/body&gt; js 代码如下： 1234function myFunction()&#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;我的第一个 JavaScript 函数&quot;;&#125; 外部脚本不能包含 &lt;script&gt; 标签。在标签中填写 onclick 事件调用函数时，不是 onclick&#x3D;函数名， 而是 onclick&#x3D;函数名 +() JavaScript JSONJSON 英文全称 JavaScript Object Notation JSON 是用于存储和传输数据的格式。 JSON 通常用于服务端向网页传递数据 。 数据为 键&#x2F;值 对。 数据由逗号分隔。 大括号保存对象 方括号保存数组 JSON 是 JS 对象的字符串表示法。它使用文本表示一个 JS 对象的信息，（JSON）本质是一个字符串。 JSON 字符串转换为 JavaScript 对象 1234567 var text = &#x27;&#123; &quot;sites&quot; : [&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Runoob&quot; , &quot;url&quot;:&quot;www.runoob.com&quot; &#125;,&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Google&quot; , &quot;url&quot;:&quot;www.google.com&quot; &#125;,&#x27; + &#x27;&#123; &quot;name&quot;:&quot;Taobao&quot; , &quot;url&quot;:&quot;www.taobao.com&quot; &#125; ]&#125;&#x27;; obj = JSON.parse(text);document.getElementById(&quot;demo&quot;).innerHTML = obj.sites[1].name + &quot; &quot; + obj.sites[1].url; JSON.parse()\t用于将一个 JSON 字符串转换为 JavaScript 对象。 JSON.stringify()\t用于将 JavaScript 值转换为 JSON 字符串。 运行与调试在 Chrome 浏览器中可以通过按下 F12 按钮或者右击页面，选择 “ 检查 “ 来开启开发者工具 或者在右上角菜单栏选择 “ 更多工具 “&#x3D;》” 开发者工具 “ 来开启 Console 窗口调试 JavaScript 代码我们在 &gt; 符号后输入我们要执行的代码 console.log(“runoob”)，按回车后执行 清空 Console 窗口到内容 Chrome snippets 小脚本我们也可以在 Chrome 浏览器中创建一个脚本来执行，在开发者工具中点击 Sources 面板，选择 Snippets 选项卡，在导航器中右击鼠标，然后选择 Create new snippet 来新建一个脚本文件 点击 Create new snippet 后，会自动创建一个文件，你只需在右侧窗口输入以下代码，然后按 Ctrl+S 保存更改即可。 保存后，右击文件名，选择 “Run” 执行代码 设置断点debugger 关键字 JavaScript 输出 使用 window.alert() 弹出警告框。 使用 document.write() 方法将内容写到 HTML 文档中。 使用 innerHTML 写入到 HTML 元素。 使用 console.log() 写入到浏览器的控制台。 数据类型JavaScript 字面量 数字（Number）字面量 可以是整数或者是小数，或者是科学计数 (e)。 字符串（String）字面量 可以使用单引号或双引号: 表达式字面量 用于计算： 5 + 6 数组（Array）字面量 定义一个数组：[40, 100, 1, 5, 25, 10] 对象（Object）字面量 定义一个对象：{firstName:”John”, lastName:”Doe”, age:50, eyeColor:”blue”} 函数（Function）字面量 定义一个函数：function myFunction(a, b) { return a * b;} 变量 var 关键词来声明变量 当您声明新变量时，可以使用关键词 “new” 来声明其类型： 12345var carname=new String;var x= new Number;var y= new Boolean;var cars= new Array;var person= new Object; 变量的数据类型可以使用 typeof 操作符来查看： 值类型 (基本类型)： 字符串（String） var x &#x3D; “John”; 数字 (Number) var x &#x3D; 5; 布尔 (Boolean) var x&#x3D;true; 空（Null） 未定义（Undefined）\tvar x; Symbol。 引用数据类型（对象类型）： 对象 (Object) 123456789 var person = &#123; firstName: &quot;John&quot;, lastName : &quot;Doe&quot;, id : 5566, fullName : function() &#123; return this.firstName + &quot; &quot; + this.lastName; &#125;&#125;; 对象属性有两种寻址方式：name&#x3D;person.lastname;name&#x3D;person[“lastname”]; 数组 (Array) 1var cars=[&quot;Saab&quot;,&quot;Volvo&quot;,&quot;BMW&quot;]; var cars&#x3D;new Array();cars[0]&#x3D;”Saab”;cars[1]&#x3D;”Volvo”;cars[2]&#x3D;”BMW”;或者 (condensed array):var cars&#x3D;new Array(“Saab”,”Volvo”,”BMW”);或者 (literal array):var cars&#x3D;[“Saab”,”Volvo”,”BMW”]; 函数 (Function) 12345678 &lt;button onclick=&quot;myFunction(&#x27;Harry Potter&#x27;,&#x27;Wizard&#x27;)&quot;&gt;点击这里&lt;/button&gt;&lt;button onclick=&quot;myFunction(&#x27;Bob&#x27;,&#x27;Builder&#x27;)&quot;&gt;点击这里&lt;/button&gt;&lt;script&gt;function myFunction(name,job)&#123;\talert(&quot;Welcome &quot; + name + &quot;, the &quot; + job);&#125;&lt;/script&gt; 带有返回值的函数 123456 function myFunction()&#123; var x=5; return x;&#125;var myVar=myFunction(); 函数表达式 1var x = function (a, b) &#123;return a * b&#125;; 还有两个特殊的对象： 正则（RegExp） &#x2F;正则表达式主体&#x2F;修饰符 (可选) 1234 var patt = /runoob/i //字符串 var n = str.search(/Runoob/i); var patt = /e/; //正则patt.test(&quot;The best things in life are free!&quot;); &#x2F;runoob&#x2F;i 是一个正则表达式。runoob 是一个正则表达式主体 (用于检索)。i 是一个修饰符 (搜索不区分大小写)。 在 JavaScript 中，正则表达式通常用于两个字符串方法 : search() 和 replace()。 search() 方法用于检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串，并返回子串的起始位置。 replace() 方法用于在字符串中用一些字符串替换另一些字符串，或替换一个与正则表达式匹配的子串。 test() 方法用于检测一个字符串是否匹配某个模式，如果字符串中含有匹配的文本，则返回 true，否则返回 false。 exec() 方法用于检索字符串中的正则表达式的匹配。 日期（Date） 生存周期 局部变量 在 JavaScript 函数内部声明的变量（使用 var）是局部变量，所以只能在函数内部访问它。（该变量的作用域是局部的）。 全局变量函数外声明的变量是全局变量，网页上的所有脚本和函数都能访问它。 事件HTML 事件可以是浏览器行为，也可以是用户行为。 HTML 页面完成加载 HTML input 字段改变时 HTML 按钮被点击 |事件 |描述 | |:–: |:–: | |onchange |HTML 元素改变 | |onclick |用户点击 HTML 元素 | |onmouseover\t|鼠标指针移动到指定的元素上时发生 | |onmouseout |用户从一个 HTML 元素上移开鼠标时发生\t| |onkeydown |用户按下键盘按键 | |onload |浏览器已完成页面的加载 | 语句条件语句if-else 1234567if (condition1)&#123; 当条件 1 为 true 时执行的代码&#125;else if (condition2)&#123; 当条件 2 为 true 时执行的代码&#125;else&#123; 当条件 1 和 条件 2 都不为 true 时执行的代码&#125; switch 1234567891011switch(n)&#123; case 1: 执行代码块 1 break; case 2: 执行代码块 2 break; default: 与 case 1 和 case 2 不同时执行的代码&#125; 循环语句for 1234for (var i=0,len=cars.length; i&lt;len; i++)&#123; document.write(cars[i] + &quot;&lt;br&gt;&quot;);&#125; 123456var person=&#123;fname:&quot;Bill&quot;,lname:&quot;Gates&quot;,age:56&#125;; for (x in person) // x 为属性名&#123; txt=txt + person[x];&#125; while 1234while (条件)&#123; 需要执行的代码&#125; 12345do&#123; 需要执行的代码&#125;while (条件); 其他breakcontinuetypeof检测变量的数据类型nullnull 是一个只有一个值的特殊类型。表示一个空对象引用。undefinedundefined 是一个没有设置值的变量 null 和 undefined 的值相等，但类型不等 错误处理 try 语句测试代码块的错误。 catch 语句处理错误。 throw 语句创建自定义错误。 finally 语句在 try 和 catch 语句之后，无论是否有触发异常，该语句都会执行。 异步编程回调函数这段程序中的 setTimeout 就是一个消耗时间较长（3 秒）的过程，它的第一个参数是个回调函数，第二个参数是毫秒数，这个函数执行之后会产生一个子线程，子线程会等待 3 秒，然后执行回调函数 “print”，在命令行输出 “RUNOOB!”。 1234function print() &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;setTimeout(print, 3000); 123setTimeout(function () &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;, 3000); JavaScript Promise类JavaScript HTML DOMHTML DOM (文档对象模型)（Document Object Model） 通过 id 找到 HTML 元素 1var x=document.getElementById(&quot;intro&quot;); 通过标签名找到 HTML 元素 12var x=document.getElementById(&quot;main&quot;);var y=x.getElementsByTagName(&quot;p&quot;); 通过类名找到 HTML 元素 1var x=document.getElementsByClassName(&quot;intro&quot;); JavaScript HTML DOM - 改变 HTML内容 12345678&lt;html&gt;&lt;body&gt;&lt;p id=&quot;p1&quot;&gt;Hello World!&lt;/p&gt;&lt;script&gt;document.getElementById(&quot;p1&quot;).innerHTML=&quot;新文本!&quot;;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 属性 12345678&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;img id=&quot;image&quot; src=&quot;smiley.gif&quot;&gt;&lt;script&gt;document.getElementById(&quot;image&quot;).src=&quot;landscape.jpg&quot;;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; JavaScript HTML DOM - 改变 CSS12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p id=&quot;p1&quot;&gt;Hello World!&lt;/p&gt;&lt;p id=&quot;p2&quot;&gt;Hello World!&lt;/p&gt;&lt;script&gt;document.getElementById(&quot;p2&quot;).style.color=&quot;blue&quot;;document.getElementById(&quot;p2&quot;).style.fontFamily=&quot;Arial&quot;;document.getElementById(&quot;p2&quot;).style.fontSize=&quot;larger&quot;;&lt;/script&gt;&lt;p&gt;以上段落通过脚本修改。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; JavaScript HTML DOM 事件123&lt;script&gt;document.getElementById(&quot;myBtn&quot;).onclick=function()&#123;displayDate()&#125;;&lt;/script&gt; onload 和 onunload 事件会在用户进入或离开页面时被触发。 onchange 事件常结合对输入字段的验证来使用。 onmouseover 和 onmouseout 事件可用于在用户的鼠标移至 HTML 元素上方或移出元素时触发函数。 onmousedown, onmouseup 以及 onclick 构成了鼠标点击事件的所有部分。首先当点击鼠标按钮时，会触发 onmousedown 事件，当释放鼠标按钮时，会触发 onmouseup 事件，最后，当完成鼠标点击时，会触发 onclick 事件。 总结JavaScript：直接写入 HTML 输出流12document.write(&quot;&lt;h1&gt;这是一个标题&lt;/h1&gt;&quot;);document.write(&quot;&lt;p&gt;这是一个段落。&lt;/p&gt;&quot;); 您只能在 HTML 输出流中使用 document.write。 如果您在文档已加载后使用它（比如在函数中），会覆盖整个文档。 JavaScript：对事件的反应1&lt;button type=&quot;button&quot; onclick=&quot;alert(&#x27;欢迎!&#x27;)&quot;&gt;点我!&lt;/button&gt; JavaScript：改变 HTML 内容12x=document.getElementById(&quot;demo&quot;); //查找元素x.innerHTML=&quot;Hello JavaScript&quot;; //改变内容 DOM (Document Object Model)（文档对象模型）是用于访问 HTML 元素的正式 W3C 标准。 JavaScript：改变 HTML 图像123456789101112131415&lt;script&gt;function changeImage()&#123; element=document.getElementById(&#x27;myimage&#x27;) if (element.src.match(&quot;bulbon&quot;)) &#123; element.src=&quot;/images/pic_bulboff.gif&quot;; &#125; else &#123; element.src=&quot;/images/pic_bulbon.gif&quot;; &#125;&#125;&lt;/script&gt;&lt;img decoding=&quot;async&quot; loading=&quot;lazy&quot; id=&quot;myimage&quot; onclick=&quot;changeImage()&quot; src=&quot;/images/pic_bulboff.gif&quot; width=&quot;100&quot; height=&quot;180&quot;&gt; JavaScript：改变 HTML 样式12x=document.getElementById(&quot;demo&quot;) //找到元素 x.style.color=&quot;#ff0000&quot;; //改变样式 JavaScript：验证输入1234567891011&lt;input id=&quot;demo&quot; type=&quot;text&quot;&gt;&lt;script&gt;function myFunction()&#123;\tvar x=document.getElementById(&quot;demo&quot;).value;\tif(isNaN(x)||x.replace(/(^\\s*)|(\\s*$)/g,&quot;&quot;)==&quot;&quot;)&#123; alert(&quot;不是数字&quot;);\t&#125;&#125;&lt;/script&gt;&lt;button type=&quot;button&quot; onclick=&quot;myFunction()&quot;&gt;点击这里&lt;/button&gt;","categories":["1.语言","前端"]},{"title":"虚拟机磁盘收缩","path":"/2024/05/22/0-平台-VMware-虚拟机磁盘收缩/","content":"1. 删除快照打开 VMware，选择工具栏的虚拟机，选择快照，选择快照管理器，删除不用的快照 2. 删除缓存文件打开虚拟机，删除虚拟机中的缓存文件目录： rm -rf /home/forlinx/.cache/vmware/drag_and_drop df -h 指令可查找到磁盘真实占据的磁盘空间 3. 压缩磁盘空间当虚拟机安装盘所剩余的空间大于.vmdk 文件的大小时，强烈推荐使用以下方式 在你的终端输入 sudo /usr/bin/vmware-toolbox-cmd disk list 一般会有 &quot;/&quot; 目录 再输入 sudo /usr/bin/vmware-toolbox-cmd disk shrink / 即压缩根目录 &quot;/&quot; 4. 使用 DiskGenius 压缩存放在物理硬盘上的虚拟磁盘文件的大小并没有减小。虚拟机磁盘文件只会慢慢地变大，虚拟机软件不会在用户删除数据后对虚拟磁盘进行“压缩”。可以使用 DiskGenius 软件进行压缩。比如我们使用的是 VMware 虚拟机，它的虚拟磁盘文件是 vmdk 格式。 1、在 DiskGenius 软件中，首先把要压缩的虚拟磁盘打开（菜单：“硬盘 –&gt; 打开虚拟硬盘文件”）。打开后就可以在左边的窗口中看到加载上的虚拟磁盘了。 2、然后我们再新建一个容量不小于源虚拟硬盘的 vmdk 虚拟磁盘（菜单：“硬盘 –&gt; 新建虚拟硬盘文件 –&gt; 新建 VMware 虚拟硬盘文件”）。 3、开始进行压缩。选择（菜单：“工具 –&gt; 克隆硬盘”），弹出对话框后，在“选择源硬盘”时选择要压缩的 vmdk 虚拟磁盘，在“选择目标硬盘”时选择刚刚我们新建的 vmdk 虚拟磁盘，然后点“开始”。 4、现在已经复制完毕了，我们找到两个虚拟磁盘文件的所在路径，对比一下大小。可以看到，虚拟硬盘被压缩了。 这时，还需要做一些后续的清理工作。首先在 DiskGenius 软件中关闭刚才打开的两个虚拟硬盘，或者直接关闭 DiskGenius 软件。然后将源虚拟硬盘文件改名（备用，以防万一），再将新的虚拟硬盘文件改名为源虚拟硬盘的文件名（注意要完全相同）。最后打开虚拟机，启动一下虚拟系统，没有问题后就可以删除压缩前的源虚拟硬盘文件了。 5. 导出 OVF 重新建立新 vmdk有时候删除虚拟机快照出现错误，但快照图标已消失，导致无法再次删除，造成文件残留，就这样越堆越多，无法清理。 优点是可以释放大量空间，缺点是只能保留 VMware 虚拟机当前的状态和文件，丢失其他快照（可以按需先转到某个快照再导出 OVF，这样就可以保留快照时的状态了。同样，会丢失其他状态）。步骤如下： 点击要清理的虚拟机，然后左上角点击文件，导出为 OVF（只存了虚拟机当前的状态，大概有十几个 G），存到其他空闲的磁盘下。 将上述步骤导出的 ovf 再部署出来，看看虚拟机是否正常。 如果正常可用，就可以把虚拟机原来占用的磁盘清空了，快速释放大量空间。","categories":["0.平台","VMware"]},{"title":"pythonWeb部署方案","path":"/2024/05/22/1-语言-Python-pythonWeb部署方案/","content":"搭建开发环境首先，确认系统安装的 Python 版本是 3.7.x： 12$ python3 --versionPython 3.7.0 然后，用 pip 安装开发 Web App 需要的第三方库： 异步框架 aiohttp： 1$pip3 install aiohttp 前端模板引擎 jinja2： 1$ pip3 install jinja2 MySQL 5.x 数据库，从 官方网站 下载并安装，安装完毕后，请务必牢记 root 口令。为避免遗忘口令，建议直接把 root 口令设置为 password； MySQL 的 Python 异步驱动程序 aiomysql： 1$ pip3 install aiomysql 项目结构选择一个工作目录，然后，我们建立如下的目录结构： 1234567891011121314151617awesome-python3-webapp/ &lt;-- 根目录|+- backup/ &lt;-- 备份目录|+- conf/ &lt;-- 配置文件|+- dist/ &lt;-- 打包目录|+- www/ &lt;-- Web目录，存放.py文件| || +- static/ &lt;-- 存放静态文件| || +- templates/ &lt;-- 存放模板文件|+- ios/ &lt;-- 存放iOS App工程|+- LICENSE &lt;-- 代码LICENSE 创建好项目的目录结构后，建议同时建立 git 仓库并同步至 GitHub，保证代码修改的安全。 Web 骨架由于我们的 Web App 建立在 asyncio 的基础上，因此用 aiohttp 写一个基本的 app.py： 12345678910111213141516import logging; logging.basicConfig(level=logging.INFO)import asyncio, os, json, timefrom datetime import datetimefrom aiohttp import webdef index(request): return web.Response(body=b&#x27;&lt;h1&gt;Awesome&lt;/h1&gt;&#x27;)@asyncio.coroutinedef init(loop): app = web.Application(loop=loop) app.router.add_route(&#x27;GET&#x27;, &#x27;/&#x27;, index) srv = yield from loop.create_server(app.make_handler(), &#x27;127.0.0.1&#x27;, 9000) logging.info(&#x27;server started at http://127.0.0.1:9000...&#x27;) return srvloop = asyncio.get_event_loop()loop.run_until_complete(init(loop))loop.run_forever() 运行 python app.py，Web App 将在 9000 端口监听 HTTP 请求，并且对首页 / 进行响应： 12$ python3 app.pyINFO:root:server started at http://127.0.0.1:9000... 这里我们简单地返回一个 Awesome 字符串，在浏览器中可以看到效果 这说明我们的 Web App 骨架已经搭好了，可以进一步往里面添加更多的东西。 ORMORM 全称是：Object Relational Mapping(对象关系映射)，其主要作用是在编程中，把面向对象的概念跟数据库中表的概念对应起来。举例来说就是，我定义一个对象，那就对应着一张表，这个对象的实例，就对应着表中的一条记录。 在一个 Web App 中，所有数据，包括用户信息、发布的日志、评论等，都存储在数据库中。在 awesome-python3-webapp 中，我们选择 MySQL 作为数据库。 Web App 里面有很多地方都要访问数据库。访问数据库需要创建数据库连接、游标对象，然后执行 SQL 语句，最后处理异常，清理资源。这些访问数据库的代码如果分散到各个函数中，势必无法维护，也不利于代码复用。 所以，我们要首先把常用的 SELECT、INSERT、UPDATE 和 DELETE 操作用函数封装起来。 由于 Web 框架使用了基于 asyncio 的 aiohttp，这是基于协程的异步模型。在协程中，不能调用普通的同步 IO 操作，因为所有用户都是由一个线程服务的，协程的执行速度必须非常快，才能处理大量用户的请求。而耗时的 IO 操作不能在协程中以同步的方式调用，否则，等待一个 IO 操作时，系统无法响应任何其他用户。 这就是异步编程的一个原则：一旦决定使用异步，则系统每一层都必须是异步，“开弓没有回头箭”。 幸运的是 aiomysql 为 MySQL 数据库提供了异步 IO 的驱动。 创建连接池我们需要创建一个全局的连接池，每个 HTTP 请求都可以从连接池中直接获取数据库连接。使用连接池的好处是不必频繁地打开和关闭数据库连接，而是能复用就尽量复用。 连接池由全局变量 __pool 存储，缺省情况下将编码设置为 utf8，自动提交事务： 12345678910111213141516@asyncio.coroutinedef create_pool(loop, **kw): logging.info(&#x27;create database connection pool...&#x27;) global __pool __pool = yield from aiomysql.create_pool( host=kw.get(&#x27;host&#x27;, &#x27;localhost&#x27;), port=kw.get(&#x27;port&#x27;, 3306), user=kw[&#x27;user&#x27;], password=kw[&#x27;password&#x27;], db=kw[&#x27;db&#x27;], charset=kw.get(&#x27;charset&#x27;, &#x27;utf8&#x27;), autocommit=kw.get(&#x27;autocommit&#x27;, True), maxsize=kw.get(&#x27;maxsize&#x27;, 10), minsize=kw.get(&#x27;minsize&#x27;, 1), loop=loop ) Select要执行 SELECT 语句，我们用 select 函数执行，需要传入 SQL 语句和 SQL 参数： 1234567891011121314@asyncio.coroutinedef select(sql, args, size=None): log(sql, args) global __pool with (yield from __pool) as conn: cur = yield from conn.cursor(aiomysql.DictCursor) yield from cur.execute(sql.replace(&#x27;?&#x27;, &#x27;%s&#x27;), args or ()) if size: rs = yield from cur.fetchmany(size) else: rs = yield from cur.fetchall() yield from cur.close() logging.info(&#x27;rows returned: %s&#x27; % len(rs)) return rs SQL 语句的占位符是 ?，而 MySQL 的占位符是 %s，select() 函数在内部自动替换。注意要始终坚持使用带参数的 SQL，而不是自己拼接 SQL 字符串，这样可以防止 SQL 注入攻击。 注意到 yield from 将调用一个子协程（也就是在一个协程中调用另一个协程）并直接获得子协程的返回结果。 如果传入 size 参数，就通过 fetchmany() 获取最多指定数量的记录，否则，通过 fetchall() 获取所有记录。 Insert, Update, Delete要执行 INSERT、UPDATE、DELETE 语句，可以定义一个通用的 execute() 函数，因为这 3 种 SQL 的执行都需要相同的参数，以及返回一个整数表示影响的行数： 123456789101112@asyncio.coroutinedef execute(sql, args): log(sql) with (yield from __pool) as conn: try: cur = yield from conn.cursor() yield from cur.execute(sql.replace(&#x27;?&#x27;, &#x27;%s&#x27;), args) affected = cur.rowcount yield from cur.close() except BaseException as e: raise return affected execute() 函数和 select() 函数所不同的是，cursor 对象不返回结果集，而是通过 rowcount 返回结果数。 ORM有了基本的 select() 和 execute() 函数，我们就可以开始编写一个简单的 ORM 了。 设计 ORM 需要从上层调用者角度来设计。 我们先考虑如何定义一个 User 对象，然后把数据库表 users 和它关联起来。 12345from orm import Model, StringField, IntegerFieldclass User(Model): __table__ = &#x27;users&#x27; id = IntegerField(primary_key=True) name = StringField() 注意到定义在 User 类中的 __table__、id 和 name 是类的属性，不是实例的属性。所以，在类级别上定义的属性用来描述 User 对象和表的映射关系，而实例属性必须通过 __init__() 方法去初始化，所以两者互不干扰： 123456# 创建实例:user = User(id=123, name=&#x27;Michael&#x27;)# 存入数据库:user.insert()# 查询所有User对象:users = User.findAll() 定义 Model首先要定义的是所有 ORM 映射的基类 Model： 123456789101112131415161718192021class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&#x27;Model&#x27; object has no attribute &#x27;%s&#x27;&quot; % key) def __setattr__(self, key, value): self[key] = value def getValue(self, key): return getattr(self, key, None) def getValueOrDefault(self, key): value = getattr(self, key, None) if value is None: field = self.__mappings__[key] if field.default is not None: value = field.default() if callable(field.default) else field.default logging.debug(&#x27;using default value for %s: %s&#x27; % (key, str(value))) setattr(self, key, value) return value Model 从 dict 继承，所以具备所有 dict 的功能，同时又实现了特殊方法 __getattr__() 和 __setattr__()，因此又可以像引用普通字段那样写： 1234&gt;&gt;&gt; user[&#x27;id&#x27;]123&gt;&gt;&gt; user.id123 以及 Field 和各种 Field 子类： 12345678class Field(object): def __init__(self, name, column_type, primary_key, default): self.name = name self.column_type = column_type self.primary_key = primary_key self.default = default def __str__(self): return &#x27;&lt;%s, %s:%s&gt;&#x27; % (self.__class__.__name__, self.column_type, self.name) 映射 varchar 的 StringField： 123class StringField(Field): def __init__(self, name=None, primary_key=False, default=None, ddl=&#x27;varchar(100)&#x27;): super().__init__(name, ddl, primary_key, default) 注意到 Model 只是一个基类，如何将具体的子类如 User 的映射信息读取出来呢？答案就是通过 metaclass：ModelMetaclass： 1234567891011121314151617181920212223242526272829303132333435363738class ModelMetaclass(type): def __new__(cls, name, bases, attrs): # 排除Model类本身: if name==&#x27;Model&#x27;: return type.__new__(cls, name, bases, attrs) # 获取table名称: tableName = attrs.get(&#x27;__table__&#x27;, None) or name logging.info(&#x27;found model: %s (table: %s)&#x27; % (name, tableName)) # 获取所有的Field和主键名: mappings = dict() fields = [] primaryKey = None for k, v in attrs.items(): if isinstance(v, Field): logging.info(&#x27; found mapping: %s ==&gt; %s&#x27; % (k, v)) mappings[k] = v if v.primary_key: # 找到主键: if primaryKey: raise RuntimeError(&#x27;Duplicate primary key for field: %s&#x27; % k) primaryKey = k else: fields.append(k) if not primaryKey: raise RuntimeError(&#x27;Primary key not found.&#x27;) for k in mappings.keys(): attrs.pop(k) escaped_fields = list(map(lambda f: &#x27;`%s`&#x27; % f, fields)) attrs[&#x27;__mappings__&#x27;] = mappings # 保存属性和列的映射关系 attrs[&#x27;__table__&#x27;] = tableName attrs[&#x27;__primary_key__&#x27;] = primaryKey # 主键属性名 attrs[&#x27;__fields__&#x27;] = fields # 除主键外的属性名 # 构造默认的SELECT, INSERT, UPDATE和DELETE语句: attrs[&#x27;__select__&#x27;] = &#x27;select `%s`, %s from `%s`&#x27; % (primaryKey, &#x27;, &#x27;.join(escaped_fields), tableName) attrs[&#x27;__insert__&#x27;] = &#x27;insert into `%s` (%s, `%s`) values (%s)&#x27; % (tableName, &#x27;, &#x27;.join(escaped_fields), primaryKey, create_args_string(len(escaped_fields) + 1)) attrs[&#x27;__update__&#x27;] = &#x27;update `%s` set %s where `%s`=?&#x27; % (tableName, &#x27;, &#x27;.join(map(lambda f: &#x27;`%s`=?&#x27; % (mappings.get(f).name or f), fields)), primaryKey) attrs[&#x27;__delete__&#x27;] = &#x27;delete from `%s` where `%s`=?&#x27; % (tableName, primaryKey) return type.__new__(cls, name, bases, attrs) 这样，任何继承自 Model 的类（比如 User），会自动通过 ModelMetaclass 扫描映射关系，并存储到自身的类属性如 __table__、__mappings__ 中。 然后，我们往 Model 类添加 class 方法，就可以让所有子类调用 class 方法： 12345678910class Model(dict): ... @classmethod @asyncio.coroutine def find(cls, pk): &#x27; find object by primary key. &#x27; rs = yield from select(&#x27;%s where `%s`=?&#x27; % (cls.__select__, cls.__primary_key__), [pk], 1) if len(rs) == 0: return None return cls(**rs[0]) User 类现在就可以通过类方法实现主键查找： 1user = yield from User.find(&#x27;123&#x27;) 往 Model 类添加实例方法，就可以让所有子类调用实例方法： 123456789class Model(dict): ... @asyncio.coroutine def save(self): args = list(map(self.getValueOrDefault, self.__fields__)) args.append(self.getValueOrDefault(self.__primary_key__)) rows = yield from execute(self.__insert__, args) if rows != 1: logging.warn(&#x27;failed to insert record: affected rows: %s&#x27; % rows) 这样，就可以把一个 User 实例存入数据库： 12user = User(id=123, name=&#x27;Michael&#x27;)yield from user.save() 最后一步是完善 ORM，对于查找，我们可以实现以下方法： findAll() - 根据 WHERE 条件查找； findNumber() - 根据 WHERE 条件查找，但返回的是整数，适用于 select count(*) 类型的 SQL。以及 update() 和 remove() 方法。所有这些方法都必须用 @asyncio.coroutine 装饰，变成一个协程。调用时需要特别注意： 1user.save() 没有任何效果，因为调用 save() 仅仅是创建了一个协程，并没有执行它。一定要用： 1yield from user.save() 才真正执行了 INSERT 操作。 编写 Model有了 ORM，我们就可以把 Web App 需要的 3 个表用 Model 表示出来： 1234567891011121314151617181920212223242526272829303132import time, uuidfrom orm import Model, StringField, BooleanField, FloatField, TextFielddef next_id(): return &#x27;%015d%s000&#x27; % (int(time.time() * 1000), uuid.uuid4().hex)class User(Model): __table__ = &#x27;users&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) email = StringField(ddl=&#x27;varchar(50)&#x27;) passwd = StringField(ddl=&#x27;varchar(50)&#x27;) admin = BooleanField() name = StringField(ddl=&#x27;varchar(50)&#x27;) image = StringField(ddl=&#x27;varchar(500)&#x27;) created_at = FloatField(default=time.time)class Blog(Model): __table__ = &#x27;blogs&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) user_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_name = StringField(ddl=&#x27;varchar(50)&#x27;) user_image = StringField(ddl=&#x27;varchar(500)&#x27;) name = StringField(ddl=&#x27;varchar(50)&#x27;) summary = StringField(ddl=&#x27;varchar(200)&#x27;) content = TextField() created_at = FloatField(default=time.time)class Comment(Model): __table__ = &#x27;comments&#x27; id = StringField(primary_key=True, default=next_id, ddl=&#x27;varchar(50)&#x27;) blog_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_id = StringField(ddl=&#x27;varchar(50)&#x27;) user_name = StringField(ddl=&#x27;varchar(50)&#x27;) user_image = StringField(ddl=&#x27;varchar(500)&#x27;) content = TextField() created_at = FloatField(default=time.time) 在编写 ORM 时，给一个 Field 增加一个 default 参数可以让 ORM 自己填入缺省值，非常方便。并且，缺省值可以作为函数对象传入，在调用 save() 时自动计算。 例如，主键 id 的缺省值是函数 next_id，创建时间 created_at 的缺省值是函数 time.time，可以自动设置当前日期和时间。 日期和时间用 float 类型存储在数据库中，而不是 datetime 类型，这么做的好处是不必关心数据库的时区以及时区转换问题，排序非常简单，显示的时候，只需要做一个 float 到 str 的转换，也非常容易。 初始化数据库表如果表的数量很少，可以手写创建表的 SQL 脚本： 12345678910111213141516171819202122232425262728293031323334353637383940-- schema.sqldrop database if exists awesome;create database awesome;use awesome;grant select, insert, update, delete on awesome.* to &#x27;www-data&#x27;@&#x27;localhost&#x27; identified by &#x27;www-data&#x27;;create table users ( `id` varchar(50) not null, `email` varchar(50) not null, `passwd` varchar(50) not null, `admin` bool not null, `name` varchar(50) not null, `image` varchar(500) not null, `created_at` real not null, unique key `idx_email` (`email`), key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table blogs ( `id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `name` varchar(50) not null, `summary` varchar(200) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8;create table comments ( `id` varchar(50) not null, `blog_id` varchar(50) not null, `user_id` varchar(50) not null, `user_name` varchar(50) not null, `user_image` varchar(500) not null, `content` mediumtext not null, `created_at` real not null, key `idx_created_at` (`created_at`), primary key (`id`)) engine=innodb default charset=utf8; 如果表的数量很多，可以从 Model 对象直接通过脚本自动生成 SQL 脚本，使用更简单。 把 SQL 脚本放到 MySQL 命令行里执行： 1$ mysql -u root -p &lt; schema.sql 我们就完成了数据库表的初始化。 编写数据访问代码接下来，就可以真正开始编写代码操作对象了。比如，对于 User 对象，我们就可以做如下操作： 12345678import ormfrom models import User, Blog, Commentdef test(): yield from orm.create_pool(user=&#x27;www-data&#x27;, password=&#x27;www-data&#x27;, database=&#x27;awesome&#x27;) u = User(name=&#x27;Test&#x27;, email=&#x27;test@example.com&#x27;, passwd=&#x27;1234567890&#x27;, image=&#x27;about:blank&#x27;) yield from u.save()for x in test(): pass 可以在 MySQL 客户端命令行查询，看看数据是不是正常存储到 MySQL 里面了。 Web 框架在正式开始 Web 开发前，我们需要编写一个 Web 框架。 aiohttp 已经是一个 Web 框架了，为什么我们还需要自己封装一个？ 原因是从使用者的角度来说，aiohttp 相对比较底层，编写一个 URL 的处理函数需要这么几步： 第一步，编写一个用 @asyncio.coroutine 装饰的函数： 123@asyncio.coroutinedef handle_url_xxx(request): pass 第二步，传入的参数需要自己从 request 中获取： 12url_param = request.match_info[&#x27;key&#x27;]query_params = parse_qs(request.query_string) 最后，需要自己构造 Response 对象： 12text = render(&#x27;template&#x27;, data)return web.Response(text.encode(&#x27;utf-8&#x27;)) 这些重复的工作可以由框架完成。例如，处理带参数的 URL/blog/&#123;id&#125; 可以这么写： 123@get(&#x27;/blog/&#123;id&#125;&#x27;)def get_blog(id): pass 处理 query_string 参数可以通过关键字参数 **kw 或者命名关键字参数接收： 123@get(&#x27;/api/comments&#x27;)def api_comments(*, page=&#x27;1&#x27;): pass 对于函数的返回值，不一定是 web.Response 对象，可以是 str、bytes 或 dict。 如果希望渲染模板，我们可以这么返回一个 dict： 1234return &#123; &#x27;__template__&#x27;: &#x27;index.html&#x27;, &#x27;data&#x27;: &#x27;...&#x27;&#125; 因此，Web 框架的设计是完全从使用者出发，目的是让使用者编写尽可能少的代码。 编写简单的函数而非引入 request 和 web.Response 还有一个额外的好处，就是可以单独测试，否则，需要模拟一个 request 才能测试。 @get 和@post要把一个函数映射为一个 URL 处理函数，我们先定义 @get()： 123456789101112def get(path): &#x27;&#x27;&#x27; Define decorator @get(&#x27;/path&#x27;) &#x27;&#x27;&#x27; def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): return func(*args, **kw) wrapper.__method__ = &#x27;GET&#x27; wrapper.__route__ = path return wrapper return decorator 这样，一个函数通过 @get() 的装饰就附带了 URL 信息。 @post 与 @get 定义类似。 定义 RequestHandlerURL 处理函数不一定是一个 coroutine，因此我们用 RequestHandler() 来封装一个 URL 处理函数。 RequestHandler 是一个类，由于定义了 __call__() 方法，因此可以将其实例视为函数。 RequestHandler 目的就是从 URL 函数中分析其需要接收的参数，从 request 中获取必要的参数，调用 URL 函数，然后把结果转换为 web.Response 对象，这样，就完全符合 aiohttp 框架的要求： 12345678910class RequestHandler(object): def __init__(self, app, fn): self._app = app self._func = fn ... @asyncio.coroutine def __call__(self, request): kw = ... 获取参数 r = yield from self._func(**kw) return r 再编写一个 add_route 函数，用来注册一个 URL 处理函数： 123456789def add_route(app, fn): method = getattr(fn, &#x27;__method__&#x27;, None) path = getattr(fn, &#x27;__route__&#x27;, None) if path is None or method is None: raise ValueError(&#x27;@get or @post not defined in %s.&#x27; % str(fn)) if not asyncio.iscoroutinefunction(fn) and not inspect.isgeneratorfunction(fn): fn = asyncio.coroutine(fn) logging.info(&#x27;add route %s %s =&gt; %s(%s)&#x27; % (method, path, fn.__name__, &#x27;, &#x27;.join(inspect.signature(fn).parameters.keys()))) app.router.add_route(method, path, RequestHandler(app, fn)) 最后一步，把很多次 add_route() 注册的调用： 1234add_route(app, handles.index)add_route(app, handles.blog)add_route(app, handles.create_comment)... 变成自动扫描： 12# 自动把handler模块的所有符合条件的函数注册了:add_routes(app, &#x27;handlers&#x27;) add_routes() 定义如下： 12345678910111213141516def add_routes(app, module_name): n = module_name.rfind(&#x27;.&#x27;) if n == (-1): mod = __import__(module_name, globals(), locals()) else: name = module_name[n+1:] mod = getattr(__import__(module_name[:n], globals(), locals(), [name]), name) for attr in dir(mod): if attr.startswith(&#x27;_&#x27;): continue fn = getattr(mod, attr) if callable(fn): method = getattr(fn, &#x27;__method__&#x27;, None) path = getattr(fn, &#x27;__route__&#x27;, None) if method and path: add_route(app, fn) 最后，在 app.py 中加入 middleware、jinja2 模板和自注册的支持： 123456app = web.Application(loop=loop, middlewares=[ logger_factory, response_factory])init_jinja2(app, filters=dict(datetime=datetime_filter))add_routes(app, &#x27;handlers&#x27;)add_static(app) middlewaremiddleware 是一种拦截器，一个 URL 在被某个函数处理前，可以经过一系列的 middleware 的处理。 一个 middleware 可以改变 URL 的输入、输出，甚至可以决定不继续处理而直接返回。middleware 的用处就在于把通用的功能从每个 URL 处理函数中拿出来，集中放到一个地方。例如，一个记录 URL 日志的 logger 可以简单定义如下： 123456789@asyncio.coroutinedef logger_factory(app, handler): @asyncio.coroutine def logger(request): # 记录日志: logging.info(&#x27;Request: %s %s&#x27; % (request.method, request.path)) # 继续处理请求: return (yield from handler(request)) return logger 而 response 这个 middleware 把返回值转换为 web.Response 对象再返回，以保证满足 aiohttp 的要求： 123456789101112131415161718@asyncio.coroutinedef response_factory(app, handler): @asyncio.coroutine def response(request): # 结果: r = yield from handler(request) if isinstance(r, web.StreamResponse): return r if isinstance(r, bytes): resp = web.Response(body=r) resp.content_type = &#x27;application/octet-stream&#x27; return resp if isinstance(r, str): resp = web.Response(body=r.encode(&#x27;utf-8&#x27;)) resp.content_type = &#x27;text/html;charset=utf-8&#x27; return resp if isinstance(r, dict): ... 有了这些基础设施，我们就可以专注地往 handlers 模块不断添加 URL 处理函数了，可以极大地提高开发效率。 配置文件有了 Web 框架和 ORM 框架，我们就可以开始装配 App 了。 通常，一个 Web App 在运行时都需要读取配置文件，比如数据库的用户名、口令等，在不同的环境中运行时，Web App 可以通过读取不同的配置文件来获得正确的配置。 由于 Python 本身语法简单，完全可以直接用 Python 源代码来实现配置，而不需要再解析一个单独的 .properties 或者 .yaml 等配置文件。 默认的配置文件应该完全符合本地开发环境，这样，无需任何设置，就可以立刻启动服务器。 我们把默认的配置文件命名为 config_default.py： 12345678910111213# config_default.pyconfigs = &#123; &#x27;db&#x27;: &#123; &#x27;host&#x27;: &#x27;127.0.0.1&#x27;, &#x27;port&#x27;: 3306, &#x27;user&#x27;: &#x27;www-data&#x27;, &#x27;password&#x27;: &#x27;www-data&#x27;, &#x27;database&#x27;: &#x27;awesome&#x27; &#125;, &#x27;session&#x27;: &#123; &#x27;secret&#x27;: &#x27;AwEsOmE&#x27; &#125;&#125; 上述配置文件简单明了。但是，如果要部署到服务器时，通常需要修改数据库的 host 等信息，直接修改 config_default.py 不是一个好办法，更好的方法是编写一个 config_override.py，用来覆盖某些默认设置： 123456# config_override.pyconfigs = &#123; &#x27;db&#x27;: &#123; &#x27;host&#x27;: &#x27;192.168.0.100&#x27; &#125;&#125; 把 config_default.py 作为开发环境的标准配置，把 config_override.py 作为生产环境的标准配置，我们就可以既方便地在本地开发，又可以随时把应用部署到服务器上。 应用程序读取配置文件需要优先从 config_override.py 读取。为了简化读取配置文件，可以把所有配置读取到统一的 config.py 中： 1234567# config.pyconfigs = config_default.configstry: import config_override configs = merge(configs, config_override.configs)except ImportError: pass 这样，我们就完成了 App 的配置。 MVC现在，ORM 框架、Web 框架和配置都已就绪，我们可以开始编写一个最简单的 MVC，把它们全部启动起来。 通过 Web 框架的 @get 和 ORM 框架的 Model 支持，可以很容易地编写一个处理首页 URL 的函数： 1234567@get(&#x27;/&#x27;)def index(request): users = yield from User.findAll() return &#123; &#x27;__template__&#x27;: &#x27;test.html&#x27;, &#x27;users&#x27;: users &#125; &#39;__template__&#39; 指定的模板文件是 test.html，其他参数是传递给模板的数据，所以我们在模板的根目录 templates 下创建 test.html： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;Test users - Awesome Python Webapp&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;All users&lt;/h1&gt; &#123;% for u in users %&#125; &lt;p&gt;&#123;&#123; u.name &#125;&#125; / &#123;&#123; u.email &#125;&#125;&lt;/p&gt; &#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 接下来，如果一切顺利，可以用命令行启动 Web 服务器： 1$ python3 app.py 然后，在浏览器中访问 http://localhost:9000/。 如果数据库的 users 表什么内容也没有，你就无法在浏览器中看到循环输出的内容。可以自己在 MySQL 的命令行里给 users 表添加几条记录，然后再访问 构建前端对于复杂的 HTML 前端页面来说，我们需要一套基础的 CSS 框架来完成页面布局和基本样式。另外，jQuery 作为操作 DOM 的 JavaScript 库也必不可少。 从零开始写 CSS 不如直接从一个已有的功能完善的 CSS 框架开始。有很多 CSS 框架可供选择。我们这次选择 uikit 这个强大的 CSS 框架。它具备完善的响应式布局，漂亮的 UI，以及丰富的 HTML 组件，让我们能轻松设计出美观而简洁的页面。 可以从 uikit首页 下载打包的资源文件。 所有的静态资源文件我们统一放到 www/static 目录下，并按照类别归类： 1234567891011121314151617181920static/+- css/| +- addons/| | +- uikit.addons.min.css| | +- uikit.almost-flat.addons.min.css| | +- uikit.gradient.addons.min.css| +- awesome.css| +- uikit.almost-flat.addons.min.css| +- uikit.gradient.addons.min.css| +- uikit.min.css+- fonts/| +- fontawesome-webfont.eot| +- fontawesome-webfont.ttf| +- fontawesome-webfont.woff| +- FontAwesome.otf+- js/ +- awesome.js +- html5.js +- jquery.min.js +- uikit.min.js 由于前端页面肯定不止首页一个页面，每个页面都有相同的页眉和页脚。如果每个页面都是独立的 HTML 模板，那么我们在修改页眉和页脚的时候，就需要把每个模板都改一遍，这显然是没有效率的。 常见的模板引擎已经考虑到了页面上重复的 HTML 部分的复用问题。有的模板通过 include 把页面拆成三部分： 12345&lt;html&gt; &lt;% include file=&quot;inc_header.html&quot; %&gt; &lt;% include file=&quot;index_body.html&quot; %&gt; &lt;% include file=&quot;inc_footer.html&quot; %&gt;&lt;/html&gt; 这样，相同的部分 inc_header.html 和 inc_footer.html 就可以共享。 但是 include 方法不利于页面整体结构的维护。jinjia2 的模板还有另一种“继承”方式，实现模板的复用更简单。 “继承”模板的方式是通过编写一个“父模板”，在父模板中定义一些可替换的 block（块）。然后，编写多个“子模板”，每个子模板都可以只替换父模板定义的 block。比如，定义一个最简单的父模板： 123456789&lt;!-- base.html --&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;&#123;% block title%&#125; 这里定义了一个名为title的block &#123;% endblock %&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &#123;% block content %&#125; 这里定义了一个名为content的block &#123;% endblock %&#125; &lt;/body&gt;&lt;/html&gt; 对于子模板 a.html，只需要把父模板的 title 和 content 替换掉： 123456&#123;% extends &#x27;base.html&#x27; %&#125;&#123;% block title %&#125; A &#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt;Chapter A&lt;/h1&gt; &lt;p&gt;blablabla...&lt;/p&gt;&#123;% endblock %&#125; 对于子模板 b.html，如法炮制： 123456789&#123;% extends &#x27;base.html&#x27; %&#125;&#123;% block title %&#125; B &#123;% endblock %&#125;&#123;% block content %&#125; &lt;h1&gt;Chapter B&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;list 1&lt;/li&gt; &lt;li&gt;list 2&lt;/li&gt; &lt;/ul&gt;&#123;% endblock %&#125; 这样，一旦定义好父模板的整体布局和 CSS 样式，编写子模板就会非常容易。 让我们通过 uikit 这个 CSS 框架来完成父模板 __base__.html 的编写： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &#123;% block meta %&#125;&lt;!-- block meta --&gt;&#123;% endblock %&#125; &lt;title&gt;&#123;% block title %&#125; ? &#123;% endblock %&#125; - Awesome Python Webapp&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/uikit.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/uikit.gradient.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/awesome.css&quot; /&gt; &lt;script src=&quot;/static/js/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/md5.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/uikit.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/static/js/awesome.js&quot;&gt;&lt;/script&gt; &#123;% block beforehead %&#125;&lt;!-- before head --&gt;&#123;% endblock %&#125;&lt;/head&gt;&lt;body&gt; &lt;nav class=&quot;uk-navbar uk-navbar-attached uk-margin-bottom&quot;&gt; &lt;div class=&quot;uk-container uk-container-center&quot;&gt; &lt;a href=&quot;/&quot; class=&quot;uk-navbar-brand&quot;&gt;Awesome&lt;/a&gt; &lt;ul class=&quot;uk-navbar-nav&quot;&gt; &lt;li data-url=&quot;blogs&quot;&gt;&lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;uk-icon-home&quot;&gt;&lt;/i&gt; 日志&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-book&quot;&gt;&lt;/i&gt; 教程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-code&quot;&gt;&lt;/i&gt; 源码&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&quot;uk-navbar-flip&quot;&gt; &lt;ul class=&quot;uk-navbar-nav&quot;&gt; &#123;% if user %&#125; &lt;li class=&quot;uk-parent&quot; data-uk-dropdown&gt; &lt;a href=&quot;#0&quot;&gt;&lt;i class=&quot;uk-icon-user&quot;&gt;&lt;/i&gt; &#123;&#123; user.name &#125;&#125;&lt;/a&gt; &lt;div class=&quot;uk-dropdown uk-dropdown-navbar&quot;&gt; &lt;ul class=&quot;uk-nav uk-nav-navbar&quot;&gt; &lt;li&gt;&lt;a href=&quot;/signout&quot;&gt;&lt;i class=&quot;uk-icon-sign-out&quot;&gt;&lt;/i&gt; 登出&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &#123;% else %&#125; &lt;li&gt;&lt;a href=&quot;/signin&quot;&gt;&lt;i class=&quot;uk-icon-sign-in&quot;&gt;&lt;/i&gt; 登陆&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/register&quot;&gt;&lt;i class=&quot;uk-icon-edit&quot;&gt;&lt;/i&gt; 注册&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/nav&gt; &lt;div class=&quot;uk-container uk-container-center&quot;&gt; &lt;div class=&quot;uk-grid&quot;&gt; &lt;!-- content --&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;!-- // content --&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-margin-large-top&quot; style=&quot;background-color:#eee; border-top:1px solid #ccc;&quot;&gt; &lt;div class=&quot;uk-container uk-container-center uk-text-center&quot;&gt; &lt;div class=&quot;uk-panel uk-margin-top uk-margin-bottom&quot;&gt; &lt;p&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-weibo&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-github&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-linkedin-square&quot;&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot; class=&quot;uk-icon-button uk-icon-twitter&quot;&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Powered by &lt;a href=&quot;#&quot;&gt;Awesome Python Webapp&lt;/a&gt;. Copyright &amp;copy; 2014. [&lt;a href=&quot;/manage/&quot; target=&quot;_blank&quot;&gt;Manage&lt;/a&gt;]&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://www.liaoxuefeng.com/&quot; target=&quot;_blank&quot;&gt;www.liaoxuefeng.com&lt;/a&gt;. All rights reserved.&lt;/p&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;uk-icon-html5&quot; style=&quot;font-size:64px; color: #444;&quot;&gt;&lt;/i&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; __base__.html 定义的几个 block 作用如下： 用于子页面定义一些 meta，例如 rss feed： 1&#123;% block meta %&#125; ... &#123;% endblock %&#125; 覆盖页面的标题： 1&#123;% block title %&#125; ... &#123;% endblock %&#125; 子页面可以在 &lt;head&gt; 标签关闭前插入 JavaScript 代码： 1&#123;% block beforehead %&#125; ... &#123;% endblock %&#125; 子页面的 content 布局和内容： 123&#123;% block content %&#125; ...&#123;% endblock %&#125; 我们把首页改造一下，从 __base__.html 继承一个 blogs.html： 1234567891011121314151617181920212223242526&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;日志&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-medium-3-4&quot;&gt; &#123;% for blog in blogs %&#125; &lt;article class=&quot;uk-article&quot;&gt; &lt;h2&gt;&lt;a href=&quot;/blog/&#123;&#123; blog.id &#125;&#125;&quot;&gt;&#123;&#123; blog.name &#125;&#125;&lt;/a&gt;&lt;/h2&gt; &lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; blog.summary &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/blog/&#123;&#123; blog.id &#125;&#125;&quot;&gt;继续阅读 &lt;i class=&quot;uk-icon-angle-double-right&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt; &lt;/article&gt; &lt;hr class=&quot;uk-article-divider&quot;&gt; &#123;% endfor %&#125; &lt;/div&gt; &lt;div class=&quot;uk-width-medium-1-4&quot;&gt; &lt;div class=&quot;uk-panel uk-panel-header&quot;&gt; &lt;h3 class=&quot;uk-panel-title&quot;&gt;友情链接&lt;/h3&gt; &lt;ul class=&quot;uk-list uk-list-line&quot;&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;编程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;读书&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;Python教程&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;uk-icon-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;a target=&quot;_blank&quot; href=&quot;#&quot;&gt;Git教程&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&#123;% endblock %&#125; 相应地，首页 URL 的处理函数更新如下： 123456789101112@get(&#x27;/&#x27;)def index(request): summary = &#x27;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.&#x27; blogs = [ Blog(id=&#x27;1&#x27;, name=&#x27;Test Blog&#x27;, summary=summary, created_at=time.time()-120), Blog(id=&#x27;2&#x27;, name=&#x27;Something New&#x27;, summary=summary, created_at=time.time()-3600), Blog(id=&#x27;3&#x27;, name=&#x27;Learn Swift&#x27;, summary=summary, created_at=time.time()-7200) ] return &#123; &#x27;__template__&#x27;: &#x27;blogs.html&#x27;, &#x27;blogs&#x27;: blogs &#125; Blog 的创建日期显示的是一个浮点数，因为它是由这段模板渲染出来的： 1&lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at &#125;&#125;&lt;/p&gt; 解决方法是通过 jinja2 的 filter（过滤器），把一个浮点数转换成日期字符串。我们来编写一个 datetime 的 filter，在模板里用法如下： 1&lt;p class=&quot;uk-article-meta&quot;&gt;发表于&#123;&#123; blog.created_at|datetime &#125;&#125;&lt;/p&gt; filter 需要在初始化 jinja2 时设置。相关代码如下： 123456789101112131415def datetime_filter(t): delta = int(time.time() - t) if delta &lt; 60: return &#x27;1分钟前&#x27; if delta &lt; 3600: return &#x27;%s分钟前&#x27; % (delta // 60) if delta &lt; 86400: return &#x27;%s小时前&#x27; % (delta // 3600) if delta &lt; 604800: return &#x27;%s天前&#x27; % (delta // 86400) dt = datetime.fromtimestamp(t) return &#x27;%s年%s月%s日&#x27; % (dt.year, dt.month, dt.day)...init_jinja2(app, filters=dict(datetime=datetime_filter))... 现在，完善的首页显示如下 编写 API什么是 Web API 呢？ 如果我们想要获取一篇 Blog，输入 http://localhost:9000/blog/123，就可以看到 id 为 123 的 Blog 页面，但这个结果是 HTML 页面，它同时混合包含了 Blog 的数据和 Blog 的展示两个部分。对于用户来说，阅读起来没有问题，但是，如果机器读取，就很难从 HTML 中解析出 Blog 的数据。 如果一个 URL 返回的不是 HTML，而是机器能直接解析的数据，这个 URL 就可以看成是一个 Web API。比如，读取 http://localhost:9000/api/blogs/123，如果能直接返回 Blog 的数据，那么机器就可以直接读取。 REST 就是一种设计 API 的模式。最常用的数据格式是 JSON。由于 JSON 能直接被 JavaScript 读取，所以，以 JSON 格式编写的 REST 风格的 API 具有简单、易读、易用的特点。 编写 API 有什么好处呢？由于 API 就是把 Web App 的功能全部封装了，所以，通过 API 操作数据，可以极大地把前端和后端的代码隔离，使得后端代码易于测试，前端代码编写更简单。 一个 API 也是一个 URL 的处理函数，我们希望能直接通过一个 @api 来把函数变成 JSON 格式的 REST API，这样，获取注册用户可以用一个 API 实现如下： 1234567891011@get(&#x27;/api/users&#x27;)def api_get_users(*, page=&#x27;1&#x27;): page_index = get_page_index(page) num = yield from User.findNumber(&#x27;count(id)&#x27;) p = Page(num, page_index) if num == 0: return dict(page=p, users=()) users = yield from User.findAll(orderBy=&#x27;created_at desc&#x27;, limit=(p.offset, p.limit)) for u in users: u.passwd = &#x27;******&#x27; return dict(page=p, users=users) 只要返回一个 dict，后续的 response 这个 middleware 就可以把结果序列化为 JSON 并返回。 我们需要对 Error 进行处理，因此定义一个 APIError，这种 Error 是指 API 调用时发生了逻辑错误（比如用户不存在），其他的 Error 视为 Bug，返回的错误代码为 internalerror。 客户端调用 API 时，必须通过错误代码来区分 API 调用是否成功。错误代码是用来告诉调用者出错的原因。很多 API 用一个整数表示错误码，这种方式很难维护错误码，客户端拿到错误码还需要查表得知错误信息。更好的方式是用字符串表示错误代码，不需要看文档也能猜到错误原因。 可以在浏览器直接测试 API，例如，输入 http://localhost:9000/api/users，就可以看到返回的 JSON： 功能注册和登录用户管理是绝大部分 Web 网站都需要解决的问题。用户管理涉及到用户注册和登录。 用户注册相对简单，我们可以先通过 API 把用户注册这个功能实现了： 123456789101112131415161718192021222324_RE_EMAIL = re.compile(r&#x27;^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)&#123;1,4&#125;$&#x27;)_RE_SHA1 = re.compile(r&#x27;^[0-9a-f]&#123;40&#125;$&#x27;)@post(&#x27;/api/users&#x27;)def api_register_user(*, email, name, passwd): if not name or not name.strip(): raise APIValueError(&#x27;name&#x27;) if not email or not _RE_EMAIL.match(email): raise APIValueError(&#x27;email&#x27;) if not passwd or not _RE_SHA1.match(passwd): raise APIValueError(&#x27;passwd&#x27;) users = yield from User.findAll(&#x27;email=?&#x27;, [email]) if len(users) &gt; 0: raise APIError(&#x27;register:failed&#x27;, &#x27;email&#x27;, &#x27;Email is already in use.&#x27;) uid = next_id() sha1_passwd = &#x27;%s:%s&#x27; % (uid, passwd) user = User(id=uid, name=name.strip(), email=email, passwd=hashlib.sha1(sha1_passwd.encode(&#x27;utf-8&#x27;)).hexdigest(), image=&#x27;http://www.gravatar.com/avatar/%s?d=mm&amp;s=120&#x27; % hashlib.md5(email.encode(&#x27;utf-8&#x27;)).hexdigest()) yield from user.save() # make session cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = &#x27;******&#x27; r.content_type = &#x27;application/json&#x27; r.body = json.dumps(user, ensure_ascii=False).encode(&#x27;utf-8&#x27;) return r 注意用户口令是客户端传递的经过 SHA1 计算后的 40 位 Hash 字符串，所以服务器端并不知道用户的原始口令。 接下来可以创建一个注册页面，让用户填写注册表单，然后，提交数据到注册用户的 API： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;注册&#123;% endblock %&#125;&#123;% block beforehead %&#125;&lt;script&gt;function validateEmail(email) &#123; var re = /^[a-z0-9\\.\\-\\_]+\\@[a-z0-9\\-\\_]+(\\.[a-z0-9\\-\\_]+)&#123;1,4&#125;$/; return re.test(email.toLowerCase());&#125;$(function () &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: &#123; name: &#x27;&#x27;, email: &#x27;&#x27;, password1: &#x27;&#x27;, password2: &#x27;&#x27; &#125;, methods: &#123; submit: function (event) &#123; event.preventDefault(); var $form = $(&#x27;#vm&#x27;); if (! this.name.trim()) &#123; return $form.showFormError(&#x27;请输入名字&#x27;); &#125; if (! validateEmail(this.email.trim().toLowerCase())) &#123; return $form.showFormError(&#x27;请输入正确的Email地址&#x27;); &#125; if (this.password1.length &lt; 6) &#123; return $form.showFormError(&#x27;口令长度至少为6个字符&#x27;); &#125; if (this.password1 !== this.password2) &#123; return $form.showFormError(&#x27;两次输入的口令不一致&#x27;); &#125; var email = this.email.trim().toLowerCase(); $form.postJSON(&#x27;/api/users&#x27;, &#123; name: this.name.trim(), email: email, passwd: CryptoJS.SHA1(email + &#x27;:&#x27; + this.password1).toString() &#125;, function (err, r) &#123; if (err) &#123; return $form.showFormError(err); &#125; return location.assign(&#x27;/&#x27;); &#125;); &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;);&lt;/script&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-2-3&quot;&gt; &lt;h1&gt;欢迎注册！&lt;/h1&gt; &lt;form id=&quot;vm&quot; v-on=&quot;submit: submit&quot; class=&quot;uk-form uk-form-stacked&quot;&gt; &lt;div class=&quot;uk-alert uk-alert-danger uk-hidden&quot;&gt;&lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;名字:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;name&quot; type=&quot;text&quot; maxlength=&quot;50&quot; placeholder=&quot;名字&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;电子邮件:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;email&quot; type=&quot;text&quot; maxlength=&quot;50&quot; placeholder=&quot;your-name@example.com&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;输入口令:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;password1&quot; type=&quot;password&quot; maxlength=&quot;50&quot; placeholder=&quot;输入口令&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;重复口令:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;password2&quot; type=&quot;password&quot; maxlength=&quot;50&quot; placeholder=&quot;重复口令&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-user&quot;&gt;&lt;/i&gt; 注册&lt;/button&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&#123;% endblock %&#125; 这样我们就把用户注册的功能完成了 用户登录比用户注册复杂。由于 HTTP 协议是一种无状态协议，而服务器要跟踪用户状态，就只能通过 cookie 实现。大多数 Web 框架提供了 Session 功能来封装保存用户状态的 cookie。 Session 的优点是简单易用，可以直接从 Session 中取出用户登录信息。 Session 的缺点是服务器需要在内存中维护一个映射表来存储用户登录信息，如果有两台以上服务器，就需要对 Session 做集群，因此，使用 Session 的 Web App 很难扩展。 我们采用直接读取 cookie 的方式来验证用户登录，每次用户访问任意 URL，都会对 cookie 进行验证，这种方式的好处是保证服务器处理任意的 URL 都是无状态的，可以扩展到多台服务器。 由于登录成功后是由服务器生成一个 cookie 发送给浏览器，所以，要保证这个 cookie 不会被客户端伪造出来。 实现防伪造 cookie 的关键是通过一个单向算法（例如 SHA1），举例如下： 当用户输入了正确的口令登录成功后，服务器可以从数据库取到用户的 id，并按照如下方式计算出一个字符串： 1&quot;用户id&quot; + &quot;过期时间&quot; + SHA1(&quot;用户id&quot; + &quot;用户口令&quot; + &quot;过期时间&quot; + &quot;SecretKey&quot;) 当浏览器发送 cookie 到服务器端后，服务器可以拿到的信息包括： 用户 id 过期时间 SHA1 值如果未到过期时间，服务器就根据用户 id 查找用户口令，并计算： 1SHA1(&quot;用户id&quot; + &quot;用户口令&quot; + &quot;过期时间&quot; + &quot;SecretKey&quot;) 并与浏览器 cookie 中的哈希进行比较，如果相等，则说明用户已登录，否则，cookie 就是伪造的。 这个算法的关键在于 SHA1 是一种单向算法，即可以通过原始字符串计算出 SHA1 结果，但无法通过 SHA1 结果反推出原始字符串。 所以登录 API 可以实现如下： 1234567891011121314151617181920212223242526272829303132@post(&#x27;/api/authenticate&#x27;)def authenticate(*, email, passwd): if not email: raise APIValueError(&#x27;email&#x27;, &#x27;Invalid email.&#x27;) if not passwd: raise APIValueError(&#x27;passwd&#x27;, &#x27;Invalid password.&#x27;) users = yield from User.findAll(&#x27;email=?&#x27;, [email]) if len(users) == 0: raise APIValueError(&#x27;email&#x27;, &#x27;Email not exist.&#x27;) user = users[0] # check passwd: sha1 = hashlib.sha1() sha1.update(user.id.encode(&#x27;utf-8&#x27;)) sha1.update(b&#x27;:&#x27;) sha1.update(passwd.encode(&#x27;utf-8&#x27;)) if user.passwd != sha1.hexdigest(): raise APIValueError(&#x27;passwd&#x27;, &#x27;Invalid password.&#x27;) # authenticate ok, set cookie: r = web.Response() r.set_cookie(COOKIE_NAME, user2cookie(user, 86400), max_age=86400, httponly=True) user.passwd = &#x27;******&#x27; r.content_type = &#x27;application/json&#x27; r.body = json.dumps(user, ensure_ascii=False).encode(&#x27;utf-8&#x27;) return r # 计算加密cookie:def user2cookie(user, max_age): # build cookie string by: id-expires-sha1 expires = str(int(time.time() + max_age)) s = &#x27;%s-%s-%s-%s&#x27; % (user.id, user.passwd, expires, _COOKIE_KEY) L = [user.id, expires, hashlib.sha1(s.encode(&#x27;utf-8&#x27;)).hexdigest()] return &#x27;-&#x27;.join(L) 对于每个 URL 处理函数，如果我们都去写解析 cookie 的代码，那会导致代码重复很多次。 利用 middle 在处理 URL 之前，把 cookie 解析出来，并将登录用户绑定到 request 对象上，这样，后续的 URL 处理函数就可以直接拿到登录用户： 123456789101112131415161718192021222324252627282930313233343536373839404142@asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(&#x27;check user: %s %s&#x27; % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(&#x27;set current user: %s&#x27; % user.email) request.__user__ = user return (yield from handler(request)) return auth # 解密cookie:@asyncio.coroutinedef cookie2user(cookie_str): &#x27;&#x27;&#x27; Parse cookie and load user if cookie is valid. &#x27;&#x27;&#x27; if not cookie_str: return None try: L = cookie_str.split(&#x27;-&#x27;) if len(L) != 3: return None uid, expires, sha1 = L if int(expires) &lt; time.time(): return None user = yield from User.find(uid) if user is None: return None s = &#x27;%s-%s-%s-%s&#x27; % (uid, user.passwd, expires, _COOKIE_KEY) if sha1 != hashlib.sha1(s.encode(&#x27;utf-8&#x27;)).hexdigest(): logging.info(&#x27;invalid sha1&#x27;) return None user.passwd = &#x27;******&#x27; return user except Exception as e: logging.exception(e) return None 这样，我们就完成了用户注册和登录的功能。 编写日志创建页在 Web 开发中，后端代码写起来其实是相当容易的。 例如，我们编写一个 REST API，用于创建一个 Blog： 123456789101112@post(&#x27;/api/blogs&#x27;)def api_create_blog(request, *, name, summary, content): check_admin(request) if not name or not name.strip(): raise APIValueError(&#x27;name&#x27;, &#x27;name cannot be empty.&#x27;) if not summary or not summary.strip(): raise APIValueError(&#x27;summary&#x27;, &#x27;summary cannot be empty.&#x27;) if not content or not content.strip(): raise APIValueError(&#x27;content&#x27;, &#x27;content cannot be empty.&#x27;) blog = Blog(user_id=request.__user__.id, user_name=request.__user__.name, user_image=request.__user__.image, name=name.strip(), summary=summary.strip(), content=content.strip()) yield from blog.save() return blog 编写后端 Python 代码不但很简单，而且非常容易测试，上面的 API：api_create_blog() 本身只是一个普通函数。 Web 开发真正困难的地方在于编写前端页面。前端页面需要混合 HTML、CSS 和 JavaScript，如果对这三者没有深入地掌握，编写的前端页面将很快难以维护。 更大的问题在于，前端页面通常是动态页面，也就是说，前端页面往往是由后端代码生成的。 生成前端页面最早的方式是拼接字符串： 12345s = &#x27;&lt;html&gt;&lt;head&gt;&lt;title&gt;&#x27; + title + &#x27;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#x27; + body + &#x27;&lt;/body&gt;&lt;/html&gt;&#x27; 显然这种方式完全不具备可维护性。所以有第二种模板方式： 12345678&lt;html&gt;&lt;head&gt; &lt;title&gt;&#123;&#123; title &#125;&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;&#123; body &#125;&#125;&lt;/body&gt;&lt;/html&gt; ASP、JSP、PHP 等都是用这种模板方式生成前端页面。 如果在页面上大量使用 JavaScript（事实上大部分页面都会），模板方式仍然会导致 JavaScript 代码与后端代码绑得非常紧密，以至于难以维护。其根本原因在于负责显示的 HTML DOM 模型与负责数据和交互的 JavaScript 代码没有分割清楚。 要编写可维护的前端代码绝非易事。和后端结合的 MVC 模式已经无法满足复杂页面逻辑的需要了，所以，新的 MVVM：Model View ViewModel 模式应运而生。 MVVM 最早由微软提出来，它借鉴了桌面应用程序的 MVC 思想，在前端页面中，把 Model 用纯 JavaScript 对象表示： 1234567&lt;script&gt; var blog = &#123; name: &#x27;hello&#x27;, summary: &#x27;this is summary&#x27;, content: &#x27;this is content...&#x27; &#125;;&lt;/script&gt; View 是纯 HTML： 123456&lt;form action=&quot;/api/blogs&quot; method=&quot;post&quot;&gt; &lt;input name=&quot;name&quot;&gt; &lt;input name=&quot;summary&quot;&gt; &lt;textarea name=&quot;content&quot;&gt;&lt;/textarea&gt; &lt;button type=&quot;submit&quot;&gt;OK&lt;/button&gt;&lt;/form&gt; 由于 Model 表示数据，View 负责显示，两者做到了最大限度的分离。 把 Model 和 View 关联起来的就是 ViewModel。ViewModel 负责把 Model 的数据同步到 View 显示出来，还负责把 View 的修改同步回 Model。 ViewModel 如何编写？需要用 JavaScript 编写一个通用的 ViewModel，这样，就可以复用整个 MVVM 模型了。 好消息是已有许多成熟的 MVVM 框架，例如 AngularJS，KnockoutJS 等。我们选择 Vue 这个简单易用的 MVVM 框架来实现创建 Blog 的页面 templates/manage_blog_edit.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#123;% extends &#x27;__base__.html&#x27; %&#125;&#123;% block title %&#125;编辑日志&#123;% endblock %&#125;&#123;% block beforehead %&#125;&lt;script&gt;var ID = &#x27;&#123;&#123; id &#125;&#125;&#x27;, action = &#x27;&#123;&#123; action &#125;&#125;&#x27;;function initVM(blog) &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: blog, methods: &#123; submit: function (event) &#123; event.preventDefault(); var $form = $(&#x27;#vm&#x27;).find(&#x27;form&#x27;); $form.postJSON(action, this.$data, function (err, r) &#123; if (err) &#123; $form.showFormError(err); &#125; else &#123; return location.assign(&#x27;/api/blogs/&#x27; + r.id); &#125; &#125;); &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;$(function () &#123; if (ID) &#123; getJSON(&#x27;/api/blogs/&#x27; + ID, function (err, blog) &#123; if (err) &#123; return fatal(err); &#125; $(&#x27;#loading&#x27;).hide(); initVM(blog); &#125;); &#125; else &#123; $(&#x27;#loading&#x27;).hide(); initVM(&#123; name: &#x27;&#x27;, summary: &#x27;&#x27;, content: &#x27;&#x27; &#125;); &#125;&#125;);&lt;/script&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;div class=&quot;uk-width-1-1 uk-margin-bottom&quot;&gt; &lt;div class=&quot;uk-panel uk-panel-box&quot;&gt; &lt;ul class=&quot;uk-breadcrumb&quot;&gt; &lt;li&gt;&lt;a href=&quot;/manage/comments&quot;&gt;评论&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/manage/blogs&quot;&gt;日志&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/manage/users&quot;&gt;用户&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=&quot;error&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;div id=&quot;loading&quot; class=&quot;uk-width-1-1 uk-text-center&quot;&gt; &lt;span&gt;&lt;i class=&quot;uk-icon-spinner uk-icon-medium uk-icon-spin&quot;&gt;&lt;/i&gt; 正在加载...&lt;/span&gt; &lt;/div&gt; &lt;div id=&quot;vm&quot; class=&quot;uk-width-2-3&quot;&gt; &lt;form v-on=&quot;submit: submit&quot; class=&quot;uk-form uk-form-stacked&quot;&gt; &lt;div class=&quot;uk-alert uk-alert-danger uk-hidden&quot;&gt;&lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;标题:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;input v-model=&quot;name&quot; name=&quot;name&quot; type=&quot;text&quot; placeholder=&quot;标题&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;摘要:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;textarea v-model=&quot;summary&quot; rows=&quot;4&quot; name=&quot;summary&quot; placeholder=&quot;摘要&quot; class=&quot;uk-width-1-1&quot; style=&quot;resize:none;&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;label class=&quot;uk-form-label&quot;&gt;内容:&lt;/label&gt; &lt;div class=&quot;uk-form-controls&quot;&gt; &lt;textarea v-model=&quot;content&quot; rows=&quot;16&quot; name=&quot;content&quot; placeholder=&quot;内容&quot; class=&quot;uk-width-1-1&quot; style=&quot;resize:none;&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;uk-form-row&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-save&quot;&gt;&lt;/i&gt; 保存&lt;/button&gt; &lt;a href=&quot;/manage/blogs&quot; class=&quot;uk-button&quot;&gt;&lt;i class=&quot;uk-icon-times&quot;&gt;&lt;/i&gt; 取消&lt;/a&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&#123;% endblock %&#125; 初始化 Vue 时，我们指定 3 个参数： el：根据选择器查找绑定的 View，这里是 #vm，就是 id 为 vm 的 DOM，对应的是一个 &lt;div&gt; 标签； data：JavaScript 对象表示的 Model，我们初始化为 &#123; name: &#39;&#39;, summary: &#39;&#39;, content: &#39;&#39;&#125;； methods：View 可以触发的 JavaScript 函数，submit 就是提交表单时触发的函数。 接下来，我们在 &lt;form&gt; 标签中，用几个简单的 v-model，就可以让 Vue 把 Model 和 View 关联起来： 12&lt;!-- input的value和Model的name关联起来了 --&gt;&lt;input v-model=&quot;name&quot; class=&quot;uk-width-1-1&quot;&gt; Form 表单通过 &lt;form v-on=&quot;submit: submit&quot;&gt; 把提交表单的事件关联到 submit 方法。 需要特别注意的是，在 MVVM 中，Model 和 View 是双向绑定的。如果我们在 Form 中修改了文本框的值，可以在 Model 中立刻拿到新的值。试试在表单中输入文本，然后在 Chrome 浏览器中打开 JavaScript 控制台，可以通过 vm.name 访问单个属性，或者通过 vm.$data 访问整个 Model 如果我们在 JavaScript 逻辑中修改了 Model，这个修改会立刻反映到 View 上。试试在 JavaScript 控制台输入 vm.name = &#39;MVVM简介&#39;，可以看到文本框的内容自动被同步了 双向绑定是 MVVM 框架最大的作用。借助于 MVVM，我们把复杂的显示逻辑交给框架完成。由于后端编写了独立的 REST API，所以，前端用 AJAX 提交表单非常容易，前后端分离得非常彻底。 日志列表页MVVM 模式不但可用于 Form 表单，在复杂的管理页面中也能大显身手。例如，分页显示 Blog 的功能，我们先把后端代码写出来： 在 apis.py 中定义一个 Page 类用于存储分页信息： 123456789101112131415161718class Page(object): def __init__(self, item_count, page_index=1, page_size=10): self.item_count = item_count self.page_size = page_size self.page_count = item_count // page_size + (1 if item_count % page_size &gt; 0 else 0) if (item_count == 0) or (page_index &gt; self.page_count): self.offset = 0 self.limit = 0 self.page_index = 1 else: self.page_index = page_index self.offset = self.page_size * (page_index - 1) self.limit = self.page_size self.has_next = self.page_index &lt; self.page_count self.has_previous = self.page_index &gt; 1 def __str__(self): return &#x27;item_count: %s, page_count: %s, page_index: %s, page_size: %s, offset: %s, limit: %s&#x27; % (self.item_count, self.page_count, self.page_index, self.page_size, self.offset, self.limit) __repr__ = __str__ 在 handlers.py 中实现 API： 123456789@get(&#x27;/api/blogs&#x27;)def api_blogs(*, page=&#x27;1&#x27;): page_index = get_page_index(page) num = yield from Blog.findNumber(&#x27;count(id)&#x27;) p = Page(num, page_index) if num == 0: return dict(page=p, blogs=()) blogs = yield from Blog.findAll(orderBy=&#x27;created_at desc&#x27;, limit=(p.offset, p.limit)) return dict(page=p, blogs=blogs) 管理页面： 123456@get(&#x27;/manage/blogs&#x27;)def manage_blogs(*, page=&#x27;1&#x27;): return &#123; &#x27;__template__&#x27;: &#x27;manage_blogs.html&#x27;, &#x27;page_index&#x27;: get_page_index(page) &#125; 模板页面首先通过 API：GET /api/blogs?page=? 拿到 Model： 12345678910&#123; &quot;page&quot;: &#123; &quot;has_next&quot;: true, &quot;page_index&quot;: 1, &quot;page_count&quot;: 2, &quot;has_previous&quot;: false, &quot;item_count&quot;: 12 &#125;, &quot;blogs&quot;: [...]&#125; 然后，通过 Vue 初始化 MVVM： 1234567891011121314151617181920212223242526272829303132333435363738&lt;script&gt;function initVM(data) &#123; var vm = new Vue(&#123; el: &#x27;#vm&#x27;, data: &#123; blogs: data.blogs, page: data.page &#125;, methods: &#123; edit_blog: function (blog) &#123; location.assign(&#x27;/manage/blogs/edit?id=&#x27; + blog.id); &#125;, delete_blog: function (blog) &#123; if (confirm(&#x27;确认要删除“&#x27; + blog.name + &#x27;”？删除后不可恢复！&#x27;)) &#123; postJSON(&#x27;/api/blogs/&#x27; + blog.id + &#x27;/delete&#x27;, function (err, r) &#123; if (err) &#123; return alert(err.message || err.error || err); &#125; refresh(); &#125;); &#125; &#125; &#125; &#125;); $(&#x27;#vm&#x27;).show();&#125;$(function() &#123; getJSON(&#x27;/api/blogs&#x27;, &#123; page: &#123;&#123; page_index &#125;&#125; &#125;, function (err, results) &#123; if (err) &#123; return fatal(err); &#125; $(&#x27;#loading&#x27;).hide(); initVM(results); &#125;);&#125;);&lt;/script&gt; View 的容器是 #vm，包含一个 table，我们用 v-repeat 可以把 Model 的数组 blogs 直接变成多行的 &lt;tr&gt;： 12345678910111213141516171819202122232425262728293031&lt;div id=&quot;vm&quot; class=&quot;uk-width-1-1&quot;&gt; &lt;a href=&quot;/manage/blogs/create&quot; class=&quot;uk-button uk-button-primary&quot;&gt;&lt;i class=&quot;uk-icon-plus&quot;&gt;&lt;/i&gt; 新日志&lt;/a&gt; &lt;table class=&quot;uk-table uk-table-hover&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=&quot;uk-width-5-10&quot;&gt;标题 / 摘要&lt;/th&gt; &lt;th class=&quot;uk-width-2-10&quot;&gt;作者&lt;/th&gt; &lt;th class=&quot;uk-width-2-10&quot;&gt;创建时间&lt;/th&gt; &lt;th class=&quot;uk-width-1-10&quot;&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr v-repeat=&quot;blog: blogs&quot; &gt; &lt;td&gt; &lt;a target=&quot;_blank&quot; v-attr=&quot;href: &#x27;/blog/&#x27;+blog.id&quot; v-text=&quot;blog.name&quot;&gt;&lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;a target=&quot;_blank&quot; v-attr=&quot;href: &#x27;/user/&#x27;+blog.user_id&quot; v-text=&quot;blog.user_name&quot;&gt;&lt;/a&gt; &lt;/td&gt; &lt;td&gt; &lt;span v-text=&quot;blog.created_at.toDateTime()&quot;&gt;&lt;/span&gt; &lt;/td&gt; &lt;td&gt; &lt;a href=&quot;#0&quot; v-on=&quot;click: edit_blog(blog)&quot;&gt;&lt;i class=&quot;uk-icon-edit&quot;&gt;&lt;/i&gt; &lt;a href=&quot;#0&quot; v-on=&quot;click: delete_blog(blog)&quot;&gt;&lt;i class=&quot;uk-icon-trash-o&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div v-component=&quot;pagination&quot; v-with=&quot;page&quot;&gt;&lt;/div&gt;&lt;/div&gt; 往 Model 的 blogs 数组中增加一个 Blog 元素，table 就神奇地增加了一行；把 blogs 数组的某个元素删除，table 就神奇地减少了一行。所有复杂的 Model-View 的映射逻辑全部由 MVVM 框架完成，我们只需要在 HTML 中写上 v-repeat 指令，就什么都不用管了。 可以把 v-repeat=&quot;blog: blogs&quot; 看成循环代码，所以，可以在一个 &lt;tr&gt; 内部引用循环变量 blog。v-text 和 v-attr 指令分别用于生成文本和 DOM 节点属性。 效率现在，我们已经把一个 Web App 的框架完全搭建好了，从后端的 API 到前端的 MVVM，流程已经跑通了。 在继续工作前，注意到每次修改 Python 代码，都必须在命令行先 Ctrl-C 停止服务器，再重启，改动才能生效。 在开发阶段，每天都要修改、保存几十次代码，每次保存都手动来这么一下非常麻烦，严重地降低了我们的开发效率。有没有办法让服务器检测到代码修改后自动重新加载呢？ Django 的开发环境在 Debug 模式下就可以做到自动重新加载，如果我们编写的服务器也能实现这个功能，就能大大提升开发效率。 可惜的是，Django 没把这个功能独立出来，不用 Django 就享受不到，怎么办？ 其实 Python 本身提供了重新载入模块的功能，但不是所有模块都能被重新载入。另一种思路是检测 www 目录下的代码改动，一旦有改动，就自动重启服务器。 按照这个思路，我们可以编写一个辅助程序 pymonitor.py，让它启动 wsgiapp.py，并时刻监控 www 目录下的代码改动，有改动时，先把当前 wsgiapp.py 进程杀掉，再重启，就完成了服务器进程的自动重启。 要监控目录文件的变化，我们也无需自己手动定时扫描，Python 的第三方库 watchdog 可以利用操作系统的 API 来监控目录文件的变化，并发送通知。我们先用 pip 安装： 1$ pip3 install watchdog 利用 watchdog 接收文件变化的通知，如果是 .py 文件，就自动重启 wsgiapp.py 进程。 利用 Python 自带的 subprocess 实现进程的启动和终止，并把输入输出重定向到当前进程的输入输出中： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python3# -*- coding: utf-8 -*-__author__ = &#x27;Michael Liao&#x27;import os, sys, time, subprocessfrom watchdog.observers import Observerfrom watchdog.events import FileSystemEventHandlerdef log(s): print(&#x27;[Monitor] %s&#x27; % s)class MyFileSystemEventHander(FileSystemEventHandler): def __init__(self, fn): super(MyFileSystemEventHander, self).__init__() self.restart = fn def on_any_event(self, event): if event.src_path.endswith(&#x27;.py&#x27;): log(&#x27;Python source file changed: %s&#x27; % event.src_path) self.restart()command = [&#x27;echo&#x27;, &#x27;ok&#x27;]process = Nonedef kill_process(): global process if process: log(&#x27;Kill process [%s]...&#x27; % process.pid) process.kill() process.wait() log(&#x27;Process ended with code %s.&#x27; % process.returncode) process = Nonedef start_process(): global process, command log(&#x27;Start process %s...&#x27; % &#x27; &#x27;.join(command)) process = subprocess.Popen(command, stdin=sys.stdin, stdout=sys.stdout, stderr=sys.stderr)def restart_process(): kill_process() start_process()def start_watch(path, callback): observer = Observer() observer.schedule(MyFileSystemEventHander(restart_process), path, recursive=True) observer.start() log(&#x27;Watching directory %s...&#x27; % path) start_process() try: while True: time.sleep(0.5) except KeyboardInterrupt: observer.stop() observer.join()if __name__ == &#x27;__main__&#x27;: argv = sys.argv[1:] if not argv: print(&#x27;Usage: ./pymonitor your-script.py&#x27;) exit(0) if argv[0] != &#x27;python3&#x27;: argv.insert(0, &#x27;python3&#x27;) command = argv path = os.path.abspath(&#x27;.&#x27;) start_watch(path, None) 一共 70 行左右的代码，就实现了 Debug 模式的自动重新加载。用下面的命令启动服务器： 1$ python3 pymonitor.py wsgiapp.py 或者给 pymonitor.py 加上可执行权限，启动服务器： 1$ ./pymonitor.py app.py 在编辑器中打开一个 .py 文件，修改后保存，看看命令行输出，是不是自动重启了服务器： 1234567891011$ ./pymonitor.py app.py [Monitor] Watching directory /Users/michael/Github/awesome-python3-webapp/www...[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000...[Monitor] Python source file changed: /Users/michael/Github/awesome-python-webapp/www/handlers.py[Monitor] Kill process [2747]...[Monitor] Process ended with code -9.[Monitor] Start process python app.py......INFO:root:application (/Users/michael/Github/awesome-python3-webapp/www) will start at 0.0.0.0:9000... 现在，只要一保存代码，就可以刷新浏览器看到效果，大大提升了开发效率。 完善在 Web App 框架和基本流程跑通后，剩下的工作全部是体力活了：在 Debug 开发模式下完成后端所有 API、前端所有页面。我们需要做的事情包括： 把当前用户绑定到 request 上，并对 URL/manage/ 进行拦截，检查当前用户是否是管理员身份： 12345678910111213141516@asyncio.coroutinedef auth_factory(app, handler): @asyncio.coroutine def auth(request): logging.info(&#x27;check user: %s %s&#x27; % (request.method, request.path)) request.__user__ = None cookie_str = request.cookies.get(COOKIE_NAME) if cookie_str: user = yield from cookie2user(cookie_str) if user: logging.info(&#x27;set current user: %s&#x27; % user.email) request.__user__ = user if request.path.startswith(&#x27;/manage/&#x27;) and (request.__user__ is None or not request.__user__.admin): return web.HTTPFound(&#x27;/signin&#x27;) return (yield from handler(request)) return auth 后端 API 包括： 获取日志：GET &#x2F;api&#x2F;blogs 创建日志：POST &#x2F;api&#x2F;blogs 修改日志：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id 删除日志：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id&#x2F;delete 获取评论：GET &#x2F;api&#x2F;comments 创建评论：POST &#x2F;api&#x2F;blogs&#x2F;:blog_id&#x2F;comments 删除评论：POST &#x2F;api&#x2F;comments&#x2F;:comment_id&#x2F;delete 创建新用户：POST &#x2F;api&#x2F;users 获取用户：GET &#x2F;api&#x2F;users管理页面包括： 评论列表页：GET &#x2F;manage&#x2F;comments 日志列表页：GET &#x2F;manage&#x2F;blogs 创建日志页：GET &#x2F;manage&#x2F;blogs&#x2F;create 修改日志页：GET &#x2F;manage&#x2F;blogs&#x2F; 用户列表页：GET &#x2F;manage&#x2F;users用户浏览页面包括： 注册页：GET &#x2F;register 登录页：GET &#x2F;signin 注销页：GET &#x2F;signout 首页：GET &#x2F; 日志详情页：GET &#x2F;blog&#x2F;:blog_id把所有的功能实现，我们第一个 Web App 就宣告完成！ 部署很多做开发的同学把部署这件事情看成是运维同学的工作，这种看法是完全错误的。首先，最近流行 DevOps 理念，就是说，开发和运维要变成一个整体。其次，运维的难度，其实跟开发质量有很大的关系。代码写得垃圾，运维再好也架不住天天挂掉。最后，DevOps 理念需要把运维、监控等功能融入到开发中。你想服务器升级时不中断用户服务？那就得在开发时考虑到这一点。 下面，我们就来把 awesome-python3-webapp 部署到 Linux 服务器。 搭建 Linux 服务器要部署到 Linux，首先得有一台 Linux 服务器。要在公网上体验的同学，可以在 Amazon 的 AWS 申请一台 EC2 虚拟机（免费使用 1 年），或者使用国内的一些云服务器，一般都提供 Ubuntu Server 的镜像。想在本地部署的同学，请安装虚拟机，推荐使用 VirtualBox。 我们选择的 Linux 服务器版本是 Ubuntu Server 14.04 LTS，原因是 apt 太简单了。如果你准备使用其他 Linux 版本，也没有问题。 Linux 安装完成后，请确保 ssh 服务正在运行，否则，需要通过 apt 安装： 1$ sudo apt-get install openssh-server 有了 ssh 服务，就可以从本地连接到服务器上。建议把公钥复制到服务器端用户的 .ssh/authorized_keys 中，这样，就可以通过证书实现无密码连接。 部署方式利用 Python 自带的 asyncio，我们已经编写了一个异步高性能服务器。但是，我们还需要一个高性能的 Web 服务器，这里选择 Nginx，它可以处理静态资源，同时作为反向代理把动态请求交给 Python 代码处理。这个模型如下 Nginx 负责分发请求 在服务器端，我们需要定义好部署的目录结构： 123456/+- srv/ +- awesome/ &lt;-- Web App根目录 +- www/ &lt;-- 存放Python源码 | +- static/ &lt;-- 存放静态资源文件 +- log/ &lt;-- 存放log 在服务器上部署，要考虑到新版本如果运行不正常，需要回退到旧版本时怎么办。每次用新的代码覆盖掉旧的文件是不行的，需要一个类似版本控制的机制。由于 Linux 系统提供了软链接功能，所以，我们把 www 作为一个软链接，它指向哪个目录，哪个目录就是当前运行的版本 而 Nginx 和 python 代码的配置文件只需要指向 www 目录即可。 Nginx 可以作为服务进程直接启动，但 app.py 还不行，所以，Supervisor 登场！Supervisor 是一个管理进程的工具，可以随系统启动而启动服务，它还时刻监控服务进程，如果服务进程意外退出，Supervisor 可以自动重启服务。 总结一下我们需要用到的服务有： Nginx：高性能 Web 服务器 + 负责反向代理； Supervisor：监控服务进程的工具； MySQL：数据库服务。在 Linux 服务器上用 apt 可以直接安装上述服务： 1$ sudo apt-get install nginx supervisor python3 mysql-server 然后，再把我们自己的 Web App 用到的 Python 库安装了： 1$ sudo pip3 install jinja2 aiomysql aiohttp 在服务器上创建目录 /srv/awesome/ 以及相应的子目录。 在服务器上初始化 MySQL 数据库，把数据库初始化脚本 schema.sql 复制到服务器上执行： 1$ mysql -u root -p &lt; schema.sql 服务器端准备就绪。 部署用 FTP 还是 SCP 还是 rsync 复制文件？如果你需要手动复制，用一次两次还行，一天如果部署 50 次不但慢、效率低，而且容易出错。 正确的部署方式是使用工具配合脚本完成自动化部署。Fabric 就是一个自动化部署工具。由于 Fabric 是用 Python 2.x 开发的，所以，部署脚本要用 Python 2.7 来编写，本机还必须安装 Python 2.7 版本。 要用 Fabric 部署，需要在本机（是开发机器，不是 Linux 服务器）安装 Fabric： 1$ easy_install fabric Linux 服务器上不需要安装 Fabric，Fabric 使用 SSH 直接登录服务器并执行部署命令。 下一步是编写部署脚本。Fabric 的部署脚本叫 fabfile.py，我们把它放到 awesome-python-webapp 的目录下，与 www 目录平级： 1234awesome-python-webapp/+- fabfile.py+- www/+- ... Fabric 的脚本编写很简单，首先导入 Fabric 的 API，设置部署时的变量： 1234567891011121314# fabfile.pyimport os, refrom datetime import datetime# 导入Fabric API:from fabric.api import *# 服务器登录用户名:env.user = &#x27;michael&#x27;# sudo用户为root:env.sudo_user = &#x27;root&#x27;# 服务器地址，可以有多个，依次部署:env.hosts = [&#x27;192.168.0.3&#x27;]# 服务器MySQL用户名和口令:db_user = &#x27;www-data&#x27;db_password = &#x27;www-data&#x27; 然后，每个 Python 函数都是一个任务。我们先编写一个打包的任务： 12345678910_TAR_FILE = &#x27;dist-awesome.tar.gz&#x27;def build(): includes = [&#x27;static&#x27;, &#x27;templates&#x27;, &#x27;transwarp&#x27;, &#x27;favicon.ico&#x27;, &#x27;*.py&#x27;] excludes = [&#x27;test&#x27;, &#x27;.*&#x27;, &#x27;*.pyc&#x27;, &#x27;*.pyo&#x27;] local(&#x27;rm -f dist/%s&#x27; % _TAR_FILE) with lcd(os.path.join(os.path.abspath(&#x27;.&#x27;), &#x27;www&#x27;)): cmd = [&#x27;tar&#x27;, &#x27;--dereference&#x27;, &#x27;-czvf&#x27;, &#x27;../dist/%s&#x27; % _TAR_FILE] cmd.extend([&#x27;--exclude=\\&#x27;%s\\&#x27;&#x27; % ex for ex in excludes]) cmd.extend(includes) local(&#x27; &#x27;.join(cmd)) Fabric 提供 local(&#39;...&#39;) 来运行本地命令，with lcd(path) 可以把当前命令的目录设定为 lcd() 指定的目录，注意 Fabric 只能运行命令行命令，Windows 下可能需要 Cgywin 环境。 在 awesome-python-webapp 目录下运行： 1$ fab build 看看是否在 dist 目录下创建了 dist-awesome.tar.gz 的文件。 打包后，我们就可以继续编写 deploy 任务，把打包文件上传至服务器，解压，重置 www 软链接，重启相关服务： 12345678910111213141516171819202122232425_REMOTE_TMP_TAR = &#x27;/tmp/%s&#x27; % _TAR_FILE_REMOTE_BASE_DIR = &#x27;/srv/awesome&#x27;def deploy(): newdir = &#x27;www-%s&#x27; % datetime.now().strftime(&#x27;%y-%m-%d_%H.%M.%S&#x27;) # 删除已有的tar文件: run(&#x27;rm -f %s&#x27; % _REMOTE_TMP_TAR) # 上传新的tar文件: put(&#x27;dist/%s&#x27; % _TAR_FILE, _REMOTE_TMP_TAR) # 创建新目录: with cd(_REMOTE_BASE_DIR): sudo(&#x27;mkdir %s&#x27; % newdir) # 解压到新目录: with cd(&#x27;%s/%s&#x27; % (_REMOTE_BASE_DIR, newdir)): sudo(&#x27;tar -xzvf %s&#x27; % _REMOTE_TMP_TAR) # 重置软链接: with cd(_REMOTE_BASE_DIR): sudo(&#x27;rm -f www&#x27;) sudo(&#x27;ln -s %s www&#x27; % newdir) sudo(&#x27;chown www-data:www-data www&#x27;) sudo(&#x27;chown -R www-data:www-data %s&#x27; % newdir) # 重启Python服务和nginx服务器: with settings(warn_only=True): sudo(&#x27;supervisorctl stop awesome&#x27;) sudo(&#x27;supervisorctl start awesome&#x27;) sudo(&#x27;/etc/init.d/nginx reload&#x27;) 注意 run() 函数执行的命令是在服务器上运行，with cd(path) 和 with lcd(path) 类似，把当前目录在服务器端设置为 cd() 指定的目录。如果一个命令需要 sudo 权限，就不能用 run()，而是用 sudo() 来执行。 配置 Supervisor上面让 Supervisor 重启 awesome 的命令会失败，因为我们还没有配置 Supervisor 呢。 编写一个 Supervisor 的配置文件 awesome.conf，存放到 /etc/supervisor/conf.d/ 目录下： 123456789[program:awesome]command = /srv/awesome/www/app.pydirectory = /srv/awesome/wwwuser = www-datastartsecs = 3redirect_stderr = truestdout_logfile_maxbytes = 50MBstdout_logfile_backups = 10stdout_logfile = /srv/awesome/log/app.log 配置文件通过 [program:awesome] 指定服务名为 awesome，command 指定启动 app.py。 然后重启 Supervisor 后，就可以随时启动和停止 Supervisor 管理的服务了： 1234$ sudo supervisorctl reload$ sudo supervisorctl start awesome$ sudo supervisorctl statusawesome RUNNING pid 1401, uptime 5:01:34 配置 NginxSupervisor 只负责运行 app.py，我们还需要配置 Nginx。把配置文件 awesome 放到 /etc/nginx/sites-available/ 目录下： 12345678910111213141516171819202122server &#123; listen 80; # 监听80端口 root /srv/awesome/www; access_log /srv/awesome/log/access_log; error_log /srv/awesome/log/error_log; # server_name awesome.liaoxuefeng.com; # 配置域名 # 处理静态文件/favicon.ico: location /favicon.ico &#123; root /srv/awesome/www; &#125; # 处理静态资源: location ~ ^\\/static\\/.*$ &#123; root /srv/awesome/www; &#125; # 动态请求转发到9000端口: location / &#123; proxy_pass http://127.0.0.1:9000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 然后在 /etc/nginx/sites-enabled/ 目录下创建软链接： 123$ pwd/etc/nginx/sites-enabled$ sudo ln -s /etc/nginx/sites-available/awesome . 让 Nginx 重新加载配置文件，不出意外，我们的 awesome-python3-webapp 应该正常运行： 1$ sudo /etc/init.d/nginx reload 如果有任何错误，都可以在 /srv/awesome/log 下查找 Nginx 和 App 本身的 log。如果 Supervisor 启动时报错，可以在 /var/log/supervisor 下查看 Supervisor 的 log。 如果一切顺利，你可以在浏览器中访问 Linux 服务器上的 awesome-python3-webapp 了 如果在开发环境更新了代码，只需要在命令行执行： 12$ fab build$ fab deploy 自动部署完成！刷新浏览器就可以看到服务器代码更新后的效果。","categories":["1.语言","Python"]},{"title":"JavaScript","path":"/2024/05/22/1-语言-前端-JavaScript/","content":"示例分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384//在当前页面重新载入页面function reloadPageContent(reloadPage)&#123; window.location.replace(reloadPage);&#125;//按钮点击展开或隐藏function updateClick()&#123; $(document).ready((function() &#123;\t//ready函数来确保文档加载完毕后再执行代码(jquery库代码)\t$(&quot;a&quot;).click((function() &#123;\t//为文档中的所有&lt;a&gt;标签绑定点击事件 $(this).next(&quot;.menu&quot;).toggle()//找到当前被点击的&lt;a&gt;标签的下一个.menu类的元素，切换它的可见性\t&#125;)) &#125;))&#125;//获取并更新innerHTML中的内容function getInnerHTML(filePos)&#123; var xhr = new XMLHttpRequest(); xhr.open(&quot;GET&quot;, filePos, true); xhr.onreadystatechange = function() &#123;\tif (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; var htmlContent = xhr.responseText; document.getElementById(&quot;mainmenu&quot;).innerHTML = htmlContent; updateClick();\t&#125; &#125;; xhr.send();&#125;function showPicture()&#123; fetch(&#x27;http://124.222.246.202/get_picture?id=1&#x27;, &#123;method: &#x27;GET&#x27;,headers: &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;,&#125;) .then(response =&gt; response.text()) .then(data =&gt; &#123;document.getElementById(&quot;mainmenu&quot;).innerHTML=data&#125;)&#125;function openFile(filePos)&#123; var xhr = new XMLHttpRequest(); xhr.open(&quot;POST&quot;, &quot;http://124.222.246.202/getFileContent&quot;, true); xhr.setRequestHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); var message = &#123; filePos &#125;; var jsonMessage = JSON.stringify(message); xhr.onreadystatechange = function () &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; var responseContainer = document.getElementById(&quot;mainmenu&quot;); responseContainer.innerHTML = &#x27;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;2.css/github-markdown-css/github-markdown.css&quot;&gt;&lt;style&gt;.markdown-body &#123;box-sizing: border-box;min-width: 200px;max-width: 980px;margin: 0 auto;padding: 45px;&#125;@media (max-width: 767px) &#123;.markdown-body &#123;padding: 15px;&#125;&#125;&lt;/style&gt;&lt;article class=&quot;markdown-body&quot;&gt;&#x27;+marked.parse(xhr.responseText)+&#x27;&lt;/article&gt;&#x27;; &#125; &#125;; xhr.send(jsonMessage);&#125;function blogList() &#123; // 创建XMLHttpRequest对象 var xhr = new XMLHttpRequest(); // 配置请求，将消息发送到后端Python服务器 xhr.open(&quot;POST&quot;, &quot;http://124.222.246.202/getFileList&quot;, true); // 设置请求头，告诉服务器发送的是JSON数据 xhr.setRequestHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); // 创建要发送的消息对象 var message = &#123; &quot;message&quot;: &quot;Hello, backend!&quot; &#125;; // 将消息对象转换为JSON格式 var jsonMessage = JSON.stringify(message); // 处理响应 xhr.onreadystatechange = function () &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; // 在页面上显示后端返回的消息 var responseContainer = document.getElementById(&quot;mainmenu&quot;); responseContainer.innerHTML = &quot;后端返回的消息: &quot; + xhr.responseText; &#125; &#125;; // 发送请求 xhr.send(jsonMessage);&#125;","categories":["1.语言","前端"]},{"title":"Python返回前端请求IP地址","path":"/2024/05/22/1-语言-Python-Python返回前端请求IP地址/","content":"前端 js 代码123456&lt;script&gt;\tfetch(&#x27;/get_ip&#x27;, &#123;method: &#x27;GET&#x27;,headers: &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;,&#125;) .then(response =&gt; response.text()) .then(data =&gt; &#123;document.getElementById(&quot;ip_addr&quot;).innerHTML=data&#125;)&lt;/script&gt;","categories":["1.语言","Python"]},{"title":"博客wordpress的LNMP环境","path":"/2024/05/22/0-平台-服务器-博客wordpress的LNMP环境/","content":"前言由于在利用 Docker 部署 wordpress 时发现，很多需要修改的文件都需要通过 docker-compose 的脚本映射到本地，不好修改，另外由于 docker 的属性，导致 docker 在关闭并重启后，数据会丢失，必须利用 volume 或者“data container”来实现数据持久化 在容器关闭之后可以利用“-v”或者“–volumes-from”重新使用以前的数据，docker 也可挂载宿主机磁盘目录，用来永久存储数据。 所以还是通过自己配置 LNMP 的基础运行环境，能够看到并修改所有文件的方式才比较放心。 目前 LNMP 环境的配置，可以通过多种方法： 通过宝塔面板，可视化配置 通过脚本，一键配置所有软件 各软件环境自己手动安装，手动配置 这次我们通过脚本配置，之后导入原来的 docker 中搭建的 wordpress 的所有数据。 LNMP 介绍LNMP 只是 wordpress 运行的基础环境，LNMP 是一种常用的 Web 服务器架构，它的名字代表了其中的四个组件：Linux、Nginx、MySQL&#x2F;MariaDB 和 PHP。这些组件分别扮演了不同的角色： Linux：操作系统，提供了基本的系统服务和资源管理； Nginx：Web 服务器，处理客户端请求并将其转发给后端的应用程序； MySQL&#x2F;MariaDB：关系型数据库，用于存储和管理应用程序的数据； PHP：服务器端编程语言，用于编写应用程序的业务逻辑。LNMP 架构的优点在于：高性能：Nginx 是一个高性能的 Web 服务器，能够处理大量并发请求；稳定可靠：Linux 是一个稳定可靠的操作系统，能够提供良好的系统服务和资源管理；易于扩展：MySQL&#x2F;MariaDB 是一个成熟的关系型数据库，支持高可用和分布式架构；灵活可定制：PHP 是一种灵活可定制的服务器端编程语言，能够满足不同的业务需求。 LNMP 架构被广泛应用于 Web 开发和运维领域，特别是在高并发和大数据场景下，具有良好的性能表现和可扩展性。 还有其余的诸如： LAMP 的全称是 Linux + Apache + MySQL + PHP LNAMP 的全称是 Linux + Nginx + Apache + MySQL + PHP 其中 Apache 是世界使用排名第一的 Web 服务器软件。 它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的 Web 服务器端软件之一。 安装 LNMP源项目地址 下载 LNMP 安装脚本（指定版本为 1.5） wget http://soft.vpser.net/lnmp/lnmp1.9.tar.gz 解压并执行 123tar zxf lnmp1.9.tar.gzcd lnmp1.9./install.sh lnmp 运行脚本后，首先会让你选择数据库的版本： MYSQL&#x2F;MariaDB 选好数据库，会让你设置数据库 root 用户的密码: 如果输入有错误需要删除，需要按住 Ctrl 再%","categories":["0.平台","服务器"]},{"title":"16-8禁食软件架构设计","path":"/2024/05/22/3-软件-0-项目-16-8禁食软件架构设计/","content":"介绍用于记录每日的禁食时间，保证不间断禁食时间保持十六个小时 如何提供奖励机制 功能记录 - 点击按钮开始计时 - 再次点击按钮结束计时 - 期间中途如果 APP 有退出情况，应记录中途退出情况，并能够续写禁食时间 程序启动时，开始时读取上次的计时状态和禁食日志 如果之前的禁食状态未为结束，根据中间经过的时间间隔继续计时，接着开始禁食 否则进入正常流程，等待重新开始计时 点击开始计时后 判断日志中是否已经有今日的禁食时间，是否覆盖？ 如果否，则不启动计时 如果是，则清除文件中已保存的禁食时间，启动定时器 定时器启动，实时写入当前的禁食数值及禁食状态 - 2023-07-26-10-10-10-1 点击结束计时后， 停止计时器 覆写当前时间和禁食时间以及禁食状态 - 2023-07-26-10-10-30-0 写入当前当前日期和禁食时间 - 2023-07-26-0-0-20 查询能够查询到每日的禁食时间 - 保存每日的禁食数据，如果有重复的禁食数据，弹窗提示，让用户选择哪条禁食数据有效 - 查询每日禁食数据，根据点击的日期显示禁食时长 - 表格显示禁食进度完成情况，绿色代表完成，红色代表未完成 目标建立每日目标及目标达成情况 - 表格显示每日目标及目标达成情况 设置 - 能够设置每日禁食时长 - 能够手动设立目标","categories":["3.软件","0.项目"]},{"title":"影视APP","path":"/2024/05/22/3-软件-音视频-影视APP/","content":"影视 APP 采用的都是用「套壳＋视频源」的模式，将壳体和视频源分开，接口也有逐渐发展为他人专门提供的趋势 TVBOXGithub 开源了一个名为 TVBox 的项目： o0HalfLife0o 最新测试版 APK https://github.com/o0HalfLife0o/TVBoxOSC/releases/ APP 设置 » 配置地址，我们需要在这里给 APP 添加视频源之后才能使用 YuanHsingYuanHsing 维护的 TVBOX接口项目 如果以上地址失效，你可以到原项目上找到 json 文件获取文件的 raw 地址进行添加，不过由于现在墙的存在，我们不能直接订阅 Github 原生文件地址，需要将链接稍作修改，改成经过 CDN 加速后的地址，才可以使用： jsDelivr 加速地址： https://gcore.jsdelivr.net/gh/YuanHsing/freed@master/TVBox/meow.json Statically 加速地址： https://cdn.staticaly.com/gh/YuanHsing/freed/master/TVBox/meow.json jsDelivr、Statically 这俩个加速服务还是挺稳的，不过具体文件名可能以后会有变化，如果文件名变化了，自行修改上面两个链接末尾的 meow.json 就行了 导入之后，返回一下首页，等待 jar 文件加载成功，再到设置 » 首页数据源 在代码托管平台上找视频源在 Github 上其实有很多程序员在维护自用的 TVBOX 接口，而 Github 上的代码多数都是公开的，搜索方法也很简单，在 github.com 上搜索关键词：TVBOX，然后再右上角 Sort 筛选这里，选择 Recently upload 最近更新 然一般我们只需要找到项目里面的 json 文件，然后点进去看一下 json 文件的具体代码，看看代码里面有没有关键词 TVBOX，有的话，就基本上就可以断定这是一个可用的 TVBOX 接口了，如果你有安装相关的 Github 加速油猴脚本，那直接从上面直接复制 json 文件的加速地址，添加到 TVBOX 就行了，如果没安装相关脚本的话，可以参照本文 1.1 节，将文件链接格式修改为 jsDelivr、Statically 等的加速链接即可使用，同理在 Gitee 上也能找到一些 TVBOX 相关的接口分享项目，虽然相关项目比较少，但优点是 Gitee.com 在国内可以直接访问，接口文件也是直接添加即可（注意是添加原始数据链接） TVBox 软件接口大全来源 某公众号在线TVBox软件接口大全 来源于导航站 风向标导航 海阔视界官方 Github海阔视界的 官方规则 Github 分享地址 你能在这里找到很多由官方维护与更新的规则文件，这里注意一下最后的更新时间，这里我们找一个最近不久才更新的规则，还是一样的：如果你有安装相关的 Github 加速油猴脚本，那直接从上面直接复制 json 文件的加速地址，如果没安装相关脚本的话，可以参照本文 1.1 节，先将文件链接格式修改为 jsDelivr、Statically 等的加速链接，比如这个规则的加速地址之一是： https://cdn.staticaly.com/gh/qiusunshine/hiker-rules/master/rules/2022-8-2.txt 但注意我们还不能直接就这样导入到海阔海阔视界，你需要在规则文件的链接前再加上一个前缀：海阔视界￥home_rule_url￥ 即我们将链接拼接成： 海阔视界￥home_rule_url￥https://cdn.staticaly.com/gh/qiusunshine/hiker-rules/master/rules/2022-8-2.txt 这样就可以将其导入到海阔视界了（如果导入后没反应，可以尝试多导入几次） 导入成功后，再回到 APP 主页，你就会发现上面多出了各种合集，而在这里就能轻松进行聚合影视搜索了 虽然他其实就是网页聚合搜索，但搭配上海阔影视不错的广告拦截效果，观看体验还是很不错的 微信公众号直接关注 APP 的官方公众号：新方圆小棉袄、海阔视界小棉袄这俩个公众号都时不时会分享海阔视界的规则，并且可以从公众号上一键复制 ZY-Player内置源已经全部失效，APP 下载链接： https://github.com/cuiocean/ZY-Player-APP YuanHsinghttps://github.com/YuanHsing/freed/tree/master/ZY-Player 虽然你可以到视频源文件写了 PC 两个字，但实际上是通用的，安卓端也可以使用还是一样的，由于现在墙的存在，我们不能直接订阅 Github 原生文件地址，需要将链接稍作修改，改成经过 CDN 加速后的地址，才可以使用： jsDelivr 加速地址： https://gcore.jsdelivr.net/gh/YuanHsing/freed@master/ZY-Player/ZY-Player-PC.json Statically 加速地址： https://cdn.staticaly.com/gh/YuanHsing/freed/master/ZY-Player/ZY-Player-PC.json 在代码托管平台上找视频源在代码托管平台上找 ZY-Player 的公开视频源，但 ZY-Player 就比较推荐到 Gitee 上找视频源了，相关的仓库会多一点，方法还是一样的很简单，在 Gitee.com 上搜索 ZY-Player，并按最近更新排序，随便点进一个项目，发现在根目录并没有找到 json 文件，没关系，看到有一个名为 resources（资源）的文件夹，点进去，果然里面有一个最近不久才更新的 json 文件，这个就是视频源，然后我们在源代码这里，点击原始数据，获取文件直链，将这个直链添加进 ZY-Player，然后就能在首页切换网站查看","categories":["3.软件","音视频"]},{"title":"TV Box源","path":"/2024/05/22/3-软件-音视频-TV-Box源/","content":"FongMi https://ghproxy.com/raw.githubusercontent.com/FongMi/CatVodSpider/main/json/config.json 巧技 (需关注公众号) http://pandown.pro/tvbox/tvbox.json 俊于 http://home.jundie.top:81/top98.json 霜辉月明 (py) https://ghproxy.com/raw.githubusercontent.com/lm317379829/PyramidStore/pyramid/py.json 小雅 (js) http://drpy.site/js1 菜妮丝 xBPQ https://tvbox.cainisi.cf 神器 https:&#x2F;&#x2F;神器每日推送.tk&#x2F;pz.json 饭太硬 http:&#x2F;&#x2F;饭太硬.ga&#x2F;x&#x2F;o.json 云星日记 https://maoyingshi.cc/tvbox/云星日记/1.m3u8 肥猫 http:&#x2F;&#x2F;肥猫.love","categories":["3.软件","音视频"]},{"title":"Docker介绍","path":"/2024/05/22/0-平台-Docker-Docker介绍/","content":"介绍Docker 是一种流行的容器化平台，它可以帮助开发人员和运维人员更轻松地构建、交付和运行应用程序。 Docker 架构Docker 的架构包括以下组件： Docker 守护进程：运行在主机上的后台进程，负责管理 Docker 对象，如镜像、容器、网络和数据卷。 Docker 客户端：通过 Docker API 与 Docker 守护进程通信。 Docker 镜像：包含应用程序和其依赖项的只读文件系统。 Docker 容器：Docker 镜像的可运行实例。 Docker 仓库：用于存储 Docker 镜像的地方。 主要需要注意的是镜像IMAGE和容器CONTAINER 可以将镜像视为虚拟机的一个快照，镜像是容器的基础，定义了容器的基本配置和内容 容器，即为镜像的实例化内容，当启动一个容器时，Docker 会从镜像创建一个只读的文件系统层，并在其上添加一个可写层，容器中的所有更改和数据都存储在这个可写层上。 Docker 基本命令Docker 提供了一系列命令行工具，用于管理 Docker 容器和镜像，以及执行与容器相关的操作 以下是一些常用的 Docker 命令： docker images：列出本地所有的镜像。 docker rmi &lt;image&gt;：删除一个镜像。 docker pull &lt;image&gt;：从仓库中拉取一个镜像。 docker build -t &lt;image_name&gt; &lt;path_to_dockerfile&gt;：根据 Dockerfile 构建新的自定义镜像。 docker push &lt;image&gt;：将一个镜像推送到仓库中。 docker run &lt;image&gt;：根据指定的镜像创建并启动一个新的容器。 docker ps：列出当前正在运行的容器。加 -a 列出所有，包括运行中的和已经停止的 docker start &lt;container_id/container_name&gt;：启动已停止的容器。 docker stop &lt;container_id/container_name&gt;：停止运行中的容器。 docker restart &lt;container_id/container_name&gt;：重启容器。 docker rm &lt;container_id/container_name&gt;：删除指定容器。 docker logs &lt;container_id/container_name&gt;：查看容器的日志输出。 docker exec -it &lt;container_id/container_name&gt; &lt;command&gt;：在正在运行的容器中执行特定命令。 docker exec -it container /bin/bash 进入 container 容器中的命令行 docker inspect &lt;container_id/container_name&gt;：查看容器的详细信息，包括 IP 地址、端口映射等。 docker network ls：列出所有 Docker 网络。 docker volume ls：列出所有 Docker 卷。 DockerfileDockerfile 是一种文本文件，用于定义如何构建 Docker 镜像。包含了一系列的指令和参数，用于指导 Docker 引擎在基础镜像上添加应用程序代码、运行时环境、依赖项和配置文件等，最终生成一个新的 Docker 镜像。 以下是一个简单的 Dockerfile 示例： 123 FROM ubuntu:latest RUN apt-get update &amp;&amp; apt-get install -y nginx CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 该 Dockerfile 使用最新版本的 Ubuntu 镜像作为基础镜像，并在其中安装了 nginx。 一些 dockerfile 中的指令： FROM： 指定基础镜像。每个 Docker 镜像都是基于一个基础镜像构建的，这个指令用于设置构建的起点。 MAINTAINER： 设置镜像的作者信息，通常是作者的名字和电子邮件。 RUN： 在镜像构建过程中执行的命令。可以用于安装软件包、更新系统、设置环境等操作。 CMD： 设置容器启动时要执行的命令。如果在运行镜像时没有指定要执行的命令，则将执行这里设置的默认命令。 ENTRYPOINT： 设置容器启动时要执行的固定命令。与 CMD 类似，但可以将参数传递给 ENTRYPOINT 指定的命令。 COPY： 将本地文件复制到镜像中。 ADD： 类似于 COPY，但它还支持复制网络资源和自动解压缩压缩文件。 WORKDIR： 设置容器的工作目录，后续的指令将在这个目录下执行。 EXPOSE： 指定容器运行时监听的端口号，但并不会自动将端口映射到宿主机。 ENV： 设置环境变量，可以在容器内部访问。 ARG： 声明构建时的参数，构建时可以通过 –build-arg 参数传递。 VOLUME： 创建一个可以从宿主机或其他容器挂载的挂载点。 USER： 设置运行镜像的用户。ONBUILD： 定义一个触发器，在子镜像构建时执行特定的操作。 Docker Compose（重点）Docker Compose 是一个工具，用于定义和运行多个 Docker 容器的应用程序。 docker-compose 需要编写 yml 脚本，定义配置以及多个容器之间的依赖关系和网络连接 * 注意：yml 文件对缩进有严格要求 通过命令控制 docker-compose以下是一个简单的 docker-compose.yml 文件示例： 123456789101112131415161718192021222324252627282930version: &quot;3.9&quot;services: db: image: mysql:5.7 volumes: - ./db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - ./wordpress_data:/var/www/html ports: - &quot;80:80&quot; - &quot;443:443&quot; restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: &#123;&#125; wordpress_data: &#123;&#125; 这里用到了 mysql:5.7 和 wordpress:latest 两个 Docker 镜像，WordPress 镜像依赖 depends_on 于 MySQL 镜像。 restart: always 参数表明容器服务宕机后会自动重启。 MYSQL_ROOT_PASSWORD 为数据库的 root 密码，MYSQL_PASSWORD 为数据库的普通用户密码，请自行修改，对应的 WORDPRESS_DB_PASSWORD 也要同时修改。MYSQL_USER 为数据库普通用户的用户名，如果有需要也可以修改，对应的 WORDPRESS_DB_USER 也要同时修改。 80:80 的意思是把宿主机的 80 端口映射到容器内部的 80 端口。如需通过其他端口访问，只需修改前面的 80。比如，我要通过 8080 端口访问 WordPress，填写 8080:80 即可。 volumes 会将主机中指定的目录 ./wordpress_data 和容器中的指定目录 /var/www/html 共享，类似于虚拟机中的共享文件夹。并且在容器销毁后目录中的文件依旧存在。 在 Docker Compose 版本 3 及以上的配置中，不再使用 links 字段来定义容器之间的连接。取而代之的是使用 Docker 网络来实现容器之间的通信。现在，Docker Compose 默认创建一个项目级别的默认网络，其中每个服务（service）都可以使用它。 只需保证 db 和 wordpress 属于同一个项目（即在同一个 docker-compose.yml 文件中定义），它们将自动连接到默认网络，并可以通过服务名称（db 和 wordpress）相互访问。 docker-compose 脚本Docker Compose官方文档 docker-compose 命令 docker-compose up -d：根据当前目录的 yml 文件配置启动容器，-d 参数代表在后台运行 docker-compose ps：查看运行状态 docker-compose stop：停止运行 docker-compose restart：重启 docker-compose restart service-name：重启单个服务 docker-compose exec service-name sh：进入容器命令行 docker-compose logs [service-name]：查看容器运行 log，-f 指定文件名 Docker 安装及使用利用 docker 配置 wordpress 个人博客安装在安装 docker 时，发现 docker 有多个版本： docker.io：debian&#x2F;ubuntu 官方基于 docker 社区源码封装的版本，将 docker 的依赖直接转接到主系统上 docker-ce：docker.com 放出来的社区版，使用 golang 将依赖封装在一个包中 docker-ee：docker.com 维护的商业版一般使用docker.io 安装 docker.io： 1sudo apt install docker.io 安装 docker-compose： 1sudo apt install docker-compose 使用 创建一个文件夹用于存储 volume 以及 yml 文件： 1mkdir wordpress &amp;&amp; cd wordpress 编辑 yml 文件（yml 文件内容参照 Docker介绍）： 1vi myBlog.yml 启动容器（初次启动时会下载镜像，速度较慢）： 1sudo docker-compose up -d 如果有错误，查看启动日志： 1sudo docker-compose logs 如果需要进入容器内命令行： 1sudo docker-compose exec -it &lt;容器名称&gt; /bin/bash 停止并删除容器 1sudo docker-compose down Docker 镜像和容器的构建、导出docker build、docker export、docker save 和 docker commit 是 Docker 的一些常用命令，它们在 Docker 镜像和容器的构建、导出和保存等方面有不同的作用。 docker build作用：使用 Dockerfile 定义构建规则，构建一个新的 Docker 镜像。 描述：docker build 命令是用于根据 Dockerfile 创建一个新的 Docker 镜像。 Dockerfile 中包含了构建镜像所需的指令，例如安装软件、配置环境等。 docker build 命令会根据 Dockerfile 的指令逐步构建镜像的不同层，最终生成一个可执行的镜像。 docker export作用：导出 Docker 容器的文件系统作为一个 tar 归档文件。 docker export 命令将 Docker 容器导出为一个 tar 文件，其中包含容器中的文件系统和元数据，但不包括镜像的元数据和层。这意味着，使用 docker export 命令导出的文件无法用作 Docker 镜像的源文件，只能用于将容器迁移到另一个 Docker 主机或将容器中的文件系统导出到本地。 例如，如果你想要将一个正在运行的 WordPress 容器迁移到另一个 Docker 主机，可以使用 docker export 命令将容器导出为一个 tar 文件，然后将该文件传输到目标主机并使用 docker import 命令导入为一个新的 Docker 镜像。 1docker export &lt;container_id&gt; &gt; wordpress.tar docker save作用：将 Docker 镜像保存为 tar 归档文件。 docker save 命令将 Docker 镜像导出为一个 tar 文件，其中包含镜像的元数据和层，可以用作 Docker 镜像的源文件。这意味着，使用 docker save 命令导出的文件可以用于在不同的 Docker 主机之间共享镜像，或者将镜像备份到本地。 例如，如果你想要将一个名为 wordpress:latest 的 Docker 镜像备份到本地，可以使用 docker save 命令将镜像导出为一个 tar 文件。 docker save -o wordpress.tar wordpress:latest 总之，docker export 命令导出的文件只包含容器中的文件系统和元数据，而 docker save 命令导出的文件包含完整的镜像元数据和层，可以用于在不同的 Docker 主机之间共享镜像或备份到本地。 docker commit作用：将容器的变更保存为新的 Docker 镜像。 描述：docker commit 命令允许你将一个正在运行的容器的变更保存为一个新的 Docker 镜像。它会创建一个新的镜像层，将容器中的变更添加到这个层中，最终生成一个新的镜像。 例如：遇到了一个 docker 环境，需要带回来自己调试，打包正在运行的容器，快速拖环境跑路 1234docker ps //获取正在运行的容器,找到IDdocker commit -a &quot;test&quot; -m &quot;wordpress&quot; &lt;容器名称或ID&gt; //将容器打包成镜像docker save -o ./wordpress.tar &lt;容器名称或ID&gt; //拖到本地docker load -i hackgod-demo.tar //导入镜像 Docker 将容器打包成镜像以及导入导出可以使用 docker commit 命令来完成，docker commit 可以从容器创建一个新的镜像。 语法格式docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 参数说明-a : 提交的镜像作者；-c : 使用 Dockerfile 指令来创建镜像；-m : 提交时的说明文字；-p : 在 commit 时，将容器暂停 容器打包成镜像：将容器 a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。 12docker stop 2a2a11e2c043docker commit -a &quot;alway.com&quot; -m &quot;socks5&quot; 2a2a11e2c043 alway.com/wangwei/socks5:v1 导入在镜像包所在的文件夹下操作docker load --input uu.tar(也可以使用docker load -i uu.tar或者 docker load &lt; uu.tar) 或 docker load &lt; uu.tar 导出（镜像打包） docker save &gt; /root/docker_images/uu.tar ubuntu:latest 或 docker save /root/docker_images/ubuntu:latest &gt; uu.tar 或 docker save -o /root/docker_images/[镜像名].tar [镜像名]:latest 启动镜像 docker run -it -d --name container-name -pp1:p1-pp2:p2new-image-name docker run -it -d --name qinglong -p 5700:5700 alway.com/wangwei/qinglong:v1 联系和区别docker build 和 docker commit 都用于构建 Docker 镜像，但它们的方式不同。 *docker build 是通过 Dockerfile 定义构建规则，逐步构建镜像，而 docker commit 是将容器的变更直接保存为新的镜像。 docker export 和 docker save 都用于导出 Docker 镜像或容器的文件系统，但它们导出的内容不同。 *docker export 导出容器的文件系统作为归档文件，但不包含镜像的元数据和历史记录，不能用于还原容器。而 docker save 导出完整的 Docker 镜像，包含了元数据和文件系统，可以用于还原镜像。 docker build 和 docker save 都用于创建 Docker 镜像 docker export 用于导出容器的文件系统，而 docker commit 用于将容器的变更保存为新的镜像。","categories":["0.平台","Docker"]},{"title":"微信公众号后端配置","path":"/2024/05/22/0-平台-服务器-微信公众号后端配置/","content":"12345678910111213141516@app.route(&#x27;/wechat&#x27;, methods=[&#x27;GET&#x27;])def wechat_signature(): data = request.args echostr = data.get(&#x27;echostr&#x27;) signature = data.get(&#x27;signature&#x27;) timestamp = data.get(&#x27;timestamp&#x27;) nonce = data.get(&quot;nonce&quot;) if not signature or not timestamp or not nonce: return False tmp_str = &quot;&quot;.join(sorted([&#x27;liuluhua&#x27;, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(&#x27;UTF-8&#x27;)).hexdigest() if tmp_str == signature: return echostr else: print(&quot;Failed&quot;) return &quot;Failed&quot; 12345678910111213141516171819202122232425262728293031@app.route(&#x27;/wechat&#x27;, methods=[&#x27;POST&#x27;])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值​ req = xmltodict.parse(xml)[&#x27;xml&#x27;] # 判断post过来的数据中数据类型是不是文本​ if &#x27;text&#x27; == req.get(&#x27;MsgType&#x27;): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式​ resp = &#123;​ &#x27;ToUserName&#x27;:req.get(&#x27;FromUserName&#x27;),​ &#x27;FromUserName&#x27;:req.get(&#x27;ToUserName&#x27;),​ &#x27;CreateTime&#x27;:int(time.time()),​ &#x27;MsgType&#x27;:&#x27;text&#x27;,​ &#x27;Content&#x27;:req.get(&#x27;Content&#x27;)​ &#125; # 把构造的字典转换成xml格式​ xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) # print(req.get(&#x27;Content&#x27;)) # 返回数据​ return xml​ else:​ resp = &#123;​ &#x27;ToUserName&#x27;: req.get(&#x27;FromUserName&#x27;, &#x27;&#x27;),​ &#x27;FromUserName&#x27;: req.get(&#x27;ToUserName&#x27;, &#x27;&#x27;),​ &#x27;CreateTime&#x27;: int(time.time()),​ &#x27;MsgType&#x27;: &#x27;text&#x27;,​ &#x27;Content&#x27;: &#x27;I LOVE ITCAST&#x27;​ &#125;​ xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;)​ return xml 实现每天下午两点定时推送消息给订阅用户","categories":["0.平台","服务器"]},{"title":"植物大战僵尸游戏架构","path":"/2024/05/22/3-软件-0-项目-植物大战僵尸游戏架构/","content":"","categories":["3.软件","0.项目"]},{"title":"内网穿透方案","path":"/2024/05/22/3-软件-内网穿透-内网穿透方案/","content":"内网穿透，也称为 NAT 穿透或端口转发，是一种技术手段，用于在没有公网 IP 的情况下，使外网用户能够访问内网中的设备和服务。其基本原理是通过中转服务器或特定的网络配置，将内网设备的 IP 地址和端口映射到外网，从而实现内外网之间的通信。 具有公网 IP服务器端具有公网 IP获取公网 IP+DDNS 解析什么是 DDNSDDNS 的意思是动态域名解析。是解决有公网 IP ，但是公网 IP 不固定的问题，用固定的域名代替动态变化的公网 IP。 无公网 IP 网络环境用内网穿透方案，即类似如 nat123 内网映射方式，将内网 IP 映射成域名（自动生成二级域名或用自己域名）地址，然后通过域名来访问。 DDNS (Dynamic Domain Name System) 是一种可以动态更新域名解析的服务，它可以让您的域名指向一个动态 IP 地址，而不是一个固定的 IP 地址。它可以让您的域名跟随您的设备，而不需要您每次更改 IP 地址时都去更新域名解析。 适用情况： 路由器是公网 IP，但是公网 IP 不固定 检测方法： 用百度搜索 IP，百度会显示当前的 IP 地址，把这个 IP 地址和路由器的 IP 地址作比较，如果一致，说明是公网 IP，如果不一致，说明是运营商用一个 IP 然后经过多层 NAT 之后分配的内网 IP。 具有公网 IP 云服务器FRP将内网端口映射到公网服务器，通过公网服务器 + 端口的形式访问内网端口。需要了解配置 frps 和 frpc 的配置文件如何配置，针对特定端口进行开放 下载 frp 文件，根据实际要部署的环境的架构利用 wget 下载相应版本 项目地址 https://github.com/fatedier/frp 安卓版本仓库地址 https://github.com/FrpcCluster/frpc-Android 下载完成后 tar -xvf 解压，进入目录，修改 fps.toml 配置文件 文档地址 https://gofrp.org/zh-cn/docs/ frps 服务端配置安装前需 uname -a 查看云服务器的外网处理器架构,根据不同的架构下载不同 frp 版本，x86_64 的 下载 后缀带 amd 的即可 wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz 解压后编辑 frps.toml 文件 12345678910111213141516171819202122#bindAddr = &quot;0.0.0.0&quot;bindPort = 9085 //内网设备绑定的端口# auth tokenauth.token = &quot;******&quot; //接入验证码，需要和设备端保持一致# Configure the web server to enable the dashboard for frps.# 使能dashboard(非必要)# 使能控制面板# 控制面板必须配置port# dashboard is available only if webServer.port is set.webServer.addr = &quot;0.0.0.0&quot;webServer.port = 9086webServer.user = &quot;lemonade&quot;webServer.password = &quot;lemonade&quot;# console or real logFile path like ./frps.log # 使能log(非必要)# 输入的日志文件log.to = &quot;./frps.log&quot; //日志存储位置# trace, debug, info, warn, errorlog.level = &quot;info&quot; //存储等级log.maxDays = 3 //时间 netstat -ntlp 查看端口占用情况 启动 frps 服务 ./frps -c ./frps.toml， 需要注意服务器开通指定端口的防火墙 frpc 客户端配置123456789101112131415161718192021222324 //具有公网IP的服务器地址serverAddr = &quot;124.222.246.***&quot; //接入端口serverPort = 9085//接入tokenauth.token=&quot;******&quot;[[proxies]]//将本设备的5000端口映射到服务器的9087端口name = &quot;frp-nas&quot;//类型type = &quot;tcp&quot; localIP = &quot;0.0.0.0&quot;//本地端口localPort = 5000//公网端口remotePort = 9087[[proxies]]name = &quot;frp-nas-ssh&quot;type = &quot;tcp&quot;localIP = &quot;0.0.0.0&quot;localPort = 9090remotePort = 9088 微软的 devtunnel缺点是穿透的地址最长只能保持 30 天 执行安装命令： 1234#Windowswinget install Microsoft.devtunnel#Linux curl -sL https://aka.ms/DevTunnelCliInstall | bash 登录自己的账户 1devtunnel user login [-g] #-g代表github账户 假定需要将本机的 9006 端口做为对外穿透的端口，则命令为： 1devtunnel host -p 9006 [--allow-anonymous] [--expiration 2d] [--allow-anonymous] 允许任何人都可以访问 [--expiration 2d] 设置有效时间，过期自动删除，默认为 30 天，最大值为 30 天 如果你需要创建多个端口，则可以改为： 1devtunnel host -p 9006 9007 9008 由于一个 powershell 窗口同一时间默认只能运行一个 devtunnel 进程，所以如果你需要创建并监听多个内网映射端口，则需要像上面那样同时填写多个端口 查看当前系统中隧道端口列表： 1devtunnel list 查看某个隧道详细信息 假定隧道 id 为 “liuluhua”，列出 liuluhua 当前的一些配置或状态信息 1devtunnel show liuluhua 托管某个隧道 假定我们在其他 powershell 窗口里创建了一个隧道 “liuluhua”，我们现在当前 powershell 中托管监控它 1devtunnel host liuluhua 删除某个隧道： 假定要删除的某个 隧道 id 为 “liuluhua” 1devtunnel delete liuluhua 删除全部的隧道： 1devtunnel delete-all 1234567891011121314151617#devtunnel port create lemonade -p 5245#devtunnel host lemonadedevtunnel create [隧道名] -a#-a 表示可以表示隧道可以匿名访问#执行成功会输出隧道信息devtunnel port create [隧道名] -p 8080#隧道名为可选，默认为刚才创建的隧道#可以添加多个端口devtunnel host [隧道名]#隧道名为可选，默认为刚才创建的隧道#devtunnel delete [隧道名]#可以删除隧道 cloudflare控制台页面 https://dash.cloudflare.com 需要信用卡 Tailscale免费版 构建虚拟局域网 —ZeroTier、Tailscale 以及蒲公英 在 zerotier 创建虚拟局域网，客户端安装后复制虚拟局域网 ID 加入即可实现访问，但是连接速度不稳定 进阶方式可以自己搭建 moon 服务器和 planet 服务器，但是也需要公网服务器 私有部署zerotier-planet服务 一分钟自建zerotier-planet 学习文档内网穿透 - Jonnyan的原创笔记 - 亖亖亖 (mrdoc.fun) cpolar 内网穿透cpolar 官网地址: https://www.cpolar.com 使用一键脚本安装命令 1curl -L https://www.cpolar.com/static/downloads/install-release-cpolar.sh | sudo bash 向系统添加服务 1sudo systemctl enable cpolar 启动 cpolar 服务 1sudo systemctl start cpolar cpolar 安装成功后，在外部浏览器上访问 Linux 的 9200 端口即:【http:&#x2F;&#x2F;服务器的局域网 ip:9200】，使用 cpolar 账号登录,登录后即可看到 cpolar web 配置界面,结下来在 web 管理界面配置即可。 登录后，点击左侧仪表盘的隧道管理——创建隧道，创建一个的公网 http 地址隧道 隧道名称：可自定义命名，注意不要与已有的隧道名称重复 协议：选择 http 本地地址：8380(本地访问的地址) 域名类型：免费选择随机域名 地区：选择 China Top 隧道创建成功后，点击左侧的状态——在线隧道列表,查看所生成的公网访问地址，有两种访问方式,一种是 http 和 https。使用上面的 Cpolar https 公网地址,在任意设备的浏览器进行访问,即可成功看到界面,这样一个公网地址且可以远程访问就创建好了,使用了 cpolar 的公网域名,无需自己购买云服务器,即可到公网进行远程访问了！ 如果我们需要长期异地远程访问，由于刚才创建的是随机的地址，24 小时会发生变化。另外它的网址是由随机字符生成，不容易记忆。如果想把域名变成固定的二级子域名，并且不想每次都重新创建隧道来访问，我们可以选择创建一个固定的 http 地址来解决这个问题。 固定公网地址我们接下来为其配置固定的 HTTP 端口地址，该地址不会变化，方便分享给别人长期查看你的博客，而无需每天重复修改服务器地址。配置固定 http 端口地址需要将 cpolar 升级到专业版套餐或以上。 登录 cpolar 官网，点击左侧的预留，选择保留二级子域名，设置一个二级子域名名称，点击保留,保留成功后复制保留的二级子域名名称。保留成功后复制保留成功的二级子域名的名称。返回登录 Cpolar web UI 管理界面，点击左侧仪表盘的隧道管理——隧道列表，找到所要配置的隧道，点击右侧的编辑。修改隧道信息，将保留成功的二级子域名配置到隧道中 域名类型：选择二级子域名 Sub Domain：填写保留成功的二级子域名 点击更新(注意,点击一次更新即可,不需要重复提交) 更新完成后,打开在线隧道列表,此时可以看到公网地址已经发生变化,地址名称也变成了固定的二级子域名名称的域名 最后,我们使用固定的公网 https 地址访问,可以看到访问成功,这样一个固定且永久不变的公网地址就设置好了，可以随时随地进行异地访问！ freedns42","categories":["3.软件","内网穿透"]},{"title":"RSS","path":"/2024/05/22/1-语言-前端-RSS/","content":"Rsshub 的 docker 部署下载 docker-compose.yml wget https://raw.githubusercontent.com/DIYgod/RSSHub/master/docker-compose.yml 检查是否有需要修改的配置 vi docker-compose.yml # or your favorite editor 创建 redis 卷 Create a docker volume to persist Redis caches docker volume create redis-data 启动 docker-compose up -d Channel1234567891011121314151617&lt;channel&gt; 参考手册 元素 描述&lt;category&gt; 可选的。为 feed 定义所属的一个或多个种类。&lt;cloud&gt; 可选的。注册进程，以获得 feed 更新的立即通知。&lt;copyright&gt; 可选。告知版权资料。&lt;description&gt; 必需的。描述频道。&lt;docs&gt; 可选的。规定指向当前 RSS 文件所用格式说明的 URL。&lt;generator&gt; 可选的。规定用于生成 feed 的程序。&lt;image&gt; 可选的。在聚合器呈现某个 feed 时，显示一个图像。&lt;language&gt; 可选的。规定编写 feed 所用的语言。&lt;lastBuildDate&gt; 可选的。定义 feed 内容的最后修改日期。&lt;link&gt; 必需的。定义指向频道的超链接。&lt;managingEditor&gt; 可选的。定义 feed 内容编辑的电子邮件地址。&lt;pubDate&gt; 可选的。为 feed 的内容定义最后发布日期。&lt;rating&gt; 可选的。feed 的 PICS 级别。&lt;skipDays&gt; 可选的。规定忽略 feed 更新的天。&lt;skipHours&gt; 可选的。规定忽略 feed 更新的小时。&lt;textInput&gt; 可选的。规定应当与 feed 一同显示的文本输入域。 Item12345678910&lt;item&gt; 参考手册 元素 描述&lt;author&gt; 可选的。规定项目作者的电子邮件地址。&lt;category&gt; 可选的。定义项目所属的一个或多个类别。&lt;comments&gt; 可选的。允许项目连接到有关此项目的注释（文件）。&lt;description&gt; 必需的。描述此项目。&lt;enclosure&gt; 可选的。允许将一个媒体文件导入一个项中。&lt;guid&gt; 可选的。为项目定义一个唯一的标识符。&lt;link&gt; 必需的。定义指向此项目的超链接。&lt;pubDate&gt; 可选的。定义此项目的最后发布日期。&lt;source&gt; 可选的。为此项目指定一个第三方来源。 验证可以在 http://www.feedvalidator.org 找到很好的验证器。 RSS 阅读器功能文字 字体 字号 背景 翻页 图片 缩放 移动 下载 视频 播放&#x2F;暂停 快进 进度条 音量 下载 设置 订阅 自动&#x2F;手动同步 逻辑部分多线程处理等待消息返回xml 文件本地缓存的命名方式页面元素布局根据实际返回的页面元素，分别显示不同的页面","categories":["1.语言","前端"]},{"title":"设置flask后端CORS跨域访问","path":"/2024/05/22/1-语言-Python-设置flask后端CORS跨域访问/","content":"设置前后端分离 环境搭建flask 项目地址 https://tutorial.helloflask.com/ 安装 flask 和 flask-cors cors 用于允许服务器进行跨域访问 12pip install flaskpip install flask-cors 浏览器 js 前端代码123456789101112131415161718192021function SendUrlToServer(url, method)&#123;\tlet requestUrl = &#x27;http://124.222.246.202:8081/fetch-sub-url?url=&#x27;+url;\t/*let requestUrl = ?url=&#x27;http://127.0.0.1:8081/fetch-sub-url*/\tfetch(requestUrl, &#123;\tmethod: method,\theaders: &#123;\t&#x27;Content-Type&#x27;: &#x27;application/json&#x27;\t&#125;,\t/*body: JSON.stringify(&#123; url: url &#125;)*/\t&#125;).then(response =&gt; response.text()).then(data =&gt; &#123;\tconsole.log(&#x27;Response from server:&#x27;);&#125;).catch(error =&gt; &#123;\tconsole.error(&#x27;Error sending data:&#x27;, error);&#125;);&#125;function RSS() &#123;\tSendUrlToServer(&quot;https://rsshub.app/bilibili/ranking/0/3/1&quot;, &#x27;GET&#x27;);&#125; 服务器端 python 代码12345678910111213141516171819202122232425262728293031323334353637from flask import Flask, request, jsonifyfrom flask_cors import CORSimport requestsimport feedparser##get python pathimport ospython_path = os.environ.get(&quot;PYTHONPATH&quot;)print(&quot;PYTHONPATH:&quot;, python_path)##get endapp = Flask(__name__)#CORS(app, resources=&#123;r&quot;/*&quot;: &#123;&quot;origins&quot;: &quot;http://127.0.0.1:80&quot;&#125;&#125;) # 允许指定的来源访问CORS(app)@app.route(&#x27;/fetch-sub-url&#x27;, methods=[&#x27;GET&#x27;,&#x27;POST&#x27;])def fetch_sub_url(): #data = request.get_json() #url = data.get(&#x27;url&#x27;) #url = &#x27;https://www.baidu.com&#x27; url = request.args.get(&#x27;url&#x27;) print (&quot;current url is ===&gt;&quot;+url) try: response = requests.get(url) response_text = response.text return response_text except requests.exceptions.RequestException as e: return jsonify(&#123;&#x27;error&#x27;: str(e)&#125;) # 解析RSS feed #feed = feedparser.parse(url) # 打印feed的标题 #print(&quot;Feed Title:&quot;, feed.feed.title) # 打印feed中的条目 #for entry in feed.entries: # print(&quot; Title:&quot;, entry.title) # print(&quot;Link:&quot;, entry.link) # print(&quot;description:&quot;, entry.description) #return feedif __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=8081) 后端服务开机自启 systemd&#x2F;etc&#x2F;systemd&#x2F;system 启动 12345678910111213[Unit]Description=Start Python BackEnd With HtmlAfter=multi-user.target[Service]WorkingDirectory=/home/ubuntuType=idle#ExecStart=/home/ubuntu/html/BackEnd/start_backend.shExecStart=/usr/bin/python3 /home/ubuntu/html/BackEnd/main.pyUser=ubuntuGroup=ubuntuEnvironment=&quot;PYTHONPATH=/home/ubuntu/.local/lib/python3.10/site-packages&quot;[Install]WantedBy=multi-user.target 将服务单元文件复制到 systemd 目录： 将您的服务单元文件复制到&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;目录下。您可以使用 sudo 命令进行拷贝，确保文件的权限设置正确。 sudo cp your-service-name.service /etc/systemd/system/ 重新加载 systemd 配置： 您需要重新加载 systemd 配置以使更改生效。 sudo systemctl daemon-reload 启用服务： 要启用服务，使其在系统启动时自动启动，可以运行以下命令： sudo systemctl enable your-service-name.service 这将会在适当的运行级别下创建符号链接，以便服务在系统启动时自动启动。 启动服务： 如果您想立即启动服务，可以运行以下命令： sudo systemctl start your-service-name.service 这将启动您的服务。 完整后端处理代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149from flask import Flask, request, make_response, jsonifyfrom flask_cors import CORSfrom werkzeug.middleware.proxy_fix import ProxyFiximport requestsimport hashlibimport timeimport xmltodictimport osimport jsonimport socketimport asynciofrom aiohttp import web# root_dir = &#x27;/home/ubuntu/html/&#x27;# pic_dir = &#x27;0.res/Picture/&#x27;# name = &#x27;1&#x27;#request.args.get(&#x27;id&#x27;)# act_addr = os.path.join(root_dir,pic_dir,name);# fileNameList = &#x27;&#x27;# for file_name in os.listdir(act_addr):# fileNameList += pic_dir+name+&quot;/&quot;+file_name# print(fileNameList)app = Flask(__name__)app.wsgi_app = ProxyFix(app.wsgi_app)# 只允许特定路由支持跨域请求CORS(app, origins=[&quot;http://124.222.246.202&quot;,&quot;http://127.0.0.1&quot;])HOME_PATH = &quot;/home/ubuntu/BlogData/&quot;#@app.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])#def home_index():# index_html = open(&quot;/home/ubuntu/liuluhua.github.io/index.html&quot;, &quot;r&quot;)# print (&quot;文件名: &quot;, index_html.name)# print (&quot;是否已关闭 : &quot;, index_html.closed)# print (&quot;访问模式 : &quot;, index_html.mode)# return index_html.read()@app.route(&#x27;/get_ip&#x27;, methods=[&#x27;GET&#x27;])def ip_addr(): ip_addr = request.remote_addr api_url = f&#x27;https://ipinfo.io/&#123;ip_addr&#125;/json&#x27; response = requests.get(api_url) data = response.json() ret_data = &quot;来自&quot;+data.get(&#x27;country&#x27;)+&quot; &quot;+data.get(&#x27;region&#x27;)+&quot;的&quot;+data.get(&#x27;ip&#x27;)+&quot;朋友&quot;; return ret_data@app.route(&#x27;/get_picture&#x27;, methods=[&#x27;GET&#x27;])def picture_show(): pic_dir = &#x27;0.res/Picture/&#x27; name = request.args.get(&#x27;id&#x27;) act_addr = os.path.join(HOME_PATH,pic_dir,name); fileNameList = &#x27;&#x27; for file_name in os.listdir(act_addr): fileNameList += f&#x27;&lt;img src=&quot;&#123;pic_dir&#125;&#123;name&#125;/&#123;file_name&#125;&quot; alt=&quot;&#123;file_name&#125;&quot;&gt;&#x27; print(file_name) print (fileNameList) return (fileNameList)@app.route(&#x27;/getFileContent&#x27;, methods=[&#x27;POST&#x27;])def getFileContent(): filePath = request.get_json().get(&#x27;filePos&#x27;) print(filePath) f = open(filePath) lines = f.read() f.close() return lines@app.route(&#x27;/getFileList&#x27;, methods=[&#x27;POST&#x27;])def getFileList(): #return json.dumps(request.get_json()) + getDirList(HOME_PATH+&quot;Python&quot;); return getDirList(HOME_PATH+&quot;Python&quot;);def getDirList(dir_path,ret_list=None,depth=0): base_list = sorted(os.scandir(dir_path),key=lambda entry: (not entry.is_dir(), entry.name)) if ret_list is None: ret_list = [] for entry in base_list: if entry.is_dir(): ret_list.append(&#x27;&lt;details&gt;&lt;summary&gt;&lt;span class=&quot;tree-item&quot;&gt;&#x27;) ret_list.append(entry.name+&#x27;&lt;/span&gt;&lt;/summary&gt;&#x27;) getDirList(entry.path, ret_list, depth+1) ret_list.append(&#x27;&lt;/details&gt;&#x27;) else: file_pos = dir_path.replace(&quot;/home/ubuntu/html&quot;,&quot;&quot;) ret_list.append(f&#x27;&lt;details&gt;&lt;summary&gt; \\ &lt;span class=&quot;tree-item&quot; onclick=&quot;openFile(\\&#x27;&#123;file_pos&#125;/&#123;entry.name&#125;\\&#x27;)&quot;&gt;&#x27; + entry.name+&#x27;&lt;/summary&gt;&lt;/details&gt;&#x27;) return &quot; &quot;.join(ret_list)@app.route(&#x27;/signin&#x27;, methods=[&#x27;POST&#x27;])def signin(): print(&quot;post signin&quot;) username = request.form.get(&#x27;username&#x27;) password = request.form.get(&#x27;password&#x27;) button_clicked = request.form.get(&#x27;signin&#x27;) # 或者使用 &#x27;signup&#x27; #jsonify(&#123;&quot;response&quot;: &quot;test&quot;&#125;) # 确定哪个按钮被点击了 if button_clicked == &#x27;signin&#x27;: # 处理登录操作 return f&#x27;Login: Username=&#123;username&#125;, Password=&#123;password&#125;&#x27; elif button_clicked == &#x27;signup&#x27;: # 处理注册操作 return f&#x27;Signup: Username=&#123;username&#125;, Password=&#123;password&#125;&#x27; else: # 没有按钮被点击或者未知按钮名称 return &#x27;Unknown button pressed&#x27;@app.route(&#x27;/wechat&#x27;, methods=[&#x27;GET&#x27;])def wechat_signature(): data = request.args echostr = data.get(&#x27;echostr&#x27;) signature = data.get(&#x27;signature&#x27;) timestamp = data.get(&#x27;timestamp&#x27;) nonce = data.get(&quot;nonce&quot;) if not signature or not timestamp or not nonce: return False tmp_str = &quot;&quot;.join(sorted([&#x27;******&#x27;, timestamp, nonce])) tmp_str = hashlib.sha1(tmp_str.encode(&#x27;UTF-8&#x27;)).hexdigest() if tmp_str == signature: return echostr else: print(&quot;Failed&quot;) return &quot;Failed&quot;@app.route(&#x27;/wechat&#x27;, methods=[&#x27;POST&#x27;])def wechat_communication(): #获取微信服务器post过来的xml数据 xml = request.data # 把xml格式的数据进行处理，转换成字典进行取值 req = xmltodict.parse(xml)[&#x27;xml&#x27;] # 判断post过来的数据中数据类型是不是文本 if &#x27;text&#x27; == req.get(&#x27;MsgType&#x27;): # 获取用户的信息，开始构造返回数据，把用户发送的信息原封不动的返回过去，字典格式 resp = &#123; &#x27;ToUserName&#x27;:req.get(&#x27;FromUserName&#x27;), &#x27;FromUserName&#x27;:req.get(&#x27;ToUserName&#x27;), &#x27;CreateTime&#x27;:int(time.time()), &#x27;MsgType&#x27;:&#x27;text&#x27;, &#x27;Content&#x27;:req.get(&#x27;Content&#x27;) &#125; # 把构造的字典转换成xml格式 xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) # print(req.get(&#x27;Content&#x27;)) # 返回数据 return xml else: resp = &#123; &#x27;ToUserName&#x27;: req.get(&#x27;FromUserName&#x27;, &#x27;&#x27;), &#x27;FromUserName&#x27;: req.get(&#x27;ToUserName&#x27;, &#x27;&#x27;), &#x27;CreateTime&#x27;: int(time.time()), &#x27;MsgType&#x27;: &#x27;text&#x27;, &#x27;Content&#x27;: &#x27;I LOVE ITCAST&#x27; &#125; xml = xmltodict.unparse(&#123;&#x27;xml&#x27;:resp&#125;) return xmlif __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;127.0.0.1&#x27;, port=9080)","categories":["1.语言","Python"]},{"title":"Obsidian笔记建设","path":"/2024/05/22/0-平台-服务器-Obsidian笔记建设/","content":"Obsidian 配置Ctrl+Shift+I 在控制台里可以查看详细日志，所有插件的日志都可以在这里看到 Hexo 忽略文件和文件夹由于 hexo 的文章只存在于 source 目录下，我们需要让 Obsidian 忽略其他文件的内容以优化性能以及减少不必要的搜索结果。具体的操作是在 设置-文件与链接-Exclude Files，将需要忽略的文件添加进去（尤其是 node_modules）。 Templater模板配置说明文档 https://silentvoid13.github.io/Templater/introduction.html 首先我们要创建模板，我们可以在 source 目录下创建 _obsidian 文件夹，并创建一篇 Post Template 的文章（md 文件），我们再创建新文章的时候，只需要点击侧边栏的『插入模板』按钮就可以快速生成 Front-matter 信息： 123456789101112131415161718---title: &lt;% tp.file.title %&gt;date: &lt;% tp.file.creation_date(format=&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;update: &lt;% tp.file.last_modified_date(&quot;YYYY-MM-DD HH:mm:ss&quot;) %&gt;comments: truetags:categories:dg-publish: true---定义脚本function generateTimestampUrl() &#123; var timestamp = Math.round(new Date() / 1000); var url = timestamp.toString(36) return url; &#125; module.exports = generateTimestampUrl; osidian-git快捷键 Ctrl + P 打开命令面板，输入 open source control view 启用可视化操作面板 obsidian-pangu已用 Linter 替代 中英文之间加空格 Hidden Folder目录隐藏插件 FileTree左侧菜单出现了一个 File Tree 的 Tab 页，点击后就可以看到文件以树形的结构呈现，我们展开 source 文件夹，并右键 _post 文件夹，选择 Focuse on Folder 后，左侧的文件列表中就只会显示 _post 文件夹中的内容了 Github Publisher已使用整个仓库进行同步发布，不采用这种单页面发布形式 将 Obsidian 中的文章和本地附件上传到 Github 仓库，上传前可以指定文件目录、自定义内容替换等操作。 能将 Obsidian 仓库里的任意笔记自动或者手动同步到 GitHub 代码仓库的任意位置。首先设置好 Github 相关信息，包括 Github repository，用户名，token 以及 Branch。当然也可以在单个笔记文件里，通过文档属性（frontmatter），单独设置接收笔记上传的 Github 仓库信息（可以选择同一用户下的不同仓库，同一仓库下的不同位置）。 上传设置 设定上传的笔记存储在 Github 仓库的位置。因为我的 hexo 博客日志文件保存在 source&#x2F;posts 目录下，故选择 Fixed Folder，设定好默认上传到的目录。 文章发布 在文章文档属性添加一个 share 属性（可以根据需要在插件设置里改成其他任意名称），赋予值 true。文章写好后，share: true 右键发布。 ShellCommand可以解决 obsidian 无法打开 . 开头的默认文件的问题 再介绍个终极优化方案，之前我们执行命令是通过运行 bat 文件，而 Shell commands 可以在 Obsidian 中设置好命令，并通过 Obsidian 的命令面板或快捷键快速运行。 在插件设置面板中添加命令 运行博客： Shell commands 没有显示终端窗口的功能，所以需要我们启动 powershell 再传入命令 有了终端窗口我们才可以在窗口中按 Ctrl + C 关闭 Hexo 服务，否则它会一直占用端口 1start powershell &#x27;-NoExit -Command start http://localhost:4000 ; cd Blog ; hexo s&#x27; 打开站点和主题配置文件： 12start Blog/_config.ymlstart Blog/themes/butterfly4.3.1/_config.yml 然后修改默认执行环境为 PowerShell 5，可以为每个命令设置下别名，就是在命令面板显示的名字 Emo 插件用 PicGo 支持更多自定义设置 用于自托管图片 image auto upload plugin也是用于自托管图片 Linter 插件用户在保存笔记时按照一定的格式，格式化笔记，这里用到的功能： 保存笔记时自动插入 front-matter 进入 Linter 的设置，选择 YAML 设置，找到其中的插入 YAML 设置（ Insert YAML attributes），打开开关后，输入要插入的 front-matter 自动更新文件修改时间戳 进入 Linter 的设置，选择 YAML 设置，找到其中的 YAML 时间戳（ yaml-timestamp），设置为 Hexo 识别的 date 和 update 格式化笔记 主要的是一个不同语言中间的空格自动添加，进入 Linter 的设置，选择空格，找到其中的 Space between Chinese Japanese or Korean and English or numbers，打开即可 其他插件 Image Converter 转化图片格式，我统一转为 webp，并设置了图片分辨率大小。 Unique attachments 用于将附件的文件名统一为 “字母 + 数字”的格式,记着在配置里加入 webp 图片格式 Image Inserter 用于找图片，我用于设置文章封面，即设置 cover.image 属性。 目前在用的插件","categories":["0.平台","服务器"]},{"title":"ELF文件分析","path":"/2024/05/22/0-平台-Linux-程序-ELF文件分析/","content":"ELF 全称 “Executable and Linkable Format”，即可执行可链接文件格式，目前常见的 Linux、 Android 可执行文件、共享库（.so）、目标文件（ .o）以及 Core 文件（吐核）均为此格式。 文件布局常见的 ELF 文件大致结构如下： 常见的 ELF 格式如上图所示，左边为链接视图，右边为执行视图。从大局上看，ELF 文件主要分为 3 个部分: ELF Header Section Header Table Program Header Table 其中，ELF Header 是文件头，包含了固定长度的文件信息；Section Header Table 则包含了链接时所需要用到的信息；Program Header Table 中包含了运行时加载程序所需要的信息。 链接视图静态链接器（即编译后参与生成最终 ELF 过程的链接器，如 ld ）会以链接视图解析 ELF。编译时生成的 .o（目标文件）以及链接后的 .so （共享库）均可通过链接视图解析，链接视图可以没有段表（如目标文件不会有段表）。 执行视图动态链接器（即加载器，如 x86 架构 linux 下的 &#x2F;lib&#x2F;ld-linux.so.2 或者安卓系统下的 &#x2F;system&#x2F;linker 均为动态链接器）会以执行视图解析 ELF 并动态链接，执行视图可以没有节表。 文件头 ELF HeaderELF 的结构声明位于系统头文件 elf.h 中，ELF 格式分为 32 位与 64 位两种，除了重定位类型稍有区别，其它大致相同，为了简化描述，后续说明将省略 32&#x2F;64 字样。 ELF Header 的声明如下 : 123456789101112131415161718#define EI_NIDENT (16)typedef struct&#123; unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version */ Elf_Addr e_entry; /* Entry point virtual address */ Elf_Off e_phoff; /* Program header table file offset */ Elf_Off e_shoff; /* Section header table file offset */ Elf_Word e_flags; /* Processor-specific flags */ Elf_Half e_ehsize; /* ELF header size in bytes */ Elf_Half e_phentsize; /* Program header table entry size */ Elf_Half e_phnum; /* Program header table entry count */ Elf_Half e_shentsize; /* Section header table entry size */ Elf_Half e_shnum; /* Section header table entry count */ Elf_Half e_shstrndx; /* Section header string table index */&#125; Elf_Ehdr; 注释都很清楚了，挑一些比较重要的来说。其中 e_type 表示 ELF 文件的类型，有以下几种: ET_NONE: 未知类型 ET_REL: 可重定向类型(relocatable)，通常是我们编译的 *.o 文件 ET_EXEC: 可执行类型(executable)，静态编译的可执行文件 ET_DYN: 共享对象(shared object)，动态编译的可执行文件或者动态库 *.so ET_CORE: coredump 文件 e_entry 是程序的入口虚拟地址，注意不是 main 函数的地址，而是.text 段的首地址 _start。当然这也要求程序本身非 PIE(-no-pie)编译的且 ASLR 关闭的情况下，对于非 ET_EXEC 类型通常并不是实际的虚拟地址值。 其他的字段大多数是指定 Section Header(e_sh)和 Program Header(e_ph)的信息。Section&#x2F;Program Header Table 本身可以看做是数组结构，ELF 头中的信息指定对应 Table 数组的位置、长度、元素大小信息。最后一个 e_shstrndx 表示的是 section table 中的第 e_shstrndx 项元素，保存了所有 section table 名称的字符串信息。 12345678910e_ident包含了Maigc Number和其它信息，共16字节。0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。 123456789e_typeELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。 12345678e_machine处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 e_verison: 文件版本，目前常见的 ELF 文件版本均为 EV_CURRENT（1）。 e_entry: 入口虚拟地址。 e_phoff: 段表文件偏移。 e_shoff: 节表文件偏移。 e_flags: 处理器特定的标志，一般为 0。 e_ehsize: Elf_Header 的大小（字节） e_phentsize: 段头（Program Header）的大小（字节）。 e_phnum: 段的数量。 e_shentsize: 节头（Section Header）的大小（字节）。 e_shnum: 字的数量。 e_shstrndx: 节字符串表的节索引。 Section Headersection header table 是一个数组结构，这个数组的位置在 e_shoff 处，共有 e_shnum 个元素(即 section)，每个元素的大小为 e_shentsize 字节。每个元素的结构如下: 12345678910111213typedef struct&#123; Elf32_Word\tsh_name; /* Section name (string tbl index) */ Elf32_Word\tsh_type; /* Section type */ Elf32_Word\tsh_flags; /* Section flags */ Elf32_Addr\tsh_addr; /* Section virtual addr at execution */ Elf32_Off\tsh_offset; /* Section file offset */ Elf32_Word\tsh_size; /* Section size in bytes */ Elf32_Word\tsh_link; /* Link to another section */ Elf32_Word\tsh_info; /* Additional section information */ Elf32_Word\tsh_addralign; /* Section alignment */ Elf32_Word\tsh_entsize; /* Entry size if section holds table */&#125; Elf32_Shdr; 其中 sh_name 是该 section 的名称，用一个 word 表示其在字符表中的偏移，字符串表(.shstrtab)就是上面说到的第 e_shstrndx 个元素。ELF 文件中经常使用这种偏移表示方式，可以方便组织不同区段之间的引用。 sh_type 表示本 section 的类型，SPEC 中定义了几十个类型，列举其中一些如下: SHT_NULL: 表示该 section 无效，通常第 0 个 section 为该类型 SHT_PROGBITS: 表示该 section 包含由程序决定的内容，如.text、.data、.plt、.go SHT_SYMTAB&#x2F;SHT_DYNSYM: 表示该 section 中包含符号表，如.symtab、.dynsym SHT_DYNAMIC: 表示该 section 中包含动态链接阶段所需要的信息 SHT_STRTAB: 表示该 section 中包含字符串信息，如.strtab、.shstrtab SHT_REL&#x2F;SHT_RELA: 包含重定向项信息 虽然每个 section header 的大小一样(e_shentsize 字节)，但不同类型的 section 有不同的内容，内容部分由这几个字段表示: sh_offset: 内容起始地址相对于文件开头的偏移 sh_size: 内容的大小 sh_entsize: 有的内容是也是一个数组，这个字段就表示数组的元素大小 与运行时信息相关的字段为: sh_addr: 如果该 section 需要在运行时加载到虚拟内存中，该字段就是对应 section 内容(第一个字节)的虚拟地址 sh_addralign: 内容地址的对齐，如果有的话需要满足 sh_addr % sh_addralign &#x3D; 0 sh_flags: 表示所映射内容的权限，可根据 SHF_WRITE&#x2F;ALLOC&#x2F;EXECINSTR 进行组合 另外两个字段 sh_link 和 sh_info 的含义根据 section 类型的不同而不同，如下表所示: 至于不同类型的 section，有的是保存符号表，有的是保存字符串，这也是 ELF 表现出拓展性和复杂性的地方，因此需要在遇到具体问题的时候查看文档去进行具体分析。 Program Headerprogram header table 用来保存程序加载到内存中所需要的信息，使用段(segment)来表示。与 section header table 类似，同样是数组结构。数组的位置在偏移 e_phoff 处，每个元素(segment header)的大小为 e_phentsize，共有 e_phnum 个元素。单个 segment header 的结构如下: 1234567891011typedef struct&#123; Elf32_Word\tp_type; /* Segment type */ Elf32_Off\tp_offset; /* Segment file offset */ Elf32_Addr\tp_vaddr; /* Segment virtual address */ Elf32_Addr\tp_paddr; /* Segment physical address */ Elf32_Word\tp_filesz; /* Segment size in file */ Elf32_Word\tp_memsz; /* Segment size in memory */ Elf32_Word\tp_flags; /* Segment flags */ Elf32_Word\tp_align; /* Segment alignment */&#125; Elf32_Phdr; 既然 program header 的作用是提供用于初始化程序进程的段信息，那么下面这些字段就是很直观的: p_offset: 该 segment 的数据在文件中的偏移地址(相对文件头) p_vaddr: segment 数据应该加载到进程的虚拟地址 p_paddr: segment 数据应该加载到进程的物理地址(如果对应系统使用的是物理地址) p_filesz: 该 segment 数据在文件中的大小 p_memsz: 该 segment 数据在进程内存中的大小。注意需要满足 p_memsz&gt;&#x3D;p_filesz，多出的部分初始化为 0，通常作为.bss 段内容 p_flags: 进程中该 segment 的权限(R&#x2F;W&#x2F;X) p_align: 该 segment 数据的对齐，2 的整数次幂。即要求 p_offset % p_align &#x3D; p_vaddr。 剩下的 p_type 字段，表示该 program segment 的类型，主要有以下几种: PT_NULL: 表示该段未使用 PT_LOAD: Loadable Segment，将文件中的 segment 内容映射到进程内存中对应的地址上。值得一提的是 SPEC 中说在 program header 中的多个 PT_LOAD 地址是按照虚拟地址递增排序的。 PT_DYNAMIC: 动态链接中用到的段，通常是 RW 映射，因为需要由 interpreter(ld.so)修复对应的的入口 PT_INTERP: 包含 interpreter 的路径，见下文 PT_HDR: 表示 program header table 本身。如果有这个 segment 的话，必须要在所有可加载的 segment 之前，并且在文件中不能出现超过一次。 在不同的操作系统中还可能有一些拓展的类型，比如 PT_GNU_STACK、PT_GNU_RELRO 等，不一而足。 参考链接 Linux Foundation Referenced Specifications Executable and Linkable Format (ELF) Tool Interface Standard (TIS) Executable and Linking Format (ELF) Specification Version 1.2 elf(5) - format of Executable and Linking Format (ELF) files How programs get run: ELF binaries 深入了解GOT,PLT和动态链接","categories":["0.平台","Linux","程序"]},{"title":"博客管理后端Qexo建设","path":"/2024/05/21/0-平台-服务器-博客管理后端Qexo建设/","content":"安装克隆 qexo 项目到本地 git clone https://github.com/Qexo/Qexo.git 编辑配置，以使用 Mysql 为例, 确认好安装相关依赖后在 manage.py 的同级目录下创建并修改 configs.py 12345678910111213141516import pymysql pymysql.install_as_MySQLdb() DOMAINS = [&quot;127.0.0.1&quot;, &quot;124.222.246.202&quot;] DATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;NAME&#x27;: &#x27;数据库表&#x27;, &#x27;USER&#x27;: &#x27;数据库用户名&#x27;, &#x27;PASSWORD&#x27;: &#x27;数据库密码&#x27;, &#x27;HOST&#x27;: &#x27;127.0.0.1&#x27;, &#x27;PORT&#x27;: &#x27;3306&#x27;, &#x27;OPTIONS&#x27;: &#123; &quot;init_command&quot;: &quot;SET sql_mode=&#x27;STRICT_TRANS_TABLES&#x27;&quot; &#125; &#125; &#125; 安装 mysqlsudo apt install mysql-server 查看并更新密码 sudo cat /etc/mysql/debian.cnf 创建 Qexo 要使用表 create database qexo; 安装依赖 123pip3 install -r requirements.txt python3 manage.py makemigrations python3 manage.py migrate 启动 Qexo 博客管理后端 后台运行，退出 shell 也在运行 nohup python3 manage.py runserver 0.0.0.0:9082 --noreload &amp; 访问公网 IP+ 端口即可打开管理页面 配置在 vercel 上配置","categories":["0.平台","服务器"]},{"title":"USB设备连接到WSL","path":"/2024/05/21/0-平台-WSL-USB设备连接到WSL/","content":"在 WSL2 中连接 3D 打印机的 USB 端口，须将该设备从 windows 中挂载至 Linux 中，需要在 windows 环境中安装 usbipd usbipd GitHub 地址 https://github.com/dorssel/usbipd-win 安装 usbipd 12#在win命令行中执行winget install usbipd 安装环境 123##在你的wsl中执行sudo apt install linux-tools-virtual hwdatasudo update-alternatives --install /usr/local/bin/usbip usbip `ls /usr/lib/linux-tools/*/usbip | tail -n1` 20 *usbipd: error: WSL ‘usbip’ client not correctly installed.重新执行此步骤 列出并挂载 win 中的设备到 linux 环境下 123# 在win终端中执行usbipd wsl listusbipd wsl attach --busid=4-1","categories":["0.平台","WSL"]},{"title":"Vmware共享文件夹","path":"/2024/05/21/0-平台-VMware-Vmware共享文件夹/","content":"查看共享的文件夹使用 vmware-hgfsclient 命令 输入 vmware-hgfsclient 显示共享文件夹名称 挂载共享文件夹使用 vmhgfs-fuse 命令 vmhgfs-fuse .host:/ShareDir /home/forlinx/ShareDir -o subtype=vmhgfs-fuse,allow_other 将主机下的 ShareDir 挂载到虚拟机的&#x2F;home&#x2F;forlinx&#x2F;ShareDir 文件夹下 在虚拟机中设置共享文件夹完成后，发现共享文件夹没有出现，执行 vmhgfs-fuse .host:/ /home/forlinx/ShareDir文件夹下 如果没有其他显示报错，就可以认为挂载成功了。 注意：&#x2F;mnt 文件夹下的 hgfs 是自己创建的，如果没有，可以用 mkdir /mnt/hgfs 命令创建。 直接用 ls 命令查看 ls /home/forlinx/ShareDir 显示挂载的共享文件夹内的文件内容已经同步，表示成功挂载。 自动挂载脚本创建一个 startShare.sh 写入 vmhgfs-fuse .host:/ /home/forlinx/ShareDir 加权限 chmod a+x startShare.sh 添加该脚本到自启中 启动文件另：如果不想每次重启后都挂载一遍的话，建议直接把挂载放入启动文件 首先，备份 /etc/fstab 文件 cp fstab fstab_bak 其次，编辑 fstab``vim fstab 在最后一句添加 12# mount hgfs.host:/kali_share /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0 然后就能够不用每次重启挂载一遍。","categories":["0.平台","VMware"]},{"title":"3D打印控制命令","path":"/2024/05/21/3-软件-3D打印机-3D打印控制命令/","content":"G-Code 协议指令 https://marlinfw.org/meta/gcode/ 限位开关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令： QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确，如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） 123[stepper_X]endstop_pin: ^PE5 #修改前endstop_pin: ^!PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令 PID_CALIBRATE HEATER=heater_bed TARGET=100 它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速 M106 S64 ，然后发送命令 PID_CALIBRATE HEATER=extruder TARGET=245 它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。 其他使 Klipper 进入 “shutdown”（关闭）状态 M112 重新加载配置文件并重启 FIRMWARE_RESTART 保存配置文件 SAVE_CONFIG 查看使用的 printer.cfg 文件位置 ps -ef | grep klippy 获取位置 GET_POSITION 调平 QUAD_GANTRY_LEVEL GCode 协议指令Klipper 支持的 G-Codes 命令官方文档 https://www.klipper3d.org/G-Codes.html 部分我使用到的命令 命令 用途 M112 使 Klipper 进入 “shutdown”（关闭）状态 FIRMWARE_RESTART 重新加载配置文件并重启 SAVE_CONFIG 保存配置文件 GET_POSITION 获取位置 限位开关测试相关确保 X、Y 和 Z 轴的限位开关都没有被触发，然后通过控制台发送命令：QUERY_ENDSTOPS 返回值是 open 打开，则限位触发电平类型设置正确 如果是 triggered（触发），则需要修改限位的电平类型（以 X 轴为例） 123456 [stepper_X] endstop_pin: ^PE5 #修改前 endstop_pin: ^!PE5 #修改后 或 endstop_pin: PE5 #修改前 endstop_pin: ^PE5 #修改后 热床 PID 校正G28 归零后，将喷嘴移至热床中心，高出床面约 5-10mm，然后发送命令PID_CALIBRATE HEATER=heater_bed TARGET=100它将执行一个 PID 校准程序，将持续约 10 分钟，完成后控制台将会返回 PID 数值，将其复制到热床的 PID 设置即可。 挤出头 PID 校正先将模型冷却风扇设置为 25% 的转速（ M106 S64 ），然后发送命令PID_CALIBRATE HEATER=extruder TARGET=245它将执行一个 PID 校准程序，将持续约 5 分钟，完成后控制台将返回 PID 数值，将其复制到配置文件即可。","categories":["3.软件","3D打印机"]},{"title":"3D打印相关软件","path":"/2024/05/21/3-软件-3D打印机-3D打印相关软件/","content":"系统固件KlipperKlipper 是一个高性能、灵活的 3D 打印机固件，它通过将一些计算工作转移到更强大的主机（如 Raspberry Pi）上来提高打印质量和速度。 MarlinMarlin 是目前最流行的 3D 打印机固件之一，支持广泛的硬件平台和 3D 打印机模型，具有丰富的功能和高度的可定制性。 控制软件fluiddFluidd 是一个基于网页的控制界面，用于管理和监控运行 Klipper 固件的 3D 打印机。它提供了用户友好的界面和实时监控功能。GitHub 地址: https://github.com/fluidd-core/fluidd安装手册: https://github.com/dw-0/kiauh Make-meMake-me 是一个通过 WiFi 控制 Replicator 2 打印机的开源项目，使用 GitHub 的聊天机器人 Hubot 来监控和完成打印任务。目前只支持 Mac 的 OS X。 Pepeteir-ServerPepeteir-Server 是一个新型的 Repeteir 产品，可以在 Raspberry Pi 上运行，支持控制多台打印机，内存消耗极小。它的网页操作界面简单，但不支持 Mac 和 PC。 OctoprintOctoprint 是一个完全基于网页的 3D 打印机控制程序，可以远程控制打印机，并通过网络摄像头监控打印过程。支持 Raspberry Pi。 BotqueueBotqueue 是一个开源的远程打印机控制软件，可以控制多台打印机。用户上传 .stl 文件后，软件会完成切片和打印工作。它支持为每台打印机设置独立的切片特性。 切片软件切片软件用于将 3D 模型按层切片，并生成用于打印的 G 代码。 CuraCura 由 Ultimaker 开发，兼容多种 3D 打印机。它不仅可以切片，还提供 3D 打印机控制界面，尤其适用于 Ultimaker 的 3D 打印机。 Slic3rSlic3r 是开源且免费的切片软件，因其快捷性和高度可定制化而广受欢迎。许多 3D 打印机制造商提供默认的 Slic3r 配置文件（.INI 文件），可以用作初始设置。 Skeinforge另一款非常流行的切片软件。同样开源，免费。 kisslicerKISSlicer 是一款跨平台的切片软件，名称源自 “Keep It Simple”（保持简单），目标是提供一个简单易用的界面。 PrintrunPrintrun 既是控制软件，也是切片软件，可以独立完成从切片到打印的整个过程。支持 Mac、Linux 和 PC 操作平台。 Repetier-HostRepetier-Host 与 Printrun 类似，是一款综合性软件，具有切片、零件定位和机器控制功能。用户界面相对更复杂但更直观，同样支持 Mac、Linux 和 PC 操作平台。 3D 建模软件BlenderBlender 是一款开源的 3D 建模软件，功能强大且完全免费。它不仅可以用于 3D 建模，还支持动画、渲染、雕刻等多种功能，适用于各种复杂的 3D 设计和制作。 TinkercadTinkercad 是一个由 Autodesk 开发的在线 3D 建模工具，适合初学者使用。它基于浏览器，无需下载软件，界面友好且易于使用。 Fusion 360Fusion 360 同样由 Autodesk 开发，是一款功能强大的云端 3D CAD、CAM 和 CAE 工具。它适用于从初学者到专业人士的各个层级，提供了全面的建模、仿真和制造功能。 SketchUpSketchUp 是一款广受欢迎的 3D 建模软件，以其直观的用户界面和易用性著称。它有免费版本（SketchUp Free）和专业版本（SketchUp Pro），适用于建筑、工程、游戏开发等多个领域。 FreeCADFreeCAD 是一款开源的 3D CAD 建模软件，适合于产品设计、机械工程以及建筑设计。它具有模块化的架构，可以通过插件扩展其功能。 SolidWorksSolidWorks 是一款由 Dassault Systèmes 开发的专业 3D CAD 软件，广泛应用于工程设计、产品设计和制造业。它功能强大，但价格较高，通常用于工业级应用。 OnshapeOnshape 是一个基于云的 3D CAD 建模软件，适用于团队协作和设计项目。它无需安装，直接在浏览器中运行，支持实时协作和版本控制。 OpenSCADOpenSCAD 是一款开源的 3D CAD 建模软件，适用于创建精确的 3D 模型。它使用编程语言来定义模型，适合那些有编程经验的用户。","categories":["3.软件","3D打印机"]},{"title":"Python","path":"/2024/05/21/1-语言-Python-Python/","content":"源码安装打开终端，使用以下命令更新软件包列表： 1sudo apt update 安装编译 Python 3.10 所需的依赖项： 1sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： 1wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码并进入解压后的目录： 12tar -xf Python-3.10.0.tgzcd Python-3.10.0 配置 Python 3.10 的编译选项： 1./configure --enable-optimizations 编译并安装 Python 3.10： 12make -j 8sudo make altinstall 确认 Python 3.10 是否安装成功： 1python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。","categories":["1.语言","Python"]},{"title":"pip下载网络问题","path":"/2024/05/21/1-语言-Python-pip下载网络问题/","content":"在使用 Python 安装包工具 pip 时经常会出现下载很慢的情况，这其中有很大一部分原因和 pip 的源有关，在我们安装 python 后，通常 python 解释器自带 pip 这个工具，但是这里 pip 是设置的默认源，也就是官方源：https://pypi.org/simple，这个源在国内的下载速度是很慢的，所以我们为了提高包的下载速度我们可以通过换源来实现。 临时使用参数可以在使用 pip 的时候加参数 -i https://pypi.tuna.tsinghua.edu.cn/simple 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple markdown 这样就会从清华这边的镜像去安装 markdown。 12345678910# 清华源pip install markdown -i https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip install markdown -i https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip install markdown -i http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip install markdown -i http://pypi.douban.com/simple/# 中国科学技术大学pip install markdown -i http://pypi.mirrors.ustc.edu.cn/simple/ 报错未添加信任源pip install beautifulsoup4 --trusted-host mirrors.aliyun.com 永久修改命令行12345678910# 清华源pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/# 腾讯源pip config set global.index-url http://mirrors.cloud.tencent.com/pypi/simple# 豆瓣源pip config set global.index-url http://pypi.douban.com/simple/# 换回默认源pip config unset global.index-url 配置文件 Linux 下 ~/.pip/pip.conf Windows 下 &#96;&#96;%HOMEPATH%\\pip\\pip.ini&#96;内容如下： 12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 报错未添加信任源12[install]trusted-host=pypi.douban.com","categories":["1.语言","Python"]},{"title":"Linux下的CH34x串口识别","path":"/2024/05/21/2-通讯协议-串口-Linux下的CH34x串口识别/","content":"ch341.ko 是一个 Linux 内核模块，用于支持 CH341 USB 转串口芯片。要在内核中编译该模块，需要找到其配置选项。这个配置选项通常在 Linux 内核的配置文件中定义，并且可以通过配置内核选项来启用。 判断是否识别使用 lsusb 命令可以看到有 Bus 001 Device 005: ID 1a86:7523 QinHeng Electronics CH340 serial converter 是能识别出 ch34x 设备 检查串口是否被驱动加载输入指令 ls /dev/ttyUSB* 将会列出 USB 的加载情况。如果提示 No such file or directory 则是没有被驱动加载。 占用情况因报文件不存在错误，采用 dmesg|grep tty 命令检查发现，被 brltty 进程占用。 brltty 是一个后台进程（守护进程），为盲人提供对 Linux&#x2F;Unix 控制台的访问（当处于文本模式时），使用可刷新盲文显示。 移除该 apt remove brltty。 权限chmod a+rw /dev/ttyUSB0 即可 重装驱动-单独编译下载最新的驱动 CH341SER_LINUX https://github.com/WCHSoftGroup/ch341ser_linux 解压后进入 “driver” 目录下 输入 make 命令编译驱动，正常编译完成后，将会看到生成了 ch341.ko 模块 输入 sudo make load 或者 sudo insmod ch341.ko 动态加载驱动（重启需要再次加载），或者输入 sudo make install 安装驱动（重启不丢失） 输入 sudo make unload 或者 sudo rmmod ch341.ko 或者 sudo make uninstall 卸载驱动 如果编译失败，可能是 ch34x.c 和实际内核版本不匹配，uname -r 可查看操作系统的发行版号，之后在 https://elixir.bootlin.com/linux/latest/source 中查找对应内核版本的源代码文件，一般位于 /drivers/usb/serial/ch341.c，替换后重新编译 如果 insmod 失败，查看 /lib/modules/$(uname -r)/kernel/drivers/usb/serial 目录下是否已经有了 ko 模块，将目录中生成 ko 文件复制到此处，使用 lsmod 查看模块 重装驱动-交叉编译编译一个 ARM64 的 ch341 的 ko 文件，用于 4.19.206 内核的 Linux，ch341.ko 模块的定义位于 drivers/usb/serial/Kconfig 文件中，通过配置 USB_SERIAL_CH341 选项可以在内核中启用该模块。编译内核时根据配置生成相应的模块文件，然后通过 modprobe 加载即可使用该模块。 在 drivers 目录下的所有文件中，在文件的内容中查找字符串 CH341grep -r &quot;CH341&quot; drivers/ 确认串口类型，是 CH341 还是 PLX2303 ch341.c 文件中的 usb_device_id 是否包含要使用的 VID，PID（lsusb 命令查看） 查找配置选项，在 Linux 内核源代码目录中，驱动程序的配置选项通常定义在 Kconfig 文件中。要查找 ch341 驱动的配置选项，可以在内核源代码目录下运行以下命令：grep -r &quot;CH341&quot; drivers/ 这将搜索包含 CH341 字符串的所有文件，通常会找到类似以下的条目： 12drivers/usb/serial/Kconfig:config USB_SERIAL_CH341drivers/usb/serial/Kconfig:\ttristate &quot;USB CH341 single port serial driver&quot; 配置内核，知道配置选项后，可以使用 make menuconfig 或 make nconfig 等工具来配置内核。在 USB Serial Converter support 菜单下，找到并启用 USB CH341 single port serial driver 选项。或者配置 USB_SERIAL_CH341=m，将其设置为模块（M）或内联（*），如果希望编译为模块，选择 M。 1234Device Drivers ---&gt; [*] USB support ---&gt; &lt;*&gt; USB Serial Converter support ---&gt; &lt;*&gt; USB CH341 single port serial driver 编译内核和模块，配置完成后，编译内核和模块： 123makemake modulesmake modules_install 加载模块，编译完成后，可以使用 modprobe 加载模块：modprobe ch341 验证模块加载，使用 lsmod 验证模块是否成功加载，如果显示 ch341 模块，则说明加载成功。lsmod | grep ch341 重装驱动-apt包提供了一些可能默认没有包含的额外内核模块。 sudo apt install linux-modules-extra-$(uname -r) 手动加载 ch341 驱动程序： sudo modprobe ch341 检查驱动程序是否已加载： lsmod | grep ch341 检查设备是否被识别： dmesg | grep ch341 KO 文件开机自动加载/etc/modules 文件中添加模块打开 /etc/modules 文件： sudo vi /etc/modules 在文件末尾添加你想要加载的 KO 文件的名字（不需要路径，只需要模块名），比如： my_module 使用 modprobe 配置文件创建一个新的文件在 /etc/modprobe.d/ 目录，例如 custom.conf： sudo vi /etc/modprobe.d/custom.conf 添加如下内容，指定模块名称： install your_module_name /sbin/insmod /path/to/your/module.ko 使用 rc.local 文件打开 /etc/rc.local 文件： sudo vi /etc/rc.local 在 exit 0 之前添加 insmod 命令，指定模块的完整路径： 12sudo insmod /path/to/your/module.koexit 0 创建 systemd 服务创建一个新的服务文件，例如 load-module.service： sudo vi /etc/systemd/system/load-module.service 在文件中添加以下内容，指定模块路径： 1234567891011[Unit]Description=Load custom kernel module[Service]Type=oneshotExecStart=/sbin/insmod /path/to/your/module.koExecStop=/sbin/rmmod your_module_nameRemainAfterExit=true[Install]WantedBy=multi-user.target","categories":["2.通讯协议","串口"]},{"title":"自启动","path":"/2024/05/21/0-平台-Linux-其他-自启动/","content":"设置脚本1234567vi /etc/rc.local# 添加内容/usr/bin/nginx startchmod +x /etc/rc.d/rc.local# /etc/rc.d/rc.local是/etc/rc.local的软连接 自启动服务在 /etc/systemd/system/my_startup.service 或 /usr/lib/systemd/system/startmyapp.service 编辑或创建一个服务文件 1234567891011121314151617181920[Unit]Description=API Server for Klipper SV1Documentation=https://moonraker.readthedocs.io/Requires=network-online.targetAfter=network-online.target[Install]WantedBy=multi-user.target[Service]Type=simpleUser=forlinxSupplementaryGroups=moonraker-adminRemainAfterExit=yesWorkingDirectory=/home/forlinx/moonrakerEnvironmentFile=/home/forlinx/printer_data/systemd/moonraker.envExecStart=/home/forlinx/moonraker-env/bin/python $MOONRAKER_ARGSRestart=alwaysRestartSec=10 加载服务到自启动中 12sudo systemctl daemon-reloadsudo systemctl enable my_startup 操作服务 12345678910111213141516171819# 设置开机自启动systemctl enable startmyapp.service# 停止开机自启动systemctl disable startmyapp.service# 启动服务systemctl start startmyapp.service# 关闭服务systemctl stop startmyapp.service# 重新启动服务systemctl restart startmyapp.service# 重新加载服务配置文件systemctl reload startmyapp.service# 查看服务当前状态systemctl status startmyapp.service# 查看所有已启动的服务systemctl list-units --type=services# 查询服务是否开机启动systemctl is-enabled startmyapp.service 查看服务状态journalctl 是 Systemd 日志收集服务 journal 的一个命令行界面。它允许用户查询和操作 systemd journal 中的日志条目。这对于诊断系统服务问题、追踪错误或者监控系统事件非常有用。下面是几个使用 journalctl 的基本命令示例： 查看所有日志，这个命令会显示系统中所有服务的日志。 journalctl 查看特定服务的日志，将&lt;服务名&gt;替换为你想查看服务的日志名称，例如查看 nginx 服务日志： 12journalctl -u &lt;服务名&gt;.servicejournalctl -u nginx.service 实时查看日志，这个命令会像 tail -f 一样实时显示新的日志条目。 journalctl -f 查看特定时间范围内的日志，这个例子会显示从 2023 年 4 月 1 日 0 点到 23 点 59 分 59 秒之间的日志。 journalctl --since &quot;2023-04-01 00:00:00&quot; --until &quot;2023-04-01 23:59:59&quot; 查看包含特定关键词的日志，使用 grep 结合 journalctl 来过滤特定关键词，例如查找包含”error”的日志，或者直接使用 journalctl 的 grep 参数（-g 或–grep）： 123journalctl | grep errorjournalctl -u &lt;服务名&gt;.service --grep &quot;关键字&quot; 清空日志，这个命令会删除所有超过 1 天的日志条目。请注意，这将永久删除日志数据。 journalctl --vacuum-time=1d","categories":["0.平台","Linux","其他"]},{"title":"CAN和CANFD","path":"/2024/05/20/2-通讯协议-CAN-CAN和CANFD/","content":"CAN 和 CANFDCAN 与 CAN-FD 主要区别： 传输速率不同 CAN：最大传输速率 1Mbps。 CAN-FD：速率可变，仲裁比特率最高 1Mbps（与 CAN 相同），数据比特率最高 8Mbps。 数据长度不同 CAN：一帧数据最长 8 字节 CAN-FD：一帧数据最长 64 字节。 帧格式不同和 ID 长度不同。 CANFD 不存在远程帧，CAN 报文中的 RTR（用于区别标准帧与远程帧）被替换为 RRS（远程请求替代位，默认值为 0） CANFD 报文的标准帧和扩展帧—IDE 为 1 表示为扩展帧、为 0 表示标准帧 FDF 用于传统 CAN 报文和 CANFD 报文，FDF 位为 0 时为传统报文，FDF 为 1 时为 CANFD 报文 BRS 位速率切换为，BRS 位为 0 时 CANFD 速率保持恒定速率、BRS 位为 1 时 CANFD 的数据段会被切换到高速率。 ESI 错误状态指示位：CAN 报文中发送节点的错误状态只有该节点自己知道，CANFD 报文中可以通过 ESI 标志位来告诉其他节点该节点的错误状态，当 ESI 为 1 时表示发送节点处于被动错误状态、当 ESI 为 0 时表示发送节点处于主动错误状态 CRC：随着数据场的扩大，为了保证信息发送的质量，CAN FD 的 CRC 计算不仅要包括数据段的位，还包括来自 SOF 的 Stuff Count 和填充位。通过比较 CRC 的计算结果，可以判断接收节点是否能够正常接收。 在 CAN 中，CRC 的位数是 15 位，而在 CAN FD 中，CRC 场扩展到了 21 位。 当传输报文为 15 字节时：CRC 15 位 当传输数据为 16 字节或更少时：CRC 17 位 当传输数据超过 16 字节时：CRC 21 位","categories":["2.通讯协议","CAN"]},{"title":"CANOpen 笔记","path":"/2024/05/20/2-通讯协议-CAN-CANOpen-笔记/","content":"项目地址 CANopenNode https://github.com/CANopenNode/CANopenNode CANopenLinux https://github.com/CANopenNode/CANopenLinux CANopenDemo https://github.com/CANopenNode/CANopenDemo CANopenEditor https://github.com/CANopenNode/CANopenEditor 帮助文档 CANopenLinux https://canopennode.github.io/CANopenLinux CANopenDemo https://canopennode.github.io/index.html CANopenCANopen 是一种基于 CAN（Controller Area Network） 通信协议的高层协议和设备协议，定义了网络管理、设备配置、通信对象和应用对象等方面的标准，以确保不同设备之间的互操作性和通信的一致性。 协议CiA 通过一系列文件维护保持 CANopen 设备和通讯协议规定。基本配置由 CiA 301 CANopen 应用层和通信配置规范定义。规范包括： CANopen 对象字典中的数据类型、编码规则和对象 CANopen 通信服务和协议 CANopen 网络管理服务和协议 CANopen 通讯配置 – 物理层 预定义的通信对象标识符连接数集、与紧急事件相关的对象、时间标识和同步通信对象 此基本 CiA 301 配置规定由其他 CiA 文件进行了补充和扩展，为一些具体领域的设备和功能规定了设备、应用程序和接口配置。具体有以下几个部分，按照自身应用程序的实际情况引入。 CiA 302 – CANopen 附加应用层功能 CiA 303-1 – 布线和接头管脚分配 CiA 303-3 – 指示器规范 CiA 306 – CANopen 电子数据表规范 CiA 309 – 从其他网络接入 CANopen CiA 315 – CANopen 通用框架 CiA 401 – 通用 I&#x2F;O 模块的 CANopen 设备配置 CiA 402 – 驱动和运动控制的 CANopen 设备配置 OSI 模型CANopen 的 OSI 模型，Data link 和 Physical 是由 CAN 进行实现的，Presentation 和 Session 是由 CANopen 进行实现的。 物理层（Physical Layer）定义了物理介质、电气特性、传输速率和编码规范等。 数据链路层（Data Link Layer）划分数据帧、错误检测与纠正、流量控制。 网络层（Network Layer）提供路径选择、逻辑寻址、路由选择等功能。 传输层（Transport Layer）提供端到端的传输控制和错误恢复。 会话层（Session Layer）建立、维护、同步和恢复会话。 表示层（Presentation Layer）数据的加密、压缩、格式转换等。 应用层（Application Layer）用户数据交互和应用支持。 设备模型每个 CANopen 设备都遵循一个通用的设备模型，因此不同的设备能依据同样的 CANopen 标准。CANopen 设备模型的三个组成部分是： 通讯接口 对象字典 应用程序一个 CANopen 设备必须支持一定数量的网络管理服务 NMT，需要至少一个 SDO。每个生产或消费过程数据的设备需要至少一个 PDO。所有其它的通讯对象是可选的。 核心概念通讯模式 设备&#x2F;节点通信有 3 种模型：主设备&#x2F;从设备、客户端&#x2F;服务器和生产者&#x2F;消费者 通讯协议 协议用于通信，例如配置节点（SDO）或传输实时数据（PDO） 定义了设备之间通信的机制和方式，包括对象字典、服务数据对象（SDO）、过程数据对象（PDO）、网络管理（NMT）等。 设备状态 设备支持不同的状态。“主”节点可以更改“从”节点的状态，例如将其重置。 对象字典（Object Dictionary，OD） 每个 CANopen 设备都有一个对象字典，OD 带有指定设备配置的条目，类似于一个查找表，列出了设备中的所有参数和数据。对象字典包括通信对象和应用对象，使用 16 位索引和 8 位子索引进行标识。可以通过 SDO 访问。 EDS（Electronic Data Sheet） EDS 是用于 OD 的标准文件格式，允许更新设备的服务 通讯模式CANopen 通过不同的通讯模式在节点之间传输报文: 生产&#x2F;消费模式: 它是一个广播连接，以推送模式工作（信号生产节点向消费节点发送无任何特定要求的信息）和引入模式（消费节点向信号生产节点要求特定信息）。 用户机&#x2F;服务器模式: 通过 SDO 协议，用户节点向服务器节点要求数据（对象字典索引），然后服务器节点通过发送在指定索引处的对象内容来响应。 主机&#x2F;从机模式: 主机节点可在任何时候向从机节点发送或要求数据。例如：NMT 协议通信。 数据帧数据帧由帧头 + 数据区组成，帧头由功能 ID+NodeID+RTR(远程传输请求)构成。 11 位的 CAN ID 称为通信对象标识符（COB-ID），分为两个部分： 前 4 位等于功能代码 Function Code（代表一个 CANopen 通信对象） 后 7 位包含节点 IDNode ID CANopen 网络中使用的 COB-ID 标识符的预定义分配 数据区部分的定义就要通过 CANopen 中的重要概念，对象字典 OD 来实现。 对象字典 OD对象字典（OD）是 CANopen 协议的核心概念。它是一组预定义的 CANopen 对象，使用索引和子索引访问对象。对象字典提供了应用程序和设备之间的沟通方式，提供了配置该设备的途径，和与设备通信的方法。 所有 CANopen 节点必须具有对象字典（OD），对象字典是指含有描述的 CANopen 节点的 行为 的所有 参数 的 标准化结构。 设备（例如从设备）的 OD 条目可以由其他设备（例如主机）使用 SDO 通过 CAN 进行访问。例如，通过 SDO 可以使应用程序主机更改从属发送心跳的频率。 作为对象索引存储在对象字典中的信息包括： 通信和应用程序配置参数 标准化设备配置参数 制造商特定设备配置文件参数 设备配置静态数据类型 设备配置复杂数据类型 复杂和静态数据类型 制造商特定数据类型 其他 可以按照 CANopen 标准的指导，以预定义的方式添加自己特定的制造商配置和数据类型。制造商还可以通过扩展由标准设备配置和数据类型规范要求的标准设备功能，来增强其设备的功能。 主索引索引值低于 0x0FFF 的是一些数据类型定义。一个节点的对象字典的有关范围在 0x1000 到 0x9FFF 之间，该范围内定义了一系列称为子协议的文档，用于定义节点的通讯行为。 通讯子协议区域详细划分 通用通讯对象 OD 示例配置下图是一个 TPDO 的定义示例，该 TPDO 在主索引 0x1800 的子索引中定义该 TPDO 相关的通信参数，主要是 TPDO 的发送类型和触发事件等设置，同时在和 0x1800 地址对应的 0x1A00 中定义了映射参数，在该参数的子索引中，定义了具体的映射地址和对象。并给出了该 TPDO 消息在发送时数据区内容。 电子数据表（EDS）一个节点的对象字典是在电子数据文档（EDS：Electronic Data Sheet）中描述。 实际上，将使用适当的软件工具来配置&#x2F;管理复杂的 CANopen 网络。 一个电子数据表（EDS）是一个标准化的电子文件，描述为 CANopen 设备定义的通信功能和对象。此供应方生成的文件有 3 个区域： 关于 EDS 文件的信息 一般设备信息 具有默认变量的对象字典 EDS 文件可用作 CANopen 设备的配置和网络设置工具。 通讯协议通信对象CANopen 通信单元由必要的通信接口和协议软件组成，通过总线在节点之间进行通信对象的发送和接收。各种 CANopen 通信对象用于实现各种类型的通信，CANopen 协议定义了几种不同类型的通信对象，每种对象都用于特定的通信目的： 过程数据对象（PDO）：用于实时数据传输，具有高优先级和低延迟。PDO 传输的数据量小，但传输速度快，适用于传感器数据和控制命令等实时性要求高的场景。 服务数据对象（SDO）：用于非实时数据传输，如配置参数和大数据块的传输。SDO 传输的灵活性更大，但优先级较低，适用于设备配置和诊断等场景。 网络管理对象（NMT）：用于控制设备状态和网络操作模式，如启动、停止和复位设备。 同步对象（SYNC）：用于网络同步，确保所有节点在同一时间点进行操作。 时间戳对象（TIME）：提供时间参考，用于时间相关的操作。 紧急情况对象 (EMCY) ： 指定状态下可用的通讯对象及状态转换说明： 中括号内的字母表示处于不同状态那些通讯对象可以使用。 123456a. NMTb. Node Guard c. SDO d. Emergencye. PDO f. Boot-up 网络管理（NMT）所有的 CANopen 节点都有自己专属的 NMT 状态，而主站可以通过 NMT 去控制从站的状态。CANopen 的网络管理采取主机&#x2F;从机通信模式。整个网络被设置为一个“状态机”，其中一个设备被指定为 NMT 主机，其余设备被指定为 NMT 从机。NMT 主机控制和监控 NMT 从机的状态。通过 NMT 主机触发，NMT 从机进行状态转换，实现 CANopen 网络的各个阶段。 NMT 服务用于通过 NMT 命令来控制 CANopen 设备的状态。只有 NMT-Master 节点能够传送 NMT Module Control 报文。所有从设备必须支持 NMT 模块控制服务。NMT Module Control 消息不需要应答。为了更改状态，NMT 主设备发送 COBID+2 字节的消息。 COB-ID 为 0（function code&#x3D;0 和 node ID&#x3D;0），优先级为最高。 第一个 CAN 数据字节 Requested State 包含请求的状态 第二个 CAN 数据字节包含目标节点的节点 ID。节点 ID 0 表示广播命令。所有从节点都处理此消息。 通过具体的 NMT 协议，如启动协议、模块控制协议、心跳协议（Heartbeat Protocol）和节点监测，主机向从机发出状态更改命令，进行这些状态转换。NMT 主机向特定节点或所有节点发送 NMT 命令代码以改变状态。 在预运行状态下，应用程序配置工具可以使用SDO 通信，配置 NMT 从机和设置参数。由于设备尚未开始运行，因此在此状态下不能使用 PDO 通信。 一旦状态从预运行变为运行状态，节点中的所有通信对象都将变为活跃状态，并且运行节点之间均可进行 PDO 和 SDO 通信。在此阶段，也可以通过 SDO 访问对象字典。当节点状态更改为停止时，PDO 和 SDO 通信都将停止。 实际状态取值 步骤 Byte 0 取值（命令） 状态 （2） 01 operation （3） 02 stop （4） 80 pre-operation （5） 81 reset app （6） 82 reset communication 示例1234# node 0x6 进入 `operational` 模式000 01 06# 所有节点进入 `pre-operational` 模式000 80 00 服务数据对象（SDO）SDO 提供了直接访问 CANopen 设备对象字典的入口，入口条件包括数据类型及大小。 访问者被称作客户端(client)，对象字典被访问且提供所请求服务的 CANopen 设备别称作服务器(server)。任何类型的 SDO 传输都由客户端发起，数据字典 OD 持有者是服务端，客户端和服务端都可以主动中止传输。通常情况下 CAN 总线网络中只有一个客户端。 客户的 CAN 报文和服务器的应答 CAN 报文总是包含 8 字节数据（尽管不是所有的数据字节都一定有意义）。一个客户的请求一定有来自服务器的应答。如果超时没有确认，则客户端节点将会重新发送原报文。 SDO 服务用于访问&#x2F;更改 CANopen 设备的对象字典中的值。允许 CANopen 节点通过 CAN 网络读取另一个节点的对象字典&#x2F;编辑值。下载（Download）是指对对象字典进行写操作，上传（Upload）指对对象字典进行读操作。 客户端节点可以通过以下 CAN 帧广播来启动 SDO 下载到节点 5，这将触发节点 5（并被其他节点忽略）。SDO 客户端的“接收”（即请求）CAN 帧如下所示： SDO 消息变量数据区 Byte 说明： Byte0 命令字节，主要定义了以下内容： CCS（客户端命令说明符，Client Command Specifier）描述传输类型（下载 download&#x2F;上载 upload） n 是数据字节 4-7 中不包含数据的 bytes （如果设置了 e＆s 则有效） 如果设置，e 表示 快速传输(所有数据在单个 CAN 帧中)&#x2F;分段传输 如果设置，s 表示数据大小显示在 n 中 Byte1+Byte2 主索引字节（16 位）确认 OD 主索引 Byte3 子索引字节（8 位）确认 OD 子索引 Byte4-7 包含实际的数据内容 一旦节点（客户端）发送了 CAN 帧，从节点 5（服务端）便会通过 RSDO 进行响应，并带有 COB-ID585。该响应包含索引&#x2F;子索引和 4 个空数据字节。自然地，如果客户端节点请求上传（即从节点 5 OD 读取数据），则节点 5 将以字节 4-7 中包含的相关数据进行响应。 SDO 灵活，但会带来大量输出，使其不适用于实时操作数据。同时数据只能包含在后续 4 个字节中，对于较大的数据方案，无法一次传输完毕。因此 SDO 中实现了 2 种传送机制，两种传送机制实际包含 4 个请求&#x2F;应答协议，共有 5 个协议如下： 快速传送（Expedited transfer） ： 最多传输 4 字节数据 启动域下载 （Initiate Domain Download） 启动域上传 （Initiate Domain Upload） 分段传送（Segmented transfer） ： 传输数据长度大于 4 字节 域分段下载（Download Domain Segment） 域分段上传 （Upload Domain Segment） 域传送中止（Abort Domain Transfer）。 快速 SDOCommand specifier(CS)命令符: 0x40 读取命令 0x2F 写一个字节 0x4F 返回值响应一个字节 0x2B 写两个字节 0x4B 返回值响应两个字节 0x27 写三个字节 0x47 返回值响应三个字节 0x23 写四个字节 0x43 返回值响应四个字节 0x60 写成功应答 0x80 异常响应 启动域下载（Initiate Domain Download） Bit 7 6 5 4 3 2 1 0 客户端 0 0 1 - n n e s 服务器 0 1 1 - - - - n ： 如果 e=1 且 s=1，则有效，否则为 0；表示数据部分中无意义数据的字节数（字节 8－n 到 7 数据无意义）。 e ： 0 &#x3D; 正常传送，1 &#x3D; 加速传送（数据在一个帧中）。 s ： 是否指明数据长度，0 &#x3D; 数据长度未指明，1 &#x3D; 数据长度指明。 e &#x3D; 0， s &#x3D; 0： 由 CiA 保留。 e &#x3D; 0， s &#x3D; 1 ： 数据字节为字节计数器，byte 4 是数据低位部分（LSB），byte 7 是数据高位部分（MSB）。 e &#x3D; 1 ： 数据字节为将要下载（download）的数据。 启动域上传（Initiate Domain Upload） Bit 7 6 5 4 3 2 1 0 客户端 0 1 0 - - - - - 服务器 0 1 0 - n n e s n，e，s： 与启动域下载相同。 分段 SDO域分段下载（Download Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 0 0 t n n n c 服务器 0 0 1 t - - - - n ：无意义的数据字节数。如果没有指明段长度，则为 0。 c ： 0 &#x3D; 有后续分段需要 download，1 &#x3D; 最后一个段。 t ： 触发位，后续每个分段交替清零和置位（第一次传送为 0，等效于 request&#x2F;response）。 域分段上传（Upload Domain Segment） Bit 7 6 5 4 3 2 1 0 客户端 0 1 1 t - - - - 服务器 0 0 0 t n n n c n，c，t ： 与域分段下载相同。 示例通讯示例 -upload 数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 40 00 14 02 00 00 00 00 若成功，应答： 585 4F 00 14 02 FE 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 40 02 18 01 00 00 00 00 若成功，应答：585 60 02 18 01 08 02 12 60 通讯示例 -download数据 0xFE ，对象字典节点 5 , 索引 index 0x1400, 子索引 subindex 2 客户端请求 ： 605 2F 00 14 02 FE 00 00 00 若成功，应答： 585 60 00 14 02 00 00 00 00 数据 0x60120208 ，对象字典节点 5 , 索引 index 0x1802, 子索引 subindex 1 客户端请求 ：605 23 02 18 01 08 02 12 60 若成功，应答：585 60 02 18 01 00 00 00 00 过程数据对象（PDO）PDO 属于过程数据，即单向传输，无需接收节点回应 CAN 报文来确认，从通讯术语上来说是属于“生产消费”模型。、生产者“生产数据”，并使用 Transmit PDO（TPDO）将其传输到“消费者”（主用户）。相反，它可以通过 Receive PDO（RPDO）从使用者接收数据。 PDO 服务用于在设备之间传输实时数据，例如来自温度传感器的温度数据。PDO 承载大量信息，被视为最重要的 CANopen 协议。PDO 消息可以包含 8 个完整字节的数据，并且它可以在单个帧中包含多个对象参数值。因此在 PDO 服务中用 1 帧完成 SDO 至少需要 4 帧的操作。 带有特定 11 位 CAN 标识符的 TPDO 由一个设备发送，并作为 RPDO 由零个或多个设备接收。每个 PDO 在对象字典中用 2 个对象描述： PDO 通讯参数：包含哪个 COB-ID 将被 PDO 使用，传输类型，禁止时间和定时器周期。在索引 0x1400+ 和 0x1800+ 的对象字典中。 PDO 映射参数：包含一个对象字典中对象的列表，这些对象映射到 PDO 里，包括它们的数据长度（in bits）。生产者和消费者必须知道这个映射，以解释 PDO 内容。在索引 0x1600+ 和 0x1A00+ 的对象字典中。 生产者节点可以被配置为每 100ms 响应消费者所广播的 SYNC 触发。然后，节点 5 可以例如在下面广播，以 COB-ID 185 的 TPDO： 注意数据区部分 3 个参数值的打包方式，这些值是由数据字典中对应的映射结构决定了一个 PDO 的数据类型和映射关系。 通信参数定义了该设备所使用的 COB-ID、传输类型、定时周期等。RPDO 通讯参数位于对象字典索引的 0x1400 to 0x15FF，TPDO 通讯参数位于对象字典索引的 0x1800 to 0x19FF。每条索引代表一个 PDO 的通信参数集，其中的子索引分别指向具体的各种参数。PDO 消息的内容是预定义的（或者在网络启动时配置的）。 Number of entries 参数条目数量：即本索引中有几条参数； COB-ID：即这个 PDO 发出或者接收的对应 CAN 帧 ID； 发送类型：即这个 PDO 发送或者接收的传输形式，通常使用循环同步和异步制造商特定事件较多； Inhibit time 生产禁止约束时间(1&#x2F;10ms)：约束 PDO 发送的最小间隔，避免导致总线负载剧烈增加，比如数字量输入过快，导致状态改变发送的 TPDO 频繁发送，总线负载加大，所以需要一个约束时间来进行“滤波”，这个时间单位为 0.1ms； Event timer 事件定时器触发的时间(单位 ms)：定时发送的 PDO，它的定时时间，如果这个时间为 0，则这个 PDO 为事件改变发送。 SYNC start value 同步起始值：同步传输的 PDO，收到诺干个同步包后，才进行发送，这个同步起始值就是同步包数量。比如设置为 2，即收到 2 个同步包后才进行发送。 发送类型PDO 可以有多种发送类型： 同步（通过接收 SYNC 对象实现同步） 非周期：远程帧预触发传送或设备子协议中规定的对象特定事件预触发传送。 周期：传送在每 1 到 240 个 SYNC 消息后触发。 异步 远程帧触发传送。通过发送与 PDO 的 COB-ID 相同的远程帧来触发 PDO 发送 由设备子协议中规定的对象特定事件触发传送。（基本采用这种，例如定时传输，数据变化传输等） 由传输类型定义的不同 PDO 传输模式，传输类型为 PDO 通讯参数对象的一部分，由 8 位无符号整数定义。 间隔时间一个 PDO 可以指定一个禁止时间，即定义两个连续 PDO 传输的最小间隔时间，避免由于高优先级信息的数据量太大，始终占据总线，而使其它优先级较低的数据无力竞争总线的问题。禁止时间由 16 位无符号整数定义，单位 100us。 定时周期一个 PDO 可以指定一个事件定时周期，当超过定时时间后，一个 PDO 传输可以被触发（不需要触发位）。事件定时周期由 16 位无符号整数定义，单位 1ms。 映射参数RPDO 通讯参数 1400h to 15FFh，映射参数 1600h to 17FFh，数据存放为 2000h 之后厂商自定义区域； TPDO 通讯参数 1800h to 19FFh，映射参数 1A00h to 1BFFh，数据存放为 2000h 之后厂商自定义区域。 包含了一个对象字典中的对象列表，这些对象映射到相应的 PDO，其中包括数据的长度（单位，位），对于生产者和消费者都必须要知道这个映射参数，才能够正确的解释 PDO 内容。就是将通信参数、应用数据和具体 CAN 报文中数据联系起来。 子索引 0：PDO 中映射应用程序对象的数量： 值 0：映射被禁用。 值 1：子索引 0x01 有效。 值 2-8: 子索引 0x01 至 (0x02 至 0x08) 有效。 子索引 1-8： 应用对象 1-8： 位 16-31：索引 位 8-15：子索引 位 0-7：数据长度（位） 示例示例设备配置 节点 ID: 0x01 第二个 Transmit PDO (TPDO2): TPDO2 的 COB-ID: 0x280 + Node_ID &#x3D; 0x281 对象字典（Object Dictionary）定义： 0x1801: TPDO2 通信参数 子索引 0x00: 0x02 (表示有 2 个子索引) 子索引 0x01: 0x00000281 (TPDO2 的 COB-ID, 使能) 子索引 0x02: 0x00 (传输类型，假设为 0x00 表示同步传输) 0x1A01: TPDO2 映射参数 子索引 0x00: 0x02 (映射对象数量，表示有两个对象映射到这个 TPDO) 子索引 0x01: 0x60000208 (映射对象 0x6000，子索引 0x02，8 位) 子索引 0x02: 0x64010110 (映射对象 0x6401，子索引 0x01，16 位) 假设当前设备中的数据如下： 对象 0x6000，子索引 0x02: 0xAB 对象 0x6401，子索引 0x01: 0x1234 TPDO2 实际发送的 CANopen 数据帧报文由以下 3 个字节组成： Byte 0: 0xAB Byte 1: 0x34 (低 8 位) Byte 2: 0x12 (高 8 位) 实际的 CANopen 数据帧：CAN ID: 0x281 Data: [0xAB, 0x34, 0x12] 设置一个 TPDO Index 1800 + n，subindex 01 ，COB_ID（通讯对象的标识符）：包含 CAN-ID 和附加控制位的标识符 Index 1800 + n，subindex 02， 写传输类型 t， t &#x3D; 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t &#x3D; FD ：收到 PDO 请求后 t &#x3D; FE ：事件驱动（制造商指定） t &#x3D; FF ：事件传输，节点自发传输 PDO Index 1800 + n， subindex 03，抑制时间。 如果传输类型设置为 FE 和 FF，它是最小的 PDO 传输间隔，单位 100us，值为 0 禁用抑制时间。PDO 报文需要延时 t × 100us 的时间才发出，以此避免在多 PDO 报文同时发出时，引起的时间冲突 。 Index 1800 + n， subindex 05，时间定时器。 如果传输类型设置为 FE 和 FF，它是 PDO 传输间隔，单位 ms，值为 0 禁用。t &#x3D;0xC8，200ms。 Index 1A00 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 18 02 FF 00 00 00 设置索引 Index 1800，事件传输 605 2F 00 18 05 C8 00 00 00 设置索引 Index 1800，时间间隔 200ms 605 2F 00 1A 00 00 00 00 00 设置子索引禁用 605 23 00 1A 01 10 00 30 400x40300010，设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 23 00 1A 02 20 00 10 200x20100020，设置映射索引 0x2010，子索引 00，大小 0x20（32 位） 605 2F 00 1A 00 02 00 00 00 设置映射数量，用多少设多少，这里用了 2 个 设置一个 RPDO Index 1400 + n, subindex 01 ，COB_ID（通讯对象的标识符） Index 1400 + n, subindex 02，写传输类型 t， t &#x3D; 1 – 0xF0：同步，时间触发模式 ，每 t 一周期 t &#x3D; FD ：收到 PDO 请求后 t &#x3D; FE ：事件驱动（制造商指定） t &#x3D; FF ：事件传输，节点自发传输 PDO Index 1600 + n，定义映射 subindex 0 ：定义映射数量（1 byte）。 值 0，映射禁用；值 01，子索引 01 有效；值 02，子索引 01–02 有效…… subindex 1 ：映射第一个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) subindex 2 ：映射第二个参数。 格式，index (2 bytes) – subindex (1 byte) – size (1 byte) 605 2F 00 14 02 FF 00 00 00 设置索引 Index 1400，事件传输 605 2F 00 16 00 00 00 00 00 设置子索引禁用 605 23 00 16 01 10 00 30 40 设置映射索引 0x4030，子索引 00，大小 0x10（16 位） 605 2F 00 16 00 01 00 00 00 设置映射数量，用多少设多少，这里用了 01 定义映射时，先设置子索引禁用；再设置相应映射；然后设置映射数量对于 TPDO 来说，其通信参数中的 COB-ID 是自身的 COB-ID，当发送 TPDO 时用来表明这个 TPDO 是谁发出的。对于 RPDO 来说，其通信参数的 COB-ID 是发送方的 COB-ID，用来表示自己只接受某个 CAN 节点发过来的 TPDO。 同步（SYNC）SYNC 消息通常由应用程序主机触发。每个节点都以该同步报文作为 PDO 触发参数，因此该同步报文的 COB-ID 具有比较高的优先级以及最短的传输时间。一般选用 0x80 作为同步报文的 CAN-ID，将 SYNC 消息（COB-ID 080）发送到 CANopen 网络。 在网络范围内同步（尤其在驱动应用中）：在整个网络范围内当前输入值准同时保存，随后传送（如果需要），根据前一个 SYNC 后接收到的报文更新输出值。 主从模式：SYNC 主节点定时发送 SYNC 对象，SYNC 从节点收到后同步执行任务。 在 SYNC 报文传送后，在给定的时间窗口内传送一个同步 PDO。 用 CAL 中基本变量类型的 CMS 对象实现。 CANopen 建议用一个最高优先级的 COB-ID 以保证同步信号正常传送。SYNC 报文可以不传送数据以使报文尽可能短。 一般同步报文由 NMT 主机发出，CAN 报文的数据为 0 字节。但如果一个网络内有 2 个同步机制，就需要设置不同的同步节拍，比如某些节点按 1 个同步帧发送 1 次 PDO，其他的节点收到 2 个同步帧才发送 1 次 PDO，所以这里 PDO 参数中的同步起始值就起了作用。 在同步协议中，有 3 个约束条件： 同步命令：0x1005 中规定了同步帧的命令为 0x80； 通讯循环周期：索引 0x1006 规定了同步帧的循环周期； 同步窗口时间：索引 0x1007 约束了同步帧发送后，从节点发送 PDO 的时效，即在这个时间内发送的 PDO 才有效，超过时间的 PDO 将被丢弃。 示例配置 1005 信息，设 SYNC 的 COB-ID 为 0x80（默认值） 23 05 10 00 80 00 00 00 读取 1006 信息 40 06 10 00 00 00 00 00 写入 1006 信息，将 SYNC 的通信周期设置为 100ms，那么需要写入到 0x1006 的值为 100000（100ms &#x3D; 100000us） 23 06 10 00 A0 86 01 00 时间戳（TIME-stamp）时间标记对象（Time Stamp），NMT 主机发送自身的时钟，为网络各个节点提供公共的时间参考，即网络对时，这在故障诊断中非常需要。 时间戳协议采用广播方式，无需节点应答，CAN-ID 为 0x100，数据长度为 6，数据为当前时刻与 1984 年 1 月 1 日 0 时的时间差。节点将此时间存储在对象字典 1012h 的索引中。 主机发出带有 CAN ID 100 的 TIME 消息，TIME 服务包含一个 6 字节的日期和时间信息。其中最初的 4 个数据字节包含午夜之后的毫秒数，随后的 2 个字节包含自 1984 年 1 月 1 日以来的天数。 紧急情况（EMCY）紧急报文协议（Emergency protocol）用于设备发生致命错误（例如传感器故障）的情况，从而使其可以向网络的其余部分指示此错误。 受影响的节点以高优先级向网络发送发送设备内部错误代码，提示 NMT 主站。紧急报文属于诊断性报文，一般不会影响 CANopen 通讯，其 CAN-ID 存储在 0x1014 的索引中，一般会定义为 0x080 + node-ID，数据包含 8 个字节，例如，节点 5 具有 COB-ID 085 + 数据字节，数据字节包含有关错误的信息，可以查找厂商定义的错误代码。 紧急信息的内容如下 Bytes 0…1： CO_EM_errorCode_t，在本例中为 0x5000（设备硬件） Bytes 2：CO_errorRegister_t，本例中为 0x01（通用错误） Bytes 3：CO_EM_errorStatusBits_t 中的错误条件索引，本例中为 0x2F（CO_EM_NON_VOLATILE_MEMORY - 访问非易失性设备内存时出错） Bytes 4…7：附加信息参数，本例中为 0x00000014 或 0x00000074 紧急信息由 CO_errorReport() 函数内部触发。您可以在 CO_EM_NON_VOLATILE_MEMORY 的源代码中查找紧急信息的来源。 CO_EM_NON_VOLATILE_MEMORY 是一般的严重错误，默认情况下会设置 CANopen 错误寄存器。如果错误寄存器的值不等于零，则禁止节点进入 NMT 运行状态，并且不能与其交换 PDO。 节点监测NMT 主机定期使用远程帧询问从机的当前状态，并将其与网络数据库中记录的早期状态相比较。任何不匹配和缺少 PDO 传输的状态都会以适当的错误代码表示，然后应用程序将采取适当的操作，如设备重置或错误标识。这称为节点监测，是通过使用节点监测协议得以实现。 NMT 从机使用一种称为生命监测的技术，通过在预定义的时间间隔里，内部检查节点监测帧的接收，来检测 NMT 主机的缺失。 现代设备设计使用 Heartbeat 协议进行节点监视，其中 NMT 从设备（Heartbeat Producer 心跳发出者）将周期性地向 NMT 主设备（Heartbeat Consumer 心跳使用者）发送 Heartbeat 报文。 这些报文之间的间隔是可配置的，并在主、从两个设备的对象字典中 Heartbeat producer time（心跳产生时间）对象上都进行设置。如果心跳报文在此时间限制内未到达，则发出者将被视为关机，使用者将采取补救措施，如设备重置或错误显示。 当一个 Heartbeat 节点启动后它的 Boot-up 报文是其第一个 Heartbeat 报文。Heartbeat 消费者通常是 NMT-Master 节点，它为每个 Heartbeat 节点设定一个超时值，当超时发生时采取相应动作。 示例读取心跳时间设置 40 17 10 00 00 00 00 00 通过配置 0x1017 的 heartbeat 时间，自动上报设备状态。 2B 17 10 00 E8 03 00 00 Master 节点发送远程帧（无数据）NMT-Master -&gt; NMT-Slave COB-ID &#x3D; 0x700 + Node_ID NMT-Slave 节点发送如下报文应答 NMT-Master &lt;- NMT-Slave COB-ID &#x3D; 0x700 + Node_ID Byte0 &#x3D; Bit 7-0 : 状态 LSSLSS（Layer Setting Services）是一个用于配置和管理 CANopen 设备的一种服务。它提供了一些特定的功能，主要用于设备的初始化和配置，例如设置节点 ID 和波特率。LSS 对于在生产、调试和运行过程中配置 CANopen 设备非常有用。 LSS 的主要功能 设置节点 ID： 在 CANopen 网络中，每个节点都有一个唯一的节点 ID，范围为 1 到 127。LSS 允许动态设置或修改节点 ID，而不需要物理访问设备。这在设备初始安装和替换时特别有用。 设置波特率： CANopen 网络中的所有节点必须使用相同的波特率进行通信。LSS 允许动态修改设备的波特率，以便在不同的网络条件下进行适应和优化。 设备识别： LSS 可以用于识别网络中的设备。通过 LSS 服务，可以查询设备的唯一标识符（例如制造商代码、产品代码、序列号等），从而实现设备的识别和管理。 LSS 服务的主要操作 Switch Mode Global： 切换所有节点到配置模式或操作模式。 Switch Mode Selective： 选择性地切换特定节点到配置模式或操作模式。 Configure Node-ID： 设置节点 ID。 Configure Bit Timing Parameters： 设置 CAN 总线的波特率参数。 Identify Remote Slave： 识别网络中的设备，读取其唯一标识符。 LSS 协议的示例假设我们需要将一个设备的节点 ID 设置为 0x02，并将波特率设置为 250 kbps。以下是使用 LSS 的步骤： 切换到配置模式： 发送 LSS Switch Mode Selective 命令，将目标设备切换到配置模式。 设置节点 ID： 使用 LSS Configure Node-ID 命令，设置设备的节点 ID。 设置波特率： 使用 LSS Configure Bit Timing Parameters 命令，设置设备的波特率。 切换到操作模式： 发送 LSS Switch Mode Global 命令，将所有设备切换到操作模式。 LSS 消息格式LSS 消息使用特定的 CAN 标识符和数据格式。以下是 LSS Switch Mode Selective 命令的示例： CAN ID：0x7E5（LSS 主站到从站） 数据：0x04 0x00 0x00 0x00 0x00 0x00 0x00 0x00（切换到配置模式） 设置节点 ID 的命令： CAN ID：0x7E5 数据：0x11 0x02 0x00 0x00 0x00 0x00 0x00 0x00（设置节点 ID 为 0x02） 设置波特率的命令： CAN ID：0x7E5 数据：0x13 0x03 0x00 0x00 0x00 0x00 0x00 0x00（设置波特率为 250 kbps，假设 0x03 表示 250 kbps）","categories":["2.通讯协议","CAN"]},{"title":"USB权限设置","path":"/2024/05/20/2-通讯协议-USB-USB权限设置/","content":"因 Linux 系统下将涉及到 usb 底层驱动的调用，运行时，一定要加 sudo 获取权限运行，否则 USB 设备没有权限操作。 现通过创建 UDEV 规则，配置 USB 权限后，可以调用指定设备不加权限运行。 输入 lsusb，查看当前的 USB 设备的 ID，确定需要配置的 USB。 创建一个新的 udev 规则。名称取为：99-myusb.rules sudo vi /etc/udev/rules.d/99-myusb.rules 在 99-myusb.rules 文件中，输入以下内容 12##ACTION==&quot;add&quot;,SUBSYSTEMS==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;04d8&quot;, ATTRS&#123;idProduct&#125;==&quot;0053&quot;, GROUP=&quot;users&quot;, MODE=&quot;0777&quot; 这条 udev 规则的作用是，当供应商 ID 为 04d8 且产品 ID 为 0053 的 USB 设备插入系统时，将该设备的用户组设置为 users，并赋予所有用户读、写、执行的全部权限。 插拔一下 USBCAN 设备或重启一下电脑后，即可不加 sudo 权限运行程序了 对某个特定 USB 设备设置权限。每当这个设备插入系统时，规则会自动应用。 ACTION==&quot;add&quot;：这表示规则在设备添加（插入）时生效。udev 可以根据不同的动作（如添加、移除等）触发规则，add 动作指设备插入时。 SUBSYSTEMS==&quot;usb&quot;：表示规则适用于 USB 子系统的设备。udev 管理系统中的设备，子系统用于分类，USB 是其中一种。 ATTRS&#123;idVendor&#125;==&quot;04d8&quot;：表示设备的供应商 ID（Vendor ID）为 04d8。每个 USB 设备都有唯一的供应商 ID，用于标识设备的制造商。 ATTRS&#123;idProduct&#125;==&quot;0053&quot;：表示设备的产品 ID（Product ID）为 0053。每个供应商的不同产品有不同的产品 ID，用于区分供应商的各个设备。 GROUP=&quot;users&quot;：表示设备的用户组被设置为 users。这决定了哪些用户组的成员有权访问该设备。 MODE=&quot;0777&quot;：表示设备的权限模式被设置为 0777，即所有用户对该设备都有读、写、执行权限。","categories":["2.通讯协议","USB"]},{"title":"Socket套接字","path":"/2024/05/20/2-通讯协议-网络-Socket套接字/","content":"Socket 最初是作为网络上不同主机之间进程的通信接口，后来应用越来越广，在同一主机上的不同进程之间通信也可以用 Socket。 简单来说，当网络上不同主机之间的两个进程（A、B）采用 Socket 进行通信时，那么它们之间需要建立一个通信端点，即创建 Socket，创建 Socket 时就分配端口号和网络地址。当进程 A 向进程 B 发送数据时，那么进程 A 必须要知道进程 B 的网络地址及端口号。 Socket 采用 C&#x2F;S 模型进行设计的，即 Client&#x2F;Server，面向客户端—服务器模型。 每一个 Socket 都用一个半相关描述： {协议，本地地址，本地端口} 一个完整的 Socket 则用一个相关描述: {协议，本地地址，本地端口，远程地址，远程端口} 类型字节流套接字（SOCK_STREAM）字节流的套接字可以提供可靠的数据传输、面向连接的通讯流。数据按何种顺序发送，就按何种顺序接收。例如，当我们按顺序发送 A-B-C，那么在数据到达接收端时，它的顺序也是 A-B-C。字节流套接字采用的是 TCP（Transmission Control Protocol）协议。保证了数据传输的可靠性。 数据报套接字（SOCK_DGRAM）数据报套接字定义了一种无连接的服务。所谓无连接服务，简单来说，即在发送数据时，无需在收发两端建立类似 TCP 那样的握手连接，在发送时，将数据打包，然后加上远程 IP 地址，即可把该数据包发送出去。 数据通过相互独立的报文进行传输。并且是无序的、不可靠的传输。 原始套接字（SOCK_ROW）先启动服务器，通过调用 socket() 函数建立一个套接字，然后调用 bind() 函数将该套接字和本地网络地址联系在一起，再调用 listen() 函数使套接字做好侦听的准备，并规定它的请求队列的长度，之后就调用 accept() 函数来接收连接。 客户端在建立套接字之后就可调用 connect() 和服务器建立连接。 连接一旦建立，客户端和服务器之间就可以通过调用 recv()&#x2F;recvfrom() 函数和 send()&#x2F;sendto 函数来进行发收数据。 最后，待数据传送结束后，双方调用 close() 函数关闭套接字。","categories":["2.通讯协议","网络"]},{"title":"ollama部署","path":"/2024/05/18/3-软件-AI-ollama部署/","content":"ollama 部署在云端服务器并通过微信服务调用使用 云服务管理软件：开源的 1panel 创建 1panel 文件夹，进入后，执行以下命令安装： 1234#先安装dockersudo apt install docker.iocurl -sSL https://resource.fit2cloud.com/1panel/package/quick_start.sh -o quick_start.sh &amp;&amp; sudo bash quick_start.sh 输入安全入口，之后登陆时需要安装 IP 地址 + 端口号 + 安全入口的形式进入管理页面 124.224.246:9090&#x2F;liuluhua 输入登录用户名和密码 liuluhua-passwd 之后已完成 1panel 部署，可以方便的进行软件的管理 安装ollama 安装在 Linux 服务器上 1curl -fsSL https://ollama.com/install.sh | sh 方式一：安装完成后转到 ollama笔记 进行配置相应的模型 方式二：1panel 按钻过 ollama 软件 之后配置微信公众号和微信用户进行对接 ollama 模型 登录微信公众号后台，选择 设置与开发-&gt;基本配置-&gt;服务器配置 填入服务器的 IP+ 接口 (该选项之后在服务器端的 Nginx 中进行配置) Token：用于验证接入 密钥随机生成即可，加解密方式可以选择明文 之后登录服务器 方式一：通过 apt 安装，配置文件配置，sudo apt install nginx 方式二：进入 1panel 中安装 nginx-proxy-manager，通过软件管理 网心云部署在云服务器","categories":["3.软件","AI"]},{"title":"CAN学习笔记","path":"/2024/05/17/2-通讯协议-CAN-CAN学习笔记/","content":"概述介绍CAN 总线是一种串行通信协议，使用的是两条差分信号线，只能表达一个信号。 简洁的物理层决定了 CAN 必然要配上一套复杂的协议。 根据不同的距离、不同的网络，可配置不同的速度，最高速度为 1MBit&#x2F;s。 CAN 2.0A 为标准格式，CAN 2.0B 为扩展格式。 优点： 可以多主方式工作，网络上的任意节点均可以在任意时刻主动地向网络上的其他节点发送信息，而不分主从，通信方式灵活。 网络上的节点 (信息) 可分成不同的优先级，可以满足不同的实时要求。 采用非破坏性位仲裁总线结构机制，当两个节点同时向网络上传送信息时，优先级低的节点主动停止数据发送，而优先级高的节点可不受影响地继续传输数据。 工作原理当 CAN 总线上的节点发送数据时，以报文形式广播给网络中的所有节点，总线上的所有节点都不使用节点地址等系统配置信息，只根据每组报文开头的 11 位标识符 (CAN 2.0A 规范) 解释数据的含义来决定是否接收。这种数据收发方式称为面向内容的编址方案。 当某个节点要向其他节点发送数据时，这个节点的处理器将要发送的数据和自己的标识符传送给该节点的 CAN 总线接口控制器，并处于准备状态；当收到总线分配时，转为发送报文状态。数据根据协议组织成一定的报文格式后发出，此时网络上的其他节点处于接收状态。处于接收状态的每个节点对接收到的报文进行检 测，判断这些报文是否是发给自己的以确定是否接收。 层次结构CAN 被细分为三个层次： （1）CAN 对象层（the object layer）； （2）CAN 传输层（the transfer layer）； （3）CAN 物理层（the phyical layer）； 对象层和传输层包括所有由 ISO&#x2F;OSI 模型定义的数据链路层的服务和功能。 对象层的作用范围包括： （1）查找被发送的报文。 （2）确定由实际要使用的传输层接收哪一个报文。 （3）为应用层相关硬件提供接口。 传输层的作用主要： （1）传送规则，也就是控制帧结构、执行仲裁、错误检测、出错标定、故障界定。 （2）总线上什么时候开始发送新报文及什么时候开始接收报文，均在传输层里确定。 （3）位定时的一些普通功能也可以看作是传输层的一部分。 （4）传输层的修改是受到限制的。 物理层的作用： 在不同节点之间根据所有的电气属性进行位信息的实际传输。当然，同一网络内，物理层对于所有的节点必须是相同的。 编程在对象层进行，这一层直接与应用层交互，并且提供了管理和处理 CAN 消息的接口。通过对象层，应用程序可以发送和接收 CAN 的打包消息。打包的过程就是在原始数据的基础上再加上帧起始段、仲裁段、控制段、CRC 校验、应答和帧结束，把这些内容按特定的格式打包好，就可以用一个通道表达各种信号了，当数据包被发送时，只要接收方按约定格式去解读，就能还原出原始数据。 传输层的功能主要由 CAN 控制器硬件和驱动程序实现。通常，程序员不直接操作传输层，而是通过对象层的 API 间接利用传输层的功能。 传输层负责处理 CAN 协议的低级细节，如位级传输、错误处理和仲裁。 位填充（BitStuffing） 位填充是为了防止突发错误而设定的功能。位填充的规则如下： （1）5 位连续相同电平之后，必须填充一位反向位，即不允许有 6 个连续相同位； （2）SOF 之前为总线空闲状态，不需要同步，因此不需要位填充； （3）CRC 之后为固定格式，不允许填充； （4）由 CAN 控制器自动实现； 物理层通常由 CAN 收发器硬件和相关电气接口组成。 CAN 属性CAN 具有以下的属性： （1）报文（Messages）：CAN 协议对数据、操作命令 (如读&#x2F;写) 以及同步信号进行打包，打包后的这些内容称为报文，简单来说就是具有固定格式的数据包。 （2）信息路由（Information Routing）：即，报文寻找结点的方式。 （3）位速率（Bit rate）：数据位的传输速度。 （4）优先权（Priorities）：即报文发送的优先权。 （5）远程数据请求（Remote Data Request）：通过发送远程帧，需要数据的节点可以请求另一节点发送相应的数据帧。 （6）多主机（Multimaster）：总线空闲时，任何结点都可以开始传送报文。 （7）仲裁（Arbitration）：当 2 个及以上的单元同时开始传送报文，那么就会有总线访问冲突。仲裁是确定哪个单元的具有发送优先权。 （8）安全性（Safety）：CAN 的每一个节点均采取了强有力的措施以进行错误检测、错误标定及错误自检。 （9）错误检测（Error Detection）：包括监视、循环冗余检查、位填充、报文格式检查。 （10）错误检测的执行（Performance of Error Detection） （11）错误标定和恢复时间（Error Sinalling and Recovery Time）：任何检测到错误的结点会标志出已损坏的报文。此报文会失效并将自动地开始重新传送。如果不再出现新的错误，从检测到错误到下一报文的传送开始为止，恢复时间最多为 29 个位的时间。 （12）故障界定（Fault Confinement）：CAN 结点能够把永久故障和短暂扰动区分开来。永久故障的结点会被关闭。 （13）连接（Connections）：CAN 串行通讯链路是可以连接许多结点的总线。理论上，可连接无数多的结点。但由于实际上受延迟时间或者总线线路上电气负载的影响，连接结点的数量是有限的。 （14）单通道（Single Channel）：总线是由单一进行双向位信号传送的通道组成。 （15）总线值（Bus value）：总线可以具有两种互补的逻辑值之一：“显性”（可表示为逻辑 0）或“隐性”（可表示为逻辑 1）。 （16）应答（Acknowledgment）：所有的接收器检查报文的连贯性。对于连贯的报文，接收器应答；对于不连贯的报文，接收器作出标志。 （17） 睡眠模式／唤醒（Sleep Mode &#x2F; Wake-up）：为了减少系统电源的功率消耗，可以将 CAN 器件设为睡眠模式以便停止内部活动及断开与总线驱动器的连接。CAN 器件可由总线激活，或系统内部状态而被唤醒。 仲裁方式在总线空闲态，最先开始发送消息的单元获得发送权。多个单元同时开始发送时，各发送单元从仲裁段的第一位开始进行仲裁。连续输出显性电平最多的单元可继续发送。即逐位地对比 各个结点发出的报文 ID。 由于线与的关系，显示位“0”可以覆盖隐性位“1”，因此 ID 最小的节点赢得仲裁，总线上表现为该结点的报文，其他结点失去仲裁，退出发送，转为接收状态。 标准格式 ID 与具有相同 ID 的远程帧或者扩展格式的数据帧在总线上竞争时，标准格式的 RTR 位为显性位的具有优先权，可继续发送。 位时序由发送单元在非同步的情况下发送的每秒钟的位数称为位速率。一个位可分为 4 段。 同步段（SS） 传播时间段（PTS） 相位缓冲段 1（PBS1） 相位缓冲段 2（PBS2） 这些段又由可称为 Time Quantum（以下称为 Tq）的最小时间单位构成。 1 位分为 4 个段，每个段又由若干个 Tq 构成，这称为位时序。 1 位由多少个 Tq 构成、每个段又由多少个 Tq 构成等，可以任意设定位时序。通过设定位时序，多个单元可 同时采样，也可任意设定采样点。 Linux 下设置位时序的方式 ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1 同步段（Sync Segment）: 固定为 1 TQ，用于同步位定时器。 传播时间段（Propagation Segment, prop-seg）: 用于补偿信号在总线上传播的时间延迟。 相位缓冲段 1（Phase Buffer Segment 1, phase-seg1）: 用于提高抗干扰能力，允许时间调整。 相位缓冲段 2（Phase Buffer Segment 2, phase-seg2）: 也用于提高抗干扰能力，允许时间调整。 *ip link set can0 type can: 设置名为 can0 的网络接口的类型为 CAN。tq 125: 设置时间量化（Time Quantum，TQ）为 125 ns。TQ 是 CAN 控制器内部的基本时间单位，用于划分整个位时间。prop-seg 6: 设置传播时间段（Propagation Segment）为 6 TQ。传播时间段用于补偿信号在 CAN 总线上传播的延迟。phase-seg1 7: 设置相位缓冲段 1（Phase Buffer Segment 1）为 7 TQ。这个时间段用于调整边沿相位，通常包括采样点之前的时间。phase-seg2 2: 设置相位缓冲段 2（Phase Buffer Segment 2）为 2 TQ。这个时间段用于调整边沿相位，通常包括采样点之后的时间。sjw 1: 设置同步跳跃宽度（Synchronization Jump Width，SJW）为 1 TQ。SJW 用于重新同步时可以跳跃的最大时间量。 具体计算tq 125: 时间量化为 125 ns。prop-seg 6: 传播时间段为 6 个时间量化，6 * 125 ns &#x3D; 750 ns。phase-seg1 7: 相位缓冲段 1 为 7 个时间量化，7 * 125 ns &#x3D; 875 ns。phase-seg2 2: 相位缓冲段 2 为 2 个时间量化，2 * 125 ns &#x3D; 250 ns。sjw 1: 同步跳跃宽度为 1 个时间量化，1 * 125 ns &#x3D; 125 ns。计算位时间总位时间是所有段的时间总和：Sync Segment: 1 TQPropagation Segment: 6 TQPhase Buffer Segment 1: 7 TQPhase Buffer Segment 2: 2 TQ总时间量化数 &#x3D; 1 + 6 + 7 + 2 &#x3D; 16 TQ总位时间 &#x3D; 16 * 125 ns &#x3D; 2000 ns &#x3D; 2 μs位速率（Bit Rate） &#x3D; 1 &#x2F; 总位时间 &#x3D; 1 &#x2F; 2 μs &#x3D; 500 kbps 数据帧帧类型为了更有效地控制通讯，CAN 一共规定了 5 种类型的帧 数据帧：发送单元向接收单元传送数据的帧。 远程帧：接收单元向发送单元请求数据的帧。 错误帧：检测出错误时向其它单元通知错误的帧。 过载帧：接收单元通知其尚未就绪的帧。 间隔帧：将数据帧及遥控帧与前面的帧分离开来的帧。 数据帧和遥控帧有标准帧和扩展帧两种帧，标准帧有 11 个位的标识符 ID，扩展帧有 29 个位的 ID 标准 CAN 帧定义数据帧由帧起始、仲裁段、控制段、数据段、CRC、ACK、帧结束共 7 个段构成 隐形=1 显性=0 帧起始 (Start Of Frame,SOF)，1bit 表示帧开始的段，设置为 0。 仲裁段（Identifier，ID），11bits&#x2F;29bits 表示数据帧优先级的段标准帧与扩展帧的构成有所不同，均禁止高 7 位为隐性 (ID&#x3D;1111111XXXX…) 仲裁段的内容主要为本数据帧的 ID，标准帧的 ID 有 11 个位，扩展帧的 ID 有 29 个位，在 CAN 协议中，ID 决定着数据帧发送的优先级，也决定着其它节点是否会接收这个数据帧。CAN 总线不对挂载在它之上的节点分配优先级和地址，对总线的占有权是由信息的 ID 决定的，即对于重要的信息，优先级高的 ID，能够优先发送出去 RTR 位 (Remote Transmission Request Bit)远程传输请求位，用于区分数据帧和遥控帧的，为 0 表示数据帧，1 表示遥控帧。 控制段 控制段由 6 个位构成，表示数据段的字节数 IDE 位 (Identifier Extension Bit)标识符扩展位，用于区分标准帧与扩展帧，为 0 表示标准帧，1 表示扩展帧 SRR 位 (Substitute Remote Request Bit)只存在于扩展帧，它用于替代标准帧中的 RTR 位，扩展帧中的 SRR 位固定为 1，RTR 在数据帧中为 0，所以两个 ID 相同的标准帧与扩展帧，标准帧的优先级较高 DLC 数据长度码（Data Length Code）数据的字节数必须为 0～8 字节 数据段（Data Field） 数据段可包含 0～8 个字节的数据 CRC 段 CRC 段是检查帧传输错误的段，由 15 个位的 CRC 值和 1 个位的 CRC 界定符 (隐性分隔位) 构成 CRC 是根据多项式生成的 CRC 值，CRC 的计算范围包括帧起始、仲裁段、控制段、数据段 接收方以同样的方式计算 CRC 值并进行比较，不一致时利用错误帧请求重新发送 ACK 段 ACK 段包括 ACK 槽位、ACK 界定符位 2 个位 发送单元的 ACK 段：发送单元在 ACK 段发送 2 个位的隐性位接收单元的 ACK 段：接收到正确消息的单元在 ACK 槽发送显性位，通知发送单元正常接收结束，这称作“发送 ACK”或者“返回 ACK” 帧结束 (End Of Frame，EOF) 帧结束是表示该帧结束的段，由发送节点发送 7 个位的隐性位构成 *CAN 数据帧的结束符长度并不是完全不定的，而是根据数据位速率（Data Bit Rate，DBR）而定。CAN 总线协议规定，对于数据位速率低于等于 125kbps 的网络，CAN 数据帧的结束符长度为 7 个位；对于数据位速率大于 125kbps 的网络，CAN 数据帧的结束符长度为 3 个位。这是因为在高速网络中，由于数据传输速率更快，所以 CAN 控制器可以更快地检测到结束位，因此可以减少结束符的长度，从而提高网络的传输效率。而在低速网络中，由于数据传输速率较慢，所以 CAN 控制器需要更长的时间来检测结束位，因此需要一个更长的结束符来确保数据帧传输的正确性和完整性。因此，CAN 数据帧的结束符长度是根据数据位速率而定的，并不是完全不定的。 Linux 下的 Socket CAN 帧定义 帧头，canid_t 定义了一个无符号的 32 位整形数，按位确定功能 0-28 位为标识符，如果是扩展帧，则高 11 位为标准 ID 29 位标识是数据帧还是错误消息 30 位说明是否是远程帧 31 位说明是标准帧还是扩展帧。 帧长，8 位无符号表示数据区长度 数据区，定义 CAN_MAX_DLEN 个 8 位无符号数，按照数组的形式申请*__attribute__((aligned(8))) 告诉编译器，将变量 data 放在一个地址是 8 的倍数的内存位置上。 1234567891011121314151617181920/* CAN payload length and DLC definitions according to ISO 11898-1 */#define CAN_MAX_DLC 8#define CAN_MAX_DLEN 8struct can_frame &#123; canid_t can_id; /* 32 bit CAN_ID + EFF/RTR/ERR flags */ __u8 can_dlc; /* frame payload length in byte */ __u8 data[CAN_MAX_DLEN] __attribute__((aligned(8)));&#125;;/** Controller Area Network Identifier structure** bit 0-28 : CAN identifier (11/29 bit)* bit 29 : error message frame flag (0 = data frame, 1 = error message)* bit 30 : remote transmission request flag (1 = rtr frame)* bit 31 : frame format flag (0 = standard 11 bit, 1 = extended 29 bit)*/typedef __u32 canid_t;typedef unsigned char __u8; Linux 处理 can_frame 时用到的掩码和标识符： 123456789/* special address description flags for the CAN_ID */#define CAN_EFF_FLAG 0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG 0x40000000U /* remote transmission request */#define CAN_ERR_FLAG 0x20000000U /* error message frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK 0x000007FFU /* standard frame format (SFF) */#define CAN_EFF_MASK 0x1FFFFFFFU /* extended frame format (EFF) */#define CAN_ERR_MASK 0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 实际对 can_frame 的处理是在 mcp251x_hw_tx&#x2F;mcp251x_hw_rx_frame 中进行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static void mcp251x_hw_tx(struct spi_device *spi, struct can_frame *frame,int tx_buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);u32 sid, eid, exide, rtr;u8 buf[SPI_TRANSFER_BUF_LEN];//取can_id的31位，判断是标准帧还是扩展帧exide = (frame-&gt;can_id &amp; CAN_EFF_FLAG) ? 1 : 0; if (exide)//如果是扩展帧，can_id的0-28位为ID，其中高11位为标准IDsid = (frame-&gt;can_id &amp; CAN_EFF_MASK) &gt;&gt; 18;elsesid = frame-&gt;can_id &amp; CAN_SFF_MASK; /* Standard ID */eid = frame-&gt;can_id &amp; CAN_EFF_MASK; /* Extended ID */rtr = (frame-&gt;can_id &amp; CAN_RTR_FLAG) ? 1 : 0; /* 是否是远程帧*/buf[TXBCTRL_OFF] = INSTRUCTION_LOAD_TXB(tx_buf_idx); //发送缓冲器控制寄存器地址buf[TXBSIDH_OFF] = sid &gt;&gt; SIDH_SHIFT; //发送缓冲器标准ID高8位//5-7位存放发送缓冲器低3位,3位存放帧格式，0-1位存放扩展标识符低18位的高两位（16-17）buf[TXBSIDL_OFF] = ((sid &amp; SIDL_SID_MASK) &lt;&lt; SIDL_SID_SHIFT) | (exide &lt;&lt;SIDL_EXIDE_SHIFT) | ((eid &gt;&gt; SIDL_EID_SHIFT) &amp; SIDL_EID_MASK);buf[TXBEID8_OFF] = GET_BYTE(eid, 1); //存放扩展标识符低18位的8-15位buf[TXBEID0_OFF] = GET_BYTE(eid, 0); //扩展标识符低18位的低8位（0-7）buf[TXBDLC_OFF] = (rtr &lt;&lt; DLC_RTR_SHIFT) | frame-&gt;can_dlc; //6位存放远程帧标识符，0-3存放数据长度码memcpy(buf + TXBDAT_OFF, frame-&gt;data, frame-&gt;can_dlc);//拷贝要发送的数据mcp251x_hw_tx_frame(spi, buf, frame-&gt;can_dlc, tx_buf_idx);/* use INSTRUCTION_RTS, to avoid &quot;repeated frame problem&quot; */priv-&gt;spi_tx_buf[0] = INSTRUCTION_RTS(1 &lt;&lt; tx_buf_idx);mcp251x_spi_trans(priv-&gt;spi, 1);&#125;static void mcp251x_hw_rx_frame(struct spi_device *spi, u8 *buf,int buf_idx)&#123;struct mcp251x_priv *priv = spi_get_drvdata(spi);if (mcp251x_is_2510(spi)) &#123;int i, len;for (i = 1; i &lt; RXBDAT_OFF; i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);\tlen = get_can_dlc(buf[RXBDLC_OFF] &amp; RXBDLC_LEN_MASK);\tfor (; i &lt; (RXBDAT_OFF + len); i++)\tbuf[i] = mcp251x_read_reg(spi, RXBCTRL(buf_idx) + i);&#125; else &#123;\tpriv-&gt;spi_tx_buf[RXBCTRL_OFF] = INSTRUCTION_READ_RXB(buf_idx);\tmcp251x_spi_trans(spi, SPI_TRANSFER_BUF_LEN);\tmemcpy(buf, priv-&gt;spi_rx_buf, SPI_TRANSFER_BUF_LEN);&#125;&#125; Linux CAN 功能分析一个标准的 CAN 功能包括： CAN 接口号指定 CAN 接口号 can0 指定 CAN 通讯波特率，单位 Kbps，默认为 500 Kbps 指定 CAN 发送帧 ID 指定 CAN 发送帧数据 需要包含数据的大小端模式转换 指定 CAN 帧发送间隔，单位 ms， 默认为 250ms, 最小值为 1ms 指定 CAN 帧发送次数 指定 CAN 发送帧为标准帧&#x2F;扩展帧 发送数据时错误判断，本地环回功能基于 LINUX SOCKET 机制实现的 CAN 接口，其基本的流程如下所示： 设置套接字 socket 指定 CAN 设备 ioctl 绑定套接字与设备 bind 设置过滤规则 setsockopt 发送&#x2F;接受报文 read/write 关闭套接字 close以下介绍各部分如何实现。 Linux 应用层 SocketCAN 实例初始化SocketCAN 中大部分的数据结构和函数在头文件 linux&#x2F;can.h 中进行了定义。 CAN 总线套接字的创建采用标准的网络套接字操作来完成。网络套接字在头文件 sys&#x2F;socket.h 中定义。 套接字的初始化方法如下： 123456789int s;struct sockaddr_can addr;struct ifreq ifr;s = socket(PF_CAN, SOCK_RAW, CAN_RAW);//创建SocketCAN 套接字strcpy(ifr.ifr_name, &quot;can0&quot;);ioctl(s, SIOCGIFINDEX, &amp;ifr);//指定 can0 设备addr.can_family = AF_CAN;addr.can_ifindex = ifr.ifr_ifindex;bind(s, (structsockaddr *)&amp;addr,sizeof(addr)); //将套接字与 can0 绑定 参数配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;linux/can.h&gt;#include &lt;linux/can/raw.h&gt;#include &lt;linux/can/error.h&gt;#include &lt;linux/can/netlink.h&gt;#include &lt;linux/sockios.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/socket.h&gt;#include &lt;net/if.h&gt;#define CAN_INTERFACE &quot;can0&quot;#define BITRATE 500000#define DBITRATE 4000000int set_bitrate(const char *ifname, int bitrate, int dbitrate) &#123; struct ifreq ifr; struct can_bittiming bt; struct can_bittiming dbt; // Open socket int s = socket(PF_INET, SOCK_DGRAM, 0); if (s &lt; 0) &#123; perror(&quot;socket&quot;); return -1; &#125; // Specify the interface name strncpy(ifr.ifr_name, ifname, IFNAMSIZ); // Bring the interface down if (ioctl(s, SIOCGIFFLAGS, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCGIFFLAGS&quot;); close(s); return -1; &#125; ifr.ifr_flags &amp;= ~IFF_UP; if (ioctl(s, SIOCSIFFLAGS, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCSIFFLAGS&quot;); close(s); return -1; &#125; // Set bitrate for classical CAN memset(&amp;bt, 0, sizeof(bt)); bt.bitrate = bitrate; ifr.ifr_data = (void *)&amp;bt; if (ioctl(s, SIOCSCANBT, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCSCANBT&quot;); close(s); return -1; &#125; // Set data bitrate for CAN FD memset(&amp;dbt, 0, sizeof(dbt)); dbt.bitrate = dbitrate; ifr.ifr_data = (void *)&amp;dbt; if (ioctl(s, SIOCSCANDBT, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCSCANDBT&quot;); close(s); return -1; &#125; // Bring the interface up if (ioctl(s, SIOCGIFFLAGS, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCGIFFLAGS&quot;); close(s); return -1; &#125; ifr.ifr_flags |= IFF_UP; if (ioctl(s, SIOCSIFFLAGS, &amp;ifr) &lt; 0) &#123; perror(&quot;SIOCSIFFLAGS&quot;); close(s); return -1; &#125; // Close socket close(s); return 0;&#125;int main() &#123; const char *ifname = CAN_INTERFACE; int bitrate = BITRATE; int dbitrate = DBITRATE; if (set_bitrate(ifname, bitrate, dbitrate) &lt; 0) &#123; fprintf(stderr, &quot;Failed to set CAN interface settings &quot;); return 1; &#125; printf(&quot;CAN interface %s configured with bitrate %d and dbitrate %d &quot;, ifname, bitrate, dbitrate); return 0;&#125; 参数查看12ip -details -statistics link show can0 canconfig can0 数据发送在数据收发的内容方面， CAN 总线与标准套接字通信稍有不同，每一次通信都采用 can_ frame 结构体将数据封装成帧。 结构体定义如下： 12345structcan_frame &#123;\tcanid_t can_id; //CAN 标识符\t__u8 can_dlc; //数据场的长度\t__u8 data[8]; //数据&#125;; can_id 为帧的标识符， 如果发出的是标准帧， 就使用 can_id 的低 11 位； 如果为扩展帧， 就使用 0～ 28 位。 can_id 的第 29、 30、 31 位是帧的标志位，用来定义帧的类型，定义如下： 123456789/* special address description flags for the CAN_ID */#define CAN_EFF_FLAG\t0x80000000U /* EFF/SFF is set in the MSB */#define CAN_RTR_FLAG\t0x40000000U /* 远程帧 */#define CAN_ERR_FLAG\t0x20000000U /* error frame *//* valid bits in CAN ID for frame formats */#define CAN_SFF_MASK\t0x000007FFU /* 标准帧 (SFF) */#define CAN_EFF_MASK\t0x1FFFFFFFU /* 扩展帧 (EFF) */#define CAN_ERR_MASK\t0x1FFFFFFFU /* omit EFF, RTR, ERR flags */ 数据发送使用 write 函数来实现。 如果发送的数据帧 (标识符为 0x123) 包含单个字节 (0xAB) 的数据，可采用如下方法进行发送： 123456789101112131415161718192021222324struct sockaddr_can addr;struct can_frame frame;struct ifreq ifr;//如果为扩展帧，那么frame.can_id = CAN_EFF_FLAG | 0x123;frame.can_id = 0x123;frame.can_dlc = 1; //数据长度为 1frame.data[0] = 0xAB; //数据内容为 0xABint nbytes = write(s, &amp;frame, sizeof(frame));//发送数据nbytes = send(s, &amp;frame, sizeof(frame), 0);nbytes = sendto(s, &amp;frame, sizeof(frame), 0, (struct sockaddr *)&amp;addr, sizeof(addr));//sendmsg struct msghdr msg;struct iovec iov;memset(&amp;msg, 0, sizeof(msg));msg.msg_name = &amp;addr;msg.msg_namelen = sizeof(addr);iov.iov_base = &amp;frame;iov.iov_len = sizeof(frame);msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;nbytes = sendmsg(s, &amp;msg, 0); 如果要发送远程帧 (标识符为 0x123)，可采用如下方法进行发送： 123struct can_frame frame;frame.can_id = CAN_RTR_FLAG | 0x123;write(s, &amp;frame, sizeof(frame)); 数据接收数据接收使用 read 函数来完成，实现如下： 12345678910111213141516struct can_frame frame;int nbytes = read(s, &amp;frame, sizeof(frame));nbytes = recv(s, &amp;frame, sizeof(frame), /*0*/MSG_DONTWAIT);nbytes = recvfrom(s, &amp;frame, sizeof(frame), 0, (struct sockaddr *)&amp;addr, sizeof(addr));struct msghdr msg;struct iovec iov;memset(&amp;msg, 0, sizeof(msg));memset(&amp;iov, 0, sizeof(iov));iov.iov_base = &amp;frame;iov.iov_len = sizeof(frame);msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;nbytes = recvmsg(s, &amp;msg, 0); 错误处理当帧接收后，可以通过判断 can_id 中的 CAN_ERR_FLAG 位来判断接收的帧是否为错误帧。 如果为错误帧，可以通过 can_id 的其他符号位来判断错误的具体原因。 错误帧的符号位在头文件 linux/can/error.h 中定义。 过滤规则设置在数据接收时，系统可以根据预先设置的过滤规则，实现对报文的过滤。过滤规则使用 can_filter 结构体来实现，定义如下： 1234struct can_filter &#123;\tcanid_t can_id;\tcanid_t can_mask;&#125;; 过滤器工作原理：CAN 过滤器使用按位与（&amp;）操作来决定是否接收一个帧。 1234if ((received_can_id &amp; filter.mask) == (filter.can_id &amp; filter.mask)) // 接收此帧else // 丢弃此帧 通过这条规则可以在系统中过滤掉所有不符合规则的报文，使得应用程序不需要对无关的报文进行处理。在 can_filter 结构的 can_id 中，符号位 CAN_INV_FILTER 在置位时可以实现 can_id 在执行过滤前的位反转。 用户可以为每个打开的套接字设置多条独立的过滤规则，使用方法如下： 12345678structcan_filter rfilter[2];rfilter[0].can_id = 0x123;rfilter[0].can_mask = CAN_SFF_MASK;//#define CAN_SFF_MASK 0x000007FFUrfilter[1].can_id = 0x200;rfilter[1].can_mask = 0x700;//设置规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER,&amp;rfilter, sizeof(rfilter)); 第一个过滤器 (rfilter): 123can_id: 0x123mask: 0x7FF (CAN_SFF_MASK)这个过滤器将只接收 ID 为 0x123 的标准帧。因为掩码是 0x7FF，所以 ID 必须完全匹配。 第二个过滤器 (rfilter): 12can_id: 0x200mask: 0x700 这个过滤器将接收 ID 范围从 0x200 到 0x2FF 的帧。因为： 10x200 &amp; 0x700 = 0x200 任何 0x2XX 的 ID 与 0x700 进行按位与操作后都等于 0x200 过滤规则禁用。原始套接字就会忽略所有接收到的报文。在这种仅仅发送数据的应用中，可以在内核中省略接收队列，以此减少 CPU 资源的消耗。禁用方法如下： 12//禁用过滤规则setsockopt(s, SOL_CAN_RAW, CAN_RAW_FILTER, NULL, 0); 通过错误掩码可以实现对错误帧的过滤， 例如： 12can_err_mask_t err_mask = (CAN_ERR_TX_TIMEOUT | CAN_ERR_BUSOFF );setsockopt(s, SOL_CAN_RAW,CAN_RAW_ERR_FILTER,err_mask,sizeof(err_mask)); 设置错误消息设置 CAN 接口的错误过滤器 123456789can_err_mask_t err_mask;err_mask = CAN_ERR_ACK | CAN_ERR_CRTL | CAN_ERR_BUSOFF | CAN_ERR_BUSERROR;ret = setsockopt(interface-&gt;fd, SOL_CAN_RAW, CAN_RAW_ERR_FILTER, &amp;err_mask, sizeof(err_mask));if(ret &lt; 0)&#123;\tlog_printf(LOG_ERR, CAN_ERROR_FILTER_FAILED, interface-&gt;ifName);\tlog_printf(LOG_DEBUG, DBG_ERRNO, &quot;setsockopt(can err)&quot;);\treturn CO_ERROR_SYSCALL;&#125; CAN_ERR_ACK, CAN_ERR_CRTL, CAN_ERR_BUSOFF, CAN_ERR_BUSERROR 是 CAN 错误的不同类型。这些标志位分别表示收到错误应答、控制器错误、总线关闭、总线错误。 SOL_CAN_RAW 表示操作的是原始 CAN 套接字。 CAN_RAW_ERR_FILTER 是设置原始 CAN 套接字的错误过滤器选项。 缓冲区大小设置1234567891011121314//todo - modify rx buffer size? first one needs rootbytes = 512*1024;sLen = sizeof(bytes);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUFFORCE, (void *)&amp;bytes, sLen);ret = setsockopt(fd, SOL_SOCKET, SO_RCVBUF, (void *)&amp;bytes, sLen);/* print socket rx buffer size in bytes (In my experience, the kernel reserves * around 450 bytes for each CAN message) */sLen = sizeof(bytes);getsockopt(interface-&gt;fd, SOL_SOCKET, SO_RCVBUF, (void *)&amp;bytes, &amp;sLen);if (sLen == sizeof(bytes)) &#123; log_printf(LOG_INFO, CAN_SOCKET_BUF_SIZE, interface-&gt;ifName, bytes / 446, bytes);&#125; 设置缓冲区大小为 512KB root 用户使用 SO_RCVBUFFORCE 设置缓冲区大小。 普通用户使用 SO_RCVBUF 设置缓冲区大小 查询当前 buff 大小 回环功能设置在默认情况下， 本地回环功能是开启的，可以使用下面的方法关闭回环&#x2F;开启功能： 12int loopback = 0; // 0 表示关闭, 1 表示开启( 默认)setsockopt(s, SOL_CAN_RAW, CAN_RAW_LOOPBACK,&amp;loopback, sizeof(loopback)); 在本地回环功能开启的情况下，所有的发送帧都会被回环到与 CAN 总线接口对应的套接字上。 默认情况下，发送 CAN 报文的套接字不想接收自己发送的报文，因此发送套接字上的回环功能是关闭的。 可以在需要的时候改变这一默认行为： 12int ro = 1; // 0 表示关闭( 默认), 1 表示开启setsockopt(s, SOL_CAN_RAW, CAN_RAW_RECV_OWN_MSGS, &amp;ro, sizeof(ro)); 套接字状态利用 ioctl() 检查套接字状态 使用 ioctl() 函数结合 FIONREAD 命令可以查询当前套接字接收缓冲区中等待读取的字节数。如果返回的字节数大于 0，则表示有数据可供接收。示例代码如下： 1234567891011int bytes_available;ioctl(sock, FIONREAD, &amp;bytes_available);if (bytes_available &gt; 0) &#123; printf(&quot;套接字中有 %d 字节的CAN数据可接收 &quot;, bytes_available); // 现在可以读取数据 // ...&#125; else &#123; printf(&quot;套接字中没有可接收的CAN数据 &quot;);&#125; ioctl() 函数和 SIOCSIFFLAGS ioctl() 函数：这是一个系统调用函数，用于在用户空间程序中向内核发出特定的控制命令，以实现对设备、接口等的配置和管理。 SIOCSIFFLAGS：这是 ioctl() 函数使用的一个常量，用于设置网络接口的标志。通过 ioctl() 和 SIOCSIFFLAGS，可以启用或禁用一个网络接口，设置接口的工作模式和其他标志位。 如何在 ARM 上实现 CAN 通讯硬件ARM 需要有 CAN 控制器和 CAN 收发器 CAN 控制器（CAN Controller）是负责实现 CAN 协议的逻辑部分的组件 CAN 收发器（CAN Transceiver）是负责 CAN 总线电平信号和 CAN 控制器之间的电信号转换的组件 CAN 控制器示例： 内置于微控制器中的 CAN 模块（例如 STM32 系列微控制器的内置 CAN 控制器）。 独立的 CAN 控制器芯片（例如 MCP2515）。CAN 收发器示例： 常见的独立 CAN 收发器芯片（例如 MCP2551、TJA1050 等）。 先选择 CAN 控制器芯片，一般的 PC 和 ARM 都没有 CAN 控制器，一般是 MCP2515 和 SJA1000，主要区别是 MCP2515 是 SPI 接口，SJA1000 是 I&#x2F;O 接口。所以 MCP2515 占用资源少，5-6 个管脚就可以控制，SJA1000 占用的管脚就多。 软件需要支持 CAN 控制器驱动，控制 CAN 控制器发送 CAN 帧。对于一般的 CAN 控制器，进行初始化时，最关键的是以下两步： 配置 CAN 的位时序； 配置 CAN 的消息报文； Can 软件设计时增加单例模式设计，增加线程方式接受数据，接收后数据进入缓冲区，调用函数获取缓冲区所有数据。 内核Linux 中有对 CAN（Controller Area Network）总线的支持，主要通过 SocketCAN 子系统实现。内核编译时选择响应的支持芯片。 1234567891011$ make linux-menuconfigNetworking support ---&gt;\tCAN bus subsystem support ---&gt;\t--- CAN bus subsystem support Raw CAN Protocol (raw access with CAN-ID filtering) Broadcast Manager CAN Protocol (with content filtering) CAN Device Drivers ---&gt; Virtual Local CAN Interface (vcan) Platform CAN drivers with Netlink support [*] CAN bit-timing calculation Microchip 251x series SPI CAN Controller SocketCAN 支持多种 CAN 控制器硬件，通过不同的内核驱动程序实现对具体硬件的支持。例如，以下是一些常见的 CAN 控制器驱动程序： sja1000：Philips&#x2F;NXP SJA1000 CAN 控制器 mcp251x：Microchip MCP251x SPI CAN 控制器系列（如 MCP2515） flexcan：Freescale&#x2F;NXP FlexCAN 模块 这些驱动程序通常位于内核源代码树的 drivers/net/can 目录下。 CAN 数据发送跟踪当我们在用户层通过 socket 进行 CAN 数据的发送时，需要进行以下操作： 创建一个套接字 socket，采用 AF_CAN 协议。 将创建的套接字返回描述符 sockfd，绑定到本地的地址。 通过 sendto 系统调用函数进行发送，sendto 的系统调用会发送一帧数据报到指定的地址，在 CAN 协议调用之前把该地址移到内核空间和检查用户空间数据域是否可读。 在 net/socket.c 源文件中，在 sendto 的系统调用 （sys_sendto） 里，会调用到 sock_sendmsg() 函数，接下来调用 __sock_sendmsg() 函数。 再往下一步就是 __sock_sendmsg_nosec 函数。在 __sock_sendmsg_nosec() 函数中会返回一个 sendmsg 函数指针。 在 /net/can/raw.c 源文件中，将 raw_sendmsg 函数地址赋给 sendmsg 函数指针，即在函数 __sock_sendmsg_nosec() 中 return sock-&gt;ops-&gt;sendmsg(iocb,sock, msg, size)，返回的函数指针将指向 raw_sendmsg() 函数。 在 net/can/af_can.c 源文件中，can_send 函数负责 CAN 协议层的数据传输，即传输一帧 CAN 报文（可选本地回环）。参数 skb 指针指向套接字缓冲区和在数据段的 CAN 帧。loop 参数是在本地 CAN 套接字上为监听者提供回环。 以下开始进行到 CAN 的底层驱动代码了，由于 CAN 驱动是编译进内核中，所以在系统启动时会注册 CAN 驱动。 注册 CAN 驱动过程中会初始化 d_can_netdev_ops 结构体变量。 在这个过程中，d_can_netdev_ops 结构体变量定义了 3 个函数指针，其中 (*ndo_start_xmit) 函数指针指向 d_can_start_xmit 函数的入口地址。 在 d_can_start_xmit() 函数中，会调用 d_can_write_msg_object() 函数准备消息报文进行传输。 CAN 数据接收跟踪对于网络设备，数据接收大体上采用中断 +NAPI 机制进行数据的接收。同样，我们现在的 CAN 模块也是采用同样的方式进行数据的接收。由于我们只针对 CAN 总线接收数据这条主线进行分析。因些，会忽略一些针对 CAN 协议的设置及初始化等相关代码。 *NAPI（New API）是一种改进的网络数据接收机制，它通过减少中断处理的次数来提高性能。NAPI 的基本思想是延迟数据包的处理，使得多个数据包可以一次性地在中断处理程序中进行处理，从而减少了中断的数量，提高了系统的处理效率。 中断 +NAPI 机制的工作原理大致如下： 当网络数据包到达时，网络接口卡会生成一个中断通知操作系统。 中断服务程序会执行一些必要的处理，然后调用 NAPI 机制。 NAPI 机制会检查网络接口缓冲区中是否有足够的数据需要处理。 如果有足够的数据，NAPI 会立即开始处理这些数据，而不会再次触发中断。如果数据量不足，NAPI 会退出，并要求在将来的某个时候再次调用。 处理完数据后，系统可以选择性地决定是否重新启用中断服务程序。 通过将数据包的处理延迟到一组数据包到达时再进行，中断 +NAPI 机制能够大大减少中断的数量，提高系统的处理效率，特别是在高负载情况下。 在初始化 CAN 设备时，我们需要给 CAN 设备分配 NAPI 功能。我们通过 netif_napi_add() 函数将 CAN 设备添加到 NAPI 机制列表中。 将 CAN 设备添加到 NAPI 机制列表中后，在中断处理函数 d_can_isr 中，我们通过 napi_schedule() 函数调度已经在 NAPI 机制列表中的 d_can_poll() 函数。该函数会通过轮询的方式接收数据。而根据 NAPI 机制，当中断产生后，会调度轮询机制同时关闭所有的中断。 当中断产生时，会调用函数 d_can_poll()，该函数即采用轮询的方式进行数据的接收。由于 CAN 总线状态中断具有最高优先权，在接收数据之前，需要对 CAN 总线的状态进行判断。而对于 CAN 总线错误状态有三种：主动&#x2F;被动&#x2F;关闭。 当总线状态数据状态正常时，从 CAN 模块的接收寄存器中接收数据。 文件系统要在 linux 下面配置和测试 CAN，需要安装以下三个组件。 iproute2 （配置 CAN 接口时需要） libsocketcan（使用 CAN 必须） can-utils https://github.com/linux-can/can-utils (CAN 的测试小工具，linux 下测试 CAN 比较好用应用程序) 可以直接通过命令行形式控制 CAN 12345678910111213141516171819202122# 配置CAN接口（假设设备名为`can0`）：ip link set can0 up type can bitrate 500000# 启动CAN接口ip link set up can0# 查看CAN接口状态ip -details link show can0# CAN 2.0 linkupip link set can0 up type can bitrate 100000# CAN 2.0 FD linkupip link set can0 up type can bitrate 500000 dbitrate 2000000 fd on# 命令来配置 CAN 总线的位速率：ip link set can0 type cantq 125 prop-seg 6phase-seg1 7 phase-seg2 2 sjw 1# 可以使用 ip 命令直接设定位速率500kbps：ip link set can0 type can bitrate 500000# 当设置完成后，可以通过下面的命令查询 can0 设备的参数设置：ip -details link show can0# 当设置完成后，可以使用下面的命令使能 can0 设备：ifconfig can0 up# 使用下面的命令取消 can0 设备使能：ifconfig can0 down# 在设备工作中，可以使用下面的命令来查询工作状态：ip -details -statistics link show can0 Qt 中使用 SocketCAN需要编译安装 socketCAN 插件， https://doc.qt.io/qt-5/qtserialbus-socketcan-overview.html ，关键字【Using SocketCAN Plugin】 pro 文件中添加 QT += serialbus 12345QString errorString;const QList&lt;QCanBusDeviceInfo&gt; devices = QCanBus::instance()-&gt;availableDevices(\tQStringLiteral(&quot;socketcan&quot;), &amp;errorString);if (!errorString.isEmpty())\tqDebug() &lt;&lt; errorString; 在 Qt 中利用线程权限进行高速的 CAN 通信用 PC 里能达到的 CAN 通信（使用 USBCAN-II）速度是 1ms 使用 3 个线程类：1 个用来接收，1 个用来发送，1 个用来解析 接收线程使用最高线程权限：QThread::HighestPriority，其余线程用 QThread::HighPriority 如何循环发送报文：在发送线程里再多加一个定时器，timeout 时间为需要循环发送的时间（可达到 1ms）； 用户在主界面设置需要发送的报文为 OBJ 结构体数组，然后通过构造函数的方式传到发送线程，最后发送就行了。 解析过程：接收函数循环接收报文，每接收到 n 帧就发送到解析线程，然后根据 ID 解析，将解析数据发送主界面显示（不要 append） CAN 波特率及负载计算在 CAN 总线上，发送一帧数据所需的时间可以通过帧的总位数和波特率来计算。一个 CAN 数据帧的结构如下： 1234567起始位：1位仲裁字段：11位（标准帧）或29位（扩展帧）控制字段：6位数据字段：0到8字节（每字节8位）CRC字段：15位+1位CRC界定符ACK字段：2位（1位ACK位和1位ACK界定符）结束字段：7位 对于一个标准帧，假设我们发送 8 字节的数据（最大数据长度），总位数：1 + 11 + 6 + 64 + 16 + 2 + 7 &#x3D; 107 位。对于 500kbps 的波特率： 123发送时间 = 总位数 / 波特率= 107 位 / 500,000 位/秒= 214 微秒 CAN 总线负载是总线实际使用的带宽与总带宽的比值，通常表示为百分比。 1234总线负载=((总帧时间×每秒发送的帧数)/总可用时间)×100%总帧时间：一帧数据的发送时间每秒发送的帧数：一秒钟内发送的帧数总可用时间：每秒可用的时间，即 1 秒 假设每秒发送 1000 帧数据： 123456总帧时间：214 微秒 = 214 \\times 10^&#123;-6&#125;秒每秒发送的帧数：1000 帧总可用时间：1 秒总线负载=((214×10$−6$ 秒×1000 帧/秒)/1 秒)×100%总线负载=(0.214)×100%总线负载=21.4% 如果在 CAN 总线上尝试以快于设定波特率的速度发送数据，会导致通信错误和数据传输失败。具体来说: 数据丢失：发送端发出的数据无法被接收端正确接收和解析，导致数据包丢失。 通信错误：由于发送速率与接收端的预期不匹配，会触发 CAN 协议中的错误检测机制，产生通信错误。 总线冲突：过快的发送速率可能导致多个节点同时发送数据，造成总线冲突。 同步失败：接收端无法正确同步和采样数据位，导致位时序错误。 系统不稳定：持续的通信错误可能导致 CAN 控制器进入总线关闭状态，使整个网络变得不稳定。 为了确保 CAN 总线通信的可靠性和稳定性，必须严格遵守以下原则: 所有节点必须使用相同的波特率配置。 发送数据的速率不得超过设定的波特率。 根据网络长度、节点数量等因素合理选择波特率。 正确配置 CAN 控制器的位时序参数，以适应选定的波特率。 通过遵守这些原则，可以确保 CAN 总线网络中的所有节点能够正确同步和通信，从而实现可靠的数据传输。 当 CAN 总线使用 500kbps 的波特率发送数据时，如果两帧数据之间的间隔只有 100μs，可能会导致以下问题： 总线负载过高：500kbps 的波特率下，一帧 CAN 数据（假设 125 位）的传输时间约为 250μs。如果帧间隔仅为 100μs，总线负载将非常高，可能超过 80%，这会增加网络拥塞和通信错误的风险。 接收节点处理不及时：较短的帧间隔可能导致接收节点来不及处理上一帧数据就接收到下一帧，增加了数据丢失或处理错误的可能性。 中断处理困难：CAN 通信通常使用中断方式接收数据。过短的帧间隔可能导致中断频率过高，影响系统的整体性能，甚至可能造成中断处理函数重叠执行。 数据冲突增加：帧间隔过短可能导致多个节点同时尝试发送数据，增加了总线冲突的概率，从而影响通信的可靠性。 同步困难：接收节点可能难以正确同步和采样数据位，导致位时序错误，特别是在网络较长或存在电磁干扰的情况下。 过滤器失效：某些 CAN 控制器的硬件过滤器可能无法在如此短的时间内完成配置，导致部分消息无法被正确过滤。 为了避免这些问题，建议采取以下措施： 增加帧间隔：根据实际应用需求和网络负载情况，适当增加帧间隔，确保接收节点有足够时间处理数据。 优化数据传输：合理设计数据包结构，避免不必要的频繁传输。 使用 CAN FD：如果需要更高的数据吞吐量，可以考虑升级到 CAN FD 协议，它支持更大的数据包和更高的传输速率。 合理设置优先级：为不同类型的消息分配合适的优先级，确保重要数据能够及时传输。 监控总线负载：定期检查总线负载，确保其处于合理范围内，通常建议不超过 80%。 通过这些措施，可以提高 CAN 总线通信的可靠性和效率，避免因帧间隔过短而导致的各种问题。 问题记录RK3568 在高速接收 CAN 帧消息时，出现 RCU 告警 rcu INFO: rcu_sched self-detected stall on CPU，CPU 占用跑满，该问题原因是错误帧中断过多导致的系统卡顿问题。 《Rockchip RK3568&amp;RK3568B2&amp;RK3568J Application Notice-RKAN18055》中提到存在以下设计缺陷： RK3568 作为发送方，扩展帧概率性变成标准帧，导致接收方存在丢帧情况，进而影响设备的正常通讯或者控制。产生原因是在发送扩展帧时候，内部寄存器状态值在特定组合条件下，触发 load 失败，从而最后按标准帧而非扩展帧的格式来发送 ID 和 DLC 段。 RK3568 作为 接收方 概率性出现 CRC 校验错误和 ID 段填充位错误 ，导致接收方会往总线发送错误帧，由发送方进行重发。","categories":["2.通讯协议","CAN"]},{"title":"数字花园建设","path":"/2024/05/17/0-平台-服务器-数字花园建设/","content":"页面部署打开 github 下方仓库 https://github.com/oleeskild/digitalgarden fork 到自己仓库，直接点击 deploy，部署到 vercel Obsidian 插件配置搜索 digital garden 插件，配置 Github 仓库即可 写文章时，需要在文章属性中添加 1dg-publish: true 搜索 publish single note，发布文章","categories":["0.平台","服务器"]},{"title":"博客部署相关环境","path":"/2024/05/17/0-平台-服务器-博客部署相关环境/","content":"更新软件包sudo apt update 更新 nodejs 到最新版本卸载自带的 nodejs sudo apt autoremove nodejs sudo apt purge nodejs 安装 20 版本的 nodejs curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp; sudo apt-get install -y nodejs 查看版本是否更新，否则关闭命令行重新打开 nodejs -v 安装 nodejs 安装工具到全局 sudo npm install n -g 安装稳定版本 nodejs sudo n stable 安装 npmsudo apt install npm -y FTP 配置 - 用于图床安装 ftp 服务端 sudo apt install vsftpd -y 修改配置文件 sudo vi &#x2F;etc&#x2F;vsftpd.conf 禁止匿名访问anonymous_enable&#x3D;NO# 接受本地用户local_enable&#x3D;YES# 允许上传write_enable&#x3D;YES # 更改创建文件权限 local_umask&#x3D;022 重启服务 sudo service vsftpd restart 创建 FTP 用户 sudo useradd -d &#x2F;home&#x2F;lemonade -M lemonade sudo passwd lemonade Mysql 环境搭建安装 mysql sudo apt install mysql-server -y sudo service mysql status # 查看服务状态sudo service mysql start # 启动服务sudo service mysql stop # 停止服务sudo service mysql restart # 重启服务 查看并更新密码 sudo cat /etc/mysql/debian.cnf 采用默认用户名密码登录 mysql -u *** -p 更新 root 用户密码 ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;newpasswd&#39;; 退出后，用 root 用户确认正常登录 mysql -u root -p newpasswd 创建 Qexo 要使用表 create database qexo; Python 环境安装安装编译 Python 3.10 所需的依赖项： sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 下载 Python 3.10 的源代码： wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz 解压源代码： tar -xf Python-3.10.0.tgz 进入解压后的目录： cd Python-3.10.0 配置 Python 3.10 的编译选项： ./configure --enable-optimizations 编译并安装 Python 3.10： make -j 8 sudo make altinstall 确认 Python 3.10 是否安装成功： python3.10 --version 如果输出了 Python 3.10 的版本号，则说明安装成功。 安装时网络问题见 pip下载网络问题 nginx 环境安装安装 nginx sudo apt install nginx 访问公网 IP，发现 nginx 页面安装成功 修改 nginx 配置文件 sudo vi /etc/nginx/sites-enabled/default 修改完成后重启 nginx 服务 sudo service nginx restart","categories":["0.平台","服务器"]},{"title":"shell","path":"/2024/05/17/1-语言-Shell-shell/","content":"什么是 shellshell 是一个编程语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支； 也是一个命令行解释器，交互式地解释和执行用户输入的命令； 还是内核的保护工具，它调用了系统核心的大部分功能来执行程序、建立文件并以并行的方式协调各个程序的运行。 Shell 有两种执行命令的方式：交互式（Interactive）：解释执行用户的命令，用户输入一条命令，Shell 就解释执行一条。批处理（Batch）：用户事先写一个 Shell 脚本 (Script)，shell 脚本是 shell 命令的有限序列，将各类命令预先放入其中，方便一次性执行的一个程序文件，主要用于方便管理员进行设置或者管理，而不必一条一条地敲命令。 *Shell 脚本是解释执行的，不需要编译，Shell 程序从脚本中一行一行读取并执行这些命令，相当于一个用户把脚本中的命令一行一行敲到 Shell 提示符下执行 Linux 的 Shell 种类众多，常见的有：Bourne Shell（&#x2F;usr&#x2F;bin&#x2F;sh 或&#x2F;bin&#x2F;sh）、Bourne Again Shell（&#x2F;bin&#x2F;bash）、C Shell（&#x2F;usr&#x2F;bin&#x2F;csh）、K Shell（&#x2F;usr&#x2F;bin&#x2F;ksh）、Shell for Root（&#x2F;sbin&#x2F;sh）等等。 不同的 Shell 语言的语法有所不同，所以不能交换使用。我们关注的重点是 Bash，Bash 也是大多数 Linux 系统默认的 Shell。在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，在下面的文字中，我们可以看到#!&#x2F;bin&#x2F;sh，它同样也可以改为#!&#x2F;bin&#x2F;bash。 编写 Shell 脚本的格式是固定的，一个简单的 shell 脚本如下： 1234#!/bin/sh#print hello world in the console windowa = &quot;hello world&quot;echo $a 首行中的符号**#!告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序**。 如果首行没有这句话，在执行脚本文件的时候，将会出现错误。 后续的部分就是主程序，Shell 脚本像高级语言一样，也有变量赋值，也有控制语句。 除第一行外，以#开头的行就是注释行，直到此行的结束。 如果一行未完成，可以在行尾加上 “，这个符号表明下一行与此行会合并为同一行。 编辑完毕，将脚本存盘为 filename.sh，文件名后缀 sh 表明这是一个 Bash 脚本文件。 执行方式： 1234567891011121.加可执行权限 chmod u+x filename.sh ./filename.sh2.执行通过bash运行 /bin/bash filename.sh3.将路径添加到环境变量 chmod u+x filename.sh PATH+=:/home/fs/Temp filename.sh //任意目录运行4.添加到bin文件夹 chmod u+x filename.sh sudo mv filename.sh /bin/ 注意，一定要写成.&#x2F;filename.sh，而不是 filename.sh。运行其它二进制的程序也一样，直接写 filename.sh，linux 系统会去 PATH 里寻找有没有叫 filename.sh 的，而只有&#x2F;bin, &#x2F;sbin, &#x2F;usr&#x2F;bin，&#x2F;usr&#x2F;sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 filename.sh 是会找不到命令的，要用.&#x2F;filename.sh 告诉系统说，就在当前目录找。 速查表 命令 含义 %!xxd 将二进制文件转换为 16 进制和 ASCII 表形式查看 * 代表通配符，可代表任意长度的任意字符； ？ 可代表单个长度的任意字符 [] 通配括号中的元素 [^……] 除去括号中的元素，其他通配 &gt;file 将输出重定向到 file 中去（新建） &gt;&gt;file 将输出重定向到 file 中去（追加模式） &lt;file 将 file 作为标准输入 2&gt; 或 &amp;&gt; –&gt;标准错误 pipe 管道,将第一个命令的输出作为第二个命令的输入 shell 命令使用 tab 补齐：命令 文件名 路径 history ：查看命令历史 通配符 *：匹配任意长度任意字符串 管道 |：第一个指令的输出作为第二个指令的输入：ls /usr/bin | wc -l 重定向 : 命令置换：反撇号 1 ls `pwd` 常用命令 用户管理命令 进程管理命令 通配符1234567*?[...][-][^...][a-z, ABC] // 表示匹配a到z和A,B,C中任意一个字符ls file[3-4][5-9].c /*表示名匹配文件名含[3-4]中的一个字符和[5-9]中的一个字符，两个字符的共两个字符的文件名都符合规则。*/ 管道| 将第一个命令的正确输出内容 通过管道输出给 第二个命令作为输入. 要求第一个命令有输出，第二个命令有输入功能。 重定向echo &quot;hello world&quot; &gt; test &#x2F;&#x2F;将内容输出到文件 test 中。 echo &quot;hello Eric&quot; &gt;&gt; test &#x2F;&#x2F;将字符串内容追加到 test 中,在 test 原有的内容上添加 2&gt; 2&gt;&gt; &#x2F;&#x2F;将报错信息重定向或追加到指定文件. &amp;&gt; &amp;&gt;&gt; &#x2F;&#x2F;将正确信息和错误信息一起重定向或追加到指定文件。 0 标准输入 stdin 1 标准输出 stdout ‘ ’ main() return ; fflush(stdout); 2 标准出错 stderr /dev/null 是一个被称作 Linux 黑洞的文件，把输出信息重定向到这个文件等同于删除数据 12cat /dev/null &gt; ~/.bash_history // 利用/dev/null清空指定文件。/dev/zero command &gt; file 将输出重定向到 file。 command &lt; file 将输入重定向到 file。 command &gt;&gt; file 将输出以追加的方式重定向到 file。 n &gt; file 将文件描述符为 n 的文件重定向到 file。 n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n &gt;&amp; m 将输出文件 m 和 n 合并。 n &lt;&amp; m 将输入文件 m 和 n 合并。 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 管道和重定向的比较command1 | command2 左输出 | 右输入 command &gt; file 左输出 &gt; 右文件 command &lt; file 左输入 &lt; 右文件 管道的命令同时执行,command2 等待 command1 的输出 (阻塞) 重定向是有优先级的,由进程优先级决定. 常用命令less/more alias 定义别名 12alias md=&#x27;mkdir&#x27;md dir1 dir2 //md就是mkdir了,这里创建了两个目录(文件夹)dir1和dir2. head/tail sort 排序命令 12345cat /etc/passwd | sort -t: -k 4 -n //-t指定分隔符 -k 4 指定分隔后的段, -n 完整比较。manman 1 可执行程序或Shell命令man 2 ?man 3 ? 用户管理命令12345678910adduserdeluser --remove-home //删除用户的同时，删除其工作目录chownchown xiaomeng jielun //将文件jielun的所有者改为xiaomeng.su 切换用户passwd 修改密码sudo //用超级用户权限执行一次命令；sudo passwd //普通用户修改root用户密码;usermodusermod -l Ez xiaoming //更改用户名xiaoming为Ez,要保证用户不在登陆状态; 相关文件: 123456789101112/etc/passwd/etc/shadow/etc/skel//etc/group/etc/gshadowchmod 改变文件读写执行权限rw- r-- r--110 100 1006 4 4| | |其他用户| |组用户权限|所属者的权限Xm 进程管理信息进程的概念:程是指正在执行的程序的实例。每个运行的程序都在系统中作为一个进程存在。进程是操作系统进行任务调度和资源管理的基本单位，它拥有自己的内存空间、执行代码、数据和资源。进程之间相互独立，彼此隔离，这样可以确保一个进程的异常不会影响其他进程的正常运行。进程与程序的区别:程序是一组静态的指令和数据的集合，它们存储在磁盘上；而进程是程序的实例，是程序在内存中的执行过程。程序只是静态的代码和数据的集合，而进程是具有动态特性、在系统中运行的实体。 &#x2F; 进程 程序 定义 进程是正在运行的程序的实例。在操作系统中，进程代表了一个独立的执行单元，拥有自己的内存空间、程序代码、数据和资源。每个运行的程序都以进程的形式存在。 程序是一组指令和数据的集合，它是静态的、存储在磁盘上的文件，描述了如何执行特定任务。程序本身并不占用系统资源，只有在被加载到内存并运行时，才成为一个进程。 特性 进程是一个动态的实体，具有生命周期，可以处于运行、就绪、阻塞、挂起等不同状态，而且进程之间相互独立，彼此隔离。 程序是一个静态的实体，只是存储在磁盘上的文件，并不具有自己的执行状态和资源。 生命周期 进程从创建、运行到终止，进程有一个明确的生命周期。当进程终止时，它占用的资源会被操作系统回收。 程序本身没有生命周期，只有在被加载到内存并执行为进程后，才会有生命周期。 进程和程序之间是一种从程序到进程的实例化关系。当运行一个程序时，操作系统会为该程序创建一个对应的进程，使得程序在内存中得以执行。 进程的查看: 12ps -auxps -elf 进程的几种状态: 运行（Running）：表示进程正在运行或正在执行。 就绪（Ready）：表示进程已经准备好运行，但由于系统资源限制或其他进程的运行，它暂时还没有得到处理器的分配。 阻塞（Blocked）：也称为等待（Waiting），表示进程由于等待某个事件的发生（如 I&#x2F;O 操作完成、信号等）而暂停执行，直到事件发生才能继续运行。 挂起（Suspended）：表示进程被暂时挂起，不占用 CPU 资源，并且可能被放置在磁盘上。这种状态通常用于系统中的一些特殊情况，如进程被调试或由于内存不足而被置换出来。 shell 命令行下查找在当前目录下所有文件中查找内容包含 string 的文件并列出字符所在的文件,所在行及所在行的内容: 1find ./ -name &quot;*&quot; -exec grep -n &quot;string&quot; ./ &#123;&#125; \\; 使用 find 查找时希望忽略某个目录 (-prune): 如果希望在&#x2F;app 目录下查找文件，但不希望在&#x2F;app&#x2F;bin 目录下查找: 1find /app -name &quot;/app/bin&quot; -prune -o -print 使用 type 选项: 如果要在&#x2F;etc 目录下查找所有的目录: 1find /etc -type d -print 如果要在&#x2F;etc 目录下查找.svn 的目录: 1find /etc -name .svn -type d -print 为了在当前目录下查找除目录以外的所有类型的文件: 1find . ! -type d -print 为了在当前目录下查找所有的符号链接文件，可以用: 1find . -type | -print 为了用 ls -l 命令列出所匹配到的文件，可以把 ls -l 命令放在 find 命令的 -exec 选项中: 1find . -type f -exec ls -l &#123;&#125; \\; 注：f 表示普通文件 shell 脚本各种执行方式source ./*.sh . ./*.sh ./*.sh 的区别 ./*.sh 的执行方式等价于 sh ./*.sh 或者 bash ./*.sh， 此三种执行脚本的方式都是重新启动一个子 shell,在子 shell 中执行此脚本。 .source ./*.sh 和 . ./*.sh 的执行方式是等价的，即两种执行方式都是在当前 shell 进程中执行此脚本，而不是重新启动一个 shell 而在子 shell 进程中执行此脚本。验证依据：没有被 export 导出的变量（即非环境变量）是不能被子 shell 继承的验证结果： 12345678910111213141516[root@localhost ~]#name=dangxu //定义一般变量[root@localhost ~]# echo $&#123;name&#125;dangxu[root@localhost ~]# cat test.sh //验证脚本，实例化标题中的./*.sh#!/bin/shecho $&#123;name&#125;[root@localhost ~]# ls -l test.sh //验证脚本可执行-rwxr-xr-x 1 root root 23 Feb 611:09 test.sh[root@localhost ~]# ./test.sh //以下三个命令证明了结论一[root@localhost ~]# sh ./test.sh[root@localhost ~]# bash ./test.sh[root@localhost ~]# . ./test.sh //以下两个命令证明了结论二dangxu[root@localhost ~]# source ./test.shdangxu[root@localhost ~]# 变量定义Shell 支持自定义变量，不区分数据类型,全部识别为字符串 定义变量时，命名符合标识符规定，变量名不加 $ 符号 varName=&quot;value&quot; 注意变量名和等号之间不能有空格，同时变量名的命令遵循以下规则 首个字符必须为字母 中间不能有空格，支持下划线 不能使用标点符号，不能使用 bash 里的关键字 使用使用一个定义过的变量，只要在变量名前面加 $ 符号即可 12echo $varNameecho $&#123;varName&#125; //&#123;&#125;帮助进行边界识别 变量名外的花括号时可选的，可以用于帮助解释器识别变量，比如下面这种情况 1234for skill in Adado\techo &quot;i am good at $&#123;skill&#125;Script&quot;done 如果不给 skill 变量加{}，解释器会把 $skillScript 当成一个变量 重新定义已定义的变量可以被重新定义 1234myUrl=&quot;http://see.xidian.edu.cn/cpp/linux/&quot;echo $&#123;myUrl&#125;myUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;echo $&#123;myUrl&#125; 第二次赋值的时候不能写 $myUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;，只有使用变量时才加 $ 符号 只读变量使用 readonly 可以将变量定义为只读变变量，只读变量的值不能被改变 1234#!/bin/bashmyUrl=&quot;http://see.xidian.edu.cn/cpp/shell/&quot;readonly myUrlmyUrl=&quot;http://see.xidian.edu.cn/cpp/danpianji/&quot; 运行脚本，会报如下错误： /bin/sh: NAME: This variable is read only. 删除变量使用 unset 可以删除变量，unset 不能删除只读变量 12unset 变量名set 显示本地的所有变量 变量类型位置变量接收用户参数 $0 表示当前脚本名称 $1 表示接收的第一个命令行参数 $2 表示第二个命令行参数，以此类推 123456$# 参数的个数$? 命令执行结果,函数返回结果,$$ 进程id$1,$2..$9,$&#123;10&#125;, $&#123;11&#125;$@ &quot;&quot;$* &quot;$*&quot; 当做整体处理 环境变量 (全局可以访问的变量)脚本中定义的变量只在本脚本有效 12envexport 变量名 //将局部变量变为全局变量 特殊变量 $0 当前脚本的文件名 $n 传递给脚本或函数的参数，$1,$2 $# 传递给脚本或函数的参数个数 $* 传递给脚本或函数的所有参数 $@ $? 上个命令的退出状态或函数的返回值 $$ 当前 shell 进程 ID $* 和 $@ 的区别 12345678910111213141516171819202122232425#!/bin/bashecho &quot;\\$*=&quot; $*echo &quot;\\&quot;\\$*\\&quot;=&quot;&quot;$*&quot;echo &quot;\\$@=&quot; $@echo &quot;\\&quot;\\$@\\&quot;=&quot;&quot;$@&quot;echo &quot;print each param from \\$*&quot;for var in $*do\techo &quot;$var&quot;doneecho &quot;print each param from \\$@&quot;for var in $@do\techo &quot;$var&quot;doneecho &quot;print each param from \\&quot;\\$*\\&quot;&quot;for var in &quot;$*&quot;do\techo &quot;$var&quot;doneecho &quot;print each param from \\&quot;\\$@\\&quot;&quot;for var in &quot;$@&quot;do\techo &quot;$var&quot;done 运行 .&#x2F;test.sh “a” “b” “c” “d”，看到下面的结果： 12345678$*= a b c d&quot;$*&quot;= a b c d$@= a b c d&quot;$@&quot;= a b c dprint each param from $*abcdprint each param from $@abcdprint each param from &quot;$*&quot;a b c dprint each param from &quot;$@&quot;abcd 替换，运算符，字符串，数组替换如果表达式中包含特殊字符，Shell 将会进行替换。例如，在双引号中使用变量就是一种替换，转义字符也是一种替换。 123#!/bin/basha=10echo -e &quot;Value of a is $a &quot; 这里 -e 表示对转义字符进行替换。如果不使用 -e 选项，将会原样输出 1Value of a is 10 命令替换命令替换是将一个命令的输出作为另一个命令的参数。命令格式如下所示。 1command1 `command2` 其中，命令 command2 的输出将作为命令 command1 的参数。 1ls `pwd` //这里是反引号,和~是同一个按键 pwd 命令用于显示当前目录的绝对路径。在上面的命令行中，使用命令置换符，将 pwd 的运行结果作为 ls 命令的参数。最终，命令执行结果是显示当前目录的文件内容。 需要注意命令置换和管道 pipe 的区别 变量替换变量替换可以根据变量的状态（是否为空、是否定义等）来改变它的值可以使用的变量替换形式 形式 说明 ${var} 变量本来的值 ${var:-word} 如果变量 var 为空或已被删除 (unset)，那么返回 word，但不改变 var 的值。 ${var:&#x3D;word} 如果变量 var 为空或已被删除(unset)，那么返回word，并将 var 的值设置为 word。 ${var:?message} 如果变量 var 为空或已被删除 (unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值。若此替换出现在 Shell 脚本中，那么脚本将停止运行。 ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值。 运算符Bash 支持很多运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符算数运算符awk 和 expr，expr 12345#!/bin/bashval=`expr 2 + 2`echo &quot;value : $val&quot;val=`expr 2 \\* 2`echo &quot;value : $val&quot; 输出 value : 4 value : 4 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2 完整的表达式要被 &#96;&#96; 包含，注意这个字符不是常用的单引号，在 Esc 键下边 乘号 * 前边必须加反斜杠 \\ 才能实现乘法运算 12345678`+``-``*``/``%`取余`=`赋值`==`相等`!=`不等 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字-eq 相等-ne 不等-gt 左侧大于右侧，返回 true-lt 小于-ge 大于等于-le 小于等于布尔运算符! 非-a 与-o 或字符串运算符 1[ -z $String ] echo $? 12345`=` 检测两个字符串是否相等，相等返回 true。`!=` 不等`-z` 检测字符串长度是否为0，为0返回 true`-n` 检测字符串长度是否为0，不为0返回 true`str` 检测字符串是否为空，不为空返回 true。 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性 1[ -d /etc/fstab ] echo $? 操作符 作用 -b file 检测文件是否是块设备文件 -c file 检测文件是否是字符设备文件 -d file 检测文件是否是目录 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件） -g file 检测文件是否设置了 SGID 位 -k file 检测文件是否设置了粘着位 (Sticky Bit) -p file 检测文件是否是具名管道 -u file 检测文件是否设置了 SUID 位 -r file 检测文件是否可读 -w file 检测文件是否可写 -x file 检测文件是否可执行 -s file 检测文件是否为空（文件大小是否大于 0） -e file 检测文件（包括目录）是否存在 字符串字符串可以用单引号，也可以用双引号，也可以不用引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号里可以有变量 双引号里可以出现转义字符 数组bash 支持一维数组（不支持多维数组），并且没有限定数组的大小。类似与 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组 在 Shell 中，用括号来表示数组，数组元素用“空格”符号分割开。定义数组的一般形式为： 1array_name=(value1 ... valuen) 还可以单独定义数组的各个分量： 123array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组读取数组元素值的一般格式是： 1$&#123;array_name[index]&#125; 使用 @ 或 * 可以获取数组中的所有元素 12$&#123;array_name[*]&#125;$&#123;array_name[@]&#125; 获取数组长度或取数组长度的方法与获取字符串长度的方法相同，例如： 123456# 取得数组元素的个数length=$&#123;#array_name[@]&#125;# 或者length=$&#123;#array_name[*]&#125;# 取得数组单个元素的长度lengthn=$&#123;#array_name[n] 逻辑语句功能语句read 是用来读取用户输入信息的命令，能够把接收到的用户输入信息赋值给后面的指定变量，-p 参数用于向用户显示一定的提示信息。 操作符 作用 -p “ 提示内容 “ -t 等待用户输入时间 -n 读的字符个数 -s 隐藏输入 1234read -n 5 AA BB CCread AA BB CChello xiaoming, mingtian you kongread -p &quot;Enter your score（0-100）：&quot; GRADE 判断语句判断语句格式： 1[ 条件表达式 ] 对应两边应均有一个空格 逻辑测试语句： &amp;&amp; 与 (当前面的命令执行成功后才会执行它后面的命令) 或（当前面的命令执行失败后才会执行它后面的命令） ！ 非（把条件测试中的判断结果取相反值） 得到当前内存剩余量： 12FreeMem=`free -m | grep Mem: | awk &#x27;&#123;print $4&#125;&#x27;`[ $FreeMem -lt 1024 ] &amp;&amp; echo &quot;Insufficient Memory&quot; break 语句break 命令允许跳出所有循环（终止执行后面的所有循环）。在嵌套循环中，break 命令后面还可以跟一个整数，表示跳出第几层循环。例如： 1break n //表示跳出第 n 层循环。 continue 语句continue 命令与 break 命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。同样，continue 后面也可以跟一个数字，表示跳出第几层循环。 结构语句case 123456789casecase var in1)...;;2|3|4)...;;esac case 工作方式如上所示。取值后面必须为关键字 in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。;; 与其他语言中的 break 类似，意思是跳到整个 case 语句的最后。 demo: 123456789101112#!/bin/bashread -p &quot;请输入一个字符，并按Enter键确认：&quot; KEYcase &quot;$KEY&quot; in[a-z]|[A-Z]) echo &quot;您输入的是 字母。&quot; ;;[0-9]) echo &quot;您输入的是 数字。&quot; ;;*) echo &quot;您输入的是 空格、功能键或其他控制字符。&quot;esac 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 if 1234567if [ ] thenelsefiif [ ] thenelif [ ] thenelsefi demo: 1234567891011121314#!/bin/bashread -p &quot;Enter The Users Password : &quot; PASSWDfor UNAME in `cat users.txt`doid $UNAME &amp;&gt; /dev/null （&amp;&gt;就是&quot;&gt;&quot;和&quot;2&gt;&quot;这两个的结合体）if [ $? -eq 0 ] then echo &quot;Already exists&quot;else useradd $UNAME &amp;&gt; /dev/null echo &quot;$PASSWD&quot; | passwd --stdin $UNAME &amp;&gt; /dev/null if [ $? -eq 0 ] then echo &quot;$UNAME , Create success&quot; else echo &quot;$UNAME , Create failure&quot; fifidone 循环语句for 12345678910for 变量 in 列表do..donefor ((i=0; i&lt;N; i++))dodonefor var in `ls`for var in $(ls)for var #列表的内容是位置参数变量时，可以省略in ... 列表是一组值（数字、字符串等）组成的序列，每个值通过空格分隔。每循环一次，就将列表中的下一个值赋给变量。 demo: 12345678910HLIST=`echo www.baidu.com`for IP in $HLISTdo ping -c 3 -i 0.2 -W 3 $IP &amp;&gt; /dev/nullif [ $? -eq 0 ] then echo &quot;baidu is online&quot;else echo &quot;baidu is offline&quot;fidone while 12345678while 表达式do..donewhile (($i &lt; $loop))do...done while 循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。 demo: 12345678910111213141516PRICE=$(expr $RANDOM % 1000)TIMES=0echo &quot;商品实际价格为0-999之间，猜猜看是多少？&quot;while truedo read -p &quot;请输入您猜测的价格数目：&quot; INT let TIMES++ if [ $INT -eq $PRICE ] ; then echo &quot;恭喜您答对了，实际价格是 $PRICE&quot; echo &quot;您总共猜测了 $TIMES 次&quot; exit 0 elif [ $INT -gt $PRICE] ; then echo &quot;太高了！&quot; else echo &quot;太低了！&quot; fidone untilluntil 循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。一般 while 循环优于 until 循环。 123456a=0until [ ! $a -lt 10 ]doecho $aa=`expr $a + 1`done 函数函数定义 12345678function_name () &#123; list of commands [ return value ]&#125;function function_name () &#123; list of commands [ return value ]&#125; 如果你希望直接从终端调用函数，可以将函数定义在主目录下的 .profile 文件，这样每次登录后，在命令提示符后面输入函数名字就可以立即调用。返回值函数返回值，可以显式增加 return 语句；如果不加，会将最后一条命令运行结果作为返回值。接收函数返回值用 $?。Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0 表示成功，其他值表示失败。（返回值范围 0-255）如果 return 其他数据，比如一个字符串，往往会得到错误提示：“numeric argument required”。如果一定要让函数返回字符串，那么可以先定义一个变量，用来接收函数的计算结果，脚本在需要的时候访问这个变量来获得函数返回值。调用调用函数只需要给出函数名，不需要加括号。 12345678910Hello() &#123;echo &quot;hello, world&quot;&#125;HelloHello2() &#123;echo &quot;hello2, world&quot;return 1&#125;Hello2ret=$? 输出给了变量 1var=$(Hello2) 删除像删除变量一样，删除函数也可以使用 unset 命令，不过要加上 .f 选项，如下所示： 1unset .f function_name 参数在 Shell 中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1 表示第一个参数，$2 表示第二个参数 获取第十个参数需要 $&#123;10&#125;。当 n&gt;&#x3D;10 时，需要使用 $&#123;n&#125; 来获取参数。 $# 传递给函数的参数个数。 $* 显示所有传递给函数的参数。 $@ 与 $* 相同，但是略有区别 $? 函数的返回值。 传参: 123function add_fun () &#123;&#125;add_fun str1 str2 str3 文件包含Shell 也可以包含外部脚本，将外部脚本的内容合并到当前脚本。 12. filenamesource filename 两种方式的效果相同，简单起见，一般使用点号 (.)，但是注意点号 (.) 和文件名中间有一空格 被包含脚本不需要有执行权限 补充环境变量环境变量一般是指在操作系统中用来指定操作系统运行环境的一些参数，比如临时文件夹位置和系统文件夹位置等等。 变量种类 按变量的生存周期来划分，Linux 变量可分为两类： 永久的：需要修改配置文件，变量永久生效。 临时的：使用 export 命令声明即可，变量在关闭 shell 时失效。设置环境变量 在&#x2F;etc&#x2F;profile 文件中添加变量【对所有用户生效（永久的）】 用 VI 在文件&#x2F;etc&#x2F;profile 文件中增加变量，该变量将会对 Linux 下所有用户有效，并且是“永久的”。例如：编辑&#x2F;etc&#x2F;profile 文件，添加 PATH 变量 1 export PATH=/home/fs : $PATH &gt; 注：修改文件后要想马上生效还要运行# source &#x2F;etc&#x2F;profile 不然只能在下次重进此用户时生效。 在用户目录下的.bash_profile 文件中增加变量【对单一用户生效（永久的）】 用 VI 在用户目录下的.bash_profile 文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。 例如：编辑 guok 用户目录（&#x2F;home&#x2F;guok）下的.bash_profile，添加如下内容： 1 export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &gt; 注：修改文件后要想马上生效还要运行 $ source &#x2F;home&#x2F;guok&#x2F;.bash_profile 不然只能在下次重进此用户时生效。 直接运行 export 命令定义变量【只对当前 shell（BASH）有效（临时的）】 在 shell 的命令行下直接使用 [export 变量名&#x3D;变量值] 定义变量，该变量只在当前的 shell（BASH）或其子 shell（BASH）下是有效的，shell 关闭了，变量也就失效了，再打开新 shell 时就没有这个变量，需要使用的话还需要重新定义。PATH 声明其格式为：PATH=$PATH: 你可以自己加上指定的路径，中间用冒号隔开。环境变量更改后，在用户下次登陆时生效。如果想立刻生效，则可执行下面的语句：$source .bash_profile需要注意的是，最好不要把当前路径 ./ 放到 PATH 里，这样可能会受到意想不到的攻击。完成后，可以通过 $ echo $PATH 查看当前的搜索路径。这样定制后，就可以避免频繁的启动位于 shell 搜索的路径之外的程序了。常用的环境变量 变量名 内容 PATH 决定了 shell 将到哪些目录中寻找命令或程序 HOME 当前用户主目录 HISTSIZE 历史记录数 LOGNAME 当前用户的登录名 HOSTNAME 指主机的名称 SHELL 当前用户 Shell 类型 LANGUGE 语言相关的环境变量，多语言可以修改此环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符，对于 root 用户是#，对于普通用户是 $ 常用的环境变量相关命令 设置一个新的环境变量 hello 1234 fs@ubuntu:~$ export HELLO=&quot;Hello&quot; fs@ubuntu:~$ echo $HELLO Hello fs@ubuntu:~$ 使用 env 命令显示所有的环境变量 12 fs@ubuntu:~$ env .... 使用 set 命令显示所有本地定义的 Shell 变量，set 可以设置某个环境变量的值。 12 fs@ubuntu:~$ set ... 使用 unset 命令来清除环境变量，清除环境变量的值用 unset 命令。如果未指定值，则该变量值将被设为 NULL。示例如下： 12345 fs@ubuntu:~$ export TEST=&quot;Test&quot; \\\\增加一个环境变量TEST fs@ubuntu:~$ env | grep TEST \\\\此命令有输出，证明环境变量TEST已存在 TEST=Test fs@ubuntu:~$ unset $TEST \\\\删除环境变量TEST fs@ubuntu:~$ env | grep TEST \\\\此命令没输出，证明环境变量TEST已经存在 使用 readonly 命令设置只读变量，如果使用了 readonly 命令的话，变量就不可以被修改或清除了。示例如下： 1234567 fs@ubuntu:~$ export TEST=&quot;Test&quot; \\\\增加一个环境变量TEST fs@ubuntu:~$ readonly TEST \\\\将环境变量TEST设为只读 fs@ubuntu:~$ unset TEST \\\\此变量无法删除 bash: unset: TEST: cannot unset: readonly variable fs@ubuntu:~$ TEST=&quot;NEW&quot; \\\\此变量不可更改 bash: TEST: readonly variable fs@ubuntu:~$ 计划任务服务程序一次性计划任务“at 时间 “ 是一个命令行工具，用于在指定的时间执行一次性任务。通过使用该命令，您可以安排计划在将来的某个时间运行的命令或脚本。时间参数可以采用多种格式，如 HH:MM，HH:MM AM&#x2F;PM 或者明天的日期。例如，以下命令将在下午 2 点运行一个脚本： 1at 2pm &lt;脚本路径&gt; 查看计划任务“at -l” 命令用于列出当前计划的 at 任务列表，显示已经被安排的任务及其相关信息，如任务序号、执行时间等。例如，以下命令将列出当前计划的 at 任务列表： 1at -l 取消计划任务“atrm 任务序号 “ 命令用于取消一个已经计划的 at 任务，其中任务序号是通过 “at -l” 命令列出的任务的序号。例如，以下命令将取消任务序号为 1 的 at 任务： 1atrm 1 长期性计划任务crontab -e 创建、编辑计划任务crontab -l 查看当前计划任务crontab -r 删除某条计划任务crontab -u 编辑他人的计划任务demo: 1234crontab -ecrontab -l&gt;25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar /home/wwwrootwhereis rm 时间周期设置： 125 3 * * 1,3,5 依次对应 分钟，小时，日期，月份，星期 任务内容: 要运行的命令 1/usr/bin/tar -czvf backup.tar /home/wwwroot 终端和控制台终端 (terminal，或者叫物理终端）：是一种设备，不是一个程序，一般说的就是能提供命令行用户界面的设备，典型的是屏幕和键盘，或其他的一些物理终端。 虚拟终端：屏幕和键盘只是一个终端，可能不够用，又不想增加设备投入，就产生了虚拟终端。gnome-terminal,urxvt，mlterm，xterm 等等是一个程序，职责是模拟终端设备，和虚拟终端的区别表面上在于它以 GUI 形式的窗口出现，内部则是程序结构和系统控制结构有所不同，但本质上差不多。控制台（console):显示系统消息的终端就叫控制台，Linux 默认所有虚拟终端都是控制台，都能显示系统消息。有时专指 CLI 下的模拟终端设备的一个程序，和 gnome-terminal,urxvt，mlterm，xterm 等相同，只是 CLI 和 GUI 界面的区别。一般 console 有 6 个，tty1-6，CTRL+ALT+f1-6 切换。shell：shell 是一个抽象概念，shell 的一切操作都在计算机内部，负责处理人机交互，执行脚本等，是操作系统能正常运行的重要组成部分,bash，ash，zsh，tcsh 等是 shell 这个抽象概念的一种具体的实现，都是一个程序，都能生成一个进程对象如果想换 shell 的程序，可以修改&#x2F;etc&#x2F;passwd，把里面的&#x2F;bin&#x2F;bash 换成你想要的 shell，或者用 chsh 命令来切换shell 与终端的关系：shell 把一些信息适当的输送到终端设备，同时还接收来自终端设备的输入。一般每个 shell 进程都会有一个终端关联，也可以没有。 12字符程序 &lt;---&gt; 虚拟终端 &lt;---&gt; 图像显示shell &lt;---&gt; xterm &lt;---&gt; X11 控制台和终端的历史遗留区别计算机最初由于价格昂贵，因此，一台计算机一般是由多个人同时使用的。在这种情况下一台计算机需要连接上许多套键盘和显示器来供多个人使用。 在以前专门有这种可以连上一台电脑的设备，只有显示器和键盘，还有简单的处理电路，本身不具有处理计算机信息的能力，他是负责连接到一台正常的计算机上（通常是通过串口） ，然后登陆计算机，并对该计算机进行操作。 当然，那时候的计算机操作系统都是多任务多用户的操作系统。 这样一台只有显示器和键盘能够通过串口连接到计算机 的设备就叫做终端。 而控制台又是什么回事呢？ 学机电的人应该知道，一台机床，或者数控设备的控制箱，通常会被称为控制台，顾名思义，控制台就是一个直接控制设备的台面（一个面板，上面有很多控制按钮）。 在计算机里，把那套直接连接在电脑上的键盘和显示器就叫做控制台。 请注意它和终端的区别，终端是通过串口连接上的，不是计算机本身就有的设备，而控制台是计算机本身就有的设备，一个计算机只有一个控制台。 计算机启动的时候，所有的信息都会显示到控制台上，而不会显示到终端上。 也就是说，控制台是计算机的基 本设备，而终端是附加设备。 当然，由于控制台也有终端一样的功能，控制台有时候也被模糊的统称为终端。 计算机操作系统中，与终端不相关的信息，比如内核消息，后台服务消息，都可以显示到控制台上，但不会显示到终端上。 现在普通用户可以简单的把终端和控制台理解为：可以输入命令行并显示程序运行过程中的信息以及程序运行结果的窗口。 不必要严格区分这两者的差别。 现在由于计算机硬件越来越便宜，通常都是一个人独占一台计算机超做，不再连接以前那种真正意义上的“终端设备了”，因此，终端和控制台的概念也慢慢演化了。 终端和控制台由硬件的概念，演化成了软件的概念。 现在说的终端，比如 linux 中的虚拟终端，都是软件的概念，他用计算机的软件来模拟以前硬件的方式。 比如在 linux 中，你用 alt+f1 ~ f6 可以切换六个虚拟终端，就好比是以前多人公用的计算机中的六个终端设备，这就是为什么这个叫“虚拟终端”的原因。 当然，现在的 linux 也可以通过串口 线，连接一个真正的终端，现在这种终端设备已经非常罕见了，但是还存在，只是一般人很难见到。 也有人利用以前的老电脑（386，486）装上一个串口通信软件，连上一台计算机，来模拟一个终端来用。这样可以达到一台电脑多人使用的目的。 简单的说，能直接显示系统消息的那个终端称为控制台，其他的则称为终端。 但是在 linux 系统中，这个概念也已经模糊化了。 比如下面这条命令： 1echo &quot;hello,world&quot; &gt; /dev/console 这条命令的目的是将 “hello,world” 显示到控制台上&#x2F;dev&#x2F;console 是控制台设备的设备名。 在 linux 中，在字符模式下，你无论在哪个虚拟终端下执行这条命令，字符 hello,world 都会显示在当前的虚拟终端下。也就是说，linux 把当前的终端当作控制台来看待。可见，linux 中已经完全淡化了控制台和终端的区别。 但是在其他的 UNIX 类系统中，却很明显的有虚拟终端和控制台的区别。比如 freeBSD 系统。在 freebsd 中，只有第一个“终端”才是真正的控制台。（就是说按 alt+f1 得到的那个虚拟终端），你无论在哪个虚拟终端上执行上面的那条命令（哪怕是通过网络连接的伪终端上执行这条命令）。hello,world 字符总会显示到第一个“终端”也就是 真正的控制台上。 另外，其他的一些系统内部信息，比如哪个用户在哪个终端登陆，系统有何严重错误警告等信息，全都显示在这个真正的控制台上。在这里，就明显的区分了终端和控制台的概念。其他 UNIX 中也是这样的。 比如 Tru64 unix 在 X 下有一个控制台模拟软件，你无论在哪里输入 echo &quot;hello,world&quot; &gt; /dev/console 命令，hello,world 总会显示在这个控制台模拟器中。 我们在 X 界面下用的那些输入命令的软件，比如 xterm ,rxvt, gnome-terminal 等等，都应该被称为终端模拟软件。 请注意它和控制台模拟软件的区别。 linux 中好象没有控制台模拟软件。 在 X 中的终端模拟 软件中输入的 echo &quot;hello,world&quot;&gt;/dev/console 命令的输出信息，都会输出到启动该 X 服务器的虚拟终端上。 比如，你用字符方式登陆系统。进入第一个虚拟终端，然后 startx 启动 X 服务器。 再打开 xterm 来输入 echo &quot;hello,world&quot;&gt;/dev/console 命令，那么字符串 hello,world 就显示在第一个虚拟终端上。 你按 ctrl+alt+f1，回到那个启动 X 服务器的终端，就可以看到 hello, world 字符串。 现在该明白终端和控制台的区别了吧。 再简单的说，控制台是直接和计算机相连接的原生设备，终端是通过电缆、网络等等和主机连接的设备。在以前的硬件终端设备中，由于生产厂家不同，所遵循的标准不同，因此有不同的型号标准。 比如 vt100 等。这里的 vt100 就是一个标准，那么现在我 们所说的终端，往往不是真正的硬件终端了，而是终端模拟软件了，因此不同的终端模拟软件可能符合不同的标准，还有一些终端模拟软件符合很多种不同终端的标准。 比如 gnome 的终端模拟软件 gnome-terminal，他提供好几中标准可供用户选择。 用户只要设置一下就可以了。现在，由于原先的这些设备在我们的视线中渐渐淡出，控制台和终端的概念也慢慢谈化。","categories":["1.语言","Shell"]},{"title":"正则表达式笔记","path":"/2024/05/17/1-语言-前端-正则表达式笔记/","content":"正则表达式什么是正则表达式在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。 正则表达式就是记录文本规则的代码，用于模式匹配和搜索文本的工具。 正则表达式的模式 字面值字符：普通字符按照字面意义进行匹配,例如字母、数字、空格等，可以直接匹配它们自身。 特殊字符：例如点号 .、星号 *、加号 +、问号 ? 等，它们具有特殊的含义和功能。 字符类：用方括号 [ ] 包围的字符集合，用于匹配方括号内的任意一个字符。[^ ] 匹配除了括号内的字符以外的任意一个字符 元字符：例如 \\d、\\w、\\s 等，用于匹配特定类型的字符，如数字、字母、空白字符等。 量词：例如 &#123;n&#125;、&#123;n,&#125;、&#123;n,m&#125; 等，用于指定匹配的次数或范围。 边界符号：例如 ^、$、\\b、\\B 等，用于匹配字符串的开头、结尾或单词边界与非边界位置。 分组和捕获：( )：用于分组和捕获子表达式。(?: )：用于分组但不捕获子表达式。 字符字符匹配直接在方括号里列出： [aeiou] 就匹配任何一个英文元音字母 [.?!] 匹配标点符号 (.或?或!) 也可以指定一个字符范围： [0-9] 代表的含意与\\d 就是完全一致的：一位数字 [a-z0-9A-Z_] 也完全等同于\\w。 普通字符 字符 含义 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（ 、\\r）之外的任何单个字符，相等于 [^ \\r]。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] 非打印字符 字符 含义 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 特殊字符 字符 含义 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则$ 也匹配 ‘ ’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。 * 匹配前面的子表达式零次或多次。要匹配 * 字符，请使用*。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。 . 匹配除换行符 之外的任何单字符。要匹配 . ，请使用 . 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 [。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’ ’ 匹配换行符。序列 ‘&#39; 匹配 “&quot;，而 ‘(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用^。 { 标记限定符表达式的开始。要匹配 {，请使用 {。 | 指明两项之间的一个选择。要匹配|，请使用 |。 分支条件| 元字符，用于在两种或多种模式之间进行选择 匹配分枝条件时，将会从左到右地测试每个条件，如果满足某个分枝，就不会再去向右测试。 分组() 元字符，标记一个子表达式的开始和结束位置。例如 IP 地址表达式:((2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?).)&#123;3&#125;(2[0-4]\\\\d|25[0-5]|[01]?\\\\d\\\\d?) 限定符 字符 含义 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于 {0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 “do” 、 “does”、 “doxy” 中的 “do” 和 “does”。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 含义 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 或 \\r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 或 \\r 之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 不能将限定符与定位符一起使用。由于在紧靠换行或者单词边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式 转义字符与反义字符 在正则表达式中，还有一些常用的转义字符,转义字符可以方便地匹配一些常见的字符类型: — — \\d 表示匹配任意一个数字字符 \\w 表示匹配任意一个字母、数字或下划线字符 \\s 表示匹配任意一个空白字符（包括空格、制表符、换行符等） \\b 表示匹配单词的边界等。 在正则表达式中，反义字符是指用于匹配除了某些字符之外的任意字符的特殊字符。 反义字符以 \\ 开头，后面跟着一个大写字母，表示匹配除了这个字符类别中的任意一个字符之外的所有字符。 — — \\D 匹配任意一个非数字字符。 \\W 匹配任意一个非字母、数字或下划线字符。 \\S 匹配任意一个非空白字符。 \\B 匹配不在单词边界上的任意一个字符。 注释小括号的另一种用途是通过语法 (?#comment) 来包含注释 IP 地址 2[0-4]\\d(?#200-249)|250-5|[01]?\\d\\d?(?#0-199)。 贪婪和懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。 以这个表达式为例：a.*b，它将会匹配最长的以 a 开始，以 b 结束的字符串。 如果用它来搜索 aabab 的话，它会匹配整个字符串 aabab。这被称为贪婪匹配。 有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。 前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。 这样 .*? 就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 现在看看懒惰版的例子吧： a.*?b 匹配最短的，以 a 开始，以 b 结束的字符串。如果把它应用于 aabab 的话，它会匹配 aab（第一到第三个字符）和 ab（第四到第五个字符）。 运算符优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?:), (?&#x3D;), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，” 或 “ 操作,字符具有高于替换运算符的优先级，使得&#96;m 反向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本 (也就是此分组捕获的内容) 可以在表达式或其它程序中作进一步的处理。 反向引用用于重复搜索前面某个分组匹配的文本。例如，\\1 代表分组 1 匹配的文本。 分组 0 对应整个正则表达式 \\b(\\w+)\\b\\s+\\1\\b 可以用来匹配重复的单词，像 go go, 或者 kitty kitty。 总结 确定需要匹配的基本字符或字符类别&#x2F;集合等 确定匹配的字符或字符集合的数量 特殊字符和转义字符的处理 边界和位置的匹配 使用捕获组 () 进行多组匹配 使用反向引用 使用逻辑操作符进行判定 正则表达式字符含义表 字符 含义 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 “n”。\\ 匹配一个换行符。序列 \\\\ 匹配 “\\ 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \\ 或 \\\\r 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 \\ 或 \\\\r 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，o&#123;2&#125; 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配 n 次。例如，o&#123;2,&#125; 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o&#123;1,&#125; 等价于 o+。o&#123;0,&#125; 则等价于 o*。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。o&#123;0,1&#125; 等价于 o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，o+? 将匹配单个 “o”，而 o+ 将匹配所有 o。 . 匹配除换行符（ 、\\r）之外的任何单个字符。要匹配包括 \\ 在内的任何字符，请使用像 &#96;(. )&#96; 的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在 VBScript 中使用 SubMatches 集合，在 JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ( 或 )。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “ 或 “ 字符 (&#96; ) 来组合一个模式的各个部分是很有用。例如， industr(?:y (?&#x3D;pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，&#96;Windows(?&#x3D;95 98 (?!pattern) 正向否定预查 (negative assert)，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如 &#96;Windows(?!95 98 (?&lt;&#x3D;pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，&#96;(?&lt;&#x3D;95 98 (? 反向否定预查，与正向否定预查类似，只是方向相反。例如 “(?” 能匹配 “3.1Windows” 中的 “Windows”，但不能匹配 “2000Windows” 中的 “Windows”。 &#96;x y&#96; 匹配 x 或 y。例如，&#96;z [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 “plain” 中的 a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，[^abc] 可以匹配 “plain” 中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\\\\b 可以匹配”never” 中的 er，但不能匹配 “verb” 中的 er。 \\B 匹配非单词边界。er\\\\B 能匹配 “verb” 中的 er，但不能匹配 “never” 中的 er。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的c 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f \\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f \\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\\\x41 匹配 “A”。\\\\x041 则等价于 \\\\x04 &amp; “1”。正则表达式中可以使用 ASCII 编码。 um 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)\\\\1 匹配两个连续的相同字符。 标识一个八进制转义值或一个向后引用。如果 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 m 标识一个八进制转义值或一个向后引用。如果 m 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 m 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 m 将匹配八进制转义值 nm。 ml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。 &#96;","categories":["1.语言","前端"]},{"title":"USB挂载监测","path":"/2024/05/17/2-通讯协议-USB-USB挂载监测/","content":"功能程序监测到插入U盘后，自动执行执行U盘内和本地指定文件夹双向同步功能 要点 Linux 下如何用 QT 检测到 U 盘已经插入，并实现 mount 与 umount 实现方式使用 qt 自带的 QDBus 可以实现，下面为连接代码，当系统有设备插入时，可以调用 slotDeviceAdded(QString udi) 函数。 在 pro 文件中应该加入 QT +=dbus 12345678910111213141516#include &lt;QtDBus/QDBusConnection&gt;#include &lt;QDbusInterface&gt;//以下为检测设备的插入 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceAdded&quot;, this, SLOT(slotDeviceAdded(QString )));//以下为检查设备的拨出 QDBusConnection::systemBus().connect( &quot;org.freedesktop.Hal&quot;, &quot;/org/freedesktop/Hal/Manager&quot;, &quot;org.freedesktop.Hal.Manager&quot;, &quot;DeviceRemoved&quot;, this, SLOT(slotDeviceRemoved(QString ))); 在 slotDeviceAdded(QString udi) 函数中，要使用到 1QDBusInterface device(&quot;org.freedesktop.Hal&quot;, udi, &quot;org.freedesktop.Hal.Device&quot; , QDBusConnection::systemBus()); 通过 HAL 可以查询到设备为 volume 的设备，然后通过判断是否为&#x2F;dev&#x2F;sd 的设备，就可以判断出是否为 U 盘，然后调用 mount 就可以了。 这时记录下 U 盘的 UDI，在检测到设备拨出时，再查询一下 U 盘的 UDI 是否还在，就知道 U 盘是否被拨出了。","categories":["2.通讯协议","USB"]},{"title":"RAG检索知识体系","path":"/2024/05/17/3-软件-AI-RAG检索知识体系/","content":"Windows 本地部署 Ollama + AnythingLLM 解读本地文档 构建私有知识库现阶段切入大模型应用落地最合适的方案依然是结合大模型基于 RAG 检索增强来实现知识库的检索和生存。从而构建个人或者企业私有化的本地知识库。 你只需要将本地私有的 PDF、Word 文档和文本文件嵌入到本地向量库，连接上 LLM，然后就可以通过对话、搜索的方式进行回答问题、提供见解，甚至生成摘要。 Ollama 下载地址 https://ollama.com/download Ollama 配置文档 ollama笔记 AnythingLLM 下载地址 https://useanything.com/download AnythingLLM 配置文档 AnythingLLM笔记 AnythingLLM 是 Mintplex Labs Inc. 开发的一个基于 RAG（Retrieval-Augmented Generation）方案构建的开源、高效、可定制的私有知识库解决方案，一款开源 ChatGPT 等效工具，用于在安全的环境中与文档等进行聊天，专为想要使用现有文档进行智能聊天或构建知识库的任何人而构建。 AnythingLLM 能够把各种文档、资料或者内容转换成一种格式，让 LLM（如 ChatGPT）在聊天时可以引用这些内容。然后你就可以用它来和各种文档、内容、资料聊天，支持多个用户同时使用，还可以设置谁能看或改哪些内容。 支持多种 LLM、嵌入器和向量数据库。 Open WebUI 安装地址 https://github.com/v1cc0/open-webui 安装 Ollama 工具后，在命令行输入 ollama pull qwen:4b 下载模型 千问 4b 的模型，也可以下载其他模型 ，支持的模型列表：https://ollama.com/library。 要开始运行 Ollama 的话，只需要在命令行输入 ollama run qwen:4b 就可以使用并访问这个模型了。 接下来我们需要安装向量模型和数据库，在 https://ollama.com/里面搜索 nomic-embed-text ，这个模型可以将文本内容转换成向量数据，里面是模型介绍。 安装模型可以在命令行输入 ollama pull nomic-embed-text 进行下载和安装。 安装 AnythingLLM 工具后打开初始化界面，会进入到配置页面，在 LLM Preference 选项卡中，选择 Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 qwen:4b ，token 填 8192 下一步是配置 Embedding Preference 选项卡中，一样选择 Ollama，然后配置 http://127.0.0.1:11434 、选择运行的大模型 nomic-embed-text ，length 填 512 下一步是配置 Vector Database ，选择默认的 LanceDB ，这是内置的向量数据库，如果想用云端数据库，可以选择 Pinecone 进行云端配置。 后面就是按提示下一步下一步，如果是要加新的工作空间，可以点 new workspace 来增加不同场景下的工作空间。如果需要更换模型，可以点左下角的配置按钮，重新执行上面三步完成配置。 到这里环境已经部署了，这时你已经可以跟大模型进行对话了。 接下来的步骤是对私有知识库的内容进行分析和获取。需要将文档上传到 AnythinLLM，通过 nomic-embed-text 模型进行向量转换，然后存在向量数据库中。最后通过提问，去向量数据库获取内容并分析回答。 Data Connectors 是一种工具，它允许用户将外部数据源无缝集成到他们的 AnythingLLM 工作空间中，而无需编写任何自定义代码或处理复杂的配置。这些经过验证的数据连接器确保与你的 AnythingLLM 实例兼容，提供了一种简单且直接的方式来扩展你的工作空间功能。 以下是一些可用的数据连接器及其功能： GitHub Repo: - 通过这个连接器，你可以一键导入整个公共或私有的 GitHub 仓库到你的 AnythingLLM 工作空间中。 - 访问 GitHub 来获取你想要导入的仓库的链接。 - 这个功能对于开发者和团队来说非常有用，因为它允许他们直接在 AnythingLLM 中管理和查看代码库，跟踪问题和特性请求，以及审查代码。 YouTube Transcript: - 这个连接器允许你从 YouTube 视频链接导入整个视频的转录文本。 - 只需提供 YouTube 视频的链接，就可以轻松获取视频的文字内容。 - 这对于需要分析视频内容、创建视频摘要或者进行视频内容相关的研究的用户来说非常有用。 使用这些数据连接器，你可以快速地将外部数据集成到你的工作流程中，从而提高效率和生产力。例如，如果你正在研究一个特定的编程问题，你可以直接导入相关的 GitHub 仓库来查看代码和文档；或者，如果你需要分析一个教育视频的内容，你可以导入视频的转录文本来进行文本分析。 这些连接器的使用通常涉及到在 AnythingLLM 工作空间中选择相应的连接器，然后按照提示输入必要的信息，如仓库链接或视频链接，之后就可以开始导入数据了。整个过程简单直观，无需专业的编程知识，使得用户可以专注于数据分析和决策，而不是技术细节。 在工作空间页面上有一个上传文档的按钮，点击可以上传我们的文档内容。上传后选中文档，点击 Save and Embed ，等待一段时间，让模型进行向量转换和保存。 然后回到主界面点击工作空间的设置，选择 Chat Setting 选项卡，这里对话模式选择 Query ，这个模式是指只从提供的文档内容进行查找分析，而不要求大语言模型里面提供的信息作答。最后点击 Update workspace 进行更新。 然后就可以进行提问了，以上是本地部署应用的地方，如果你的电脑不太行，可以装 Ollama 部署在云端 GPU 服务器，然后本地安装 AnythingLLM，在选择 URL 上填写云端 Ollama 的地址即可。 配置 LLM这里选择 Ollama 作为后台的服务，URL 这里填写 http://127.0.0.1:11434，也就是前面 Ollama 启动的服务端口，填写后 LLM 模型选择 gemma:2b 配置 Embedding Model这里同样选择 Ollama 作为后台的服务，URL 这里同样填写 http://127.0.0.1:11434，填写后 Embedding Model 选择 nomic-embed-text:latest 配置 Vector DatabaseVector Database 选择默认的第一个 LanceDB 以上三个关键配置完成后，就可以开始使用 AnythingLLM 了。 创建文档库点击 New Workspace 新建文档库，并填写名称点击按钮开始添加文档我们使用的文档是 paul_graham_essay.txt，这个文档也可以从 github 上下载：https://github.com/xinsblog/try-llama-index/blob/master/data/paul_graham_essay.txt 。 添加文档后还要将文档 Move to Workspace然后点击 Save and Embed出现 Workspace updated successfully 就表示配置已经完成 开始测试回到主页面，输入问题 What did the author do in 9th grade?几秒钟后就可以看到 AnythingLLM 给出的回答 第三个工具就是 Open WebUI，此工具可以支持云端部署 web 界面，在浏览器上访问大模型。 前置需要安装 Docker，具体安装步骤可以看 https://github.com/v1cc0/open-webui 上面的安装步骤，这里就不再赘述。 安装完后输入 github 上的指令即可连通 Ollama，并进行使用。","categories":["3.软件","AI"]},{"title":"ollama笔记","path":"/2024/05/17/3-软件-AI-ollama笔记/","content":"支持的模型 https://ollama.com/library 在用的 ollama 模型ollama.exe list ollama run llama3:8b ollama run codellama:7b ollama run qwen:14b ollama run starcoder2:7b ollama run nomic-embed-text NAME SIZE FEATURES codellama:latest 3.8 GB llama3:latest 4.7 GB starcoder2:3b 1.7 GB qwen:4b nomic-embed-text 新建系统环境变量，变量名：OLLAMA_MODELS，变量值中指定模型位置 https://huggingface.co/ https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file Ollama on Linux安装1curl -fsSL https://ollama.com/install.sh | sh Ollama 使用Ollama 大模型联网Python 及库123import requestsimport jsonimport time 定义联网函数需要定义一个联网函数，用于与互联网上的服务器进行通信。这个函数可以发送 HTTP 请求，接收服务器的响应，并返回结果。以下是一个示例： 12345678def connect_to_server(url, data): headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; response = requests.post(url, data=json.dumps(data), headers=headers) if response.status_code == 200: return response.json() else: print(&quot;Error connecting to server:&quot;, response.status_code) return None 配置 Ollama在联网之前，我们需要对 Ollama 大模型进行一些配置。这包括设置模型的参数、训练数据和测试数据等。具体的配置方法取决于你所使用的 Ollama 大模型。以下是一个示例： 12345678910# 设置模型参数model_params = &#123; &quot;learning_rate&quot;: 0.001, &quot;num_epochs&quot;: 100, &quot;batch_size&quot;: 32&#125;# 加载训练数据和测试数据train_data = load_train_data()test_data = load_test_data() 训练模型在配置好 Ollama 大模型后，我们可以开始训练模型。训练过程中，我们可以使用之前定义的联网函数将模型的中间结果上传到服务器上。以下是一个示例： for epoch in range(model_params[&quot;num_epochs&quot;]): # 训练模型 train_model(train_data, model_params) # 将中间结果上传到服务器 url = &quot;http://example.com/upload&quot; data = &#123; &quot;epoch&quot;: epoch, &quot;loss&quot;: get_current_loss(), &quot;accuracy&quot;: get_current_accuracy() &#125; connect_to_server(url, data) 测试模型训练完成后，我们可以使用测试数据对模型进行测试。同样，我们可以使用联网函数将测试结果上传到服务器上。以下是一个示例： 1234567891011# 测试模型test_model(test_data)# 将测试结果上传到服务器url = &quot;http://example.com/upload&quot;data = &#123; &quot;test_loss&quot;: get_test_loss(), &quot;test_accuracy&quot;: get_test_accuracy()&#125;connect_to_server(url, data) 通过以上步骤，我们已经成功地让 Ollama 大模型联网了。在实际应用中，你可能需要根据具体的需求和环境进行调整和优化。希望本文能够帮助你更好地理解和应用 Ollama 大模型的联网功能。","categories":["3.软件","AI"]},{"title":"Git介绍和基本命令","path":"/2024/05/17/3-软件-Git-Git介绍和基本命令/","content":"版本控制版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 Git 是免费、开源的分布式版本控制系统。 集中式版本控制系统集中管理的中央服务器，保存着所有文件的修改历史版本。 协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。 分布式版本控制系统远程仓库同步所有版本信息到本地的每个用户 本地可以查看所有的历史版本信息，偶尔远程更新，查看其他用户修改提交到远程 用户即使离线也可以本地提交，push 推送到远程服务器才需要联网 每个用户都保存了历史版本 工作区域Workspace：电脑本地看到的文件和目录，在 Git 的版本控制下，构成了工作区。 Index&#x2F;Stage：暂存区，一般存放在.git 目录下，即.git&#x2F;index,它又叫待提交更新区，用于临时存放你未提交的改动。执行 git add，这些改动就添加到这个区域。 Repository：本地仓库，你执行 git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 HEAD 指向最新放入仓库的版本。当你执行 git commit，文件改动就到本地仓库。 Remote：远程仓库，云端版本库 文件状态Untracked: 文件未加入到 git 库，未参与版本控制，处于未跟踪状态。通过 git add，可以变为 Staged 状态 Unmodified：文件已经加入 git 库，版本库中的文件快照内容与文件夹中还完全一致。 Unmodified 的文件如果被修改, 就会变为 Modified。如果使用 git remove 移出版本库，则成为 Untracked 文件。 Modified：文件被修改进入 modified 状态，文件这个状态通过 stage 命令可以进入 staged 状态 staged：暂存状态. 执行 git commit 则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为 Unmodified 状态。 正向工作流git 的正向工作流程一般就这样： 从远程仓库拉取文件代码回来；git pull 在工作目录，增删改文件； 把改动的文件放入暂存区；git add 将暂存区的文件提交本地仓库；git commit 将本地仓库的文件推送到远程仓库；git push 常用命令123456789101112131415161718192021222324git clone [url] #克隆远程仓库git add [dir/file]#添加目录/文件到暂存区git commit [--amend] -m [msg] #提交暂存区到仓库区,msg为说明信息(amend用新的commit覆盖提交)git log [--oneline] [-p [file]]#查看提交历史(online精简模式)(p指定文件)git blame #列表方式查看指定文件的提交历史git diff #显示暂存区和工作区的差异git diff #显示暂存区和工作区的差异git diff filepath #filepath路径文件中，工作区与暂存区的比较差异git diff HEAD filepath #工作区与HEAD ( 当前工作分支)的比较差异git diff branchName filepath #当前分支文件与branchName分支的文件的比较差异git diff commitId filepath #与某一次提交的比较差异git status [-s] [--show-stash] #查看当前工作区暂存区变动(-s概要信息)（show-stash显示暂存文件）git pull/fetch #拉取远端代码#git pull = git fetch+ git merge。pull的话，拉取远程分支并与本地分支合并#fetch只是拉远程分支，怎么合并，可以自己再做选择。git pull #拉取远程仓库所有分支更新并合并到本地分支。git pull origin master #将远程master分支合并到当前本地master分支git pull origin master:master #将远程master分支合并到当前本地master分支，冒号后面表示本地分支git fetch --all #拉取所有远端的最新代码git fetch origin master #拉取远程最新master分支代码git push #推送到远端git push origin master #将本地分支的更新全部推送到远程仓库master分支。git push origin -d #删除远程branchname分支git push --tags #推送所有标签 123456789101112131415161718192021222324252627# git rebase`rebase`又称为衍合，是合并的另外一种选择。 `rebase`好处是： 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：`git pull --rebase`# git stash`stash`命令可用于临时保存和恢复修改git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作git stash list 显示保存的工作进度列表git stash pop stash@&#123;num&#125; 恢复工作进度到工作区git stash show ：显示做了哪些改动git stash drop stash@&#123;num&#125; ：删除一条保存的工作进度git stash clear 删除所有缓存的stash。# git reflog显示当前分支的最近几次提交# git blame`git blame filepath`记录了某个文件的更改历史和更改人# git remotegit remote 查看关联的远程仓库的名称git remote add url 添加一个远程仓库git remote show [remote] 显示某个远程仓库的信息","categories":["3.软件","Git"]},{"title":"Git常用操作","path":"/2024/05/17/3-软件-Git-Git常用操作/","content":"项目创建对于网络项目git clone [url] 将 GitHub 中的网络项目复制到本地，只需在修改完之后 commit 即可，然后更新仓库代码，就可同步修改。 对于本地项目首先要创建一个文件夹用以存放文件，然后使用 git init 对进行初始化操作 git status 得到 git 中文件的状态 git add filename 将 filename 文件加入到 git 本地仓库中去（git rm -cached 可移除） git commit -m ‘status’ 表示提交信息（status 表示附加信息） 之后对本地项目进行关联 git remote add origin [url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 关联之后可以向远程仓库提交代码（更新仓库代码） 日常 push1234`git status` #获取状态`git add . `#添加文件到暂存区`git commit -m &quot;20191121 push&quot; `#提交文件`git push origin master `#推送 日常 pull git diff 比较工作目录和 Index 中的代码。 git fetch 当于从远程获取最新版本到本地，不会自动 merge ，比 Git pull 更安全些 git checkout app/model/user.rb 将 user.rb 文件从上一个已提交的版本中更新回来，未提交的工作目录中的内容全部会被覆盖 首次使用配置 ssh ssh-keygen -t rsa ssh -T &lt;git@github.com&gt; 首次使用设置用户 git config (--global) user.name &quot;username&quot; git config (--global) user.email &quot;&lt;username@gmail.com&gt;&quot; 上传&#x2F;下载常用命令 git push origin（仓库名） master（分支） 更新仓库代码（上传） git pull origin（仓库名） master（分支） 更新本地代码（下载） 回退历史版本 git log git reset --hard \\[commit\\_id] git revert \\[commit\\_id] 网络项目 git clone \\[url] git remote add origin \\[url] 添加本地到远程 origin 仓库 git remote -v 查看当前项目有哪些远程仓库 版本情况 git tag 查看版本情况 git tag V1.0 新建版本 git checkout V1.0 切换至版本 V1.0 分支情况 git branch 查看当前分支情况 git checkout a 切换到分支 a git checkout -b a 新建分支 a 并切换到分支 a git branch -d a 删除 a 分支 git merge a 将 a 分支的代码合并到 master 分支上 撤销或回退在 Git 中，撤销和回退是指撤销或回退先前的提交或更改。 简单介绍下 Git 中的撤销和回退操作，以及如何使用它们来管理代码库。 可以把版本库上的提交回退到暂存区，修改记录保留 git reset –-soft [] 可以把版本库上的提交回退到工作区，修改记录保留 git reset –-mixed [] 可以把版本库上的提交彻底回退，修改的记录全部 revert。git reset –-hard reset 和 revert 的区别git reset 和 git revert 的主要区别在于它们对历史记录的处理方式。git reset 会删除历史记录并永久删除更改，而 git revert 会创建一个新的提交来撤销更改并保留历史记录。 git reset 命令会将 HEAD 指针指向指定的 commit，并将暂存区和工作目录恢复到该 commit 的状态。这意味着在执行 git reset 后，之前的更改将不再存在于工作目录和暂存区中。如果您希望永久删除一些更改并且不再需要它们，可以使用 git reset。 git revert 命令会创建一个新的提交来撤销指定的提交。这意味着在执行 git revert 后，之前的更改仍然存在于工作目录和暂存区中，并且您需要提交一个新的撤销提交。如果您想要保留更改历史记录并且不想永久删除更改，可以使用 git revert。 获取 IDgit log 获取到想要回退的 commit_id 撤销&#x2F;回退未提交的更改**(add 之后，commit 之前)** 要撤销未提交的更改，请使用以下命令： git checkout &lt;file-name&gt; 将名为 file-name 的文件恢复到上一个提交的状态。 本地本次的更改也不再保存，恢复到上一个提交 (commit) 的状态 git reset HEAD --file 回退暂存区里的某个文件，回退到当前版本工作区状态 保存工作区的更改，只是撤销 git add 这一步操作 git checkout . 将所有文件恢复到最新提交的状态。请注意，此操作将删除所有未提交的更改。 撤销&#x2F;回退上一个提交**(commit 之后，push 之前)** 撤销上一个提交 git reset HEAD~1 将 HEAD 指针移动到上一个提交。 工作区保留先前的更改，需要重新添加到暂存区 (git add) 回退到上一个提交 git reset --hard HEAD~1 将 HEAD 指针和工作树都重置为上一个提交的状态。 请注意，此操作将删除所有未提交 (commit) 的更改。 撤销&#x2F;回退到特定的提交**(push 之后)** 撤销到特定版本 git revert &lt;commit_id&gt; 这将创建一个新的提交，该提交撤销名为 commit-hash 的提交所做的更改。 本次撤销操作也会作为一次提交 (push) 进行保存 回退到特定版本 git reset --hard &lt;commit_id&gt; 将 HEAD 指针和工作树都重置为名为 commit-hash 的提交的状态。 请注意，此操作将删除所有未提交的更改。 回退完成后，git push -f 强制提交 分支Git 是一个流行的分布式版本控制系统，一般都是存在多个分支的，开发分支，回归测试分支以及主干分支等 在 Git 中，分支是指指向 Git 提交历史中某个特定提交的指针。 每个分支都包含在 Git 提交历史中的一系列提交，这些提交构成了分支的历史记录。 分支在 Git 中非常重要，因为它们允许多个开发人员同时在同一个代码库中工作，而不会相互干扰。 通过创建分支，每个开发人员都可以在自己的分支上进行工作，而不会影响其他人的工作。 这样，开发人员可以在不干扰其他人的情况下，独立地开发和测试新功能，最终将这些更改合并到主分支中。 在 Git 中，分支操作非常简单。以下是一些常用的 Git 分支操作： 创建分支要创建一个新分支，请使用以下命令： git branch &lt;branch-name&gt; 这将创建一个名为 branch-name 的新分支。 注意，此时仍然在当前分支上工作。 git checkout -b &lt;branch-name&gt; 新建一个分支，并且切换到新的分支 branch-name 查看分支要查看所有分支，请使用以下命令： git branch 这将列出所有分支，当前分支将用一个星号标记。 git branch -r 查看所有远程的分支 git branch -a 查看所有远程分支和本地分支 删除分支要删除一个分支，请使用以下命令： git branch -d &lt;branch-name&gt; 这将删除名为的分支。 注意，如果该分支包含未合并的更改，则必须使用 -D 选项而不是 -d 选项来强制删除该分支。 切换分支要切换到另一个分支，请使用以下命令： git checkout &lt;branch-name&gt; 这将使您从当前分支切换到名为 branch-name 的分支。 注意，需要在切换分支之前将所有更改提交或保存。 合并分支要将一个分支合并到另一个分支，请使用以下命令： git merge &lt;branch-name&gt; 将名为 branch-name 的分支合并到当前分支中。 注意，如果两个分支上都有对同一文件的更改，则可能会发生冲突。在这种情况下，需要手动解决冲突并提交更改。 git merge –no-ff origin&#x2F;dev 在当前分支上合并远程分支 dev git merge –abort 终止本次 merge，并回到 merge 前的状态 以上是一些常用的 Git 分支操作。使用这些操作，您可以轻松地创建、切换、合并和删除分支。这些操作使多人协作变得更加容易，因为每个开发人员都可以在自己的分支上进行工作，并将更改合并到主分支中。在实际开发中，分支操作是非常重要的，最好能够熟练掌握并运用这些操作 标签在 Git 中，tag 是用于标记某个特定提交的名称。它类似于一个快照，可以用于标记版本、发布或重要的里程碑。Git 中有两种类型的 tag：轻量级标签和附注标签。 轻量级标签是一个简单的指向某个特定提交的引用，类似于一个分支，但不会随着新的提交而移动。创建轻量级标签的方法很简单，只需在命令行中输入 git tag &lt;tag-name&gt; 即可。例如，git tag v1.0 将创建一个名为 v1.0 的轻量级标签。 附注标签是一个包含标签名称、标签创建者、标签创建日期和标签说明的 Git 对象。它们是 Git 中最常用的标签类型，可以用于发布版本、重要的里程碑和其他重要的提交。创建附注标签的方法是使用 -a 标志和标签名称，然后输入标签说明。例如，git tag -a v1.0 -m &quot;Release version 1.0&quot; 将创建一个名为 v1.0 的附注标签，并将其说明设置为 “Release version 1.0”。 标签可以使用 git push 命令推送到远程存储库中，以便在其他计算机上使用。例如，要将名为 v1.0 的标签推送到远程存储库，可以使用 git push origin v1.0 命令。 1234567git tag #列出所有taggit tag [tag] #新建一个tag在当前commitgit tag [tag] [commit] #新建一个tag在指定commitgit tag -d [tag] #删除本地taggit push origin [tag] #推送tag到远程git show [tag] #查看特定taggit checkout -b [branch] [tag] #新建一个分支，指向某个tag","categories":["3.软件","Git"]},{"title":"Git服务器环境搭建和客户端使用","path":"/2024/05/17/3-软件-Git-Git服务器环境搭建和客户端使用/","content":"服务端安装 git 和 ssh sudo apt-get install git sudo apt-get install openssh-server openssh-client 增加 git 用户并生成文件夹 sudo adduser git sudo mkdir /home/git 创建 ssh 证书认证文件 sudo mkdir /home/git/.ssh sudo touch /home/git/.ssh/authorized_keys 临时修改 authorized_keys 文件的权限 sudo chmod 777 /home/git/.ssh/authorized_keys 把需要访问 git 服务器的客户端公钥 id_rsa.pub的内容复制到 authorized_keys 文件 修改 authorized_keys 文件的权限 1234567sudo chmod 700 /home/gitsudo chmod 700 /home/git/.sshsudo chmod 600 /home/git/authorized_keyssudo chown -R git:git /home/gitsudo chown -R git:git /home/git/.sshsudo chown -R git:git /home/git/.ssh/authorized_keys``` 为了安全考虑禁止登录 git 服务器的 shell，修改 git 的 shell 用 /usr/bin/git-shell 把 /etc/passwd 的 git:x:1004:1004:,,,:/home/git:/bin/bash 改成： git:x:1004:1004:,,,:/home/git:/usr/bin/git-shell 保存 建代码仓库 sudo mkdir /home/Repo #创建仓库的目录 sudo git init --bare /home/Repo/test.git #创建仓库 sudo chown -R git:git /home/Repo/test.git #修改权限为git 以后每创建一个新的仓库，记得最后一步操作: 修改仓库所属用户为 git。 客户端安装 git Linux 环境下 sudo apt-get install git Windows 环境下直接安装 Git安装包 配置连接 通过密钥方式 ssh-keygen -t rsa [-C &quot;你的邮箱地址&quot;] 会生成 id_rsa.pub 文件 添加该公钥到到服务器 Linux 环境下，密钥默认位于 /home/ubuntu/.ssh/id\\_rsa Windows 环境下密钥位于 C:\\Users\\xxx.ssh\\id\\_rsa.pub 通过用户名&#x2F;密码 12git config –global user.name “username”git config –global user.email “username@gmail.com” 在连接 git 时，会需要输入账号密码，直接输入即可 附注：增量备份 -Git 服务器备份使用 crontab 建立每天凌晨 3 点定时触发的任务crontab -e 0 3 * * * * rsync -av -e &quot;ssh -i /path/to/id_rsa&quot; /homt/git/ remote_user@X.X.X.X:~/backup","categories":["3.软件","Git"]},{"title":"版本控制方案","path":"/2024/05/17/3-软件-Git-版本控制方案/","content":"Git 方案1. 仓库创建 仓库创建基于当前的项目，例如备份仪表项目仓库，LSA 项目等 2. 分支创建 项目主分支保存项目代码及文档，负责发布代码 项目开发分支保存项目源码，分支仅管理员可见 项目运行分支保存项目头文件及库文件代码，分支所有人可见 项目人员开发分支基于运行分支创建，仅该人员有权限，该人员开发任务基于该分支进行修改代码 3. 代码提交 各人员代码仅提交在单独分支，提交完成后，由管理员审核后，同步源代码至开发分支 4. 版本回退 SVN 方案","categories":["3.软件","Git"]},{"title":"DRM+EGL 执行错误分析","path":"/2024/05/17/0-平台-Linux-Graphics-DRM-EGL-执行错误分析/","content":"mesa 运行 DRM+EGL 执行错误分析： src\\egl\\main\\egldefines.h 中定义了 EGL_VENDOR #define _EGL_VENDOR_STRING &quot;Mesa Project&quot; 输出结果为 Mesa Project，确认输出无误 https://askubuntu.com/questions/1027168/why-is-opengl-vendor-mesa-project 以上问题项中，该选项显卡为 Nvidia glxinfo tells you what the X11 server you’re running under is using for GL. It doesn’t tell you what an arbitrary program not using X11 might use. 故分析如下： 未正确启用显卡，EGL 采用的是 Mesa 软件渲染，故无法提供正确的 config 证明： 是否有 GLX 或 Wayland 等方案解决该问题","categories":["0.平台","Linux","Graphics"]},{"title":"DRM+GBM+EGL显示","path":"/2024/05/17/0-平台-Linux-Graphics-DRM-GBM-EGL显示/","content":"DRM (Direct Rendering Manager)、GBM (Generic Buffer Manager) 和 EGL (Embedded-System Graphics Library) 组合在一起，是在 Linux 平台上进行图形渲染和硬件加速的常见方式。这些组件一起提供了一个完整的图形渲染栈，允许应用程序直接与图形硬件进行交互。 DRM（Direct Rendering Manager）：DRM 是 Linux 内核中的一个子系统，用于管理图形硬件的驱动程序。它提供了一种通用的接口，允许用户空间程序直接与硬件交互，通过设备文件 /dev/dri/cardX 访问。DRM 提供了诸如模式设置、显示控制、渲染加速等功能。 GBM（Generic Buffer Manager）：GBM 是一个用于管理图形缓冲区的库，通常与 DRM 配合使用。它提供了一种标准的接口，用于分配、管理和操作图形内存。GBM 还提供了与 EGL 和 OpenGL ES 兼容的接口，使应用程序能够使用硬件加速进行渲染。 EGL（Embedded-System Graphics Library）：EGL 是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。EGL 通常与 GBM 和 DRM 一起使用，通过 GBM 提供的接口来创建图形表面，并将其与 OpenGL 或 OpenGL ES 上下文关联起来，实现硬件加速的图形渲染。","categories":["0.平台","Linux","Graphics"]},{"title":"Mesa","path":"/2024/05/17/0-平台-Linux-Graphics-Mesa/","content":"","categories":["0.平台","Linux","Graphics"]},{"title":"OpenGL显示","path":"/2024/05/17/0-平台-Linux-Graphics-OpenGL显示/","content":"GLUGLU（OpenGL Utility Library）是 OpenGL 的一个辅助库，提供了一些更高级的几何计算和对象构造函数，如曲面和体的生成、平移、旋转等，这些函数在处理复杂的几何操作时非常有用。 GLFWGLFW 是一个流行的开源库，主要用于创建和管理图形应用程序中的窗口、OpenGL 或 Vulkan 上下文，以及处理用户输入、定时器等功能。适用于各种图形应用程序的开发，提供了窗口管理、上下文管理、输入处理等功能，使开发者能够专注于图形渲染和应用逻辑的实现。 主要功能： 窗口管理： GLFW 允许开发者创建窗口并对其进行管理，包括调整大小、最小化、最大化、关闭等操作。 上下文管理： 它提供了创建 OpenGL 或 Vulkan 上下文的功能，使得图形渲染程序可以在窗口中绘制图形。 输入处理： GLFW 支持处理用户输入，包括键盘输入、鼠标移动和点击、游戏手柄等。 事件处理： 它允许开发者监听和响应各种事件，如窗口大小改变、键盘按键、鼠标移动等。 监视器管理： GLFW 支持多个显示器的管理，可以获取显示器的分辨率、刷新率等信息。 使用步骤： 初始化： 在程序启动时，调用 GLFW 的初始化函数来初始化库。 创建窗口： 使用 GLFW 的窗口创建函数来创建一个窗口并指定其属性，如大小、标题等。 创建上下文： 使用 GLFW 的上下文创建函数来创建一个 OpenGL 或 Vulkan 上下文。 主循环： 在主循环中轮询事件，并根据事件类型做出相应的处理。 渲染： 在渲染阶段，使用 OpenGL 或 Vulkan 等图形 API 绘制场景。 清理： 在程序结束时，调用 GLFW 的清理函数来释放资源并关闭库。 利用 glfw 监视器 Demo 1234567891011121314151617181920212223242526272829#include &lt;GLFW/glfw3.h&gt; int main() &#123; // 初始化 GLFW if (!glfwInit()) &#123; return -1; &#125; // 获取监视器（显示器）列表 int count; GLFWmonitor** monitors = glfwGetMonitors(&amp;count); // 指定要使用的显示设备索引 int monitor_index = 0; // 设置为你想要的显示设备索引 // 获取指定索引的显示设备 GLFWmonitor* monitor = (monitor_index &lt; count) ? monitors[monitor_index] : NULL; // 获取显示设备的视频模式 const GLFWvidmode* mode = glfwGetVideoMode(monitor); // 创建窗口并指定显示设备 GLFWwindow* window = glfwCreateWindow(mode-&gt;width, mode-&gt;height, &quot;OpenGL Window&quot;, monitor, NULL); if (!window) &#123; glfwTerminate(); return -1; &#125; // 进入主循环 while (!glfwWindowShouldClose(window)) &#123; // 渲染代码 glClear(GL_COLOR_BUFFER_BIT); // ... glfwSwapBuffers(window); glfwPollEvents(); &#125; // 清理资源 glfwDestroyWindow(window); glfwTerminate(); return 0; &#125; GLUT（OpenGL Utility Toolkit） GLUT 是一个跨平台的工具包，用于创建和管理 OpenGL 窗口、处理用户输入等。它提供了一组简单的 API，使得编写基本的 OpenGL 程序变得更加容易。 - GLUT 支持多种操作系统，包括 Windows、Linux 和 macOS。 - 使用 GLUT，你可以很快地编写出一个可以在不同平台上运行的简单 OpenGL 程序，而不必担心平台特定的细节。 - 但是，GLUT 对于创建复杂的图形用户界面（GUI）可能不够灵活，因为它的功能相对有限。 GLUT 是一个跨平台的工具包，用于简化 OpenGL 应用程序的开发。它提供了一组函数，用于创建窗口、处理输入事件、进行基本的图形绘制等，使开发者可以更轻松地编写 OpenGL 应用程序，而无需处理底层的窗口系统的细节。 GLUT 提供了一个相对简单的接口，适用于快速原型设计和简单的图形应用程序。它通常用于学习 OpenGL、编写小型游戏、演示程序等。 GLX（OpenGL Extension to the X Window System） GLX 是 OpenGL 在 X Window System 上的扩展，它允许 OpenGL 应用程序与 X 服务器通信，并在 X 窗口系统中创建 OpenGL 上下文。GLX 提供了一组函数，用于在 X 窗口系统中创建 OpenGL 渲染上下文、管理 OpenGL 窗口和图形渲染等。 GLX 允许 OpenGL 应用程序直接与 X 服务器通信，而不需要借助其他库或工具。它提供了对 OpenGL 的完整支持，可以实现高性能的图形渲染和交互。 GLX 则是 OpenGL 在 X 窗口系统上的扩展，提供了与 X 服务器通信和在 X 窗口系统中创建 OpenGL 渲染上下文的功能。 EGL（Embedded Graphics Library）EGL 是一个用于管理图形渲染上下文的接口，通常用于嵌入式系统和移动设备上。 - EGL 是 OpenGL ES 和 OpenVG 的标准的本地显示系统接口，它提供了与底层窗口系统交互的能力。 - 在 Linux 上，EGL 通常与 GBM（Generic Buffer Manager）或其他图形系统配合使用，如 Wayland。 - 使用 EGL，你可以在嵌入式系统上更好地控制 OpenGL 上下文的创建和管理，以及与窗口系统的交互。","categories":["0.平台","Linux","Graphics"]},{"title":"一些关于Linux显示的说明","path":"/2024/05/17/0-平台-Linux-Graphics-一些关于Linux显示的说明/","content":"modetest 命令 利用 xrandr 在命令行指定输出 xrandr --output HDMI-1 --mode 1920x1080 | ./a.out Mesa 是一个开源的实现了 OpenGL 规范的图形库，它提供了一个 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU（OpenGL Utility Library）通常被视为 OpenGL 的一个独立组件，而不是 OpenGL 的核心部分。 GLU 提供了一些 OpenGL 的辅助功能，比如进行复杂几何运算和对象构造等。虽然 GLU 在许多 OpenGL 实现中都有支持，但它并不是 OpenGL 规范的一部分，因此在某些情况下，OpenGL 实现可能不包括 GLU 或将其作为一个可选组件。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 如果你需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，例如从系统的 OpenGL 安装中获取，或者从其他地方下载 GLU 的实现。然后将 GLU 的头文件包含到你的项目中，并链接 GLU 库以使用 GLU 提供的功能。 Mesa 是一个开源的图形库，提供了 OpenGL 兼容的渲染器和工具库。在 Mesa 生成的头文件中可能不包含 GLU，因为 GLU 不是 OpenGL 规范的一部分。如果需要在使用 Mesa 的项目中使用 GLU，可以通过其他途径获取 GLU 的头文件和库文件，然后将其包含到项目中并链接以使用 GLU 提供的功能。 DRM利用 DRM+GBM+EGL 指定显卡运行代码分析 Mesa GBM（Generic Buffer Management）是一个开源图形缓冲区管理库，用于管理图形内存缓冲区。它是 Mesa 3D 图形库的一部分。GBM 主要用于 Linux 平台，为 Direct Rendering Manager (DRM) 内核子系统提供了一个用户空间 API。它提供了一种统一的接口，用于在 Linux 系统中管理图形缓冲区和设备之间的交互。 在 DRM（Direct Rendering Manager）中，CRTC（Cathode Ray Tube Controller）是一个显示管控制器，负责控制显示管的扫描、同步和刷新操作。它与 Encoder（编码器）和 Connector（连接器）之间存在着一定的联系。 CRTC（Cathode Ray Tube Controller）：CRTC 控制着实际显示设备的扫描和刷新操作。每个 CRTC 都与一个显示管（如液晶显示器或投影仪）相关联，负责生成该显示设备的图像信号。一个显卡可能有多个 CRTC，每个 CRTC 控制一个显示输出。 Encoder（编码器）：Encoder 是 CRTC 输出信号的编码器，将图像数据转换为特定格式的信号以便发送到显示设备。Encoder 通常与特定类型的连接器（如 HDMI、DVI、VGA 等）相关联，以便将图像数据转换为对应的视频信号格式。一个 CRTC 可能与多个 Encoder 相关联，这意味着它可以同时支持多种连接器类型。 Connector（连接器）：Connector 表示与显卡相连的物理显示端口，如 HDMI 接口、DVI 接口等。每个 Connector 对应一个实际的显示输出接口，比如连接显示器或投影仪的端口。每个 Connector 都与一个 Encoder 相关联，该 Encoder 负责将图像数据编码成连接器所需的信号格式。 在 DRM 中，通常的工作流程是： 用户空间（如图形驱动程序）通过 DRM 接口选择一个 Connector，然后创建一个 CRTC 并将其与所选 Connector 关联起来。 然后，用户空间会创建一个 Encoder，并将其与所选的 Connector 关联起来，以便将图像数据编码成正确的视频信号格式。 最后，用户空间会将帧缓冲区（Framebuffer）的内容提交给 CRTC 进行显示。CRTC 接收到帧缓冲区的内容后，会将其发送给相关联的 Encoder，最终显示到连接器所代表的显示设备上。 总之，CRTC 负责控制实际的显示设备，Encoder 负责将图像数据转换为视频信号格式，而 Connector 则表示实际的物理显示端口，它们之间相互关联，共同完成图像显示的任务。 EGL 是 Khronos 渲染 API（如 OpenGL、OpenGL ES 或 OpenVG）与底层本地平台 (窗口) 系统之间的接口。 EGL 主要功能：处理图形上下文管理、Buffer 管理和渲染同步 Display (EGLDisplay): 对实际显示设备&#x2F;窗口系统的抽象； Surface (EGLSurface): 存储图像的内存区域； Context (EGLContext): 存储渲染 API 的状态信息；一套标准的 EGL 绘制流程简介: 获取 EGL Display 对象：eglGetDisplay 初始化与 EGLDisplay 之间的连接：eglInitialize 获取 EGLConfig 对象：eglChooseConfig &#x2F; eglGetconfigs 创建 EGLContext 实例：eglCreateContext 创建 EGLSurface 实例：eglCreatewindowSurface &#x2F; eglCratePbufferSurface 连接 EGLContext 和 EGLSurface 上下文: eglMakeCurrent 使用 OpenGL ES API 绘制图形：gl_* 切换 front buffer 和 back buffer 显示：eglSwapBuffer 断开并释放与 EGLSurface 关联的 EGLContext 对象：eglRelease 删除 EGLSurface 对象 删除 EGLContext 对象 终止与 EGLDisplay 之间的连接 EGL Display 的获取12345EGLDisplay eglGetDisplay(NativeDisplayType native_display)EGLDisplay eglGetPlatformDisplay( EGLenum platform, void * native_display, const EGLAttrib * attrib_list);EGLDisplay eglGetPlatformDisplayEXT( EGLenum platform, void *native_display, const EGLint *attrib_list); eglGetDisplay 会根据现在的环境来决定默认的原生窗口系统，其他两个需要手动指定平台； compositor 运行相当于是裸机运行没有窗口环境，首先必须通过 GBM 或者 EGL_PLATFORM_DEVICE_EXT 扩展这两种方式来获取 EGLDisplay; GBM 概念: 基于 GEM&#x2F;TTM 的驱动对外是没有提供统一的内存管理接口的，至少 Buffer Object 创建销毁等操作是需要自行提供设备相关的即口进行实现的。 用户态没有统一的接口对缓冲区进行管理，这导致某些特定用户态程序的开发的困难，如 wayland compositor。 简单的说 GBM 就是为了实现 DRM(gbm_device) 作为 EGL 的本地平台，创建的句柄可以用来初始化 EGL 和创建渲染目标缓冲区 123456789101112131415// get gdm_device// path = &quot;/dev/dri/renderD128&quot; / &quot;dev/dri/card0&quot;egl_gbm.render_fd = open(path, O_RDWR|O_CLOEXEC);assert(-1 != egl_gbm.render_fd);egl_gbm.gbm_device = gbm_create_device(egl_gbm.render_fd);assert(NULL != egl_gbm.gbm_device);// get display1. egl_gbm.display = eglGetDisplay((EGLNativeDisplayType)egl_gbm.gbm_device);2. egl_gbm.display = eglGetPlatformDisplay(EGL_PLATFORM_GBM_KHR, egl_gbm.gbm_device, NULL);3. egl_gbm.display = eglGetPlatformDisplayEXT(EGL_PLATFORM_GBM_MESA, egl_gbm.gbm_device, NULL);// wlroots里面从严谨性来说，通过GBM获取EGL Display的时候，eglGetPlatformDisplayEXT后面的参数应该是EGL_PLATFORM_GBM_MESA而不是EGL_PLATFORM_GBM_KHR； Wayland：Wayland 是一种图形显示服务器协议，而 DRM 是 Linux 内核中的 Direct Rendering Manager 子系统，用于管理图形硬件驱动程序。在 Wayland 中，客户端应用程序通过 Wayland 协议与显示服务器通信，而 Wayland 服务器通过 DRM 接口与底层的图形硬件交互。 ** GBM**：直接的关系是 DRM 和 GBM，其中 DRM（Direct Rendering Manager）是 Linux 内核中的子系统，用于管理图形硬件的驱动程序，而 GBM（Generic Buffer Manager）是一个用户态库，提供了一个标准接口，用于分配、管理和操作图形内存，通常与 DRM 配合使用。GBM 通常与 DRM（Direct Rendering Manager）配合使用，用于与底层的图形硬件进行交互。应用程序可以使用 GBM 接口来分配和管理图形缓冲区，以便进行硬件加速的图形渲染。GBM 与 Wayland 无直接关联，但在一些特定的场景下，它们可能会一起使用。 GBM 控制 EGL：GBM 通常与 EGL 结合使用，以在硬件加速的图形渲染中创建和管理图形表面（buffers）。EGL（Embedded-System Graphics Library）是一个用于管理图形资源的库，提供了一个通用的接口，用于创建和管理 OpenGL 和 OpenGL ES 上下文、表面和其他相关对象。 EGL 操作 OpenGL API 进行操作：EGL 用于管理 OpenGL 或 OpenGL ES 的上下文和表面，以便应用程序可以使用 OpenGL API 进行图形操作。EGL 提供了一个标准的接口，用于在不同的图形系统中创建和管理 OpenGL 上下文和表面，以便实现跨平台的图形渲染。 确定显卡linux 内核检测到机器上的显卡时，会加载正确的设备驱动程序（位于内核树中的 ./drivers/gpu/drm/&lt;xy&gt;），并提供两个字符设备来控制显卡。 Udev （或您使用的任何热插拔应用程序）将把它们创建为 /dev/dri/card0 /dev/dri/controlID64 我们只需要第一个。 你可以像我们在这里做的那样，在应用程序中硬编码这个路径，但建议使用真正支持热插拔和多座的 libudev。不过，这超出了本文的讨论范围。 如果有多块显卡，可能还会有 /dev/dri/card1、/dev/dri/card2、…… modeset_open(out,node)： 辅助函数用于打开作为 @node 给定的 DRM 设备。 成功时，新的 fd 将存储在 @out 中。如果失败，则返回负错误代码。 打开文件后，我们还要检查 DRM_CAP_DUMB_BUFFER 功能。 如果驱动程序支持该功能，我们就可以创建简单的内存映射缓冲区，而无需任何依赖于驱动程序的代码。 由于我们希望避免使用任何 radeon、nvidia、intel 等驱动程序的特定代码，因此我们在此依赖于 DUMB_BUFFER。 确认显示设备我们需要找到可用的显示设备。 libdrm 提供了 drmModeRes 结构，其中包含所有需要的信息。 通过 drmModeGetResources(fd) 获取， 通过 drmModeFreeResources(res) 释放。 显卡上的物理连接器称为 “connector”。您可以将显示器插入其中并控制显示内容。 我们肯定会对当前使用的 connector 感兴趣，因此，我们需遍历连接器列表，并尝试在每个可用的显示器上显示测试图片。 然而，这并不像听起来那么容易。首先，我们需要检查连接器是否被实际使用（显示器已插入并打开）。 然后，我们需要找到一个能控制该连接器的 CRTC，CRTC 稍后介绍。 然后，我们创建一个帧缓冲器对象 framebuffer object。 准备完成后我们就可以对帧缓冲区进行 mmap()，并在其中绘制测试图片。 然后，我们就可以告诉 DRM 设备在给定的 CRTC 上用选定的连接器显示帧缓冲。 由于我们要在帧缓存上绘制动态图像，因此必须记住所有这些设置。 因此，我们要为成功初始化的每对连接器 +crtc+ 帧缓冲器创建一个 “struct modeset_dev “ 对象，并将其推入全局设备列表。 因此，下一步我们需要实际准备好找到的所有连接器。 这段文字主要讲述了在 Linux 系统中确定显卡和显示设备的过程。以下是关键点的概括： 内核检测与驱动加载：Linux 内核会自动检测并加载适合的显卡驱动程序。 创建字符设备：显卡驱动程序会创建两个字符设备，用于控制显卡。 确认显示设备和 CRTC：通过遍历连接器列表，并尝试在每个可用显示器上显示测试图片，来确定合适的显示设备（CRTC）。 避免完整模式集的设置：在使用 CRTC 之前，需要确保其他设备没有占用该 CRTC。 创建并维护设备列表：为成功初始化的每一对连接器 +CRTC+ 帧缓冲器创建一个 struct modeset_dev 对象，并将其添加到全局设备列表中。modeset_prepare(fd)：该辅助函数将 DRM fd 作为参数，然后简单地从设备中获取资源信息。 如果初始化成功，我们只需将此对象作为新设备添加到全局模式集设备列表中。 资源结构包含所有连接器 ID 的列表。 我们使用辅助函数 drmModeGetConnector() 获取每个连接器的更多信息。 如果连接器当前未使用，也未插入监视器，我们的辅助函数 modeset_setup_dev() 将返回 -ENOENT。 因此，我们可以忽略该连接器。 modeset_find_crtc(fd, res, conn, dev)： 这个小助手试图为给定的连接器找到合适的 CRTC。 实际上，我们必须再引入一个 DRM 对象，以便更清楚地说明这一点：编码器（Encoders）。 编码器可以帮助 CRTC 将帧缓冲器中的数据转换成正确的格式，以便用于所选的连接器。 我们不需要了解更多的转换信息就能使用它。 不过，您必须知道，每个连接器可以使用的编码器都是有限的。 而每个编码器只能与有限的 CRTC 配合使用。 因此，我们要做的就是尝试每一个可用的编码器，并寻找该编码器可以配合使用的 CRTC。 如果我们找到了第一个工作组合，我们就会很高兴，并将其写入 @dev 结构。 但在遍历所有可用编码器之前，我们首先要在一个连接器上尝试当前激活的编码器 +CRTC，以避免出现完整的模式集。 不过，在使用 CRTC 之前，我们必须确保之前设置的其他设备都没有使用该 CRTC。 请记住，每个 CRTC 只能驱动一个连接器！因此，我们只需遍历之前设置的设备的 “modeset_list”，并检查该 CRTC 之前是否未被使用。 否则，我们将继续使用下一个 CRTC&#x2F;编码器组合。","categories":["0.平台","Linux","Graphics"]},{"title":"Ubuntu更换国内源","path":"/2024/05/17/0-平台-Linux-Ubuntu-Ubuntu更换国内源/","content":"Ubuntu 更换国内源Ubuntu 本身的源使用的是国内的源，下载速度比较慢。 清华源地址 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu-ports/ bionic 代表 ubuntu18 备份&#x2F;etc&#x2F;apt&#x2F;sources.list 文件1mv /etc/apt/sources.list /etc/apt/sourses.list.backup 新建&#x2F;etc&#x2F;apt&#x2F;sources.list 文件并添加以下内容1234567891011#163源deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 更改完成之后执行一下 apt update 命令 其他的一些 apt 命令12345678910111213141516sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 其他几个国内的源：1234567891011121314151617181920212223242526272829303132333435#中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse#阿里云源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse#清华源deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse","categories":["0.平台","Linux","Ubuntu"]},{"title":"终端","path":"/2024/05/17/0-平台-Linux-其他-终端/","content":"终端一个基于文本的交互界面 快捷键 打开命令行终端 Ctrl+Alt+t 放大终端 Ctrl Shirft + 缩小终端 Ctrl - 终端提示符含义lemonade@ubuntu:~$ 对应用户名 (lemonade)@主机名 (ubuntu): 工作目录 (~) 提示符 ($) ~：家目录 $: 普通用户#: 超级用户 (root) 命令— 在终端中用于告诉计算机去执行一个动作 参数— 选项— 选项通常用一个连接号（-）或两个连接号（--）来划分 常用 ls: 列出当前目录内容 cd ~: 进入当前用户的家目录 ./ 当前目录 (可省略) ../ 上一层目录 ../../ 上一层的上一层 文件操作指令 mkdir 创建文件夹 mkdir mydir touch 创建空文件 touch myfile rmdir 删除一个空文件夹 rm 删除一个文件或文件夹,默认删除文件 rm -r 删除文件夹 打印定向指令 echo 打印一串字符 echo hello world &gt; 输出重定向&#x2F;指定输出的目标文件 &gt;&gt; 向指定文件中追加内容 cat 读文件内容并打印 cat readme root&amp;sudo sudo passwd 通过普通用户修改超级用户 (root) 的密码. su root 切换用户为 root 用户 (超级用户) su lemonade 切换为 lemonade 用户. sudo 用普通用户权限执行 root 的功能 普通用户权限执行 root 的功能需注意用户环境下的环境变量和 root 用户环境的下环境变量是否一致 移动拷贝指令 mv 移动命令 mv source dest``mv source dir cp 拷贝命令 man 用户帮助手册 man ls ls [options]... [file]... options 选项或参数 file 目标文件或文件夹 [] 可选标志 ... 多参机制 改变权值的命令 chmod 777 readme.sh 所有用户可读可写可执行 文件类型: - ：普通文件d : 文件夹&#x2F;目录l : 链接 (快捷方式)s : 网络套接字p: 管道b : 块设备, 磁盘 c : 字符设备, 键盘 关机 halt 关机 reboot 重启 sudo shutdown -h now 加上关机时间 sudo shutdown -h +1 &quot;See You la la&quot; 加上关机备注","categories":["0.平台","Linux","其他"]},{"title":"加密方案","path":"/2024/05/17/0-平台-Linux-加密-加密方案/","content":"3568 应用程序及主板可执行文件加密在针对可执行文件的加壳加密和解密中，通常会使用以下步骤： 加壳加密： 选择壳程序： 选择一个用于加壳的程序，通常是一个小型的程序，它可以将原始的 ELF 文件嵌入到自身中，并添加解密逻辑。 嵌入并加密原始 ELF 文件： 将原始的 ELF 可执行文件嵌入到壳程序中，并对嵌入的原始 ELF 文件进行加密处理，使用加密算法对文件内容进行加密，确保只有正确的解密密钥可以解密文件。 生成加密后的文件： 将加密后的 ELF 文件保存为一个新的可执行文件，这个文件是经过加密处理的。 解密： 执行加密后的文件： 执行加密后的 ELF 文件，这个文件是壳程序，它包含了解密逻辑。 解密逻辑： 壳程序在运行时会对自身进行解密，并将嵌入的原始 ELF 文件解密出来。 还原原始 ELF 文件： 解密后的原始 ELF 文件会被还原到内存中，然后壳程序会将控制权转移到原始 ELF 文件，使得原始程序可以正常执行。 本文档实现的加密方式主要分为以下两个模块： 内核空间下，基于内核密钥保留服务的 ELF 文件解密并交付内核正常运行模块 用户空间下，基于非对称加密算法的 ELF 文件内容加密，主要针对 ELF Header 模块【可选加密 program header 和 section header】 1. 应用程序加壳1.1 ELF 文件格式介绍应用程序加壳模块对应用程序进行加密操作，主要针对以下模块进行加密操作 ELF header Program header table 【可选】 Section header table 【可选】 其中 ELF header 指明了 ELF 文件的整体信息，如 ELF 文件的 magic value、类型、版本、目标机器等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#define EI_NIDENT (16)typedef struct&#123; unsigned char\te_ident[EI_NIDENT];\t/* Magic number and other info */ Elf_Half e_type; /* Object file type */ Elf_Half e_machine; /* Architecture */ Elf_Word e_version; /* Object file version 文件版本,目前常见的ELF文件版本均为EV_CURRENT(1)*/ Elf_Addr e_entry; /* Entry point virtual address 入口虚拟地址。*/ Elf_Off e_phoff; /* Program header table file offset 段表文件偏移。*/ Elf_Off e_shoff; /* Section header table file offset 节表文件偏移。*/ Elf_Word e_flags; /* Processor-specific flags 处理器特定的标志，一般为0。*/ Elf_Half e_ehsize; /* ELF header size in bytes Elf_Header的大小（字节）*/ Elf_Half e_phentsize;\t/* Program header table entry size 段头的大小（字节）。*/ Elf_Half e_phnum; /* Program header table entry count 段的数量。*/ Elf_Half e_shentsize;\t/* Section header table entry size 节头的大小（字节）。*/ Elf_Half e_shnum; /* Section header table entry count 字的数量。*/ Elf_Half e_shstrndx; /* Section header string table index 节字符串表的节索引*/&#125; Elf_Ehdr;[e_ident]包含了Maigc Number和其它信息，共16字节。\t0~3：前4字节为Magic Number，固定为ELFMAG。4（EI_CLASS）：ELFCLASS32代表是32位ELF，ELFCLASS64 代表64位ELF。5（EI_DATA）：ELFDATA2LSB代表小端，ELFDATA2MSB代表大端。6（EI_VERSION）：固定为EV_CURRENT（1）。7（EI_OSABI）：操作系统ABI标识（实际未使用）。8（EI_ABIVERSION）：ABI版本（实际 未使用）。9~15：对齐填充，无实际意义。[e_type]ELF的文件类型，定义如下：ET_REL 可重定位文 件（如目标文件）ET_EXEC 可执行文件（可直接执行的文件）DT_DYN 共享目标文件（如SO库）DT_CORE Core文件（吐核文件）注：GCC使用编译选项 -pie 编译的可执行文件实际 也是DT_DYN类型。[e_machine]处理器架构类型，常见的定义如下：EM_386 Intel 386架构（实际上就是32位的x86架构）EM_X86_64\tAmd x86-64架构EM_ARM ARM架构（包括thumb,thumb2）EM_AARCH64\tARM64架构 另外，ELF header 还指明了 program header table 与 section header table 两个表在文件中的偏移位置、条目个数、条目大小。 这两个表的位置和长度随着 section&#x2F;segment 的个数而变化，而 ELF header 总是位于文件最开头，且长度固定。 如果想要访问 program header table 和 section header table 中的信息，必须通过 ELF header 来找到它们在文件中的确切位置。 Program header table 主要描述了将哪一个或哪几个 section 组织为一个 segment，以及各个 segment 的描述信息。 ELF 程序头是对二进制文件中段的描述，是程序装载必需的一部分。段（segment）是在内核装载时被解析的，描述了磁盘上可执行文件的内存布局以及如何映射到内存中。可以通过引用原始 ELF 头中名为 e_phoff（程序头表偏移量）的偏移量来得到程序头表， Section header table 描述了 ELF 文件中所有的 section，以及每个 section 的类型、长度等描述信息。 节，不是段。段是程序执行的必要组成部分，在每个段中，会有代码或者数据被划分为不同的节。节头表是对这些节的位置和大小的描述，主要用于链接和调试。节头对于程序的执行来说不是必需的，没有节头表，程序仍可以正常执行，因为节头表没有对程序的内存布局进行描述，对程序内存布局的描述是程序头表的任务。节头是对程序头的补充。readelf –l 命令可以显示一个段对应有哪些节，可以很直观地看到节和段之间的关系。 Section header table 中并不存储每个 section 的名称。所有 section 的名称全部存储在一个名为 section header string table 的 section 中，名称之间用 \\0 分隔。在 ELF header 中，记录了该 section 在 section header table 中的索引。 1.2 功能模块针对以上理解，加壳程序的功能有以下： 针对 ELF 文件，通过字段异或&#x2F;【RSA 加密(可选)】的方式进行覆写 ELF header&#x2F;【Program&#x2F;Section header table(可选)】 ELF 开头修改为 HMAVIC【加密方式字段】【加密内容字段】ELF 【可选】单独进行末尾追加签名，确认为 HMAVIC 程序 1.3 代码实现1234#define SIGN_OFFSET 9#define SIGN_CONTENT &quot;HMAVIC&quot;#define SIGN_LENGTH 6 调试 123xxd -l 100 a.runreadelf -h a.run 2. 内核密钥保留服务2.1 密钥配置文件配置文件内容 1234567891011121314151617181920212223242526272829303132#表示这个配置文件包含一系列的请求信息，用于生成证书请求[ req ]# 指定生成的 RSA 密钥长度为 2048 位default_bits = 2048# 指定用于请求的分辨名 (DN)，在 [ req_distinguished_name ] 部分中定义distinguished_name = req_distinguished_name# 禁用交互式提示，生成证书时不会要求用户输入prompt = no# 指定字符编码为 UTF-8string_mask = utf8only# 指定用于 X.509 扩展的配置，定义在 [ myexts ] 部分x509_extensions = myexts# 定义了请求的分辨名信息，包括组织 (O)、通用名 (CN) 和电子邮件地址 (emailAddress)[ req_distinguished_name ]# 指定组织名为hmavicO = hmavic# 指定通用名为 verification for hmavicCN = verification for hmavic# 指定电子邮件地址emailAddress = liuluhua7@gmail.com# 定义了 X.509 扩展信息，包括基本约束 (basicConstraints)、密钥用途 (keyUsage)、主题密钥标识符 (subjectKeyIdentifier) 和颁发者密钥标识符 (authorityKeyIdentifier)[ myexts ]# 指定证书不是 CA 证书，即不具有颁发其他证书的权限basicConstraints=critical,CA:FALSE# 指定密钥用途为数字签名keyUsage=digitalSignature# 指定使用 SHA-1 哈希算法生成主题密钥标识符subjectKeyIdentifier=hash# 指定使用密钥标识符生成颁发者密钥标识符authorityKeyIdentifier=keyid 生成密钥并导入证书 1openssl req -new -nodes -utf8 -sha256 -days 36500 -batch -x509 -config x509.hm.genkey -outform PEM -out kernel_key.pem -keyout kernel_key.pem 使用 OpenSSL 工具生成一个配置信息由 x509.hm.genkey 指定的自签名的 X.509 格式证书。 以下是命令中每个选项的解释： openssl req：使用 OpenSSL 工具中的 req 子命令，用于处理证书请求和生成证书。-new：指定创建一个新的证书请求。-nodes：不加密生成的私钥，即不设置私钥密码。-utf8：指定使用 UTF-8 编码。-sha256：指定使用 SHA-256 哈希算法生成证书签名。-days 36500：指定证书的有效期为 36500 天-batch：在生成证书请求时不会提示用户输入任何信息，而是使用配置文件中指定的默认值。-x509：指定生成自签名的 X.509 格式证书，而不是生成证书请求。-config x509.genkey：指定使用配置文件 x509.genkey 中的配置信息来生成证书。-outform PEM：指定输出的证书格式为 PEM 格式。-out kernel_key.pem：指定输出的证书文件名为 kernel_key.pem。-keyout kernel_key.pem：指定输出的私钥文件名为 kernel_key.pem，因为在本例中私钥和证书是一对的。 2.2 编译内核修改 kernel/arch/arm64/configs/OK3568-C-linux_defconfig 在文件最后增加以下内容： 12345## Certificates for signature checking#CONFIG_SYSTEM_TRUSTED_KEYRING=yCONFIG_SYSTEM_TRUSTED_KEYS=&quot;certs/kernel_key.pem&quot; 进入顶层目录执行 ./build.sh kernel 在编译过程中，应该可以看到如下信息： 12345...EXTRACT_CERTS &lt;PATH_TO_CERT&gt;/kernel_key.pemAS certs/system_certificates.oAR certs/built-in.o... 待内核编译完成，烧录内核至开发板，查看 proc 文件系统中的 /proc/keys。如果能够看到自行生成的密钥，那么说明该密钥已经被放置于内核的系统密钥环中。 3. 内核模块脱壳并运行3.1 功能模块针对加壳进行编写脱壳模块功能如下： 内核模块安装时进行 RSA 核验，核验通过则安装模块，否则卸载模块 注入到内核 ELF 运行之前，对 HMAVIC 开头的 ELF 进行拦截 根据加密方式和内容进行解密处理，解密完成后覆写内容交由 Linux 内核处理 【可选】针对未签名程序，拒绝执行 3.2 将解密模块嵌入内核中我们为 ELF 的签名与验证生成了一对 RSA 公私钥，将公私钥以符合 X.509 标准的方式导入到一个 PEM 编码的文件中。通过上述机制，可以将文件中的公钥证书编译到内核的系统密钥环上。这样，在 ELF 签名验证模块 中，可以通过使用系统密钥环中的公钥证书，对 ELF 文件中的签名信息进行验证。 首先，我们对 Linux 内核中已有的 内核模块签名 验证机制的代码进行了分析。在内核源代码目录 certs/system_keyring.c 中，定义了内核内置的受信密钥： certs&#x2F;system_keyring.c 复制 1static struct key *builtin_trusted_keys; 但由于这个变量没有被声明为 extern，因此无法在其它内核代码中直接引用这个变量。但是在这个源文件中，开放了 verify_pkcs7_signature() 函数，使得其它内核代码能够通过这个函数，间接使用内置密钥环的签名验证功能： certs&#x2F;system_keyring.c 复制 12345678910111213141516171819202122/** * verify_pkcs7_signature - Verify a PKCS#7-based signature on system data. * @data: The data to be verified (NULL if expecting internal data). * @len: Size of @data. * @raw_pkcs7: The PKCS#7 message that is the signature. * @pkcs7_len: The size of @raw_pkcs7. * @trusted_keys: Trusted keys to use (NULL for builtin trusted keys only, * (void *)1UL for all trusted keys). * @usage: The use to which the key is being put. * @view_content: Callback to gain access to content. * @ctx: Context for callback. */int verify_pkcs7_signature(const void *data, size_t len, const void *raw_pkcs7, size_t pkcs7_len, struct key *trusted_keys, enum key_being_used_for usage, int (*view_content)(void *ctx, const void *data, size_t len, size_t asn1hdrlen), void *ctx)&#123;... 在内核代码中，通过 #include &lt;linux/verification.h&gt; 使用该函数时，输入 签名数据 与 被签名数据 的 缓冲区内存地址 和 缓冲区长度，就能够使用内置密钥完成签名认证。因此，ELF 签名验证模块 只要能够从 ELF 文件中正确提取 PKCS #7 格式的签名数据，以及签名保护的目标数据，就可以通过这个函数验证数字签名是否正确。 模块代码 123456789101112131415161718192021222324252627```编译 Makefile```makefileifneq ($(KERNELRELEASE),)obj-m := binfmt_elf_signature_verification.oelse# KDIR := ../#KDIR := /lib/modules/$(shell uname -r)/buildKDIR := /home/forlinx/Desktop/OK3568-linux-source/kernelall: $(MAKE) -C $(KDIR) M=$(PWD) modulesclean: $(RM) *.ko $(RM) *.o $(RM) *.mod* $(RM) *.symvers $(RM) *.order $(RM) .*.mk $(RM) .*.cmd $(RM) -r .tmp_versionsendif 执行 1make ARCH=arm64 CROSS_COMPILE=/home/forlinx/Desktop/OK3568-linux-source/buildroot/output/OK3568/host/bin/aarch64-buildroot-linux-gnu- 参考Linux ELF 文件数据完整性保护系统 附录 A OpenSSL 进行密钥生成验证A1 私钥1openssl genpkey -algorithm RSA -out private_key.pem -aes256 将生成一个 AES256 加密的 RSA 私钥，并将其保存到名为 private_key.pem 的文件中。 生成时需要密码，密码为 HmAvic@123 A2 公钥1openssl rsa -in private_key.pem -pubout -out public_key.pem 将从私钥文件 private_key.pem 中提取公钥，并将其保存到名为 public_key.pem 的文件中。 A3 签名1openssl dgst -sha256 -sign private_key.pem -out signature.bin your_elf_file 使用 SHA-256 算法对 your_elf_file 进行签名，并将签名结果保存到 signature.bin 文件中。 A4 签名认证1openssl dgst -sha256 -verify public_key.pem -signature signature.bin your_elf_file 使用公钥 public_key.pem 验证 signature.bin 文件中的签名是否与 your_elf_file 匹配。 A5 签名和认证代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143&gt;#include &lt;stdio.h&gt;&gt;#include &lt;stdlib.h&gt;&gt;#include &lt;openssl/rsa.h&gt;&gt;#include &lt;openssl/pem.h&gt;&gt;#include &lt;openssl/sha.h&gt;&gt;#define BUF_SIZE 1024&gt;// 函数声明&gt;int sign_file(const char* file_path, const char* private_key_path, const char* signature_path);&gt;int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path);&gt;int main() &#123; const char* file_path = &quot;your_elf_file&quot;; const char* private_key_path = &quot;private_key.pem&quot;; const char* public_key_path = &quot;public_key.pem&quot;; const char* signature_path = &quot;signature.bin&quot;; // 签名文件 if (sign_file(file_path, private_key_path, signature_path) != 0) &#123; fprintf(stderr, &quot;Failed to sign file. &quot;); return 1; &#125; printf(&quot;File signed successfully. &quot;); // 验证签名 if (verify_signature(file_path, signature_path, public_key_path) != 0) &#123; fprintf(stderr, &quot;Signature verification failed. &quot;); return 1; &#125; printf(&quot;Signature verified successfully. &quot;); return 0;&gt;&#125;&gt;int sign_file(const char* file_path, const char* private_key_path, const char* signature_path) &#123; FILE* file = fopen(file_path, &quot;rb&quot;); if (!file) &#123; fprintf(stderr, &quot;Failed to open file. &quot;); return 1; &#125; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(&amp;sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) &#123; SHA256_Update(&amp;sha256, buffer, bytes_read); &#125; unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, &amp;sha256); fclose(file); // 加载私钥 FILE* private_key_file = fopen(private_key_path, &quot;rb&quot;); if (!private_key_file) &#123; fprintf(stderr, &quot;Failed to open private key file. &quot;); return 1; &#125; RSA* rsa = PEM_read_RSAPrivateKey(private_key_file, NULL, NULL, NULL); fclose(private_key_file); if (!rsa) &#123; fprintf(stderr, &quot;Failed to load private key. &quot;); return 1; &#125; // 对 ELF 文件哈希进行签名 unsigned char signature[BUF_SIZE]; unsigned int signature_length; if (!RSA_sign(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, &amp;signature_length, rsa)) &#123; fprintf(stderr, &quot;Failed to sign hash. &quot;); RSA_free(rsa); return 1; &#125; // 将签名写入文件 FILE* signature_file = fopen(signature_path, &quot;wb&quot;); if (!signature_file) &#123; fprintf(stderr, &quot;Failed to create signature file. &quot;); RSA_free(rsa); return 1; &#125; fwrite(signature, 1, signature_length, signature_file); fclose(signature_file); RSA_free(rsa); return 0;&gt;&#125;&gt;int verify_signature(const char* file_path, const char* signature_path, const char* public_key_path) &#123; FILE* file = fopen(file_path, &quot;rb&quot;); if (!file) &#123; fprintf(stderr, &quot;Failed to open file. &quot;); return 1; &#125; // 读取 ELF 文件内容 unsigned char buffer[BUF_SIZE]; size_t bytes_read; SHA256_CTX sha256; SHA256_Init(&amp;sha256); while ((bytes_read = fread(buffer, 1, BUF_SIZE, file)) != 0) &#123; SHA256_Update(&amp;sha256, buffer, bytes_read); &#125; unsigned char hash[SHA256_DIGEST_LENGTH]; SHA256_Final(hash, &amp;sha256); fclose(file); // 加载公钥 FILE* public_key_file = fopen(public_key_path, &quot;rb&quot;); if (!public_key_file) &#123; fprintf(stderr, &quot;Failed to open public key file. &quot;); return 1; &#125; RSA* rsa = PEM_read_RSA_PUBKEY(public_key_file, NULL, NULL, NULL); fclose(public_key_file); if (!rsa) &#123; fprintf(stderr, &quot;Failed to load public key. &quot;); return 1; &#125; // 读取签名文件 FILE* signature_file = fopen(signature_path, &quot;rb&quot;); if (!signature_file) &#123; fprintf(stderr, &quot;Failed to open signature file. &quot;); RSA_free(rsa); return 1; &#125; unsigned char signature[BUF_SIZE]; size_t signature_length = fread(signature, 1, BUF_SIZE, signature_file); fclose(signature_file); // 验证签名 if (RSA_verify(NID_sha256, hash, SHA256_DIGEST_LENGTH, signature, signature_length, rsa) != 1) &#123; fprintf(stderr, &quot;Signature verification failed. &quot;); RSA_free(rsa); return 1; &#125; RSA_free(rsa); return 0;&gt;&#125; 附录 B 如何实现对程序的加解密公钥加密，私钥解密 方式一：不同设备内核烧录不同的私钥进行解密 方式二：不同设备内核烧录相同的私钥进行解密 B1 生成 RSA 密钥对首先，你需要生成 RSA 密钥对，包括私钥和公钥。下面是一个示例命令来生成 RSA 密钥对： 12openssl genpkey -algorithm RSA -out private_key.pem -aes256openssl rsa -pubout -in private_key.pem -out public_key.pem 这个命令会生成一个 RSA 私钥文件 private_key.pem，并在生成的同时使用 AES256 算法对私钥进行加密保护。然后从私钥中提取公钥，并保存到 public_key.pem 文件中。 B2 使用 RSA 加密文件要使用 RSA 公钥加密文件，你可以执行以下命令： 1openssl rsautl -encrypt -pubin -inkey public_key.pem -in plaintext.txt -out encrypted.txt 这个命令会使用公钥文件 public_key.pem 对明文文件 plaintext.txt 进行加密，并将加密后的结果输出到 encrypted.txt 文件中。 B3 使用 RSA 解密文件要使用 RSA 私钥解密文件，你可以执行以下命令： 1openssl rsautl -decrypt -inkey private_key.pem -in encrypted.txt -out decrypted.txt 这个命令会使用私钥文件 private_key.pem 对加密文件 encrypted.txt 进行解密，并将解密后的结果输出到 decrypted.txt 文件中。 如何向内核中添加密钥 如何在程序中读取密钥","categories":["0.平台","Linux","加密"]},{"title":"博客Hexo建设","path":"/2024/05/17/0-平台-服务器-博客Hexo建设/","content":"√ 博客框架采用 Hexo √ 部署到 GitHubPages（） √ 部署到 Vercel（GitHub Publish） × 通过 Netlify 部署和构建 √ 利用 Obsidian Digital Garden&#x2F;Flowershow 插件在 Vercel 上将笔记内容部署为 Obsidian 数字花园 部署流程 创建 GitHub 发布仓库 GitHub仓库部署 创建 GitHub 源码仓库，并在仓库中部署 Hexo 在源码仓库中创建工作流，工作流主要完成任务是在接收到同步后，完成以下几个动作 GitHub Actions 构建静态页面生成 public 文件夹，在构建之前需要调用 hexo 插件自动生成 category 信息 将 public 文件夹拷贝至发布仓库 确定 Hexo 仓库部署在 GitHub 还是本地如果部署在 GitHub则需要整个仓库拉取到 obsidian，主要显示 post 下文件，需要通过 github actions 进行发布管理 优点：本地不需要 Hexo 环境，直接提交后自动构建页面 缺点：所有源码都在 Github 且仓库必须公开 如果部署在本地需要在本地生成静态网页，之后将静态网页通过 publisher 发布 public 文件夹到 github 仓库 优点：仓库可以不开源 缺点：本地需要具有 Hexo 环境，且需要在本地生成静态网页 两个仓库都在 Github是否可以实现，编辑完成后，github 从源码仓库复制到发布仓库？ 源码仓库闭源，同步笔记到源码仓库后，源码仓库通过 actions 时触发同步到发布仓库，更新发布仓库页面 扩展：三仓库管理，Markdown 仓库只用于编辑 Markdown 文件，同步后触发 actions，同步到源码仓库中的 post，源码仓库接受到 push 后，触发 actions 生成静态页面 public，public 生成完成后拷贝 public 到发布仓库利用 actions，可以实现，感觉没啥必要，太过复杂了，源码仓库 + 发布仓库基本就可以了 两仓库实现步骤可以实现两个仓库都在 GitHub，并通过 GitHub Actions 在源码仓库进行编译，编译完成后自动将源码仓库的静态页面内容复制到发布仓库，实现自动化的发布管理。 将 Hexo 的源码仓库设置在 GitHub 上，你可以在这个仓库中编辑和管理 Hexo 的源代码、主题和文章。 创建另一个 GitHub 仓库作为发布仓库，用于存放生成的静态网页。你可以将 Hexo 生成的 public 文件夹的内容推送到这个仓库中。该仓库利用 GitHub Pages，直接通过.github.io 进行访问 在 Hexo 源码仓库中设置一个 GitHub Actions workflow，以便在每次提交或推送时自动将更新的内容复制到发布仓库。 需要配置 GitHub 的 ssh，可以有权限访问两个仓库 需要配置发布仓库的 deploy key，可以有权限写入发布仓库 域名获取 GitHub 二级域名 GitHubPages liuluhua.github.io 二级域名 https://freedomain.one/ linglu.work.gd 二级可穿透域名 解析包括添加三条解析记录 192.30.252.153 是 GitHub 的地址，你也可以 ping 你的 http:&#x2F;&#x2F;你的用户名.github.io 的 ip 地址，填入进去。 第三个记录类型是 CNAME，CNAME 的记录值是：http:&#x2F;&#x2F;你的用户名.github.io 这里千万别弄错了。 绑定 Github 域名，登录 GitHub，进入之前创建的仓库，点击 settings，设置 Custom domain，输入你的域名 图床GitHub 图床 创建一个 public 仓库 进入 Settings-Developer Settings-Personal access tokens (classic) 生成 token 设置自定义域名为 https://raw.staticdn.net/liuluhua/liuluhua.github.io/ImageBed PicGo介绍PicGo 是一个开源的图片上传工具，主要用于将本地图片上传到各种图片托管服务，并生成图片链接。它提供了图形界面和命令行两种方式来使用。 用途图片托管：将本地图片上传到图片托管服务，如 GitHub 等。图片压缩：在上传图片之前，可以选择对图片进行压缩以减小图片文件大小，节省存储空间和加快图片加载速度。图片管理：通过 PicGo 上传的图片可以在相应的托管服务上进行管理，包括查看、删除等操作。图片链接生成：上传成功后，PicGo 会生成图片链接，方便在博客、论坛等地方直接使用图片。 配置 Github 图床图床设计选择 GitHub，输入在 GitHub 的仓库名，分支名和 token 即可 设置 GitHub 为默认图床 设置图床参数 设定存储路径 插件 super-prefix安装 super prefix 插件，将图片存储时按照时间分类存储 配置文件路径插件 需要在 PicGo 设置中关闭时间戳重命名 /img/2019/11/18/20191118005858.jpeg 参数 建议值 说明 prefixFormat YYYY/MM/DD/ 文件名个性前缀格式 (以&#x2F;结尾) fileFormat YYYYMMDDHHmmss 文件名个性格式 GitHubGithub Pages 部署GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。 创建 GitHub 账号，并创建一个基于用户名.github.io 的仓库 使用 GitHub Pages 进行部署，所建仓库必须取名为“GitHub 用户名.github.io” 勾选“Add a README file”，不然后面会看不到 GitHub Pages 域名和部署分支 仓库需要创建为公有仓库，即 public 仓库大小限制为 创建完成后 GitHub Pages 给我们提供了一个格式为 https://GitHub用户名.github.io 的免费域名，并且相应的网站是从该仓库的 main&#x2F;master 分支构建得到的 自定义域名，在 GitHub 仓库 Settings-Pages-Custom domain 添加自己的域名 Git HookGit hook 是一种机制，允许在特定的 Git 事件发生时触发自定义的脚本或命令。这些事件可以包括提交 (commit)、推送 (push)、合并 (merge) 等。使用 Git hook，你可以在这些事件发生时执行自定义的操作，比如运行测试、格式化代码、触发构建等。Git 提供了一系列的预定义钩子，你可以将自己的脚本绑定到这些钩子上，或者创建自定义的钩子。 GitHub ActionsGitHub Actions 是 GitHub 提供的一项持续集成（CI）和持续部署（CD）服务，允许开发者自动化软件开发工作流程。通过 GitHub Actions，你可以在 GitHub 上运行自定义的代码（称为动作），以响应存储库中的事件，例如推送代码、创建拉取请求等。 一个 GitHub Actions 的核心概念是 workflow（工作流），它是一系列由动作组成的自定义任务，这些任务可以在特定的事件触发时自动执行。每个 workflow 都定义了一系列步骤，每个步骤又包含一个或多个动作。workflow 可以用 YAML 格式定义，并存储在存储库的 .github/workflows 目录中。 通过 GitHub Actions，实现将代码同步 GitHub 之后，由 GitHub Actions 执行页面的发布。 执行 GitHub Actions，在需要执行的储存库中前往 Settings &gt; Pages &gt; Source，并将 Source 改为 GitHub Actions。 在储存库中建立 .github/workflows/blogPublish.yml 并写入内容 环境变量配置在 Settings –&gt; Secrets and Variables –&gt; Actions 里面,配置后，可以在 actions 里面通过 $&#123;&#123; secrets.dingtalk_secret &#125;&#125; 调用到对应的数据 文章更新时间问题使用 Github Actions 造成的文章更新时间问题参考原文： https://mrseawave.github.io/blogs/articles/2021/01/07/ci-hexo-update-time/ 当使用 Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。对于 Github Actions 可以使用命令在构建之前进行处理 123456jobs: deploy_gh_pages: steps: - name: Restore file modification time run: | git ls-files -z | while read -d &#x27;&#x27; path; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$path&quot;)&quot; &quot;$path&quot;; done 如果 git 命令不好用， 也可以使用 find 命令 1find source/_posts -name &#x27;*.md&#x27; | while read file; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$file&quot;)&quot; &quot;$file&quot;; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果 github actions 中使用 actions&#x2F;checkout@v2，请设定它的参数 fetch-depth: 0，因为 0 表示获取所有分支和标签的所有历史记录。默认值为 1 gitignore在 Git 仓库的根目录下编辑有.gitignore 文件，该文件中定义了一些不需要上传至 GitHub 的内容，列在该文件中的文件或文件夹将会被忽略，不在上传 Hexo 忽略文件12345678.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_multiconfig.yml Obsidian 忽略文件1.obsidian/workspace .obsidian 文件本身是可以同步的，当前存储库的插件以及相关的配置都会下载在这个文件夹中，因此将其同步到 git 记录中也是非常有用的，假如你切换设备就不需要重新为当前的存储库重新配置 Obsidian 了。 GitHub 仓库部署源码仓库部署 创建一个私有仓库，此处我创建一个 BlogDeploy 仓库，仓库拉取到本地后，在仓库中部署 Hexo使用 创建 gitignore 文件，排除 Hexo 不用上传的文件 同步仓库到远端 发布仓库部署 创建一个 GitHub 仓库，仓库必须取名为“GitHub 用户名.github.io” 仓库需要创建为公有仓库，即 public 创建一个分支，分支名为 ImageBed，用于做图床上传 获取 Token，选择用户 Settings-&gt;Developer settings-&gt;Personal access tokens，token 的权限获取，勾上 workflow 即可 图床分支创建用于存储图片，图床分支的相关信息部署完成后，需要在 PicGo 中进行配置 1234git checkout -b my-test //在当前分支下创建my-test的本地分支分支git push origin my-test //将my-test分支推送到远程git branch --set-upstream-to=origin/my-test //将本地分支my-test关联到远程分支my-test上 git branch -a //查看远程分支 Hexo 部署Hexo 是一个基于 Node.js 的静态网站生成器，主要用于快速、简单地搭建个人博客或静态网站。它采用 Markdown 格式来撰写内容，并提供了丰富的主题和插件生态系统，可以轻松扩展和定制网站功能和外观。 适用于个人博客、项目文档、个人简历等各种静态网站的搭建和管理。 目录架构12345678_config.yml #网站的配置信息package.json #应用程序的信息scaffolds #模版文件夹source #存放用户资源，Markdown 文档\t_drafts\t_poststhemes #主题文件夹public #网站文件 Hexo 使用使用流程 安装 hexosudo npm install -g hexo-cli 查看版本，确认安装成功 hexo -v 创建一个新文件夹 Hexo，并初始化该文件夹 hexo init Hexo 清除缓存 hexo clean 生成静态文件 hexo g 开启本地服务器并修改端口为 80hexo s -p 9050 常用命令 12345678910111213141516171819202122npm install -g hexo-cli #安装Hexo npm update hexo -g #升级 hexo init #初始化博客 命令简写 hexo n &quot;我的博客&quot;hexo new &quot;我的博客&quot; #新建文章 hexo ghexo generate #生成 hexo shexo server #启动服务预览 hexo dhexo deploy #部署 hexo server #Hexo会监视文件变动并自动更新，无须重启服务器 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令端口修改 node_modules\\hexo-server\\index.js 临时启动 hexo s -p 9050 hexo generate 将 Hexo 源码目录中已有的源码编译生成为静态网页文件，生成以下： db.json 文件：编译过程中产生的中间文件，不用关心； public 文件夹：新生成的静态网页文件就存放在这个目录下。 hexo deploy 将静态网页文件推送到 GitHub Pages Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容 配置文件配置快捷打开 站点配置文件和主题配置文件是我们 DIY 博客经常要编辑的两个文件，在 Obsidian 中没法编辑 yml 文件，可以通过 URL 来打开 yml 文件，会自动调用默认的编辑器打开。创建一个专门用于编辑配置的文件，写入我们两个配置文件所在的相对路径： 12345[打开站点配置文件](Blog/_config.yml)[打开主题配置文件](Blog/themes/stellar/_config.yml)# 或者通过shellcommand形式打开.开头的隐藏文件[Github 同步忽略文件配置](obsidian://shell-commands/?vault=BlogDeploy&amp;execute=f4b02rlcvr) 站点配置文件在 blog 根目录里的 _config.yml 文件称为站点配置文件 主题修改：theme 网站标题:title 副标题:subtitle 网站描述:description 作者:author 网站头像外部链接:avatar 网站语言:language:zh-Hans 时区:timezone:Asia&#x2F;Shanghai 自定义域名：url: 忽略文件： 12345skip_render: # 排除一些obsidian编辑器的文件和一些脚本/模板文件 - &#x27;_posts/.obsidian/*&#x27; - &#x27;_posts/Scripts/*&#x27; - &#x27;_posts/Templates/*&#x27; 主题配置文件使用的主题：stellar 或者 Next，二选其一 进入根目录 themes 文件夹，里面有个 _config.yml 文件，为主题配置文件 社交外链的设置，即在侧栏展示你的个人社交网站信息。(插件 jiathis) 插入网易云，进入网页版的网易云音乐，选择喜欢的音乐，点击生成外链播放器，在侧栏插入这首歌的音乐播放器，修改 blog/themes/next/layout/_macro 的 sidebar.swig 文件，添加刚刚复制的外链代码 设置背景，在 blog/themes/next/source/css/_custom 文件的 custom.styl 首部添加 body &#123; background:url(./background.jpg); background-attachment: fixed; &#125;，fixed 固定背景图片 增加侧栏菜单条目，默认的侧栏菜单条目有：首页、归档、标签、关于、搜索等。如果你想要增加其他的菜单条目，修改主题配置文件 _config.yml 里的 Menu Settings 中的 menu 和 menu_icons 两个地方 域名配置文件进入 blog/source 目录下，创建一个文件，文件名 CNAME，写入你的自定义域名即可 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 扩展：abbrlink&#x3D;文章永久链接 category123456789并列分类，了解一下： categories: - [Linux] - [Tools]并列+子分类，再了解一下： categories: - [Linux, Hexo] - [Tools, PHP] 自定义文章标签生成标签页面 hexo new page tags 修改 blog&#x2F;source&#x2F;tags&#x2F;index.md，添加 type: “tags” 123title: tagsdate: 2023-01-08 11:27:57type: &quot;tags&quot; 以后就可以在文章文件头添加标签了，如下 123456title: Hexo + GitHub 搭建个人博客date: 2023-01-07 13:15:00tags:- Hexo- Next- 博客 手动生成和添加是十分繁琐的，后续利用插件形式按照目录格式为文章自动生成标签。 评论系统 Waline Waline评论系统的配置 前往 Waline 官网 根据指引到 Vercel 进行 Waline 服务端部署 安装 @waline&#x2F;hexo-nextnpm install @waline/hexo-next 为了不使用魔法也能正常评论，我们需要有自己的域名解析到 Waline 服务端，可以在域名控制台给自己的博客域名添加二级域名，添加 CNAME 解析到 cname-china.vercel-dns.com 或添加 A 解析到 76.223.126.88（也可以前往 Vercel All IP 自行挑选合适的节点），接着进入 Vercel 的 Waline 应用的控制台，在 Settings-Domains 里添加上文提到的二级域名，这样在主题配置文件添加配置后就可以正常评论了 主题配置文件添加配置 配置完评论后及时到 Waline 服务端登录，以便管理评论 可选择开启评论邮件提醒功能， Waline 官网 有详细的说明 评论系统 utterancUtterances 是一个基于 Github Issues 的轻量级评论系统，主页地址 http://utteranc.es Hexo Stellar 主题的配置文件如下： 123456789101112######## Comments ########comments: service: utterances # beaudar, utterances, giscus, twikoo, waline, artalk comment_title: 快来参与讨论吧~ # utterances # https://utteranc.es/ utterances: repo: liuluhua/liuluhua.github.io issue-term: title issue-number: theme: preferred-color-scheme label: &quot;💬&quot; 其他使用情况下，在你的网页需要插入 Utterances 评论的位置，粘贴以下代码（username，reponame 分别修改为你的 GitHub 用户名，仓库名）。 1234567&lt;script src=&quot;https://utteranc.es/client.js&quot; repo=&quot;username/reponame&quot; issue-term=&quot;pathname&quot; theme=&quot;github-light&quot; crossorigin=&quot;anonymous&quot; async&gt;&lt;/script&gt; 设置字体更改站点配置文件，增加如下字段 1234inject: head: &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/satouriko/LxgwWenKai_Webfonts@v1.101/dist/LXGWWenKaiMono-Bold.css&quot; /&gt; 更改主题配置文件，找到 style 字段在 font-family 中增加字体名称： 123456style: font-family: logo: &#x27;LXGWWenKaiMono&#x27; body: &#x27;LXGWWenKaiMono&#x27; code: &#x27;LXGWWenKaiMono&#x27; codeblock: &#x27;LXGWWenKaiMono&#x27; 设置背景音乐在 stellar 主题的 _data/widgets.yml 文件中找到 welcome 字段，在其中的 content 部分添加： 12345welcome: layout: markdown title: 哈喽~ 旅人： content: |&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=224 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=512983678&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt; 插件部署插件 hexo-deployer-git 编辑 Hexo 顶层目录下的 _config.yml 文件，文件最后可以看到 deployment 相关内容 1234deploy： type: git repo: git@github.com:liuluhua/liuluhua.github.io.git branch: main repo 填写仓库 ssh 地址 branch 的填写需要和 GitHub Pages部分指定的Branch保持一致 搜索插件 hexo-generator-searchdbstellar 自带了搜索插件，故未配置该插件 安装 hexo-generator-searchdbnpm install hexo-generator-searchdb 修改主题配置文件 12local_search:\tenable: true 自动标签插件 hexo-auto-category该插件在 Hexo 进行 build 的时候会去自动根据文章目录情况来自动修改文章的 categories 信息 安装插件 npm install hexo-auto-category --save 修改站点配置文件 _config.yml，使文章链接清晰 12345678910111213# Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the max_depth of directory-tree you want to generate, should &gt; 0# multiple: multiple category hierarchiesauto_category: enable: true multiple: true depth: 5# 修改 permalink 让你的文章链接更加友好，并且有益于 SEO permalink: :year/:month/:hash.html# 规定你的新文章在 _post 目录下是以 cateory new_post_name: :category/:title| 该插件需要每次手动构建执行 hexo g 时才会更新 categories 信息。 1.仓库部署在本地，上传时使用 git hook，在我们每次执行 commit 前都自动运行 npx hexo generate 触发自动生成 categories 的行为，并将生成后的变更自动添加到本次提交中，然后一同 push 到 github 上去。这里可以使用 husky 来很方便的设置这样一个 git hook1. 安装 huksy：npm install husky --save-dev2. 执行 huksy 初始化指令：npx husky install*3. 在 package.json 中的 scripts 中写入：&quot;prepare&quot;: &quot;husky install&quot;4. 在生成的 .husky 目录创建 pre-commit 文件（chmod a+x pre-commit），并写入以下内容，之后提交代码时，检查有无 categories 的生成信息。 1234#!/usr/bin/env sh . &quot;$(dirname -- &quot;$0&quot;)/_/husky.sh&quot; npx hexo generate &amp;&amp; git add . 2. 仓库部署在 GitHub 时直接利用 GitHub Actions 自动生成 百度数据分析进入 https://tongji.baidu.com/ 申请账号后，输入网址获取统计代码，之后在 stellar 主题的配置文件 _config.yml 的扩展插件部分插入以下代码： 1234 baiduanalytics: enable: true # 使能百度分析接口 inject: | ...扩展插件代码 阅读量统计用于 next 主题 Leancloud（https://console.leancloud.cn/） 创建应用，进入该应用的 设置-&gt;应用凭证，找到 AppID 和 AppKey，记录下来后面配置要用 配置 _config.yml 启用网页访问统计，配置 leancloud 的 app_id 和 app_key，打开计数功能，统计来源改为 leancloud 123456789101112131415161718#网页访问统计#Analysis of website visitorsweb analytics:\tenable:trueleancloud:\tapp id: app key: # 浏览量计数# Number of visitsviews:\tenable:true\t#统计数据来源\t#Data Source\t#Options:busuanzi | leancloud\tsource:&quot;leancloud&quot;\tformat:&quot;&#123;&#125;次&quot; 页面底部展示网站的 PV、UV 统计数用于 next 主题显示页面的访问量和访客数量 123456789101112# 展示网站的 pv、w 统计数# Display website pv and uv statisticsstatistics:\tenable:true\t#统计数据来源，使用leancloud 需要设置&#x27;web analytics:leancloud&#x27;中的参数;busuanzi 显示统计数据很大属于正常现象，部署后会正常\t# Data source.If use leancloud,you need to set the parameter in&#x27;web analytics:leancloud\t# Options:busuanzian | leancloud\tsource:&quot;leancloud&#x27;\t#页面显示的文本，&#123;&#125;是数字的占位符(必须包含)，下同\t# Displayed text, &#123;&#125;is a placeholder for numbers (must be included), the same below\tpv format:&quot;总访问量 &#123;&#125;次&quot;\tuv format:&quot;总访客数 &#123;&#125;人&quot; Canvas nest 背景动画 在 blog/source/_data 文件夹下新建 footer.njk 并编辑 1&lt;script color=&quot;0,255,255&quot; opacity=&quot;1&quot; zIndex=&quot;-1&quot; count=&quot;70&quot; src=&quot;https://cdn.staticfile.org/canvas-nest.js/1.0.1/canvas-nest.js&quot;&gt;&lt;/script&gt; 修改主题配置文件 12custom_file_path: footer: source/_data/footer.njk stellar 主题中直接添加在主题配置文件 _config.yml footer 的 content 中 MathJax 安装 hexo-filter-mathjax 修改主题配置文件 123math: mathjax: enable: true 此后可在文章文件开头添加参数 mathjax: true 以使用 MathJax CDN 修改主题配置文件 123vendors: plugins: custom custom_cdn_url: https://cdn.staticfile.org/$&#123;cdnjs_name&#125;/$&#123;version&#125;/$&#123;cdnjs_file&#125; 字数统计 安装 hexo-word-counter 运行时间next 主题在 /blog/themes/next/layout/_partials/footer.njk 中添加 stellar 主题在主题配置文件 _config.yml 中找到 footer: 中的 content: |，在其后添加 1234567891011121314151617181920&lt;div&gt; &lt;span id=&quot;timeDate&quot;&gt;载入天数...&lt;/span&gt; &lt;span id=&quot;times&quot;&gt;载入时分秒...&lt;/span&gt;&lt;/div&gt;&lt;script&gt; var now = new Date(); function createtime() &#123; var grt= new Date(&quot;05/20/2024 05:20:00&quot;);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125; document.getElementById(&quot;timeDate&quot;).innerHTML = &quot;本站已安全运行 &quot;+dnum+&quot; 天 &quot;; document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; 小时 &quot; + mnum + &quot; 分 &quot; + snum + &quot; 秒&quot;; &#125;setInterval(&quot;createtime()&quot;,250);&lt;/script&gt; 站点地图 安装 hexo-generator-sitemap 修改主题配置文件 12menu: sitemap: /sitemap.xml || fa fa-sitemap 执行 hexo cl &amp;&amp; hexo g 生成 sitemap.xml 此时可以在 blog/public 文件夹下看到 sitemap.xml 验证，进入 Google Search Console ，选择网址前缀，输入网址时记得加上 https:&#x2F;&#x2F;，选择 HTML 标记，你会得到元标记 &lt;meta name=&quot;google-site-verification&quot; content=&quot;xxxxxxxx&quot; /&gt;，将 content 后的内容加入到主题配置文件中 google_site_verification: &quot;xxxxxxxx&quot;，执行 hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 点击前往资源页面 添加站点地图，成功提交 静态资源压缩 安装 hexo-neat 主题配置文件添加配置 123456789101112131415161718neat_enable: trueneat_html: enable: true exclude:neat_css: enable: true exclude: - &#x27;**/*.min.css&#x27;neat_js: enable: true mangle: true output: compress: exclude: - &#x27;**/*.min.js&#x27; 文章页眉显示标签用于 next 主题 在 blog/source/_data 文件夹下新建 post-meta.njk 并编辑 12345678910&lt;span class=&quot;post-meta-item&quot;&gt; &#123;%- if post.tags and post.tags.length %&#125; &#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27; if theme.tag_icon else &#x27;#&#x27; %&#125; &lt;span class=&quot;post-tags&quot;&gt; &#123;%- for tag in post.tags.toArray() %&#125; &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&#123;&#123; tag_indicate &#125;&#125; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;%- endfor %&#125; &lt;/span&gt; &#123;%- endif %&#125;&lt;/span&gt; 修改主题配置文件 12custom_file_path: postMeta: source/_data/post-meta.njk","categories":["0.平台","服务器"]},{"title":"Markdown笔记","path":"/2024/05/16/1-语言-前端-Markdown笔记/","content":"Markdown 笔记语法表格 &amp; 文本样式 样式 语法 示例 加粗 前后 ** 或 __ 加粗 1 加粗 2 斜体 前后 * 或 _ 斜体 1 斜体 2 删除线 前后 ~~ 删除线 内联代码 前后 &#96; code 下划线 前&lt;u&gt; 后 &lt;/u&gt; 下划线 高亮 前后== &#x3D;&#x3D;高亮文本&#x3D;&#x3D; 引用 此内容为引用内容 链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接 Blog网址 图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中 图片可拖动为文件到任意窗口使用 无序列表 项目 项目 1 项目 A 项目 B 项目 2 有序列表 项目 1 项目 A 项目 B 项目 2 任务列表 A 计划 A1 计划 A2 计划 B 计划 代码块代码块支持 168 种编程语言 12345678910111213141516// javascript 冒泡排序function bubbleSort(array) &#123; let swapped = true; do &#123; swapped = false; for (let j = 0; j &lt; array.length; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; let temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; swapped = true; &#125; &#125; &#125; while (swapped); return array;&#125; KaTeX 数学公式内联公式质能方程 $E&#x3D;mc^2$ 公式块$$\\displaystyle \\left( \\sum_{k&#x3D;1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k&#x3D;1}^n a_k^2 \\right) \\left( \\sum_{k&#x3D;1}^n b_k^2 \\right)$$","categories":["1.语言","前端"]},{"title":"Nginx学习笔记","path":"/2024/05/16/3-软件-Web相关-Nginx学习笔记/","content":"Nginx功能： Web 服务器 负载均衡 API 网关 DDoS 防御 反向代理 Web 应用防火墙 缓存 下载sudo apt install nginx -y 配置 nginxnginx 的配置文件位于 /etc/nginx/ 根据配置文件中的 root 确定根目录位置 /var/www/html 链接网页根目录到指定位置 ln -s /var/www/html ~/html 配置文件cd /etc/nginx/sites-enable 原来的配置为 default（链接到 sites-avaliable），删除并添加自己的页面 输入下列内容 12345678910111213141516171819202122232425server &#123; listen 8080 default_server;# 注意这里，要把默认的那个default_server去掉,因为我们在下面要单独配置域名访问，所以这里不要留default_server，不然会报错。 #server_name mytest.com; //这里写你想设置的域名，可以写多个，与名之间用空格隔开 root /home/ubuntu/html;# //这里是你虚拟机的根目录，写绝对路径 # Load configuration files for the default server block. location / &#123; index index.php index.html index.htm;# //这里配置默认访问的页面 &#125; #location ~* \\.php$ &#123; //这里配置php解析.php文件 # fastcgi_index index.php; # fastcgi_pass 127.0.0.1:9000; # include fastcgi_params; # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param SCRIPT_NAME $fastcgi_script_name; #&#125; #error_page 404 /404.html; //默认的错误页面 # location = /40x.html &#123; #&#125; #error_page 500 502 503 504 /50x.html; # location = /50x.html &#123; #&#125;&#125; 123456789101112131415161718192021http &#123; upstream backend1 &#123; server 127.0.0.1:8000; # 本地端口 1 &#125; upstream backend2 &#123; server 127.0.0.1:8001; # 本地端口 2 &#125; server &#123; listen 80; # 远程访问的端口 location /service1/ &#123; proxy_pass http://backend1; &#125; location /service2/ &#123; proxy_pass http://backend2; &#125; &#125;&#125; 输入 nginx -t 检查配置文件 之后重新启动 nginx 并访问 sudo systemctl start nginx sudo systemctl enable nginx 直接输入 IP 地址即可访问，根据设置的端口进行访问 修改页面，重载页面sudo nginx -s reload 命令查看 nginx 版本 nginx -v 配置文件所在位置 /etc/nginx，文件名 nginx.conf 检查配置文件是否有问题 nginx -t 重新加载 nginx 配置文件 nginx -s reload 关闭 nginx nginx -s quit 或 nginx -s stop eventshttpserverincludelistenserver_nameroot 根目录节点index 指定页面returnlocation &#x3D;(完全匹配) ~(启用正则表达式)rewrite 重写proxy_pass","categories":["3.软件","Web相关"]},{"title":"ffmpeg-m3u8转mp4","path":"/2024/05/16/3-软件-音视频-ffmpeg-m3u8转mp4/","content":"FFmpeg 命令行工具将 m3u8 文件转换为 mp4 格式 下载并安装 FFmpeg您可以从 官方网站 下载适合您操作系统的版本。 打开命令行工具 在 Windows 上，您可以按下 Win + R 键，然后输入 cmd 并按 Enter 键打开命令提示符。 在 Mac OS 或 Linux 上，您可以打开终端应用程序。 转换 m3u8 文件在命令行中，导航到包含 m3u8 文件的目录，然后运行以下命令： 1ffmpeg -i input.m3u8 -c copy output.mp4 input.m3u8 是要转换的 m3u8 文件的名称，output.mp4 是转换后的 mp4 文件的名称。 该命令将使用 FFmpeg 将 m3u8 文件转换为 mp4 格式，并将其保存在相同的目录中。 请注意，此命令只能将 m3u8 文件转换为 mp4 格式，而不能将其中的视频文件下载到本地计算机。 如果您需要下载 m3u8 文件中的视频文件，请使用其他工具或软件。 将分段式 m3u8 文件转换为 MP4 文件1234567891011121314151617#!/bin/bashcd ./m3u8Movie #分段式m3u8文件所在文件夹for i in &#123;1..2473&#125; #轮询所有分段式文件数量do if [ -f &quot;$i&quot; ]; then #检测文件存在 mv &quot;$i&quot; &quot;$i.mp4&quot; #重命名 fi echo &quot;file &#x27;./$i.mp4&#x27;&quot; &gt;&gt; list.txt #添加到列表中去done#调用ffmpeg进行视频连接操作ffmpeg -f concat -safe 0 -i list.txt -c copy ../movie.mp4#-f 指定输入格式为concat，表示要进行视频文件的连接操作#-safe 0 设置安全模式为0，允许使用不安全的文件名#-i 指定文本文件包含了要连接的视频文件的列表及其路径#-c 直接复制输入视频文件的音视频流，而不进行重新编码。这样可以加快处理速度而不损失质量。#指定输出文件路径和名称","categories":["3.软件","音视频"]},{"title":"Qt多项目管理","path":"/2024/03/03/1-语言-Qt-Qt多项目管理/","content":"Qt 工程过大或需要将工程分模块编译成库的形式加载时,需要将整体的 Qt 项目拆分各个小模块进行编译。 1.条件编译文件123456789unix&#123; //执行unix环境下的配置选项&#125;win32&#123; //执行Windows环境下的配置选项&#125;contains(QT_ARCH, arm64)&#123; //执行在架构为arm64的环境下的配置选项&#125; 2. 子项目 lib子项目工程文件为 12345678QT -= guiTARGET = printHelloCONFIG += staticlibTEMPLATE = libDEFINES += printHello_LIBRARYCONFIG -= debug_and_releaseSOURCES += printHello. cppHEADERS += printHello. h 3. 子项目 dll1234567QT -= guiTARGET = printNiceTEMPLATE = libDEFINES += printNice_LIBRARYCONFIG -= debug_and_releaseSOURCES += printNice. cppHEADERS += printNice. h 4.可执行程序项目 exe1234567QT += core gui widgetsTARGET = printTEMPLATE = appSOURCES += main. cpp printwindow. cppLIBS += -LprintHello -lprintHello -LprintNice -lprintNiceFORMS += printwindow. uiHEADERS += printwindow. h 5.管理项 Dirs123TEMPLATE = subdirsSUBDIRS += printHello/printHello.pro printNice/printNice.pro print.proCONFIG += ordered","categories":["1.语言","Qt"]},{"path":"/photo.html","content":""},{"path":"/photo_sl.html","content":""}]